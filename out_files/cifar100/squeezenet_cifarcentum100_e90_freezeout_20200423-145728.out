# Model: squeezenet
# Dataset: cifarcentum
# Batch size: 128
# Freezeout: True
# Low precision: False
# Epochs: 90
# Initial learning rate: 0.1
# module_name: models_cifarcentum.squeezenet
<function squeezenet at 0x7fb78a26ff28>
# model requested: 'squeezenet'
# printing out the model
SqueezeNet(
  (stem): Sequential(
    (0): Conv2d(3, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (fire2): Fire(
    (squeeze): Sequential(
      (0): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (expand_1x1): Sequential(
      (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (expand_3x3): Sequential(
      (0): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
  )
  (fire3): Fire(
    (squeeze): Sequential(
      (0): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (expand_1x1): Sequential(
      (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (expand_3x3): Sequential(
      (0): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
  )
  (fire4): Fire(
    (squeeze): Sequential(
      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (expand_1x1): Sequential(
      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (expand_3x3): Sequential(
      (0): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
  )
  (fire5): Fire(
    (squeeze): Sequential(
      (0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (expand_1x1): Sequential(
      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (expand_3x3): Sequential(
      (0): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
  )
  (fire6): Fire(
    (squeeze): Sequential(
      (0): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (expand_1x1): Sequential(
      (0): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (expand_3x3): Sequential(
      (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
  )
  (fire7): Fire(
    (squeeze): Sequential(
      (0): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (expand_1x1): Sequential(
      (0): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (expand_3x3): Sequential(
      (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
  )
  (fire8): Fire(
    (squeeze): Sequential(
      (0): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (expand_1x1): Sequential(
      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (expand_3x3): Sequential(
      (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
  )
  (fire9): Fire(
    (squeeze): Sequential(
      (0): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (expand_1x1): Sequential(
      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (expand_3x3): Sequential(
      (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
  )
  (conv10): Conv2d(512, 100, kernel_size=(1, 1), stride=(1, 1))
  (avg): AdaptiveAvgPool2d(output_size=1)
  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
)
# model is full precision
PARAM TOTAL COUNT: 102
PARAM TO FREEZE COUNT: 102

module.stem.0.weight
[0.1, 0.10088384267912825, 0.10053591041744064, 0.0999578198101117, 0.09915225683538814, 0.09812296437474749, 0.09687472482237458, 0.09541333786475781, 0.09374559353364734, 0.0918792406575792, 0.0898229508585488, 0.08758627826111579, 0.08517961510114358, 0.08261414344042829, 0.07990178321156519, 0.0770551368344512, 0.07408743066175172, 0.07101245352539297, 0.06784449266961103, 0.06459826736823124, 0.06128886053461177, 0.05793164864201136, 0.054542230279991735, 0.05113635367880273, 0.04772984353849288, 0.044338527502719036, 0.040978162618878995, 0.03766436212625511, 0.034412522912332426, 0.031237753974350746, 0.028154806218479014, 0.025178003922785554, 0.022321178182447728, 0.019597602646433312, 0.017019931844240544, 0.01460014238924829, 0.01234947733186318, 0.010278393921015021, 0.0083965150167161, 0.006712584379435493, 0.005234426044027662, 0.003968907966975204, 0.002921910115851916, 0.0020982971492716097, 0.001501895814259612, 0.0011354771660654897, 0.0010007436930289206, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.stem.0.bias
[0.1, 0.10088553567013014, 0.10054266676383303, 0.09997296313149238, 0.0991790332028882, 0.09816451204431016, 0.09693404471514046, 0.09549326500010952, 0.09384876961460016, 0.09200808800110345, 0.08997964785511511, 0.08777273653831481, 0.08539745855570091, 0.08286468929137482, 0.08018602521479878, 0.07737373078551167, 0.07444068229940325, 0.07140030893365108, 0.0682665312602498, 0.06505369750965323, 0.0617765178763512, 0.058449997167167284, 0.05508936610065251, 0.05171001157212554, 0.048327406203646464, 0.04495703750148394, 0.04161433694543428, 0.03831460933466163, 0.035072962713554805, 0.031904239198440175, 0.028822947021865816, 0.025843194105596646, 0.022978623466462275, 0.02024235075080559, 0.017646904183536174, 0.015204167206735463, 0.01292532407044733, 0.010820808624770743, 0.008900256547713335, 0.007172461227534282, 0.005645333501572674, 0.004325865435899644, 0.003220098311632024, 0.00233309496448471, 0.001668916604206632, 0.0012306042200347137, 0.0010201646573020852, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.stem.1.weight
[0.1, 0.10088719995079998, 0.10054930875724394, 0.0999878509850621, 0.09920535993282756, 0.09820536620170793, 0.096992381765386, 0.09557187961202561, 0.09395026905013826, 0.09213486678977055, 0.09013386392949395, 0.087956288998152, 0.0856119672181204, 0.08311147617388426, 0.08046609808595613, 0.07768776890547491, 0.0747890244591706, 0.07178294388768972, 0.06868309063248672, 0.06550345123754962, 0.06225837224208589, 0.05896249544890939, 0.055630691860597214, 0.052277994581496824, 0.04891953098832961, 0.04557045447543743, 0.04224587608263742, 0.03896079631418069, 0.035730037456447504, 0.03256817669976214, 0.029489480366081306, 0.0265078395393214, 0.023636707388760666, 0.02088903846831284, 0.018277230265554358, 0.015813067264236137, 0.013507667772669579, 0.011371433757897682, 0.009414003911999192, 0.007644210162291009, 0.006070037821654799, 0.004698589558789484, 0.003536053350956108, 0.002587674563812297, 0.0018577322843120517, 0.0013495200134569997, 0.0010653308060134083, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.stem.1.bias
[0.1, 0.1008888360760043, 0.10055583860073712, 0.10000248826643972, 0.09923124557689228, 0.09824553990664374, 0.09704975425210248, 0.09564920574229314, 0.09405012199593964, 0.09225961343000363, 0.09028564164281064, 0.08813698401234948, 0.08582319466716118, 0.08335456200336218, 0.08074206293670494, 0.07799731409309685, 0.07513252015461143, 0.07216041959067432, 0.06909422801573344, 0.06594757942527647, 0.06273446557149345, 0.05946917374815365, 0.05616622326134002, 0.05284030086852764, 0.04950619547308011, 0.046178732364548405, 0.042872707297176293, 0.0396028206997365, 0.0363836123092367, 0.03322939651915079, 0.030154198729653026, 0.027171692982877083, 0.024295141160509067, 0.02153733401407501, 0.018910534290135752, 0.016426422203285863, 0.014096043499414113, 0.011929760340165234, 0.009937205226997942, 0.008127238169718536, 0.00650790728994261, 0.005086413034663916, 0.0038690761590565994, 0.0028613096208773663, 0.0020675945114404285, 0.0014914601301897691, 0.0011354682914681438, 0.001001201933263656, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire2.squeeze.0.weight
[0.1, 0.10089044458858155, 0.10056225844985306, 0.10001687976651251, 0.09925669850600122, 0.09828504594714907, 0.09710618008178971, 0.09572526695531863, 0.09414835802796394, 0.0923823636559779, 0.0904350228089599, 0.08831486915601666, 0.08603119366937689, 0.08359400390934, 0.08101398016898063, 0.07830242867079255, 0.0754712320203744, 0.07253279713427992, 0.069500000870224, 0.06638613359790489, 0.06320484095772752, 0.05997006406265329, 0.056695978405225736, 0.05339693173749356, 0.05008738119605566, 0.046781829947759125, 0.043494763633682855, 0.04024058688992277, 0.0370335602233585, 0.033887737519025476, 0.03081690445294859, 0.027834518080325905, 0.024953647863799878, 0.022186918400243116, 0.019546454097042126, 0.017043826040319843, 0.014690001287931537, 0.012495294809443381, 0.010469324283703119, 0.008620967952089536, 0.006958325712136919, 0.005488683622030876, 0.004218481971524157, 0.0031532870591930266, 0.0022977667997119136, 0.0016556702680409867, 0.0012298112701681564, 0.0010220560124021441, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire2.squeeze.0.bias
[0.1, 0.10089202601963099, 0.10056857041374144, 0.10003103017390096, 0.0992817269144817, 0.0983238968457006, 0.0971616767965594, 0.09580008634804892, 0.09424500615378345, 0.09250315254169772, 0.09058204850650045, 0.08848999121816692, 0.0862360161868004, 0.08382985823863245, 0.0812819094717055, 0.07860317437282519, 0.0758052222896307, 0.07290013746305424, 0.06990046683597721, 0.06681916586349566, 0.06366954255883815, 0.06046520001659933, 0.0572199776615293, 0.05394789147662238, 0.05066307346865839, 0.04737971063264163, 0.04411198367874813, 0.04087400578641672, 0.037679761650102686, 0.034543047079952725, 0.03147740941826369, 0.028496089029063643, 0.02561196211351966, 0.022837485098150173, 0.020184640836026863, 0.017664886853320967, 0.015289105864714974, 0.013067558771401911, 0.011009840344671468, 0.009124837786484128, 0.0074206923460084446, 0.005904764157897851, 0.004583600454169278, 0.0034629072869751913, 0.002547524884396939, 0.0018414067456971597, 0.0013476025663177174, 0.0010682450663694156, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire2.squeeze.1.weight
[0.1, 0.10089358088879381, 0.10057477655626441, 0.10004494407736048, 0.09930633882414173, 0.09836210486519137, 0.09721626158205665, 0.09587368655968853, 0.0943400948237113, 0.0926220145129048, 0.09072675909045531, 0.08866239621226549, 0.08643771338484343, 0.08406218055895759, 0.08154590981828683, 0.07889961233466221, 0.07613455277313148, 0.07326250134093348, 0.07029568368449833, 0.06724672884775038, 0.06412861551324298, 0.06095461675496409, 0.05773824353798676, 0.054493187205473276, 0.051233261197852466, 0.04797234225225747, 0.044724311332524525, 0.04150299454119958, 0.03832210426507646, 0.03519518080479637, 0.0321355347369774, 0.029156190254225268, 0.026269829724213246, 0.023488739703830298, 0.020824758638202597, 0.018289226467221094, 0.015892936354088595, 0.013646088741366386, 0.011558247930092962, 0.009638301366807298, 0.007894421811782553, 0.006334032549510598, 0.004963775789528468, 0.003789484392097053, 0.0028161570390888117, 0.0020479369557765293, 0.0014880942740992877, 0.0011390121124810572, 0.0010021764314569405, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire2.squeeze.1.bias
[0.1, 0.10089510970452692, 0.10058087889707105, 0.10005862596812203, 0.09933054208824099, 0.09839968201475957, 0.09726995127520384, 0.09594608978121684, 0.09443365194172937, 0.0927389833588162, 0.0908691942040129, 0.08883212938679633, 0.08663633564038947, 0.08429102566298666, 0.08180603946484816, 0.07919180308343672, 0.07645928483981164, 0.07361994931981133, 0.07068570927310137, 0.0676688756319013, 0.06458210585909185, 0.06143835084241413, 0.05825080055757192, 0.05503282872821369, 0.051797936714979675, 0.04855969686903355, 0.045331695587745455, 0.04212747631144268, 0.038960482700391284, 0.03584400223041625, 0.03279111044381088, 0.029814616089436904, 0.02692700738218652, 0.024140399607280295, 0.02146648428923332, 0.018916480138756808, 0.016501085983402775, 0.014230435879436794, 0.012114056593271711, 0.01016082763085388, 0.008378943982703085, 0.0067758817409134635, 0.005358366732373109, 0.004132346299805383, 0.0031029643490274087, 0.0022745397671180326, 0.0016505483020442294, 0.0012336079797717438, 0.0010254681200445028, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire2.expand_1x1.0.weight
[0.1, 0.10089661296436964, 0.10058687941264395, 0.10007208024217291, 0.09935434439536371, 0.09843664005547902, 0.09732276237177027, 0.09601731776470844, 0.09452570487621764, 0.09285409224369184, 0.09100939279012303, 0.08899923523583653, 0.08683193255005983, 0.08451644757279282, 0.08206235594914933, 0.0794798065294547, 0.07677947939886381, 0.07397254171006719, 0.0710706015017386, 0.06808565969370671, 0.06503006045737392, 0.061916440166625036, 0.0587576751403376, 0.055566828392604434, 0.052357095610881504, 0.049141750585467533, 0.045934090315990786, 0.04274738002191408, 0.0395947982844661, 0.036489382546863534, 0.03344397519820684, 0.030471170464018562, 0.02758326232305773, 0.024792193665799035, 0.02210950690483107, 0.019546296241423473, 0.01711316178566369, 0.01482016571989856, 0.012676790686766148, 0.010691900573903245, 0.00887370385750269, 0.007229719656312549, 0.005766746636460168, 0.004490834895694761, 0.0034072609433204773, 0.0025205058792901794, 0.0018342368626999164, 0.0013512919463204757, 0.001073668339882954, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire2.expand_1x1.0.bias
[0.1, 0.10089809115520323, 0.10059278003731885, 0.10008531120247993, 0.09937775327319563, 0.09847299050591395, 0.09737471103377204, 0.09608739183246072, 0.09461628047048758, 0.09296737371823127, 0.0911473931029838, 0.08916375750962725, 0.08702455293863431, 0.0847384995446695, 0.08231491609015379, 0.07976368195869184, 0.07709519688320941, 0.07432033855296251, 0.07145041827222752, 0.06849713485142321, 0.06547252691862042, 0.06238892384583496, 0.059258895490145215, 0.05609520095450753, 0.05291073657713862, 0.04971848336147821, 0.04653145406102657, 0.04336264013475745, 0.040224958789334866, 0.03713120032400894, 0.034093975992830955, 0.03112566659672003, 0.02823837201493847, 0.025443861881702973, 0.02275352760899157, 0.02017833595111822, 0.017728784300362295, 0.015414857895883722, 0.013245989120355552, 0.011231019050234915, 0.0093781614164077, 0.007694969122115341, 0.006188303454649119, 0.004864306116315714, 0.003728374188685634, 0.002785138132179398, 0.002038442910672577, 0.0014913323180627317, 0.001146036570688618, 0.0010039632161793536, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire2.expand_1x1.1.weight
[0.1, 0.10089954475350396, 0.10059858266427779, 0.10009832306115585, 0.0994007760922079, 0.09850874464754225, 0.09742581309670516, 0.09615633288593171, 0.09470540505312175, 0.09307885973079895, 0.09128323271941496, 0.08932573922513154, 0.08721424486760798, 0.08495723407429068, 0.08256377598820312, 0.08004348802622593, 0.07740649723429759, 0.07466339959481848, 0.07182521744977012, 0.06890335521063175, 0.06590955353306177, 0.06285584214047941, 0.05975449148611146, 0.05661796344773611, 0.05345886125324284, 0.0502898788382178, 0.04712374983904671, 0.04397319642649159, 0.0408508781853387, 0.037769341245530226, 0.03474096786918116, 0.03177792669605163, 0.028892123847398612, 0.026095155084682138, 0.0233982592153622, 0.020812272933011924, 0.01834758727320839, 0.016014105860171275, 0.013821205111922197, 0.011777696563869417, 0.009891791462209393, 0.00817106776941634, 0.006622439714398692, 0.00525213000967638, 0.004065644847215921, 0.0030677517733956818, 0.0022624605320039565, 0.0016530069522469484, 0.0012418399465079547, 0.0010306116701034754, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire2.expand_1x1.1.bias
[0.1, 0.10090097422558925, 0.10060428914651687, 0.10011111994157135, 0.09942342006925006, 0.09854391353004979, 0.09747608407661626, 0.09622416141449207, 0.09479310444812197, 0.09318858163847883, 0.09141694855011402, 0.08948522267656941, 0.08740105564386809, 0.08517270290218665, 0.08280899102576128, 0.08031928275055389, 0.07771343988816484, 0.07500178426289174, 0.07219505682666373, 0.06930437511379813, 0.06634118920410255, 0.06331723636875423, 0.06024449457860529, 0.057135135059069045, 0.05400147407951923, 0.050855924168165485, 0.047710944945644596, 0.04457899377207722, 0.04147247640307847, 0.03840369785017579, 0.035384813640277075, 0.03242778166725192, 0.029544314826343832, 0.02674583461902912, 0.024043425912095896, 0.021447793030143304, 0.018969217355420193, 0.01661751660295157, 0.014402005932265278, 0.012331461049756482, 0.0104140834478429, 0.008657467918599226, 0.007068572470550482, 0.005653690767784696, 0.004418427200554508, 0.0033676746861137524, 0.0025055952877207233, 0.0018356037285765727, 0.0013603538660010342, 0.0010817281794213032, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire2.expand_3x3.0.weight
[0.1, 0.10090238002785763, 0.10060990129778898, 0.10012370588041329, 0.09944569227105456, 0.0985785079764991, 0.097525539177014, 0.09629089750399414, 0.09487940398486856, 0.09329657021795794, 0.09154857685079151, 0.08964224944592161, 0.08758503182847453, 0.08538495701951053, 0.08305061586869207, 0.08059112350874371, 0.07801608376269197, 0.07533555164286782, 0.07255999408810583, 0.06970024909245302, 0.0667674833849818, 0.06377314882595868, 0.060728937689633146, 0.05764673700825815, 0.054538582155619776, 0.05141660985132321, 0.04829301076934344, 0.04517998193589512, 0.04208967910249823, 0.03903416928021309, 0.036025383620389005, 0.033075070825917714, 0.030194751274911537, 0.027395672035943675, 0.02468876295050745, 0.022084593954183336, 0.01959333380316634, 0.017224710367318107, 0.014987972644791604, 0.01289185464655333, 0.010944541291827085, 0.009153636447630502, 0.00752613323720358, 0.006068386733268882, 0.004786089142750576, 0.003684247579851251, 0.002767164514277936, 0.002038420970963161, 0.0015008625468828298, 0.00115658829957228, 0.0010069425507287836, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire2.expand_3x3.0.bias
[0.1, 0.10090376260702254, 0.1006154208935224, 0.10013608482969137, 0.09946759961765515, 0.09861253858837576, 0.097574193295625, 0.09635656084516225, 0.09496432850789299, 0.09340285567623953, 0.09167815323318283, 0.08979686041339414, 0.08776621924552962, 0.08559404667407196, 0.08328870446803616, 0.08085906703237541, 0.07831448724599725, 0.07566476045789623, 0.07292008677999995, 0.07009103182188178, 0.06718848601849207, 0.0642236227074755, 0.06120785511745556, 0.05815279243285975, 0.05507019510441405, 0.05197192957733801, 0.04886992261151475, 0.045776115369479814, 0.04270241744896713, 0.03966066103696351, 0.03666255536175552, 0.03371964161830527, 0.03084324854046984, 0.028044448791088805, 0.025334016337816054, 0.02272238497877733, 0.020219608177709132, 0.017835320363193016, 0.015578699840964098, 0.013458433462062287, 0.011482683182836545, 0.009659054645528745, 0.007994567900386478, 0.006495630382009681, 0.005168012243958541, 0.004016824146572056, 0.0030464975835030263, 0.0022607678227020917, 0.0016626595275198433, 0.0012544751132781298, 0.0010377858841321798, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire2.expand_3x3.1.weight
[0.1, 0.10090512240033983, 0.10062084967171599, 0.10014826065869414, 0.09948914888572148, 0.09864601575051515, 0.09762206103099763, 0.09642117074180685, 0.09504790238646658, 0.09350746766118656, 0.0918057126759335, 0.08994909576783583, 0.08794466299112269, 0.08580002137661548, 0.08352331006225483, 0.08112316940422577, 0.07860870818590751, 0.07598946904909336, 0.07327539227867283, 0.0704767780782167, 0.06760424747963358, 0.0646687020352492, 0.061681282445281864, 0.05865332627772647, 0.0555963249411052, 0.05252188007337714, 0.049441659512515765, 0.046367353015850626, 0.04331062789622265, 0.04028308474331867, 0.037296213398227335, 0.03436134934829723, 0.03148963070778384, 0.028691955947547615, 0.025978942534223805, 0.02336088663583249, 0.02084772404675027, 0.01844899248033747, 0.0161737953723241, 0.014030767332324657, 0.012028041374596714, 0.01017321805240613, 0.008473336613137029, 0.006934848283615996, 0.005563591787035454, 0.00436477118439193, 0.00334293612453354, 0.002501964577769371, 0.0018450481185690306, 0.001374679813205553, 0.0010926447583096957, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire2.expand_3x3.1.bias
[0.1, 0.10090645983582973, 0.1006261893338114, 0.10016023715589589, 0.09951034671181187, 0.09867894963591267, 0.09766915668895707, 0.09648474611886654, 0.09513014952400789, 0.09361043527189589, 0.09193128953535587, 0.0900989950171023, 0.08812040744233705, 0.08600292990732283, 0.08375448517990974, 0.08138348605565499, 0.07889880388045178, 0.07630973535744329, 0.07362596776241714, 0.07085754269783069, 0.06801481852108529, 0.06510843158762829, 0.06214925645389564, 0.05914836518900001, 0.05611698594740444, 0.0530664609575858, 0.050008204083878176, 0.046953658120283265, 0.043914251976037065, 0.040901357913128086, 0.03792624899576724, 0.03500005691101667, 0.03213373031839644, 0.029337993884308133, 0.026623308154552595, 0.023999830415083148, 0.0214773766874376, 0.019065385001047847, 0.016772880079846758, 0.014608439575301935, 0.01258016197221868, 0.010695636287395994, 0.008961913674511511, 0.00738548104147867, 0.005972236778989342, 0.004727468691056552, 0.0036558342101322854, 0.002761342970827579, 0.00204734180743738, 0.0015165022314033373, 0.0011708104355690576, 0.00101155986262793, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire3.squeeze.0.weight
[0.1, 0.10090777533249282, 0.10063144154554313, 0.10017201803081582, 0.09953119959554654, 0.09871135021042028, 0.09771549428891504, 0.09654730553028062, 0.09521109336731105, 0.09371178706890432, 0.09205491755605487, 0.09024659699835974, 0.08829349626630612, 0.08620282032251886, 0.08398228164274923, 0.08164007176465436, 0.07918483106932382, 0.07662561690702868, 0.07397187018477686, 0.07123338053893268, 0.06842025022137849, 0.06554285683244197, 0.06261181503806638, 0.059637937412449174, 0.056632194550599514, 0.053605674597959264, 0.05056954234638186, 0.04753499804736372, 0.0445132360944653, 0.041515403727342304, 0.03855255990972676, 0.03563563453305684, 0.03277538809625282, 0.029982372010379645, 0.027266889674631752, 0.024638958467230618, 0.0221082727914496, 0.01968416831308925, 0.017375587521330366, 0.015191046740010261, 0.013138604711017486, 0.011225832865700103, 0.009459787393956153, 0.007846983214043025, 0.006393369939130588, 0.005104309929257327, 0.003984558509655566, 0.003038246428419821, 0.002268864618232113, 0.0016792513183576598, 0.0012715816044180086, 0.001047359364565991, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire3.squeeze.0.bias
[0.1, 0.10090906930052064, 0.10063660793776688, 0.10018360691583056, 0.09955171390270323, 0.09874322723733216, 0.09776108757003736, 0.0966088671666962, 0.09529075691559788, 0.09381155108422734, 0.09217662988142138, 0.09039193988832261, 0.08846397242930809, 0.08639973996156264, 0.08420675056917352, 0.08189298065451674, 0.07946684592626324, 0.07693717078952789, 0.07431315624949623, 0.07160434644527107, 0.06882059393566255, 0.06597202386318572, 0.06306899712660888, 0.06012207269600253, 0.05714196920735823, 0.05413952597646569, 0.051125663573850205, 0.04811134410416795, 0.045107531334532235, 0.042125150816792946, 0.03917505014881379, 0.0362679595192857, 0.03341445267958439, 0.03062490848462598, 0.027909473142605543, 0.0252780233109247, 0.022740130172537027, 0.020305024623373635, 0.017981563697470178, 0.01577819835191487, 0.013702942728790912, 0.011763345005914676, 0.00996645994239212, 0.00831882321885168, 0.006826427665683737, 0.005494701465750229, 0.004328488410846192, 0.0033320302837245843, 0.002508951429765465, 0.0018622455744055012, 0.0013942649342761119, 0.0011067116616552898, 0.0010006316533517127, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire3.squeeze.1.weight
[0.1, 0.10091034214150087, 0.10064169010726709, 0.1001950073679415, 0.09957189586823754, 0.09877459028186202, 0.09780594999727267, 0.09666944886301242, 0.0953691627293964, 0.0939097548312317, 0.09229645906399137, 0.09053506121342003, 0.08863187820588758, 0.08659373545390553, 0.0844279423780522, 0.08214226619309294, 0.07974490405230636, 0.07724445364991606, 0.07464988238705648, 0.07197049521185375, 0.06921590124895653, 0.06639597933819481, 0.06352084260595472, 0.06060080219632842, 0.05764633029211025, 0.05466802255825736, 0.05167656014250446, 0.04868267136941066, 0.04569709326521514, 0.04273053305148608, 0.039793629745658365, 0.036896916006172745, 0.03405078035905192, 0.03126542994138065, 0.028550853895303666, 0.02591678754382193, 0.023372677476864192, 0.020927647672846023, 0.018590466777215237, 0.016369516655332882, 0.014272762332469453, 0.01230772342872043, 0.01048144719128486, 0.008800483220821852, 0.00727085998252363, 0.005898063186144425, 0.004687016112520986, 0.00364206195713978, 0.002766948254072892, 0.0020648134361427256, 0.0015381755795153933, 0.0011889233730881068, 0.001018309345057027, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire3.squeeze.1.bias
[0.1, 0.10091159424861718, 0.10064668961754383, 0.10020622287049813, 0.09959175159922935, 0.0988054487155151, 0.09785009476724532, 0.09672906810576536, 0.09544633293924834, 0.09400642531434311, 0.09241443707566975, 0.09067599785988555, 0.08879725518799467, 0.08678485272629968, 0.08464590679286904, 0.08238798119259919, 0.08001906046986046, 0.07754752167331128, 0.07498210473272687, 0.07233188155259694, 0.06960622393178433, 0.06681477042268828, 0.06396739224710567, 0.06107415838931977, 0.058145299989855584, 0.05519117416581305, 0.052222227385718314, 0.0492489585284078, 0.046281881756577214, 0.04333148933628353, 0.040408214533878384, 0.037522394721577944, 0.034684234822136714, 0.031903771221892856, 0.029190836279797284, 0.026555023557930338, 0.024005653896459228, 0.021551742453002978, 0.019201966822961027, 0.016964636353539536, 0.01484766275998816, 0.012858532147954738, 0.01100427854089344, 0.009291459006139775, 0.007726130467611835, 0.006313828287133993, 0.005059546690124072, 0.003967721104863219, 0.0030422124778012086, 0.002286293620361501, 0.0017026376355271482, 0.0012933084651336958, 0.0010597535912959912, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire3.expand_1x1.0.weight
[0.1, 0.10091282600684416, 0.10065160799957994, 0.10021725683487843, 0.09961128707775802, 0.09883581172035705, 0.09789353481401551, 0.09678774204035674, 0.09552228925424809, 0.09410158903859013, 0.09253059531781793, 0.09081478608376599, 0.08896014429413135, 0.08697313701014103, 0.0848606928461701, 0.08263017780994217, 0.08028936961755737, 0.07784643057290935, 0.0753098791060605, 0.07268856006981919, 0.06999161389809441, 0.0672284447335708, 0.06440868763584183, 0.06154217498434503, 0.05863890219325089, 0.05570899285785624, 0.052762663454015146, 0.049810187713699, 0.04686186080090696, 0.04392796341284369, 0.04101872593154231, 0.03814429275093413, 0.035314686903755686, 0.03253977511163721, 0.029829233380241682, 0.02719251325942276, 0.024638808886051067, 0.022177024924429252, 0.01981574551608621, 0.017563204347221178, 0.015427255938171715, 0.013415348255017466, 0.01153449673882248, 0.009791259843074777, 0.008191716164623108, 0.0067414432478545665, 0.0054454981360219975, 0.004308399737537749, 0.003334113068722127, 0.002526035427951078, 0.0018869845494136443, 0.0014191887777863057, 0.0011242792980848228, 0.0010032844477878048, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire3.expand_1x1.0.bias
[0.1, 0.10091403779313711, 0.10065644675258877, 0.10022811260212752, 0.0996305081637073, 0.09886568829318243, 0.09793628281470981, 0.09684548747812945, 0.09559705297041608, 0.09419527201898598, 0.09264496463120404, 0.09095146152084509, 0.08912058577849694, 0.08715863284893174, 0.08507234888429298, 0.08286890754753035, 0.0805558853458439, 0.07814123557895283, 0.07563326099176766, 0.07304058522549921, 0.07037212316536941, 0.067637050286883, 0.06484477110606261, 0.062004886842130694, 0.0591271624038297, 0.056221492812898066, 0.05329786918015381, 0.05036634435117724, 0.047436998339719205, 0.04451990366769214, 0.041625090730921466, 0.03876251330974714, 0.0359420143430668, 0.033173292083505654, 0.03046586675008859, 0.02782904779307871, 0.025271901883541684, 0.022803221737703695, 0.02043149588329976, 0.018164879471870572, 0.016011166237369673, 0.01397776169750058, 0.012071657689930942, 0.01029940833094084, 0.008667107479170655, 0.007180367781959678, 0.005844301376324045, 0.004663502310933481, 0.0036420307495289234, 0.0027833990100969864, 0.002090559487805848, 0.0015658945032290253, 0.0012112081107640274, 0.0010277198954124925, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire3.expand_1x1.1.weight
[0.1, 0.10091522997661714, 0.10066120734474314, 0.10023879344455572, 0.09964942059750276, 0.09889508724958528, 0.09797835119502492, 0.09690232090329294, 0.09567064497890898, 0.09428749978974944, 0.0927575753058154, 0.0910860591964779, 0.08927861924012395, 0.08734138410584802, 0.08528092257235537, 0.08310422125454092, 0.08081866091326904, 0.07843199142868262, 0.07595230552190228, 0.07338801131422004, 0.0707478038168337, 0.06804063544779482, 0.06527568567614123, 0.06246232989614471, 0.05961010763721546, 0.05672869021725679, 0.0538278479491513, 0.05091741701157493, 0.048007266096472934, 0.045107262946290166, 0.04222724089442068, 0.039376965522331685, 0.03656610154642075, 0.03380418004688644, 0.031100566149732656, 0.0284644272714906, 0.025904702034334218, 0.02343006995699179, 0.021048922024225772, 0.01876933223467368, 0.016599030223526053, 0.014545375052872234, 0.01261533025858566, 0.010815440238360025, 0.009151808060959353, 0.007630074771926792, 0.006255400265922111, 0.005032445790546002, 0.003965358140977437, 0.0030577555990166307, 0.0023127156642117445, 0.0017327646186705728, 0.0013198689609407667, 0.001075428738004757, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire3.expand_1x1.1.bias
[0.1, 0.10091640291875158, 0.10066589121388603, 0.1002493025672972, 0.09966803000278247, 0.09892401722793404, 0.0980197521346074, 0.09695825847970167, 0.09574308577406938, 0.0943782974133667, 0.09286845709053268, 0.09121861353533292, 0.08943428363199667, 0.08752143397140005, 0.08548646089948281, 0.08333616912861415, 0.0810777489834292, 0.07871875235722275, 0.07626706745929986, 0.07373089243772475, 0.07111870796567103, 0.06843924888304052, 0.06570147498817856, 0.06291454107735422, 0.06008776633219065, 0.057230603157409535, 0.05435260557309333, 0.051463397267157644, 0.04857263941486222, 0.04568999837296899, 0.04282511335657355, 0.039987564206695185, 0.03718683935640705, 0.034432304102623726, 0.03173316928964168, 0.029098460509151394, 0.026536987919712363, 0.02405731678661162, 0.0216677388406165, 0.019376244551395, 0.017190496408318195, 0.015117803297990319, 0.0131650960641852, 0.011338904331914063, 0.009645334673121581, 0.008090050187022378, 0.00667825156335845, 0.005414659691899714, 0.004303499876339916, 0.0033484877053743083, 0.0025528166282048617, 0.0019191472760189889, 0.0014495985651494562, 0.001145740611665579, 0.001008589481088367, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire3.expand_3x3.0.weight
[0.1, 0.10091755697352973, 0.1006704997682235, 0.10025964310982992, 0.09968634188900356, 0.0989524866932534, 0.09806049757231255, 0.09701331605748938, 0.09581439546131772, 0.09446768948949541, 0.09297763920266576, 0.09134915837103831, 0.08958761727014541, 0.08769882497117143, 0.0856890101842564, 0.08356480071794747, 0.08133320162253498, 0.07900157208935071, 0.07657760118220759, 0.07406928248101206, 0.07148488772116722, 0.06883293951569693, 0.06612218325004522, 0.06336155824223466, 0.06056016826348896, 0.05772725151653496, 0.054872150170587, 0.05200427955347861, 0.04913309710253777, 0.04626807117659665, 0.04341864983198527, 0.040594229665477155, 0.03780412482693434, 0.03505753630383919, 0.032363521579004184, 0.029730964761520186, 0.027168547289442686, 0.02468471930083084, 0.02228767176754918, 0.019985309483727134, 0.017785224997953087, 0.015694673575166972, 0.013720549270820191, 0.011869362196203936, 0.010147217049917934, 0.008559792986277437, 0.007112324887046383, 0.005809586098257535, 0.00465587268904885, 0.003654989284425691, 0.0028102365186688785, 0.002124400150763566, 0.0015997418777430764, 0.0012379918762430323, 0.001040343096861406, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire3.expand_3x3.0.bias
[0.1, 0.10091869248763435, 0.10067503438700008, 0.1002698181474584, 0.09970436165398561, 0.09898050394101511, 0.09810059921134484, 0.09706750917956233, 0.09588459376488895, 0.09455570016371291, 0.09308515033735065, 0.09147772695572981, 0.08973865784270951, 0.08787359897362622, 0.08588861608036236, 0.08379016492376352, 0.08158507029756426, 0.07928050383210805, 0.0768839606700504, 0.07440323508990267, 0.0718463951566962, 0.06922175648221043, 0.06653785518010462, 0.06380342010391112, 0.061027344458180754, 0.05821865687510927, 0.05538649205071233, 0.052540061036049204, 0.04968862128011676, 0.04684144652184363, 0.04400779662910446, 0.041196887482846965, 0.038417861004277874, 0.035679755422588035, 0.03299147587991511, 0.030361765469145426, 0.02779917679874864, 0.02531204417712501, 0.022908456506930054, 0.020596230977532434, 0.018382887641165063, 0.01627562495545561, 0.014281296371879103, 0.01240638804627437, 0.010656997743916152, 0.009038815007750074, 0.0075571026542894095, 0.006216679657354168, 0.005021905475320331, 0.003976665872851065, 0.003084360283222492, 0.002347890752345121, 0.0017696525004385001, 0.0013515261320553187, 0.0010948715197902795, 0.0010005233815658034, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire3.expand_3x3.1.weight
[0.1, 0.10091980980060865, 0.10067949642115771, 0.1002798306927598, 0.09972209458639288, 0.09900807710084006, 0.09814006852428277, 0.09712085308795411, 0.09595370003541653, 0.09464235313611019, 0.09319101867680815, 0.0916043519694974, 0.08988744241896302, 0.08804579719797274, 0.08608532358242582, 0.08401231000312748, 0.08183340587496835, 0.07955560026820806, 0.07718619949027788, 0.07473280365001063, 0.07220328227947095, 0.0696057490915816, 0.06694853595451307, 0.06424016616631682, 0.061489327115526515, 0.05870484241542121, 0.05589564360133301, 0.05307074148178326, 0.050239197235340996, 0.047410093345914554, 0.044592504469703614, 0.04179546832725962, 0.03902795671402127, 0.03629884672231191, 0.03361689226710736, 0.030990696006908514, 0.02842868174978519, 0.025939067433102286, 0.0235298387635983, 0.021208723602368702, 0.018983167176917067, 0.016860308199783947, 0.014846955970355576, 0.012949568533300863, 0.011174231963695835, 0.009526640845280602, 0.008012080004467226, 0.006635407558688299, 0.0054010393334607935, 0.0043129346981488174, 0.0033745838658589484, 0.0025889966982048035, 0.0019586930508509173, 0.0014856946908036396, 0.0011715188113751154, 0.0010171731656219642, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire3.expand_3x3.1.bias
[0.1, 0.10092090924501924, 0.10068388719397792, 0.10028968369699456, 0.09973954586815688, 0.09903521414011394, 0.09817891675799084, 0.09717336273004518, 0.09602173325736674, 0.0947276716697336, 0.09329527189946407, 0.09172906552972873, 0.09003400745829711, 0.08821546022207345, 0.08627917703201299, 0.08423128357209005, 0.08207825861989926, 0.07982691355019907, 0.07748437078624087, 0.07505804126705572, 0.07255560100198376, 0.06998496678661938, 0.06735427115699748, 0.06467183666125688, 0.06194614953017578, 0.05918583282987573, 0.05639961918162925, 0.053596323135075424, 0.05078481328224449, 0.04797398420061233, 0.045172728313946475, 0.04238990775996572, 0.0396343263538137, 0.03691470173604335, 0.03423963779322602, 0.0316175974384361, 0.029056875837723567, 0.02656557416727627, 0.024151573984294225, 0.021822512292657272, 0.01958575738226893, 0.01744838551851202, 0.015417158555561632, 0.013498502544379315, 0.011698487403063972, 0.010022807713875696, 0.008476764707683498, 0.007065249492831021, 0.005792727581478695, 0.004663224762374429, 0.0036803143647468556, 0.002847105953613054, 0.0021662354922647392, 0.0016398570030551943, 0.0012696357528691128, 0.001056742984833974, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire4.squeeze.0.weight
[0.1, 0.10092199114661499, 0.1006882080017082, 0.10029938005148265, 0.09975672057684076, 0.09906192286751836, 0.09821715493842101, 0.09722505276464971, 0.0960887120563251, 0.09481167859887568, 0.0933979371889314, 0.0918518992003472, 0.09017838881915421, 0.08838262799039105, 0.08647022012378594, 0.08444713260913402, 0.08231967819592786, 0.08009449529534365, 0.07777852726604723, 0.07537900074845623, 0.07290340311506287, 0.07035945910718008, 0.06775510673101309, 0.0650984724882689, 0.062397846018593106, 0.05966165423295853, 0.05689843501871873, 0.0541168105983759, 0.05132546062519316, 0.048533095099602686, 0.045748427190919816, 0.0429801460491691, 0.040236889691859165, 0.037527218050309015, 0.03485958625963094, 0.0322423182757147, 0.02968358090153736, 0.027191358303845836, 0.02477342709972918, 0.022437332090819263, 0.020190362720837837, 0.018039530329950648, 0.015991546276903107, 0.014052800997204427, 0.012229344062705604, 0.010526865304792882, 0.008950677060099, 0.007505697594131405, 0.0061964357545423445, 0.005026976901927277, 0.004000970162053129, 0.0031216170392936553, 0.002391661426801899, 0.0018133810445919766, 0.0013885803322459358, 0.0011185848184232564, 0.0010042369847420454, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire4.squeeze.0.bias
[0.1, 0.1009230558244818, 0.100692460114173, 0.10030892258894594, 0.09977362368794696, 0.0990882109364798, 0.09825479387530651, 0.09727593756797248, 0.09615465470613845, 0.09489439633721748, 0.09349904124285503, 0.09197288400094275, 0.09032062176790823, 0.08854733982196189, 0.08665849591179545, 0.0846599034589029, 0.08255771366522363, 0.08035839658117593, 0.07806872119234923, 0.07569573458614343, 0.07324674026247571, 0.07072927565530944, 0.0681510889341884, 0.06552011515717614, 0.06284445184859591, 0.060132334076737494, 0.05739210910823542, 0.05463221071712712, 0.051861133227661296, 0.049087405370746934, 0.046319564034506516, 0.04356612798972331, 0.040835571671049654, 0.0381362990946714, 0.03547661799270409, 0.032864714243929005, 0.030308626679565437, 0.027816222341621084, 0.025395172269969613, 0.02305292789267704, 0.020796698092242313, 0.018633427018336386, 0.01656977271532743, 0.014612086630371425, 0.012766394065137597, 0.011038375631333596, 0.009433349767106247, 0.007956256368127822, 0.00661164158374829, 0.005403643825006576, 0.004335981027565632, 0.0034119392087727123, 0.0026343623540634456, 0.0020056436638373524, 0.0015277181877445247, 0.0012020568690536406, 0.0010296620174312923, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire4.squeeze.1.weight
[0.1, 0.10092410359119364, 0.10069664477536933, 0.10031831408481795, 0.09979026007716969, 0.099114085848538, 0.09829184416675009, 0.09732603123943871, 0.09621957913591433, 0.0949758468858239, 0.09359861028161937, 0.09209205041579414, 0.09046074098768696, 0.08870963441838764, 0.08684404681589804, 0.08486964183619189, 0.08279241348916873, 0.08061866794170099, 0.0783550043730171, 0.07600829494054143, 0.07358566391701145, 0.07109446606220914, 0.06854226429496668, 0.06593680673323143, 0.06328600317189269, 0.060597901069780746, 0.05788066111873779, 0.055142532468929806, 0.052391827685611604, 0.04963689751337278, 0.04688610552447678, 0.04414780272825678, 0.04143030221865111, 0.03874185393684411, 0.03609061962562981, 0.03348464805153322, 0.030931850569911365, 0.028439977107214832, 0.026016592633324388, 0.023669054195389012, 0.021404488582887717, 0.01922977069172029, 0.01715150265301097, 0.015175993789986804, 0.013309241463778522, 0.011556912866293713, 0.009924327815436312, 0.00841644260490354, 0.007037834957590294, 0.005792690128279914, 0.004684788197811934, 0.003717492597299659, 0.0028937398972363965, 0.002216030892489334, 0.0016864230102455072, 0.0013065240639584244, 0.0010774873722573955, 0.001000008257637818, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire4.squeeze.1.bias
[0.1, 0.10092513475295983, 0.10070076320404789, 0.10032755725852169, 0.09980663452259358, 0.09913955495663615, 0.09832831620370941, 0.09737534760739922, 0.09628350293688095, 0.09505605184099414, 0.09369667005691967, 0.09220942840278105, 0.0905987805871321, 0.08886954987183732, 0.08702691462828432, 0.08507639283018167, 0.08302382552938022, 0.08087535936420165, 0.07863742815265447, 0.07631673362565916, 0.07392022535797842, 0.07145507995695202, 0.0689286795713575, 0.0663485897847544, 0.06372253695951316, 0.06105838509937383, 0.05836411229982291, 0.05564778685680969, 0.052917543105347464, 0.05018155706035356, 0.04744802193267425, 0.04472512359361461, 0.04202101606144737, 0.03934379708330933, 0.03670148388560762, 0.034101989165554396, 0.031553097395725496, 0.02906244151260201, 0.02663748005890323, 0.024285474848160876, 0.022013469218420664, 0.01982826694019249, 0.017736411841812016, 0.015744168213227765, 0.013857502046896446, 0.012082063171963059, 0.01042316833522668, 0.008885785279557915, 0.007474517867447122, 0.006193592294232163, 0.005046844432292212, 0.004037708344106349, 0.0031692059985761237, 0.0024439382214076757, 0.0018640769066533161, 0.001431358512736174, 0.0011470788624346243, 0.0010120892623986014, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire4.expand_1x1.0.weight
[0.1, 0.10092614960976859, 0.10070481659427986, 0.10033665477471641, 0.09982275170683995, 0.09916462546833463, 0.09836422017438187, 0.09742390023471373, 0.09634644336910968, 0.09513503240196902, 0.09379324586019792, 0.09232504740218506, 0.09073477410909286, 0.08902712367305214, 0.0872071405201061, 0.08528020090889714, 0.08325199704911485, 0.08112852028661975, 0.0789160434049142, 0.07662110209524188, 0.07425047565005385, 0.07181116693687291, 0.06931038171171365, 0.06675550733316651, 0.06415409094002544, 0.06151381715692196, 0.05884248539382408, 0.056147986806457474, 0.053438280985708346, 0.05072137244486768, 0.048005286974174055, 0.04529804793250395, 0.04260765254624446, 0.039942048285361666, 0.037309109386450316, 0.03471661359211603, 0.032172219175402174, 0.029683442317131825, 0.027257634902992312, 0.02490196280595, 0.022623384718149866, 0.020428631594830195, 0.018324186770975692, 0.016316266809444903, 0.014410803137146287, 0.012613424523510674, 0.010929440453018534, 0.009363825440899785, 0.007921204338338372, 0.006605838670589464, 0.005421614048367462, 0.004372028689691309, 0.0034601830860937536, 0.002688770843721077, 0.0020600707263784095, 0.0015759399240259145, 0.0012378085666106754, 0.0010466754994404683, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire4.expand_1x1.0.bias
[0.1, 0.10092714845552711, 0.10070880611600971, 0.10034560924451413, 0.09983861621916178, 0.09918930444895005, 0.09839956606849108, 0.09747170242421475, 0.09640841736810286, 0.09521280937849752, 0.09388836253094383, 0.09243893634537843, 0.09086875453925003, 0.08918239271934586, 0.08738476504819066, 0.0854811099238737, 0.083476974715033, 0.08137819959548041, 0.07919090052557436, 0.07692145142993351, 0.07457646562342667, 0.07216277653956467, 0.06968741781745301, 0.06715760280533288, 0.06458070354043881, 0.061964229266426765, 0.059315804550974176, 0.056643147067318655, 0.05395404510448144, 0.051256334871712085, 0.04855787766329046, 0.04586653695022968, 0.04319015546563571, 0.040536532350498596, 0.037913400426513824, 0.03532840366216213, 0.03278907489771312, 0.03030281389406338, 0.02787686576937607, 0.025518299886358942, 0.023233989251704758, 0.021030590487725178, 0.018914524434541953, 0.016891957439362382, 0.014968783387362416, 0.013150606526541136, 0.011442725136596027, 0.009850116089408407, 0.008377420346131492, 0.007028929433142694, 0.005808572936270766, 0.004719907049739935, 0.003766104213200105, 0.002949943867041887, 0.0022738043529354816, 0.0017396559831961526, 0.0013490552991724295, 0.0011031405353884517, 0.0010026283026582253, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire4.expand_1x1.1.weight
[0.1, 0.10092813157819809, 0.10071273291559446, 0.1003544232266667, 0.09985423255748915, 0.09921359882462162, 0.09843436368147745, 0.09751876722405467, 0.09646944155124935, 0.09528940319826394, 0.09398204446486222, 0.09255112366340014, 0.09100075431466668, 0.08933539332259398, 0.08755982816183128, 0.08567916311501499, 0.0836988045992992, 0.08162444562432901, 0.07946204942633564, 0.07721783232540154, 0.0748982458551757, 0.07250995821641203, 0.07005983510764682, 0.06755491998812196, 0.06500241382969299, 0.062409654415929716, 0.05978409524791931, 0.05713328411741191, 0.05446484140890526, 0.05178643819304451, 0.049105774174312625, 0.04643055555640588, 0.04376847288892602, 0.0411271789590738, 0.03851426679189934, 0.03593724782235313, 0.03340353030188692, 0.03092039800168027, 0.0284949892737148, 0.026134276529890667, 0.02384504619817689, 0.021633879213416758, 0.01950713209887165, 0.01747091869288936, 0.015531092573227451, 0.013693230229557547, 0.011962615032524809, 0.010344222045447497, 0.008842703722319094, 0.007462376533227188, 0.006207208555637777, 0.005080808067216702, 0.004086413172980746, 0.003226882496597782, 0.0025046869625958857, 0.001921902693105492, 0.0014802050395545821, 0.0011808637664741208, 0.0010247394012591663, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire4.expand_1x1.1.bias
[0.1, 0.10092909925993304, 0.10071659811632981, 0.10036309922872419, 0.09986960513042593, 0.09923751538530658, 0.09846862261859482, 0.09756510743293834, 0.09652953222415012, 0.0953648339141781, 0.09407431562190754, 0.09266163729541813, 0.09113080533226284, 0.08948616121720593, 0.08773236920964353, 0.08587440311562607, 0.08391753218199693, 0.08186730615265253, 0.07972953952930427, 0.07751029508137956, 0.07521586665182829, 0.07285276130759794, 0.07042768088539897, 0.0679475029850976, 0.06541926146463901, 0.06285012649181793, 0.06024738420947057, 0.05761841607175783, 0.05497067791014271, 0.05231167878843174, 0.049648959706847566, 0.04699007221552918, 0.04434255699811217, 0.04171392248612664, 0.03911162356486324, 0.03654304043109768, 0.034015457662634245, 0.03153604355902753, 0.029111829812072682, 0.026749691563719254, 0.02445632790796519, 0.02223824289202797, 0.02010172707067398, 0.018052839666019227, 0.01609739138339586, 0.014240927932019865, 0.012488714297195676, 0.010845719808661846, 0.009316604047424935, 0.007905703631049692, 0.006617019914883398, 0.005454207644093616, 0.004420564588702624, 0.0035190221910141478, 0.002752137251956093, 0.0021220846799174567, 0.0016306513226438104, 0.0012792308996841186, 0.0010688200497608704, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire4.expand_3x3.0.weight
[0.1, 0.10093005177720211, 0.10072040281896336, 0.10037163970816534, 0.09988473825919918, 0.09926106078770619, 0.09850235229891555, 0.09761073560524379, 0.09658870538681646, 0.09543912121153057, 0.09416519953418682, 0.09277050469707777, 0.09125893895721147, 0.08963473156807374, 0.08790242694647761, 0.08606687195760808, 0.08413320235383792, 0.08210682840525761, 0.07999341976212423, 0.07779888959158311, 0.07552937803304648, 0.07319123501851986, 0.07079100250594383, 0.06833539617526062, 0.06583128663841914, 0.06328568021589112, 0.06070569933348452, 0.05809856259430242, 0.055471564581604654, 0.05283205544908252, 0.05018742035565118, 0.04754505880229998, 0.0449123639288148, 0.0422967018282984, 0.03970539093736564, 0.03714568155967801, 0.034624735580109436, 0.032149606426301526, 0.029727219333674462, 0.02736435196911054, 0.025067615467524104, 0.022843435934376002, 0.020698036465887276, 0.01863741973725849, 0.01666735120761099, 0.014793342988642367, 0.01302063842212962, 0.011354197409431686, 0.009798682534038, 0.00835844601599135, 0.007037517534685549, 0.005839592954109029, 0.004768023982080077, 0.0038258087924066425, 0.003015583636209173, 0.002339615465877331, 0.0017997955922984467, 0.0013976343931040127, 0.0011342570867405191, 0.0010104005841881749, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire4.expand_3x3.0.bias
[0.1, 0.100930989400921, 0.1007241481021954, 0.10038004707350079, 0.09989963617956249, 0.09928424155812432, 0.0985355619592461, 0.09765566405603329, 0.09664697673974305, 0.09551228441501464, 0.09425471931373199, 0.09287775284873596, 0.091385186031253, 0.08978113897849266, 0.08807003954037745, 0.0862566110767997, 0.08434585941914574, 0.082343059052079, 0.08025373855372614, 0.07808366533445757, 0.07583882971638954, 0.07352542839755555, 0.0711498473463925, 0.06871864417376045, 0.06623853003115643, 0.06371635108509108, 0.06115906961876647, 0.05857374481322284, 0.05596751326100591, 0.05334756926614598, 0.05072114498482862, 0.04809549046157737, 0.04547785361605721, 0.042875460235743366, 0.04029549402968442, 0.037745076798419736, 0.03523124877479052, 0.0327609491899125, 0.030340997117955945, 0.027978072652609966, 0.025678698467191858, 0.02344922180930331, 0.021295796979736076, 0.019224368343992555, 0.01724065392331684, 0.015350129610531782, 0.013558014054253397, 0.01186925425320793, 0.010288511900418257, 0.008820150514954567, 0.007468223396771872, 0.006236462437883682, 0.005128267820757758, 0.004146698632371098, 0.0032944644198327926, 0.00257391771088537, 0.0019870475199307786, 0.001535473857507407, 0.0012204432583741256, 0.0010428253405459212, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire4.expand_3x3.1.weight
[0.1, 0.10093191239657447, 0.10072783502316746, 0.10038832368534974, 0.09991430304365441, 0.09930706409526016, 0.0985682606579551, 0.0976999048659572, 0.09670436168985833, 0.0955843424956172, 0.09434289766014291, 0.09298340826358069, 0.09150957688092634, 0.08992541749804782, 0.08823524457957806, 0.08644366131845281, 0.08455554709909557, 0.08257604420839391, 0.08051054383065993, 0.0783646713647174, 0.07614427110310482, 0.07385539031512053, 0.07150426277705978, 0.06909729179449912, 0.06664103276286729, 0.06414217531379846, 0.06160752509589305, 0.05904398523950543, 0.05645853755603987, 0.05385822352295834, 0.05125012510628751, 0.04864134547285493, 0.04603898964478483, 0.043450145148940966, 0.040881862714017864, 0.03834113706785212, 0.03583488788725204, 0.03336994095222943, 0.030953009555959365, 0.02859067622109847, 0.02628937477225727, 0.024055372813452214, 0.02189475465826021, 0.019813404759165477, 0.01781699168122877, 0.01591095266372704, 0.014100478811809813, 0.01239050095850272, 0.010785676235563497, 0.009290375389764231, 0.007908670879144541, 0.006644325781655269, 0.005500783546400028, 0.0044811586153874145, 0.0035882279413352418, 0.0028244234246283632, 0.0021918252900279037, 0.0016921564211705258, 0.0013267776682876922, 0.0010966841419244747, 0.001002502502751811, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire4.expand_3x3.1.bias
[0.1, 0.10093282102433705, 0.10073146461793905, 0.100396471857491, 0.09992874292181293, 0.09932953467293636, 0.09860045727871597, 0.0977434698860527, 0.09676087535635436, 0.09565531407738082, 0.09442975686810225, 0.09308749699563608, 0.09163214132571454, 0.09006760063046285, 0.08839807907953262, 0.08662806294282938, 0.08476230853519195, 0.08280582943541812, 0.080763883013981, 0.07864195630563864, 0.07644575126489897, 0.07418116944396129, 0.07185429613430704, 0.0694713840145538, 0.06703883634851356, 0.06456318977860458, 0.06205109676085362, 0.05950930768868884, 0.05694465275355897, 0.054364023591122856, 0.051774354762328445, 0.04918260511914471, 0.04659573910501982, 0.044020708040314, 0.04146443144299637, 0.03893377843479967, 0.036435549282797866, 0.033976457126007054, 0.03156310993611343, 0.02920199276080241, 0.026899450297404294, 0.02466166984368357, 0.022494664671585785, 0.02040425786861967, 0.018396066690294928, 0.01647548746566333, 0.014647681096524527, 0.012917559189262035, 0.011289770856575974, 0.00976869022457777, 0.008358404678817738, 0.007062703880830145, 0.005885069584709973, 0.004828666281085991, 0.0038963326936311596, 0.0030905741509607335, 0.0024135558544158492, 0.0018670970598231853, 0.0014526661888652473, 0.0011713768831977992, 0.001023985011917632, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire5.squeeze.0.weight
[0.1, 0.10093371553919077, 0.10073503790195285, 0.1004044938578886, 0.09994295980434742, 0.09935165944276468, 0.09863216053416608, 0.09778637074244007, 0.09681653257639869, 0.09572521744403828, 0.09451531883476375, 0.093190044647653, 0.09175290868610278, 0.0902077213414059, 0.08855857948996204, 0.0868098556309081, 0.08496618629296807, 0.08303245974126103, 0.08101380301666027, 0.07891556834206775, 0.07674331893164572, 0.07450281424063072, 0.07219999469483815, 0.0698409659403453, 0.06743198265511323, 0.06497943196546832, 0.06248981651141339, 0.05996973720566822, 0.05742587573215191, 0.0548649768303103, 0.05229383041225919, 0.04971925356015787, 0.047148072451544475, 0.04458710426055611, 0.042043139083020334, 0.039522921933341594, 0.0370331348609154, 0.03458037923348678, 0.03217115823442619, 0.029811859620329336, 0.027508738784657163, 0.025267902172320514, 0.023095291089183775, 0.020996665949414746, 0.01897759100244661, 0.017043419580047094, 0.01519927990261007, 0.013450061482302555, 0.01180040215911769, 0.010254675804205683, 0.008816980723086298, 0.007491128789489964, 0.006280635338637907, 0.005188709846758266, 0.004218247421549947, 0.003371821126156576, 0.0026516751570023526, 0.0020597188935780487, 0.0015975218359534187, 0.0012663094434385393, 0.00106695988542747, 0.001000001713038822, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire5.squeeze.0.bias
[0.1, 0.1009345961910399, 0.10073855587048863, 0.10041239190969319, 0.09995695760326878, 0.0993734444367503, 0.09866337896948446, 0.0978286188409181, 0.09687134791073027, 0.09579407054552258, 0.0945996050670147, 0.09329107637888528, 0.09187190779154775, 0.0903458120662489, 0.0887167817019196, 0.0869890784901894, 0.0851672223658903, 0.08325597958221856, 0.08126035024149014, 0.07918555521411133, 0.07703702247998617, 0.07482037292809418, 0.0725414056513883, 0.07020608277548417, 0.06782051386083127, 0.06539093991917178, 0.06292371708610309, 0.06042529999245865, 0.05790222487801027, 0.05536109249166905, 0.05280855082292055, 0.05025127770967133, 0.047695963368007764, 0.04514929288957124, 0.042617928752339995, 0.04010849339057163, 0.037627551869506094, 0.03518159471015479, 0.032777020909108716, 0.03042012119778842, 0.028117061584932202, 0.025873867225377795, 0.023696406657339276, 0.02159037644941709, 0.019561286297506537, 0.01761444461059394, 0.01575494462314999, 0.013987651070452262, 0.012317187461696667, 0.010747923984192866, 0.009283966070288464, 0.007929143656932569, 0.0066870011659770625, 0.005560788231429164, 0.004553451197913643, 0.0036676254125864276, 0.002905628330664955, 0.002269453452612185, 0.001760765108835687, 0.0013808941055457316, 0.0011308342431634636, 0.00101123971638759, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire5.squeeze.1.weight
[0.1, 0.10093546322482311, 0.10074201949910638, 0.10042016819221927, 0.09997074015397911, 0.09939489556983638, 0.09869412096588964, 0.09787022537146145, 0.09692533564914169, 0.09586189100435341, 0.09468263668861476, 0.09339061691275181, 0.09198916698835652, 0.09048190471777656, 0.0888727210548635, 0.08716577006058823, 0.08536545817945294, 0.0834764328643825, 0.0815035705794594, 0.0794519642114731, 0.07732690992278052, 0.07513389347941636, 0.07287857608974722, 0.07056677979022628, 0.06820447241597503, 0.06579775219498987, 0.06335283200574346, 0.060876023338818946, 0.058373720003980036, 0.05585238162473656, 0.053318516963013575, 0.050778667116971134, 0.04823938863534915, 0.045707236591926825, 0.043188747663789745, 0.040690423257087556, 0.03821871272384242, 0.03577999671313381, 0.033380570699637846, 0.031026628732042, 0.02872424744328796, 0.026479370363919896, 0.02429779257903262, 0.022185145768427506, 0.02014688366859435, 0.018188267994048664, 0.016314354854368295, 0.01452998170199312, 0.012839754844481816, 0.011248037553462393, 0.009758938800973099, 0.008376302652270174, 0.007103698342484787, 0.005944411062746185, 0.004901433479555855, 0.003977458009305822, 0.0031748698678838107, 0.0024957409133075197, 0.0019418242972832392, 0.0015145499394955955, 0.0012150208363112694, 0.0010440102134259047, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire5.squeeze.1.bias
[0.1, 0.10093631688062268, 0.10074542974407846, 0.1004278248418995, 0.0999843112169218, 0.09941601864239039, 0.09872439474405985, 0.09791120131262143, 0.09697850981585003, 0.09592869612190286, 0.09476443444721172, 0.09348869054438527, 0.09210471414747386, 0.09061603069384146, 0.08902643234373181, 0.08733996832040458, 0.08556093459544867, 0.08369386294554743, 0.0817435094085715, 0.0797148421684058, 0.07761302889937163, 0.07544342360248184, 0.07321155296706136, 0.07092310229247459, 0.06858390100582148, 0.06619990781249345, 0.06377719551741555, 0.06132193555563993, 0.058840382271696516, 0.05633885698774619, 0.053823731901120324, 0.0513014138522645, 0.04877832800443524, 0.046260901476722426, 0.043755546972089554, 0.04126864644213668, 0.03880653483019694, 0.036375483934178464, 0.03398168643025822, 0.031631240098124465, 0.029330132287951585, 0.027084224668674595, 0.02489923829641465, 0.02278073904109105, 0.020734123408342887, 0.01876460479287654, 0.016877200198256233, 0.015076717456966437, 0.013367742983301185, 0.011754630090277229, 0.010241487900331987, 0.008832170878054161, 0.007530269011610562, 0.0063390986678803106, 0.005261694144591349, 0.004300799940978644, 0.003458863766653319, 0.0027380303064912562, 0.0021401357574242544, 0.0016667031510500465, 0.0013189384739761825, 0.001097727595780478, 0.0010036340124134782, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire5.expand_1x1.0.weight
[0.1, 0.10093715739377138, 0.10074878754281179, 0.100435363953216, 0.099997674479193, 0.0994368193426334, 0.09875420836747714, 0.097951557435833, 0.09703088417475841, 0.09599450288454181, 0.09484501872123619, 0.09358532114806713, 0.09221857667217695, 0.0907482208849622, 0.08917794982601297, 0.08751171069236244, 0.08575369191640095, 0.08390831263739572, 0.08198021159308166, 0.07997423545924667, 0.07789542666662203, 0.07574901072570292, 0.0735403830913605, 0.07127509560026393, 0.06895884251520516, 0.0665974462114062, 0.0641968425407898, 0.061763065911003334, 0.059302234116702546, 0.05682053296122519, 0.05432420070731092, 0.05181951239595367, 0.04931276407280449, 0.0468102569617748, 0.044318281625623124, 0.041843102153340736, 0.03939094041408447, 0.03696796041723788, 0.03458025281791468, 0.03223381960685296, 0.029934559023185727, 0.027688250728012034, 0.025500541276038326, 0.02337692992180996, 0.021322754796211596, 0.01934317948798489, 0.017443180063993674, 0.015627532560863383, 0.013900800979437623, 0.01226732581222973, 0.010731213132708379, 0.009296324273843276, 0.007966266121855975, 0.006744382049574759, 0.005633743512184075, 0.004637142326494619, 0.0037570836531415847, 0.002995779699351652, 0.002355144158108357, 0.0018367873976938833, 0.0014420124136994609, 0.0011718115536798015, 0.0010268640226848693, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire5.expand_1x1.0.bias
[0.1, 0.10093798499495639, 0.1007520938142596, 0.10044278757960995, 0.10001083355611551, 0.09945730324901414, 0.09878356974569726, 0.09799130430962916, 0.09708247223461033, 0.09605932796966948, 0.0949244095266766, 0.09368053218455036, 0.09233078150567656, 0.09087850568186151, 0.0893273072288068, 0.087681034049708, 0.0859437698901453, 0.0841198242079434, 0.08221372148312953, 0.08023018999450743, 0.07817415009068791, 0.07605070198467122, 0.07386511310225753, 0.07162280501566945, 0.06932933999479898, 0.06699040720943956, 0.06461180861673045, 0.06219944456882057, 0.05975929917645384, 0.057297425464782864, 0.054819930358233494, 0.05233295953166681, 0.049842682165416985, 0.047355275642021084, 0.0448769102226029, 0.04241373374092183, 0.03997185635305526, 0.037557335380544156, 0.03517616028460007, 0.032834237808646353, 0.030537377326049355, 0.028291276429385594, 0.02610150679699242, 0.023973500371861772, 0.02191253588716115, 0.019923725771807028, 0.018012003468572842, 0.01618211119618963, 0.014438588185797498, 0.012785759420927717, 0.011227724908947866, 0.009768349510582728, 0.00841125335273989, 0.007159802848422275, 0.006017102346003378, 0.004985986428580013, 0.004069012882504996, 0.0032684563525416867, 0.002586302699379827, 0.002024244073509073, 0.0015836747176701518, 0.0012656875082960365, 0.001071071244522458, 0.0010003086914925899, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire5.expand_1x1.1.weight
[0.1, 0.10093879991032112, 0.1007553494593235, 0.10045009773436926, 0.10002379199277608, 0.09947747583252861, 0.09881248663754685, 0.09803045230376553, 0.09713328725403904, 0.09612318775162737, 0.09500262652373581, 0.09377434670826988, 0.09244135513862384, 0.09100691498294185, 0.08947453775587058, 0.0878479747223588, 0.08613120771454724, 0.08432843938422935, 0.08244408291474457, 0.08048275121748966, 0.07844924563949512, 0.07634854420971038, 0.07418578945277109, 0.07196627580008036, 0.06969543662902175, 0.06737883096203183, 0.06502212985809347, 0.06263110252996293, 0.06021160222111645, 0.05776955187698921, 0.055310929645583685, 0.05284175424294179, 0.050368070219306504, 0.04789593316204121, 0.04543139487152999, 0.04298048854634873, 0.04054921401397324, 0.03814352304318013, 0.03576930477409552, 0.03343237130155879, 0.031138443447093673, 0.028893136754316564, 0.02670194774206565, 0.024570240448903054, 0.02250323330192923, 0.020505986342054607, 0.018583388837001415, 0.016740147312358677, 0.014980774029990714, 0.013309575942003927, 0.011730644147312508, 0.010247843876613798, 0.008864805030289451, 0.007584913292396472, 0.0064113018425003936, 0.005346843685640467, 0.004394144619203093, 0.003555536853920365, 0.0028330733046099277, 0.0022285225646320786, 0.0017433645763668894, 0.0013787870083099888, 0.0011356823476557634, 0.0010146457154855562, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire5.expand_1x1.1.bias
[0.1, 0.10093960236156418, 0.10075855536124588, 0.10045729639149566, 0.1000365532655268, 0.0994973424589871, 0.09884096665424998, 0.09806901159325672, 0.09718334224651382, 0.09618609830750041, 0.09507968902337093, 0.09386678737444155, 0.09255032361652232, 0.0911334782016958, 0.08961967409464539, 0.08801256850309586, 0.08631604404234508, 0.08453419935523218, 0.0826713392102036, 0.08073196410139918, 0.07872075937588344, 0.07664258391428966, 0.07450245839222326, 0.0723055531507838, 0.07005717570550929, 0.06776275792392002, 0.06542784290263969, 0.06305807157579768, 0.06065916908706494, 0.05823693095824774, 0.055797209087854516, 0.053345897613461694, 0.05088891867203428, 0.04843220809260219, 0.045981701055858165, 0.04354331775532179, 0.0411229490947112, 0.03872644245607621, 0.036359587573075586, 0.03402810254352747, 0.03173762001502518, 0.029493673576992743, 0.02730168439205546, 0.025166948099023246, 0.02309462201912741, 0.021089712696419707, 0.019157063802434936, 0.017301344434337975, 0.015527037834826136, 0.013838430561038294, 0.012239602128637728, 0.010734415156087695, 0.009326506032930008, 0.008019276134611574, 0.006815883605082395, 0.005719235727018267, 0.004731981898100434, 0.0038565072303210096, 0.003094926787777779, 0.002449080476879089, 0.001920528601303755, 0.0015105480924548047, 0.0012201294245138097, 0.001049974221548821, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire5.expand_3x3.0.weight
[0.1, 0.10094039256603643, 0.10076171238599303, 0.10046438548655115, 0.1000491207834517, 0.09951690839122941, 0.09886901726248525, 0.09810699216232606, 0.09723264998518533, 0.0962480754228065, 0.09515561599371787, 0.0939578764460506, 0.09265771254704439, 0.09125822427404928, 0.08976274842325795, 0.08817485065379116, 0.0864983169861063, 0.08473714477499873, 0.08289553317871937, 0.08097787314693264, 0.07898873695138693, 0.07693286728425909, 0.07481516595016593, 0.07264068217880452, 0.07041460058608713, 0.06814222881247514, 0.06582898486798604, 0.06348038421404632, 0.061102026612991446, 0.058699582776567276, 0.05627878084526708, 0.053845392730741154, 0.051405220353843296, 0.04896408181112617, 0.04652779750276897, 0.044102176255012795, 0.0416930014701915, 0.03930601733738077, 0.036946915136543385, 0.034621319668825326, 0.032334775845357294, 0.030092735466537818, 0.027900544223319806, 0.02576342895149394, 0.023686485169357716, 0.021674664928484695, 0.019732765006561105, 0.017865415470441317, 0.016077068636691783, 0.01437198845594436, 0.01275424034637011, 0.011227681500513502, 0.009795951688598342, 0.00846246458023337, 0.007230399605208665, 0.006102694372789741, 0.005082037667583494, 0.004170863038676109, 0.003371342997328452, 0.0026853838370632425, 0.0021146210884943387, 0.001660415619735516, 0.0013238503916861812, 0.0011057278759305392, 0.0010065681414067541, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire5.expand_3x3.0.bias
[0.1, 0.10094117073683527, 0.10076482138262921, 0.10047136691748454, 0.10006149788979954, 0.09953617879128991, 0.09889664578737532, 0.09814440380827139, 0.09728122300763216, 0.09630913459707685, 0.0952304260664024, 0.09404763580073, 0.09276354710725193, 0.09138118166563523, 0.08990379241749409, 0.08833485591166355, 0.0866780641232872, 0.08493731576597013, 0.08311670711744101, 0.08122052238031204, 0.07925322360061955, 0.07721944016786893, 0.0751239579212916, 0.0729717078879492, 0.07076775467918603, 0.06851728457273493, 0.06622559330852139, 0.06389807362688442, 0.061540202578538844, 0.05915752863614117, 0.056755658637787136, 0.05434024459316553, 0.051916970383415695, 0.04949153838598584, 0.047069656055966594, 0.044657022495475804, 0.042259315042699475, 0.03988217591214688, 0.03753119891755762, 0.03521191630870407, 0.03292978575306421, 0.030690177492999418, 0.02849836170865835, 0.02635949611634446, 0.02427861383152992, 0.02226061152507662, 0.020310237900534746, 0.01843208251963337, 0.016630565002259234, 0.014909924626337313, 0.013274210352087083, 0.011727271294128667, 0.01027274766385965, 0.008914062203417034, 0.007654412131381244, 0.006496761619175572, 0.005443834815865472, 0.0044981094377711354, 0.003661810937978526, 0.0029369072694688187, 0.002325104254189341, 0.0018278415689637444, 0.0014462893576868631, 0.0011813454777766343, 0.0010336333873624585, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire5.expand_3x3.1.weight
[0.1, 0.10094193708289698, 0.1007678831836816, 0.10047824254543872, 0.10007368786338308, 0.09955515872251337, 0.09892385941541049, 0.09818125614524784, 0.09732907362051005, 0.09636929104932877, 0.09530413754273866, 0.09413608693752995, 0.09286785205072112, 0.0915023783789962, 0.09004283725773946, 0.08849261849555619, 0.08685532250138561, 0.08513475192249102, 0.08333490281274811, 0.08145995535174316, 0.07951426413623619, 0.07750234806653739, 0.07542887985128566, 0.07329867515500495, 0.07111668141364291, 0.06888796634406856, 0.06661770617421513, 0.06431117362120435, 0.0619737256453731, 0.059610791008643506, 0.05722785766613288, 0.0548304600202863, 0.05242416606713475, 0.050014564464531334, 0.04760725155240016, 0.045207818355143564, 0.0428218375963946, 0.040454850756273475, 0.03811235520120745, 0.03579979141620564, 0.03352253036924182, 0.03128586103709165, 0.029094978121595907, 0.02695496998487881, 0.024870806831542025, 0.022847329165281607, 0.02088923654673739, 0.019001076678684982, 0.01718723484392026, 0.0154519237203668, 0.013799173597061183, 0.012232823013739496, 0.010756509845764678, 0.009373662855100332, 0.008087493726953865, 0.00690098961058399, 0.005816906181596775, 0.004837761241843008, 0.003965828871781435, 0.003203134148888969, 0.0025514484443844012, 0.002012285309189248, 0.0015868969586804661, 0.0012762713643993497, 0.0010811299594711212, 0.0010019259630644974, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire5.expand_3x3.1.bias
[0.1, 0.10094269180908678, 0.10077089860549697, 0.1004850141955389, 0.10008569391994637, 0.09957385315162298, 0.09895066519730744, 0.09821755860797017, 0.09737621390410643, 0.09642855972343274, 0.09537676839981735, 0.09422325098357923, 0.0929706517145708, 0.09162184196071398, 0.09017991363588389, 0.08864817211222946, 0.08703012864317738, 0.08532949231448886, 0.08355016154181982, 0.08169621513427504, 0.0797719029444411, 0.0777816361263321, 0.07572997702357925, 0.07362162871104454, 0.0714614242138322, 0.06925431542841176, 0.06700536177124886, 0.0647197185809651, 0.06240262530061278, 0.06005939346715488, 0.057695394535682065, 0.05531604756627761, 0.052926806801756425, 0.0505331491647533, 0.04814056170282196, 0.0457545290103242, 0.04338052065594267, 0.04102397864463749, 0.03869030494278781, 0.036384849095115, 0.03411289596177352, 0.03187965360371978, 0.02969024134413023, 0.027549678033235315, 0.025462870543470312, 0.02343460252131608, 0.021469523421614175, 0.019572137849492743, 0.017746795234335932, 0.015997679859466624, 0.01432880127039806, 0.012743985083642016, 0.011246864217142171, 0.009840870562436072, 0.008529227117635157, 0.007314940599257202, 0.006200794549846982, 0.0051893429571846774, 0.004282904399709141, 0.0034835567315765195, 0.002793132319537649, 0.002213213842553168, 0.0017451306637748347, 0.0013899557832095335, 0.0011485033780517897, 0.0010213269363228575, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire6.squeeze.0.weight
[0.1, 0.10094343511628673, 0.10077386844858967, 0.10049168365766242, 0.10009751921350038, 0.09959226695074144, 0.0989770700508052, 0.0982533204553358, 0.09742265571680153, 0.09648695529337598, 0.09544833629648475, 0.09430914870063918, 0.09307197002639467, 0.09173959950846491, 0.0903150517621863, 0.08880154996266326, 0.08720251855202744, 0.0855215754913107, 0.08376252407446334, 0.08192934432303899, 0.08002618398101617, 0.07805734913013232, 0.07602729444696303, 0.07394061312379173, 0.07180202647607407, 0.06961637326001165, 0.06738859872440459, 0.06512374342155476, 0.06282693180253546, 0.06050336062263234, 0.058158287183189064, 0.05579701743646163, 0.053424893980395655, 0.05104728397048894, 0.04866956697609053, 0.0462971228086121, 0.04393531934919161, 0.0415895004033505, 0.039264973610124126, 0.03696699843302236, 0.03470077425999198, 0.032471428639305605, 0.030284005677994857, 0.02814345462907728, 0.026054618693399447, 0.024022224061433273, 0.022050869219819413, 0.02014501454685279, 0.01830897222045148, 0.016546896461442872, 0.014862774134243056, 0.013260415726195941, 0.011743446725982216, 0.010315299420605665, 0.008979205129516447, 0.00773818689344275, 0.006595052634472981, 0.005552388802864227, 0.004612554524951961, 0.0037776762654017854, 0.003049643015880348, 0.0024301020210315875, 0.0019204550514286757, 0.001521855231934426, 0.0012352044326463631, 0.0010611512283295924, 0.0010000894309546084, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire6.squeeze.0.bias
[0.1, 0.10094416720148147, 0.10077679349798152, 0.1004982526871907, 0.10010916683762779, 0.09961040489936654, 0.09900308076339928, 0.09828855077397076, 0.0974684106994384, 0.09654449216842373, 0.09551885857921433, 0.0943938004915518, 0.09317183051109734, 0.09185567767799957, 0.09044828137209644, 0.0889527847483633, 0.08737252771726725, 0.0857110394857053, 0.0839720306751844, 0.08215938503484613, 0.08027715076784338, 0.07832953149043993, 0.07632087684402403, 0.07425567278100233, 0.07213853154626886, 0.06997418137662337, 0.06776745594114367, 0.06552328354609478, 0.06324667612848361, 0.06094271806284033, 0.05861655480622389, 0.05627338140681139, 0.053918430901734975, 0.05155696263007749, 0.049194250487127694, 0.04683557114612701, 0.044486192273812036, 0.042151360766071636, 0.0398362910299917, 0.03754615333845742, 0.035286062283321276, 0.03306106535292385, 0.030876131659477904, 0.028736140841490756, 0.02664587216600929, 0.024609993855025793, 0.022633052659882094, 0.020719463706955456, 0.01887350063730413, 0.017099286062293727, 0.01540078235652003, 0.013781782808590558, 0.01224590314952776, 0.010796573477713761, 0.009437030598410695, 0.00817031079496483, 0.006999243047838821, 0.005926442716615714, 0.004954305699085253, 0.004085003080456744, 0.0033204762846484872, 0.002662432738482561, 0.002112342058468163, 0.001671432768689445, 0.0013406895571280654, 0.0011208510765477178, 0.0010124082948521121, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire6.squeeze.1.weight
[0.1, 0.1009448882578422, 0.1007796745235337, 0.10050472300574359, 0.100120639826758, 0.09962827168630206, 0.0990287039950159, 0.09832325848169986, 0.09751349027960338, 0.09660118449818089, 0.09558835228787227, 0.09447722640658238, 0.09327025629763425, 0.09197010269004531, 0.09057963173303106, 0.08910190867766593, 0.08754019111963025, 0.08589792181793927, 0.08417872110548535, 0.08238637890812378, 0.0805248463898961, 0.07859822724280889, 0.07661076864036893, 0.07456685187481814, 0.07247098269870747, 0.07032778139210216, 0.06814197257731429, 0.06591837480361615, 0.06366188992489435, 0.06137749229366173, 0.059070217795247786, 0.05674515274634228, 0.054407422682364204, 0.05206218105837443, 0.04971459788844007, 0.04736984834849539, 0.04503310136782315, 0.04270950823430686, 0.040404191238572654, 0.038122232382054984, 0.03586866217387844, 0.03364844854125295, 0.03146648587782873, 0.029327584254154028, 0.027236458814020193, 0.025197719380070274, 0.02321586029158475, 0.021295250496846663, 0.019440123921927798, 0.017654570137126825, 0.015942525341635615, 0.014307763686307439, 0.012753888953655795, 0.011284326613425173, 0.009902316271246752, 0.008610904527026009, 0.007412938258805645, 0.0063110583469091815, 0.005307693852200339, 0.004405056661292033, 0.0036051366105093567, 0.0029096970993557287, 0.0023202712031521622, 0.0018381582934191556, 0.0014644211734516012, 0.0011998837354011186, 0.0010451291440307755, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire6.squeeze.1.bias
[0.1, 0.10094559847480829, 0.10078251228027087, 0.10051109630189657, 0.1001319411574128, 0.09964587191154528, 0.09905394628062704, 0.09835745233094291, 0.0975579056758189, 0.09665704617755502, 0.09565683416137882, 0.09455944614965815, 0.09336727012565556, 0.09208290033713117, 0.0907091316511012, 0.0892489534720369, 0.08770554323673796, 0.08608225950003626, 0.08438263462637563, 0.0826103671031713, 0.08076931349267565, 0.07886348003986354, 0.07689701395459872, 0.07487419438705226, 0.07279942311601062, 0.07067721497033656, 0.06851218800442604, 0.06630905344904015, 0.06407260545937947, 0.06180771068270999, 0.05951929766824171, 0.05721234614230485, 0.05489187617216158, 0.05256293724203338, 0.050230597265115376, 0.04789993155548795, 0.04557601178392372, 0.04326389494162255, 0.04096861233589015, 0.03869515864170642, 0.03644848103300801, 0.034233468417336044, 0.03205494079727493, 0.02991763878183286, 0.027826213270587232, 0.02578521533304349, 0.023799086305230283, 0.021872148125081217, 0.020008593927634318, 0.018212478920514318, 0.016487711559553486, 0.014838045043753339, 0.013267069148094536, 0.011778202411967632, 0.010374684700222712, 0.009059570153025876, 0.007835720539863904, 0.006705799032159254, 0.005672264408046539, 0.004737365701921402, 0.003903137310404347, 0.003171394565369639, 0.0025437297836723985, 0.002021508802169957, 0.0016058680055775591, 0.0012977118536258649, 0.0010977109129013942, 0.0010063003976527754, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire6.expand_1x1.0.weight
[0.1, 0.10094629803816738, 0.10078530750869763, 0.10051737423188158, 0.1001430737494234, 0.09966321008813202, 0.09907881403280837, 0.0983911409120388, 0.09760166790165066, 0.09671209085162287, 0.09572432064326693, 0.09464047908450396, 0.09346289435205483, 0.09219409599033379, 0.09083680947778866, 0.08939395037235909, 0.08786861804862951, 0.08626408904012915, 0.08458381000108095, 0.08283139030271783, 0.08101059428007007, 0.07912533314587818, 0.0771796565890011, 0.07517774407536663, 0.07312389587015078, 0.07102252380047061, 0.06887814177843339, 0.06669535610489924, 0.06447885557478528, 0.06223340140516631, 0.059963817007806924, 0.057674977628094405, 0.055371799872629184, 0.05305923114796797, 0.05074223903320624, 0.04842580060922855, 0.04611489176754816, 0.04381447652170167, 0.04152949634415835, 0.0392648595516495, 0.03702543076171897, 0.034816020443142914, 0.032641374582665354, 0.03050616449024626, 0.028414976764721125, 0.026372303441426784, 0.024382532342957036, 0.022449937653775277, 0.02057867073893099, 0.018772751226601738, 0.017036058373616474, 0.015372322732507465, 0.013785118137990621, 0.012277854030088187, 0.010853768130383912, 0.009515919487143077, 0.008267181904236798, 0.007110237767985711, 0.0060475722851837, 0.005081468144678707, 0.004214000613977941, 0.003447033081410366, 0.0027822130534224266, 0.0022209686156048672, 0.00176450536505282, 0.0014138038206486562, 0.001169617316830456, 0.0010324703853705588, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire6.expand_1x1.0.bias
[0.1, 0.10094698713013323, 0.10078806093510771, 0.10052355842027129, 0.1001540404671199, 0.09968029064394011, 0.09910331354424091, 0.09842433265649844, 0.09764478776973043, 0.09676633192040239, 0.09579082788713929, 0.09472034424067591, 0.09355715095742205, 0.09230371460594389, 0.09096269311656896, 0.08953693014520542, 0.08802944904332771, 0.08644344644691511, 0.08478228549793769, 0.08304948871276406, 0.08124873051261335, 0.07938382943189061, 0.07745874002092812, 0.07547754446030286, 0.07344444390451232, 0.07136374957336407, 0.06923987360997051, 0.0670773197247341, 0.06488067364516269, 0.06265459339176671, 0.06040379940065763, 0.05813306451379331, 0.055847203858096155, 0.05355106463490511, 0.05124951584141359, 0.04894743794588885, 0.04664971253856683, 0.04436121198016785, 0.042086789069983616, 0.03983126675544452, 0.03759942790498823, 0.035396005165916476, 0.03322567092874638, 0.03109302741933724, 0.02900259693980252, 0.026958812278901297, 0.02496600731224414, 0.023028407812245733, 0.021150122487312007, 0.01933513426926305, 0.017587291867467415, 0.015910301607596867, 0.014307719572307948, 0.012782944060516221, 0.011339208381252956, 0.00997957399738561, 0.008706924033740564, 0.00752395716339414, 0.006433181885096495, 0.005436911203962957, 0.004537257726712356, 0.0037361291818532533, 0.003035224374317496, 0.0024360295831190974, 0.0019398154096776856, 0.001547634083489379, 0.0012603172308585423, 0.001078474111421939, 0.0010024903262046516, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire6.expand_1x1.1.weight
[0.1, 0.10094766592942202, 0.10079077327188578, 0.1005296504606478, 0.10016484412049338, 0.09969711792345266, 0.09912745099015792, 0.09845703584018888, 0.09768727589569652, 0.09681978254353138, 0.0958563717620262, 0.09479906031949435, 0.0936500615524021, 0.0924117807320523, 0.09108681002947883, 0.0896779230890922, 0.08818806922243538, 0.08662036723420473, 0.08497809889346011, 0.08326470206369163, 0.08148376350612402, 0.0796390113713239, 0.07773430739482817, 0.07577363881313023, 0.0737611100169475, 0.07170093395924236, 0.0695974233359831, 0.06745498155810646, 0.06527809353358097, 0.06307131627886724, 0.06083926937942924, 0.058586625319265666, 0.05631809969970582, 0.054038441367944945, 0.05175242247598419, 0.049464828490784936, 0.04718044817655018, 0.04490406357010361, 0.042640439970351496, 0.04039431596278308, 0.03817039349989193, 0.03597332805828336, 0.03380771889307278, 0.03167809940997608, 0.029588927675246547, 0.027544577083324764, 0.0255493272017373, 0.0236073548124091, 0.02172272516814351, 0.019899383482573203, 0.018141146671396553, 0.01645169536218834, 0.01483456618951074, 0.013293144391454004, 0.01183065672310495, 0.010450164701777731, 0.00915455819814746, 0.007946549386702195, 0.006828667068177812, 0.005803251375860563, 0.004872448876838952, 0.00403820807846012, 0.003302275349396915, 0.002666191263864675, 0.0021312873766404384, 0.0016986834356356555, 0.0013692850378575641, 0.0011437817336660651, 0.0010226455832946448, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire6.expand_1x1.1.bias
[0.1, 0.10094833461132674, 0.10079344521780242, 0.10053565191625578, 0.10017548746633165, 0.09971369618948173, 0.09915123243073816, 0.09848925858644937, 0.09772914270205363, 0.0968724556448551, 0.09592096785764502, 0.09487664569987718, 0.09374164738395879, 0.09251831851505532, 0.09120918724362621, 0.08981695904070999, 0.08834451110675567, 0.08679488642555562, 0.0851712874755679, 0.08347706961162454, 0.08171573413070307, 0.07989092103609169, 0.078006401514902, 0.07606607014447495, 0.07407393684378687, 0.07203411858648855, 0.0699508308927034, 0.06782837911716814, 0.06567114955171971, 0.06348360036051634, 0.06127025236672628, 0.059035679709724224, 0.0567845003921039, 0.05452136673604205, 0.052250955768737034, 0.04997795955679183, 0.047707075509516146, 0.04544299667118737, 0.043190402022332264, 0.04095394681007307, 0.038738252927521484, 0.03654789936210241, 0.0343874127325474, 0.032261257934114065, 0.030173828911364012, 0.02812943957756875, 0.026132314899509512, 0.0241865821660951, 0.0222962624588426, 0.02046526234184767, 0.018697365788418515, 0.016996226361057822, 0.015365359660953655, 0.013808136062583454, 0.012327773748445636, 0.010927332058313682, 0.00960970516675701, 0.008377616101994756, 0.00723361111844335, 0.006180054434587578, 0.005219123347049864, 0.00435280373095524, 0.0035828859358909442, 0.0029109610859421034, 0.0023384177914500086, 0.001866439279288339, 0.0014960009475881377, 0.0012278683499648826, 0.0010625956134134576, 0.001000524293140708, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire6.expand_3x3.0.weight
[0.1, 0.10094899334778984, 0.10079607745830216, 0.10054156432064064, 0.1001859732093291, 0.09973002962485332, 0.09917466381344689, 0.09852100886914153, 0.09777039842195359, 0.09692436391692408, 0.09598463148956322, 0.09495311844407478, 0.09383192934154516, 0.092623351706079, 0.09132985135764107, 0.08995406738112771, 0.08849880674193111, 0.08696703855898325, 0.0853618880469631, 0.08368663014002711, 0.08194468281007215, 0.0801396000931633, 0.07827506483835465, 0.07635488119369721, 0.0743829668447647, 0.0723633450215325, 0.07030013628991791, 0.0681975501447294, 0.06605987642117693, 0.06389147654246674, 0.06169677462133747, 0.05948024843369296, 0.057246420282747915, 0.054999847772326055, 0.052745114508135515, 0.05048682074599367, 0.04822957400608102, 0.04597797967237422, 0.04373663159643716, 0.04151010272474149, 0.03930293576863898, 0.03711963393602165, 0.03496465174357929, 0.032842385928400324, 0.030757166477457992, 0.02871324779328495, 0.02671480001386002, 0.024765900504416946, 0.022870525538534598, 0.02103254218548068, 0.019255700420361472, 0.017543625473174812, 0.015899810432376243, 0.014327609118049162, 0.0128302292392193, 0.011410725849274883, 0.010071995112844827, 0.008816768396852182, 0.007647606697798809, 0.00656689541665118, 0.005576839491987572, 0.004679458901336708, 0.0038765845398860735, 0.003169854484968592, 0.0025607106539489825, 0.0020503958623286234, 0.0016399512880712667, 0.0013302143473229492, 0.0011218169858602015, 0.0010151843897525372, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire6.expand_3x3.0.bias
[0.1, 0.10094964230747422, 0.10079867066578471, 0.10054738917827198, 0.10019630400317146, 0.09974612233405505, 0.09919775097532574, 0.09855229451563441, 0.09781105310289853, 0.09697551982540409, 0.0960473777042664, 0.09502849630330773, 0.09392092796318047, 0.09272690366732156, 0.09144882854806535, 0.09008927704196709, 0.08865098770409544, 0.08713685769173996, 0.08554993692864495, 0.0838934219615244, 0.08217064952123349, 0.08038508980156578, 0.07854033946921529, 0.07664011441898294, 0.07468824228882108, 0.07268865474979296, 0.07064537958647732, 0.06856253258377097, 0.06644430923643146, 0.06429497629805994, 0.062118863186546205, 0.059920353263289074, 0.05770387500375779, 0.05547389307717966, 0.053234899353322596, 0.05099140385448711, 0.04874792567093372, 0.04650898385804467, 0.044279088333555816, 0.04206273079319463, 0.0398643756630229, 0.03768845110670895, 0.0355393401058434, 0.033421371631265684, 0.03133881192318469, 0.029295855897658235, 0.027296618696741437, 0.02534512739932428, 0.02344531290935565, 0.021601002037793235, 0.019815909794228665, 0.018093631903715265, 0.016437637563871187, 0.014851262456848046, 0.01333770203024066, 0.011900005060472278, 0.010541067511620893, 0.009263626702056382, 0.008070255790639018, 0.006963358593585905, 0.005945164742445291, 0.005017725192932664, 0.00418290809367488, 0.003442395023183891, 0.0027976776026403354, 0.0022500544913093825, 0.0018006287706414429, 0.0014503057223267215, 0.0011997910047792707, 0.0010495892317238732, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire6.expand_3x3.1.weight
[0.1, 0.10095028165583253, 0.10080122549987998, 0.10055312796515284, 0.10020648245159586, 0.0997619783448469, 0.0992204996452325, 0.09858312320972655, 0.09785111661036841, 0.09702593561339969, 0.09610922128413268, 0.09510279672330846, 0.09400866344143471, 0.09282899737831439, 0.09156614457568067, 0.0902226165115445, 0.08880108510553353, 0.08730437740515534, 0.08573546996355254, 0.08409748291993108, 0.08239367379443399, 0.08062743100980119, 0.07880226715269865, 0.07692181198811876, 0.07498980524074408, 0.07301008915763059, 0.07098660086700127, 0.06892336454834623, 0.06682448342940103, 0.06469413162591921, 0.0625365458404673, 0.060356016936751404, 0.05815688140623157, 0.055943512743994894, 0.05372031275103814, 0.05149170278025742, 0.04926211494355442, 0.04703598329754582, 0.04481773502540514, 0.04261178163237411, 0.04042251017245323, 0.038254274523719316, 0.03611138672962113, 0.03399810842347308, 0.031918642353201035, 0.029877124023195624, 0.027877613469895077, 0.02592408718745361, 0.02402043021955327, 0.022170428433086295, 0.0203777609890739, 0.018645993025794477, 0.016978568568672636, 0.01537880368102974, 0.013849879869316573, 0.012394837755944209, 0.01101657103229551, 0.009717820703943274, 0.008501169639520023, 0.007369037434079867, 0.006323675597168143, 0.005367163075168312, 0.004501402116831159, 0.0037281144902084166, 0.003048838058514524, 0.002464923721726108, 0.0019775327300016014, 0.0015876343742638292, 0.0012960040585384294, 0.0011032217578816775, 0.0010096708649645172, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire6.expand_3x3.1.bias
[0.1, 0.10095091155517498, 0.1008037426077165, 0.10055878212941487, 0.100216511109427, 0.09977760160983612, 0.09924291544603236, 0.09861350249450579, 0.09789059863137406, 0.09707562330569319, 0.0961701767523155, 0.0951760368497681, 0.09409515562932115, 0.09292965544210077, 0.0916818247917723, 0.09035411384097694, 0.08894912960034473, 0.08746963080953077, 0.08591852252032547, 0.08429885039247575, 0.08261379471341693, 0.08086666415365812, 0.07906088927008273, 0.0772000157699203, 0.0752876975486164, 0.07332768951527083, 0.07132384021973161, 0.06928008429582204, 0.06720043473553837, 0.06508897500938841, 0.0629498510483429, 0.060787263103143196, 0.058605457496950446, 0.05640871828752935, 0.05420135885533901, 0.05198771343404726, 0.04977212860009908, 0.04755895473804956, 0.04535253749841931, 0.04315720926484548, 0.040977280647282704, 0.038817032017957664, 0.03668070510669624, 0.034572494672126995, 0.03249654026511375, 0.03045691810059121, 0.02845763305376288, 0.026502610796377203, 0.024595690088522693, 0.02274061524107749, 0.020941028763613374, 0.01920046421219068, 0.017522339251087204, 0.01590994894208551, 0.014366459274494377, 0.012894900948609223, 0.011498163424817527, 0.01017898925003416, 0.008939968672606852, 0.007783534556265703, 0.006711957603103269, 0.005727341894965165, 0.004831620762005927, 0.004026552986522097, 0.0033137193495167854, 0.002694519526776356, 0.002170169340554178, 0.0017416983722576764, 0.0014099479408262996, 0.001175569450770008, 0.0010390231131118968, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire7.squeeze.0.weight
[0.1, 0.10095153216473539, 0.1008062226241837, 0.10056435309189993, 0.10022639248358994, 0.09979299600801726, 0.09926500389674123, 0.09864343977514863, 0.09792950867793755, 0.09712459471290039, 0.09623025837753552, 0.09524823353368989, 0.09418042404609779, 0.09302890009133279, 0.09179589414432857, 0.09048379665024991, 0.08909515139010463, 0.08763265054908105, 0.08609912949717272, 0.08449756129220834, 0.08283105091594485, 0.08110282925439762, 0.07931624683407834, 0.07747476732628439, 0.07558196083203282, 0.07364149696065773, 0.0716571377154893, 0.06963273020040754, 0.06757219916141044, 0.06547953937765623, 0.06335880791673146, 0.06121411626915967, 0.059049622377399594, 0.05686952257478631, 0.054678043450043526, 0.052479433653139465, 0.050277955658371974, 0.04807787750065264, 0.04588346450101016, 0.04369897099735531, 0.04152863209653895, 0.039376655463693636, 0.03724721316477667, 0.03514443357813011, 0.033072393390738045, 0.031035109694699026, 0.029036532199235777, 0.027080535573340815, 0.02517091193390384, 0.023311363493883776, 0.021505495384778934, 0.019756808667310208, 0.018068693543867625, 0.016444422785879632, 0.014887145388847178, 0.013399880467343868, 0.01198551140181811, 0.01064678024854479, 0.009386282423563892, 0.00820646167091274, 0.007109605324906564, 0.006097839875652866, 0.005173126846396491, 0.004337258990688186, 0.0035918568167492885, 0.0029383654457707012, 0.002378051810237041, 0.0019120021977076453, 0.001541120144816326, 0.0012661246855727717, 0.001087548957361666, 0.0010057391673420893, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire7.squeeze.0.bias
[0.1, 0.10095214364073586, 0.10080866617218831, 0.10056984224672863, 0.10023612903409987, 0.09980816534627786, 0.09928677041462246, 0.09867294232166035, 0.09796785609050129, 0.09717286143554489, 0.09628948017878397, 0.09531940333665018, 0.09426448788297832, 0.0931267531942862, 0.09190837718417418, 0.09061169213424461, 0.08923918022952156, 0.0877934688069173, 0.08627732532584112, 0.0846936520705781, 0.08304548059457864, 0.08133596591729414, 0.07956838048466713, 0.07774610790483735, 0.07587263647105512, 0.0739515524842007, 0.0719865333876921, 0.06998134072792313, 0.0679398129537065, 0.06586585806850669, 0.06376344614952703, 0.06163660174797217, 0.059489396185033266, 0.057325939758343714, 0.055150373873823814, 0.05296686311797647, 0.05077958728580923, 0.048592733379643455, 0.04641048759412683, 0.0442370273027919, 0.04207651306150062, 0.03993308064408205, 0.03781083312540923, 0.03571383302707023, 0.03364609454066836, 0.03161157584363837, 0.029614171522288114, 0.027657705116569453, 0.025745921800850453, 0.023882481214698784, 0.022070950457400748, 0.020314797259625962, 0.018617383345308613, 0.01698195799645288, 0.015411651833180523, 0.013909470820927687, 0.012478290516262508, 0.01112085056233823, 0.00983974944451942, 0.008637439516220018, 0.007516222304475056, 0.006478244104232444, 0.005525491869798576, 0.004659789411302255, 0.0038827939034582976, 0.0031959927133134772, 0.0026007005530477457, 0.0020980569632806636, 0.0016890241317007717, 0.0013743850511936265, 0.0011547420209942474, 0.0010305154937331465, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire7.squeeze.1.weight
[0.1, 0.10095274613644999, 0.10081107386290472, 0.10057525096185554, 0.10024572317502996, 0.09982311336087098, 0.09930822031723832, 0.09870201727155703, 0.09800565004126732, 0.09722043486805237, 0.09634785592993833, 0.0953895625359683, 0.09434736600875347, 0.09322323626079342, 0.09201929807103704, 0.09073782706872198, 0.08938124543208376, 0.08795211731006439, 0.08645314397567487, 0.0848871587201715, 0.0832571214976977, 0.08156611333051314, 0.0798173304853856, 0.07801407843215276, 0.07615976559587341, 0.07425789691437733, 0.07231206721339116, 0.07032595441176218, 0.06830331256962328, 0.06624796479263924, 0.06416379600574613, 0.06205474561004279, 0.05992480003671396, 0.057777985212059284, 0.0556183589478704, 0.05345000327153964, 0.05127701671039724, 0.04910350654486147, 0.04693358104504382, 0.04477134170548355, 0.04262087549268924, 0.04048624712014041, 0.03837149136535091, 0.03628060544351591, 0.034217541452157364, 0.03218619890104893, 0.030190417341540012, 0.02823396910921011, 0.02632055219357179, 0.024453783248298874, 0.022637190755192105, 0.02087420835480332, 0.019168168356324077, 0.017522295439006363, 0.015939700557020375, 0.014423375059270445, 0.012976185035283305, 0.011600865897855937, 0.010300017212702631, 0.009076097784874105, 0.007931421011235913, 0.006868150507790854, 0.005888296020110411, 0.004993709624604952, 0.004186082227813175, 0.0034669403703273586, 0.0028376433413957675, 0.0022993806096559145, 0.001853169574854984, 0.0014998536448070968, 0.0012401006412221963, 0.0010744015374197992, 0.001003069530313571, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire7.squeeze.1.bias
[0.1, 0.10095333980226438, 0.10081344629601958, 0.1005805805796122, 0.1002551772754571, 0.09983784371885496, 0.09932935882445669, 0.098730671632491, 0.09804289953746824, 0.09726732620266645, 0.09640539916429205, 0.09545872712978681, 0.09442907697532354, 0.09331837044809453, 0.09212868057954718, 0.09086222781626195, 0.08952137587569314, 0.08810862733450797, 0.08662661895775779, 0.08507811677759877, 0.08346601093074772, 0.08179331026430803, 0.08006313672003366, 0.0782787195075123, 0.07644338907714314, 0.0745605709041578, 0.07263377909528639, 0.07066660983000077, 0.06866273464857685, 0.06662589359950274, 0.0645598882590227, 0.06246857463584509, 0.0603558559742573, 0.058225675469079724, 0.056082008906055705, 0.053928857241413664, 0.05177023913445067, 0.04961018344707498, 0.04745272172430634, 0.04530188066976837, 0.043161674630217195, 0.041036098103132836, 0.03892911828135751, 0.036844667648695616, 0.034786636640294744, 0.03275886638150678, 0.030765141518781288, 0.028809183155971214, 0.02689464190923545, 0.025025091093499843, 0.023204020053193886, 0.021434827649710886, 0.019720815917745993, 0.018065183902352584, 0.016471021688219307, 0.014941304632311476, 0.013478887810641483, 0.012086500689532126, 0.01076674203131922, 0.009522075044001037, 0.008354822783887265, 0.007267163819828481, 0.006261128167117968, 0.005338593498655108, 0.0045012816404418395, 0.003750755357952989, 0.003088415439378416, 0.002515498081180883, 0.0020330725808491816, 0.001642039341152828, 0.0013431281896232486, 0.001136897016397869, 0.0010237307329695735, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire7.expand_1x1.0.weight
[0.1, 0.10095392478573909, 0.10081578405997108, 0.1005858324172375, 0.1002644936603867, 0.09985236001950158, 0.09935019106041443, 0.09875891228482069, 0.09807961342457125, 0.09731354643328748, 0.09646212317899981, 0.09552691284206301, 0.09450963902314316, 0.09341217656660705, 0.09223654810516779, 0.09098492033215548, 0.08965960000828276, 0.0882630297102651, 0.08679778332913098, 0.08526656132651862, 0.08367218575770208, 0.08201759507051919, 0.08030583868978698, 0.07854007139718566, 0.07672354751696887, 0.07485961491821627, 0.07295170884468206, 0.07100334558361139, 0.06901811598519268, 0.06699967884459014, 0.0649517541587528, 0.06287811627042823, 0.060782586912016615, 0.058669028162085114, 0.05654133532752395, 0.054403429764462524, 0.052259251651176286, 0.05011275272630461, 0.04796788900576245, 0.04582861349176917, 0.043698868887431616, 0.04158258033030842, 0.039483648158347845, 0.03740594072153162, 0.03535328725247263, 0.03332947080910649, 0.03133822130248335, 0.02938320862250974, 0.02746803587431021, 0.025596232737673558, 0.023771248961822727, 0.021996448007497574, 0.020275100848067714, 0.018610379941100676, 0.017005353381495402, 0.01546297924695698, 0.013986100146234248, 0.012577437980167288, 0.011239588925201011, 0.009975018648609713, 0.008786057764251037, 0.0076748975372247724, 0.0066435858453524725, 0.005694023404921028, 0.004827960267646347, 0.0040469925953129475, 0.003352559718034181, 0.0027459414815544586, 0.0022282558884825993, 0.0018004570378034315, 0.001463333366465174, 0.0012175061962834014, 0.0010634285888396092, 0.00100138451048482, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire7.expand_1x1.0.bias
[0.1, 0.10095450123166638, 0.10081808773218233, 0.10059100776739627, 0.10027367461165665, 0.09986666579567294, 0.09937072205543829, 0.09878674598412646, 0.09811580038941664, 0.097359106359236, 0.09651804103943967, 0.09559413512747318, 0.09458907008657859, 0.09350467508561411, 0.09234292367005702, 0.09110593017024798, 0.08979594585341413, 0.08841535482647356, 0.08696666969707821, 0.08545252700079169, 0.0838756824027245, 0.08223900568235927, 0.08054547551069349, 0.078798174029205, 0.0770002812405064, 0.07515506922089699, 0.073265896165345, 0.07133620027573835, 0.0693694935035264, 0.06736935515814155, 0.06533942539283226, 0.06328339857976353, 0.06120501658644161, 0.0591080619656994, 0.05699635107163671, 0.054873727114043806, 0.05274405316394892, 0.050611205123019316, 0.04847906466961119, 0.046351512194306325, 0.04423241973779237, 0.042125643943939584, 0.040035019040898984, 0.03796434986299603, 0.03591740492611952, 0.03389790956920846, 0.031909539174318664, 0.029955912477608423, 0.02804058498341715, 0.026167042493422478, 0.02433869476265299, 0.022558869293902148, 0.020830805281837006, 0.01915764771782363, 0.017542441666197606, 0.0159881267223971, 0.014497531663043944, 0.013073369297709508, 0.011718231531734995, 0.010434584649091395, 0.009224764823864102, 0.008090973868531248, 0.007035275226773479, 0.006059590218108024, 0.005165694541181936, 0.004355215042087967, 0.0036296267535848464, 0.002990250210610356, 0.0024382490469727503, 0.0019746278775946025, 0.0016002304701631268, 0.0013157382095145267, 0.001121668857547208, 0.0010183756109206012, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire7.expand_1x1.1.weight
[0.1, 0.10095506928212841, 0.10082035787928996, 0.10059610789868606, 0.10028272236882113, 0.09988076451516831, 0.09939095674792431, 0.09881417936367323, 0.09815146896329208, 0.0974040165889421, 0.09657316558349345, 0.09566040917623092, 0.09466738779917927, 0.09359588613887183, 0.09244782992886057, 0.09122528248873235, 0.08993044101585186, 0.08856563263649536, 0.08713331022347255, 0.08563604798775301, 0.08407653685202049, 0.08245757961446926, 0.08078208591153478, 0.07905306698861155, 0.0772736302881564, 0.07544697386490362, 0.07357638063822934, 0.07166521249199434, 0.06971690423246996, 0.06773495741520562, 0.06572293405193266, 0.06368445020881451, 0.061623169507548814, 0.05954279654100129, 0.05744707021520502, 0.055339757029691274, 0.05322464430822821, 0.051105533392134056, 0.048986232808397166, 0.046870551424882084, 0.04476229160492275, 0.04266524237360602, 0.040583172608026845, 0.03851982426375432, 0.03647890564968153, 0.03446408476334636, 0.03247898269870107, 0.030527167138178157, 0.028612145940749147, 0.026737360837499582, 0.024906181246051234, 0.023121898214947964, 0.021387718508888667, 0.019706758845437846, 0.01808204029357116, 0.016516482844123586, 0.015012900161898074, 0.013573994528866252, 0.01220235198754981, 0.01090043769331054, 0.009670591483902317, 0.008515023674247562, 0.007435811083995768, 0.006434893305003564, 0.005514069215444594, 0.0046749937468139316, 0.003919174909637739, 0.00324797108323343, 0.002662588574391349, 0.0021640794493655627, 0.001753339643070189, 0.0014311073488794393, 0.0011979616919252857, 0.0010543216882771592, 0.0010004454918742126, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire7.expand_1x1.1.bias
[0.1, 0.10095562907655327, 0.10082259505736699, 0.10060113405613239, 0.10029163913001476, 0.09989465958204106, 0.09941089998617664, 0.09884121893682123, 0.09818662752494407, 0.09744828754356216, 0.09662750942574719, 0.09572574991882042, 0.09474460949886382, 0.09368582953013598, 0.09255128917443445, 0.09134300205589008, 0.09006311268711237, 0.08871389266302941, 0.08729773662917728, 0.08581715803159465, 0.08427478465586591, 0.0826733539632303, 0.08101570823203455, 0.07930478951315227, 0.07754363440832344, 0.07573536868068141, 0.0738832017070331, 0.07199042078173844, 0.07006038528229894, 0.06809652070701037, 0.06610231259526199, 0.06408130034127228, 0.06203707091224151, 0.05997325248206982, 0.057893507991940124, 0.05580152864919485, 0.05370102737604472, 0.0515957322197374, 0.04948937973588142, 0.04738570835666928, 0.04528845175576997, 0.04320133222166694, 0.041128054051203046, 0.03907229697505774, 0.037037709626825045, 0.03502790306728389, 0.03304644437535417, 0.031096850317113147, 0.029182581104109262, 0.027307034252050767, 0.02547353855076939, 0.023685348156161214, 0.021945636814590504, 0.020257492230007543, 0.018623910583777475, 0.017047791216947078, 0.015531931484387106, 0.014079021789943517, 0.012691640811409388, 0.011372250923792342, 0.01012319382900036, 0.00894668639970278, 0.00784481674474281, 0.006819540503084775, 0.005872677372873908, 0.005005907881768806, 0.004220770404278883, 0.0035186584314005225, 0.0029008180973976944, 0.002368345968116891, 0.0019221870947615507, 0.0015631333365802628, 0.0012918219554457202, 0.0011087344848188343, 0.0010141958751053329, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire7.expand_3x3.0.weight
[0.1, 0.10095618075177012, 0.1008247998121411, 0.10060608746167317, 0.10030042705279739, 0.09990835433788699, 0.0994305565302067, 0.09886787109938608, 0.09822128430352786, 0.09749192946052443, 0.09668108496161232, 0.09579017203064649, 0.09482075223302186, 0.09377452473860848, 0.09265332334349763, 0.09145911325577925, 0.09019398765098424, 0.08886016400322932, 0.08745998019849516, 0.08599589043685002, 0.08447046093080174, 0.08288636540731764, 0.0812463804213963, 0.0795533804894053, 0.07781033305071561, 0.07602029326646292, 0.07418639866455311, 0.07231186364029775, 0.07039997382231855, 0.06845408031359644, 0.06647759381775889, 0.06447397866090125, 0.06244674671942019, 0.060399451264502205, 0.058335680734056865, 0.05625905244301071, 0.05417320624298636, 0.05208179814248018, 0.0499884938987204, 0.04789696259243814, 0.045810870196813014, 0.043733873151865624, 0.04166961195555934, 0.039621704782845095, 0.03759374114383298, 0.03558927559220696, 0.03361182149491004, 0.031664844874020305, 0.029751758331611724, 0.027875915068247784, 0.026040603005592355, 0.02424903902343958, 0.022504363321263595, 0.020809633914171368, 0.0191678212729058, 0.01758180311729382, 0.016054359372265802, 0.014588167295286537, 0.013185796783738973, 0.011849705870485373, 0.010582236415501118, 0.009385610001133093, 0.008261924038176893, 0.007213148089598242, 0.006241120418342272, 0.005347544765281508, 0.004533987362950075, 0.0038018741902984925, 0.003152488473280523, 0.002586968435653413, 0.002106305303933475, 0.0017113415700040482, 0.001402769514421103, 0.0011811299930046472, 0.0010468114888429404, 0.0010000494313710186, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire7.expand_3x3.0.bias
[0.1, 0.10095672444206277, 0.10082697267920765, 0.1006109693146319, 0.10030908825498022, 0.09992185206310414, 0.0994499310534939, 0.09889414213194922, 0.09825544738149715, 0.09753495239700474, 0.09673390437136982, 0.09585368993660213, 0.09489583276353243, 0.09386199092430428, 0.09275395402221412, 0.09157364009386809, 0.09032309228901779, 0.0890044753338225, 0.08762007178365988, 0.08617227807197168, 0.08466360036198396, 0.08309665020848261, 0.08147414003715372, 0.07979887844931421, 0.07807376536016028, 0.07630178697894945, 0.07448601063980567, 0.07262957949209561, 0.07073570705956682, 0.06880767167766648, 0.06684881081866959, 0.0648625153144399, 0.06285222348682437, 0.06082141519584129, 0.05877360581596487, 0.05671234015093366, 0.054641186297616086, 0.052563729469555204, 0.050483565790884005, 0.0484042960713543, 0.046329519573254666, 0.044262827781007145, 0.04220779818422746, 0.04016798808501076, 0.0381469284401622, 0.036148117749032004, 0.034175015997534974, 0.0322310386688376, 0.03031955083108058, 0.028443861312370658, 0.026607216973125403, 0.024812797085685352, 0.023063707830922597, 0.021362976921372425, 0.019713548360195315, 0.01811827734504175, 0.016579925325641415, 0.015101155223672058, 0.013684526823182587, 0.012332492339549896, 0.011047392174639115, 0.009831450865515939, 0.008686773233723221, 0.007615340741787912, 0.006619008063265258, 0.005699499872257396, 0.0048584078579640855, 0.004097187969433141, 0.0034171578952801145, 0.0028194947827399333, 0.0023052331999987513, 0.0018752633453333104, 0.0015303295061578838, 0.0012710287706461534, 0.0010978099941582155, 0.0010109730222619896, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire7.expand_3x3.1.weight
[0.1, 0.10095726027922221, 0.10082911418423811, 0.10061578079218043, 0.10031762481543356, 0.09993515597812526, 0.09946902814470804, 0.09892003820211978, 0.09828912469743473, 0.09757736623333389, 0.09678597962413793, 0.09591631781555504, 0.09496986757169999, 0.0939482469333389, 0.09285320245170475, 0.09168660620261292, 0.09045045258598122, 0.08914685491622625, 0.08777804180936444, 0.08634635337299518, 0.08485423720567892, 0.08330424421255002, 0.08169902424431784, 0.08004132156711152, 0.07833397017091337, 0.07657988892460106, 0.07478207658588218, 0.07294360667465143, 0.0710676222185354, 0.06915733037960756, 0.06721599697145995, 0.06524694087600459, 0.0632535283695501, 0.06123916736785332, 0.05920730159998455, 0.05716140472096692, 0.055104974373254345, 0.053041526207201255, 0.05097458787074591, 0.04890769297858291, 0.04684437507113499, 0.04478816157365175, 0.04274256776576285, 0.04071109077179527, 0.03869720358212857, 0.036704349115809276, 0.03473593433457508, 0.03279532441835096, 0.030885837012175257, 0.029010736554390706, 0.027173228695797108, 0.025376454819306678, 0.023623486669470607, 0.02191732110105923, 0.020260874955672276, 0.018656980075139242, 0.01710837846023421, 0.015617717582981812, 0.014187545860568772, 0.012820308298598353, 0.01151834231113593, 0.01028387372469217, 0.009119012972974821, 0.008025751488914795, 0.007005958300134767, 0.006061376833680287, 0.005193621935476489, 0.004404177109605488, 0.0036943919821243614, 0.003065479993759567, 0.002518516325422137, 0.0020544360600904966, 0.001674032584202994, 0.0013779562312933248, 0.0011667131701875823, 0.0010406645396636763, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire7.expand_3x3.1.bias
[0.1, 0.1009577883925979, 0.10083122484318359, 0.10062052304979141, 0.10032603877487667, 0.09994826924462329, 0.09948785230939526, 0.09894556536674902, 0.09832232404882546, 0.09761918067633774, 0.09683732248176534, 0.0959780696047544, 0.09504287286310904, 0.09403331130313736, 0.09295108953348807, 0.09179803484697967, 0.09057609413528174, 0.08928733060165793, 0.08793392027732086, 0.08651814834728114, 0.085042405291894, 0.08350918285061869, 0.08192106981480524, 0.08028074765661275, 0.07859098600143946, 0.07685463795150896, 0.07507463526850917, 0.07325398342341727, 0.07139575652186927, 0.06950309211364247, 0.06757918589501465, 0.06562728631294494, 0.06365068908018724, 0.06165273161059677, 0.05963678738402606, 0.05760626025032454, 0.05556457868205971, 0.05351518998566357, 0.05146155448077875, 0.049407139657632444, 0.047355414322302884, 0.04530984273976413, 0.043273878784598374, 0.041250960109252055, 0.03924450233968235, 0.037257893308194796, 0.03529448733320934, 0.03335759955561343, 0.031450500341265106, 0.029576409759096867, 0.02773849214414429, 0.025939850754679444, 0.024183522532469817, 0.022472472975010895, 0.020809591128389218, 0.019197684709231427, 0.01763947536397491, 0.01613759407346497, 0.014694576710637529, 0.013312859758788431, 0.011994776197658107, 0.010742551564278807, 0.009558300195234664, 0.008444021656679894, 0.007401597368142742, 0.006432787425815789, 0.0055392276306963075, 0.004722426726594813, 0.00398376385267487, 0.003324486214825933, 0.002745706979800721, 0.0022484033956728924, 0.0018334151417885572, 0.0015014429109977015, 0.0012530472265592943, 0.0010886474957178141, 0.0010085213015490805, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire8.squeeze.0.weight
[0.1, 0.10095830890914792, 0.10083330516247396, 0.10062519722168049, 0.10033433213665018, 0.09996119496669043, 0.09950640797162741, 0.09897072957409825, 0.09835505309477255, 0.09766040526261169, 0.0968879445026509, 0.09603895900415911, 0.09511486457239832, 0.09411720226756493, 0.09304763583485057, 0.091907948929908, 0.09070004214434907, 0.08942592983623528, 0.08808773677084639, 0.08668769457732904, 0.08522813802713472, 0.08371150114045295, 0.08214031312713299, 0.08051719416886322, 0.07884485104964174, 0.07712607264182536, 0.07536372525528423, 0.0735607478574186, 0.07172014717200839, 0.06984499266506952, 0.06793841142607841, 0.06600358295310112, 0.06404373385052364, 0.062062132448225685, 0.06006208335117105, 0.058046921928504316, 0.056020008751343636, 0.053984723988545716, 0.05194446176978882, 0.0499026245253739, 0.04786261731218343, 0.045827842135259984, 0.04380169227447414, 0.04178754662574295, 0.03978876406623563, 0.03780867785296343, 0.035850590064094884, 0.03391776609226606, 0.03201342919906939, 0.030140755139801956, 0.028302866867437406, 0.02650282932465331, 0.024743644332598992, 0.023028245584927654, 0.021359493755440724, 0.01974017172750353, 0.01817297995318749, 0.016660531949878443, 0.015205349941860964, 0.013809860654147167, 0.01247639126556415, 0.011207165527848995, 0.01000430005722346, 0.008869800804632243, 0.007805559710531856, 0.006813351549807977, 0.005894830972083497, 0.0050515297423526775, 0.004284854186542857, 0.0035960828462641196, 0.002986364346657399, 0.0024567154808971476, 0.002008019514542663, 0.0016410247125658631, 0.001356343091512007, 0.0011544493988741957, 0.0010356803213837076, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire8.squeeze.0.bias
[0.1, 0.10095882195348799, 0.10083535563921248, 0.10062980442123877, 0.10034250686747144, 0.09997393619199176, 0.09952469947561643, 0.09899553666596153, 0.09838731935865862, 0.09770104936173044, 0.09693785704549115, 0.09609899948068859, 0.09518585836795554, 0.0941999377619805, 0.09314286159414631, 0.09201637099771715, 0.09082232143998004, 0.08956267966606403, 0.08823952045947132, 0.08685502322465598, 0.08541146839727926, 0.08391123368805409, 0.08235679016636595, 0.08075069819012026, 0.07909560318852105, 0.07739423130472663, 0.07564938490555957, 0.07386393796566719, 0.07204083133373484, 0.07018306788855001, 0.06829370759289487, 0.06637586245341469, 0.06443269139476374, 0.062467395056471364, 0.06048321052109871, 0.05848340598236922, 0.0564712753620553, 0.054450132884487835, 0.05242330761762477, 0.05039413798967052, 0.04836596629027792, 0.04634213316538985, 0.04432597211478826, 0.042320804001413886, 0.040329931581500174, 0.038356634064531395, 0.036404161711984996, 0.03447573048375483, 0.03257451674107336, 0.030703652014657603, 0.02886621784669642, 0.0270652407151751, 0.025303687048897124, 0.02358445834141471, 0.021910386371915086, 0.020284228540935197, 0.018708663328587113, 0.017186285882774665, 0.01571960374466875, 0.014311032718481421, 0.012962892892341975, 0.011677404816829006, 0.01045668584745309, 0.009302746657114187, 0.008217487924278382, 0.007202697202328789, 0.006260045975247352, 0.005391086904477016, 0.0045972512714990916, 0.0038798466203383, 0.0032400546038783774, 0.002678929037535787, 0.002197394163497334, 0.0017962431283806359, 0.001476136676824973, 0.0012376020631643995, 0.001081032182975549, 0.0010066849259307723, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire8.squeeze.1.weight
[0.1, 0.10095932764793925, 0.1008373767613659, 0.1006343457414556, 0.10035056489817326, 0.09998649591289349, 0.09954273108729406, 0.09901999237974371, 0.09841913023075241, 0.09774112217939473, 0.09698707127295723, 0.09615820427239748, 0.09525586965653379, 0.09428153542821309, 0.09323678672602574, 0.09212332324545294, 0.09094295647364227, 0.08969760674230987, 0.08838930010356419, 0.08702016503373383, 0.08559242897056192, 0.08410841468940092, 0.0825705365243031, 0.08098129644015473, 0.07934327996224431, 0.07765915196988665, 0.07593165236094655, 0.07416359159431525, 0.07235784611759133, 0.07051735368740523, 0.06864510859000042, 0.06674415676984669, 0.06481759087421123, 0.06286854522174909, 0.060900190703298634, 0.05891572962317805, 0.05691839048937541, 0.05491142276110807, 0.05289809156229683, 0.05088167236955496, 0.04886544568333484, 0.046852691690901144, 0.04484668492981352, 0.04285068896060093, 0.040867951057294225, 0.038901696924455276, 0.03695512544929739, 0.0350314034974345, 0.03313366076072637, 0.031264984665601306, 0.029428415350140416, 0.02762694071809505, 0.02586349157788368, 0.02414093687447723, 0.022462079021929284, 0.020829649344145426, 0.019246303631308432, 0.017714617819188944, 0.016237083798370827, 0.014816105360209171, 0.013453994286116266, 0.012152966586538149, 0.010915138895740372, 0.009742525028268133, 0.008637032702683418, 0.007600460437908896, 0.0066344946272281265, 0.005740706794702343, 0.004920551038467224, 0.004175361665069271, 0.0035063510186903396, 0.0029146075087921157, 0.002401093839389167, 0.001966645442831493, 0.0016119691206445677, 0.001337641893638152, 0.0011441100631544956, 0.0010316884849833777, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire8.squeeze.1.bias
[0.1, 0.10095982611257533, 0.10083936900795053, 0.10063882225533204, 0.10035850812442637, 0.09999887706756708, 0.09956050699585788, 0.0990441023504952, 0.09845049297076257, 0.09778063276051582, 0.09703559815530205, 0.09621658639257552, 0.09532491358779044, 0.09436201261946198, 0.09332943082659427, 0.09222882752217541, 0.09106197132673549, 0.0898307373262519, 0.08853710405896985, 0.08718315033597925, 0.08577105190065794, 0.08430307793234884, 0.08278158739988978, 0.08120902527085548, 0.07958791858260356, 0.0779208723814379, 0.0762105655364152, 0.0744597464345216, 0.07267122856413714, 0.07084788599388507, 0.06899264875413155, 0.06710849812855722, 0.065198461863367, 0.0632656093018367, 0.06131304645201488, 0.05934391099550634, 0.05736136724535719, 0.055368601061144766, 0.053368814729442986, 0.05136522181789038, 0.0493610420111299, 0.047359495936918974, 0.045363799990724, 0.043377161167116075, 0.041402771906273284, 0.03944380496387154, 0.03750340831260738, 0.03558470008354584, 0.03369076355542277, 0.03182464219995296, 0.029989334791106617, 0.02818779058621307, 0.02642290458663542, 0.024697512885632263, 0.023014388110881967, 0.021376234968993435, 0.019785685899162936, 0.018245296842961455, 0.016757543137050357, 0.015324815535425522, 0.013949416367582061, 0.012633555838773299, 0.011379348478309258, 0.010188809741602217, 0.009063852771419488, 0.008006285323548183, 0.007017806861812103, 0.006100005827108983, 0.005254357084856664, 0.0044822195549500616, 0.0037848340280372643, 0.003163321171624266, 0.0026186797292121304, 0.0021517849153606374, 0.0017633870092574047, 0.0014541101490526777, 0.0012244513288970408, 0.0010747796002939839, 0.0010053354790505278, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire8.expand_1x1.0.weight
[0.1, 0.1009603174652679, 0.10084133284921414, 0.10064323501628503, 0.10036633840744603, 0.10001108254106905, 0.09957803131528431, 0.09906787211290416, 0.09848141471033926, 0.09781958999223948, 0.09708344847389933, 0.09627415863377355, 0.09539300505874973, 0.09444138640512166, 0.09342081317850033, 0.09233290533618622, 0.09117938971580884, 0.08996209729431498, 0.08868296028165644, 0.0873440090537905, 0.08594736892986132, 0.08449525679867798, 0.08298997759984367, 0.08143392066512195, 0.07982955592584713, 0.07817942999239878, 0.07648616211196356, 0.0747524400110005, 0.07298101562900909, 0.0711747007503719, 0.06933636254120526, 0.06746891899830253, 0.0655753343173938, 0.06365861418807381, 0.06172180102286665, 0.0597679691280003, 0.05780021982355587, 0.05582167652073805, 0.05383547976408022, 0.05184478224645356, 0.04985274380479346, 0.04786252640448589, 0.0458772891203753, 0.04390018312236085, 0.04193434667353995, 0.03998290014883888, 0.03804894108203745, 0.036135539249049185, 0.03424573179526189, 0.0323825184146724, 0.03054885658846825, 0.028747656890613694, 0.026981778367891465, 0.02525402400173403, 0.023567136259047092, 0.0219237927390882, 0.020326601923309685, 0.01877809903491235, 0.017280742014682254, 0.01583690761949789, 0.0144488876497006, 0.01311888531131681, 0.011849011718906, 0.010641282544585594, 0.009497614818551901, 0.00841982388617531, 0.007409620526500132, 0.006468608236722655, 0.005598280686957773, 0.004800019349334366, 0.004075091305182654, 0.003424647233794231, 0.002849719585947285, 0.0023512209450959657, 0.0019299425788254657, 0.0015865531828718352, 0.0013215978197003366, 0.0011354970533270273, 0.0010285462817569248, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire8.expand_1x1.0.bias
[0.1, 0.1009608018217316, 0.10084326874681354, 0.10064758505854277, 0.10037405757468318, 0.10002311516639768, 0.09959530808580959, 0.09909130710324725, 0.09851190245552516, 0.09785800260691013, 0.09713063282471562, 0.0963309335717572, 0.09546015871819, 0.0945196735755317, 0.09351095275595354, 0.09243557786019586, 0.09129523499773345, 0.09009171214307868, 0.08882689633236784, 0.08750277070462593, 0.08612141139234918, 0.08468498426628061, 0.08319574153948252, 0.08165601823603048, 0.08006822852986582, 0.07843486195954674, 0.07675847952483328, 0.07504170967122632, 0.07328724416875654, 0.07149783389148523, 0.06967628450433415, 0.06782545206400735, 0.06594823854090247, 0.06404758726903262, 0.062126478331092985, 0.06018792388590849, 0.05823496344558813, 0.056270659109791545, 0.054298090764579865, 0.05232035125337875, 0.050340541527625376, 0.04836176578470244, 0.046387126600782876, 0.044419720066216625, 0.0424626309310864, 0.040518927768544405, 0.038591658163513336, 0.03668384393429513, 0.03479847639458022, 0.03293851166328551, 0.031106866029575398, 0.02930641138033291, 0.0275399706972502, 0.025810313630599185, 0.02412015215662148, 0.02247213632534747, 0.0208688501055109, 0.019312807333074205, 0.01780644776971682, 0.016352133277466846, 0.014952144115473253, 0.013608675364725892, 0.012323833486328352, 0.011099633018720474, 0.009937993419028884, 0.008840736053498093, 0.007809581341720872, 0.0068461460591458575, 0.005951940802091265, 0.005128367619240109, 0.004376717813329905, 0.0036981699164841666, 0.0030937878423598565, 0.0025645192180083257, 0.002111193898065144, 0.0017345226635985026, 0.0014350961076562798, 0.0012133837092592073, 0.0010697330972919519, 0.0010043695054463666, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire8.expand_1x1.1.weight
[0.1, 0.10096127929556764, 0.10084517715398862, 0.10065187339753129, 0.10038166742050039, 0.10003497772552683, 0.09961234127537898, 0.09911441266129956, 0.09854196308915636, 0.09789587918497676, 0.09717716162171648, 0.09638692356938901, 0.09552638897095656, 0.09459689064665272, 0.09359986822967292, 0.09253686593642996, 0.09140953017482817, 0.09021960699426038, 0.08896893938127745, 0.08765946440511882, 0.08629321021752501, 0.08487229291147913, 0.08339891324374238, 0.08187535322626, 0.08030397259171687, 0.07868720513871702, 0.07702755496224781, 0.07532759257526699, 0.07358995092741982, 0.07181732132705258, 0.07001244927283823, 0.06817813020147072, 0.06631720515801393, 0.064432556395611, 0.06252710291136947, 0.06060379592533624, 0.05866561430956485, 0.056715559974354526, 0.05475665321880693, 0.052791928052901706, 0.050824427498336475, 0.048857198875408965, 0.04689328908324156, 0.04493573988065805, 0.042987583175021805, 0.0410518363263323, 0.039131497473852944, 0.037229540892508343, 0.035348912386243735, 0.0334925247254806, 0.03166325313573592, 0.02986393084439184, 0.028097344692513196, 0.026366230818509664, 0.024673270420327388, 0.02302108560273411, 0.02141223531612942, 0.019849211393170293, 0.018334434689350337, 0.016870251333510795, 0.015458929094089885, 0.01410265386673925, 0.01280352628874722, 0.011563558485512444, 0.010384670954107535, 0.009268689588759, 0.0082173428528508, 0.00723225910183165, 0.006314964061172095, 0.005466878463278023, 0.004689315847020197, 0.003983480523288279, 0.003350465709720218, 0.0027912518374958884, 0.00230670503281774, 0.0018975757754300818, 0.0015644977362548988, 0.0013079867959445038, 0.0011284402458710421, 0.001026136172790403, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire8.expand_1x1.1.bias
[0.1, 0.10096174999830676, 0.1008470585157322, 0.10065610103025245, 0.10038916970683319, 0.10004667295041736, 0.09962913478106548, 0.09913719403220492, 0.09857160337321476, 0.09793322815784156, 0.09722304510020809, 0.09644214078044062, 0.09559170998220129, 0.09467305386466898, 0.09368757797176579, 0.09263679008167455, 0.0915222978999383, 0.09034580659967058, 0.08910911621264048, 0.0878141188752239, 0.08646279593343482, 0.08505721491146571, 0.08359952634837536, 0.08209196050776402, 0.08053682396546996, 0.0789364960805082, 0.07729342535465114, 0.07561012568622061, 0.07388917252382331, 0.07213319892591429, 0.07034489153221728, 0.06852698645316573, 0.06668226508365376, 0.06481354984750162, 0.06292369987914723, 0.06101560664917014, 0.05909218954034147, 0.057156391380968, 0.05521117394236468, 0.05325951340734432, 0.05130439581665767, 0.04934881250035093, 0.04739575550103048, 0.04544821299603758, 0.04350916472553676, 0.041581577433513206, 0.03966840032865431, 0.03777256057206004, 0.03589695879868643, 0.03404446467937374, 0.032217912530250005, 0.030420096976227107, 0.028653768675224435, 0.026921630109662212, 0.025226331451663003, 0.02357046650828841, 0.021956568753013925, 0.020387107449514438, 0.018864483873690597, 0.017391027639716544, 0.01596899313573006, 0.014600556074618548, 0.013287810165178205, 0.012032763908739374, 0.010837337526159424, 0.009703360019884654, 0.008632566375576477, 0.007626594907583211, 0.006686984752319019, 0.00581517351338509, 0.005012495062036043, 0.004280177496356812, 0.0036193412622724736, 0.003030997439265958, 0.0025160461934262794, 0.002075275400194481, 0.0017093594389140535, 0.001418858161030522, 0.0012042160335187504, 0.0010657614588483457, 0.001003706272527948, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire8.expand_3x3.0.weight
[0.1, 0.10096221403945092, 0.10084891326895624, 0.10066026893565376, 0.10039656616383688, 0.10005820352400692, 0.09964569243045829, 0.09915965636830724, 0.09860082995113258, 0.09797005781065243, 0.09726829332011543, 0.09649659715333571, 0.09565613568154985, 0.09474817921051851, 0.09377410006053744, 0.09273537049225995, 0.0916335604814656, 0.09047033534613838, 0.08924745322944123, 0.08796676244239086, 0.08663019867024946, 0.08523978204685566, 0.08379761410131659, 0.08230587458167606, 0.0807668181603596, 0.079182771026376, 0.07755612736942573, 0.07588934576123074, 0.07418494543955471, 0.07244550250053021, 0.07067364600504811, 0.06887205400509387, 0.0670434494960369, 0.06519059630099082, 0.06331629489346483, 0.06142337816462064, 0.05951470714153178, 0.057593166662917444, 0.055661661018886366, 0.05372310956128117, 0.05178044229125785, 0.0498365954307694, 0.047894506984647145, 0.04595711229998745, 0.04402733962955522, 0.04210810570591016, 0.040202311332945224, 0.038312837001500066, 0.036442538535676576, 0.034594242776436517, 0.03277074330900553, 0.03097479624054116, 0.029209116034446477, 0.02747637140762589, 0.025779181296883804, 0.02412011090056297, 0.022501667801405167, 0.02092629817649419, 0.019396383100009903, 0.017914234944381303, 0.01648209388527782, 0.015102124515721838, 0.01377641257443966, 0.012506961793395766, 0.011295690869275472, 0.010144430563492856, 0.009054920935107763, 0.00802880871083364, 0.0070676447961115045, 0.00617288193101188, 0.005345872494507608, 0.004587866460436351, 0.0039000095082420854, 0.0032833412913511766, 0.002738793865800231, 0.0022671902814908208, 0.0018692433382001875, 0.0015455545082283298, 0.001296613027309639, 0.00112279515516318, 0.0010243636067993492, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire8.expand_3x3.0.bias
[0.1, 0.1009626715265143, 0.10085074184265448, 0.10066437807499001, 0.10040385849051928, 0.10006957208117834, 0.0996620179830219, 0.09918180473094387, 0.09862964935005011, 0.0980063762850405, 0.09731291616919824, 0.09655030443482529, 0.09571967976719789, 0.09482228240435131, 0.09385945228523217, 0.09283262704898337, 0.09174333988834915, 0.09059321726040528, 0.08938397645803266, 0.08811742304576044, 0.08679544816380735, 0.0854200257043466, 0.08399320936421058, 0.08251712957843611, 0.0809939903392291, 0.07942606590509774, 0.07781569740506872, 0.07616528934305626, 0.0744773060076037, 0.07275426779235832, 0.0709987474327734, 0.06921336616465683, 0.06740078981030173, 0.0655637247980435, 0.0637049141211862, 0.061827133242332445, 0.05993318594923221, 0.058025900168338, 0.05610812374231792, 0.05418272017783076, 0.05225256436991277, 0.05032053830935994, 0.048389526779515225, 0.04646241304888638, 0.04454207456602528, 0.042631378663097554, 0.040733178274557316, 0.038850307677319486, 0.03698557825879072, 0.03514177431907735, 0.03332164891363838, 0.031527919742591365, 0.029763265092808334, 0.028030319838861575, 0.026331671508789622, 0.02466985642055849, 0.023047355894986576, 0.021466592550787846, 0.019929926687265516, 0.01843965276005734, 0.016997995955194436, 0.01560710886658941, 0.014269068281914644, 0.012985872081669625, 0.011759436256067884, 0.010591592044197334, 0.009484083199725882, 0.008438563387235004, 0.007456593713068654, 0.006539640394384671, 0.005689072569888814, 0.004906160255520474, 0.004192072448142386, 0.0035478753800659174, 0.0029745309270180756, 0.0024728951719274186, 0.0020437171266732826, 0.0016876376137069707, 0.0014051883092148433, 0.001196790949251835, 0.001062756700030997, 0.001003285693309052, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire8.expand_3x3.1.weight
[0.1, 0.10096312256506323, 0.10085254465806126, 0.1006684293921769, 0.10041104835535972, 0.10008078120970726, 0.09967811513142653, 0.09920364409220167, 0.09865806798302784, 0.09804219158180376, 0.09735692336620605, 0.09660327417359614, 0.09578235570993664, 0.09489537890991678, 0.09394365215070595, 0.09292857932196975, 0.09185165775499607, 0.09071447601398566, 0.0895187115527651, 0.08826612824037916, 0.08695857375921204, 0.08559797687947596, 0.08418634461408724, 0.0827257592581267, 0.08121837531725173, 0.0796664163295905, 0.07807217158580669, 0.07643799275217279, 0.07476629040163328, 0.07305953045797482, 0.07132023055834838, 0.06955095633950929, 0.06775431765325322, 0.06593296471663046, 0.06408958420261766, 0.06222689527701363, 0.0603476455874048, 0.058454607210117505, 0.056550572561135416, 0.054638350277013914, 0.0527207610718677, 0.05080063357654273, 0.04888080016611011, 0.0469640927818372, 0.04505333875379824, 0.04315135663028717, 0.041260952020184455, 0.03938491345441058, 0.03752600827257153, 0.03568697854086313, 0.0338705370072565, 0.03207936309993055, 0.030316098974854357, 0.028583345618349906, 0.026883659010383816, 0.025219546354248, 0.023593462378190655, 0.02200780571445292, 0.020464915361052743, 0.018967067231535018, 0.017516470797777395, 0.016115265830804075, 0.014765519244415205, 0.013469222046287567, 0.012228286401044508, 0.011044542809626728, 0.009919737409125207, 0.008855529397058887, 0.007853488583896718, 0.006915093077434381, 0.006041727102441241, 0.005234678958794042, 0.004495139121109131, 0.0038241984826763937, 0.00322284674628544, 0.00269197096431758, 0.002232354230257177, 0.0018446745235524689, 0.0015295037095298882, 0.0012873066958369419, 0.0011184407466582106, 0.0010231549557158483, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire8.expand_3x3.1.bias
[0.1, 0.10096356725875544, 0.10085432212880713, 0.10067242381413713, 0.1004181373969147, 0.10009183345118947, 0.0996939875028503, 0.09922517933663683, 0.09868609215121359, 0.09807751156353794, 0.09740032446397301, 0.0966555177238137, 0.09584417675710964, 0.09496748393888088, 0.09402671688203133, 0.09302324657547115, 0.09195853538616133, 0.09083413492799229, 0.08965168380060194, 0.08841290520142864, 0.08711960441447889, 0.08577366617946958, 0.08437705194517862, 0.08293179701100667, 0.08144000756091566, 0.07990385759406667, 0.0783255857566299, 0.07670749207938406, 0.0750519346258592, 0.07336132605590814, 0.07163813010971387, 0.06988485801735725, 0.06810406483917715, 0.06629834574225642, 0.06447033221845977, 0.0626226882495354, 0.06075810642486856, 0.05887930401754515, 0.05698901902444342, 0.05509000617612463, 0.0531850329223377, 0.05127687539898795, 0.04936831438244746, 0.047462131237102856, 0.045561103862046086, 0.0436680026428153, 0.04178558641408534, 0.0399165984391912, 0.03806376241234407, 0.03622977848936531, 0.03441731935272341, 0.03262902631660806, 0.0308675054777174, 0.02913532391736828, 0.027435005960463738, 0.025769029496770086, 0.024139822369864186, 0.022549758839013542, 0.021001156119145444, 0.019496271003947237, 0.018037296577019135, 0.016626359015872227, 0.015265514493429687, 0.01395674618154586, 0.012701961360911042, 0.011502988641552699, 0.010361575297984593, 0.009279384722886714, 0.008257994003027014, 0.007298891620957792, 0.00640347528583553, 0.005573049896525994, 0.004808825639962443, 0.004111916227528572, 0.0034833372720361293, 0.0029240048076626217, 0.0024347339550058068, 0.00201623773320062, 0.0016691260208295026, 0.0013939046671404324, 0.0011909747548679841, 0.0010606320157315265, 0.0010030663994625869, 0, 0, 0, 0, 0, 0, 0]
module.fire9.squeeze.0.weight
[0.1, 0.10096400570937812, 0.10085607466107074, 0.10067636225113867, 0.10042512722441037, 0.1001027313019485, 0.09970963866025417, 0.09924641526295888, 0.09871372804596601, 0.09811234395721553, 0.09744312885245408, 0.09670704624860041, 0.09590515593650112, 0.09503861245507385, 0.09410866342903486, 0.09311664777260445, 0.09206399376177615, 0.09095221697792558, 0.08978291812571931, 0.08855778072846576, 0.08727856870422607, 0.08594712382617492, 0.08456536307086784, 0.08313527585823266, 0.08165892118725926, 0.08013842467151114, 0.07857597547872741, 0.07697382317892115, 0.07533427450551232, 0.07365969003415851, 0.07195248078406506, 0.07021510474666798, 0.06845006334668761, 0.0666598978406484, 0.06484718565804977, 0.0630145366904563, 0.06116458953384988, 0.05930000768965411, 0.057423475729900544, 0.05553769543205799, 0.053645381889090016, 0.051749259600341185, 0.04985205854888009, 0.04795651027094736, 0.04606534392316713, 0.04418128235318481, 0.04230703817938844, 0.0404453098853575, 0.03859877793466299, 0.03677010091161194, 0.034961911693493164, 0.03317681365983537, 0.031417376944134996, 0.029686134733451122, 0.02798557962119443, 0.026318160018362097, 0.024686276628385052, 0.023092278990663302, 0.021538462097765707, 0.020027063091164976, 0.01856025804026464, 0.01714015880935621, 0.015768810017016882, 0.014448186092325628, 0.013180188432136409, 0.011966642663500726, 0.010809296015181769, 0.009709814802043925, 0.00866978202593996, 0.007690695096549859, 0.006773963675452826, 0.005920907646536588, 0.005132755215666017, 0.004410641142347165, 0.003755605105932696, 0.0031685902087211387, 0.0026504416181048532, 0.0022019053497220878, 0.0018236271933647955, 0.0015161517831887954, 0.0012799218135650205, 0.001115277401700664, 0.0010224555979481344, 0, 0, 0, 0, 0, 0, 0]
module.fire9.squeeze.0.bias
[0.1, 0.10096443801688548, 0.10085780265372767, 0.1006802455971259, 0.10043201941832214, 0.10011347721392355, 0.09972507210362987, 0.0992673565856801, 0.09874098175093504, 0.0981466963567141, 0.09748534576170345, 0.0967578707234508, 0.09596530606015719, 0.09510877917866958, 0.09418950847076785, 0.09320880158002763, 0.09216805354172448, 0.09106874479842503, 0.08991243909408791, 0.08870078124967046, 0.08743549482340479, 0.08611837965907199, 0.08475130932576139, 0.08333622845275736, 0.08187514996334437, 0.0803701522114652, 0.07882337602530542, 0.07723702166200963, 0.07561334567786104, 0.07395465771837696, 0.07226331723288566, 0.07054173011825858, 0.06879234529657174, 0.06701765123156474, 0.06522017238885247, 0.06340246564492512, 0.061567116650044024, 0.05971673615020781, 0.0578539562734201, 0.05598142678554187, 0.054101811321054294, 0.052217783594093785, 0.050332023595148837, 0.04844721377882912, 0.04656603524812909, 0.0446911639406145, 0.042825266821956566, 0.04097099809222835, 0.039130995410360137, 0.037307876142124025, 0.03550423363698534, 0.03372263353911658, 0.03196561013782161, 0.03023566276256162, 0.028535252227710497, 0.02686679733209737, 0.025232671418315252, 0.023635198996690268, 0.02207665243871372, 0.020559248744640796, 0.019085146389853303, 0.01765644225447326, 0.016275168640594185, 0.014943290381373413, 0.013662702046097548, 0.012435225245196808, 0.01126260603904189, 0.010146512454209142, 0.009088532110747293, 0.008090169963820731, 0.007152846162941911, 0.006277894031837993, 0.0054665581718255024, 0.004719992691390578, 0.0040392595644935855, 0.003425327119933096, 0.0028790686639181876, 0.0024012612378084153, 0.001992584512788558, 0.0016536198230503887, 0.0013848493388568242, 0.0011866553806646853, 0.0010593198752817602, 0.001003023954831738, 0, 0, 0, 0, 0, 0]
module.fire9.squeeze.1.weight
[0.1, 0.10096486427943537, 0.10085950649849584, 0.10068407473004344, 0.10043881553094194, 0.10012407359553877, 0.09974029127122162, 0.09928800793673068, 0.09876785924410021, 0.09818057622529491, 0.09752698426479636, 0.09680800193958408, 0.09602463972814086, 0.09517799859029719, 0.09426926841991058, 0.09329972637255445, 0.09227073507056682, 0.09118374068798174, 0.09004027091803447, 0.08884193282609745, 0.0875904105910643, 0.08628746313835621, 0.08493492166787756, 0.08353468708039469, 0.08208872730595523, 0.0805990745381025, 0.07906782237777205, 0.07749712289088467, 0.07588918358377084, 0.07424626430067775, 0.0725706740477191, 0.07086476774773114, 0.06913094293059656, 0.06737163636368666, 0.06558932062715837, 0.0637865006389187, 0.06196571013414113, 0.06012950810428089, 0.058280475200594865, 0.05642121010721982, 0.05455432588890679, 0.05268244631854462, 0.050808202189633916, 0.048934227618894016, 0.04706315634419943, 0.0451976180230487, 0.043340234536768045, 0.04149361630564363, 0.03966035862016186, 0.03784303799351309, 0.036044208540485866, 0.03426639838784046, 0.03251210612120642, 0.030783797273498555, 0.029083900859785752, 0.027414805963483224, 0.025778858378665906, 0.024178357313221724, 0.02261555215747861, 0.02109263932284657, 0.019611759154917658, 0.018174992925362666, 0.01678435990685196, 0.015441814535111353, 0.014149243662101962, 0.012908463904183931, 0.011721219088991496, 0.010589177804607431, 0.009513931054481145, 0.008496990021386645, 0.007539783943562744, 0.00664365810602035, 0.005809871949840211, 0.0050395973021180925, 0.004333916729045217, 0.003693822014438513, 0.00312021276585907, 0.0026138951502777613, 0.002175580761064893, 0.0018058856178964126, 0.0015053293009821213, 0.0012743342208326005, 0.0011132250245913734, 0.0010222281397664226, 0, 0, 0, 0, 0, 0]
module.fire9.squeeze.1.bias
[0.1, 0.10096528459342491, 0.1008611865800778, 0.10068785051215293, 0.1004455170869332, 0.10013452281255393, 0.09975529954072222, 0.09930837386704067, 0.09879436639976809, 0.09821399089803283, 0.09756805328069527, 0.09685745050723571, 0.09608316933222194, 0.09524628493508569, 0.0943479594271111, 0.093389440237708, 0.0923720583822112, 0.09129722661361094, 0.09016643746078107, 0.08898126115592925, 0.08774334345414692, 0.08645440334808703, 0.08511623068094293, 0.08373068366104286, 0.08229968628151185, 0.08082522564858341, 0.07930934922227162, 0.07775416197323473, 0.07616182345977877, 0.07453454482905975, 0.07287458574664869, 0.0711842512587234, 0.06946588859124367, 0.06772188389055532, 0.0659546589099485, 0.06416666764677167, 0.06236039293477096, 0.0605383429963869, 0.05870304795979599, 0.05685705634553337, 0.05500293152757603, 0.05314324817379981, 0.051280588670753795, 0.04941753953771637, 0.04755668783501243, 0.045700617571579366, 0.0438519061167703, 0.04201312062137695, 0.04018681445284242, 0.03837552364961355, 0.036581763399556724, 0.034808024547327114, 0.03305677013554122, 0.03133043198455594, 0.029631407315603178, 0.027962055421969424, 0.026324694392842924, 0.024721597894377126, 0.0231549920124409, 0.02162705216143969, 0.02013990006349945, 0.018695600802208952, 0.017296159955011065, 0.015943520808225302, 0.014639561658568917, 0.013386093204923365, 0.012184856033968544, 0.011037518203175788, 0.009945672924516091, 0.008910836352100077, 0.00793444547682175, 0.007017856130929578, 0.006162341105295754, 0.005369088381998127, 0.0046391994846689205, 0.003973687948901189, 0.0033734779148366805, 0.00283940284388992, 0.002372204361390106, 0.00197253122674808, 0.0016409384325784863, 0.0013778864340280076, 0.0011837405093798484, 0.0010587702528223656, 0.0010031492000862165, 0, 0, 0, 0, 0]
module.fire9.expand_1x1.0.weight
[0.1, 0.10096569905352569, 0.10086284327629991, 0.10069157379034299, 0.10045212558387383, 0.10014482718889689, 0.09977010023044414, 0.0993284588480893, 0.09882050899052909, 0.09824694758419854, 0.09760856157706155, 0.0969062268588886, 0.09614090705950265, 0.09531365222664269, 0.09442559738525844, 0.0934779609802131, 0.09247204320453095, 0.09140922421548323, 0.09029096224096014, 0.089118791578727, 0.08789432049130955, 0.08661922899939695, 0.08529526657678976, 0.08392424975005566, 0.08250805960618622, 0.08104863921167432, 0.07954799094655338, 0.07800817375705617, 0.07643130033066255, 0.07481953419741237, 0.07317508676146024, 0.0715002142669454, 0.06979721470233924, 0.06806842464751824, 0.06631621606788782, 0.06454299305995606, 0.06275118855282222, 0.060943260970105974, 0.05912169085689711, 0.05728897747635373, 0.055447635380618546, 0.05360019096075826, 0.05174917898045922, 0.04989713909823589, 0.048046612382922946, 0.04620013782723283, 0.04436024886416162, 0.042529469891022936, 0.040710312805879334, 0.03890527356112306, 0.03711682873893483, 0.035347432153319404, 0.03359951148337973, 0.0318754649424495, 0.030177657987653497, 0.028508420074410862, 0.02687004146033429, 0.02526477006290956, 0.023694808375267884, 0.022162310444281866, 0.020669378915131577, 0.019218062146395876, 0.01781035139962686, 0.016448178107263522, 0.015133411222633529, 0.013867854655678274, 0.01265324479792031, 0.011491248140068366, 0.010383458985528993, 0.009331397262961987, 0.008336506440880707, 0.007400151547158551, 0.006523617296159189, 0.005708106326059647, 0.004954737548785315, 0.004264544614820386, 0.0036384744950002483, 0.003077386181231672, 0.0025820495079233777, 0.002153144095744069, 0.0017912584191571925, 0.00149688899901163, 0.0012704397212963561, 0.0011122212829935243, 0.001022450765790477, 0, 0, 0, 0, 0]
module.fire9.expand_1x1.0.bias
[0.1, 0.10096610775271786, 0.10086447695824846, 0.10069524539643251, 0.10045864249278766, 0.10015498900747861, 0.09978469660046586, 0.09934826727342241, 0.09884629268917522, 0.0982794533695938, 0.09764851777301371, 0.09695434125244527, 0.0961978648959802, 0.09538011425096796, 0.09450219793369158, 0.09356530612642776, 0.09257070896392885, 0.09151975481151398, 0.09041386843710376, 0.08925454907967689, 0.08804336841676702, 0.08678196843375535, 0.08547205919784773, 0.0841154165397538, 0.08271387964621119, 0.08126934856661876, 0.07978378163715875, 0.07825919282590028, 0.07669764900248313, 0.07510126713608349, 0.07347221142546032, 0.07181269036497279, 0.07012495375054699, 0.06841128962965029, 0.06667402119940842, 0.0649155036570707, 0.06313812100709296, 0.0613442828291667, 0.05953642101157633, 0.05771698645431281, 0.055888445746413266, 0.05405327782203121, 0.05221397059977054, 0.050373017609839456, 0.04853291461359672, 0.046696156220073254, 0.04486523250405594, 0.043042625630318236, 0.041230806488574696, 0.03943223134372062, 0.03764933850589858, 0.035884545024906074, 0.03414024341342548, 0.03241879840351887, 0.030722543740784536, 0.029053779020521798, 0.02741476657019288, 0.02580772838240838, 0.024234843102594335, 0.0226982430754248, 0.02120001145402356, 0.019742179375854495, 0.01832672320912924, 0.01695556187346452, 0.01563055423842246, 0.014353496603459769, 0.013126120262702705, 0.011950089157849286, 0.01082699762238018, 0.00975836822013701, 0.00874564968119793, 0.0077902149378488985, 0.006893359263313258, 0.006056298515762914, 0.005280167489991715, 0.0045660183789856135, 0.003914819347475267, 0.003327453219404918, 0.0028047162810968633, 0.0023473172017341773, 0.0019558760726250336, 0.0016309235665512003, 0.0013729002183403053, 0.001182155827637237, 0.0010589489846842873, 0.0010034467197529919, 0, 0, 0, 0]
module.fire9.expand_1x1.1.weight
[0.1, 0.10096651078232374, 0.10086608799040298, 0.10069886614746724, 0.10046506925866446, 0.10016501051099069, 0.09979909185375457, 0.09936780346013871, 0.09887172307057886, 0.09831151521884107, 0.09768793034183298, 0.09700180377434203, 0.09625405463004708, 0.09544568457030256, 0.09457777646234422, 0.0936514929287141, 0.09266807478984768, 0.09162883940190973, 0.09053517889210522, 0.08938855829382919, 0.08819051358415396, 0.08694264962628225, 0.0856466380197227, 0.08430421486106743, 0.08291717841837139, 0.08148738672224874, 0.08001675507691322, 0.07850725349449653, 0.07696090405608169, 0.07537977820298658, 0.07376599396192593, 0.07212171310776898, 0.07044913826769356, 0.06875050997061564, 0.06702810364584688, 0.06528422657500081, 0.06352121480123045, 0.061741429999938084, 0.059947256315148835, 0.05814109716578585, 0.05632537202612558, 0.05450251318474571, 0.052674962486307486, 0.05084516806053716, 0.04901558104278779, 0.047188652290575166, 0.045366829100485784, 0.04355255192985484, 0.04174825112760607, 0.039956343678632246, 0.038179229966077935, 0.03641929055586137, 0.034678883007742745, 0.03296033871721108, 0.031265959792419626, 0.029598015970353914, 0.027958741576363133, 0.02635033253112772, 0.024774943409072776, 0.023234684552167702, 0.021731619242977913, 0.02026776094075627, 0.018845070584275998, 0.017465453965018418, 0.016130759174234476, 0.01484277412729933, 0.013603224168677003, 0.012413769760702915, 0.011276004259280409, 0.010191451779471204, 0.009161565153838373, 0.008187723986277429, 0.00727123280394209, 0.006413319309740478, 0.005615132737742789, 0.00487774231370327, 0.004202135822758828, 0.0035892182862230166, 0.0030398107492477836, 0.0025546491809770805, 0.00213438348866563, 0.001779576647083491, 0.0014907039443727002, 0.0012681523453661183, 0.0011122199732214945, 0.0010231157100649636, 0, 0, 0, 0]
module.fire9.expand_1x1.1.bias
[0.1, 0.10096690823204053, 0.10086767673076641, 0.10070243684601017, 0.10047140730096882, 0.10017489390268618, 0.09981328913726517, 0.09938707165034542, 0.09889680561353402, 0.0983431399776281, 0.09772680761361768, 0.0970486243426058, 0.09630948785593, 0.09551037652691458, 0.09465234811582646, 0.09373653836974893, 0.09276415951922652, 0.0917364986736708, 0.09065491611765147, 0.08952084351032745, 0.08833578199040155, 0.08710130018910718, 0.08581903215385711, 0.08449067518530268, 0.08311798759066673, 0.08170278635632376, 0.08024694474270828, 0.07875238980473487, 0.07722109984101187, 0.07565510177522565, 0.07405646847316091, 0.07242731599890903, 0.07076980081389594, 0.06908611692243731, 0.0673784929675993, 0.0656491892812089, 0.06390049489191897, 0.06213472449528801, 0.06035421538988544, 0.058561324383477845, 0.0567584246733917, 0.054947902705181385, 0.05313215501376121, 0.05131358505118229, 0.049494600005253395, 0.04767760761321698, 0.04586501297469792, 0.0440592153681435, 0.042262605074968866, 0.04047756021561139, 0.0387064436016824, 0.036951599608382624, 0.03521535107132127, 0.033499996211846704, 0.03180780559495805, 0.030141019123824764, 0.028501843074892497, 0.02689244717749949, 0.025314961741869386, 0.023771474839282006, 0.022264029538154526, 0.02079462119969156, 0.01936519483668411, 0.01797764253895295, 0.01663380096884483, 0.015335448930096206, 0.014084305013282943, 0.012882025320972205, 0.011730201275587986, 0.010630357512891903, 0.00958394986386743, 0.008592363427679044, 0.007656910738257094, 0.006778830026934989, 0.005959283583438673, 0.00519935621739776, 0.004500053822414778, 0.003862302044593246, 0.0032869450572870656, 0.0027747444436929496, 0.0023263781887650483, 0.0019424397817861196, 0.0016234374307831415, 0.0013697933898272222, 0.0011818434001082837, 0.0010598362455242196, 0.0010039334233729982, 0, 0, 0]
module.fire9.expand_3x3.0.weight
[0.1, 0.10096730018997241, 0.10086924353099268, 0.10070595828042561, 0.10047765801413816, 0.10018464134714383, 0.09982729154301641, 0.09940607601258426, 0.0989215457025604, 0.09837433437490845, 0.09776515777788677, 0.0970948127098552, 0.09636417597706887, 0.09557420324682217, 0.09472592779744339, 0.09382045916677435, 0.0928589817009034, 0.09184275300504972, 0.09077310229862529, 0.08965142867662593, 0.08847919927962575, 0.08725794737476836, 0.08598927035026516, 0.08467482762602366, 0.08331633848313885, 0.08191557981508657, 0.08047438380356048, 0.0789946355219921, 0.0774782704698893, 0.0759272720412175, 0.07434366893013555, 0.07272953247747911, 0.07108697396146259, 0.0694181418361433, 0.06772521892125988, 0.06601041954712068, 0.06427598665827645, 0.06252418887976605, 0.06075731754977203, 0.05897768372256776, 0.057187615145675955, 0.055389453215192654, 0.05358554991325886, 0.051778264731685876, 0.0499699615857578, 0.04816300572224838, 0.046359760625696245, 0.044562584926985, 0.04277382931827201, 0.04099583347830091, 0.03923092301211954, 0.03748140640920635, 0.03574957202398351, 0.03403768508266689, 0.03234798472036727, 0.030682681052318667, 0.029043952283064434, 0.027433941857382238, 0.02585475565667454, 0.024308459244491806, 0.02279707516479104, 0.021322580296463608, 0.019886903267592765, 0.018491921932822713, 0.017139460917139034, 0.015831289229272995, 0.014569117947851672, 0.01335459798332007, 0.01218931791856278, 0.01107480193104967, 0.010012507799223296, 0.009003824995735831, 0.008050072870029379, 0.007152498922636868, 0.006312277173460934, 0.0055305066261647435, 0.004808209830683568, 0.00414633154573723, 0.003545737503092893, 0.0030072132751944973, 0.0025314632476399358, 0.002119109697850068, 0.0017706919811346024, 0.0014866658252193957, 0.0012674027341581175, 0.0011131895024077067, 0.0010242278397034445, 0, 0, 0]
module.fire9.expand_3x3.0.bias
[0.1, 0.10096768674266186, 0.10087078873651144, 0.10070943122515706, 0.10048382276807022, 0.10019425497101622, 0.09984110210914475, 0.09942482064322802, 0.09894594862967139, 0.09840510502505909, 0.09780298888613413, 0.09714037846624629, 0.09641813020943611, 0.09563717764345492, 0.0947985301731521, 0.0939032717757886, 0.0929525595999635, 0.09194762246996452, 0.09088975929747525, 0.08978033740269258, 0.08862079074702377, 0.08741261807964802, 0.08615738100033778, 0.08485670194104356, 0.08351226206885169, 0.08212579911302477, 0.08069910511893408, 0.07923402413178658, 0.0777324498131406, 0.07619632299329099, 0.07462762916268709, 0.07302839590562622, 0.07140069027953956, 0.06974661614325776, 0.06806831143770971, 0.06636794542256909, 0.06464771587242055, 0.06290984623606946, 0.06115658276266705, 0.059390191598365165, 0.05761295585725393, 0.055827172670367436, 0.054035150216572396, 0.052239204739177064, 0.050441657552116465, 0.04864483203958389, 0.046851050652986524, 0.04506263190910645, 0.04328188739334768, 0.04151111877194186, 0.039752614816974945, 0.03800864844808006, 0.036281473794619865, 0.03457332328215618, 0.03288640474697226, 0.031222898582377534, 0.02958495492048323, 0.027974690853091413, 0.026394187695289745, 0.024845488295288744, 0.02333059439397845, 0.021851464037617764, 0.0204100090470004, 0.019008092546368444, 0.01764752655526799, 0.01633006964645886, 0.015057424672906106, 0.013831236566790944, 0.012653090213386082, 0.011524508402543522, 0.010446949860442489, 0.009421807364141683, 0.008450405941372785, 0.007534001157901876, 0.0066737774946727165, 0.005870846816829261, 0.005126246936596212, 0.004440940271875315, 0.003815812602291096, 0.0032516719242938023, 0.002749247406799559, 0.002309188448717436, 0.0019320638395816927, 0.001618361024374059, 0.0013684854734863797, 0.0011827601586377736, 0.0010614251354239537, 0.0010046372330381017, 0, 0]
module.fire9.expand_3x3.1.weight
[0.1, 0.10096806797512041, 0.10087231268665012, 0.1007128564409993, 0.10048990290860008, 0.10020373686376219, 0.09985472382093617, 0.09944330956784873, 0.09897001959610643, 0.09843545842999545, 0.09784030885433398, 0.09718533104236429, 0.09647136158479792, 0.09569931242125417, 0.09487016967545693, 0.09398499239567774, 0.09304491120203341, 0.09205112684236653, 0.091004908658553, 0.08990759296519583, 0.08876058134277585, 0.08756533884743965, 0.08632339213971114, 0.08503632753451716, 0.08370578897501747, 0.0823334759328275, 0.08092114123731545, 0.07947058883674679, 0.07798367149413521, 0.07646228842074393, 0.0749083828502589, 0.07332393955673368, 0.07171098231947498, 0.07007157133810803, 0.06840780060112261, 0.06672179521126145, 0.06501570867116675, 0.06329172013275233, 0.06155203161381423, 0.05979886518543523, 0.05803446013377567, 0.05626107009987588, 0.05448096020112317, 0.052696404138060586, 0.050909681290232295, 0.04912307380477549, 0.04733886368147724, 0.04555932985801939, 0.04378674529913497, 0.04202337409339338, 0.04027146856132318, 0.038533266378565835, 0.03681098771773516, 0.03510683241263307, 0.033422977148443604, 0.031761572681494335, 0.030124741092136222, 0.028514573074250683, 0.02693312526484598, 0.025382417617153992, 0.023864430820582167, 0.0223811037708167, 0.020934331093307935, 0.01952596072330116, 0.018157791545504214, 0.016831571096406046, 0.015548993332181738, 0.014311696465034395, 0.013121260870737794, 0.011979207070052546, 0.010886993786593736, 0.009846016083630994, 0.008857603582200752, 0.007923018762806478, 0.00704345535287636, 0.006220036802037986, 0.0054538148471574, 0.004745768168975672, 0.004096801142058558, 0.003507742679656028, 0.002979345174947167, 0.0025122835400226465, 0.0021071543438323176, 0.001764475050199076, 0.0014846833568721344, 0.0012681366364639837, 0.0011151114799851638, 0.0010258033435598325, 0, 0]
module.fire9.expand_3x3.1.bias
[0.1, 0.10096844397085858, 0.10087381571475333, 0.10071623467536453, 0.10049589975796702, 0.10021308907836379, 0.09986815961183673, 0.0994615467425577, 0.09899376371402882, 0.09846540098124529, 0.0978771254653988, 0.09722967971206226, 0.096523880953918, 0.09576062007921325, 0.09494086050724418, 0.0940656369722885, 0.09313605421752115, 0.09215328560056212, 0.091118571612416, 0.09003321831167335, 0.08889859567594965, 0.08771613587264315, 0.08648733145119439, 0.0852137334591286, 0.08389694948425988, 0.0825386416255276, 0.0811405243950267, 0.0797043625538799, 0.07823196888468364, 0.07672520190333927, 0.07518596351315768, 0.07361619660419869, 0.07201788260087527, 0.07039303896091811, 0.0687437166288573, 0.06707199744723578, 0.06537999152882204, 0.0636698345931388, 0.06194368527067007, 0.060203722378148694, 0.05845214216836434, 0.05669115555796275, 0.05492298533673573, 0.05314986336192445, 0.05137402774107719, 0.04959772000701804, 0.047823182288491806, 0.046052654480056826, 0.044288371414797856, 0.04253256004342773, 0.0407874366233385, 0.03905520392115018, 0.03733804843228796, 0.03563813762109772, 0.033957617184983295, 0.032298608346018845, 0.030663205173455128, 0.029053471940499006, 0.027471440518702806, 0.025919107813252525, 0.02439843324239176, 0.022911336264163397, 0.021459693953590715, 0.02004533863335589, 0.01867005556096702, 0.01733558067533251, 0.016043598405587507, 0.014795739544938225, 0.013593579192207467, 0.012438634763680196, 0.011332364077758138, 0.010276163514841414, 0.009271366254759737, 0.008319240593977918, 0.007420988344699868, 0.006577743317891787, 0.005790569892139241, 0.005060461670144711, 0.004388340224561398, 0.00377505393474623, 0.0032213769159005583, 0.0027280080419500355, 0.0022955700633972113, 0.00192460882126022, 0.0016155925580897392, 0.0013689113269340183, 0.001184876498997799, 0.0010637203706168265, 0.001005595870043812, 0]
module.conv10.weight
[0.1, 0.10096881481191539, 0.10087529814829976, 0.10071956666254292, 0.10050181461527177, 0.10022231363202834, 0.09988141236444192, 0.09947953605531844, 0.09901718600818935, 0.09849493896198187, 0.09791344637159054, 0.09727343359524737, 0.09657569898970464, 0.09582111291435864, 0.09501061664555681, 0.09414522120244251, 0.09322600608580217, 0.09225411793148793, 0.09123076908009534, 0.0901572360646807, 0.08903485801840401, 0.08786503500408432, 0.08664922626775068, 0.0853889484183678, 0.08408577353600658, 0.08274132721081952, 0.08135728651526748, 0.07993537791212675, 0.07847737510088647, 0.07698509680522246, 0.07546040450430773, 0.07390520011078931, 0.07232142359832806, 0.07071105058166098, 0.06907608985220452, 0.06741858087227305, 0.06574059123103819, 0.06404421406540262, 0.06233156544900521, 0.060604781752614995, 0.058866016979206084, 0.057117440077038256, 0.05536123223409445, 0.053599584157250635, 0.051834693339571386, 0.05006876131914063, 0.04830399093284645, 0.04654258356854574, 0.0447867364190365, 0.04303863974126292, 0.041300474124172454, 0.03957440776863278, 0.03786259378280162, 0.03616716749632356, 0.0344902437967037, 0.03283391449118107, 0.0312002456973926, 0.029591275266082375, 0.028009010239071288, 0.026455424345658042, 0.024932455540574328, 0.02344200358656545, 0.021985927684612112, 0.020566044154749004, 0.01918412417037363, 0.017841891548871208, 0.016541020601311913, 0.015283134043902698, 0.01406980097379884, 0.012902534911800372, 0.01178279191437482, 0.010711968757361395, 0.009691401193622412, 0.008722362286814977, 0.007806060823361893, 0.006943639804602369, 0.0061361750210035424, 0.005384673710211318, 0.004690073300614627, 0.004053240241990141, 0.003474968924686333, 0.002955980688694964, 0.002496922923846145, 0.002098368262249433, 0.0017608138639881746, 0.0014846807969583257, 0.0012703135116251365, 0.0011179794113531142, 0.0010278685188449923, 0]
module.conv10.bias
[0.1, 0.10096918057888697, 0.10087676030901657, 0.10072285312395748, 0.10050764875692363, 0.10023141250687553, 0.0998944849114659, 0.0994972813272326, 0.09904029141755682, 0.09852407854901746, 0.09794927909688562, 0.09731660166061618, 0.0966268261903026, 0.09588080302517263, 0.09507945184530969, 0.09422376053789266, 0.09331478397935136, 0.0923536427349394, 0.09134152167732722, 0.09027966852591844, 0.08916939230869043, 0.08801206174845483, 0.08680910357552774, 0.08556200076888965, 0.08427229072800335, 0.08294156337754338, 0.08157145920737377, 0.08016366725019008, 0.07871992299931901, 0.07724200626924248, 0.07573173900148343, 0.07419098301855863, 0.07262163772876683, 0.07102563778464238, 0.06940495069796025, 0.06776157441423314, 0.06609753484969041, 0.06441488339377564, 0.06271569438024108, 0.061002062529957046, 0.05927610036858865, 0.057539935622322916, 0.0557957085948573, 0.05404556952888289, 0.05229167595531491, 0.05053619003353855, 0.04878127588594914, 0.047029096930071894, 0.0452818132115511, 0.04354157874129575, 0.04181053884006482, 0.04009082749376549, 0.038384564722724716, 0.03669385396817735, 0.035020779499192356, 0.03336740384323424, 0.031735765243527, 0.03012787514635496, 0.028545715721398458, 0.026991237418160913, 0.025466356561499877, 0.023972952989226082, 0.02251286773468297, 0.02108790075716334, 0.019699808722961315, 0.018350302839794726, 0.01704104674726787, 0.015773654465975163, 0.014549688407773903, 0.013370657449679146, 0.012238015073755, 0.011153157575295593, 0.010117422341504662, 0.00913208620279548, 0.008198363858743906, 0.007317406380634905, 0.0064902997924484946, 0.005718063732034539, 0.0050016501941268325, 0.004341942356746003, 0.0037397534924381243, 0.0031958259656911397, 0.002710830317765122, 0.0022853644400645293, 0.0019199528370715249, 0.0016150459797490016, 0.0013710197502103997, 0.0011881749783409492, 0.0010667370709415472, 0.00100685573385249]
*** Model named parameters and requires_grad:
name:           module.stem.0.weight  req_grad:  True 
name:             module.stem.0.bias  req_grad:  True 
name:           module.stem.1.weight  req_grad:  True 
name:             module.stem.1.bias  req_grad:  True 
name:  module.fire2.squeeze.0.weight  req_grad:  True 
name:    module.fire2.squeeze.0.bias  req_grad:  True 
name:  module.fire2.squeeze.1.weight  req_grad:  True 
name:    module.fire2.squeeze.1.bias  req_grad:  True 
name: module.fire2.expand_1x1.0.weight  req_grad:  True 
name: module.fire2.expand_1x1.0.bias  req_grad:  True 
name: module.fire2.expand_1x1.1.weight  req_grad:  True 
name: module.fire2.expand_1x1.1.bias  req_grad:  True 
name: module.fire2.expand_3x3.0.weight  req_grad:  True 
name: module.fire2.expand_3x3.0.bias  req_grad:  True 
name: module.fire2.expand_3x3.1.weight  req_grad:  True 
name: module.fire2.expand_3x3.1.bias  req_grad:  True 
name:  module.fire3.squeeze.0.weight  req_grad:  True 
name:    module.fire3.squeeze.0.bias  req_grad:  True 
name:  module.fire3.squeeze.1.weight  req_grad:  True 
name:    module.fire3.squeeze.1.bias  req_grad:  True 
name: module.fire3.expand_1x1.0.weight  req_grad:  True 
name: module.fire3.expand_1x1.0.bias  req_grad:  True 
name: module.fire3.expand_1x1.1.weight  req_grad:  True 
name: module.fire3.expand_1x1.1.bias  req_grad:  True 
name: module.fire3.expand_3x3.0.weight  req_grad:  True 
name: module.fire3.expand_3x3.0.bias  req_grad:  True 
name: module.fire3.expand_3x3.1.weight  req_grad:  True 
name: module.fire3.expand_3x3.1.bias  req_grad:  True 
name:  module.fire4.squeeze.0.weight  req_grad:  True 
name:    module.fire4.squeeze.0.bias  req_grad:  True 
name:  module.fire4.squeeze.1.weight  req_grad:  True 
name:    module.fire4.squeeze.1.bias  req_grad:  True 
name: module.fire4.expand_1x1.0.weight  req_grad:  True 
name: module.fire4.expand_1x1.0.bias  req_grad:  True 
name: module.fire4.expand_1x1.1.weight  req_grad:  True 
name: module.fire4.expand_1x1.1.bias  req_grad:  True 
name: module.fire4.expand_3x3.0.weight  req_grad:  True 
name: module.fire4.expand_3x3.0.bias  req_grad:  True 
name: module.fire4.expand_3x3.1.weight  req_grad:  True 
name: module.fire4.expand_3x3.1.bias  req_grad:  True 
name:  module.fire5.squeeze.0.weight  req_grad:  True 
name:    module.fire5.squeeze.0.bias  req_grad:  True 
name:  module.fire5.squeeze.1.weight  req_grad:  True 
name:    module.fire5.squeeze.1.bias  req_grad:  True 
name: module.fire5.expand_1x1.0.weight  req_grad:  True 
name: module.fire5.expand_1x1.0.bias  req_grad:  True 
name: module.fire5.expand_1x1.1.weight  req_grad:  True 
name: module.fire5.expand_1x1.1.bias  req_grad:  True 
name: module.fire5.expand_3x3.0.weight  req_grad:  True 
name: module.fire5.expand_3x3.0.bias  req_grad:  True 
name: module.fire5.expand_3x3.1.weight  req_grad:  True 
name: module.fire5.expand_3x3.1.bias  req_grad:  True 
name:  module.fire6.squeeze.0.weight  req_grad:  True 
name:    module.fire6.squeeze.0.bias  req_grad:  True 
name:  module.fire6.squeeze.1.weight  req_grad:  True 
name:    module.fire6.squeeze.1.bias  req_grad:  True 
name: module.fire6.expand_1x1.0.weight  req_grad:  True 
name: module.fire6.expand_1x1.0.bias  req_grad:  True 
name: module.fire6.expand_1x1.1.weight  req_grad:  True 
name: module.fire6.expand_1x1.1.bias  req_grad:  True 
name: module.fire6.expand_3x3.0.weight  req_grad:  True 
name: module.fire6.expand_3x3.0.bias  req_grad:  True 
name: module.fire6.expand_3x3.1.weight  req_grad:  True 
name: module.fire6.expand_3x3.1.bias  req_grad:  True 
name:  module.fire7.squeeze.0.weight  req_grad:  True 
name:    module.fire7.squeeze.0.bias  req_grad:  True 
name:  module.fire7.squeeze.1.weight  req_grad:  True 
name:    module.fire7.squeeze.1.bias  req_grad:  True 
name: module.fire7.expand_1x1.0.weight  req_grad:  True 
name: module.fire7.expand_1x1.0.bias  req_grad:  True 
name: module.fire7.expand_1x1.1.weight  req_grad:  True 
name: module.fire7.expand_1x1.1.bias  req_grad:  True 
name: module.fire7.expand_3x3.0.weight  req_grad:  True 
name: module.fire7.expand_3x3.0.bias  req_grad:  True 
name: module.fire7.expand_3x3.1.weight  req_grad:  True 
name: module.fire7.expand_3x3.1.bias  req_grad:  True 
name:  module.fire8.squeeze.0.weight  req_grad:  True 
name:    module.fire8.squeeze.0.bias  req_grad:  True 
name:  module.fire8.squeeze.1.weight  req_grad:  True 
name:    module.fire8.squeeze.1.bias  req_grad:  True 
name: module.fire8.expand_1x1.0.weight  req_grad:  True 
name: module.fire8.expand_1x1.0.bias  req_grad:  True 
name: module.fire8.expand_1x1.1.weight  req_grad:  True 
name: module.fire8.expand_1x1.1.bias  req_grad:  True 
name: module.fire8.expand_3x3.0.weight  req_grad:  True 
name: module.fire8.expand_3x3.0.bias  req_grad:  True 
name: module.fire8.expand_3x3.1.weight  req_grad:  True 
name: module.fire8.expand_3x3.1.bias  req_grad:  True 
name:  module.fire9.squeeze.0.weight  req_grad:  True 
name:    module.fire9.squeeze.0.bias  req_grad:  True 
name:  module.fire9.squeeze.1.weight  req_grad:  True 
name:    module.fire9.squeeze.1.bias  req_grad:  True 
name: module.fire9.expand_1x1.0.weight  req_grad:  True 
name: module.fire9.expand_1x1.0.bias  req_grad:  True 
name: module.fire9.expand_1x1.1.weight  req_grad:  True 
name: module.fire9.expand_1x1.1.bias  req_grad:  True 
name: module.fire9.expand_3x3.0.weight  req_grad:  True 
name: module.fire9.expand_3x3.0.bias  req_grad:  True 
name: module.fire9.expand_3x3.1.weight  req_grad:  True 
name: module.fire9.expand_3x3.1.bias  req_grad:  True 
name:           module.conv10.weight  req_grad:  True 
name:             module.conv10.bias  req_grad:  True 


*** Optimizer groups, parameters and req_grads
#        requires_grad:                            True
#           param_name:            module.stem.0.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:              module.stem.0.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:            module.stem.1.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:              module.stem.1.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:   module.fire2.squeeze.0.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:     module.fire2.squeeze.0.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:   module.fire2.squeeze.1.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:     module.fire2.squeeze.1.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire2.expand_1x1.0.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire2.expand_1x1.0.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire2.expand_1x1.1.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire2.expand_1x1.1.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire2.expand_3x3.0.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire2.expand_3x3.0.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire2.expand_3x3.1.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire2.expand_3x3.1.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:   module.fire3.squeeze.0.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:     module.fire3.squeeze.0.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:   module.fire3.squeeze.1.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:     module.fire3.squeeze.1.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire3.expand_1x1.0.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire3.expand_1x1.0.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire3.expand_1x1.1.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire3.expand_1x1.1.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire3.expand_3x3.0.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire3.expand_3x3.0.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire3.expand_3x3.1.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire3.expand_3x3.1.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:   module.fire4.squeeze.0.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:     module.fire4.squeeze.0.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:   module.fire4.squeeze.1.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:     module.fire4.squeeze.1.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire4.expand_1x1.0.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire4.expand_1x1.0.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire4.expand_1x1.1.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire4.expand_1x1.1.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire4.expand_3x3.0.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire4.expand_3x3.0.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire4.expand_3x3.1.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire4.expand_3x3.1.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:   module.fire5.squeeze.0.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:     module.fire5.squeeze.0.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:   module.fire5.squeeze.1.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:     module.fire5.squeeze.1.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire5.expand_1x1.0.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire5.expand_1x1.0.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire5.expand_1x1.1.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire5.expand_1x1.1.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire5.expand_3x3.0.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire5.expand_3x3.0.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire5.expand_3x3.1.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire5.expand_3x3.1.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:   module.fire6.squeeze.0.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:     module.fire6.squeeze.0.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:   module.fire6.squeeze.1.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:     module.fire6.squeeze.1.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire6.expand_1x1.0.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire6.expand_1x1.0.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire6.expand_1x1.1.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire6.expand_1x1.1.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire6.expand_3x3.0.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire6.expand_3x3.0.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire6.expand_3x3.1.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire6.expand_3x3.1.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:   module.fire7.squeeze.0.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:     module.fire7.squeeze.0.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:   module.fire7.squeeze.1.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:     module.fire7.squeeze.1.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire7.expand_1x1.0.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire7.expand_1x1.0.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire7.expand_1x1.1.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire7.expand_1x1.1.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire7.expand_3x3.0.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire7.expand_3x3.0.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire7.expand_3x3.1.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire7.expand_3x3.1.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:   module.fire8.squeeze.0.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:     module.fire8.squeeze.0.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:   module.fire8.squeeze.1.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:     module.fire8.squeeze.1.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire8.expand_1x1.0.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire8.expand_1x1.0.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire8.expand_1x1.1.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire8.expand_1x1.1.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire8.expand_3x3.0.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire8.expand_3x3.0.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire8.expand_3x3.1.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire8.expand_3x3.1.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:   module.fire9.squeeze.0.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:     module.fire9.squeeze.0.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:   module.fire9.squeeze.1.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:     module.fire9.squeeze.1.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire9.expand_1x1.0.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire9.expand_1x1.0.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire9.expand_1x1.1.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire9.expand_1x1.1.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire9.expand_3x3.0.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire9.expand_3x3.0.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire9.expand_3x3.1.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire9.expand_3x3.1.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:            module.conv10.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:              module.conv10.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False



*** Optimizer group lrs
# group:  0,   name:           module.stem.0.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group:  1,   name:             module.stem.0.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group:  2,   name:           module.stem.1.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group:  3,   name:             module.stem.1.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group:  4,   name:  module.fire2.squeeze.0.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group:  5,   name:    module.fire2.squeeze.0.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group:  6,   name:  module.fire2.squeeze.1.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group:  7,   name:    module.fire2.squeeze.1.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group:  8,   name: module.fire2.expand_1x1.0.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group:  9,   name: module.fire2.expand_1x1.0.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 10,   name: module.fire2.expand_1x1.1.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 11,   name: module.fire2.expand_1x1.1.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 12,   name: module.fire2.expand_3x3.0.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 13,   name: module.fire2.expand_3x3.0.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 14,   name: module.fire2.expand_3x3.1.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 15,   name: module.fire2.expand_3x3.1.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 16,   name:  module.fire3.squeeze.0.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 17,   name:    module.fire3.squeeze.0.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 18,   name:  module.fire3.squeeze.1.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 19,   name:    module.fire3.squeeze.1.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 20,   name: module.fire3.expand_1x1.0.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 21,   name: module.fire3.expand_1x1.0.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 22,   name: module.fire3.expand_1x1.1.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 23,   name: module.fire3.expand_1x1.1.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 24,   name: module.fire3.expand_3x3.0.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 25,   name: module.fire3.expand_3x3.0.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 26,   name: module.fire3.expand_3x3.1.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 27,   name: module.fire3.expand_3x3.1.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 28,   name:  module.fire4.squeeze.0.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 29,   name:    module.fire4.squeeze.0.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 30,   name:  module.fire4.squeeze.1.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 31,   name:    module.fire4.squeeze.1.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 32,   name: module.fire4.expand_1x1.0.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 33,   name: module.fire4.expand_1x1.0.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 34,   name: module.fire4.expand_1x1.1.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 35,   name: module.fire4.expand_1x1.1.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 36,   name: module.fire4.expand_3x3.0.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 37,   name: module.fire4.expand_3x3.0.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 38,   name: module.fire4.expand_3x3.1.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 39,   name: module.fire4.expand_3x3.1.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 40,   name:  module.fire5.squeeze.0.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 41,   name:    module.fire5.squeeze.0.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 42,   name:  module.fire5.squeeze.1.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 43,   name:    module.fire5.squeeze.1.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 44,   name: module.fire5.expand_1x1.0.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 45,   name: module.fire5.expand_1x1.0.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 46,   name: module.fire5.expand_1x1.1.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 47,   name: module.fire5.expand_1x1.1.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 48,   name: module.fire5.expand_3x3.0.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 49,   name: module.fire5.expand_3x3.0.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 50,   name: module.fire5.expand_3x3.1.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 51,   name: module.fire5.expand_3x3.1.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 52,   name:  module.fire6.squeeze.0.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 53,   name:    module.fire6.squeeze.0.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 54,   name:  module.fire6.squeeze.1.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 55,   name:    module.fire6.squeeze.1.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 56,   name: module.fire6.expand_1x1.0.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 57,   name: module.fire6.expand_1x1.0.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 58,   name: module.fire6.expand_1x1.1.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 59,   name: module.fire6.expand_1x1.1.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 60,   name: module.fire6.expand_3x3.0.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 61,   name: module.fire6.expand_3x3.0.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 62,   name: module.fire6.expand_3x3.1.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 63,   name: module.fire6.expand_3x3.1.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 64,   name:  module.fire7.squeeze.0.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 65,   name:    module.fire7.squeeze.0.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 66,   name:  module.fire7.squeeze.1.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 67,   name:    module.fire7.squeeze.1.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 68,   name: module.fire7.expand_1x1.0.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 69,   name: module.fire7.expand_1x1.0.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 70,   name: module.fire7.expand_1x1.1.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 71,   name: module.fire7.expand_1x1.1.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 72,   name: module.fire7.expand_3x3.0.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 73,   name: module.fire7.expand_3x3.0.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 74,   name: module.fire7.expand_3x3.1.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 75,   name: module.fire7.expand_3x3.1.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 76,   name:  module.fire8.squeeze.0.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 77,   name:    module.fire8.squeeze.0.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 78,   name:  module.fire8.squeeze.1.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 79,   name:    module.fire8.squeeze.1.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 80,   name: module.fire8.expand_1x1.0.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 81,   name: module.fire8.expand_1x1.0.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 82,   name: module.fire8.expand_1x1.1.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 83,   name: module.fire8.expand_1x1.1.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 84,   name: module.fire8.expand_3x3.0.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 85,   name: module.fire8.expand_3x3.0.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 86,   name: module.fire8.expand_3x3.1.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 87,   name: module.fire8.expand_3x3.1.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 88,   name:  module.fire9.squeeze.0.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 89,   name:    module.fire9.squeeze.0.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 90,   name:  module.fire9.squeeze.1.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 91,   name:    module.fire9.squeeze.1.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 92,   name: module.fire9.expand_1x1.0.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 93,   name: module.fire9.expand_1x1.0.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 94,   name: module.fire9.expand_1x1.1.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 95,   name: module.fire9.expand_1x1.1.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 96,   name: module.fire9.expand_3x3.0.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 97,   name: module.fire9.expand_3x3.0.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 98,   name: module.fire9.expand_3x3.1.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 99,   name: module.fire9.expand_3x3.1.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 100,   name:           module.conv10.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 101,   name:             module.conv10.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
---------------
# Model: squeezenet
# Dataset: cifarcentum
# Freezeout: True
# Low precision: False
# Initial learning rate: 0.1
# Criterion: CrossEntropyLoss()
# Optimizer: SGD
#	param_name module.stem.0.weight
#	lr 0.1
#	momentum 0.9
#	weight_decay 0.0001
#	dampening 0
#	nesterov False
CIFAR100 loading and normalization
==> Preparing data..
# CIFAR100 / full precision
Files already downloaded and verified
Files already downloaded and verified
#--> Training data: <--#
#-->>
EPOCH 0
i:   0, name:           module.stem.0.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:   1, name:             module.stem.0.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:   2, name:           module.stem.1.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:   3, name:             module.stem.1.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i: 100, name:           module.conv10.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i: 101, name:             module.conv10.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006



# Switched to train mode...
Epoch: [0][  0/391]	Time  3.190 ( 3.190)	Data  0.126 ( 0.126)	Loss 4.6284e+00 (4.6284e+00)	Acc@1   0.78 (  0.78)	Acc@5   1.56 (  1.56)
Epoch: [0][ 10/391]	Time  0.043 ( 0.329)	Data  0.001 ( 0.012)	Loss 4.7467e+00 (4.5933e+00)	Acc@1   2.34 (  2.56)	Acc@5   6.25 (  9.02)
Epoch: [0][ 20/391]	Time  0.041 ( 0.192)	Data  0.001 ( 0.007)	Loss 4.6453e+00 (4.6126e+00)	Acc@1   1.56 (  2.27)	Acc@5   8.59 (  9.45)
Epoch: [0][ 30/391]	Time  0.039 ( 0.143)	Data  0.001 ( 0.005)	Loss 4.3082e+00 (4.5534e+00)	Acc@1   4.69 (  2.77)	Acc@5  16.41 ( 11.29)
Epoch: [0][ 40/391]	Time  0.043 ( 0.118)	Data  0.001 ( 0.004)	Loss 4.3258e+00 (4.5239e+00)	Acc@1   4.69 (  2.90)	Acc@5  14.84 ( 11.95)
Epoch: [0][ 50/391]	Time  0.040 ( 0.103)	Data  0.001 ( 0.003)	Loss 4.2826e+00 (4.4909e+00)	Acc@1   7.03 (  3.19)	Acc@5  17.97 ( 12.73)
Epoch: [0][ 60/391]	Time  0.041 ( 0.093)	Data  0.001 ( 0.003)	Loss 4.3455e+00 (4.4627e+00)	Acc@1   4.69 (  3.53)	Acc@5  18.75 ( 13.55)
Epoch: [0][ 70/391]	Time  0.041 ( 0.086)	Data  0.001 ( 0.003)	Loss 4.2473e+00 (4.4387e+00)	Acc@1   3.12 (  3.75)	Acc@5  21.09 ( 14.12)
Epoch: [0][ 80/391]	Time  0.041 ( 0.080)	Data  0.001 ( 0.003)	Loss 4.1805e+00 (4.4105e+00)	Acc@1   7.03 (  3.94)	Acc@5  23.44 ( 14.92)
Epoch: [0][ 90/391]	Time  0.042 ( 0.076)	Data  0.001 ( 0.002)	Loss 4.3222e+00 (4.3792e+00)	Acc@1   3.91 (  4.36)	Acc@5  17.97 ( 15.74)
Epoch: [0][100/391]	Time  0.040 ( 0.073)	Data  0.001 ( 0.002)	Loss 3.9786e+00 (4.3494e+00)	Acc@1   8.59 (  4.66)	Acc@5  31.25 ( 16.77)
Epoch: [0][110/391]	Time  0.037 ( 0.070)	Data  0.001 ( 0.002)	Loss 4.1309e+00 (4.3290e+00)	Acc@1   7.03 (  4.79)	Acc@5  23.44 ( 17.26)
Epoch: [0][120/391]	Time  0.042 ( 0.067)	Data  0.001 ( 0.002)	Loss 3.9617e+00 (4.3017e+00)	Acc@1   7.03 (  4.98)	Acc@5  18.75 ( 18.06)
Epoch: [0][130/391]	Time  0.040 ( 0.065)	Data  0.001 ( 0.002)	Loss 3.9920e+00 (4.2782e+00)	Acc@1   6.25 (  5.19)	Acc@5  25.00 ( 18.77)
Epoch: [0][140/391]	Time  0.041 ( 0.064)	Data  0.001 ( 0.002)	Loss 3.9346e+00 (4.2555e+00)	Acc@1   7.81 (  5.40)	Acc@5  28.12 ( 19.37)
Epoch: [0][150/391]	Time  0.044 ( 0.062)	Data  0.002 ( 0.002)	Loss 3.8458e+00 (4.2358e+00)	Acc@1   7.03 (  5.62)	Acc@5  32.81 ( 19.92)
Epoch: [0][160/391]	Time  0.045 ( 0.061)	Data  0.002 ( 0.002)	Loss 3.7571e+00 (4.2121e+00)	Acc@1  11.72 (  5.90)	Acc@5  28.12 ( 20.53)
Epoch: [0][170/391]	Time  0.039 ( 0.060)	Data  0.001 ( 0.002)	Loss 3.9229e+00 (4.1914e+00)	Acc@1   9.38 (  6.09)	Acc@5  30.47 ( 21.13)
Epoch: [0][180/391]	Time  0.043 ( 0.059)	Data  0.001 ( 0.002)	Loss 3.8530e+00 (4.1759e+00)	Acc@1   4.69 (  6.17)	Acc@5  32.03 ( 21.54)
Epoch: [0][190/391]	Time  0.041 ( 0.058)	Data  0.001 ( 0.002)	Loss 4.0011e+00 (4.1607e+00)	Acc@1   9.38 (  6.34)	Acc@5  27.34 ( 21.94)
Epoch: [0][200/391]	Time  0.040 ( 0.057)	Data  0.001 ( 0.002)	Loss 3.9831e+00 (4.1452e+00)	Acc@1   9.38 (  6.52)	Acc@5  23.44 ( 22.42)
Epoch: [0][210/391]	Time  0.040 ( 0.056)	Data  0.001 ( 0.002)	Loss 3.8138e+00 (4.1304e+00)	Acc@1  10.94 (  6.67)	Acc@5  32.03 ( 22.82)
Epoch: [0][220/391]	Time  0.041 ( 0.056)	Data  0.002 ( 0.002)	Loss 3.8264e+00 (4.1131e+00)	Acc@1  10.16 (  6.85)	Acc@5  28.91 ( 23.27)
Epoch: [0][230/391]	Time  0.042 ( 0.055)	Data  0.001 ( 0.002)	Loss 3.7510e+00 (4.1005e+00)	Acc@1  13.28 (  7.03)	Acc@5  32.03 ( 23.61)
Epoch: [0][240/391]	Time  0.041 ( 0.054)	Data  0.001 ( 0.002)	Loss 3.7600e+00 (4.0865e+00)	Acc@1  10.94 (  7.20)	Acc@5  30.47 ( 24.02)
Epoch: [0][250/391]	Time  0.040 ( 0.054)	Data  0.001 ( 0.002)	Loss 3.7784e+00 (4.0721e+00)	Acc@1  10.16 (  7.40)	Acc@5  31.25 ( 24.46)
Epoch: [0][260/391]	Time  0.042 ( 0.053)	Data  0.001 ( 0.001)	Loss 3.6421e+00 (4.0582e+00)	Acc@1  13.28 (  7.57)	Acc@5  35.16 ( 24.90)
Epoch: [0][270/391]	Time  0.042 ( 0.053)	Data  0.001 ( 0.001)	Loss 3.7284e+00 (4.0473e+00)	Acc@1   9.38 (  7.67)	Acc@5  33.59 ( 25.23)
Epoch: [0][280/391]	Time  0.041 ( 0.053)	Data  0.002 ( 0.001)	Loss 3.9771e+00 (4.0378e+00)	Acc@1   7.81 (  7.82)	Acc@5  23.44 ( 25.48)
Epoch: [0][290/391]	Time  0.039 ( 0.052)	Data  0.001 ( 0.001)	Loss 3.6505e+00 (4.0261e+00)	Acc@1  12.50 (  7.95)	Acc@5  35.16 ( 25.82)
Epoch: [0][300/391]	Time  0.044 ( 0.052)	Data  0.001 ( 0.001)	Loss 3.7228e+00 (4.0136e+00)	Acc@1  10.94 (  8.10)	Acc@5  35.16 ( 26.14)
Epoch: [0][310/391]	Time  0.043 ( 0.051)	Data  0.001 ( 0.001)	Loss 3.8078e+00 (4.0019e+00)	Acc@1  11.72 (  8.24)	Acc@5  31.25 ( 26.45)
Epoch: [0][320/391]	Time  0.041 ( 0.051)	Data  0.002 ( 0.001)	Loss 3.6095e+00 (3.9916e+00)	Acc@1  11.72 (  8.36)	Acc@5  35.16 ( 26.71)
Epoch: [0][330/391]	Time  0.040 ( 0.051)	Data  0.002 ( 0.001)	Loss 3.7442e+00 (3.9795e+00)	Acc@1  10.16 (  8.50)	Acc@5  39.06 ( 27.09)
Epoch: [0][340/391]	Time  0.040 ( 0.050)	Data  0.001 ( 0.001)	Loss 3.7243e+00 (3.9681e+00)	Acc@1  11.72 (  8.63)	Acc@5  35.94 ( 27.41)
Epoch: [0][350/391]	Time  0.041 ( 0.050)	Data  0.002 ( 0.001)	Loss 3.3818e+00 (3.9568e+00)	Acc@1  14.06 (  8.81)	Acc@5  50.78 ( 27.75)
Epoch: [0][360/391]	Time  0.042 ( 0.050)	Data  0.001 ( 0.001)	Loss 3.6617e+00 (3.9469e+00)	Acc@1  12.50 (  8.95)	Acc@5  35.94 ( 28.02)
Epoch: [0][370/391]	Time  0.039 ( 0.050)	Data  0.001 ( 0.001)	Loss 3.5215e+00 (3.9357e+00)	Acc@1  13.28 (  9.08)	Acc@5  39.84 ( 28.37)
Epoch: [0][380/391]	Time  0.040 ( 0.049)	Data  0.001 ( 0.001)	Loss 3.6445e+00 (3.9255e+00)	Acc@1  12.50 (  9.22)	Acc@5  35.16 ( 28.69)
Epoch: [0][390/391]	Time  0.239 ( 0.050)	Data  0.001 ( 0.001)	Loss 3.4628e+00 (3.9157e+00)	Acc@1  13.75 (  9.37)	Acc@5  50.00 ( 28.97)
## e[0] optimizer.zero_grad (sum) time: 0.2877316474914551
## e[0]       loss.backward (sum) time: 4.43546986579895
## e[0]      optimizer.step (sum) time: 1.8558883666992188
## epoch[0] training(only) time: 19.46439552307129
# Switched to evaluate mode...
Test: [  0/100]	Time  0.235 ( 0.235)	Loss 4.0594e+00 (4.0594e+00)	Acc@1  11.00 ( 11.00)	Acc@5  34.00 ( 34.00)
Test: [ 10/100]	Time  0.018 ( 0.043)	Loss 3.7322e+00 (3.7033e+00)	Acc@1  13.00 ( 12.91)	Acc@5  37.00 ( 37.45)
Test: [ 20/100]	Time  0.018 ( 0.032)	Loss 3.7218e+00 (3.7113e+00)	Acc@1  13.00 ( 12.43)	Acc@5  34.00 ( 36.14)
Test: [ 30/100]	Time  0.023 ( 0.028)	Loss 3.7896e+00 (3.7107e+00)	Acc@1  10.00 ( 12.48)	Acc@5  41.00 ( 36.48)
Test: [ 40/100]	Time  0.024 ( 0.027)	Loss 3.6281e+00 (3.6908e+00)	Acc@1  13.00 ( 12.61)	Acc@5  36.00 ( 36.85)
Test: [ 50/100]	Time  0.024 ( 0.026)	Loss 3.7122e+00 (3.6862e+00)	Acc@1  12.00 ( 12.57)	Acc@5  37.00 ( 36.96)
Test: [ 60/100]	Time  0.024 ( 0.026)	Loss 3.5807e+00 (3.6822e+00)	Acc@1  12.00 ( 12.44)	Acc@5  39.00 ( 37.07)
Test: [ 70/100]	Time  0.018 ( 0.025)	Loss 3.7785e+00 (3.6821e+00)	Acc@1   8.00 ( 12.28)	Acc@5  36.00 ( 37.00)
Test: [ 80/100]	Time  0.020 ( 0.024)	Loss 3.7807e+00 (3.6812e+00)	Acc@1  12.00 ( 12.28)	Acc@5  41.00 ( 37.07)
Test: [ 90/100]	Time  0.018 ( 0.024)	Loss 3.5932e+00 (3.6796e+00)	Acc@1  17.00 ( 12.48)	Acc@5  40.00 ( 37.09)
 * Acc@1 12.500 Acc@5 37.160
### epoch[0] execution time: 21.891945600509644
EPOCH 1
i:   0, name:           module.stem.0.weight  changing lr from: 0.100000000000000006   to: 0.100883842679128255
i:   1, name:             module.stem.0.bias  changing lr from: 0.100000000000000006   to: 0.100885535670130144
i:   2, name:           module.stem.1.weight  changing lr from: 0.100000000000000006   to: 0.100887199950799977
i:   3, name:             module.stem.1.bias  changing lr from: 0.100000000000000006   to: 0.100888836076004296
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.100000000000000006   to: 0.100890444588581554
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.100000000000000006   to: 0.100892026019630987
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.100000000000000006   to: 0.100893580888793813
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.100000000000000006   to: 0.100895109704526920
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.100000000000000006   to: 0.100896612964369636
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.100000000000000006   to: 0.100898091155203234
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.100000000000000006   to: 0.100899544753503961
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.100000000000000006   to: 0.100900974225589246
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.100000000000000006   to: 0.100902380027857633
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.100000000000000006   to: 0.100903762607022537
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.100000000000000006   to: 0.100905122400339831
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.100000000000000006   to: 0.100906459835829729
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.100000000000000006   to: 0.100907775332492816
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.100000000000000006   to: 0.100909069300520640
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.100000000000000006   to: 0.100910342141500867
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.100000000000000006   to: 0.100911594248617176
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.100000000000000006   to: 0.100912826006844161
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.100000000000000006   to: 0.100914037793137110
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.100000000000000006   to: 0.100915229976617143
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.100000000000000006   to: 0.100916402918751577
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.100000000000000006   to: 0.100917556973529735
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.100000000000000006   to: 0.100918692487634354
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.100000000000000006   to: 0.100919809800608648
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.100000000000000006   to: 0.100920909245019244
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.100000000000000006   to: 0.100921991146614987
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.100000000000000006   to: 0.100923055824481800
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.100000000000000006   to: 0.100924103591193637
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.100000000000000006   to: 0.100925134752959833
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.100000000000000006   to: 0.100926149609768590
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.100000000000000006   to: 0.100927148455527110
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.100000000000000006   to: 0.100928131578198091
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.100000000000000006   to: 0.100929099259933042
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.100000000000000006   to: 0.100930051777202115
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.100000000000000006   to: 0.100930989400921003
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.100000000000000006   to: 0.100931912396574466
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.100000000000000006   to: 0.100932821024337052
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.100000000000000006   to: 0.100933715539190769
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.100000000000000006   to: 0.100934596191039894
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.100000000000000006   to: 0.100935463224823108
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.100000000000000006   to: 0.100936316880622684
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.100000000000000006   to: 0.100937157393771376
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.100000000000000006   to: 0.100937984994956390
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.100000000000000006   to: 0.100938799910321120
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.100000000000000006   to: 0.100939602361564185
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.100000000000000006   to: 0.100940392566036430
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.100000000000000006   to: 0.100941170736835270
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.100000000000000006   to: 0.100941937082896976
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.100000000000000006   to: 0.100942691809086785
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.100000000000000006   to: 0.100943435116286728
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.100000000000000006   to: 0.100944167201481472
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.100000000000000006   to: 0.100944888257842202
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.100000000000000006   to: 0.100945598474808287
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.100000000000000006   to: 0.100946298038167376
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.100000000000000006   to: 0.100946987130133226
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.100000000000000006   to: 0.100947665929422017
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.100000000000000006   to: 0.100948334611326740
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.100000000000000006   to: 0.100948993347789839
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.100000000000000006   to: 0.100949642307474219
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.100000000000000006   to: 0.100950281655832530
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.100000000000000006   to: 0.100950911555174980
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.100000000000000006   to: 0.100951532164735389
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.100000000000000006   to: 0.100952143640735861
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.100000000000000006   to: 0.100952746136449986
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.100000000000000006   to: 0.100953339802264383
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.100000000000000006   to: 0.100953924785739085
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.100000000000000006   to: 0.100954501231666383
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.100000000000000006   to: 0.100955069282128412
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.100000000000000006   to: 0.100955629076553269
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.100000000000000006   to: 0.100956180751770125
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.100000000000000006   to: 0.100956724442062773
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.100000000000000006   to: 0.100957260279222208
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.100000000000000006   to: 0.100957788392597905
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.100000000000000006   to: 0.100958308909147920
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.100000000000000006   to: 0.100958821953487987
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.100000000000000006   to: 0.100959327647939245
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.100000000000000006   to: 0.100959826112575327
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.100000000000000006   to: 0.100960317465267901
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.100000000000000006   to: 0.100960801821731602
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.100000000000000006   to: 0.100961279295567641
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.100000000000000006   to: 0.100961749998306760
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.100000000000000006   to: 0.100962214039450923
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.100000000000000006   to: 0.100962671526514294
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.100000000000000006   to: 0.100963122565063235
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.100000000000000006   to: 0.100963567258755438
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.100000000000000006   to: 0.100964005709378121
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.100000000000000006   to: 0.100964438016885483
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.100000000000000006   to: 0.100964864279435365
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.100000000000000006   to: 0.100965284593424909
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.100000000000000006   to: 0.100965699053525690
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.100000000000000006   to: 0.100966107752717860
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.100000000000000006   to: 0.100966510782323743
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.100000000000000006   to: 0.100966908232040534
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.100000000000000006   to: 0.100967300189972409
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.100000000000000006   to: 0.100967686742661863
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.100000000000000006   to: 0.100968067975120410
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.100000000000000006   to: 0.100968443970858579
i: 100, name:           module.conv10.weight  changing lr from: 0.100000000000000006   to: 0.100968814811915386
i: 101, name:             module.conv10.bias  changing lr from: 0.100000000000000006   to: 0.100969180578886972



# Switched to train mode...
Epoch: [1][  0/391]	Time  0.208 ( 0.208)	Data  0.152 ( 0.152)	Loss 3.5660e+00 (3.5660e+00)	Acc@1  14.84 ( 14.84)	Acc@5  39.84 ( 39.84)
Epoch: [1][ 10/391]	Time  0.044 ( 0.058)	Data  0.001 ( 0.015)	Loss 3.9129e+00 (3.5661e+00)	Acc@1   6.25 ( 14.42)	Acc@5  29.69 ( 39.49)
Epoch: [1][ 20/391]	Time  0.045 ( 0.050)	Data  0.001 ( 0.008)	Loss 3.1932e+00 (3.5269e+00)	Acc@1  19.53 ( 14.21)	Acc@5  46.88 ( 40.51)
Epoch: [1][ 30/391]	Time  0.040 ( 0.047)	Data  0.001 ( 0.006)	Loss 3.3975e+00 (3.5145e+00)	Acc@1  15.62 ( 14.26)	Acc@5  43.75 ( 40.75)
Epoch: [1][ 40/391]	Time  0.055 ( 0.046)	Data  0.001 ( 0.005)	Loss 3.3909e+00 (3.4995e+00)	Acc@1  21.88 ( 14.58)	Acc@5  50.00 ( 41.54)
Epoch: [1][ 50/391]	Time  0.040 ( 0.045)	Data  0.001 ( 0.004)	Loss 3.6956e+00 (3.4879e+00)	Acc@1  13.28 ( 14.95)	Acc@5  38.28 ( 42.23)
Epoch: [1][ 60/391]	Time  0.040 ( 0.045)	Data  0.001 ( 0.004)	Loss 3.5297e+00 (3.4782e+00)	Acc@1  14.06 ( 15.19)	Acc@5  42.97 ( 42.62)
Epoch: [1][ 70/391]	Time  0.041 ( 0.044)	Data  0.001 ( 0.003)	Loss 3.4134e+00 (3.4710e+00)	Acc@1  17.19 ( 15.49)	Acc@5  44.53 ( 42.84)
Epoch: [1][ 80/391]	Time  0.040 ( 0.044)	Data  0.001 ( 0.003)	Loss 3.4949e+00 (3.4718e+00)	Acc@1  11.72 ( 15.36)	Acc@5  42.97 ( 42.96)
Epoch: [1][ 90/391]	Time  0.043 ( 0.044)	Data  0.001 ( 0.003)	Loss 3.4468e+00 (3.4615e+00)	Acc@1  13.28 ( 15.52)	Acc@5  42.97 ( 43.21)
Epoch: [1][100/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.003)	Loss 3.3872e+00 (3.4545e+00)	Acc@1  14.84 ( 15.67)	Acc@5  48.44 ( 43.48)
Epoch: [1][110/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 3.2830e+00 (3.4451e+00)	Acc@1  20.31 ( 15.95)	Acc@5  45.31 ( 43.61)
Epoch: [1][120/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 3.3372e+00 (3.4312e+00)	Acc@1  15.62 ( 16.12)	Acc@5  47.66 ( 43.90)
Epoch: [1][130/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 3.4476e+00 (3.4261e+00)	Acc@1  14.84 ( 16.31)	Acc@5  38.28 ( 43.94)
Epoch: [1][140/391]	Time  0.037 ( 0.043)	Data  0.002 ( 0.002)	Loss 3.4655e+00 (3.4201e+00)	Acc@1  17.97 ( 16.51)	Acc@5  43.75 ( 44.14)
Epoch: [1][150/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 3.3516e+00 (3.4141e+00)	Acc@1  20.31 ( 16.57)	Acc@5  46.09 ( 44.33)
Epoch: [1][160/391]	Time  0.043 ( 0.043)	Data  0.002 ( 0.002)	Loss 3.2547e+00 (3.4087e+00)	Acc@1  22.66 ( 16.74)	Acc@5  48.44 ( 44.53)
Epoch: [1][170/391]	Time  0.045 ( 0.043)	Data  0.001 ( 0.002)	Loss 3.3510e+00 (3.4043e+00)	Acc@1  14.84 ( 16.84)	Acc@5  43.75 ( 44.60)
Epoch: [1][180/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.002)	Loss 3.3571e+00 (3.3981e+00)	Acc@1  18.75 ( 16.94)	Acc@5  46.88 ( 44.81)
Epoch: [1][190/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 3.2195e+00 (3.3892e+00)	Acc@1  21.88 ( 17.15)	Acc@5  46.88 ( 44.96)
Epoch: [1][200/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 3.3837e+00 (3.3858e+00)	Acc@1  17.19 ( 17.17)	Acc@5  45.31 ( 45.02)
Epoch: [1][210/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 3.1722e+00 (3.3766e+00)	Acc@1  25.78 ( 17.44)	Acc@5  53.12 ( 45.19)
Epoch: [1][220/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 3.3680e+00 (3.3730e+00)	Acc@1  11.72 ( 17.46)	Acc@5  46.09 ( 45.25)
Epoch: [1][230/391]	Time  0.045 ( 0.042)	Data  0.001 ( 0.002)	Loss 3.1694e+00 (3.3672e+00)	Acc@1  20.31 ( 17.57)	Acc@5  50.78 ( 45.39)
Epoch: [1][240/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 3.1651e+00 (3.3624e+00)	Acc@1  15.62 ( 17.66)	Acc@5  54.69 ( 45.57)
Epoch: [1][250/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 3.1834e+00 (3.3549e+00)	Acc@1  24.22 ( 17.78)	Acc@5  53.12 ( 45.78)
Epoch: [1][260/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 3.1373e+00 (3.3491e+00)	Acc@1  21.09 ( 17.88)	Acc@5  50.00 ( 45.94)
Epoch: [1][270/391]	Time  0.047 ( 0.042)	Data  0.001 ( 0.002)	Loss 3.1948e+00 (3.3415e+00)	Acc@1  21.88 ( 18.06)	Acc@5  52.34 ( 46.15)
Epoch: [1][280/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 3.3792e+00 (3.3374e+00)	Acc@1  17.97 ( 18.10)	Acc@5  50.78 ( 46.29)
Epoch: [1][290/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 3.0818e+00 (3.3286e+00)	Acc@1  22.66 ( 18.26)	Acc@5  50.78 ( 46.49)
Epoch: [1][300/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.9680e+00 (3.3230e+00)	Acc@1  28.12 ( 18.37)	Acc@5  55.47 ( 46.64)
Epoch: [1][310/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.001)	Loss 3.0161e+00 (3.3183e+00)	Acc@1  22.66 ( 18.44)	Acc@5  53.91 ( 46.73)
Epoch: [1][320/391]	Time  0.045 ( 0.042)	Data  0.001 ( 0.001)	Loss 2.9817e+00 (3.3111e+00)	Acc@1  28.12 ( 18.55)	Acc@5  53.91 ( 46.97)
Epoch: [1][330/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 3.0120e+00 (3.3017e+00)	Acc@1  21.09 ( 18.73)	Acc@5  54.69 ( 47.21)
Epoch: [1][340/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.001)	Loss 2.9341e+00 (3.2955e+00)	Acc@1  19.53 ( 18.81)	Acc@5  59.38 ( 47.40)
Epoch: [1][350/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.001)	Loss 2.9625e+00 (3.2910e+00)	Acc@1  24.22 ( 18.87)	Acc@5  57.03 ( 47.59)
Epoch: [1][360/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 3.0055e+00 (3.2855e+00)	Acc@1  28.91 ( 19.00)	Acc@5  60.16 ( 47.74)
Epoch: [1][370/391]	Time  0.041 ( 0.042)	Data  0.002 ( 0.001)	Loss 2.8884e+00 (3.2790e+00)	Acc@1  27.34 ( 19.12)	Acc@5  55.47 ( 47.84)
Epoch: [1][380/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 3.0672e+00 (3.2702e+00)	Acc@1  21.09 ( 19.31)	Acc@5  59.38 ( 48.08)
Epoch: [1][390/391]	Time  0.029 ( 0.042)	Data  0.001 ( 0.001)	Loss 2.9681e+00 (3.2660e+00)	Acc@1  20.00 ( 19.37)	Acc@5  57.50 ( 48.21)
## e[1] optimizer.zero_grad (sum) time: 0.28640103340148926
## e[1]       loss.backward (sum) time: 4.158424139022827
## e[1]      optimizer.step (sum) time: 1.8554024696350098
## epoch[1] training(only) time: 16.495131731033325
# Switched to evaluate mode...
Test: [  0/100]	Time  0.162 ( 0.162)	Loss 3.4460e+00 (3.4460e+00)	Acc@1  26.00 ( 26.00)	Acc@5  50.00 ( 50.00)
Test: [ 10/100]	Time  0.018 ( 0.033)	Loss 3.3953e+00 (3.2197e+00)	Acc@1  16.00 ( 23.18)	Acc@5  45.00 ( 51.91)
Test: [ 20/100]	Time  0.024 ( 0.028)	Loss 2.9917e+00 (3.2022e+00)	Acc@1  24.00 ( 21.86)	Acc@5  59.00 ( 52.14)
Test: [ 30/100]	Time  0.020 ( 0.026)	Loss 3.0734e+00 (3.2067e+00)	Acc@1  27.00 ( 22.19)	Acc@5  55.00 ( 52.42)
Test: [ 40/100]	Time  0.018 ( 0.025)	Loss 3.4195e+00 (3.2013e+00)	Acc@1  21.00 ( 22.39)	Acc@5  50.00 ( 52.63)
Test: [ 50/100]	Time  0.020 ( 0.024)	Loss 3.2450e+00 (3.2071e+00)	Acc@1  23.00 ( 22.16)	Acc@5  49.00 ( 52.55)
Test: [ 60/100]	Time  0.019 ( 0.024)	Loss 3.0869e+00 (3.2001e+00)	Acc@1  19.00 ( 21.85)	Acc@5  50.00 ( 52.70)
Test: [ 70/100]	Time  0.019 ( 0.023)	Loss 3.3671e+00 (3.2094e+00)	Acc@1  21.00 ( 21.77)	Acc@5  46.00 ( 52.45)
Test: [ 80/100]	Time  0.024 ( 0.023)	Loss 3.6344e+00 (3.2150e+00)	Acc@1  16.00 ( 21.59)	Acc@5  49.00 ( 52.37)
Test: [ 90/100]	Time  0.017 ( 0.023)	Loss 3.0070e+00 (3.2115e+00)	Acc@1  28.00 ( 21.73)	Acc@5  57.00 ( 52.58)
 * Acc@1 21.860 Acc@5 52.680
### epoch[1] execution time: 18.86606192588806
EPOCH 2
i:   0, name:           module.stem.0.weight  changing lr from: 0.100883842679128255   to: 0.100535910417440644
i:   1, name:             module.stem.0.bias  changing lr from: 0.100885535670130144   to: 0.100542666763833027
i:   2, name:           module.stem.1.weight  changing lr from: 0.100887199950799977   to: 0.100549308757243938
i:   3, name:             module.stem.1.bias  changing lr from: 0.100888836076004296   to: 0.100555838600737121
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.100890444588581554   to: 0.100562258449853059
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.100892026019630987   to: 0.100568570413741440
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.100893580888793813   to: 0.100574776556264414
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.100895109704526920   to: 0.100580878897071055
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.100896612964369636   to: 0.100586879412643951
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.100898091155203234   to: 0.100592780037318849
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.100899544753503961   to: 0.100598582664277791
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.100900974225589246   to: 0.100604289146516868
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.100902380027857633   to: 0.100609901297788976
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.100903762607022537   to: 0.100615420893522406
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.100905122400339831   to: 0.100620849671715987
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.100906459835829729   to: 0.100626189333811400
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.100907775332492816   to: 0.100631441545543127
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.100909069300520640   to: 0.100636607937766881
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.100910342141500867   to: 0.100641690107267090
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.100911594248617176   to: 0.100646689617543833
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.100912826006844161   to: 0.100651607999579937
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.100914037793137110   to: 0.100656446752588766
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.100915229976617143   to: 0.100661207344743139
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.100916402918751577   to: 0.100665891213886027
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.100917556973529735   to: 0.100670499768223495
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.100918692487634354   to: 0.100675034387000081
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.100919809800608648   to: 0.100679496421157713
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.100920909245019244   to: 0.100683887193977917
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.100921991146614987   to: 0.100688208001708204
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.100923055824481800   to: 0.100692460114173002
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.100924103591193637   to: 0.100696644775369326
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.100925134752959833   to: 0.100700763204047888
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.100926149609768590   to: 0.100704816594279864
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.100927148455527110   to: 0.100708806116009714
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.100928131578198091   to: 0.100712732915594461
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.100929099259933042   to: 0.100716598116329811
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.100930051777202115   to: 0.100720402818963356
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.100930989400921003   to: 0.100724148102195404
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.100931912396574466   to: 0.100727835023167456
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.100932821024337052   to: 0.100731464617939054
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.100933715539190769   to: 0.100735037901952845
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.100934596191039894   to: 0.100738555870488633
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.100935463224823108   to: 0.100742019499106383
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.100936316880622684   to: 0.100745429744078463
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.100937157393771376   to: 0.100748787542811788
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.100937984994956390   to: 0.100752093814259605
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.100938799910321120   to: 0.100755349459323504
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.100939602361564185   to: 0.100758555361245880
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.100940392566036430   to: 0.100761712385993032
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.100941170736835270   to: 0.100764821382629211
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.100941937082896976   to: 0.100767883183681600
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.100942691809086785   to: 0.100770898605496970
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.100943435116286728   to: 0.100773868448589668
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.100944167201481472   to: 0.100776793497981521
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.100944888257842202   to: 0.100779674523533702
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.100945598474808287   to: 0.100782512280270867
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.100946298038167376   to: 0.100785307508697630
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.100946987130133226   to: 0.100788060935107712
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.100947665929422017   to: 0.100790773271885778
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.100948334611326740   to: 0.100793445217802424
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.100948993347789839   to: 0.100796077458302158
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.100949642307474219   to: 0.100798670665784712
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.100950281655832530   to: 0.100801225499879979
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.100950911555174980   to: 0.100803742607716504
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.100951532164735389   to: 0.100806222624183706
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.100952143640735861   to: 0.100808666172188310
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.100952746136449986   to: 0.100811073862904721
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.100953339802264383   to: 0.100813446296019585
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.100953924785739085   to: 0.100815784059971075
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.100954501231666383   to: 0.100818087732182329
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.100955069282128412   to: 0.100820357879289960
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.100955629076553269   to: 0.100822595057366987
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.100956180751770125   to: 0.100824799812141097
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.100956724442062773   to: 0.100826972679207649
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.100957260279222208   to: 0.100829114184238108
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.100957788392597905   to: 0.100831224843183589
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.100958308909147920   to: 0.100833305162473963
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.100958821953487987   to: 0.100835355639212476
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.100959327647939245   to: 0.100837376761365893
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.100959826112575327   to: 0.100839369007950527
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.100960317465267901   to: 0.100841332849214135
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.100960801821731602   to: 0.100843268746813541
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.100961279295567641   to: 0.100845177153988622
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.100961749998306760   to: 0.100847058515732196
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.100962214039450923   to: 0.100848913268956245
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.100962671526514294   to: 0.100850741842654482
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.100963122565063235   to: 0.100852544658061261
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.100963567258755438   to: 0.100854322128807128
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.100964005709378121   to: 0.100856074661070744
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.100964438016885483   to: 0.100857802653727666
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.100964864279435365   to: 0.100859506498495843
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.100965284593424909   to: 0.100861186580077797
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.100965699053525690   to: 0.100862843276299907
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.100966107752717860   to: 0.100864476958248461
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.100966510782323743   to: 0.100866087990402975
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.100966908232040534   to: 0.100867676730766409
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.100967300189972409   to: 0.100869243530992678
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.100967686742661863   to: 0.100870788736511438
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.100968067975120410   to: 0.100872312686650117
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.100968443970858579   to: 0.100873815714753332
i: 100, name:           module.conv10.weight  changing lr from: 0.100968814811915386   to: 0.100875298148299763
i: 101, name:             module.conv10.bias  changing lr from: 0.100969180578886972   to: 0.100876760309016572



# Switched to train mode...
Epoch: [2][  0/391]	Time  0.194 ( 0.194)	Data  0.150 ( 0.150)	Loss 2.8116e+00 (2.8116e+00)	Acc@1  33.59 ( 33.59)	Acc@5  63.28 ( 63.28)
Epoch: [2][ 10/391]	Time  0.047 ( 0.057)	Data  0.001 ( 0.014)	Loss 3.1793e+00 (3.0252e+00)	Acc@1  24.22 ( 25.00)	Acc@5  51.56 ( 56.25)
Epoch: [2][ 20/391]	Time  0.042 ( 0.049)	Data  0.001 ( 0.008)	Loss 3.1343e+00 (3.0061e+00)	Acc@1  22.66 ( 24.67)	Acc@5  52.34 ( 55.51)
Epoch: [2][ 30/391]	Time  0.040 ( 0.047)	Data  0.001 ( 0.006)	Loss 2.9702e+00 (2.9663e+00)	Acc@1  25.00 ( 25.53)	Acc@5  56.25 ( 56.78)
Epoch: [2][ 40/391]	Time  0.041 ( 0.046)	Data  0.001 ( 0.005)	Loss 2.7558e+00 (2.9611e+00)	Acc@1  24.22 ( 25.17)	Acc@5  64.06 ( 56.99)
Epoch: [2][ 50/391]	Time  0.043 ( 0.045)	Data  0.001 ( 0.004)	Loss 3.0578e+00 (2.9555e+00)	Acc@1  22.66 ( 25.23)	Acc@5  50.78 ( 56.89)
Epoch: [2][ 60/391]	Time  0.040 ( 0.044)	Data  0.001 ( 0.003)	Loss 2.8358e+00 (2.9374e+00)	Acc@1  24.22 ( 25.64)	Acc@5  57.81 ( 57.31)
Epoch: [2][ 70/391]	Time  0.041 ( 0.044)	Data  0.001 ( 0.003)	Loss 2.6695e+00 (2.9324e+00)	Acc@1  32.81 ( 25.77)	Acc@5  62.50 ( 57.19)
Epoch: [2][ 80/391]	Time  0.040 ( 0.044)	Data  0.001 ( 0.003)	Loss 2.8618e+00 (2.9262e+00)	Acc@1  21.09 ( 25.84)	Acc@5  64.06 ( 57.46)
Epoch: [2][ 90/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.003)	Loss 2.9046e+00 (2.9260e+00)	Acc@1  28.12 ( 25.77)	Acc@5  55.47 ( 57.25)
Epoch: [2][100/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.002)	Loss 3.0436e+00 (2.9233e+00)	Acc@1  22.66 ( 25.84)	Acc@5  53.91 ( 57.36)
Epoch: [2][110/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.002)	Loss 2.9835e+00 (2.9167e+00)	Acc@1  24.22 ( 26.18)	Acc@5  53.91 ( 57.36)
Epoch: [2][120/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 2.6230e+00 (2.9039e+00)	Acc@1  35.16 ( 26.43)	Acc@5  67.19 ( 57.64)
Epoch: [2][130/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.002)	Loss 2.9154e+00 (2.8951e+00)	Acc@1  26.56 ( 26.68)	Acc@5  55.47 ( 57.81)
Epoch: [2][140/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 2.7412e+00 (2.8896e+00)	Acc@1  29.69 ( 26.76)	Acc@5  65.62 ( 57.96)
Epoch: [2][150/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.7534e+00 (2.8825e+00)	Acc@1  23.44 ( 26.88)	Acc@5  60.16 ( 58.14)
Epoch: [2][160/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.5532e+00 (2.8749e+00)	Acc@1  35.94 ( 27.07)	Acc@5  64.84 ( 58.36)
Epoch: [2][170/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.9569e+00 (2.8748e+00)	Acc@1  23.44 ( 27.11)	Acc@5  55.47 ( 58.37)
Epoch: [2][180/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.9454e+00 (2.8693e+00)	Acc@1  23.44 ( 27.21)	Acc@5  54.69 ( 58.49)
Epoch: [2][190/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.7991e+00 (2.8668e+00)	Acc@1  25.78 ( 27.19)	Acc@5  62.50 ( 58.50)
Epoch: [2][200/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.7599e+00 (2.8656e+00)	Acc@1  31.25 ( 27.15)	Acc@5  60.16 ( 58.56)
Epoch: [2][210/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.6334e+00 (2.8639e+00)	Acc@1  30.47 ( 27.21)	Acc@5  59.38 ( 58.61)
Epoch: [2][220/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.7343e+00 (2.8613e+00)	Acc@1  29.69 ( 27.23)	Acc@5  60.94 ( 58.73)
Epoch: [2][230/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.8086e+00 (2.8571e+00)	Acc@1  28.91 ( 27.27)	Acc@5  62.50 ( 58.88)
Epoch: [2][240/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.7857e+00 (2.8552e+00)	Acc@1  27.34 ( 27.30)	Acc@5  57.81 ( 58.98)
Epoch: [2][250/391]	Time  0.050 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.9216e+00 (2.8513e+00)	Acc@1  25.78 ( 27.37)	Acc@5  53.91 ( 59.07)
Epoch: [2][260/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.5485e+00 (2.8477e+00)	Acc@1  39.84 ( 27.49)	Acc@5  66.41 ( 59.12)
Epoch: [2][270/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.3732e+00 (2.8438e+00)	Acc@1  40.62 ( 27.57)	Acc@5  71.09 ( 59.24)
Epoch: [2][280/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.7469e+00 (2.8419e+00)	Acc@1  31.25 ( 27.61)	Acc@5  54.69 ( 59.30)
Epoch: [2][290/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.7651e+00 (2.8356e+00)	Acc@1  35.16 ( 27.72)	Acc@5  61.72 ( 59.45)
Epoch: [2][300/391]	Time  0.045 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.5375e+00 (2.8314e+00)	Acc@1  30.47 ( 27.78)	Acc@5  70.31 ( 59.55)
Epoch: [2][310/391]	Time  0.045 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.4378e+00 (2.8287e+00)	Acc@1  38.28 ( 27.89)	Acc@5  75.78 ( 59.62)
Epoch: [2][320/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.7003e+00 (2.8241e+00)	Acc@1  35.94 ( 27.99)	Acc@5  60.16 ( 59.73)
Epoch: [2][330/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.5173e+00 (2.8208e+00)	Acc@1  30.47 ( 28.06)	Acc@5  65.62 ( 59.80)
Epoch: [2][340/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 2.8238e+00 (2.8184e+00)	Acc@1  28.12 ( 28.07)	Acc@5  60.16 ( 59.91)
Epoch: [2][350/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 2.5774e+00 (2.8150e+00)	Acc@1  30.47 ( 28.16)	Acc@5  64.84 ( 59.97)
Epoch: [2][360/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 2.5380e+00 (2.8110e+00)	Acc@1  36.72 ( 28.26)	Acc@5  67.19 ( 60.10)
Epoch: [2][370/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.001)	Loss 2.8296e+00 (2.8062e+00)	Acc@1  32.81 ( 28.38)	Acc@5  55.47 ( 60.24)
Epoch: [2][380/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.001)	Loss 2.4419e+00 (2.8012e+00)	Acc@1  34.38 ( 28.49)	Acc@5  67.19 ( 60.34)
Epoch: [2][390/391]	Time  0.028 ( 0.042)	Data  0.001 ( 0.001)	Loss 2.8948e+00 (2.7974e+00)	Acc@1  23.75 ( 28.50)	Acc@5  55.00 ( 60.45)
## e[2] optimizer.zero_grad (sum) time: 0.28974032402038574
## e[2]       loss.backward (sum) time: 4.091953992843628
## e[2]      optimizer.step (sum) time: 1.8848507404327393
## epoch[2] training(only) time: 16.407464027404785
# Switched to evaluate mode...
Test: [  0/100]	Time  0.152 ( 0.152)	Loss 2.6557e+00 (2.6557e+00)	Acc@1  32.00 ( 32.00)	Acc@5  66.00 ( 66.00)
Test: [ 10/100]	Time  0.024 ( 0.035)	Loss 2.5817e+00 (2.6575e+00)	Acc@1  31.00 ( 32.27)	Acc@5  66.00 ( 63.18)
Test: [ 20/100]	Time  0.025 ( 0.030)	Loss 2.4596e+00 (2.6654e+00)	Acc@1  39.00 ( 32.33)	Acc@5  71.00 ( 64.05)
Test: [ 30/100]	Time  0.024 ( 0.028)	Loss 3.0291e+00 (2.6743e+00)	Acc@1  25.00 ( 32.06)	Acc@5  55.00 ( 63.90)
Test: [ 40/100]	Time  0.021 ( 0.027)	Loss 2.8999e+00 (2.6781e+00)	Acc@1  24.00 ( 31.80)	Acc@5  62.00 ( 63.51)
Test: [ 50/100]	Time  0.024 ( 0.026)	Loss 2.7185e+00 (2.6938e+00)	Acc@1  33.00 ( 31.49)	Acc@5  62.00 ( 63.29)
Test: [ 60/100]	Time  0.024 ( 0.026)	Loss 2.6040e+00 (2.6881e+00)	Acc@1  33.00 ( 31.44)	Acc@5  68.00 ( 63.34)
Test: [ 70/100]	Time  0.024 ( 0.025)	Loss 2.8833e+00 (2.6894e+00)	Acc@1  31.00 ( 31.37)	Acc@5  59.00 ( 63.28)
Test: [ 80/100]	Time  0.024 ( 0.025)	Loss 2.9024e+00 (2.7064e+00)	Acc@1  26.00 ( 30.91)	Acc@5  58.00 ( 62.89)
Test: [ 90/100]	Time  0.024 ( 0.025)	Loss 2.7848e+00 (2.7009e+00)	Acc@1  27.00 ( 30.84)	Acc@5  64.00 ( 63.10)
 * Acc@1 30.720 Acc@5 63.100
### epoch[2] execution time: 18.93250560760498
EPOCH 3
i:   0, name:           module.stem.0.weight  changing lr from: 0.100535910417440644   to: 0.099957819810111703
i:   1, name:             module.stem.0.bias  changing lr from: 0.100542666763833027   to: 0.099972963131492384
i:   2, name:           module.stem.1.weight  changing lr from: 0.100549308757243938   to: 0.099987850985062104
i:   3, name:             module.stem.1.bias  changing lr from: 0.100555838600737121   to: 0.100002488266439718
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.100562258449853059   to: 0.100016879766512509
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.100568570413741440   to: 0.100031030173900956
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.100574776556264414   to: 0.100044944077360476
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.100580878897071055   to: 0.100058625968122025
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.100586879412643951   to: 0.100072080242172914
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.100592780037318849   to: 0.100085311202479932
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.100598582664277791   to: 0.100098323061155847
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.100604289146516868   to: 0.100111119941571347
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.100609901297788976   to: 0.100123705880413291
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.100615420893522406   to: 0.100136084829691371
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.100620849671715987   to: 0.100148260658694144
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.100626189333811400   to: 0.100160237155895893
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.100631441545543127   to: 0.100172018030815824
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.100636607937766881   to: 0.100183606915830559
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.100641690107267090   to: 0.100195007367941499
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.100646689617543833   to: 0.100206222870498129
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.100651607999579937   to: 0.100217256834878435
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.100656446752588766   to: 0.100228112602127523
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.100661207344743139   to: 0.100238793444555718
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.100665891213886027   to: 0.100249302567297194
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.100670499768223495   to: 0.100259643109829918
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.100675034387000081   to: 0.100269818147458403
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.100679496421157713   to: 0.100279830692759794
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.100683887193977917   to: 0.100289683696994564
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.100688208001708204   to: 0.100299380051482645
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.100692460114173002   to: 0.100308922588945942
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.100696644775369326   to: 0.100318314084817950
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.100700763204047888   to: 0.100327557258521688
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.100704816594279864   to: 0.100336654774716413
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.100708806116009714   to: 0.100345609244514133
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.100712732915594461   to: 0.100354423226666697
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.100716598116329811   to: 0.100363099228724190
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.100720402818963356   to: 0.100371639708165344
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.100724148102195404   to: 0.100380047073500789
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.100727835023167456   to: 0.100388323685349737
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.100731464617939054   to: 0.100396471857490996
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.100735037901952845   to: 0.100404493857888605
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.100738555870488633   to: 0.100412391909693186
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.100742019499106383   to: 0.100420168192219272
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.100745429744078463   to: 0.100427824841899493
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.100748787542811788   to: 0.100435363953216006
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.100752093814259605   to: 0.100442787579609949
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.100755349459323504   to: 0.100450097734369262
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.100758555361245880   to: 0.100457296391495657
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.100761712385993032   to: 0.100464385486551150
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.100764821382629211   to: 0.100471366917484539
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.100767883183681600   to: 0.100478242545438717
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.100770898605496970   to: 0.100485014195538902
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.100773868448589668   to: 0.100491683657662423
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.100776793497981521   to: 0.100498252687190703
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.100779674523533702   to: 0.100504723005743590
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.100782512280270867   to: 0.100511096301896571
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.100785307508697630   to: 0.100517374231881576
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.100788060935107712   to: 0.100523558420271289
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.100790773271885778   to: 0.100529650460647796
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.100793445217802424   to: 0.100535651916255783
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.100796077458302158   to: 0.100541564320640639
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.100798670665784712   to: 0.100547389178271981
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.100801225499879979   to: 0.100553127965152839
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.100803742607716504   to: 0.100558782129414867
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.100806222624183706   to: 0.100564353091899927
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.100808666172188310   to: 0.100569842246728630
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.100811073862904721   to: 0.100575250961855545
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.100813446296019585   to: 0.100580580579612194
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.100815784059971075   to: 0.100585832417237495
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.100818087732182329   to: 0.100591007767396268
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.100820357879289960   to: 0.100596107898686060
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.100822595057366987   to: 0.100601134056132385
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.100824799812141097   to: 0.100606087461673169
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.100826972679207649   to: 0.100610969314631898
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.100829114184238108   to: 0.100615780792180434
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.100831224843183589   to: 0.100620523049791410
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.100833305162473963   to: 0.100625197221680493
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.100835355639212476   to: 0.100629804421238769
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.100837376761365893   to: 0.100634345741455605
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.100839369007950527   to: 0.100638822255332036
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.100841332849214135   to: 0.100643235016285026
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.100843268746813541   to: 0.100647585058542766
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.100845177153988622   to: 0.100651873397531288
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.100847058515732196   to: 0.100656101030252451
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.100848913268956245   to: 0.100660268935653760
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.100850741842654482   to: 0.100664378074990013
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.100852544658061261   to: 0.100668429392176906
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.100854322128807128   to: 0.100672423814137130
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.100856074661070744   to: 0.100676362251138671
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.100857802653727666   to: 0.100680245597125906
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.100859506498495843   to: 0.100684074730043441
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.100861186580077797   to: 0.100687850512152927
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.100862843276299907   to: 0.100691573790342992
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.100864476958248461   to: 0.100695245396432514
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.100866087990402975   to: 0.100698866147467245
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.100867676730766409   to: 0.100702436846010171
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.100869243530992678   to: 0.100705958280425611
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.100870788736511438   to: 0.100709431225157062
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.100872312686650117   to: 0.100712856440999296
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.100873815714753332   to: 0.100716234675364530
i: 100, name:           module.conv10.weight  changing lr from: 0.100875298148299763   to: 0.100719566662542920
i: 101, name:             module.conv10.bias  changing lr from: 0.100876760309016572   to: 0.100722853123957484



# Switched to train mode...
Epoch: [3][  0/391]	Time  0.206 ( 0.206)	Data  0.159 ( 0.159)	Loss 2.6868e+00 (2.6868e+00)	Acc@1  25.00 ( 25.00)	Acc@5  65.62 ( 65.62)
Epoch: [3][ 10/391]	Time  0.042 ( 0.057)	Data  0.001 ( 0.015)	Loss 2.5266e+00 (2.6715e+00)	Acc@1  31.25 ( 31.11)	Acc@5  66.41 ( 63.92)
Epoch: [3][ 20/391]	Time  0.040 ( 0.050)	Data  0.001 ( 0.008)	Loss 2.4599e+00 (2.6837e+00)	Acc@1  28.91 ( 30.21)	Acc@5  71.88 ( 63.73)
Epoch: [3][ 30/391]	Time  0.041 ( 0.047)	Data  0.001 ( 0.006)	Loss 2.4395e+00 (2.6293e+00)	Acc@1  37.50 ( 31.53)	Acc@5  67.19 ( 65.30)
Epoch: [3][ 40/391]	Time  0.046 ( 0.046)	Data  0.001 ( 0.005)	Loss 2.3973e+00 (2.5934e+00)	Acc@1  41.41 ( 32.07)	Acc@5  72.66 ( 65.93)
Epoch: [3][ 50/391]	Time  0.040 ( 0.045)	Data  0.001 ( 0.004)	Loss 2.3166e+00 (2.5877e+00)	Acc@1  39.06 ( 31.97)	Acc@5  73.44 ( 65.75)
Epoch: [3][ 60/391]	Time  0.040 ( 0.044)	Data  0.001 ( 0.004)	Loss 2.6469e+00 (2.5839e+00)	Acc@1  30.47 ( 32.18)	Acc@5  63.28 ( 65.93)
Epoch: [3][ 70/391]	Time  0.039 ( 0.044)	Data  0.001 ( 0.003)	Loss 2.6316e+00 (2.5822e+00)	Acc@1  28.91 ( 32.22)	Acc@5  65.62 ( 65.97)
Epoch: [3][ 80/391]	Time  0.040 ( 0.044)	Data  0.001 ( 0.003)	Loss 2.4647e+00 (2.5824e+00)	Acc@1  37.50 ( 32.33)	Acc@5  70.31 ( 66.00)
Epoch: [3][ 90/391]	Time  0.039 ( 0.043)	Data  0.001 ( 0.003)	Loss 2.6986e+00 (2.5815e+00)	Acc@1  35.16 ( 32.36)	Acc@5  63.28 ( 66.05)
Epoch: [3][100/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.003)	Loss 2.5150e+00 (2.5814e+00)	Acc@1  32.81 ( 32.37)	Acc@5  64.84 ( 65.99)
Epoch: [3][110/391]	Time  0.044 ( 0.043)	Data  0.001 ( 0.002)	Loss 2.3378e+00 (2.5753e+00)	Acc@1  35.94 ( 32.57)	Acc@5  72.66 ( 66.10)
Epoch: [3][120/391]	Time  0.039 ( 0.043)	Data  0.001 ( 0.002)	Loss 2.6718e+00 (2.5716e+00)	Acc@1  32.03 ( 32.66)	Acc@5  62.50 ( 66.15)
Epoch: [3][130/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.002)	Loss 2.3409e+00 (2.5693e+00)	Acc@1  34.38 ( 32.57)	Acc@5  73.44 ( 66.23)
Epoch: [3][140/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.3483e+00 (2.5624e+00)	Acc@1  35.16 ( 32.67)	Acc@5  69.53 ( 66.30)
Epoch: [3][150/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.3986e+00 (2.5595e+00)	Acc@1  40.62 ( 32.84)	Acc@5  68.75 ( 66.39)
Epoch: [3][160/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.7597e+00 (2.5605e+00)	Acc@1  27.34 ( 32.85)	Acc@5  59.38 ( 66.31)
Epoch: [3][170/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.3941e+00 (2.5550e+00)	Acc@1  37.50 ( 33.00)	Acc@5  68.75 ( 66.41)
Epoch: [3][180/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.3145e+00 (2.5503e+00)	Acc@1  40.62 ( 33.09)	Acc@5  69.53 ( 66.43)
Epoch: [3][190/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.3834e+00 (2.5480e+00)	Acc@1  38.28 ( 33.11)	Acc@5  68.75 ( 66.48)
Epoch: [3][200/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.5672e+00 (2.5497e+00)	Acc@1  27.34 ( 33.08)	Acc@5  63.28 ( 66.46)
Epoch: [3][210/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.7538e+00 (2.5500e+00)	Acc@1  27.34 ( 33.11)	Acc@5  57.81 ( 66.38)
Epoch: [3][220/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.2088e+00 (2.5406e+00)	Acc@1  35.94 ( 33.39)	Acc@5  76.56 ( 66.59)
Epoch: [3][230/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.6921e+00 (2.5402e+00)	Acc@1  32.03 ( 33.36)	Acc@5  60.94 ( 66.59)
Epoch: [3][240/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.3522e+00 (2.5370e+00)	Acc@1  31.25 ( 33.38)	Acc@5  74.22 ( 66.62)
Epoch: [3][250/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.3341e+00 (2.5323e+00)	Acc@1  34.38 ( 33.51)	Acc@5  71.09 ( 66.71)
Epoch: [3][260/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.5406e+00 (2.5295e+00)	Acc@1  29.69 ( 33.54)	Acc@5  62.50 ( 66.79)
Epoch: [3][270/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.6434e+00 (2.5244e+00)	Acc@1  28.91 ( 33.71)	Acc@5  65.62 ( 66.94)
Epoch: [3][280/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.5778e+00 (2.5260e+00)	Acc@1  31.25 ( 33.67)	Acc@5  64.84 ( 66.93)
Epoch: [3][290/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.4434e+00 (2.5237e+00)	Acc@1  39.84 ( 33.74)	Acc@5  68.75 ( 66.97)
Epoch: [3][300/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.5820e+00 (2.5227e+00)	Acc@1  33.59 ( 33.77)	Acc@5  67.97 ( 66.99)
Epoch: [3][310/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.2749e+00 (2.5201e+00)	Acc@1  37.50 ( 33.82)	Acc@5  75.00 ( 67.03)
Epoch: [3][320/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.4352e+00 (2.5166e+00)	Acc@1  29.69 ( 33.87)	Acc@5  64.84 ( 67.14)
Epoch: [3][330/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.5556e+00 (2.5137e+00)	Acc@1  32.81 ( 33.94)	Acc@5  64.06 ( 67.20)
Epoch: [3][340/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.2978e+00 (2.5097e+00)	Acc@1  40.62 ( 34.02)	Acc@5  72.66 ( 67.28)
Epoch: [3][350/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.3561e+00 (2.5081e+00)	Acc@1  36.72 ( 34.06)	Acc@5  68.75 ( 67.30)
Epoch: [3][360/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.001)	Loss 2.4784e+00 (2.5053e+00)	Acc@1  35.94 ( 34.08)	Acc@5  67.97 ( 67.38)
Epoch: [3][370/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 2.3084e+00 (2.5015e+00)	Acc@1  37.50 ( 34.15)	Acc@5  75.78 ( 67.48)
Epoch: [3][380/391]	Time  0.046 ( 0.042)	Data  0.001 ( 0.001)	Loss 2.5288e+00 (2.4994e+00)	Acc@1  31.25 ( 34.16)	Acc@5  67.19 ( 67.52)
Epoch: [3][390/391]	Time  0.029 ( 0.042)	Data  0.001 ( 0.001)	Loss 2.5592e+00 (2.4976e+00)	Acc@1  26.25 ( 34.20)	Acc@5  68.75 ( 67.59)
## e[3] optimizer.zero_grad (sum) time: 0.28513097763061523
## e[3]       loss.backward (sum) time: 4.104995489120483
## e[3]      optimizer.step (sum) time: 1.8929436206817627
## epoch[3] training(only) time: 16.356558561325073
# Switched to evaluate mode...
Test: [  0/100]	Time  0.156 ( 0.156)	Loss 2.5674e+00 (2.5674e+00)	Acc@1  36.00 ( 36.00)	Acc@5  62.00 ( 62.00)
Test: [ 10/100]	Time  0.025 ( 0.034)	Loss 2.9746e+00 (2.7006e+00)	Acc@1  22.00 ( 31.09)	Acc@5  57.00 ( 64.09)
Test: [ 20/100]	Time  0.022 ( 0.029)	Loss 2.3437e+00 (2.6839e+00)	Acc@1  39.00 ( 32.38)	Acc@5  70.00 ( 64.95)
Test: [ 30/100]	Time  0.024 ( 0.027)	Loss 2.7367e+00 (2.6804e+00)	Acc@1  32.00 ( 32.32)	Acc@5  60.00 ( 65.16)
Test: [ 40/100]	Time  0.021 ( 0.026)	Loss 2.6715e+00 (2.6684e+00)	Acc@1  29.00 ( 32.39)	Acc@5  58.00 ( 65.37)
Test: [ 50/100]	Time  0.024 ( 0.026)	Loss 2.6071e+00 (2.6716e+00)	Acc@1  34.00 ( 32.57)	Acc@5  68.00 ( 65.39)
Test: [ 60/100]	Time  0.018 ( 0.025)	Loss 2.5017e+00 (2.6653e+00)	Acc@1  33.00 ( 32.64)	Acc@5  67.00 ( 65.41)
Test: [ 70/100]	Time  0.021 ( 0.024)	Loss 2.9295e+00 (2.6661e+00)	Acc@1  30.00 ( 32.63)	Acc@5  59.00 ( 65.27)
Test: [ 80/100]	Time  0.024 ( 0.024)	Loss 3.0064e+00 (2.6774e+00)	Acc@1  27.00 ( 32.54)	Acc@5  65.00 ( 65.06)
Test: [ 90/100]	Time  0.019 ( 0.024)	Loss 2.7161e+00 (2.6764e+00)	Acc@1  35.00 ( 32.69)	Acc@5  68.00 ( 65.07)
 * Acc@1 32.510 Acc@5 64.950
### epoch[3] execution time: 18.756019115447998
EPOCH 4
i:   0, name:           module.stem.0.weight  changing lr from: 0.099957819810111703   to: 0.099152256835388142
i:   1, name:             module.stem.0.bias  changing lr from: 0.099972963131492384   to: 0.099179033202888206
i:   2, name:           module.stem.1.weight  changing lr from: 0.099987850985062104   to: 0.099205359932827558
i:   3, name:             module.stem.1.bias  changing lr from: 0.100002488266439718   to: 0.099231245576892280
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.100016879766512509   to: 0.099256698506001217
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.100031030173900956   to: 0.099281726914481699
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.100044944077360476   to: 0.099306338824141735
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.100058625968122025   to: 0.099330542088240992
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.100072080242172914   to: 0.099354344395363711
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.100085311202479932   to: 0.099377753273195632
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.100098323061155847   to: 0.099400776092207904
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.100111119941571347   to: 0.099423420069250062
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.100123705880413291   to: 0.099445692271054556
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.100136084829691371   to: 0.099467599617655153
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.100148260658694144   to: 0.099489148885721482
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.100160237155895893   to: 0.099510346711811873
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.100172018030815824   to: 0.099531199595546543
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.100183606915830559   to: 0.099551713902703232
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.100195007367941499   to: 0.099571895868237545
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.100206222870498129   to: 0.099591751599229353
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.100217256834878435   to: 0.099611287077758015
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.100228112602127523   to: 0.099630508163707304
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.100238793444555718   to: 0.099649420597502758
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.100249302567297194   to: 0.099668030002782473
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.100259643109829918   to: 0.099686341889003563
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.100269818147458403   to: 0.099704361653985607
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.100279830692759794   to: 0.099722094586392876
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.100289683696994564   to: 0.099739545868156879
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.100299380051482645   to: 0.099756720576840763
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.100308922588945942   to: 0.099773623687946955
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.100318314084817950   to: 0.099790260077169693
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.100327557258521688   to: 0.099806634522593585
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.100336654774716413   to: 0.099822751706839949
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.100345609244514133   to: 0.099838616219161777
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.100354423226666697   to: 0.099854232557489153
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.100363099228724190   to: 0.099869605130425934
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.100371639708165344   to: 0.099884738259199177
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.100380047073500789   to: 0.099899636179562490
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.100388323685349737   to: 0.099914303043654409
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.100396471857490996   to: 0.099928742921812932
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.100404493857888605   to: 0.099942959804347420
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.100412391909693186   to: 0.099956957603268781
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.100420168192219272   to: 0.099970740153979110
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.100427824841899493   to: 0.099984311216921806
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.100435363953216006   to: 0.099997674479192999
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.100442787579609949   to: 0.100010833556115508
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.100450097734369262   to: 0.100023791992776084
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.100457296391495657   to: 0.100036553265526795
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.100464385486551150   to: 0.100049120783451698
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.100471366917484539   to: 0.100061497889799539
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.100478242545438717   to: 0.100073687863383082
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.100485014195538902   to: 0.100085693919946372
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.100491683657662423   to: 0.100097519213500380
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.100498252687190703   to: 0.100109166837627786
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.100504723005743590   to: 0.100120639826758007
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.100511096301896571   to: 0.100131941157412793
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.100517374231881576   to: 0.100143073749423397
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.100523558420271289   to: 0.100154040467119898
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.100529650460647796   to: 0.100164844120493382
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.100535651916255783   to: 0.100175487466331647
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.100541564320640639   to: 0.100185973209329093
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.100547389178271981   to: 0.100196304003171463
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.100553127965152839   to: 0.100206482451595857
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.100558782129414867   to: 0.100216511109427003
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.100564353091899927   to: 0.100226392483589943
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.100569842246728630   to: 0.100236129034099869
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.100575250961855545   to: 0.100245723175029958
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.100580580579612194   to: 0.100255177275457102
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.100585832417237495   to: 0.100264493660386700
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.100591007767396268   to: 0.100273674611656649
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.100596107898686060   to: 0.100282722368821131
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.100601134056132385   to: 0.100291639130014765
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.100606087461673169   to: 0.100300427052797389
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.100610969314631898   to: 0.100309088254980222
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.100615780792180434   to: 0.100317624815433562
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.100620523049791410   to: 0.100326038774876669
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.100625197221680493   to: 0.100334332136650176
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.100629804421238769   to: 0.100342506867471440
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.100634345741455605   to: 0.100350564898173261
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.100638822255332036   to: 0.100358508124426371
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.100643235016285026   to: 0.100366338407446035
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.100647585058542766   to: 0.100374057574683179
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.100651873397531288   to: 0.100381667420500392
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.100656101030252451   to: 0.100389169706833190
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.100660268935653760   to: 0.100396566163836881
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.100664378074990013   to: 0.100403858490519277
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.100668429392176906   to: 0.100411048355359717
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.100672423814137130   to: 0.100418137396914700
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.100676362251138671   to: 0.100425127224410368
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.100680245597125906   to: 0.100432019418322138
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.100684074730043441   to: 0.100438815530941944
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.100687850512152927   to: 0.100445517086933195
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.100691573790342992   to: 0.100452125583873828
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.100695245396432514   to: 0.100458642492787659
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.100698866147467245   to: 0.100465069258664455
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.100702436846010171   to: 0.100471407300968818
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.100705958280425611   to: 0.100477658014138160
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.100709431225157062   to: 0.100483822768070219
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.100712856440999296   to: 0.100489902908600076
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.100716234675364530   to: 0.100495899757967022
i: 100, name:           module.conv10.weight  changing lr from: 0.100719566662542920   to: 0.100501814615271773
i: 101, name:             module.conv10.bias  changing lr from: 0.100722853123957484   to: 0.100507648756923626



# Switched to train mode...
Epoch: [4][  0/391]	Time  0.204 ( 0.204)	Data  0.159 ( 0.159)	Loss 2.2572e+00 (2.2572e+00)	Acc@1  44.53 ( 44.53)	Acc@5  77.34 ( 77.34)
Epoch: [4][ 10/391]	Time  0.042 ( 0.058)	Data  0.001 ( 0.015)	Loss 2.0534e+00 (2.3081e+00)	Acc@1  46.09 ( 39.42)	Acc@5  78.12 ( 71.59)
Epoch: [4][ 20/391]	Time  0.041 ( 0.049)	Data  0.001 ( 0.009)	Loss 2.2642e+00 (2.2735e+00)	Acc@1  45.31 ( 40.22)	Acc@5  72.66 ( 72.32)
Epoch: [4][ 30/391]	Time  0.042 ( 0.047)	Data  0.001 ( 0.006)	Loss 2.4031e+00 (2.2740e+00)	Acc@1  40.62 ( 40.22)	Acc@5  66.41 ( 72.43)
Epoch: [4][ 40/391]	Time  0.040 ( 0.046)	Data  0.001 ( 0.005)	Loss 2.4652e+00 (2.2904e+00)	Acc@1  39.06 ( 40.15)	Acc@5  70.31 ( 72.08)
Epoch: [4][ 50/391]	Time  0.046 ( 0.045)	Data  0.001 ( 0.004)	Loss 2.3590e+00 (2.3075e+00)	Acc@1  36.72 ( 39.63)	Acc@5  65.62 ( 71.74)
Epoch: [4][ 60/391]	Time  0.043 ( 0.045)	Data  0.001 ( 0.004)	Loss 2.4409e+00 (2.3171e+00)	Acc@1  37.50 ( 39.33)	Acc@5  64.06 ( 71.64)
Epoch: [4][ 70/391]	Time  0.040 ( 0.044)	Data  0.001 ( 0.003)	Loss 2.5864e+00 (2.3202e+00)	Acc@1  35.16 ( 39.21)	Acc@5  67.97 ( 71.61)
Epoch: [4][ 80/391]	Time  0.042 ( 0.044)	Data  0.001 ( 0.003)	Loss 2.2535e+00 (2.3233e+00)	Acc@1  35.16 ( 39.06)	Acc@5  75.78 ( 71.54)
Epoch: [4][ 90/391]	Time  0.045 ( 0.044)	Data  0.001 ( 0.003)	Loss 2.4510e+00 (2.3244e+00)	Acc@1  33.59 ( 39.06)	Acc@5  65.62 ( 71.47)
Epoch: [4][100/391]	Time  0.041 ( 0.044)	Data  0.001 ( 0.003)	Loss 2.4214e+00 (2.3155e+00)	Acc@1  33.59 ( 39.07)	Acc@5  70.31 ( 71.85)
Epoch: [4][110/391]	Time  0.038 ( 0.043)	Data  0.001 ( 0.002)	Loss 2.1087e+00 (2.3129e+00)	Acc@1  46.09 ( 39.12)	Acc@5  75.78 ( 71.74)
Epoch: [4][120/391]	Time  0.038 ( 0.043)	Data  0.001 ( 0.002)	Loss 2.4917e+00 (2.3137e+00)	Acc@1  36.72 ( 38.99)	Acc@5  66.41 ( 71.62)
Epoch: [4][130/391]	Time  0.039 ( 0.043)	Data  0.001 ( 0.002)	Loss 2.2721e+00 (2.3180e+00)	Acc@1  42.97 ( 39.01)	Acc@5  67.19 ( 71.51)
Epoch: [4][140/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.9908e+00 (2.3110e+00)	Acc@1  46.09 ( 39.11)	Acc@5  77.34 ( 71.71)
Epoch: [4][150/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.0209e+00 (2.3082e+00)	Acc@1  45.31 ( 39.03)	Acc@5  79.69 ( 71.71)
Epoch: [4][160/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.3161e+00 (2.3064e+00)	Acc@1  37.50 ( 39.02)	Acc@5  75.00 ( 71.74)
Epoch: [4][170/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.1230e+00 (2.3064e+00)	Acc@1  45.31 ( 38.92)	Acc@5  75.78 ( 71.79)
Epoch: [4][180/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.1075e+00 (2.3035e+00)	Acc@1  44.53 ( 38.95)	Acc@5  75.00 ( 71.94)
Epoch: [4][190/391]	Time  0.045 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.0370e+00 (2.3006e+00)	Acc@1  47.66 ( 38.98)	Acc@5  79.69 ( 72.00)
Epoch: [4][200/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.2886e+00 (2.2990e+00)	Acc@1  35.94 ( 39.02)	Acc@5  72.66 ( 72.02)
Epoch: [4][210/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.2129e+00 (2.3011e+00)	Acc@1  40.62 ( 38.94)	Acc@5  74.22 ( 71.95)
Epoch: [4][220/391]	Time  0.045 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.3324e+00 (2.3061e+00)	Acc@1  41.41 ( 38.91)	Acc@5  73.44 ( 71.75)
Epoch: [4][230/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.3581e+00 (2.3050e+00)	Acc@1  35.94 ( 38.91)	Acc@5  71.88 ( 71.85)
Epoch: [4][240/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.4712e+00 (2.3043e+00)	Acc@1  32.81 ( 38.89)	Acc@5  71.09 ( 71.92)
Epoch: [4][250/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.4155e+00 (2.3010e+00)	Acc@1  32.81 ( 38.86)	Acc@5  68.75 ( 72.00)
Epoch: [4][260/391]	Time  0.054 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.4444e+00 (2.3044e+00)	Acc@1  32.81 ( 38.73)	Acc@5  70.31 ( 71.92)
Epoch: [4][270/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.2453e+00 (2.3041e+00)	Acc@1  38.28 ( 38.71)	Acc@5  75.00 ( 71.93)
Epoch: [4][280/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.2785e+00 (2.3051e+00)	Acc@1  39.84 ( 38.65)	Acc@5  74.22 ( 71.88)
Epoch: [4][290/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.0526e+00 (2.3056e+00)	Acc@1  50.00 ( 38.68)	Acc@5  78.91 ( 71.90)
Epoch: [4][300/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.9976e+00 (2.3014e+00)	Acc@1  46.88 ( 38.79)	Acc@5  79.69 ( 72.01)
Epoch: [4][310/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.5123e+00 (2.2989e+00)	Acc@1  33.59 ( 38.87)	Acc@5  64.84 ( 72.05)
Epoch: [4][320/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.1511e+00 (2.2968e+00)	Acc@1  38.28 ( 38.90)	Acc@5  77.34 ( 72.03)
Epoch: [4][330/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.4543e+00 (2.2970e+00)	Acc@1  37.50 ( 38.92)	Acc@5  70.31 ( 72.04)
Epoch: [4][340/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.1467e+00 (2.2930e+00)	Acc@1  46.09 ( 39.03)	Acc@5  70.31 ( 72.10)
Epoch: [4][350/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 2.1601e+00 (2.2895e+00)	Acc@1  42.97 ( 39.09)	Acc@5  73.44 ( 72.17)
Epoch: [4][360/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.001)	Loss 2.1781e+00 (2.2875e+00)	Acc@1  42.97 ( 39.19)	Acc@5  75.00 ( 72.18)
Epoch: [4][370/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.001)	Loss 2.3278e+00 (2.2849e+00)	Acc@1  41.41 ( 39.28)	Acc@5  70.31 ( 72.23)
Epoch: [4][380/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.001)	Loss 2.2809e+00 (2.2843e+00)	Acc@1  43.75 ( 39.31)	Acc@5  69.53 ( 72.22)
Epoch: [4][390/391]	Time  0.034 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.9976e+00 (2.2809e+00)	Acc@1  46.25 ( 39.38)	Acc@5  75.00 ( 72.28)
## e[4] optimizer.zero_grad (sum) time: 0.2885019779205322
## e[4]       loss.backward (sum) time: 4.083239555358887
## e[4]      optimizer.step (sum) time: 1.8998901844024658
## epoch[4] training(only) time: 16.402058362960815
# Switched to evaluate mode...
Test: [  0/100]	Time  0.152 ( 0.152)	Loss 2.5649e+00 (2.5649e+00)	Acc@1  39.00 ( 39.00)	Acc@5  72.00 ( 72.00)
Test: [ 10/100]	Time  0.023 ( 0.034)	Loss 2.7306e+00 (2.6024e+00)	Acc@1  27.00 ( 34.00)	Acc@5  66.00 ( 67.91)
Test: [ 20/100]	Time  0.025 ( 0.029)	Loss 2.1761e+00 (2.5679e+00)	Acc@1  43.00 ( 34.62)	Acc@5  75.00 ( 69.19)
Test: [ 30/100]	Time  0.022 ( 0.027)	Loss 2.5714e+00 (2.5719e+00)	Acc@1  34.00 ( 34.45)	Acc@5  68.00 ( 68.87)
Test: [ 40/100]	Time  0.024 ( 0.026)	Loss 2.6603e+00 (2.5672e+00)	Acc@1  40.00 ( 34.54)	Acc@5  67.00 ( 68.90)
Test: [ 50/100]	Time  0.018 ( 0.025)	Loss 2.6960e+00 (2.5764e+00)	Acc@1  32.00 ( 34.49)	Acc@5  63.00 ( 68.57)
Test: [ 60/100]	Time  0.022 ( 0.025)	Loss 2.5825e+00 (2.5704e+00)	Acc@1  36.00 ( 34.49)	Acc@5  71.00 ( 68.38)
Test: [ 70/100]	Time  0.022 ( 0.025)	Loss 2.8782e+00 (2.5762e+00)	Acc@1  29.00 ( 34.49)	Acc@5  63.00 ( 68.04)
Test: [ 80/100]	Time  0.022 ( 0.024)	Loss 2.8448e+00 (2.5850e+00)	Acc@1  30.00 ( 34.31)	Acc@5  62.00 ( 67.93)
Test: [ 90/100]	Time  0.019 ( 0.024)	Loss 2.5398e+00 (2.5775e+00)	Acc@1  38.00 ( 34.44)	Acc@5  70.00 ( 68.08)
 * Acc@1 34.640 Acc@5 68.160
### epoch[4] execution time: 18.79923152923584
EPOCH 5
i:   0, name:           module.stem.0.weight  changing lr from: 0.099152256835388142   to: 0.098122964374747490
i:   1, name:             module.stem.0.bias  changing lr from: 0.099179033202888206   to: 0.098164512044310162
i:   2, name:           module.stem.1.weight  changing lr from: 0.099205359932827558   to: 0.098205366201707930
i:   3, name:             module.stem.1.bias  changing lr from: 0.099231245576892280   to: 0.098245539906643739
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.099256698506001217   to: 0.098285045947149069
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.099281726914481699   to: 0.098323896845700601
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.099306338824141735   to: 0.098362104865191369
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.099330542088240992   to: 0.098399682014759571
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.099354344395363711   to: 0.098436640055479016
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.099377753273195632   to: 0.098472990505913946
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.099400776092207904   to: 0.098508744647542251
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.099423420069250062   to: 0.098543913530049793
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.099445692271054556   to: 0.098578507976499100
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.099467599617655153   to: 0.098612538588375764
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.099489148885721482   to: 0.098646015750515154
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.099510346711811873   to: 0.098678949635912672
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.099531199595546543   to: 0.098711350210420282
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.099551713902703232   to: 0.098743227237332157
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.099571895868237545   to: 0.098774590281862015
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.099591751599229353   to: 0.098805448715515096
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.099611287077758015   to: 0.098835811720357047
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.099630508163707304   to: 0.098865688293182430
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.099649420597502758   to: 0.098895087249585276
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.099668030002782473   to: 0.098924017227934036
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.099686341889003563   to: 0.098952486693253405
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.099704361653985607   to: 0.098980503941015111
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.099722094586392876   to: 0.099008077100840058
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.099739545868156879   to: 0.099035214140113945
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.099756720576840763   to: 0.099061922867518359
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.099773623687946955   to: 0.099088210936479806
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.099790260077169693   to: 0.099114085848537994
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.099806634522593585   to: 0.099139554956636150
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.099822751706839949   to: 0.099164625468334627
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.099838616219161777   to: 0.099189304448950050
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.099854232557489153   to: 0.099213598824621621
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.099869605130425934   to: 0.099237515385306577
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.099884738259199177   to: 0.099261060787706190
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.099899636179562490   to: 0.099284241558124320
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.099914303043654409   to: 0.099307064095260161
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.099928742921812932   to: 0.099329534672936357
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.099942959804347420   to: 0.099351659442764681
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.099956957603268781   to: 0.099373444436750294
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.099970740153979110   to: 0.099394895569836383
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.099984311216921806   to: 0.099416018642390386
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.099997674479192999   to: 0.099436819342633403
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.100010833556115508   to: 0.099457303249014140
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.100023791992776084   to: 0.099477475832528611
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.100036553265526795   to: 0.099497342458987101
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.100049120783451698   to: 0.099516908391229411
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.100061497889799539   to: 0.099536178791289912
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.100073687863383082   to: 0.099555158722513373
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.100085693919946372   to: 0.099573853151622982
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.100097519213500380   to: 0.099592266950741443
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.100109166837627786   to: 0.099610404899366539
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.100120639826758007   to: 0.099628271686302061
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.100131941157412793   to: 0.099645871911545281
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.100143073749423397   to: 0.099663210088132018
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.100154040467119898   to: 0.099680290643940114
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.100164844120493382   to: 0.099697117923452663
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.100175487466331647   to: 0.099713696189481726
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.100185973209329093   to: 0.099730029624853320
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.100196304003171463   to: 0.099746122334055054
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.100206482451595857   to: 0.099761978344846902
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.100216511109427003   to: 0.099777601609836120
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.100226392483589943   to: 0.099792996008017262
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.100236129034099869   to: 0.099808165346277858
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.100245723175029958   to: 0.099823113360870977
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.100255177275457102   to: 0.099837843718854957
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.100264493660386700   to: 0.099852360019501582
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.100273674611656649   to: 0.099866665795672938
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.100282722368821131   to: 0.099880764515168308
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.100291639130014765   to: 0.099894659582041065
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.100300427052797389   to: 0.099908354337886987
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.100309088254980222   to: 0.099921852063104138
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.100317624815433562   to: 0.099935155978125259
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.100326038774876669   to: 0.099948269244623286
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.100334332136650176   to: 0.099961194966690425
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.100342506867471440   to: 0.099973936191991755
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.100350564898173261   to: 0.099986495912893492
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.100358508124426371   to: 0.099998877067567077
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.100366338407446035   to: 0.100011082541069052
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.100374057574683179   to: 0.100023115166397683
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.100381667420500392   to: 0.100034977725526830
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.100389169706833190   to: 0.100046672950417359
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.100396566163836881   to: 0.100058203524006920
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.100403858490519277   to: 0.100069572081178337
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.100411048355359717   to: 0.100080781209707259
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.100418137396914700   to: 0.100091833451189466
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.100425127224410368   to: 0.100102731301948494
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.100432019418322138   to: 0.100113477213923552
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.100438815530941944   to: 0.100124073595538765
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.100445517086933195   to: 0.100134522812553931
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.100452125583873828   to: 0.100144827188896890
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.100458642492787659   to: 0.100154989007478615
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.100465069258664455   to: 0.100165010510990693
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.100471407300968818   to: 0.100174893902686177
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.100477658014138160   to: 0.100184641347143832
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.100483822768070219   to: 0.100194254971016222
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.100489902908600076   to: 0.100203736863762188
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.100495899757967022   to: 0.100213089078363793
i: 100, name:           module.conv10.weight  changing lr from: 0.100501814615271773   to: 0.100222313632028340
i: 101, name:             module.conv10.bias  changing lr from: 0.100507648756923626   to: 0.100231412506875533



# Switched to train mode...
Epoch: [5][  0/391]	Time  0.206 ( 0.206)	Data  0.160 ( 0.160)	Loss 2.0193e+00 (2.0193e+00)	Acc@1  46.09 ( 46.09)	Acc@5  75.00 ( 75.00)
Epoch: [5][ 10/391]	Time  0.042 ( 0.057)	Data  0.001 ( 0.016)	Loss 2.3076e+00 (2.1298e+00)	Acc@1  42.19 ( 43.18)	Acc@5  71.09 ( 73.51)
Epoch: [5][ 20/391]	Time  0.038 ( 0.049)	Data  0.002 ( 0.009)	Loss 2.2904e+00 (2.1486e+00)	Acc@1  39.84 ( 42.34)	Acc@5  67.97 ( 73.74)
Epoch: [5][ 30/391]	Time  0.043 ( 0.046)	Data  0.001 ( 0.006)	Loss 2.4286e+00 (2.1727e+00)	Acc@1  38.28 ( 41.89)	Acc@5  67.97 ( 73.99)
Epoch: [5][ 40/391]	Time  0.042 ( 0.045)	Data  0.001 ( 0.005)	Loss 2.0237e+00 (2.1479e+00)	Acc@1  48.44 ( 42.47)	Acc@5  75.78 ( 74.70)
Epoch: [5][ 50/391]	Time  0.043 ( 0.044)	Data  0.001 ( 0.004)	Loss 2.4103e+00 (2.1622e+00)	Acc@1  34.38 ( 42.20)	Acc@5  69.53 ( 74.40)
Epoch: [5][ 60/391]	Time  0.040 ( 0.044)	Data  0.001 ( 0.004)	Loss 1.9259e+00 (2.1631e+00)	Acc@1  44.53 ( 42.07)	Acc@5  80.47 ( 74.35)
Epoch: [5][ 70/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.003)	Loss 2.4023e+00 (2.1650e+00)	Acc@1  40.62 ( 41.91)	Acc@5  68.75 ( 74.42)
Epoch: [5][ 80/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.003)	Loss 2.1833e+00 (2.1662e+00)	Acc@1  38.28 ( 41.94)	Acc@5  76.56 ( 74.32)
Epoch: [5][ 90/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.003)	Loss 1.7888e+00 (2.1588e+00)	Acc@1  48.44 ( 42.00)	Acc@5  82.81 ( 74.60)
Epoch: [5][100/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.003)	Loss 2.1777e+00 (2.1486e+00)	Acc@1  37.50 ( 42.21)	Acc@5  75.78 ( 74.76)
Epoch: [5][110/391]	Time  0.044 ( 0.043)	Data  0.001 ( 0.002)	Loss 2.1838e+00 (2.1477e+00)	Acc@1  34.38 ( 42.24)	Acc@5  75.00 ( 74.86)
Epoch: [5][120/391]	Time  0.039 ( 0.043)	Data  0.001 ( 0.002)	Loss 2.2225e+00 (2.1461e+00)	Acc@1  39.84 ( 42.19)	Acc@5  75.00 ( 74.85)
Epoch: [5][130/391]	Time  0.044 ( 0.043)	Data  0.001 ( 0.002)	Loss 2.2763e+00 (2.1445e+00)	Acc@1  43.75 ( 42.38)	Acc@5  70.31 ( 74.82)
Epoch: [5][140/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.002)	Loss 2.1480e+00 (2.1462e+00)	Acc@1  39.06 ( 42.29)	Acc@5  78.91 ( 74.80)
Epoch: [5][150/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.1172e+00 (2.1478e+00)	Acc@1  43.75 ( 42.19)	Acc@5  76.56 ( 74.73)
Epoch: [5][160/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.0217e+00 (2.1486e+00)	Acc@1  46.88 ( 42.23)	Acc@5  75.78 ( 74.69)
Epoch: [5][170/391]	Time  0.046 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.3592e+00 (2.1496e+00)	Acc@1  42.97 ( 42.18)	Acc@5  67.19 ( 74.67)
Epoch: [5][180/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.2042e+00 (2.1467e+00)	Acc@1  45.31 ( 42.25)	Acc@5  73.44 ( 74.70)
Epoch: [5][190/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.4087e+00 (2.1504e+00)	Acc@1  39.84 ( 42.20)	Acc@5  71.88 ( 74.64)
Epoch: [5][200/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.0486e+00 (2.1451e+00)	Acc@1  40.62 ( 42.28)	Acc@5  78.12 ( 74.74)
Epoch: [5][210/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.3005e+00 (2.1419e+00)	Acc@1  40.62 ( 42.39)	Acc@5  70.31 ( 74.77)
Epoch: [5][220/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.9997e+00 (2.1384e+00)	Acc@1  44.53 ( 42.51)	Acc@5  81.25 ( 74.83)
Epoch: [5][230/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.3544e+00 (2.1396e+00)	Acc@1  37.50 ( 42.44)	Acc@5  71.88 ( 74.81)
Epoch: [5][240/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.9984e+00 (2.1355e+00)	Acc@1  44.53 ( 42.59)	Acc@5  78.91 ( 74.92)
Epoch: [5][250/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.1807e+00 (2.1306e+00)	Acc@1  43.75 ( 42.68)	Acc@5  77.34 ( 75.06)
Epoch: [5][260/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.1289e+00 (2.1283e+00)	Acc@1  42.19 ( 42.72)	Acc@5  75.78 ( 75.07)
Epoch: [5][270/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.1525e+00 (2.1227e+00)	Acc@1  42.19 ( 42.89)	Acc@5  75.00 ( 75.20)
Epoch: [5][280/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.0805e+00 (2.1239e+00)	Acc@1  45.31 ( 42.93)	Acc@5  76.56 ( 75.14)
Epoch: [5][290/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.9739e+00 (2.1229e+00)	Acc@1  44.53 ( 42.95)	Acc@5  78.91 ( 75.17)
Epoch: [5][300/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.1750e+00 (2.1210e+00)	Acc@1  39.06 ( 43.02)	Acc@5  73.44 ( 75.16)
Epoch: [5][310/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.001)	Loss 2.4603e+00 (2.1220e+00)	Acc@1  28.91 ( 42.97)	Acc@5  68.75 ( 75.16)
Epoch: [5][320/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 2.2338e+00 (2.1208e+00)	Acc@1  38.28 ( 42.96)	Acc@5  75.00 ( 75.21)
Epoch: [5][330/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 2.0788e+00 (2.1205e+00)	Acc@1  44.53 ( 42.97)	Acc@5  71.09 ( 75.22)
Epoch: [5][340/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.9613e+00 (2.1208e+00)	Acc@1  47.66 ( 43.00)	Acc@5  78.12 ( 75.22)
Epoch: [5][350/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.001)	Loss 2.2633e+00 (2.1198e+00)	Acc@1  38.28 ( 42.95)	Acc@5  75.00 ( 75.25)
Epoch: [5][360/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.001)	Loss 2.0773e+00 (2.1192e+00)	Acc@1  50.78 ( 42.96)	Acc@5  70.31 ( 75.25)
Epoch: [5][370/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.001)	Loss 2.1286e+00 (2.1178e+00)	Acc@1  46.09 ( 42.97)	Acc@5  76.56 ( 75.31)
Epoch: [5][380/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.9225e+00 (2.1158e+00)	Acc@1  46.09 ( 43.02)	Acc@5  79.69 ( 75.33)
Epoch: [5][390/391]	Time  0.028 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.7779e+00 (2.1150e+00)	Acc@1  52.50 ( 43.04)	Acc@5  80.00 ( 75.34)
## e[5] optimizer.zero_grad (sum) time: 0.2861006259918213
## e[5]       loss.backward (sum) time: 4.17320442199707
## e[5]      optimizer.step (sum) time: 1.8556809425354004
## epoch[5] training(only) time: 16.417322397232056
# Switched to evaluate mode...
Test: [  0/100]	Time  0.149 ( 0.149)	Loss 2.4926e+00 (2.4926e+00)	Acc@1  41.00 ( 41.00)	Acc@5  70.00 ( 70.00)
Test: [ 10/100]	Time  0.027 ( 0.033)	Loss 2.8728e+00 (2.5344e+00)	Acc@1  30.00 ( 38.27)	Acc@5  63.00 ( 70.64)
Test: [ 20/100]	Time  0.021 ( 0.029)	Loss 2.3042e+00 (2.4846e+00)	Acc@1  44.00 ( 38.00)	Acc@5  75.00 ( 71.52)
Test: [ 30/100]	Time  0.022 ( 0.027)	Loss 2.9196e+00 (2.5026e+00)	Acc@1  37.00 ( 37.77)	Acc@5  64.00 ( 70.77)
Test: [ 40/100]	Time  0.026 ( 0.026)	Loss 2.6861e+00 (2.4953e+00)	Acc@1  35.00 ( 38.34)	Acc@5  67.00 ( 71.24)
Test: [ 50/100]	Time  0.023 ( 0.025)	Loss 2.3564e+00 (2.5124e+00)	Acc@1  40.00 ( 38.02)	Acc@5  67.00 ( 70.57)
Test: [ 60/100]	Time  0.024 ( 0.024)	Loss 2.1235e+00 (2.4990e+00)	Acc@1  43.00 ( 38.26)	Acc@5  79.00 ( 70.59)
Test: [ 70/100]	Time  0.024 ( 0.024)	Loss 2.6564e+00 (2.4972e+00)	Acc@1  33.00 ( 38.25)	Acc@5  69.00 ( 70.62)
Test: [ 80/100]	Time  0.024 ( 0.024)	Loss 2.6898e+00 (2.5089e+00)	Acc@1  39.00 ( 38.22)	Acc@5  60.00 ( 70.21)
Test: [ 90/100]	Time  0.022 ( 0.024)	Loss 2.5812e+00 (2.4928e+00)	Acc@1  40.00 ( 38.46)	Acc@5  70.00 ( 70.46)
 * Acc@1 38.400 Acc@5 70.600
### epoch[5] execution time: 18.876144409179688
EPOCH 6
i:   0, name:           module.stem.0.weight  changing lr from: 0.098122964374747490   to: 0.096874724822374580
i:   1, name:             module.stem.0.bias  changing lr from: 0.098164512044310162   to: 0.096934044715140458
i:   2, name:           module.stem.1.weight  changing lr from: 0.098205366201707930   to: 0.096992381765385993
i:   3, name:             module.stem.1.bias  changing lr from: 0.098245539906643739   to: 0.097049754252102480
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.098285045947149069   to: 0.097106180081789714
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.098323896845700601   to: 0.097161676796559404
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.098362104865191369   to: 0.097216261582056651
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.098399682014759571   to: 0.097269951275203839
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.098436640055479016   to: 0.097322762371770274
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.098472990505913946   to: 0.097374711033772043
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.098508744647542251   to: 0.097425813096705158
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.098543913530049793   to: 0.097476084076616260
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.098578507976499100   to: 0.097525539177013995
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.098612538588375764   to: 0.097574193295625000
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.098646015750515154   to: 0.097622061030997631
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.098678949635912672   to: 0.097669156688957065
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.098711350210420282   to: 0.097715494288915045
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.098743227237332157   to: 0.097761087570037361
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.098774590281862015   to: 0.097805949997272670
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.098805448715515096   to: 0.097850094767245321
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.098835811720357047   to: 0.097893534814015512
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.098865688293182430   to: 0.097936282814709813
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.098895087249585276   to: 0.097978351195024918
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.098924017227934036   to: 0.098019752134607396
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.098952486693253405   to: 0.098060497572312555
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.098980503941015111   to: 0.098100599211344841
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.099008077100840058   to: 0.098140068524282767
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.099035214140113945   to: 0.098178916757990842
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.099061922867518359   to: 0.098217154938421009
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.099088210936479806   to: 0.098254793875306515
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.099114085848537994   to: 0.098291844166750089
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.099139554956636150   to: 0.098328316203709409
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.099164625468334627   to: 0.098364220174381872
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.099189304448950050   to: 0.098399566068491082
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.099213598824621621   to: 0.098434363681477455
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.099237515385306577   to: 0.098468622618594820
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.099261060787706190   to: 0.098502352298915546
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.099284241558124320   to: 0.098535561959246107
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.099307064095260161   to: 0.098568260657955098
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.099329534672936357   to: 0.098600457278715969
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.099351659442764681   to: 0.098632160534166083
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.099373444436750294   to: 0.098663378969484461
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.099394895569836383   to: 0.098694120965889642
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.099416018642390386   to: 0.098724394744059848
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.099436819342633403   to: 0.098754208367477142
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.099457303249014140   to: 0.098783569745697256
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.099477475832528611   to: 0.098812486637546854
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.099497342458987101   to: 0.098840966654249976
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.099516908391229411   to: 0.098869017262485245
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.099536178791289912   to: 0.098896645787375323
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.099555158722513373   to: 0.098923859415410487
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.099573853151622982   to: 0.098950665197307441
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.099592266950741443   to: 0.098977070050805194
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.099610404899366539   to: 0.099003080763399282
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.099628271686302061   to: 0.099028703995015899
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.099645871911545281   to: 0.099053946280627039
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.099663210088132018   to: 0.099078814032808368
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.099680290643940114   to: 0.099103313544240915
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.099697117923452663   to: 0.099127450990157920
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.099713696189481726   to: 0.099151232430738159
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.099730029624853320   to: 0.099174663813446889
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.099746122334055054   to: 0.099197750975325738
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.099761978344846902   to: 0.099220499645232496
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.099777601609836120   to: 0.099242915446032365
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.099792996008017262   to: 0.099265003896741227
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.099808165346277858   to: 0.099286770414622458
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.099823113360870977   to: 0.099308220317238322
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.099837843718854957   to: 0.099329358824456690
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.099852360019501582   to: 0.099350191060414428
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.099866665795672938   to: 0.099370722055438288
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.099880764515168308   to: 0.099390956747924308
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.099894659582041065   to: 0.099410899986176637
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.099908354337886987   to: 0.099430556530206701
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.099921852063104138   to: 0.099449931053493895
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.099935155978125259   to: 0.099469028144708038
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.099948269244623286   to: 0.099487852309395261
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.099961194966690425   to: 0.099506407971627409
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.099973936191991755   to: 0.099524699475616429
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.099986495912893492   to: 0.099542731087294056
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.099998877067567077   to: 0.099560506995857875
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.100011082541069052   to: 0.099578031315284310
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.100023115166397683   to: 0.099595308085809589
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.100034977725526830   to: 0.099612341275378977
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.100046672950417359   to: 0.099629134781065484
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.100058203524006920   to: 0.099645692430458288
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.100069572081178337   to: 0.099662017983021906
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.100080781209707259   to: 0.099678115131426534
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.100091833451189466   to: 0.099693987502850301
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.100102731301948494   to: 0.099709638660254174
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.100113477213923552   to: 0.099725072103629867
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.100124073595538765   to: 0.099740291271221623
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.100134522812553931   to: 0.099755299540722223
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.100144827188896890   to: 0.099770100230444136
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.100154989007478615   to: 0.099784696600465864
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.100165010510990693   to: 0.099799091853754573
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.100174893902686177   to: 0.099813289137265171
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.100184641347143832   to: 0.099827291543016408
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.100194254971016222   to: 0.099841102109144750
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.100203736863762188   to: 0.099854723820936173
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.100213089078363793   to: 0.099868159611836732
i: 100, name:           module.conv10.weight  changing lr from: 0.100222313632028340   to: 0.099881412364441924
i: 101, name:             module.conv10.bias  changing lr from: 0.100231412506875533   to: 0.099894484911465894



# Switched to train mode...
Epoch: [6][  0/391]	Time  0.206 ( 0.206)	Data  0.159 ( 0.159)	Loss 1.9688e+00 (1.9688e+00)	Acc@1  50.78 ( 50.78)	Acc@5  75.78 ( 75.78)
Epoch: [6][ 10/391]	Time  0.041 ( 0.057)	Data  0.001 ( 0.015)	Loss 2.2046e+00 (2.0069e+00)	Acc@1  38.28 ( 45.24)	Acc@5  76.56 ( 77.34)
Epoch: [6][ 20/391]	Time  0.040 ( 0.050)	Data  0.001 ( 0.008)	Loss 1.9572e+00 (1.9802e+00)	Acc@1  42.97 ( 45.54)	Acc@5  78.91 ( 78.12)
Epoch: [6][ 30/391]	Time  0.040 ( 0.048)	Data  0.001 ( 0.006)	Loss 1.9652e+00 (2.0014e+00)	Acc@1  45.31 ( 44.96)	Acc@5  76.56 ( 78.12)
Epoch: [6][ 40/391]	Time  0.042 ( 0.046)	Data  0.001 ( 0.005)	Loss 1.9325e+00 (1.9972e+00)	Acc@1  44.53 ( 45.03)	Acc@5  82.81 ( 77.84)
Epoch: [6][ 50/391]	Time  0.040 ( 0.045)	Data  0.001 ( 0.004)	Loss 2.0504e+00 (2.0006e+00)	Acc@1  40.62 ( 44.79)	Acc@5  80.47 ( 77.85)
Epoch: [6][ 60/391]	Time  0.044 ( 0.045)	Data  0.001 ( 0.004)	Loss 2.1187e+00 (2.0009e+00)	Acc@1  36.72 ( 44.71)	Acc@5  76.56 ( 78.00)
Epoch: [6][ 70/391]	Time  0.040 ( 0.044)	Data  0.001 ( 0.003)	Loss 1.8609e+00 (2.0081e+00)	Acc@1  46.09 ( 44.66)	Acc@5  80.47 ( 77.90)
Epoch: [6][ 80/391]	Time  0.040 ( 0.044)	Data  0.001 ( 0.003)	Loss 2.2398e+00 (2.0209e+00)	Acc@1  39.84 ( 44.37)	Acc@5  71.09 ( 77.57)
Epoch: [6][ 90/391]	Time  0.041 ( 0.044)	Data  0.001 ( 0.003)	Loss 2.0544e+00 (2.0264e+00)	Acc@1  42.97 ( 44.45)	Acc@5  78.91 ( 77.52)
Epoch: [6][100/391]	Time  0.041 ( 0.043)	Data  0.002 ( 0.003)	Loss 1.8687e+00 (2.0271e+00)	Acc@1  51.56 ( 44.59)	Acc@5  81.25 ( 77.43)
Epoch: [6][110/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.7248e+00 (2.0249e+00)	Acc@1  55.47 ( 44.79)	Acc@5  86.72 ( 77.48)
Epoch: [6][120/391]	Time  0.044 ( 0.043)	Data  0.001 ( 0.002)	Loss 2.3215e+00 (2.0175e+00)	Acc@1  41.41 ( 45.07)	Acc@5  72.66 ( 77.53)
Epoch: [6][130/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.002)	Loss 2.1924e+00 (2.0116e+00)	Acc@1  34.38 ( 45.16)	Acc@5  75.00 ( 77.58)
Epoch: [6][140/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.8812e+00 (2.0043e+00)	Acc@1  50.78 ( 45.47)	Acc@5  79.69 ( 77.71)
Epoch: [6][150/391]	Time  0.039 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.8775e+00 (1.9985e+00)	Acc@1  45.31 ( 45.55)	Acc@5  79.69 ( 77.73)
Epoch: [6][160/391]	Time  0.047 ( 0.043)	Data  0.001 ( 0.002)	Loss 2.0126e+00 (2.0007e+00)	Acc@1  44.53 ( 45.54)	Acc@5  76.56 ( 77.73)
Epoch: [6][170/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.002)	Loss 2.1473e+00 (1.9979e+00)	Acc@1  46.09 ( 45.66)	Acc@5  72.66 ( 77.77)
Epoch: [6][180/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.002)	Loss 2.0165e+00 (1.9988e+00)	Acc@1  45.31 ( 45.69)	Acc@5  80.47 ( 77.74)
Epoch: [6][190/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.8623e+00 (1.9969e+00)	Acc@1  52.34 ( 45.75)	Acc@5  81.25 ( 77.80)
Epoch: [6][200/391]	Time  0.047 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.7344e+00 (1.9957e+00)	Acc@1  53.12 ( 45.62)	Acc@5  82.03 ( 77.86)
Epoch: [6][210/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.9987e+00 (1.9922e+00)	Acc@1  45.31 ( 45.67)	Acc@5  75.78 ( 77.95)
Epoch: [6][220/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.8855e+00 (1.9908e+00)	Acc@1  48.44 ( 45.84)	Acc@5  82.81 ( 77.96)
Epoch: [6][230/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.002)	Loss 2.0964e+00 (1.9915e+00)	Acc@1  42.97 ( 45.80)	Acc@5  74.22 ( 77.94)
Epoch: [6][240/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.8524e+00 (1.9900e+00)	Acc@1  45.31 ( 45.91)	Acc@5  77.34 ( 77.94)
Epoch: [6][250/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.9570e+00 (1.9887e+00)	Acc@1  46.09 ( 45.96)	Acc@5  76.56 ( 77.98)
Epoch: [6][260/391]	Time  0.037 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.8026e+00 (1.9886e+00)	Acc@1  46.88 ( 45.90)	Acc@5  80.47 ( 78.04)
Epoch: [6][270/391]	Time  0.053 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.0685e+00 (1.9866e+00)	Acc@1  42.19 ( 45.90)	Acc@5  78.12 ( 78.12)
Epoch: [6][280/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.9136e+00 (1.9840e+00)	Acc@1  50.00 ( 45.96)	Acc@5  77.34 ( 78.13)
Epoch: [6][290/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.0095e+00 (1.9831e+00)	Acc@1  42.97 ( 45.98)	Acc@5  76.56 ( 78.13)
Epoch: [6][300/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.0978e+00 (1.9829e+00)	Acc@1  45.31 ( 45.99)	Acc@5  77.34 ( 78.15)
Epoch: [6][310/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.9074e+00 (1.9807e+00)	Acc@1  45.31 ( 46.06)	Acc@5  78.12 ( 78.18)
Epoch: [6][320/391]	Time  0.045 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.0995e+00 (1.9835e+00)	Acc@1  39.06 ( 46.01)	Acc@5  75.00 ( 78.13)
Epoch: [6][330/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.8613e+00 (1.9809e+00)	Acc@1  50.00 ( 46.09)	Acc@5  79.69 ( 78.17)
Epoch: [6][340/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.8744e+00 (1.9797e+00)	Acc@1  50.00 ( 46.16)	Acc@5  79.69 ( 78.18)
Epoch: [6][350/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.6382e+00 (1.9788e+00)	Acc@1  53.12 ( 46.14)	Acc@5  82.81 ( 78.18)
Epoch: [6][360/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.9999e+00 (1.9801e+00)	Acc@1  46.88 ( 46.12)	Acc@5  78.91 ( 78.18)
Epoch: [6][370/391]	Time  0.045 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.8030e+00 (1.9791e+00)	Acc@1  49.22 ( 46.11)	Acc@5  82.03 ( 78.21)
Epoch: [6][380/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.8430e+00 (1.9765e+00)	Acc@1  47.66 ( 46.14)	Acc@5  82.81 ( 78.22)
Epoch: [6][390/391]	Time  0.028 ( 0.042)	Data  0.001 ( 0.001)	Loss 2.4029e+00 (1.9784e+00)	Acc@1  31.25 ( 46.10)	Acc@5  73.75 ( 78.19)
## e[6] optimizer.zero_grad (sum) time: 0.2838292121887207
## e[6]       loss.backward (sum) time: 4.146304130554199
## e[6]      optimizer.step (sum) time: 1.8714919090270996
## epoch[6] training(only) time: 16.528124570846558
# Switched to evaluate mode...
Test: [  0/100]	Time  0.151 ( 0.151)	Loss 2.2789e+00 (2.2789e+00)	Acc@1  42.00 ( 42.00)	Acc@5  70.00 ( 70.00)
Test: [ 10/100]	Time  0.021 ( 0.032)	Loss 2.8764e+00 (2.5604e+00)	Acc@1  29.00 ( 37.45)	Acc@5  62.00 ( 68.45)
Test: [ 20/100]	Time  0.018 ( 0.028)	Loss 2.1331e+00 (2.4870e+00)	Acc@1  47.00 ( 38.71)	Acc@5  74.00 ( 68.95)
Test: [ 30/100]	Time  0.021 ( 0.026)	Loss 2.6287e+00 (2.4945e+00)	Acc@1  29.00 ( 38.61)	Acc@5  66.00 ( 69.16)
Test: [ 40/100]	Time  0.024 ( 0.025)	Loss 2.3345e+00 (2.4894e+00)	Acc@1  47.00 ( 38.51)	Acc@5  78.00 ( 69.44)
Test: [ 50/100]	Time  0.019 ( 0.025)	Loss 2.4578e+00 (2.5038e+00)	Acc@1  39.00 ( 38.25)	Acc@5  66.00 ( 69.06)
Test: [ 60/100]	Time  0.025 ( 0.024)	Loss 2.3253e+00 (2.4958e+00)	Acc@1  36.00 ( 38.00)	Acc@5  72.00 ( 69.28)
Test: [ 70/100]	Time  0.018 ( 0.024)	Loss 2.6267e+00 (2.4900e+00)	Acc@1  34.00 ( 38.06)	Acc@5  68.00 ( 69.46)
Test: [ 80/100]	Time  0.024 ( 0.024)	Loss 2.7797e+00 (2.5010e+00)	Acc@1  34.00 ( 37.70)	Acc@5  68.00 ( 69.23)
Test: [ 90/100]	Time  0.018 ( 0.023)	Loss 2.7615e+00 (2.5077e+00)	Acc@1  33.00 ( 37.62)	Acc@5  69.00 ( 69.19)
 * Acc@1 37.780 Acc@5 69.280
### epoch[6] execution time: 18.92546820640564
EPOCH 7
i:   0, name:           module.stem.0.weight  changing lr from: 0.096874724822374580   to: 0.095413337864757808
i:   1, name:             module.stem.0.bias  changing lr from: 0.096934044715140458   to: 0.095493265000109517
i:   2, name:           module.stem.1.weight  changing lr from: 0.096992381765385993   to: 0.095571879612025609
i:   3, name:             module.stem.1.bias  changing lr from: 0.097049754252102480   to: 0.095649205742293145
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.097106180081789714   to: 0.095725266955318633
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.097161676796559404   to: 0.095800086348048916
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.097216261582056651   to: 0.095873686559688531
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.097269951275203839   to: 0.095946089781216840
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.097322762371770274   to: 0.096017317764708440
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.097374711033772043   to: 0.096087391832460720
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.097425813096705158   to: 0.096156332885931714
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.097476084076616260   to: 0.096224161414492068
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.097525539177013995   to: 0.096290897503994138
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.097574193295625000   to: 0.096356560845162254
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.097622061030997631   to: 0.096421170741806853
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.097669156688957065   to: 0.096484746118866538
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.097715494288915045   to: 0.096547305530280625
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.097761087570037361   to: 0.096608867166696200
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.097805949997272670   to: 0.096669448863012417
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.097850094767245321   to: 0.096729068105765356
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.097893534814015512   to: 0.096787742040356742
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.097936282814709813   to: 0.096845487478129447
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.097978351195024918   to: 0.096902320903292941
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.098019752134607396   to: 0.096958258479701673
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.098060497572312555   to: 0.097013316057489377
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.098100599211344841   to: 0.097067509179562333
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.098140068524282767   to: 0.097120853087954109
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.098178916757990842   to: 0.097173362730045176
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.098217154938421009   to: 0.097225052764649711
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.098254793875306515   to: 0.097275937567972481
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.098291844166750089   to: 0.097326031239438712
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.098328316203709409   to: 0.097375347607399215
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.098364220174381872   to: 0.097423900234713728
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.098399566068491082   to: 0.097471702424214754
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.098434363681477455   to: 0.097518767224054670
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.098468622618594820   to: 0.097565107432938336
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.098502352298915546   to: 0.097610735605243790
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.098535561959246107   to: 0.097655664056033292
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.098568260657955098   to: 0.097699904865957199
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.098600457278715969   to: 0.097743469886052703
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.098632160534166083   to: 0.097786370742440065
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.098663378969484461   to: 0.097828618840918105
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.098694120965889642   to: 0.097870225371461450
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.098724394744059848   to: 0.097911201312621432
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.098754208367477142   to: 0.097951557435833003
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.098783569745697256   to: 0.097991304309629157
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.098812486637546854   to: 0.098030452303765531
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.098840966654249976   to: 0.098069011593256719
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.098869017262485245   to: 0.098106992162326059
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.098896645787375323   to: 0.098144403808271385
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.098923859415410487   to: 0.098181256145247836
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.098950665197307441   to: 0.098217558607970171
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.098977070050805194   to: 0.098253320455335802
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.099003080763399282   to: 0.098288550773970765
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.099028703995015899   to: 0.098323258481699857
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.099053946280627039   to: 0.098357452330942910
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.099078814032808368   to: 0.098391140912038794
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.099103313544240915   to: 0.098424332656498442
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.099127450990157920   to: 0.098457035840188875
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.099151232430738159   to: 0.098489258586449371
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.099174663813446889   to: 0.098521008869141530
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.099197750975325738   to: 0.098552294515634409
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.099220499645232496   to: 0.098583123209726550
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.099242915446032365   to: 0.098613502494505789
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.099265003896741227   to: 0.098643439775148625
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.099286770414622458   to: 0.098672942321660351
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.099308220317238322   to: 0.098702017271557030
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.099329358824456690   to: 0.098730671632490996
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.099350191060414428   to: 0.098758912284820685
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.099370722055438288   to: 0.098786745984126456
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.099390956747924308   to: 0.098814179363673232
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.099410899986176637   to: 0.098841218936821226
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.099430556530206701   to: 0.098867871099386079
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.099449931053493895   to: 0.098894142131949220
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.099469028144708038   to: 0.098920038202119781
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.099487852309395261   to: 0.098945565366749019
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.099506407971627409   to: 0.098970729574098248
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.099524699475616429   to: 0.098995536665961531
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.099542731087294056   to: 0.099019992379743710
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.099560506995857875   to: 0.099044102350495197
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.099578031315284310   to: 0.099067872112904160
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.099595308085809589   to: 0.099091307103247248
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.099612341275378977   to: 0.099114412661299556
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.099629134781065484   to: 0.099137194032204917
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.099645692430458288   to: 0.099159656368307245
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.099662017983021906   to: 0.099181804730943873
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.099678115131426534   to: 0.099203644092201670
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.099693987502850301   to: 0.099225179336636826
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.099709638660254174   to: 0.099246415262958881
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.099725072103629867   to: 0.099267356585680103
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.099740291271221623   to: 0.099288007936730677
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.099755299540722223   to: 0.099308373867040667
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.099770100230444136   to: 0.099328458848089302
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.099784696600465864   to: 0.099348267273422414
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.099799091853754573   to: 0.099367803460138709
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.099813289137265171   to: 0.099387071650345424
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.099827291543016408   to: 0.099406076012584263
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.099841102109144750   to: 0.099424820643228023
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.099854723820936173   to: 0.099443309567848734
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.099868159611836732   to: 0.099461546742557694
i: 100, name:           module.conv10.weight  changing lr from: 0.099881412364441924   to: 0.099479536055318438
i: 101, name:             module.conv10.bias  changing lr from: 0.099894484911465894   to: 0.099497281327232595



# Switched to train mode...
Epoch: [7][  0/391]	Time  0.199 ( 0.199)	Data  0.150 ( 0.150)	Loss 1.8313e+00 (1.8313e+00)	Acc@1  51.56 ( 51.56)	Acc@5  79.69 ( 79.69)
Epoch: [7][ 10/391]	Time  0.041 ( 0.056)	Data  0.001 ( 0.015)	Loss 1.8448e+00 (1.8955e+00)	Acc@1  52.34 ( 49.43)	Acc@5  77.34 ( 78.55)
Epoch: [7][ 20/391]	Time  0.041 ( 0.049)	Data  0.001 ( 0.008)	Loss 2.0623e+00 (1.8966e+00)	Acc@1  40.62 ( 48.92)	Acc@5  77.34 ( 79.43)
Epoch: [7][ 30/391]	Time  0.040 ( 0.047)	Data  0.001 ( 0.006)	Loss 1.6705e+00 (1.8730e+00)	Acc@1  54.69 ( 49.34)	Acc@5  82.81 ( 79.61)
Epoch: [7][ 40/391]	Time  0.040 ( 0.045)	Data  0.001 ( 0.005)	Loss 1.6489e+00 (1.8738e+00)	Acc@1  47.66 ( 49.05)	Acc@5  86.72 ( 79.84)
Epoch: [7][ 50/391]	Time  0.040 ( 0.044)	Data  0.001 ( 0.004)	Loss 1.7686e+00 (1.8775e+00)	Acc@1  46.09 ( 49.03)	Acc@5  82.03 ( 79.99)
Epoch: [7][ 60/391]	Time  0.041 ( 0.044)	Data  0.001 ( 0.003)	Loss 1.8108e+00 (1.8826e+00)	Acc@1  53.91 ( 49.01)	Acc@5  76.56 ( 79.82)
Epoch: [7][ 70/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.003)	Loss 2.1633e+00 (1.8898e+00)	Acc@1  44.53 ( 48.84)	Acc@5  76.56 ( 79.73)
Epoch: [7][ 80/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.003)	Loss 1.9863e+00 (1.8934e+00)	Acc@1  42.97 ( 48.59)	Acc@5  78.91 ( 79.66)
Epoch: [7][ 90/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.003)	Loss 1.7692e+00 (1.8935e+00)	Acc@1  48.44 ( 48.37)	Acc@5  77.34 ( 79.67)
Epoch: [7][100/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.002)	Loss 2.0940e+00 (1.8880e+00)	Acc@1  41.41 ( 48.58)	Acc@5  77.34 ( 79.76)
Epoch: [7][110/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.7869e+00 (1.8862e+00)	Acc@1  45.31 ( 48.56)	Acc@5  83.59 ( 79.81)
Epoch: [7][120/391]	Time  0.044 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.8603e+00 (1.8893e+00)	Acc@1  50.78 ( 48.47)	Acc@5  82.03 ( 79.72)
Epoch: [7][130/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.6140e+00 (1.8879e+00)	Acc@1  53.91 ( 48.52)	Acc@5  84.38 ( 79.70)
Epoch: [7][140/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.7858e+00 (1.8886e+00)	Acc@1  51.56 ( 48.59)	Acc@5  82.81 ( 79.62)
Epoch: [7][150/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.9850e+00 (1.8854e+00)	Acc@1  49.22 ( 48.69)	Acc@5  77.34 ( 79.74)
Epoch: [7][160/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.1794e+00 (1.8863e+00)	Acc@1  40.62 ( 48.63)	Acc@5  76.56 ( 79.71)
Epoch: [7][170/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.6508e+00 (1.8812e+00)	Acc@1  51.56 ( 48.73)	Acc@5  86.72 ( 79.85)
Epoch: [7][180/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.7621e+00 (1.8793e+00)	Acc@1  50.78 ( 48.70)	Acc@5  85.16 ( 79.91)
Epoch: [7][190/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.9001e+00 (1.8803e+00)	Acc@1  45.31 ( 48.63)	Acc@5  81.25 ( 79.94)
Epoch: [7][200/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.5935e+00 (1.8757e+00)	Acc@1  60.16 ( 48.77)	Acc@5  85.16 ( 79.96)
Epoch: [7][210/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.9695e+00 (1.8740e+00)	Acc@1  45.31 ( 48.82)	Acc@5  75.00 ( 79.97)
Epoch: [7][220/391]	Time  0.042 ( 0.042)	Data  0.002 ( 0.002)	Loss 1.9672e+00 (1.8739e+00)	Acc@1  41.41 ( 48.75)	Acc@5  79.69 ( 79.96)
Epoch: [7][230/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.6726e+00 (1.8734e+00)	Acc@1  54.69 ( 48.78)	Acc@5  85.16 ( 80.05)
Epoch: [7][240/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.0235e+00 (1.8729e+00)	Acc@1  43.75 ( 48.72)	Acc@5  75.00 ( 80.07)
Epoch: [7][250/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.8598e+00 (1.8710e+00)	Acc@1  44.53 ( 48.75)	Acc@5  78.91 ( 80.15)
Epoch: [7][260/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.4366e+00 (1.8689e+00)	Acc@1  65.62 ( 48.83)	Acc@5  89.06 ( 80.19)
Epoch: [7][270/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.8862e+00 (1.8673e+00)	Acc@1  46.88 ( 48.80)	Acc@5  82.03 ( 80.24)
Epoch: [7][280/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.8072e+00 (1.8672e+00)	Acc@1  53.91 ( 48.77)	Acc@5  85.94 ( 80.24)
Epoch: [7][290/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.8563e+00 (1.8656e+00)	Acc@1  47.66 ( 48.82)	Acc@5  81.25 ( 80.26)
Epoch: [7][300/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.001)	Loss 2.0969e+00 (1.8682e+00)	Acc@1  44.53 ( 48.79)	Acc@5  76.56 ( 80.22)
Epoch: [7][310/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.9613e+00 (1.8701e+00)	Acc@1  50.00 ( 48.77)	Acc@5  77.34 ( 80.19)
Epoch: [7][320/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 2.1608e+00 (1.8711e+00)	Acc@1  44.53 ( 48.71)	Acc@5  71.88 ( 80.20)
Epoch: [7][330/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.7919e+00 (1.8731e+00)	Acc@1  47.66 ( 48.64)	Acc@5  81.25 ( 80.16)
Epoch: [7][340/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.8642e+00 (1.8720e+00)	Acc@1  50.78 ( 48.65)	Acc@5  75.78 ( 80.15)
Epoch: [7][350/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.001)	Loss 2.1490e+00 (1.8745e+00)	Acc@1  45.31 ( 48.65)	Acc@5  75.78 ( 80.12)
Epoch: [7][360/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.001)	Loss 2.0357e+00 (1.8759e+00)	Acc@1  39.84 ( 48.62)	Acc@5  80.47 ( 80.08)
Epoch: [7][370/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.9652e+00 (1.8761e+00)	Acc@1  48.44 ( 48.62)	Acc@5  80.47 ( 80.11)
Epoch: [7][380/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.7313e+00 (1.8740e+00)	Acc@1  53.91 ( 48.64)	Acc@5  83.59 ( 80.15)
Epoch: [7][390/391]	Time  0.028 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.7877e+00 (1.8745e+00)	Acc@1  51.25 ( 48.66)	Acc@5  78.75 ( 80.11)
## e[7] optimizer.zero_grad (sum) time: 0.2856912612915039
## e[7]       loss.backward (sum) time: 4.172940731048584
## e[7]      optimizer.step (sum) time: 1.8537249565124512
## epoch[7] training(only) time: 16.49325728416443
# Switched to evaluate mode...
Test: [  0/100]	Time  0.151 ( 0.151)	Loss 2.0875e+00 (2.0875e+00)	Acc@1  45.00 ( 45.00)	Acc@5  80.00 ( 80.00)
Test: [ 10/100]	Time  0.024 ( 0.035)	Loss 2.2773e+00 (2.0687e+00)	Acc@1  45.00 ( 47.18)	Acc@5  76.00 ( 78.00)
Test: [ 20/100]	Time  0.023 ( 0.030)	Loss 1.9239e+00 (2.0256e+00)	Acc@1  49.00 ( 47.38)	Acc@5  80.00 ( 79.05)
Test: [ 30/100]	Time  0.021 ( 0.028)	Loss 2.1626e+00 (2.0333e+00)	Acc@1  42.00 ( 47.26)	Acc@5  75.00 ( 78.74)
Test: [ 40/100]	Time  0.024 ( 0.026)	Loss 2.1557e+00 (2.0533e+00)	Acc@1  41.00 ( 46.37)	Acc@5  76.00 ( 78.85)
Test: [ 50/100]	Time  0.024 ( 0.025)	Loss 1.8346e+00 (2.0670e+00)	Acc@1  50.00 ( 46.22)	Acc@5  82.00 ( 78.47)
Test: [ 60/100]	Time  0.024 ( 0.025)	Loss 1.9581e+00 (2.0552e+00)	Acc@1  46.00 ( 46.25)	Acc@5  81.00 ( 78.49)
Test: [ 70/100]	Time  0.024 ( 0.025)	Loss 2.3053e+00 (2.0625e+00)	Acc@1  40.00 ( 46.10)	Acc@5  73.00 ( 78.20)
Test: [ 80/100]	Time  0.020 ( 0.024)	Loss 2.5434e+00 (2.0660e+00)	Acc@1  40.00 ( 45.84)	Acc@5  67.00 ( 78.14)
Test: [ 90/100]	Time  0.024 ( 0.024)	Loss 2.1771e+00 (2.0621e+00)	Acc@1  46.00 ( 45.91)	Acc@5  76.00 ( 78.12)
 * Acc@1 46.030 Acc@5 78.050
### epoch[7] execution time: 18.973820209503174
EPOCH 8
i:   0, name:           module.stem.0.weight  changing lr from: 0.095413337864757808   to: 0.093745593533647337
i:   1, name:             module.stem.0.bias  changing lr from: 0.095493265000109517   to: 0.093848769614600161
i:   2, name:           module.stem.1.weight  changing lr from: 0.095571879612025609   to: 0.093950269050138258
i:   3, name:             module.stem.1.bias  changing lr from: 0.095649205742293145   to: 0.094050121995939637
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.095725266955318633   to: 0.094148358027963938
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.095800086348048916   to: 0.094245006153783450
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.095873686559688531   to: 0.094340094823711307
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.095946089781216840   to: 0.094433651941729368
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.096017317764708440   to: 0.094525704876217642
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.096087391832460720   to: 0.094616280470487577
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.096156332885931714   to: 0.094705405053121750
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.096224161414492068   to: 0.094793104448121973
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.096290897503994138   to: 0.094879403984868563
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.096356560845162254   to: 0.094964328507892992
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.096421170741806853   to: 0.095047902386466585
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.096484746118866538   to: 0.095130149524007890
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.096547305530280625   to: 0.095211093367311053
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.096608867166696200   to: 0.095290756915597880
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.096669448863012417   to: 0.095369162729396398
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.096729068105765356   to: 0.095446332939248341
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.096787742040356742   to: 0.095522289254248091
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.096845487478129447   to: 0.095597052970416083
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.096902320903292941   to: 0.095670644978908981
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.096958258479701673   to: 0.095743085774069384
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.097013316057489377   to: 0.095814395461317717
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.097067509179562333   to: 0.095884593764888948
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.097120853087954109   to: 0.095953700035416534
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.097173362730045176   to: 0.096021733257366737
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.097225052764649711   to: 0.096088712056325104
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.097275937567972481   to: 0.096154654706138445
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.097326031239438712   to: 0.096219579135914335
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.097375347607399215   to: 0.096283502936880955
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.097423900234713728   to: 0.096346443369109677
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.097471702424214754   to: 0.096408417368102864
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.097518767224054670   to: 0.096469441551249355
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.097565107432938336   to: 0.096529532224150116
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.097610735605243790   to: 0.096588705386816465
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.097655664056033292   to: 0.096646976739743054
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.097699904865957199   to: 0.096704361689858326
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.097743469886052703   to: 0.096760875356354359
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.097786370742440065   to: 0.096816532576398689
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.097828618840918105   to: 0.096871347910730266
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.097870225371461450   to: 0.096925335649141686
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.097911201312621432   to: 0.096978509815850031
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.097951557435833003   to: 0.097030884174758414
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.097991304309629157   to: 0.097082472234610334
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.098030452303765531   to: 0.097133287254039039
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.098069011593256719   to: 0.097183342246513815
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.098106992162326059   to: 0.097232649985185327
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.098144403808271385   to: 0.097281223007632159
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.098181256145247836   to: 0.097329073620510048
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.098217558607970171   to: 0.097376213904106432
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.098253320455335802   to: 0.097422655716801532
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.098288550773970765   to: 0.097468410699438401
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.098323258481699857   to: 0.097513490279603376
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.098357452330942910   to: 0.097557905675818901
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.098391140912038794   to: 0.097601667901650660
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.098424332656498442   to: 0.097644787769730429
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.098457035840188875   to: 0.097687275895696521
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.098489258586449371   to: 0.097729142702053629
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.098521008869141530   to: 0.097770398421953592
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.098552294515634409   to: 0.097811053102898532
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.098583123209726550   to: 0.097851116610368410
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.098613502494505789   to: 0.097890598631374059
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.098643439775148625   to: 0.097929508677937552
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.098672942321660351   to: 0.097967856090501293
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.098702017271557030   to: 0.098005650041267323
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.098730671632490996   to: 0.098042899537468239
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.098758912284820685   to: 0.098079613424571249
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.098786745984126456   to: 0.098115800389416641
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.098814179363673232   to: 0.098151468963292077
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.098841218936821226   to: 0.098186627524944073
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.098867871099386079   to: 0.098221284303527862
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.098894142131949220   to: 0.098255447381497149
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.098920038202119781   to: 0.098289124697434727
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.098945565366749019   to: 0.098322324048825460
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.098970729574098248   to: 0.098355053094772549
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.098995536665961531   to: 0.098387319358658618
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.099019992379743710   to: 0.098419130230752411
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.099044102350495197   to: 0.098450492970762568
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.099067872112904160   to: 0.098481414710339263
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.099091307103247248   to: 0.098511902455525158
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.099114412661299556   to: 0.098541963089156359
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.099137194032204917   to: 0.098571603373214758
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.099159656368307245   to: 0.098600829951132576
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.099181804730943873   to: 0.098629649350050114
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.099203644092201670   to: 0.098658067983027842
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.099225179336636826   to: 0.098686092151213586
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.099246415262958881   to: 0.098713728045966009
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.099267356585680103   to: 0.098740981750935042
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.099288007936730677   to: 0.098767859244100212
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.099308373867040667   to: 0.098794366399768088
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.099328458848089302   to: 0.098820508990529091
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.099348267273422414   to: 0.098846292689175219
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.099367803460138709   to: 0.098871723070578857
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.099387071650345424   to: 0.098896805613534020
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.099406076012584263   to: 0.098921545702560398
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.099424820643228023   to: 0.098945948629671390
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.099443309567848734   to: 0.098970019596106434
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.099461546742557694   to: 0.098993763714028821
i: 100, name:           module.conv10.weight  changing lr from: 0.099479536055318438   to: 0.099017186008189345
i: 101, name:             module.conv10.bias  changing lr from: 0.099497281327232595   to: 0.099040291417556825



# Switched to train mode...
Epoch: [8][  0/391]	Time  0.202 ( 0.202)	Data  0.151 ( 0.151)	Loss 1.5349e+00 (1.5349e+00)	Acc@1  59.38 ( 59.38)	Acc@5  86.72 ( 86.72)
Epoch: [8][ 10/391]	Time  0.042 ( 0.057)	Data  0.001 ( 0.015)	Loss 1.7882e+00 (1.7584e+00)	Acc@1  51.56 ( 51.35)	Acc@5  83.59 ( 83.31)
Epoch: [8][ 20/391]	Time  0.042 ( 0.050)	Data  0.001 ( 0.008)	Loss 1.8971e+00 (1.7802e+00)	Acc@1  46.09 ( 50.74)	Acc@5  76.56 ( 82.37)
Epoch: [8][ 30/391]	Time  0.040 ( 0.047)	Data  0.001 ( 0.006)	Loss 1.7404e+00 (1.7789e+00)	Acc@1  50.00 ( 50.63)	Acc@5  84.38 ( 82.61)
Epoch: [8][ 40/391]	Time  0.046 ( 0.046)	Data  0.001 ( 0.005)	Loss 1.5749e+00 (1.7791e+00)	Acc@1  57.03 ( 50.27)	Acc@5  87.50 ( 82.51)
Epoch: [8][ 50/391]	Time  0.043 ( 0.045)	Data  0.001 ( 0.004)	Loss 1.5665e+00 (1.7684e+00)	Acc@1  64.06 ( 50.87)	Acc@5  87.50 ( 82.78)
Epoch: [8][ 60/391]	Time  0.041 ( 0.045)	Data  0.001 ( 0.003)	Loss 1.7206e+00 (1.7661e+00)	Acc@1  53.12 ( 50.85)	Acc@5  85.16 ( 82.71)
Epoch: [8][ 70/391]	Time  0.044 ( 0.044)	Data  0.001 ( 0.003)	Loss 1.8130e+00 (1.7669e+00)	Acc@1  51.56 ( 50.70)	Acc@5  82.03 ( 82.58)
Epoch: [8][ 80/391]	Time  0.044 ( 0.044)	Data  0.001 ( 0.003)	Loss 1.7118e+00 (1.7612e+00)	Acc@1  53.91 ( 50.84)	Acc@5  84.38 ( 82.62)
Epoch: [8][ 90/391]	Time  0.040 ( 0.044)	Data  0.001 ( 0.003)	Loss 1.9386e+00 (1.7617e+00)	Acc@1  53.12 ( 50.95)	Acc@5  75.00 ( 82.45)
Epoch: [8][100/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.6606e+00 (1.7626e+00)	Acc@1  52.34 ( 50.87)	Acc@5  83.59 ( 82.36)
Epoch: [8][110/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.9214e+00 (1.7722e+00)	Acc@1  53.91 ( 50.75)	Acc@5  75.00 ( 82.14)
Epoch: [8][120/391]	Time  0.044 ( 0.043)	Data  0.001 ( 0.002)	Loss 2.0489e+00 (1.7710e+00)	Acc@1  49.22 ( 50.85)	Acc@5  77.34 ( 82.06)
Epoch: [8][130/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.8633e+00 (1.7747e+00)	Acc@1  50.78 ( 50.89)	Acc@5  76.56 ( 82.02)
Epoch: [8][140/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.7556e+00 (1.7766e+00)	Acc@1  48.44 ( 50.90)	Acc@5  82.03 ( 82.05)
Epoch: [8][150/391]	Time  0.044 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.6376e+00 (1.7776e+00)	Acc@1  55.47 ( 50.86)	Acc@5  81.25 ( 81.98)
Epoch: [8][160/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.7159e+00 (1.7828e+00)	Acc@1  53.12 ( 50.80)	Acc@5  75.00 ( 81.83)
Epoch: [8][170/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.8052e+00 (1.7831e+00)	Acc@1  48.44 ( 50.79)	Acc@5  83.59 ( 81.83)
Epoch: [8][180/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.7103e+00 (1.7804e+00)	Acc@1  46.88 ( 50.79)	Acc@5  80.47 ( 81.84)
Epoch: [8][190/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.5219e+00 (1.7789e+00)	Acc@1  53.91 ( 50.80)	Acc@5  89.84 ( 81.93)
Epoch: [8][200/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.8670e+00 (1.7796e+00)	Acc@1  46.88 ( 50.76)	Acc@5  75.78 ( 81.87)
Epoch: [8][210/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.5787e+00 (1.7765e+00)	Acc@1  53.91 ( 50.82)	Acc@5  84.38 ( 81.96)
Epoch: [8][220/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.0122e+00 (1.7769e+00)	Acc@1  49.22 ( 50.85)	Acc@5  81.25 ( 81.92)
Epoch: [8][230/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.7518e+00 (1.7764e+00)	Acc@1  47.66 ( 50.80)	Acc@5  82.03 ( 81.92)
Epoch: [8][240/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.9391e+00 (1.7746e+00)	Acc@1  50.78 ( 50.87)	Acc@5  78.12 ( 81.93)
Epoch: [8][250/391]	Time  0.041 ( 0.042)	Data  0.002 ( 0.002)	Loss 1.6907e+00 (1.7747e+00)	Acc@1  57.81 ( 50.87)	Acc@5  81.25 ( 81.87)
Epoch: [8][260/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.9771e+00 (1.7749e+00)	Acc@1  43.75 ( 50.83)	Acc@5  79.69 ( 81.88)
Epoch: [8][270/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.8248e+00 (1.7729e+00)	Acc@1  52.34 ( 50.92)	Acc@5  80.47 ( 81.92)
Epoch: [8][280/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.8022e+00 (1.7775e+00)	Acc@1  50.78 ( 50.80)	Acc@5  79.69 ( 81.88)
Epoch: [8][290/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.6998e+00 (1.7759e+00)	Acc@1  52.34 ( 50.84)	Acc@5  81.25 ( 81.92)
Epoch: [8][300/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.8773e+00 (1.7789e+00)	Acc@1  44.53 ( 50.81)	Acc@5  80.47 ( 81.83)
Epoch: [8][310/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.9090e+00 (1.7774e+00)	Acc@1  47.66 ( 50.88)	Acc@5  83.59 ( 81.87)
Epoch: [8][320/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.6240e+00 (1.7762e+00)	Acc@1  55.47 ( 50.94)	Acc@5  87.50 ( 81.89)
Epoch: [8][330/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.9567e+00 (1.7758e+00)	Acc@1  46.88 ( 50.96)	Acc@5  75.78 ( 81.89)
Epoch: [8][340/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.5868e+00 (1.7750e+00)	Acc@1  57.03 ( 51.02)	Acc@5  85.16 ( 81.91)
Epoch: [8][350/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.7404e+00 (1.7764e+00)	Acc@1  57.03 ( 50.99)	Acc@5  81.25 ( 81.86)
Epoch: [8][360/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.5609e+00 (1.7766e+00)	Acc@1  56.25 ( 51.00)	Acc@5  88.28 ( 81.86)
Epoch: [8][370/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.7788e+00 (1.7785e+00)	Acc@1  53.12 ( 50.99)	Acc@5  81.25 ( 81.82)
Epoch: [8][380/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.6774e+00 (1.7792e+00)	Acc@1  56.25 ( 50.97)	Acc@5  83.59 ( 81.81)
Epoch: [8][390/391]	Time  0.030 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.9431e+00 (1.7786e+00)	Acc@1  45.00 ( 50.96)	Acc@5  77.50 ( 81.84)
## e[8] optimizer.zero_grad (sum) time: 0.2856266498565674
## e[8]       loss.backward (sum) time: 4.176384687423706
## e[8]      optimizer.step (sum) time: 1.8504478931427002
## epoch[8] training(only) time: 16.496138095855713
# Switched to evaluate mode...
Test: [  0/100]	Time  0.155 ( 0.155)	Loss 2.0959e+00 (2.0959e+00)	Acc@1  50.00 ( 50.00)	Acc@5  75.00 ( 75.00)
Test: [ 10/100]	Time  0.024 ( 0.035)	Loss 2.0383e+00 (1.9273e+00)	Acc@1  47.00 ( 49.00)	Acc@5  80.00 ( 79.45)
Test: [ 20/100]	Time  0.022 ( 0.030)	Loss 1.6358e+00 (1.8953e+00)	Acc@1  52.00 ( 48.81)	Acc@5  85.00 ( 80.90)
Test: [ 30/100]	Time  0.021 ( 0.027)	Loss 1.8410e+00 (1.9235e+00)	Acc@1  48.00 ( 49.03)	Acc@5  80.00 ( 80.42)
Test: [ 40/100]	Time  0.022 ( 0.025)	Loss 2.0443e+00 (1.9253e+00)	Acc@1  49.00 ( 48.68)	Acc@5  76.00 ( 80.32)
Test: [ 50/100]	Time  0.017 ( 0.025)	Loss 1.7693e+00 (1.9381e+00)	Acc@1  51.00 ( 48.33)	Acc@5  80.00 ( 79.59)
Test: [ 60/100]	Time  0.022 ( 0.024)	Loss 1.7988e+00 (1.9180e+00)	Acc@1  46.00 ( 48.74)	Acc@5  86.00 ( 79.89)
Test: [ 70/100]	Time  0.018 ( 0.023)	Loss 2.0460e+00 (1.9220e+00)	Acc@1  48.00 ( 48.65)	Acc@5  77.00 ( 79.75)
Test: [ 80/100]	Time  0.029 ( 0.023)	Loss 2.1158e+00 (1.9271e+00)	Acc@1  47.00 ( 48.48)	Acc@5  77.00 ( 79.69)
Test: [ 90/100]	Time  0.022 ( 0.023)	Loss 2.0817e+00 (1.9238e+00)	Acc@1  46.00 ( 48.55)	Acc@5  77.00 ( 79.64)
 * Acc@1 48.510 Acc@5 79.730
### epoch[8] execution time: 18.820866107940674
EPOCH 9
i:   0, name:           module.stem.0.weight  changing lr from: 0.093745593533647337   to: 0.091879240657579200
i:   1, name:             module.stem.0.bias  changing lr from: 0.093848769614600161   to: 0.092008088001103452
i:   2, name:           module.stem.1.weight  changing lr from: 0.093950269050138258   to: 0.092134866789770550
i:   3, name:             module.stem.1.bias  changing lr from: 0.094050121995939637   to: 0.092259613430003634
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.094148358027963938   to: 0.092382363655977906
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.094245006153783450   to: 0.092503152541697720
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.094340094823711307   to: 0.092622014512904804
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.094433651941729368   to: 0.092738983358816196
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.094525704876217642   to: 0.092854092243691844
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.094616280470487577   to: 0.092967373718231272
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.094705405053121750   to: 0.093078859730798949
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.094793104448121973   to: 0.093188581638478832
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.094879403984868563   to: 0.093296570217957939
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.094964328507892992   to: 0.093402855676239530
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.095047902386466585   to: 0.093507467661186561
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.095130149524007890   to: 0.093610435271895887
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.095211093367311053   to: 0.093711787068904318
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.095290756915597880   to: 0.093811551084227340
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.095369162729396398   to: 0.093909754831231707
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.095446332939248341   to: 0.094006425314343112
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.095522289254248091   to: 0.094101589038590130
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.095597052970416083   to: 0.094195272018985976
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.095670644978908981   to: 0.094287499789749443
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.095743085774069384   to: 0.094378297413366702
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.095814395461317717   to: 0.094467689489495410
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.095884593764888948   to: 0.094555700163712911
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.095953700035416534   to: 0.094642353136110191
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.096021733257366737   to: 0.094727671669733601
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.096088712056325104   to: 0.094811678598875682
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.096154654706138445   to: 0.094894396337217482
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.096219579135914335   to: 0.094975846885823903
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.096283502936880955   to: 0.095056051840994138
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.096346443369109677   to: 0.095135032401969022
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.096408417368102864   to: 0.095212809378497520
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.096469441551249355   to: 0.095289403198263942
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.096529532224150116   to: 0.095364833914178104
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.096588705386816465   to: 0.095439121211530573
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.096646976739743054   to: 0.095512284415014637
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.096704361689858326   to: 0.095584342495617203
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.096760875356354359   to: 0.095655314077380815
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.096816532576398689   to: 0.095725217444038280
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.096871347910730266   to: 0.095794070545522580
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.096925335649141686   to: 0.095861891004353411
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.096978509815850031   to: 0.095928696121902857
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.097030884174758414   to: 0.095994502884541810
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.097082472234610334   to: 0.096059327969669484
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.097133287254039039   to: 0.096123187751627370
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.097183342246513815   to: 0.096186098307500412
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.097232649985185327   to: 0.096248075422806501
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.097281223007632159   to: 0.096309134597076851
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.097329073620510048   to: 0.096369291049328773
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.097376213904106432   to: 0.096428559723432741
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.097422655716801532   to: 0.096486955293375976
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.097468410699438401   to: 0.096544492168423729
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.097513490279603376   to: 0.096601184498180892
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.097557905675818901   to: 0.096657046177555023
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.097601667901650660   to: 0.096712090851622870
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.097644787769730429   to: 0.096766331920402390
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.097687275895696521   to: 0.096819782543531380
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.097729142702053629   to: 0.096872455644855096
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.097770398421953592   to: 0.096924363916924078
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.097811053102898532   to: 0.096975519825404088
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.097851116610368410   to: 0.097025935613399686
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.097890598631374059   to: 0.097075623305693193
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.097929508677937552   to: 0.097124594712900386
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.097967856090501293   to: 0.097172861435544891
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.098005650041267323   to: 0.097220434868052374
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.098042899537468239   to: 0.097267326202666454
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.098079613424571249   to: 0.097313546433287476
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.098115800389416641   to: 0.097359106359236003
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.098151468963292077   to: 0.097404016588942099
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.098186627524944073   to: 0.097448287543562162
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.098221284303527862   to: 0.097491929460524429
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.098255447381497149   to: 0.097534952397004743
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.098289124697434727   to: 0.097577366233333893
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.098322324048825460   to: 0.097619180676337736
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.098355053094772549   to: 0.097660405262611688
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.098387319358658618   to: 0.097701049361730435
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.098419130230752411   to: 0.097741122179394735
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.098450492970762568   to: 0.097780632760515823
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.098481414710339263   to: 0.097819589992239483
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.098511902455525158   to: 0.097858002606910133
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.098541963089156359   to: 0.097895879184976761
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.098571603373214758   to: 0.097933228157841556
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.098600829951132576   to: 0.097970057810652433
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.098629649350050114   to: 0.098006376285040497
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.098658067983027842   to: 0.098042191581803759
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.098686092151213586   to: 0.098077511563537945
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.098713728045966009   to: 0.098112343957215534
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.098740981750935042   to: 0.098146696356714094
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.098767859244100212   to: 0.098180576225294913
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.098794366399768088   to: 0.098213990898032830
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.098820508990529091   to: 0.098246947584198538
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.098846292689175219   to: 0.098279453369593803
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.098871723070578857   to: 0.098311515218841072
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.098896805613534020   to: 0.098343139977628100
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.098921545702560398   to: 0.098374334374908445
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.098945948629671390   to: 0.098405105025059086
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.098970019596106434   to: 0.098435458429995445
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.098993763714028821   to: 0.098465400981245288
i: 100, name:           module.conv10.weight  changing lr from: 0.099017186008189345   to: 0.098494938961981873
i: 101, name:             module.conv10.bias  changing lr from: 0.099040291417556825   to: 0.098524078549017458



# Switched to train mode...
Epoch: [9][  0/391]	Time  0.207 ( 0.207)	Data  0.158 ( 0.158)	Loss 1.7414e+00 (1.7414e+00)	Acc@1  50.78 ( 50.78)	Acc@5  82.03 ( 82.03)
Epoch: [9][ 10/391]	Time  0.042 ( 0.058)	Data  0.001 ( 0.015)	Loss 1.6011e+00 (1.6256e+00)	Acc@1  56.25 ( 54.33)	Acc@5  78.91 ( 83.38)
Epoch: [9][ 20/391]	Time  0.040 ( 0.050)	Data  0.001 ( 0.009)	Loss 1.7015e+00 (1.7014e+00)	Acc@1  46.09 ( 52.75)	Acc@5  82.03 ( 81.99)
Epoch: [9][ 30/391]	Time  0.042 ( 0.047)	Data  0.001 ( 0.006)	Loss 1.8399e+00 (1.6830e+00)	Acc@1  46.88 ( 53.07)	Acc@5  81.25 ( 82.96)
Epoch: [9][ 40/391]	Time  0.039 ( 0.045)	Data  0.001 ( 0.005)	Loss 1.7197e+00 (1.6796e+00)	Acc@1  53.91 ( 53.70)	Acc@5  85.16 ( 83.21)
Epoch: [9][ 50/391]	Time  0.043 ( 0.045)	Data  0.001 ( 0.004)	Loss 1.6867e+00 (1.6769e+00)	Acc@1  53.12 ( 53.39)	Acc@5  82.03 ( 83.16)
Epoch: [9][ 60/391]	Time  0.040 ( 0.044)	Data  0.001 ( 0.004)	Loss 1.8679e+00 (1.6878e+00)	Acc@1  46.09 ( 53.28)	Acc@5  81.25 ( 83.00)
Epoch: [9][ 70/391]	Time  0.040 ( 0.044)	Data  0.001 ( 0.003)	Loss 1.8413e+00 (1.6929e+00)	Acc@1  47.66 ( 52.96)	Acc@5  80.47 ( 82.83)
Epoch: [9][ 80/391]	Time  0.040 ( 0.044)	Data  0.001 ( 0.003)	Loss 1.7489e+00 (1.6924e+00)	Acc@1  52.34 ( 53.12)	Acc@5  82.03 ( 82.96)
Epoch: [9][ 90/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.003)	Loss 1.6486e+00 (1.6980e+00)	Acc@1  53.91 ( 53.02)	Acc@5  81.25 ( 82.86)
Epoch: [9][100/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.003)	Loss 1.9716e+00 (1.6982e+00)	Acc@1  46.09 ( 52.88)	Acc@5  79.69 ( 82.89)
Epoch: [9][110/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.7912e+00 (1.6949e+00)	Acc@1  50.78 ( 52.89)	Acc@5  82.81 ( 82.92)
Epoch: [9][120/391]	Time  0.039 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.8921e+00 (1.6955e+00)	Acc@1  48.44 ( 52.94)	Acc@5  84.38 ( 82.97)
Epoch: [9][130/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.5737e+00 (1.6926e+00)	Acc@1  57.03 ( 52.97)	Acc@5  87.50 ( 83.06)
Epoch: [9][140/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.7651e+00 (1.6936e+00)	Acc@1  52.34 ( 52.88)	Acc@5  80.47 ( 83.08)
Epoch: [9][150/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.5642e+00 (1.6927e+00)	Acc@1  53.91 ( 52.99)	Acc@5  86.72 ( 83.08)
Epoch: [9][160/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.7548e+00 (1.6920e+00)	Acc@1  54.69 ( 52.99)	Acc@5  80.47 ( 83.09)
Epoch: [9][170/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.5942e+00 (1.6928e+00)	Acc@1  50.78 ( 52.91)	Acc@5  85.16 ( 83.13)
Epoch: [9][180/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.6307e+00 (1.6959e+00)	Acc@1  54.69 ( 52.75)	Acc@5  79.69 ( 83.06)
Epoch: [9][190/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.4756e+00 (1.6958e+00)	Acc@1  57.81 ( 52.80)	Acc@5  84.38 ( 83.01)
Epoch: [9][200/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.7107e+00 (1.6956e+00)	Acc@1  57.03 ( 52.88)	Acc@5  82.81 ( 83.12)
Epoch: [9][210/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.6759e+00 (1.6979e+00)	Acc@1  47.66 ( 52.83)	Acc@5  84.38 ( 83.05)
Epoch: [9][220/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.7135e+00 (1.6979e+00)	Acc@1  48.44 ( 52.79)	Acc@5  82.03 ( 83.05)
Epoch: [9][230/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.7744e+00 (1.6997e+00)	Acc@1  52.34 ( 52.74)	Acc@5  80.47 ( 83.03)
Epoch: [9][240/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.5820e+00 (1.6997e+00)	Acc@1  52.34 ( 52.68)	Acc@5  83.59 ( 83.08)
Epoch: [9][250/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.6238e+00 (1.6961e+00)	Acc@1  55.47 ( 52.81)	Acc@5  83.59 ( 83.12)
Epoch: [9][260/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.7918e+00 (1.6990e+00)	Acc@1  51.56 ( 52.72)	Acc@5  82.81 ( 83.08)
Epoch: [9][270/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.6980e+00 (1.7009e+00)	Acc@1  49.22 ( 52.62)	Acc@5  82.81 ( 83.07)
Epoch: [9][280/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.8297e+00 (1.7013e+00)	Acc@1  47.66 ( 52.63)	Acc@5  84.38 ( 83.11)
Epoch: [9][290/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.9189e+00 (1.7011e+00)	Acc@1  51.56 ( 52.68)	Acc@5  76.56 ( 83.10)
Epoch: [9][300/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.7160e+00 (1.7037e+00)	Acc@1  57.03 ( 52.60)	Acc@5  83.59 ( 83.02)
Epoch: [9][310/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.8079e+00 (1.7035e+00)	Acc@1  53.91 ( 52.60)	Acc@5  80.47 ( 83.00)
Epoch: [9][320/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.6270e+00 (1.7033e+00)	Acc@1  47.66 ( 52.58)	Acc@5  84.38 ( 83.01)
Epoch: [9][330/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.5579e+00 (1.7022e+00)	Acc@1  61.72 ( 52.61)	Acc@5  83.59 ( 83.03)
Epoch: [9][340/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.5201e+00 (1.7018e+00)	Acc@1  54.69 ( 52.58)	Acc@5  86.72 ( 83.04)
Epoch: [9][350/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.6314e+00 (1.7012e+00)	Acc@1  54.69 ( 52.58)	Acc@5  83.59 ( 83.06)
Epoch: [9][360/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.6723e+00 (1.7025e+00)	Acc@1  61.72 ( 52.60)	Acc@5  81.25 ( 83.03)
Epoch: [9][370/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.6828e+00 (1.7019e+00)	Acc@1  56.25 ( 52.60)	Acc@5  85.94 ( 83.05)
Epoch: [9][380/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.7400e+00 (1.7017e+00)	Acc@1  51.56 ( 52.65)	Acc@5  85.16 ( 83.04)
Epoch: [9][390/391]	Time  0.036 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.6708e+00 (1.6988e+00)	Acc@1  51.25 ( 52.71)	Acc@5  83.75 ( 83.11)
## e[9] optimizer.zero_grad (sum) time: 0.2855558395385742
## e[9]       loss.backward (sum) time: 4.170839071273804
## e[9]      optimizer.step (sum) time: 1.8752262592315674
## epoch[9] training(only) time: 16.43133568763733
# Switched to evaluate mode...
Test: [  0/100]	Time  0.150 ( 0.150)	Loss 1.9276e+00 (1.9276e+00)	Acc@1  47.00 ( 47.00)	Acc@5  77.00 ( 77.00)
Test: [ 10/100]	Time  0.023 ( 0.034)	Loss 2.0423e+00 (2.0432e+00)	Acc@1  43.00 ( 45.82)	Acc@5  79.00 ( 77.73)
Test: [ 20/100]	Time  0.024 ( 0.028)	Loss 1.9219e+00 (2.0272e+00)	Acc@1  47.00 ( 46.86)	Acc@5  82.00 ( 78.05)
Test: [ 30/100]	Time  0.019 ( 0.026)	Loss 2.0602e+00 (2.0522e+00)	Acc@1  47.00 ( 46.00)	Acc@5  79.00 ( 77.68)
Test: [ 40/100]	Time  0.019 ( 0.024)	Loss 1.9388e+00 (2.0403e+00)	Acc@1  49.00 ( 45.93)	Acc@5  80.00 ( 77.83)
Test: [ 50/100]	Time  0.024 ( 0.023)	Loss 2.0061e+00 (2.0508e+00)	Acc@1  53.00 ( 46.10)	Acc@5  76.00 ( 77.51)
Test: [ 60/100]	Time  0.018 ( 0.023)	Loss 1.8468e+00 (2.0444e+00)	Acc@1  46.00 ( 46.02)	Acc@5  81.00 ( 77.66)
Test: [ 70/100]	Time  0.023 ( 0.023)	Loss 2.0467e+00 (2.0502e+00)	Acc@1  49.00 ( 46.11)	Acc@5  75.00 ( 77.63)
Test: [ 80/100]	Time  0.025 ( 0.022)	Loss 2.2143e+00 (2.0589e+00)	Acc@1  46.00 ( 45.94)	Acc@5  73.00 ( 77.54)
Test: [ 90/100]	Time  0.022 ( 0.022)	Loss 2.3693e+00 (2.0573e+00)	Acc@1  40.00 ( 46.16)	Acc@5  69.00 ( 77.34)
 * Acc@1 46.130 Acc@5 77.370
### epoch[9] execution time: 18.694685459136963
EPOCH 10
i:   0, name:           module.stem.0.weight  changing lr from: 0.091879240657579200   to: 0.089822950858548800
i:   1, name:             module.stem.0.bias  changing lr from: 0.092008088001103452   to: 0.089979647855115114
i:   2, name:           module.stem.1.weight  changing lr from: 0.092134866789770550   to: 0.090133863929493949
i:   3, name:             module.stem.1.bias  changing lr from: 0.092259613430003634   to: 0.090285641642810638
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.092382363655977906   to: 0.090435022808959903
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.092503152541697720   to: 0.090582048506500451
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.092622014512904804   to: 0.090726759090455314
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.092738983358816196   to: 0.090869194204012904
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.092854092243691844   to: 0.091009392790123031
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.092967373718231272   to: 0.091147393102983795
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.093078859730798949   to: 0.091283232719414964
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.093188581638478832   to: 0.091416948550114022
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.093296570217957939   to: 0.091548576850791513
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.093402855676239530   to: 0.091678153233182832
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.093507467661186561   to: 0.091805712675933501
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.093610435271895887   to: 0.091931289535355870
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.093711787068904318   to: 0.092054917556054869
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.093811551084227340   to: 0.092176629881421376
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.093909754831231707   to: 0.092296459063991365
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.094006425314343112   to: 0.092414437075669750
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.094101589038590130   to: 0.092530595317817932
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.094195272018985976   to: 0.092644964631204044
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.094287499789749443   to: 0.092757575305815396
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.094378297413366702   to: 0.092868457090532680
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.094467689489495410   to: 0.092977639202665760
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.094555700163712911   to: 0.093085150337350653
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.094642353136110191   to: 0.093191018676808152
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.094727671669733601   to: 0.093295271899464072
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.094811678598875682   to: 0.093397937188931399
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.094894396337217482   to: 0.093499041242855033
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.094975846885823903   to: 0.093598610281619365
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.095056051840994138   to: 0.093696670056919673
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.095135032401969022   to: 0.093793245860197924
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.095212809378497520   to: 0.093888362530943834
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.095289403198263942   to: 0.093982044464862219
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.095364833914178104   to: 0.094074315621907545
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.095439121211530573   to: 0.094165199534186825
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.095512284415014637   to: 0.094254719313731986
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.095584342495617203   to: 0.094342897660142908
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.095655314077380815   to: 0.094429756868102246
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.095725217444038280   to: 0.094515318834763745
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.095794070545522580   to: 0.094599605067014703
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.095861891004353411   to: 0.094682636688614763
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.095928696121902857   to: 0.094764434447211721
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.095994502884541810   to: 0.094845018721236185
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.096059327969669484   to: 0.094924409526676606
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.096123187751627370   to: 0.095002626523735811
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.096186098307500412   to: 0.095079689023370925
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.096248075422806501   to: 0.095155615993717871
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.096309134597076851   to: 0.095230426066402404
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.096369291049328773   to: 0.095304137542738657
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.096428559723432741   to: 0.095376768399817347
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.096486955293375976   to: 0.095448336296484748
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.096544492168423729   to: 0.095518858579214327
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.096601184498180892   to: 0.095588352287872269
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.096657046177555023   to: 0.095656834161378823
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.096712090851622870   to: 0.095724320643266927
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.096766331920402390   to: 0.095790827887139288
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.096819782543531380   to: 0.095856371762026202
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.096872455644855096   to: 0.095920967857645020
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.096924363916924078   to: 0.095984631489563224
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.096975519825404088   to: 0.096047377704266398
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.097025935613399686   to: 0.096109221284132684
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.097075623305693193   to: 0.096170176752315498
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.097124594712900386   to: 0.096230258377535516
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.097172861435544891   to: 0.096289480178783970
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.097220434868052374   to: 0.096347855929938331
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.097267326202666454   to: 0.096405399164292055
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.097313546433287476   to: 0.096462123178999812
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.097359106359236003   to: 0.096518041039439673
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.097404016588942099   to: 0.096573165583493450
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.097448287543562162   to: 0.096627509425747188
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.097491929460524429   to: 0.096681084961612318
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.097534952397004743   to: 0.096733904371369819
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.097577366233333893   to: 0.096785979624137930
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.097619180676337736   to: 0.096837322481765339
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.097660405262611688   to: 0.096887944502650897
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.097701049361730435   to: 0.096937857045491155
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.097741122179394735   to: 0.096987071272957234
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.097780632760515823   to: 0.097035598155302050
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.097819589992239483   to: 0.097083448473899325
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.097858002606910133   to: 0.097130632824715624
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.097895879184976761   to: 0.097177161621716482
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.097933228157841556   to: 0.097223045100208086
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.097970057810652433   to: 0.097268293320115426
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.098006376285040497   to: 0.097312916169198238
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.098042191581803759   to: 0.097356923366206050
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.098077511563537945   to: 0.097400324463973009
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.098112343957215534   to: 0.097443128852454083
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.098146696356714094   to: 0.097485345761703451
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.098180576225294913   to: 0.097526984264796363
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.098213990898032830   to: 0.097568053280695274
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.098246947584198538   to: 0.097608561577061548
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.098279453369593803   to: 0.097648517773013713
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.098311515218841072   to: 0.097687930341832985
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.098343139977628100   to: 0.097726807613617683
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.098374334374908445   to: 0.097765157777886774
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.098405105025059086   to: 0.097802988886134132
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.098435458429995445   to: 0.097840308854333979
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.098465400981245288   to: 0.097877125465398798
i: 100, name:           module.conv10.weight  changing lr from: 0.098494938961981873   to: 0.097913446371590537
i: 101, name:             module.conv10.bias  changing lr from: 0.098524078549017458   to: 0.097949279096885625



# Switched to train mode...
Epoch: [10][  0/391]	Time  0.201 ( 0.201)	Data  0.151 ( 0.151)	Loss 1.8770e+00 (1.8770e+00)	Acc@1  45.31 ( 45.31)	Acc@5  82.81 ( 82.81)
Epoch: [10][ 10/391]	Time  0.040 ( 0.057)	Data  0.001 ( 0.015)	Loss 1.4107e+00 (1.6278e+00)	Acc@1  60.94 ( 54.05)	Acc@5  85.94 ( 85.30)
Epoch: [10][ 20/391]	Time  0.045 ( 0.050)	Data  0.001 ( 0.008)	Loss 1.8348e+00 (1.6309e+00)	Acc@1  49.22 ( 53.46)	Acc@5  84.38 ( 84.90)
Epoch: [10][ 30/391]	Time  0.040 ( 0.047)	Data  0.001 ( 0.006)	Loss 1.5661e+00 (1.6144e+00)	Acc@1  64.06 ( 54.28)	Acc@5  87.50 ( 85.06)
Epoch: [10][ 40/391]	Time  0.041 ( 0.046)	Data  0.001 ( 0.005)	Loss 1.7116e+00 (1.6124e+00)	Acc@1  55.47 ( 54.31)	Acc@5  79.69 ( 85.04)
Epoch: [10][ 50/391]	Time  0.040 ( 0.045)	Data  0.001 ( 0.004)	Loss 1.5711e+00 (1.6369e+00)	Acc@1  55.47 ( 53.71)	Acc@5  81.25 ( 84.48)
Epoch: [10][ 60/391]	Time  0.042 ( 0.044)	Data  0.001 ( 0.004)	Loss 1.7164e+00 (1.6343e+00)	Acc@1  57.03 ( 54.15)	Acc@5  82.03 ( 84.35)
Epoch: [10][ 70/391]	Time  0.045 ( 0.044)	Data  0.001 ( 0.003)	Loss 1.5522e+00 (1.6259e+00)	Acc@1  58.59 ( 54.54)	Acc@5  85.94 ( 84.44)
Epoch: [10][ 80/391]	Time  0.042 ( 0.044)	Data  0.001 ( 0.003)	Loss 1.6624e+00 (1.6394e+00)	Acc@1  51.56 ( 54.24)	Acc@5  83.59 ( 84.19)
Epoch: [10][ 90/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.003)	Loss 1.7028e+00 (1.6394e+00)	Acc@1  52.34 ( 54.36)	Acc@5  82.03 ( 84.16)
Epoch: [10][100/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.003)	Loss 1.8199e+00 (1.6437e+00)	Acc@1  50.00 ( 54.24)	Acc@5  81.25 ( 84.11)
Epoch: [10][110/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.4904e+00 (1.6378e+00)	Acc@1  57.03 ( 54.45)	Acc@5  90.62 ( 84.15)
Epoch: [10][120/391]	Time  0.041 ( 0.043)	Data  0.002 ( 0.002)	Loss 1.8839e+00 (1.6406e+00)	Acc@1  49.22 ( 54.28)	Acc@5  81.25 ( 84.03)
Epoch: [10][130/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.5432e+00 (1.6408e+00)	Acc@1  55.47 ( 54.31)	Acc@5  85.94 ( 84.05)
Epoch: [10][140/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.5808e+00 (1.6388e+00)	Acc@1  60.94 ( 54.34)	Acc@5  84.38 ( 84.08)
Epoch: [10][150/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.3973e+00 (1.6284e+00)	Acc@1  60.16 ( 54.52)	Acc@5  85.94 ( 84.22)
Epoch: [10][160/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.4841e+00 (1.6285e+00)	Acc@1  55.47 ( 54.57)	Acc@5  89.06 ( 84.28)
Epoch: [10][170/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 2.0300e+00 (1.6283e+00)	Acc@1  50.00 ( 54.51)	Acc@5  79.69 ( 84.32)
Epoch: [10][180/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.7441e+00 (1.6288e+00)	Acc@1  52.34 ( 54.45)	Acc@5  81.25 ( 84.29)
Epoch: [10][190/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.6961e+00 (1.6286e+00)	Acc@1  50.00 ( 54.39)	Acc@5  83.59 ( 84.30)
Epoch: [10][200/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.6255e+00 (1.6273e+00)	Acc@1  53.91 ( 54.45)	Acc@5  78.12 ( 84.25)
Epoch: [10][210/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.6550e+00 (1.6271e+00)	Acc@1  50.78 ( 54.47)	Acc@5  85.94 ( 84.29)
Epoch: [10][220/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.4508e+00 (1.6288e+00)	Acc@1  58.59 ( 54.43)	Acc@5  87.50 ( 84.23)
Epoch: [10][230/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.6279e+00 (1.6289e+00)	Acc@1  53.91 ( 54.45)	Acc@5  84.38 ( 84.26)
Epoch: [10][240/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.4493e+00 (1.6270e+00)	Acc@1  62.50 ( 54.54)	Acc@5  86.72 ( 84.29)
Epoch: [10][250/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.6286e+00 (1.6256e+00)	Acc@1  60.16 ( 54.60)	Acc@5  82.81 ( 84.33)
Epoch: [10][260/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.5658e+00 (1.6256e+00)	Acc@1  56.25 ( 54.63)	Acc@5  85.94 ( 84.38)
Epoch: [10][270/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.5945e+00 (1.6248e+00)	Acc@1  55.47 ( 54.62)	Acc@5  83.59 ( 84.38)
Epoch: [10][280/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.3658e+00 (1.6233e+00)	Acc@1  67.97 ( 54.68)	Acc@5  88.28 ( 84.38)
Epoch: [10][290/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.5653e+00 (1.6280e+00)	Acc@1  58.59 ( 54.53)	Acc@5  87.50 ( 84.31)
Epoch: [10][300/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.5705e+00 (1.6263e+00)	Acc@1  57.81 ( 54.56)	Acc@5  82.81 ( 84.34)
Epoch: [10][310/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.8352e+00 (1.6276e+00)	Acc@1  48.44 ( 54.55)	Acc@5  82.81 ( 84.35)
Epoch: [10][320/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.4644e+00 (1.6284e+00)	Acc@1  57.81 ( 54.55)	Acc@5  88.28 ( 84.33)
Epoch: [10][330/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.6525e+00 (1.6297e+00)	Acc@1  52.34 ( 54.50)	Acc@5  85.16 ( 84.31)
Epoch: [10][340/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.2955e+00 (1.6274e+00)	Acc@1  65.62 ( 54.56)	Acc@5  87.50 ( 84.38)
Epoch: [10][350/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.5985e+00 (1.6281e+00)	Acc@1  52.34 ( 54.57)	Acc@5  84.38 ( 84.36)
Epoch: [10][360/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.5157e+00 (1.6298e+00)	Acc@1  53.91 ( 54.50)	Acc@5  88.28 ( 84.33)
Epoch: [10][370/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.5302e+00 (1.6311e+00)	Acc@1  53.91 ( 54.52)	Acc@5  85.16 ( 84.28)
Epoch: [10][380/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.7116e+00 (1.6329e+00)	Acc@1  46.88 ( 54.45)	Acc@5  87.50 ( 84.28)
Epoch: [10][390/391]	Time  0.030 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.7875e+00 (1.6329e+00)	Acc@1  48.75 ( 54.44)	Acc@5  81.25 ( 84.30)
## e[10] optimizer.zero_grad (sum) time: 0.28508687019348145
## e[10]       loss.backward (sum) time: 4.144092321395874
## e[10]      optimizer.step (sum) time: 1.83603835105896
## epoch[10] training(only) time: 16.523391246795654
# Switched to evaluate mode...
Test: [  0/100]	Time  0.154 ( 0.154)	Loss 2.0716e+00 (2.0716e+00)	Acc@1  50.00 ( 50.00)	Acc@5  78.00 ( 78.00)
Test: [ 10/100]	Time  0.022 ( 0.035)	Loss 2.0922e+00 (1.9650e+00)	Acc@1  47.00 ( 50.45)	Acc@5  80.00 ( 78.82)
Test: [ 20/100]	Time  0.025 ( 0.030)	Loss 1.7809e+00 (1.9169e+00)	Acc@1  54.00 ( 50.38)	Acc@5  84.00 ( 79.81)
Test: [ 30/100]	Time  0.024 ( 0.028)	Loss 1.8516e+00 (1.9282e+00)	Acc@1  49.00 ( 49.94)	Acc@5  79.00 ( 79.61)
Test: [ 40/100]	Time  0.022 ( 0.026)	Loss 2.0642e+00 (1.9365e+00)	Acc@1  46.00 ( 49.15)	Acc@5  74.00 ( 79.39)
Test: [ 50/100]	Time  0.024 ( 0.025)	Loss 1.6994e+00 (1.9505e+00)	Acc@1  56.00 ( 48.75)	Acc@5  76.00 ( 78.84)
Test: [ 60/100]	Time  0.021 ( 0.025)	Loss 1.8970e+00 (1.9326e+00)	Acc@1  50.00 ( 48.92)	Acc@5  84.00 ( 79.16)
Test: [ 70/100]	Time  0.024 ( 0.025)	Loss 1.8882e+00 (1.9333e+00)	Acc@1  45.00 ( 49.03)	Acc@5  75.00 ( 79.17)
Test: [ 80/100]	Time  0.023 ( 0.025)	Loss 2.1820e+00 (1.9393e+00)	Acc@1  45.00 ( 48.75)	Acc@5  74.00 ( 79.09)
Test: [ 90/100]	Time  0.023 ( 0.024)	Loss 2.2286e+00 (1.9379e+00)	Acc@1  46.00 ( 48.77)	Acc@5  72.00 ( 79.02)
 * Acc@1 48.790 Acc@5 79.170
### epoch[10] execution time: 18.98723578453064
EPOCH 11
i:   0, name:           module.stem.0.weight  changing lr from: 0.089822950858548800   to: 0.087586278261115785
i:   1, name:             module.stem.0.bias  changing lr from: 0.089979647855115114   to: 0.087772736538314813
i:   2, name:           module.stem.1.weight  changing lr from: 0.090133863929493949   to: 0.087956288998151999
i:   3, name:             module.stem.1.bias  changing lr from: 0.090285641642810638   to: 0.088136984012349484
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.090435022808959903   to: 0.088314869156016662
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.090582048506500451   to: 0.088489991218166919
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.090726759090455314   to: 0.088662396212265487
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.090869194204012904   to: 0.088832129386796327
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.091009392790123031   to: 0.088999235235836527
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.091147393102983795   to: 0.089163757509627253
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.091283232719414964   to: 0.089325739225131540
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.091416948550114022   to: 0.089485222676569415
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.091548576850791513   to: 0.089642249445921612
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.091678153233182832   to: 0.089796860413394144
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.091805712675933501   to: 0.089949095767835829
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.091931289535355870   to: 0.090098995017102307
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.092054917556054869   to: 0.090246596998359740
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.092176629881421376   to: 0.090391939888322614
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.092296459063991365   to: 0.090535061213420032
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.092414437075669750   to: 0.090675997859885546
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.092530595317817932   to: 0.090814786083765989
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.092644964631204044   to: 0.090951461520845087
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.092757575305815396   to: 0.091086059196477900
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.092868457090532680   to: 0.091218613535332921
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.092977639202665760   to: 0.091349158371038311
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.093085150337350653   to: 0.091477726955729810
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.093191018676808152   to: 0.091604351969497400
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.093295271899464072   to: 0.091729065529728732
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.093397937188931399   to: 0.091851899200347198
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.093499041242855033   to: 0.091972884000942751
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.093598610281619365   to: 0.092092050415794144
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.093696670056919673   to: 0.092209428402781055
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.093793245860197924   to: 0.092325047402185056
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.093888362530943834   to: 0.092438936345378434
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.093982044464862219   to: 0.092551123663400139
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.094074315621907545   to: 0.092661637295418126
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.094165199534186825   to: 0.092770504697077774
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.094254719313731986   to: 0.092877752848735964
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.094342897660142908   to: 0.092983408263580689
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.094429756868102246   to: 0.093087496995636079
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.094515318834763745   to: 0.093190044647653000
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.094599605067014703   to: 0.093291076378885285
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.094682636688614763   to: 0.093390616912751814
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.094764434447211721   to: 0.093488690544385272
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.094845018721236185   to: 0.093585321148067127
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.094924409526676606   to: 0.093680532184550358
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.095002626523735811   to: 0.093774346708269882
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.095079689023370925   to: 0.093866787374441554
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.095155615993717871   to: 0.093957876446050595
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.095230426066402404   to: 0.094047635800730001
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.095304137542738657   to: 0.094136086937529950
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.095376768399817347   to: 0.094223250983579226
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.095448336296484748   to: 0.094309148700639181
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.095518858579214327   to: 0.094393800491551799
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.095588352287872269   to: 0.094477226406582376
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.095656834161378823   to: 0.094559446149658152
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.095724320643266927   to: 0.094640479084503959
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.095790827887139288   to: 0.094720344240675908
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.095856371762026202   to: 0.094799060319494352
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.095920967857645020   to: 0.094876645699877180
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.095984631489563224   to: 0.094953118444074780
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.096047377704266398   to: 0.095028496303307730
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.096109221284132684   to: 0.095102796723308458
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.096170176752315498   to: 0.095176036849768095
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.096230258377535516   to: 0.095248233533689886
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.096289480178783970   to: 0.095319403336650177
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.096347855929938331   to: 0.095389562535968295
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.096405399164292055   to: 0.095458727129786813
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.096462123178999812   to: 0.095526912842063008
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.096518041039439673   to: 0.095594135127473182
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.096573165583493450   to: 0.095660409176230921
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.096627509425747188   to: 0.095725749918820421
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.096681084961612318   to: 0.095790172030646492
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.096733904371369819   to: 0.095853689936602135
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.096785979624137930   to: 0.095916317815555041
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.096837322481765339   to: 0.095978069604754399
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.096887944502650897   to: 0.096038959004159111
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.096937857045491155   to: 0.096098999480688591
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.096987071272957234   to: 0.096158204272397477
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.097035598155302050   to: 0.096216586392575520
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.097083448473899325   to: 0.096274158633773546
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.097130632824715624   to: 0.096330933571757205
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.097177161621716482   to: 0.096386923569389008
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.097223045100208086   to: 0.096442140780440624
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.097268293320115426   to: 0.096496597153335709
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.097312916169198238   to: 0.096550304434825290
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.097356923366206050   to: 0.096603274173596140
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.097400324463973009   to: 0.096655517723813700
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.097443128852454083   to: 0.096707046248600409
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.097485345761703451   to: 0.096757870723450795
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.097526984264796363   to: 0.096808001939584082
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.097568053280695274   to: 0.096857450507235709
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.097608561577061548   to: 0.096906226858888597
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.097648517773013713   to: 0.096954341252445272
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.097687930341832985   to: 0.097001803774342032
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.097726807613617683   to: 0.097048624342605805
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.097765157777886774   to: 0.097094812709855205
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.097802988886134132   to: 0.097140378466246291
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.097840308854333979   to: 0.097185331042364292
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.097877125465398798   to: 0.097229679712062256
i: 100, name:           module.conv10.weight  changing lr from: 0.097913446371590537   to: 0.097273433595247372
i: 101, name:             module.conv10.bias  changing lr from: 0.097949279096885625   to: 0.097316601660616175



# Switched to train mode...
Epoch: [11][  0/391]	Time  0.195 ( 0.195)	Data  0.149 ( 0.149)	Loss 1.5384e+00 (1.5384e+00)	Acc@1  53.12 ( 53.12)	Acc@5  85.94 ( 85.94)
Epoch: [11][ 10/391]	Time  0.042 ( 0.056)	Data  0.001 ( 0.014)	Loss 1.6072e+00 (1.5735e+00)	Acc@1  54.69 ( 54.90)	Acc@5  85.16 ( 85.30)
Epoch: [11][ 20/391]	Time  0.040 ( 0.049)	Data  0.001 ( 0.008)	Loss 1.5500e+00 (1.5835e+00)	Acc@1  53.12 ( 54.76)	Acc@5  86.72 ( 85.16)
Epoch: [11][ 30/391]	Time  0.042 ( 0.046)	Data  0.001 ( 0.006)	Loss 1.4046e+00 (1.5464e+00)	Acc@1  62.50 ( 56.75)	Acc@5  86.72 ( 85.69)
Epoch: [11][ 40/391]	Time  0.044 ( 0.045)	Data  0.001 ( 0.005)	Loss 1.4545e+00 (1.5334e+00)	Acc@1  55.47 ( 56.73)	Acc@5  89.84 ( 85.99)
Epoch: [11][ 50/391]	Time  0.043 ( 0.044)	Data  0.001 ( 0.004)	Loss 1.5638e+00 (1.5340e+00)	Acc@1  56.25 ( 56.65)	Acc@5  87.50 ( 86.18)
Epoch: [11][ 60/391]	Time  0.045 ( 0.044)	Data  0.001 ( 0.003)	Loss 1.4372e+00 (1.5291e+00)	Acc@1  58.59 ( 56.75)	Acc@5  91.41 ( 86.49)
Epoch: [11][ 70/391]	Time  0.041 ( 0.044)	Data  0.001 ( 0.003)	Loss 1.7199e+00 (1.5287e+00)	Acc@1  51.56 ( 56.75)	Acc@5  82.03 ( 86.48)
Epoch: [11][ 80/391]	Time  0.039 ( 0.043)	Data  0.001 ( 0.003)	Loss 1.3926e+00 (1.5381e+00)	Acc@1  62.50 ( 56.45)	Acc@5  89.84 ( 86.25)
Epoch: [11][ 90/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.003)	Loss 1.7503e+00 (1.5433e+00)	Acc@1  50.00 ( 56.17)	Acc@5  88.28 ( 86.07)
Epoch: [11][100/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.6511e+00 (1.5471e+00)	Acc@1  57.03 ( 56.17)	Acc@5  79.69 ( 85.89)
Epoch: [11][110/391]	Time  0.046 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.4110e+00 (1.5468e+00)	Acc@1  62.50 ( 56.23)	Acc@5  85.94 ( 85.80)
Epoch: [11][120/391]	Time  0.039 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.4676e+00 (1.5510e+00)	Acc@1  57.81 ( 56.17)	Acc@5  85.16 ( 85.74)
Epoch: [11][130/391]	Time  0.044 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.3822e+00 (1.5492e+00)	Acc@1  53.91 ( 56.23)	Acc@5  89.84 ( 85.83)
Epoch: [11][140/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.4664e+00 (1.5487e+00)	Acc@1  58.59 ( 56.29)	Acc@5  85.94 ( 85.83)
Epoch: [11][150/391]	Time  0.051 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.4448e+00 (1.5506e+00)	Acc@1  55.47 ( 56.19)	Acc@5  84.38 ( 85.76)
Epoch: [11][160/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.7985e+00 (1.5552e+00)	Acc@1  51.56 ( 56.07)	Acc@5  81.25 ( 85.71)
Epoch: [11][170/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.4627e+00 (1.5581e+00)	Acc@1  54.69 ( 55.98)	Acc@5  89.84 ( 85.74)
Epoch: [11][180/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.4713e+00 (1.5590e+00)	Acc@1  58.59 ( 56.05)	Acc@5  88.28 ( 85.74)
Epoch: [11][190/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.7062e+00 (1.5603e+00)	Acc@1  52.34 ( 56.11)	Acc@5  82.03 ( 85.64)
Epoch: [11][200/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.5540e+00 (1.5594e+00)	Acc@1  59.38 ( 56.17)	Acc@5  84.38 ( 85.59)
Epoch: [11][210/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.6153e+00 (1.5656e+00)	Acc@1  57.81 ( 56.10)	Acc@5  84.38 ( 85.43)
Epoch: [11][220/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.5832e+00 (1.5632e+00)	Acc@1  53.91 ( 56.11)	Acc@5  83.59 ( 85.45)
Epoch: [11][230/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.4094e+00 (1.5618e+00)	Acc@1  57.81 ( 56.17)	Acc@5  85.94 ( 85.47)
Epoch: [11][240/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.5176e+00 (1.5612e+00)	Acc@1  61.72 ( 56.23)	Acc@5  82.81 ( 85.50)
Epoch: [11][250/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.5142e+00 (1.5618e+00)	Acc@1  57.81 ( 56.18)	Acc@5  86.72 ( 85.50)
Epoch: [11][260/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.5653e+00 (1.5634e+00)	Acc@1  56.25 ( 56.13)	Acc@5  87.50 ( 85.49)
Epoch: [11][270/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.6672e+00 (1.5626e+00)	Acc@1  55.47 ( 56.14)	Acc@5  85.16 ( 85.45)
Epoch: [11][280/391]	Time  0.045 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.6857e+00 (1.5650e+00)	Acc@1  50.78 ( 56.07)	Acc@5  84.38 ( 85.39)
Epoch: [11][290/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.6911e+00 (1.5675e+00)	Acc@1  51.56 ( 56.03)	Acc@5  88.28 ( 85.34)
Epoch: [11][300/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.7644e+00 (1.5681e+00)	Acc@1  49.22 ( 56.04)	Acc@5  85.94 ( 85.33)
Epoch: [11][310/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.5956e+00 (1.5687e+00)	Acc@1  64.84 ( 56.06)	Acc@5  84.38 ( 85.31)
Epoch: [11][320/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.6069e+00 (1.5691e+00)	Acc@1  53.91 ( 56.07)	Acc@5  89.06 ( 85.33)
Epoch: [11][330/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.5504e+00 (1.5688e+00)	Acc@1  53.91 ( 56.07)	Acc@5  89.84 ( 85.35)
Epoch: [11][340/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.4471e+00 (1.5685e+00)	Acc@1  57.03 ( 56.08)	Acc@5  88.28 ( 85.35)
Epoch: [11][350/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.6895e+00 (1.5685e+00)	Acc@1  51.56 ( 56.07)	Acc@5  83.59 ( 85.35)
Epoch: [11][360/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.5671e+00 (1.5672e+00)	Acc@1  54.69 ( 56.09)	Acc@5  85.16 ( 85.37)
Epoch: [11][370/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.7607e+00 (1.5657e+00)	Acc@1  56.25 ( 56.12)	Acc@5  82.81 ( 85.36)
Epoch: [11][380/391]	Time  0.049 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.6187e+00 (1.5674e+00)	Acc@1  60.94 ( 56.11)	Acc@5  83.59 ( 85.32)
Epoch: [11][390/391]	Time  0.028 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.6197e+00 (1.5671e+00)	Acc@1  55.00 ( 56.12)	Acc@5  85.00 ( 85.31)
## e[11] optimizer.zero_grad (sum) time: 0.28476810455322266
## e[11]       loss.backward (sum) time: 4.189118385314941
## e[11]      optimizer.step (sum) time: 1.8493151664733887
## epoch[11] training(only) time: 16.560174703598022
# Switched to evaluate mode...
Test: [  0/100]	Time  0.151 ( 0.151)	Loss 1.8909e+00 (1.8909e+00)	Acc@1  53.00 ( 53.00)	Acc@5  79.00 ( 79.00)
Test: [ 10/100]	Time  0.024 ( 0.035)	Loss 2.0791e+00 (1.8349e+00)	Acc@1  45.00 ( 52.09)	Acc@5  86.00 ( 82.55)
Test: [ 20/100]	Time  0.019 ( 0.029)	Loss 1.7622e+00 (1.8166e+00)	Acc@1  54.00 ( 51.95)	Acc@5  80.00 ( 82.24)
Test: [ 30/100]	Time  0.021 ( 0.027)	Loss 1.7879e+00 (1.8254e+00)	Acc@1  52.00 ( 51.52)	Acc@5  80.00 ( 81.35)
Test: [ 40/100]	Time  0.024 ( 0.026)	Loss 2.0825e+00 (1.8397e+00)	Acc@1  53.00 ( 50.71)	Acc@5  76.00 ( 81.34)
Test: [ 50/100]	Time  0.025 ( 0.025)	Loss 1.5749e+00 (1.8606e+00)	Acc@1  57.00 ( 50.65)	Acc@5  79.00 ( 80.71)
Test: [ 60/100]	Time  0.024 ( 0.025)	Loss 1.7596e+00 (1.8443e+00)	Acc@1  48.00 ( 50.77)	Acc@5  86.00 ( 80.82)
Test: [ 70/100]	Time  0.024 ( 0.024)	Loss 1.8897e+00 (1.8459e+00)	Acc@1  49.00 ( 50.70)	Acc@5  77.00 ( 80.96)
Test: [ 80/100]	Time  0.024 ( 0.024)	Loss 2.0866e+00 (1.8514e+00)	Acc@1  47.00 ( 50.60)	Acc@5  74.00 ( 80.84)
Test: [ 90/100]	Time  0.022 ( 0.024)	Loss 2.0639e+00 (1.8411e+00)	Acc@1  45.00 ( 50.81)	Acc@5  80.00 ( 80.98)
 * Acc@1 50.960 Acc@5 81.070
### epoch[11] execution time: 19.00694990158081
EPOCH 12
i:   0, name:           module.stem.0.weight  changing lr from: 0.087586278261115785   to: 0.085179615101143580
i:   1, name:             module.stem.0.bias  changing lr from: 0.087772736538314813   to: 0.085397458555700911
i:   2, name:           module.stem.1.weight  changing lr from: 0.087956288998151999   to: 0.085611967218120394
i:   3, name:             module.stem.1.bias  changing lr from: 0.088136984012349484   to: 0.085823194667161179
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.088314869156016662   to: 0.086031193669376893
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.088489991218166919   to: 0.086236016186800393
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.088662396212265487   to: 0.086437713384843434
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.088832129386796327   to: 0.086636335640389472
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.088999235235836527   to: 0.086831932550059832
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.089163757509627253   to: 0.087024552938634314
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.089325739225131540   to: 0.087214244867607982
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.089485222676569415   to: 0.087401055643868089
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.089642249445921612   to: 0.087585031828474533
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.089796860413394144   to: 0.087766219245529617
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.089949095767835829   to: 0.087944662991122691
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.090098995017102307   to: 0.088120407442337054
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.090246596998359740   to: 0.088293496266306115
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.090391939888322614   to: 0.088463972429308091
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.090535061213420032   to: 0.088631878205887582
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.090675997859885546   to: 0.088797255187994667
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.090814786083765989   to: 0.088960144294131349
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.090951461520845087   to: 0.089120585778496936
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.091086059196477900   to: 0.089278619240123952
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.091218613535332921   to: 0.089434283631996667
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.091349158371038311   to: 0.089587617270145414
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.091477726955729810   to: 0.089738657842709513
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.091604351969497400   to: 0.089887442418963015
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.091729065529728732   to: 0.090034007458297108
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.091851899200347198   to: 0.090178388819154215
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.091972884000942751   to: 0.090320621767908227
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.092092050415794144   to: 0.090460740987686958
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.092209428402781055   to: 0.090598780587132097
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.092325047402185056   to: 0.090734774109092864
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.092438936345378434   to: 0.090868754539250030
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.092551123663400139   to: 0.091000754314666685
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.092661637295418126   to: 0.091130805332262838
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.092770504697077774   to: 0.091258938957211475
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.092877752848735964   to: 0.091385186031252993
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.092983408263580689   to: 0.091509576880926341
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.093087496995636079   to: 0.091632141325714539
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.093190044647653000   to: 0.091752908686102780
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.093291076378885285   to: 0.091871907791547747
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.093390616912751814   to: 0.091989166988356519
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.093488690544385272   to: 0.092104714147473857
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.093585321148067127   to: 0.092218576672176950
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.093680532184550358   to: 0.092330781505676557
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.093774346708269882   to: 0.092441355138623837
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.093866787374441554   to: 0.092550323616522323
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.093957876446050595   to: 0.092657712547044385
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.094047635800730001   to: 0.092763547107251931
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.094136086937529950   to: 0.092867852050721122
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.094223250983579226   to: 0.092970651714570807
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.094309148700639181   to: 0.093071970026394668
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.094393800491551799   to: 0.093171830511097342
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.094477226406582376   to: 0.093270256297634246
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.094559446149658152   to: 0.093367270125655558
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.094640479084503959   to: 0.093462894352054834
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.094720344240675908   to: 0.093557150957422050
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.094799060319494352   to: 0.093650061552402103
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.094876645699877180   to: 0.093741647383958793
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.094953118444074780   to: 0.093831929341545162
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.095028496303307730   to: 0.093920927963180467
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.095102796723308458   to: 0.094008663441434714
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.095176036849768095   to: 0.094095155629321151
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.095248233533689886   to: 0.094180424046097791
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.095319403336650177   to: 0.094264487882978323
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.095389562535968295   to: 0.094347366008753472
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.095458727129786813   to: 0.094429076975323545
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.095526912842063008   to: 0.094509639023143160
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.095594135127473182   to: 0.094589070086578589
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.095660409176230921   to: 0.094667387799179270
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.095725749918820421   to: 0.094744609498863819
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.095790172030646492   to: 0.094820752233021860
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.095853689936602135   to: 0.094895832763532431
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.095916317815555041   to: 0.094969867571699992
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.095978069604754399   to: 0.095042872863109043
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.096038959004159111   to: 0.095114864572398317
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.096098999480688591   to: 0.095185858367955539
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.096158204272397477   to: 0.095255869656533793
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.096216586392575520   to: 0.095324913587790439
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.096274158633773546   to: 0.095393005058749730
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.096330933571757205   to: 0.095460158718189997
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.096386923569389008   to: 0.095526388970956555
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.096442140780440624   to: 0.095591709982201289
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.096496597153335709   to: 0.095656135681549848
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.096550304434825290   to: 0.095719679767197891
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.096603274173596140   to: 0.095782355709936637
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.096655517723813700   to: 0.095844176757109642
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.096707046248600409   to: 0.095905155936501119
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.096757870723450795   to: 0.095965306060157185
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.096808001939584082   to: 0.096024639728140862
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.096857450507235709   to: 0.096083169332221940
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.096906226858888597   to: 0.096140907059502650
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.096954341252445272   to: 0.096197864895980201
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.097001803774342032   to: 0.096254054630047076
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.097048624342605805   to: 0.096309487855930007
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.097094812709855205   to: 0.096364175977068867
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.097140378466246291   to: 0.096418130209436112
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.097185331042364292   to: 0.096471361584797924
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.097229679712062256   to: 0.096523880953918006
i: 100, name:           module.conv10.weight  changing lr from: 0.097273433595247372   to: 0.096575698989704639
i: 101, name:             module.conv10.bias  changing lr from: 0.097316601660616175   to: 0.096626826190302606



# Switched to train mode...
Epoch: [12][  0/391]	Time  0.192 ( 0.192)	Data  0.144 ( 0.144)	Loss 1.3737e+00 (1.3737e+00)	Acc@1  57.03 ( 57.03)	Acc@5  90.62 ( 90.62)
Epoch: [12][ 10/391]	Time  0.042 ( 0.055)	Data  0.001 ( 0.014)	Loss 1.6911e+00 (1.4376e+00)	Acc@1  50.78 ( 59.16)	Acc@5  78.91 ( 87.50)
Epoch: [12][ 20/391]	Time  0.043 ( 0.049)	Data  0.001 ( 0.008)	Loss 1.4256e+00 (1.4662e+00)	Acc@1  57.03 ( 58.11)	Acc@5  90.62 ( 87.46)
Epoch: [12][ 30/391]	Time  0.047 ( 0.047)	Data  0.001 ( 0.006)	Loss 1.3882e+00 (1.4669e+00)	Acc@1  60.94 ( 58.57)	Acc@5  85.94 ( 87.27)
Epoch: [12][ 40/391]	Time  0.041 ( 0.045)	Data  0.001 ( 0.005)	Loss 1.4959e+00 (1.4762e+00)	Acc@1  58.59 ( 58.50)	Acc@5  86.72 ( 86.95)
Epoch: [12][ 50/391]	Time  0.043 ( 0.045)	Data  0.001 ( 0.004)	Loss 1.4749e+00 (1.4815e+00)	Acc@1  57.81 ( 58.16)	Acc@5  84.38 ( 86.93)
Epoch: [12][ 60/391]	Time  0.043 ( 0.044)	Data  0.001 ( 0.003)	Loss 1.3652e+00 (1.4817e+00)	Acc@1  56.25 ( 58.15)	Acc@5  89.84 ( 86.90)
Epoch: [12][ 70/391]	Time  0.040 ( 0.044)	Data  0.001 ( 0.003)	Loss 1.4716e+00 (1.4809e+00)	Acc@1  62.50 ( 58.30)	Acc@5  86.72 ( 87.00)
Epoch: [12][ 80/391]	Time  0.039 ( 0.043)	Data  0.001 ( 0.003)	Loss 1.2203e+00 (1.4826e+00)	Acc@1  64.06 ( 58.35)	Acc@5  87.50 ( 86.85)
Epoch: [12][ 90/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.003)	Loss 1.6809e+00 (1.4943e+00)	Acc@1  50.78 ( 57.92)	Acc@5  82.81 ( 86.73)
Epoch: [12][100/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.4354e+00 (1.4921e+00)	Acc@1  62.50 ( 58.08)	Acc@5  86.72 ( 86.83)
Epoch: [12][110/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.5979e+00 (1.4953e+00)	Acc@1  53.12 ( 58.01)	Acc@5  86.72 ( 86.74)
Epoch: [12][120/391]	Time  0.039 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.4913e+00 (1.5051e+00)	Acc@1  57.03 ( 57.79)	Acc@5  87.50 ( 86.56)
Epoch: [12][130/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.5871e+00 (1.5026e+00)	Acc@1  57.03 ( 57.88)	Acc@5  87.50 ( 86.67)
Epoch: [12][140/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.4673e+00 (1.5052e+00)	Acc@1  60.94 ( 57.75)	Acc@5  85.94 ( 86.66)
Epoch: [12][150/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.5660e+00 (1.5009e+00)	Acc@1  56.25 ( 57.76)	Acc@5  87.50 ( 86.79)
Epoch: [12][160/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.6966e+00 (1.4996e+00)	Acc@1  51.56 ( 57.76)	Acc@5  85.94 ( 86.84)
Epoch: [12][170/391]	Time  0.037 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.6340e+00 (1.5049e+00)	Acc@1  54.69 ( 57.58)	Acc@5  82.81 ( 86.71)
Epoch: [12][180/391]	Time  0.046 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.7640e+00 (1.5073e+00)	Acc@1  51.56 ( 57.49)	Acc@5  78.12 ( 86.65)
Epoch: [12][190/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.3028e+00 (1.5075e+00)	Acc@1  56.25 ( 57.45)	Acc@5  89.84 ( 86.64)
Epoch: [12][200/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.4434e+00 (1.5093e+00)	Acc@1  56.25 ( 57.42)	Acc@5  85.16 ( 86.52)
Epoch: [12][210/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.5518e+00 (1.5096e+00)	Acc@1  61.72 ( 57.46)	Acc@5  83.59 ( 86.45)
Epoch: [12][220/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.4769e+00 (1.5088e+00)	Acc@1  57.03 ( 57.51)	Acc@5  88.28 ( 86.42)
Epoch: [12][230/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.3484e+00 (1.5071e+00)	Acc@1  63.28 ( 57.54)	Acc@5  92.19 ( 86.46)
Epoch: [12][240/391]	Time  0.046 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.2570e+00 (1.5080e+00)	Acc@1  66.41 ( 57.53)	Acc@5  90.62 ( 86.49)
Epoch: [12][250/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.4596e+00 (1.5081e+00)	Acc@1  59.38 ( 57.56)	Acc@5  89.84 ( 86.47)
Epoch: [12][260/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.6831e+00 (1.5082e+00)	Acc@1  46.09 ( 57.53)	Acc@5  85.16 ( 86.43)
Epoch: [12][270/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.4661e+00 (1.5107e+00)	Acc@1  52.34 ( 57.43)	Acc@5  85.94 ( 86.34)
Epoch: [12][280/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.5820e+00 (1.5140e+00)	Acc@1  59.38 ( 57.35)	Acc@5  82.81 ( 86.28)
Epoch: [12][290/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.8107e+00 (1.5145e+00)	Acc@1  54.69 ( 57.32)	Acc@5  78.91 ( 86.26)
Epoch: [12][300/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.6826e+00 (1.5152e+00)	Acc@1  53.91 ( 57.31)	Acc@5  80.47 ( 86.20)
Epoch: [12][310/391]	Time  0.046 ( 0.042)	Data  0.002 ( 0.002)	Loss 1.5338e+00 (1.5156e+00)	Acc@1  60.16 ( 57.31)	Acc@5  87.50 ( 86.21)
Epoch: [12][320/391]	Time  0.045 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.3548e+00 (1.5145e+00)	Acc@1  62.50 ( 57.30)	Acc@5  89.84 ( 86.21)
Epoch: [12][330/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.5072e+00 (1.5157e+00)	Acc@1  60.16 ( 57.22)	Acc@5  85.16 ( 86.18)
Epoch: [12][340/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.3951e+00 (1.5135e+00)	Acc@1  55.47 ( 57.26)	Acc@5  88.28 ( 86.17)
Epoch: [12][350/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.5516e+00 (1.5145e+00)	Acc@1  57.03 ( 57.21)	Acc@5  86.72 ( 86.14)
Epoch: [12][360/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.3646e+00 (1.5135e+00)	Acc@1  65.62 ( 57.24)	Acc@5  88.28 ( 86.12)
Epoch: [12][370/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.6475e+00 (1.5154e+00)	Acc@1  53.12 ( 57.15)	Acc@5  82.03 ( 86.10)
Epoch: [12][380/391]	Time  0.037 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.3618e+00 (1.5149e+00)	Acc@1  64.06 ( 57.18)	Acc@5  89.06 ( 86.10)
Epoch: [12][390/391]	Time  0.036 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.6912e+00 (1.5154e+00)	Acc@1  51.25 ( 57.18)	Acc@5  86.25 ( 86.10)
## e[12] optimizer.zero_grad (sum) time: 0.28658390045166016
## e[12]       loss.backward (sum) time: 4.138598680496216
## e[12]      optimizer.step (sum) time: 1.89323091506958
## epoch[12] training(only) time: 16.42162275314331
# Switched to evaluate mode...
Test: [  0/100]	Time  0.154 ( 0.154)	Loss 2.0025e+00 (2.0025e+00)	Acc@1  51.00 ( 51.00)	Acc@5  74.00 ( 74.00)
Test: [ 10/100]	Time  0.025 ( 0.036)	Loss 1.9132e+00 (1.8632e+00)	Acc@1  46.00 ( 51.64)	Acc@5  81.00 ( 81.09)
Test: [ 20/100]	Time  0.022 ( 0.030)	Loss 1.6768e+00 (1.8414e+00)	Acc@1  51.00 ( 51.62)	Acc@5  84.00 ( 81.29)
Test: [ 30/100]	Time  0.022 ( 0.027)	Loss 1.9627e+00 (1.8729e+00)	Acc@1  45.00 ( 50.65)	Acc@5  83.00 ( 80.55)
Test: [ 40/100]	Time  0.021 ( 0.026)	Loss 1.8810e+00 (1.8836e+00)	Acc@1  51.00 ( 49.95)	Acc@5  83.00 ( 80.68)
Test: [ 50/100]	Time  0.020 ( 0.025)	Loss 1.7439e+00 (1.9068e+00)	Acc@1  53.00 ( 49.84)	Acc@5  79.00 ( 80.16)
Test: [ 60/100]	Time  0.019 ( 0.024)	Loss 1.7949e+00 (1.9108e+00)	Acc@1  51.00 ( 49.49)	Acc@5  82.00 ( 80.10)
Test: [ 70/100]	Time  0.019 ( 0.023)	Loss 2.0533e+00 (1.9112e+00)	Acc@1  49.00 ( 49.62)	Acc@5  78.00 ( 80.00)
Test: [ 80/100]	Time  0.017 ( 0.023)	Loss 2.1081e+00 (1.9181e+00)	Acc@1  46.00 ( 49.48)	Acc@5  79.00 ( 80.11)
Test: [ 90/100]	Time  0.024 ( 0.023)	Loss 2.0734e+00 (1.9099e+00)	Acc@1  52.00 ( 49.71)	Acc@5  73.00 ( 80.19)
 * Acc@1 49.920 Acc@5 80.140
### epoch[12] execution time: 18.78303861618042
EPOCH 13
i:   0, name:           module.stem.0.weight  changing lr from: 0.085179615101143580   to: 0.082614143440428292
i:   1, name:             module.stem.0.bias  changing lr from: 0.085397458555700911   to: 0.082864689291374818
i:   2, name:           module.stem.1.weight  changing lr from: 0.085611967218120394   to: 0.083111476173884258
i:   3, name:             module.stem.1.bias  changing lr from: 0.085823194667161179   to: 0.083354562003362179
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.086031193669376893   to: 0.083594003909340006
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.086236016186800393   to: 0.083829858238632454
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.086437713384843434   to: 0.084062180558957589
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.086636335640389472   to: 0.084291025662986657
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.086831932550059832   to: 0.084516447572792822
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.087024552938634314   to: 0.084738499544669499
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.087214244867607982   to: 0.084957234074290677
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.087401055643868089   to: 0.085172702902186648
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.087585031828474533   to: 0.085384957019510530
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.087766219245529617   to: 0.085594046674071958
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.087944662991122691   to: 0.085800021376615479
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.088120407442337054   to: 0.086002929907322834
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.088293496266306115   to: 0.086202820322518858
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.088463972429308091   to: 0.086399739961562638
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.088631878205887582   to: 0.086593735453905529
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.088797255187994667   to: 0.086784852726299683
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.088960144294131349   to: 0.086973137010141033
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.089120585778496936   to: 0.087158632848931744
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.089278619240123952   to: 0.087341384105848019
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.089434283631996667   to: 0.087521433971400053
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.089587617270145414   to: 0.087698824971171430
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.089738657842709513   to: 0.087873598973626219
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.089887442418963015   to: 0.088045797197972744
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.090034007458297108   to: 0.088215460222073452
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.090178388819154215   to: 0.088382627990391052
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.090320621767908227   to: 0.088547339821961890
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.090460740987686958   to: 0.088709634418387640
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.090598780587132097   to: 0.088869549871837317
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.090734774109092864   to: 0.089027123673052141
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.090868754539250030   to: 0.089182392719345860
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.091000754314666685   to: 0.089335393322593978
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.091130805332262838   to: 0.089486161217205928
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.091258938957211475   to: 0.089634731568073736
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.091385186031252993   to: 0.089781138978492658
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.091509576880926341   to: 0.089925417498047819
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.091632141325714539   to: 0.090067600630462846
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.091752908686102780   to: 0.090207721341405894
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.091871907791547747   to: 0.090345812066248907
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.091989166988356519   to: 0.090481904717776562
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.092104714147473857   to: 0.090616030693841457
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.092218576672176950   to: 0.090748220884962205
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.092330781505676557   to: 0.090878505681861510
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.092441355138623837   to: 0.091006914982941847
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.092550323616522323   to: 0.091133478201695803
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.092657712547044385   to: 0.091258224274049282
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.092763547107251931   to: 0.091381181665635233
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.092867852050721122   to: 0.091502378378996205
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.092970651714570807   to: 0.091621841960713976
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.093071970026394668   to: 0.091739599508464914
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.093171830511097342   to: 0.091855677677999570
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.093270256297634246   to: 0.091970102690045311
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.093367270125655558   to: 0.092082900337131166
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.093462894352054834   to: 0.092194095990333791
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.093557150957422050   to: 0.092303714605943887
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.093650061552402103   to: 0.092411780732052307
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.093741647383958793   to: 0.092518318515055320
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.093831929341545162   to: 0.092623351706078993
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.093920927963180467   to: 0.092726903667321559
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.094008663441434714   to: 0.092828997378314390
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.094095155629321151   to: 0.092929655442100773
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.094180424046097791   to: 0.093028900091332786
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.094264487882978323   to: 0.093126753194286205
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.094347366008753472   to: 0.093223236260793416
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.094429076975323545   to: 0.093318370448094531
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.094509639023143160   to: 0.093412176566607052
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.094589070086578589   to: 0.093504675085614108
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.094667387799179270   to: 0.093595886138871834
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.094744609498863819   to: 0.093685829530135975
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.094820752233021860   to: 0.093774524738608478
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.094895832763532431   to: 0.093861990924304278
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.094969867571699992   to: 0.093948246933338905
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.095042872863109043   to: 0.094033311303137357
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.095114864572398317   to: 0.094117202267564926
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.095185858367955539   to: 0.094199937761980504
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.095255869656533793   to: 0.094281535428213090
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.095324913587790439   to: 0.094362012619461977
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.095393005058749730   to: 0.094441386405121661
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.095460158718189997   to: 0.094519673575531704
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.095526388970956555   to: 0.094596890646652720
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.095591709982201289   to: 0.094673053864668982
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.095656135681549848   to: 0.094748179210518507
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.095719679767197891   to: 0.094822282404351310
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.095782355709936637   to: 0.094895378909916783
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.095844176757109642   to: 0.094967483938880881
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.095905155936501119   to: 0.095038612455073848
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.095965306060157185   to: 0.095108779178669584
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.096024639728140862   to: 0.095177998590297186
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.096083169332221940   to: 0.095246284935085690
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.096140907059502650   to: 0.095313652226642689
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.096197864895980201   to: 0.095380114250967957
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.096254054630047076   to: 0.095445684570302558
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.096309487855930007   to: 0.095510376526914575
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.096364175977068867   to: 0.095574203246822170
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.096418130209436112   to: 0.095637177643454918
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.096471361584797924   to: 0.095699312421254165
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.096523880953918006   to: 0.095760620079213252
i: 100, name:           module.conv10.weight  changing lr from: 0.096575698989704639   to: 0.095821112914358644
i: 101, name:             module.conv10.bias  changing lr from: 0.096626826190302606   to: 0.095880803025172628



# Switched to train mode...
Epoch: [13][  0/391]	Time  0.197 ( 0.197)	Data  0.149 ( 0.149)	Loss 1.6495e+00 (1.6495e+00)	Acc@1  51.56 ( 51.56)	Acc@5  84.38 ( 84.38)
Epoch: [13][ 10/391]	Time  0.040 ( 0.056)	Data  0.001 ( 0.014)	Loss 1.5127e+00 (1.4621e+00)	Acc@1  55.47 ( 58.38)	Acc@5  87.50 ( 87.14)
Epoch: [13][ 20/391]	Time  0.039 ( 0.048)	Data  0.001 ( 0.008)	Loss 1.3790e+00 (1.4334e+00)	Acc@1  58.59 ( 59.11)	Acc@5  85.16 ( 87.09)
Epoch: [13][ 30/391]	Time  0.040 ( 0.046)	Data  0.001 ( 0.006)	Loss 1.5333e+00 (1.4241e+00)	Acc@1  58.59 ( 59.88)	Acc@5  89.06 ( 87.42)
Epoch: [13][ 40/391]	Time  0.041 ( 0.045)	Data  0.001 ( 0.005)	Loss 1.3192e+00 (1.4248e+00)	Acc@1  64.84 ( 59.74)	Acc@5  85.16 ( 87.23)
Epoch: [13][ 50/391]	Time  0.042 ( 0.044)	Data  0.001 ( 0.004)	Loss 1.4804e+00 (1.4294e+00)	Acc@1  54.69 ( 59.24)	Acc@5  84.38 ( 87.38)
Epoch: [13][ 60/391]	Time  0.040 ( 0.044)	Data  0.001 ( 0.004)	Loss 1.4157e+00 (1.4352e+00)	Acc@1  61.72 ( 59.32)	Acc@5  83.59 ( 87.17)
Epoch: [13][ 70/391]	Time  0.040 ( 0.044)	Data  0.001 ( 0.003)	Loss 1.4866e+00 (1.4377e+00)	Acc@1  54.69 ( 59.15)	Acc@5  87.50 ( 87.04)
Epoch: [13][ 80/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.003)	Loss 1.3962e+00 (1.4421e+00)	Acc@1  60.94 ( 59.16)	Acc@5  87.50 ( 87.09)
Epoch: [13][ 90/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.003)	Loss 1.3265e+00 (1.4450e+00)	Acc@1  61.72 ( 59.02)	Acc@5  85.16 ( 87.06)
Epoch: [13][100/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.003)	Loss 1.5354e+00 (1.4472e+00)	Acc@1  55.47 ( 58.97)	Acc@5  85.94 ( 86.99)
Epoch: [13][110/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.4399e+00 (1.4475e+00)	Acc@1  57.03 ( 58.94)	Acc@5  87.50 ( 86.98)
Epoch: [13][120/391]	Time  0.048 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.5218e+00 (1.4519e+00)	Acc@1  53.91 ( 58.79)	Acc@5  85.16 ( 86.94)
Epoch: [13][130/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.5485e+00 (1.4490e+00)	Acc@1  56.25 ( 58.89)	Acc@5  84.38 ( 87.02)
Epoch: [13][140/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.5245e+00 (1.4452e+00)	Acc@1  58.59 ( 58.98)	Acc@5  89.84 ( 87.15)
Epoch: [13][150/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.3568e+00 (1.4424e+00)	Acc@1  61.72 ( 58.99)	Acc@5  85.94 ( 87.22)
Epoch: [13][160/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.5055e+00 (1.4523e+00)	Acc@1  57.03 ( 58.79)	Acc@5  82.03 ( 87.03)
Epoch: [13][170/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.5967e+00 (1.4540e+00)	Acc@1  56.25 ( 58.70)	Acc@5  85.16 ( 87.03)
Epoch: [13][180/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.5701e+00 (1.4551e+00)	Acc@1  53.91 ( 58.72)	Acc@5  85.94 ( 87.04)
Epoch: [13][190/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.4610e+00 (1.4574e+00)	Acc@1  60.16 ( 58.63)	Acc@5  85.16 ( 86.96)
Epoch: [13][200/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.6644e+00 (1.4602e+00)	Acc@1  48.44 ( 58.43)	Acc@5  86.72 ( 86.97)
Epoch: [13][210/391]	Time  0.037 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.4122e+00 (1.4560e+00)	Acc@1  59.38 ( 58.58)	Acc@5  88.28 ( 87.04)
Epoch: [13][220/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.4738e+00 (1.4589e+00)	Acc@1  51.56 ( 58.45)	Acc@5  89.06 ( 87.01)
Epoch: [13][230/391]	Time  0.043 ( 0.042)	Data  0.004 ( 0.002)	Loss 1.2037e+00 (1.4626e+00)	Acc@1  69.53 ( 58.42)	Acc@5  92.97 ( 86.89)
Epoch: [13][240/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.4614e+00 (1.4637e+00)	Acc@1  57.03 ( 58.38)	Acc@5  89.06 ( 86.88)
Epoch: [13][250/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.4643e+00 (1.4667e+00)	Acc@1  58.59 ( 58.32)	Acc@5  85.16 ( 86.82)
Epoch: [13][260/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.6815e+00 (1.4714e+00)	Acc@1  53.12 ( 58.20)	Acc@5  85.16 ( 86.73)
Epoch: [13][270/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.3985e+00 (1.4719e+00)	Acc@1  59.38 ( 58.19)	Acc@5  87.50 ( 86.74)
Epoch: [13][280/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.4590e+00 (1.4708e+00)	Acc@1  57.03 ( 58.24)	Acc@5  83.59 ( 86.72)
Epoch: [13][290/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.3441e+00 (1.4705e+00)	Acc@1  64.06 ( 58.24)	Acc@5  85.94 ( 86.71)
Epoch: [13][300/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.3901e+00 (1.4718e+00)	Acc@1  57.03 ( 58.18)	Acc@5  87.50 ( 86.69)
Epoch: [13][310/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.5261e+00 (1.4747e+00)	Acc@1  61.72 ( 58.12)	Acc@5  85.94 ( 86.66)
Epoch: [13][320/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.4493e+00 (1.4746e+00)	Acc@1  57.03 ( 58.15)	Acc@5  87.50 ( 86.62)
Epoch: [13][330/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.4362e+00 (1.4755e+00)	Acc@1  60.16 ( 58.15)	Acc@5  88.28 ( 86.59)
Epoch: [13][340/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.2985e+00 (1.4732e+00)	Acc@1  64.84 ( 58.28)	Acc@5  85.16 ( 86.63)
Epoch: [13][350/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.2525e+00 (1.4716e+00)	Acc@1  67.97 ( 58.34)	Acc@5  88.28 ( 86.66)
Epoch: [13][360/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.4217e+00 (1.4723e+00)	Acc@1  62.50 ( 58.31)	Acc@5  80.47 ( 86.64)
Epoch: [13][370/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.3477e+00 (1.4717e+00)	Acc@1  61.72 ( 58.35)	Acc@5  87.50 ( 86.64)
Epoch: [13][380/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.5536e+00 (1.4731e+00)	Acc@1  56.25 ( 58.32)	Acc@5  87.50 ( 86.63)
Epoch: [13][390/391]	Time  0.029 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.1697e+00 (1.4747e+00)	Acc@1  68.75 ( 58.30)	Acc@5  86.25 ( 86.60)
## e[13] optimizer.zero_grad (sum) time: 0.2866654396057129
## e[13]       loss.backward (sum) time: 4.1446123123168945
## e[13]      optimizer.step (sum) time: 1.854191541671753
## epoch[13] training(only) time: 16.422388076782227
# Switched to evaluate mode...
Test: [  0/100]	Time  0.155 ( 0.155)	Loss 1.8929e+00 (1.8929e+00)	Acc@1  49.00 ( 49.00)	Acc@5  79.00 ( 79.00)
Test: [ 10/100]	Time  0.025 ( 0.034)	Loss 2.1660e+00 (1.8943e+00)	Acc@1  43.00 ( 50.36)	Acc@5  73.00 ( 80.18)
Test: [ 20/100]	Time  0.019 ( 0.028)	Loss 1.7614e+00 (1.8928e+00)	Acc@1  55.00 ( 50.62)	Acc@5  83.00 ( 80.76)
Test: [ 30/100]	Time  0.019 ( 0.025)	Loss 1.9691e+00 (1.9167e+00)	Acc@1  45.00 ( 49.94)	Acc@5  84.00 ( 80.48)
Test: [ 40/100]	Time  0.021 ( 0.024)	Loss 2.0498e+00 (1.9279e+00)	Acc@1  47.00 ( 49.78)	Acc@5  77.00 ( 80.29)
Test: [ 50/100]	Time  0.024 ( 0.024)	Loss 1.8320e+00 (1.9412e+00)	Acc@1  58.00 ( 49.73)	Acc@5  76.00 ( 80.00)
Test: [ 60/100]	Time  0.024 ( 0.024)	Loss 1.8196e+00 (1.9344e+00)	Acc@1  50.00 ( 49.70)	Acc@5  81.00 ( 79.97)
Test: [ 70/100]	Time  0.024 ( 0.024)	Loss 2.0016e+00 (1.9454e+00)	Acc@1  50.00 ( 49.35)	Acc@5  77.00 ( 79.63)
Test: [ 80/100]	Time  0.022 ( 0.024)	Loss 2.1241e+00 (1.9519e+00)	Acc@1  48.00 ( 49.16)	Acc@5  77.00 ( 79.40)
Test: [ 90/100]	Time  0.018 ( 0.023)	Loss 1.8942e+00 (1.9394e+00)	Acc@1  51.00 ( 49.22)	Acc@5  81.00 ( 79.65)
 * Acc@1 49.340 Acc@5 79.590
### epoch[13] execution time: 18.80923318862915
EPOCH 14
i:   0, name:           module.stem.0.weight  changing lr from: 0.082614143440428292   to: 0.079901783211565186
i:   1, name:             module.stem.0.bias  changing lr from: 0.082864689291374818   to: 0.080186025214798784
i:   2, name:           module.stem.1.weight  changing lr from: 0.083111476173884258   to: 0.080466098085956131
i:   3, name:             module.stem.1.bias  changing lr from: 0.083354562003362179   to: 0.080742062936704939
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.083594003909340006   to: 0.081013980168980634
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.083829858238632454   to: 0.081281909471705494
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.084062180558957589   to: 0.081545909818286827
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.084291025662986657   to: 0.081806039464848157
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.084516447572792822   to: 0.082062355949149332
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.084738499544669499   to: 0.082314916090153789
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.084957234074290677   to: 0.082563775988203122
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.085172702902186648   to: 0.082808991025761280
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.085384957019510530   to: 0.083050615868692071
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.085594046674071958   to: 0.083288704468036157
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.085800021376615479   to: 0.083523310062254830
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.086002929907322834   to: 0.083754485179909743
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.086202820322518858   to: 0.083982281642749235
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.086399739961562638   to: 0.084206750569173525
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.086593735453905529   to: 0.084427942378052206
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.086784852726299683   to: 0.084645906792869041
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.086973137010141033   to: 0.084860692846170094
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.087158632848931744   to: 0.085072348884292978
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.087341384105848019   to: 0.085280922572355367
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.087521433971400053   to: 0.085486460899482808
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.087698824971171430   to: 0.085689010184256398
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.087873598973626219   to: 0.085888616080362357
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.088045797197972744   to: 0.086085323582425821
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.088215460222073452   to: 0.086279177032012988
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.088382627990391052   to: 0.086470220123785940
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.088547339821961890   to: 0.086658495911795447
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.088709634418387640   to: 0.086844046815898038
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.088869549871837317   to: 0.087026914628284324
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.089027123673052141   to: 0.087207140520106100
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.089182392719345860   to: 0.087384765048190663
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.089335393322593978   to: 0.087559828161831277
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.089486161217205928   to: 0.087732369209643529
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.089634731568073736   to: 0.087902426946477610
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.089781138978492658   to: 0.088070039540377454
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.089925417498047819   to: 0.088235244579578057
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.090067600630462846   to: 0.088398079079532621
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.090207721341405894   to: 0.088558579489962042
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.090345812066248907   to: 0.088716781701919600
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.090481904717776562   to: 0.088872721054863504
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.090616030693841457   to: 0.089026432343731809
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.090748220884962205   to: 0.089177949826012973
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.090878505681861510   to: 0.089327307228806802
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.091006914982941847   to: 0.089474537755870581
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.091133478201695803   to: 0.089619674094645385
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.091258224274049282   to: 0.089762748423257946
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.091381181665635233   to: 0.089903792417494091
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.091502378378996205   to: 0.090042837257739455
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.091621841960713976   to: 0.090179913635883888
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.091739599508464914   to: 0.090315051762186294
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.091855677677999570   to: 0.090448281372096442
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.091970102690045311   to: 0.090579631733031060
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.092082900337131166   to: 0.090709131651101199
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.092194095990333791   to: 0.090836809477788660
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.092303714605943887   to: 0.090962693116568960
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.092411780732052307   to: 0.091086810029478826
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.092518318515055320   to: 0.091209187243626214
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.092623351706078993   to: 0.091329851357641073
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.092726903667321559   to: 0.091448828548065353
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.092828997378314390   to: 0.091566144575680672
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.092929655442100773   to: 0.091681824791772296
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.093028900091332786   to: 0.091795894144328566
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.093126753194286205   to: 0.091908377184174175
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.093223236260793416   to: 0.092019298071037037
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.093318370448094531   to: 0.092128680579547179
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.093412176566607052   to: 0.092236548105167793
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.093504675085614108   to: 0.092342923670057017
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.093595886138871834   to: 0.092447829928860567
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.093685829530135975   to: 0.092551289174434448
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.093774524738608478   to: 0.092653323343497629
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.093861990924304278   to: 0.092753954022214119
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.093948246933338905   to: 0.092853202451704753
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.094033311303137357   to: 0.092951089533488074
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.094117202267564926   to: 0.093047635834850567
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.094199937761980504   to: 0.093142861594146309
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.094281535428213090   to: 0.093236786726025742
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.094362012619461977   to: 0.093329430826594270
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.094441386405121661   to: 0.093420813178500331
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.094519673575531704   to: 0.093510952755953544
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.094596890646652720   to: 0.093599868229672922
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.094673053864668982   to: 0.093687577971765787
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.094748179210518507   to: 0.093774100060537435
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.094822282404351310   to: 0.093859452285232167
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.094895378909916783   to: 0.093943652150705950
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.094967483938880881   to: 0.094026716882031333
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.095038612455073848   to: 0.094108663429034858
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.095108779178669584   to: 0.094189508470767846
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.095177998590297186   to: 0.094269268419910582
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.095246284935085690   to: 0.094347959427111106
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.095313652226642689   to: 0.094425597385258436
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.095380114250967957   to: 0.094502197933691579
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.095445684570302558   to: 0.094577776462344221
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.095510376526914575   to: 0.094652348115826457
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.095574203246822170   to: 0.094725927797443391
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.095637177643454918   to: 0.094798530173152096
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.095699312421254165   to: 0.094870169675456931
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.095760620079213252   to: 0.094940860507244179
i: 100, name:           module.conv10.weight  changing lr from: 0.095821112914358644   to: 0.095010616645556809
i: 101, name:             module.conv10.bias  changing lr from: 0.095880803025172628   to: 0.095079451845309693



# Switched to train mode...
Epoch: [14][  0/391]	Time  0.196 ( 0.196)	Data  0.150 ( 0.150)	Loss 1.3295e+00 (1.3295e+00)	Acc@1  62.50 ( 62.50)	Acc@5  88.28 ( 88.28)
Epoch: [14][ 10/391]	Time  0.043 ( 0.056)	Data  0.001 ( 0.015)	Loss 1.3882e+00 (1.4316e+00)	Acc@1  64.84 ( 61.08)	Acc@5  85.94 ( 87.43)
Epoch: [14][ 20/391]	Time  0.039 ( 0.049)	Data  0.001 ( 0.008)	Loss 1.1889e+00 (1.3570e+00)	Acc@1  63.28 ( 61.83)	Acc@5  88.28 ( 88.21)
Epoch: [14][ 30/391]	Time  0.040 ( 0.047)	Data  0.001 ( 0.006)	Loss 1.3057e+00 (1.3744e+00)	Acc@1  63.28 ( 60.99)	Acc@5  89.84 ( 88.48)
Epoch: [14][ 40/391]	Time  0.040 ( 0.045)	Data  0.001 ( 0.005)	Loss 1.2945e+00 (1.3678e+00)	Acc@1  59.38 ( 60.71)	Acc@5  89.06 ( 88.40)
Epoch: [14][ 50/391]	Time  0.040 ( 0.044)	Data  0.001 ( 0.004)	Loss 1.3329e+00 (1.3746e+00)	Acc@1  60.94 ( 60.65)	Acc@5  88.28 ( 88.01)
Epoch: [14][ 60/391]	Time  0.040 ( 0.044)	Data  0.001 ( 0.003)	Loss 1.6067e+00 (1.3806e+00)	Acc@1  64.84 ( 60.54)	Acc@5  82.81 ( 88.05)
Epoch: [14][ 70/391]	Time  0.039 ( 0.043)	Data  0.001 ( 0.003)	Loss 1.3109e+00 (1.3746e+00)	Acc@1  64.06 ( 60.75)	Acc@5  92.19 ( 88.20)
Epoch: [14][ 80/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.003)	Loss 1.4650e+00 (1.3695e+00)	Acc@1  55.47 ( 60.87)	Acc@5  88.28 ( 88.29)
Epoch: [14][ 90/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.003)	Loss 1.3441e+00 (1.3727e+00)	Acc@1  59.38 ( 60.72)	Acc@5  90.62 ( 88.26)
Epoch: [14][100/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.003)	Loss 1.4771e+00 (1.3806e+00)	Acc@1  52.34 ( 60.48)	Acc@5  88.28 ( 88.06)
Epoch: [14][110/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.5744e+00 (1.3834e+00)	Acc@1  53.91 ( 60.33)	Acc@5  82.81 ( 87.96)
Epoch: [14][120/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.2715e+00 (1.3853e+00)	Acc@1  58.59 ( 60.24)	Acc@5  90.62 ( 87.93)
Epoch: [14][130/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.3566e+00 (1.3917e+00)	Acc@1  62.50 ( 60.14)	Acc@5  89.06 ( 87.87)
Epoch: [14][140/391]	Time  0.041 ( 0.042)	Data  0.002 ( 0.002)	Loss 1.6317e+00 (1.3943e+00)	Acc@1  54.69 ( 60.11)	Acc@5  82.81 ( 87.79)
Epoch: [14][150/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.3853e+00 (1.3976e+00)	Acc@1  60.16 ( 60.08)	Acc@5  85.94 ( 87.71)
Epoch: [14][160/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.2906e+00 (1.3983e+00)	Acc@1  61.72 ( 60.18)	Acc@5  87.50 ( 87.71)
Epoch: [14][170/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.3906e+00 (1.3954e+00)	Acc@1  60.94 ( 60.25)	Acc@5  89.06 ( 87.78)
Epoch: [14][180/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.2235e+00 (1.3943e+00)	Acc@1  67.19 ( 60.36)	Acc@5  91.41 ( 87.83)
Epoch: [14][190/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.3021e+00 (1.3943e+00)	Acc@1  61.72 ( 60.36)	Acc@5  89.06 ( 87.81)
Epoch: [14][200/391]	Time  0.047 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.4053e+00 (1.3946e+00)	Acc@1  57.03 ( 60.38)	Acc@5  88.28 ( 87.83)
Epoch: [14][210/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.4748e+00 (1.3928e+00)	Acc@1  55.47 ( 60.41)	Acc@5  86.72 ( 87.84)
Epoch: [14][220/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.3954e+00 (1.3950e+00)	Acc@1  60.94 ( 60.33)	Acc@5  89.84 ( 87.81)
Epoch: [14][230/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.2789e+00 (1.3962e+00)	Acc@1  63.28 ( 60.29)	Acc@5  88.28 ( 87.79)
Epoch: [14][240/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.4438e+00 (1.3958e+00)	Acc@1  60.16 ( 60.34)	Acc@5  88.28 ( 87.81)
Epoch: [14][250/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.3166e+00 (1.3957e+00)	Acc@1  61.72 ( 60.35)	Acc@5  88.28 ( 87.79)
Epoch: [14][260/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.3211e+00 (1.3949e+00)	Acc@1  62.50 ( 60.35)	Acc@5  87.50 ( 87.81)
Epoch: [14][270/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.3890e+00 (1.3977e+00)	Acc@1  59.38 ( 60.31)	Acc@5  89.06 ( 87.78)
Epoch: [14][280/391]	Time  0.046 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.5246e+00 (1.4010e+00)	Acc@1  56.25 ( 60.21)	Acc@5  90.62 ( 87.76)
Epoch: [14][290/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.3844e+00 (1.4028e+00)	Acc@1  61.72 ( 60.18)	Acc@5  89.84 ( 87.73)
Epoch: [14][300/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.3784e+00 (1.4040e+00)	Acc@1  54.69 ( 60.13)	Acc@5  91.41 ( 87.76)
Epoch: [14][310/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.3985e+00 (1.4041e+00)	Acc@1  55.47 ( 60.13)	Acc@5  88.28 ( 87.78)
Epoch: [14][320/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.2844e+00 (1.4062e+00)	Acc@1  67.19 ( 60.08)	Acc@5  89.84 ( 87.77)
Epoch: [14][330/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.4037e+00 (1.4071e+00)	Acc@1  60.94 ( 60.08)	Acc@5  87.50 ( 87.78)
Epoch: [14][340/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.5205e+00 (1.4084e+00)	Acc@1  50.00 ( 60.02)	Acc@5  82.81 ( 87.77)
Epoch: [14][350/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.6079e+00 (1.4114e+00)	Acc@1  54.69 ( 59.92)	Acc@5  80.47 ( 87.70)
Epoch: [14][360/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.4315e+00 (1.4130e+00)	Acc@1  60.16 ( 59.92)	Acc@5  91.41 ( 87.69)
Epoch: [14][370/391]	Time  0.045 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.4727e+00 (1.4132e+00)	Acc@1  57.03 ( 59.93)	Acc@5  86.72 ( 87.69)
Epoch: [14][380/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.4808e+00 (1.4143e+00)	Acc@1  56.25 ( 59.87)	Acc@5  89.84 ( 87.70)
Epoch: [14][390/391]	Time  0.028 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.2426e+00 (1.4132e+00)	Acc@1  65.00 ( 59.95)	Acc@5  86.25 ( 87.69)
## e[14] optimizer.zero_grad (sum) time: 0.28826403617858887
## e[14]       loss.backward (sum) time: 4.159190893173218
## e[14]      optimizer.step (sum) time: 1.8954918384552002
## epoch[14] training(only) time: 16.401691198349
# Switched to evaluate mode...
Test: [  0/100]	Time  0.154 ( 0.154)	Loss 1.7055e+00 (1.7055e+00)	Acc@1  54.00 ( 54.00)	Acc@5  79.00 ( 79.00)
Test: [ 10/100]	Time  0.024 ( 0.034)	Loss 1.7946e+00 (1.7507e+00)	Acc@1  55.00 ( 55.27)	Acc@5  85.00 ( 82.18)
Test: [ 20/100]	Time  0.025 ( 0.029)	Loss 1.2926e+00 (1.7020e+00)	Acc@1  61.00 ( 55.81)	Acc@5  87.00 ( 83.00)
Test: [ 30/100]	Time  0.024 ( 0.027)	Loss 1.9028e+00 (1.7443e+00)	Acc@1  47.00 ( 54.87)	Acc@5  82.00 ( 82.65)
Test: [ 40/100]	Time  0.023 ( 0.026)	Loss 1.8764e+00 (1.7305e+00)	Acc@1  55.00 ( 55.07)	Acc@5  78.00 ( 83.05)
Test: [ 50/100]	Time  0.024 ( 0.026)	Loss 1.6686e+00 (1.7474e+00)	Acc@1  52.00 ( 54.33)	Acc@5  85.00 ( 82.78)
Test: [ 60/100]	Time  0.018 ( 0.025)	Loss 1.5862e+00 (1.7387e+00)	Acc@1  56.00 ( 54.41)	Acc@5  85.00 ( 82.95)
Test: [ 70/100]	Time  0.024 ( 0.025)	Loss 1.7980e+00 (1.7429e+00)	Acc@1  53.00 ( 54.32)	Acc@5  83.00 ( 83.00)
Test: [ 80/100]	Time  0.028 ( 0.024)	Loss 1.7900e+00 (1.7521e+00)	Acc@1  56.00 ( 54.19)	Acc@5  81.00 ( 82.96)
Test: [ 90/100]	Time  0.019 ( 0.024)	Loss 1.8670e+00 (1.7359e+00)	Acc@1  55.00 ( 54.46)	Acc@5  77.00 ( 83.15)
 * Acc@1 54.510 Acc@5 83.240
### epoch[14] execution time: 18.825736045837402
EPOCH 15
i:   0, name:           module.stem.0.weight  changing lr from: 0.079901783211565186   to: 0.077055136834451199
i:   1, name:             module.stem.0.bias  changing lr from: 0.080186025214798784   to: 0.077373730785511671
i:   2, name:           module.stem.1.weight  changing lr from: 0.080466098085956131   to: 0.077687768905474908
i:   3, name:             module.stem.1.bias  changing lr from: 0.080742062936704939   to: 0.077997314093096848
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.081013980168980634   to: 0.078302428670792554
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.081281909471705494   to: 0.078603174372825185
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.081545909818286827   to: 0.078899612334662209
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.081806039464848157   to: 0.079191803083436721
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.082062355949149332   to: 0.079479806529454702
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.082314916090153789   to: 0.079763681958691837
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.082563775988203122   to: 0.080043488026225934
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.082808991025761280   to: 0.080319282750553889
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.083050615868692071   to: 0.080591123508743714
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.083288704468036157   to: 0.080859067032375415
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.083523310062254830   to: 0.081123169404225773
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.083754485179909743   to: 0.081383486055654986
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.083982281642749235   to: 0.081640071764654362
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.084206750569173525   to: 0.081892980654516737
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.084427942378052206   to: 0.082142266193092936
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.084645906792869041   to: 0.082387981192599186
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.084860692846170094   to: 0.082630177809942168
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.085072348884292978   to: 0.082868907547530346
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.085280922572355367   to: 0.083104221254540922
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.085486460899482808   to: 0.083336169128614149
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.085689010184256398   to: 0.083564800717947474
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.085888616080362357   to: 0.083790164923763524
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.086085323582425821   to: 0.084012310003127477
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.086279177032012988   to: 0.084231283572090046
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.086470220123785940   to: 0.084447132609134015
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.086658495911795447   to: 0.084659903458902896
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.086844046815898038   to: 0.084869641836191889
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.087026914628284324   to: 0.085076392830181674
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.087207140520106100   to: 0.085280200908897139
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.087384765048190663   to: 0.085481109923873699
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.087559828161831277   to: 0.085679163115014986
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.087732369209643529   to: 0.085874403115626066
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.087902426946477610   to: 0.086066871957608079
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.088070039540377454   to: 0.086256611076799702
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.088235244579578057   to: 0.086443661318452811
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.088398079079532621   to: 0.086628062942829376
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.088558579489962042   to: 0.086809855630908095
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.088716781701919600   to: 0.086989078490189400
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.088872721054863504   to: 0.087165770060588232
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.089026432343731809   to: 0.087339968320404582
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.089177949826012973   to: 0.087511710692362438
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.089327307228806802   to: 0.087681034049708007
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.089474537755870581   to: 0.087847974722358793
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.089619674094645385   to: 0.088012568503095856
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.089762748423257946   to: 0.088174850653791159
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.089903792417494091   to: 0.088334855911663554
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.090042837257739455   to: 0.088492618495556188
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.090179913635883888   to: 0.088648172112229459
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.090315051762186294   to: 0.088801549962663262
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.090448281372096442   to: 0.088952784748363295
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.090579631733031060   to: 0.089101908677665931
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.090709131651101199   to: 0.089248953472036902
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.090836809477788660   to: 0.089393950372359088
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.090962693116568960   to: 0.089536930145205418
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.091086810029478826   to: 0.089677923089092199
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.091209187243626214   to: 0.089816959040709993
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.091329851357641073   to: 0.089954067381127711
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.091448828548065353   to: 0.090089277041967092
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.091566144575680672   to: 0.090222616511544507
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.091681824791772296   to: 0.090354113840976941
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.091795894144328566   to: 0.090483796650249915
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.091908377184174175   to: 0.090611692134244609
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.092019298071037037   to: 0.090737827068721980
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.092128680579547179   to: 0.090862227816261951
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.092236548105167793   to: 0.090984920332155481
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.092342923670057017   to: 0.091105930170247984
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.092447829928860567   to: 0.091225282488732351
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.092551289174434448   to: 0.091343002055890077
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.092653323343497629   to: 0.091459113255779254
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.092753954022214119   to: 0.091573640093868092
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.092853202451704753   to: 0.091686606202612916
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.092951089533488074   to: 0.091798034846979668
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.093047635834850567   to: 0.091907948929908001
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.093142861594146309   to: 0.092016370997717145
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.093236786726025742   to: 0.092123323245452943
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.093329430826594270   to: 0.092228827522175413
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.093420813178500331   to: 0.092332905336186225
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.093510952755953544   to: 0.092435577860195864
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.093599868229672922   to: 0.092536865936429957
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.093687577971765787   to: 0.092636790081674553
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.093774100060537435   to: 0.092735370492259953
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.093859452285232167   to: 0.092832627048983374
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.093943652150705950   to: 0.092928579321969754
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.094026716882031333   to: 0.093023246575471147
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.094108663429034858   to: 0.093116647772604449
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.094189508470767846   to: 0.093208801580027631
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.094269268419910582   to: 0.093299726372554445
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.094347959427111106   to: 0.093389440237707996
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.094425597385258436   to: 0.093477960980213104
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.094502197933691579   to: 0.093565306126427758
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.094577776462344221   to: 0.093651492928714095
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.094652348115826457   to: 0.093736538369748934
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.094725927797443391   to: 0.093820459166774353
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.094798530173152096   to: 0.093903271775788597
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.094870169675456931   to: 0.093984992395677744
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.094940860507244179   to: 0.094065636972288494
i: 100, name:           module.conv10.weight  changing lr from: 0.095010616645556809   to: 0.094145221202442508
i: 101, name:             module.conv10.bias  changing lr from: 0.095079451845309693   to: 0.094223760537892665



# Switched to train mode...
Epoch: [15][  0/391]	Time  0.199 ( 0.199)	Data  0.150 ( 0.150)	Loss 1.4079e+00 (1.4079e+00)	Acc@1  63.28 ( 63.28)	Acc@5  89.06 ( 89.06)
Epoch: [15][ 10/391]	Time  0.040 ( 0.056)	Data  0.001 ( 0.015)	Loss 1.5358e+00 (1.4507e+00)	Acc@1  58.59 ( 58.17)	Acc@5  86.72 ( 87.71)
Epoch: [15][ 20/391]	Time  0.043 ( 0.049)	Data  0.001 ( 0.008)	Loss 1.2523e+00 (1.3713e+00)	Acc@1  64.06 ( 59.82)	Acc@5  89.84 ( 88.69)
Epoch: [15][ 30/391]	Time  0.041 ( 0.047)	Data  0.001 ( 0.006)	Loss 1.2987e+00 (1.3518e+00)	Acc@1  66.41 ( 60.66)	Acc@5  91.41 ( 88.73)
Epoch: [15][ 40/391]	Time  0.044 ( 0.045)	Data  0.001 ( 0.005)	Loss 1.4287e+00 (1.3418e+00)	Acc@1  57.81 ( 60.80)	Acc@5  89.06 ( 89.01)
Epoch: [15][ 50/391]	Time  0.040 ( 0.045)	Data  0.001 ( 0.004)	Loss 1.5230e+00 (1.3493e+00)	Acc@1  53.91 ( 60.59)	Acc@5  85.16 ( 89.09)
Epoch: [15][ 60/391]	Time  0.041 ( 0.044)	Data  0.001 ( 0.003)	Loss 1.2684e+00 (1.3501e+00)	Acc@1  65.62 ( 60.58)	Acc@5  91.41 ( 89.05)
Epoch: [15][ 70/391]	Time  0.039 ( 0.044)	Data  0.001 ( 0.003)	Loss 1.3271e+00 (1.3536e+00)	Acc@1  64.84 ( 60.56)	Acc@5  85.16 ( 88.88)
Epoch: [15][ 80/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.003)	Loss 1.1898e+00 (1.3528e+00)	Acc@1  62.50 ( 60.74)	Acc@5  89.84 ( 88.83)
Epoch: [15][ 90/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.003)	Loss 1.2999e+00 (1.3583e+00)	Acc@1  56.25 ( 60.50)	Acc@5  89.06 ( 88.75)
Epoch: [15][100/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.003)	Loss 1.2631e+00 (1.3519e+00)	Acc@1  63.28 ( 60.85)	Acc@5  90.62 ( 88.78)
Epoch: [15][110/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.4329e+00 (1.3550e+00)	Acc@1  57.81 ( 60.85)	Acc@5  89.84 ( 88.68)
Epoch: [15][120/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.4274e+00 (1.3590e+00)	Acc@1  62.50 ( 60.81)	Acc@5  85.94 ( 88.57)
Epoch: [15][130/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.3224e+00 (1.3626e+00)	Acc@1  66.41 ( 60.88)	Acc@5  88.28 ( 88.41)
Epoch: [15][140/391]	Time  0.041 ( 0.043)	Data  0.002 ( 0.002)	Loss 1.6258e+00 (1.3669e+00)	Acc@1  58.59 ( 60.82)	Acc@5  86.72 ( 88.34)
Epoch: [15][150/391]	Time  0.043 ( 0.043)	Data  0.002 ( 0.002)	Loss 1.3407e+00 (1.3678e+00)	Acc@1  69.53 ( 60.83)	Acc@5  86.72 ( 88.31)
Epoch: [15][160/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.3916e+00 (1.3683e+00)	Acc@1  62.50 ( 60.89)	Acc@5  89.06 ( 88.25)
Epoch: [15][170/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.2121e+00 (1.3672e+00)	Acc@1  64.84 ( 60.83)	Acc@5  90.62 ( 88.38)
Epoch: [15][180/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.0310e+00 (1.3634e+00)	Acc@1  66.41 ( 60.95)	Acc@5  96.88 ( 88.45)
Epoch: [15][190/391]	Time  0.045 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.3837e+00 (1.3621e+00)	Acc@1  58.59 ( 60.99)	Acc@5  90.62 ( 88.44)
Epoch: [15][200/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.2725e+00 (1.3640e+00)	Acc@1  60.94 ( 60.89)	Acc@5  91.41 ( 88.44)
Epoch: [15][210/391]	Time  0.045 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.5121e+00 (1.3651e+00)	Acc@1  58.59 ( 60.87)	Acc@5  82.81 ( 88.43)
Epoch: [15][220/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.5051e+00 (1.3645e+00)	Acc@1  58.59 ( 60.83)	Acc@5  87.50 ( 88.40)
Epoch: [15][230/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.5646e+00 (1.3704e+00)	Acc@1  53.12 ( 60.77)	Acc@5  89.06 ( 88.34)
Epoch: [15][240/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.3177e+00 (1.3703e+00)	Acc@1  60.94 ( 60.70)	Acc@5  86.72 ( 88.37)
Epoch: [15][250/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.3748e+00 (1.3687e+00)	Acc@1  65.62 ( 60.78)	Acc@5  89.84 ( 88.39)
Epoch: [15][260/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.4046e+00 (1.3696e+00)	Acc@1  59.38 ( 60.69)	Acc@5  87.50 ( 88.37)
Epoch: [15][270/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.6988e+00 (1.3731e+00)	Acc@1  54.69 ( 60.61)	Acc@5  82.03 ( 88.33)
Epoch: [15][280/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.4671e+00 (1.3713e+00)	Acc@1  60.16 ( 60.69)	Acc@5  85.94 ( 88.35)
Epoch: [15][290/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.3157e+00 (1.3716e+00)	Acc@1  61.72 ( 60.67)	Acc@5  89.06 ( 88.36)
Epoch: [15][300/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.3483e+00 (1.3743e+00)	Acc@1  62.50 ( 60.62)	Acc@5  89.06 ( 88.32)
Epoch: [15][310/391]	Time  0.046 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.5037e+00 (1.3731e+00)	Acc@1  52.34 ( 60.59)	Acc@5  89.06 ( 88.35)
Epoch: [15][320/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.2311e+00 (1.3769e+00)	Acc@1  61.72 ( 60.52)	Acc@5  90.62 ( 88.31)
Epoch: [15][330/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.4395e+00 (1.3773e+00)	Acc@1  60.94 ( 60.47)	Acc@5  89.06 ( 88.30)
Epoch: [15][340/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.3019e+00 (1.3782e+00)	Acc@1  67.19 ( 60.45)	Acc@5  91.41 ( 88.29)
Epoch: [15][350/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.4006e+00 (1.3784e+00)	Acc@1  59.38 ( 60.43)	Acc@5  87.50 ( 88.24)
Epoch: [15][360/391]	Time  0.047 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.4209e+00 (1.3795e+00)	Acc@1  63.28 ( 60.43)	Acc@5  85.94 ( 88.22)
Epoch: [15][370/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.3975e+00 (1.3801e+00)	Acc@1  60.94 ( 60.43)	Acc@5  88.28 ( 88.20)
Epoch: [15][380/391]	Time  0.045 ( 0.042)	Data  0.002 ( 0.001)	Loss 1.4266e+00 (1.3789e+00)	Acc@1  63.28 ( 60.50)	Acc@5  90.62 ( 88.23)
Epoch: [15][390/391]	Time  0.029 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.6800e+00 (1.3813e+00)	Acc@1  48.75 ( 60.45)	Acc@5  80.00 ( 88.18)
## e[15] optimizer.zero_grad (sum) time: 0.2866511344909668
## e[15]       loss.backward (sum) time: 4.140379428863525
## e[15]      optimizer.step (sum) time: 1.842296838760376
## epoch[15] training(only) time: 16.495619535446167
# Switched to evaluate mode...
Test: [  0/100]	Time  0.157 ( 0.157)	Loss 1.6118e+00 (1.6118e+00)	Acc@1  58.00 ( 58.00)	Acc@5  83.00 ( 83.00)
Test: [ 10/100]	Time  0.024 ( 0.036)	Loss 1.6278e+00 (1.6984e+00)	Acc@1  52.00 ( 56.64)	Acc@5  88.00 ( 82.82)
Test: [ 20/100]	Time  0.024 ( 0.030)	Loss 1.5348e+00 (1.6704e+00)	Acc@1  60.00 ( 55.76)	Acc@5  86.00 ( 83.57)
Test: [ 30/100]	Time  0.020 ( 0.027)	Loss 1.6162e+00 (1.6855e+00)	Acc@1  53.00 ( 55.35)	Acc@5  85.00 ( 83.06)
Test: [ 40/100]	Time  0.020 ( 0.025)	Loss 1.8153e+00 (1.6935e+00)	Acc@1  56.00 ( 54.93)	Acc@5  79.00 ( 82.85)
Test: [ 50/100]	Time  0.021 ( 0.024)	Loss 1.6699e+00 (1.6995e+00)	Acc@1  54.00 ( 54.61)	Acc@5  79.00 ( 82.63)
Test: [ 60/100]	Time  0.022 ( 0.024)	Loss 1.5800e+00 (1.6877e+00)	Acc@1  58.00 ( 54.85)	Acc@5  84.00 ( 82.79)
Test: [ 70/100]	Time  0.023 ( 0.024)	Loss 1.6958e+00 (1.6857e+00)	Acc@1  58.00 ( 54.92)	Acc@5  83.00 ( 82.90)
Test: [ 80/100]	Time  0.024 ( 0.023)	Loss 1.7746e+00 (1.6885e+00)	Acc@1  59.00 ( 54.96)	Acc@5  78.00 ( 82.90)
Test: [ 90/100]	Time  0.024 ( 0.023)	Loss 2.0457e+00 (1.6835e+00)	Acc@1  51.00 ( 55.01)	Acc@5  73.00 ( 82.84)
 * Acc@1 55.010 Acc@5 82.880
### epoch[15] execution time: 18.887572765350342
EPOCH 16
i:   0, name:           module.stem.0.weight  changing lr from: 0.077055136834451199   to: 0.074087430661751719
i:   1, name:             module.stem.0.bias  changing lr from: 0.077373730785511671   to: 0.074440682299403246
i:   2, name:           module.stem.1.weight  changing lr from: 0.077687768905474908   to: 0.074789024459170600
i:   3, name:             module.stem.1.bias  changing lr from: 0.077997314093096848   to: 0.075132520154611429
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.078302428670792554   to: 0.075471232020374396
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.078603174372825185   to: 0.075805222289630700
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.078899612334662209   to: 0.076134552773131484
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.079191803083436721   to: 0.076459284839811639
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.079479806529454702   to: 0.076779479398863815
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.079763681958691837   to: 0.077095196883209413
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.080043488026225934   to: 0.077406497234297586
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.080319282750553889   to: 0.077713439888164842
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.080591123508743714   to: 0.078016083762691965
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.080859067032375415   to: 0.078314487245997252
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.081123169404225773   to: 0.078608708185907511
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.081383486055654986   to: 0.078898803880451784
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.081640071764654362   to: 0.079184831069323822
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.081892980654516737   to: 0.079466845926263241
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.082142266193092936   to: 0.079744904052306359
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.082387981192599186   to: 0.080019060469860459
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.082630177809942168   to: 0.080289369617557366
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.082868907547530346   to: 0.080555885345843903
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.083104221254540922   to: 0.080818660913269044
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.083336169128614149   to: 0.081077748983429204
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.083564800717947474   to: 0.081333201622534976
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.083790164923763524   to: 0.081585070297564261
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.084012310003127477   to: 0.081833405874968346
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.084231283572090046   to: 0.082078258619899258
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.084447132609134015   to: 0.082319678195927865
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.084659903458902896   to: 0.082557713665223631
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.084869641836191889   to: 0.082792413489168729
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.085076392830181674   to: 0.083023825529380216
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.085280200908897139   to: 0.083251997049114845
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.085481109923873699   to: 0.083476974715033000
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.085679163115014986   to: 0.083698804599299195
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.085874403115626066   to: 0.083917532181996934
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.086066871957608079   to: 0.084133202353837921
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.086256611076799702   to: 0.084345859419145741
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.086443661318452811   to: 0.084555547099095574
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.086628062942829376   to: 0.084762308535191955
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.086809855630908095   to: 0.084966186292968066
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.086989078490189400   to: 0.085167222365890305
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.087165770060588232   to: 0.085365458179452944
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.087339968320404582   to: 0.085560934595448668
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.087511710692362438   to: 0.085753691916400948
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.087681034049708007   to: 0.085943769890145294
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.087847974722358793   to: 0.086131207714547242
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.088012568503095856   to: 0.086316044042345080
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.088174850653791159   to: 0.086498316986106299
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.088334855911663554   to: 0.086678064123287199
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.088492618495556188   to: 0.086855322501385612
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.088648172112229459   to: 0.087030128643177385
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.088801549962663262   to: 0.087202518552027444
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.088952784748363295   to: 0.087372527717267251
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.089101908677665931   to: 0.087540191119630253
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.089248953472036902   to: 0.087705543236737959
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.089393950372359088   to: 0.087868618048629513
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.089536930145205418   to: 0.088029449043327712
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.089677923089092199   to: 0.088188069222435383
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.089816959040709993   to: 0.088344511106755674
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.089954067381127711   to: 0.088498806741931113
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.090089277041967092   to: 0.088650987704095435
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.090222616511544507   to: 0.088801085105533528
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.090354113840976941   to: 0.088949129600344734
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.090483796650249915   to: 0.089095151390104627
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.090611692134244609   to: 0.089239180229521556
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.090737827068721980   to: 0.089381245432083756
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.090862227816261951   to: 0.089521375875693143
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.090984920332155481   to: 0.089659600008282755
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.091105930170247984   to: 0.089795945853414133
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.091225282488732351   to: 0.089930441015851861
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.091343002055890077   to: 0.090063112687112368
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.091459113255779254   to: 0.090193987650984242
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.091573640093868092   to: 0.090323092289017790
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.091686606202612916   to: 0.090450452585981223
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.091798034846979668   to: 0.090576094135281740
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.091907948929908001   to: 0.090700042144349069
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.092016370997717145   to: 0.090822321439980036
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.092123323245452943   to: 0.090942956473642270
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.092228827522175413   to: 0.091061971326735491
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.092332905336186225   to: 0.091179389715808842
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.092435577860195864   to: 0.091295234997733454
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.092536865936429957   to: 0.091409530174828169
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.092636790081674553   to: 0.091522297899938307
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.092735370492259953   to: 0.091633560481465606
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.092832627048983374   to: 0.091743339888349151
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.092928579321969754   to: 0.091851657754996069
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.093023246575471147   to: 0.091958535386161333
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.093116647772604449   to: 0.092063993761776153
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.093208801580027631   to: 0.092168053541724485
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.093299726372554445   to: 0.092270735070566823
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.093389440237707996   to: 0.092372058382211200
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.093477960980213104   to: 0.092472043204530951
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.093565306126427758   to: 0.092570708963928855
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.093651492928714095   to: 0.092668074789847676
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.093736538369748934   to: 0.092764159519226522
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.093820459166774353   to: 0.092858981700903398
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.093903271775788597   to: 0.092952559599963500
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.093984992395677744   to: 0.093044911202033412
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.094065636972288494   to: 0.093136054217521150
i: 100, name:           module.conv10.weight  changing lr from: 0.094145221202442508   to: 0.093226006085802171
i: 101, name:             module.conv10.bias  changing lr from: 0.094223760537892665   to: 0.093314783979351362



# Switched to train mode...
Epoch: [16][  0/391]	Time  0.201 ( 0.201)	Data  0.155 ( 0.155)	Loss 1.3857e+00 (1.3857e+00)	Acc@1  57.03 ( 57.03)	Acc@5  88.28 ( 88.28)
Epoch: [16][ 10/391]	Time  0.043 ( 0.057)	Data  0.001 ( 0.015)	Loss 1.2230e+00 (1.3126e+00)	Acc@1  59.38 ( 61.72)	Acc@5  92.19 ( 88.99)
Epoch: [16][ 20/391]	Time  0.042 ( 0.051)	Data  0.001 ( 0.008)	Loss 1.0329e+00 (1.2903e+00)	Acc@1  70.31 ( 62.46)	Acc@5  94.53 ( 89.55)
Epoch: [16][ 30/391]	Time  0.043 ( 0.048)	Data  0.001 ( 0.006)	Loss 1.0546e+00 (1.2746e+00)	Acc@1  70.31 ( 63.08)	Acc@5  92.97 ( 89.57)
Epoch: [16][ 40/391]	Time  0.044 ( 0.046)	Data  0.001 ( 0.005)	Loss 1.3020e+00 (1.2798e+00)	Acc@1  63.28 ( 62.98)	Acc@5  86.72 ( 89.33)
Epoch: [16][ 50/391]	Time  0.042 ( 0.045)	Data  0.001 ( 0.004)	Loss 1.2561e+00 (1.2825e+00)	Acc@1  64.06 ( 62.84)	Acc@5  90.62 ( 89.48)
Epoch: [16][ 60/391]	Time  0.045 ( 0.045)	Data  0.001 ( 0.004)	Loss 1.3324e+00 (1.2801e+00)	Acc@1  60.16 ( 62.87)	Acc@5  91.41 ( 89.59)
Epoch: [16][ 70/391]	Time  0.042 ( 0.044)	Data  0.001 ( 0.003)	Loss 1.1089e+00 (1.2790e+00)	Acc@1  68.75 ( 62.86)	Acc@5  93.75 ( 89.74)
Epoch: [16][ 80/391]	Time  0.043 ( 0.044)	Data  0.001 ( 0.003)	Loss 1.3251e+00 (1.2737e+00)	Acc@1  67.19 ( 63.16)	Acc@5  89.06 ( 89.71)
Epoch: [16][ 90/391]	Time  0.040 ( 0.044)	Data  0.001 ( 0.003)	Loss 1.2378e+00 (1.2754e+00)	Acc@1  64.06 ( 63.09)	Acc@5  92.19 ( 89.65)
Epoch: [16][100/391]	Time  0.041 ( 0.044)	Data  0.001 ( 0.003)	Loss 1.1382e+00 (1.2749e+00)	Acc@1  67.97 ( 63.17)	Acc@5  89.84 ( 89.63)
Epoch: [16][110/391]	Time  0.042 ( 0.044)	Data  0.001 ( 0.002)	Loss 1.2742e+00 (1.2801e+00)	Acc@1  63.28 ( 62.94)	Acc@5  89.84 ( 89.54)
Epoch: [16][120/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.1068e+00 (1.2771e+00)	Acc@1  69.53 ( 63.07)	Acc@5  90.62 ( 89.61)
Epoch: [16][130/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.5968e+00 (1.2846e+00)	Acc@1  55.47 ( 62.95)	Acc@5  85.94 ( 89.53)
Epoch: [16][140/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.4101e+00 (1.2904e+00)	Acc@1  64.84 ( 62.80)	Acc@5  84.38 ( 89.42)
Epoch: [16][150/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.2805e+00 (1.2959e+00)	Acc@1  60.94 ( 62.62)	Acc@5  90.62 ( 89.28)
Epoch: [16][160/391]	Time  0.046 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.2326e+00 (1.2969e+00)	Acc@1  68.75 ( 62.55)	Acc@5  91.41 ( 89.31)
Epoch: [16][170/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.1103e+00 (1.2953e+00)	Acc@1  66.41 ( 62.60)	Acc@5  92.19 ( 89.34)
Epoch: [16][180/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.2772e+00 (1.2995e+00)	Acc@1  65.62 ( 62.54)	Acc@5  92.19 ( 89.32)
Epoch: [16][190/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.2750e+00 (1.3038e+00)	Acc@1  62.50 ( 62.49)	Acc@5  89.06 ( 89.23)
Epoch: [16][200/391]	Time  0.044 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.6511e+00 (1.3089e+00)	Acc@1  49.22 ( 62.30)	Acc@5  81.25 ( 89.14)
Epoch: [16][210/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.4494e+00 (1.3105e+00)	Acc@1  53.91 ( 62.21)	Acc@5  90.62 ( 89.17)
Epoch: [16][220/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.2466e+00 (1.3128e+00)	Acc@1  61.72 ( 62.14)	Acc@5  90.62 ( 89.12)
Epoch: [16][230/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.3653e+00 (1.3176e+00)	Acc@1  56.25 ( 61.99)	Acc@5  89.06 ( 89.07)
Epoch: [16][240/391]	Time  0.037 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.3813e+00 (1.3167e+00)	Acc@1  65.62 ( 62.07)	Acc@5  89.06 ( 89.13)
Epoch: [16][250/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.2723e+00 (1.3185e+00)	Acc@1  64.84 ( 62.06)	Acc@5  89.06 ( 89.08)
Epoch: [16][260/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.5222e+00 (1.3214e+00)	Acc@1  55.47 ( 61.97)	Acc@5  85.94 ( 89.03)
Epoch: [16][270/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.3111e+00 (1.3229e+00)	Acc@1  59.38 ( 61.94)	Acc@5  84.38 ( 88.98)
Epoch: [16][280/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.1822e+00 (1.3207e+00)	Acc@1  68.75 ( 62.00)	Acc@5  91.41 ( 89.01)
Epoch: [16][290/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.4966e+00 (1.3248e+00)	Acc@1  56.25 ( 61.91)	Acc@5  87.50 ( 88.96)
Epoch: [16][300/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.4723e+00 (1.3265e+00)	Acc@1  53.91 ( 61.84)	Acc@5  84.38 ( 88.93)
Epoch: [16][310/391]	Time  0.046 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.3973e+00 (1.3280e+00)	Acc@1  59.38 ( 61.82)	Acc@5  88.28 ( 88.90)
Epoch: [16][320/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.2690e+00 (1.3297e+00)	Acc@1  64.06 ( 61.79)	Acc@5  92.97 ( 88.91)
Epoch: [16][330/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.3232e+00 (1.3307e+00)	Acc@1  62.50 ( 61.71)	Acc@5  89.06 ( 88.89)
Epoch: [16][340/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.3484e+00 (1.3318e+00)	Acc@1  67.19 ( 61.71)	Acc@5  90.62 ( 88.86)
Epoch: [16][350/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.6732e+00 (1.3340e+00)	Acc@1  54.69 ( 61.63)	Acc@5  81.25 ( 88.81)
Epoch: [16][360/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.4635e+00 (1.3335e+00)	Acc@1  57.81 ( 61.61)	Acc@5  89.84 ( 88.84)
Epoch: [16][370/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.5245e+00 (1.3345e+00)	Acc@1  50.00 ( 61.57)	Acc@5  89.06 ( 88.83)
Epoch: [16][380/391]	Time  0.037 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.2199e+00 (1.3342e+00)	Acc@1  64.06 ( 61.60)	Acc@5  89.84 ( 88.85)
Epoch: [16][390/391]	Time  0.026 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.4004e+00 (1.3352e+00)	Acc@1  63.75 ( 61.56)	Acc@5  85.00 ( 88.86)
## e[16] optimizer.zero_grad (sum) time: 0.28873372077941895
## e[16]       loss.backward (sum) time: 4.133502244949341
## e[16]      optimizer.step (sum) time: 1.903968095779419
## epoch[16] training(only) time: 16.419167041778564
# Switched to evaluate mode...
Test: [  0/100]	Time  0.152 ( 0.152)	Loss 1.6520e+00 (1.6520e+00)	Acc@1  54.00 ( 54.00)	Acc@5  82.00 ( 82.00)
Test: [ 10/100]	Time  0.023 ( 0.034)	Loss 1.7550e+00 (1.7252e+00)	Acc@1  54.00 ( 56.27)	Acc@5  89.00 ( 84.00)
Test: [ 20/100]	Time  0.024 ( 0.029)	Loss 1.5368e+00 (1.6996e+00)	Acc@1  57.00 ( 55.67)	Acc@5  88.00 ( 84.00)
Test: [ 30/100]	Time  0.024 ( 0.027)	Loss 1.7756e+00 (1.7188e+00)	Acc@1  50.00 ( 54.94)	Acc@5  84.00 ( 83.39)
Test: [ 40/100]	Time  0.021 ( 0.026)	Loss 1.7068e+00 (1.7181e+00)	Acc@1  52.00 ( 54.80)	Acc@5  82.00 ( 83.05)
Test: [ 50/100]	Time  0.022 ( 0.025)	Loss 1.6983e+00 (1.7313e+00)	Acc@1  58.00 ( 54.47)	Acc@5  83.00 ( 82.65)
Test: [ 60/100]	Time  0.017 ( 0.024)	Loss 1.6921e+00 (1.7092e+00)	Acc@1  50.00 ( 54.61)	Acc@5  79.00 ( 82.82)
Test: [ 70/100]	Time  0.023 ( 0.024)	Loss 1.8682e+00 (1.7096e+00)	Acc@1  51.00 ( 54.55)	Acc@5  78.00 ( 82.85)
Test: [ 80/100]	Time  0.022 ( 0.023)	Loss 1.7623e+00 (1.7120e+00)	Acc@1  56.00 ( 54.52)	Acc@5  81.00 ( 82.81)
Test: [ 90/100]	Time  0.024 ( 0.024)	Loss 1.9773e+00 (1.6995e+00)	Acc@1  51.00 ( 54.81)	Acc@5  79.00 ( 83.08)
 * Acc@1 54.930 Acc@5 83.160
### epoch[16] execution time: 18.83674716949463
EPOCH 17
i:   0, name:           module.stem.0.weight  changing lr from: 0.074087430661751719   to: 0.071012453525392968
i:   1, name:             module.stem.0.bias  changing lr from: 0.074440682299403246   to: 0.071400308933651083
i:   2, name:           module.stem.1.weight  changing lr from: 0.074789024459170600   to: 0.071782943887689715
i:   3, name:             module.stem.1.bias  changing lr from: 0.075132520154611429   to: 0.072160419590674318
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.075471232020374396   to: 0.072532797134279917
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.075805222289630700   to: 0.072900137463054238
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.076134552773131484   to: 0.073262501340933484
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.076459284839811639   to: 0.073619949319811334
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.076779479398863815   to: 0.073972541710067188
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.077095196883209413   to: 0.074320338552962509
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.077406497234297586   to: 0.074663399594818478
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.077713439888164842   to: 0.075001784262891738
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.078016083762691965   to: 0.075335551642867815
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.078314487245997252   to: 0.075664760457896232
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.078608708185907511   to: 0.075989469049093358
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.078898803880451784   to: 0.076309735357443287
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.079184831069323822   to: 0.076625616907028682
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.079466845926263241   to: 0.076937170789527887
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.079744904052306359   to: 0.077244453649916056
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.080019060469860459   to: 0.077547521673311276
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.080289369617557366   to: 0.077846430572909353
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.080555885345843903   to: 0.078141235578952833
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.080818660913269044   to: 0.078431991428682624
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.081077748983429204   to: 0.078718752357222754
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.081333201622534976   to: 0.079001572089350713
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.081585070297564261   to: 0.079280503832108051
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.081833405874968346   to: 0.079555600268208057
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.082078258619899258   to: 0.079826913550199066
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.082319678195927865   to: 0.080094495295343654
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.082557713665223631   to: 0.080358396581175925
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.082792413489168729   to: 0.080618667941700986
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.083023825529380216   to: 0.080875359364201649
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.083251997049114845   to: 0.081128520286619751
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.083476974715033000   to: 0.081378199595480413
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.083698804599299195   to: 0.081624445624329009
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.083917532181996934   to: 0.081867306152652530
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.084133202353837921   to: 0.082106828405257612
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.084345859419145741   to: 0.082343059052079004
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.084555547099095574   to: 0.082576044208393914
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.084762308535191955   to: 0.082805829435418116
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.084966186292968066   to: 0.083032459741261028
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.085167222365890305   to: 0.083255979582218559
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.085365458179452944   to: 0.083476432864382499
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.085560934595448668   to: 0.083693862945547426
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.085753691916400948   to: 0.083908312637395718
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.085943769890145294   to: 0.084119824207943394
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.086131207714547242   to: 0.084328439384229348
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.086316044042345080   to: 0.084534199355232181
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.086498316986106299   to: 0.084737144774998732
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.086678064123287199   to: 0.084937315765970134
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.086855322501385612   to: 0.085134751922491023
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.087030128643177385   to: 0.085329492314488858
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.087202518552027444   to: 0.085521575491310703
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.087372527717267251   to: 0.085711039485705298
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.087540191119630253   to: 0.085897921817939274
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.087705543236737959   to: 0.086082259500036257
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.087868618048629513   to: 0.086264089040129152
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.088029449043327712   to: 0.086443446446915109
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.088188069222435383   to: 0.086620367234204729
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.088344511106755674   to: 0.086794886425555620
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.088498806741931113   to: 0.086967038558983245
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.088650987704095435   to: 0.087136857691739955
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.088801085105533528   to: 0.087304377405155342
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.088949129600344734   to: 0.087469630809530768
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.089095151390104627   to: 0.087632650549081051
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.089239180229521556   to: 0.087793468806917296
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.089381245432083756   to: 0.087952117310064387
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.089521375875693143   to: 0.088108627334507972
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.089659600008282755   to: 0.088263029710265103
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.089795945853414133   to: 0.088415354826473558
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.089930441015851861   to: 0.088565632636495362
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.090063112687112368   to: 0.088713892663029412
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.090193987650984242   to: 0.088860164003229325
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.090323092289017790   to: 0.089004475333822497
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.090450452585981223   to: 0.089146854916226245
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.090576094135281740   to: 0.089287330601657930
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.090700042144349069   to: 0.089425929836235277
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.090822321439980036   to: 0.089562679666064030
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.090942956473642270   to: 0.089697606742309866
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.091061971326735491   to: 0.089830737326251894
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.091179389715808842   to: 0.089962097294314980
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.091295234997733454   to: 0.090091712143078678
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.091409530174828169   to: 0.090219606994260376
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.091522297899938307   to: 0.090345806599670578
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.091633560481465606   to: 0.090470335346138381
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.091743339888349151   to: 0.090593217260405284
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.091851657754996069   to: 0.090714476013985662
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.091958535386161333   to: 0.090834134927992291
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.092063993761776153   to: 0.090952216977925576
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.092168053541724485   to: 0.091068744798425028
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.092270735070566823   to: 0.091183740687981740
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.092372058382211200   to: 0.091297226613610935
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.092472043204530951   to: 0.091409224215483226
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.092570708963928855   to: 0.091519754811513976
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.092668074789847676   to: 0.091628839401909731
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.092764159519226522   to: 0.091736498673670799
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.092858981700903398   to: 0.091842753005049724
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.092952559599963500   to: 0.091947622469964518
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.093044911202033412   to: 0.092051126842366535
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.093136054217521150   to: 0.092153285600562115
i: 100, name:           module.conv10.weight  changing lr from: 0.093226006085802171   to: 0.092254117931487925
i: 101, name:             module.conv10.bias  changing lr from: 0.093314783979351362   to: 0.092353642734939401



# Switched to train mode...
Epoch: [17][  0/391]	Time  0.197 ( 0.197)	Data  0.150 ( 0.150)	Loss 1.2787e+00 (1.2787e+00)	Acc@1  63.28 ( 63.28)	Acc@5  86.72 ( 86.72)
Epoch: [17][ 10/391]	Time  0.041 ( 0.056)	Data  0.001 ( 0.014)	Loss 1.1528e+00 (1.2320e+00)	Acc@1  68.75 ( 64.56)	Acc@5  91.41 ( 90.34)
Epoch: [17][ 20/391]	Time  0.044 ( 0.049)	Data  0.001 ( 0.008)	Loss 1.1474e+00 (1.2435e+00)	Acc@1  71.09 ( 64.92)	Acc@5  91.41 ( 90.14)
Epoch: [17][ 30/391]	Time  0.042 ( 0.047)	Data  0.001 ( 0.006)	Loss 1.1829e+00 (1.2415e+00)	Acc@1  64.06 ( 64.69)	Acc@5  91.41 ( 90.12)
Epoch: [17][ 40/391]	Time  0.041 ( 0.046)	Data  0.001 ( 0.005)	Loss 1.4493e+00 (1.2438e+00)	Acc@1  60.16 ( 64.88)	Acc@5  86.72 ( 90.03)
Epoch: [17][ 50/391]	Time  0.043 ( 0.045)	Data  0.001 ( 0.004)	Loss 1.2340e+00 (1.2406e+00)	Acc@1  63.28 ( 64.71)	Acc@5  89.06 ( 89.86)
Epoch: [17][ 60/391]	Time  0.041 ( 0.044)	Data  0.001 ( 0.003)	Loss 1.5456e+00 (1.2405e+00)	Acc@1  54.69 ( 64.37)	Acc@5  88.28 ( 90.02)
Epoch: [17][ 70/391]	Time  0.043 ( 0.044)	Data  0.001 ( 0.003)	Loss 1.2778e+00 (1.2448e+00)	Acc@1  61.72 ( 64.49)	Acc@5  87.50 ( 89.90)
Epoch: [17][ 80/391]	Time  0.043 ( 0.044)	Data  0.001 ( 0.003)	Loss 1.2955e+00 (1.2540e+00)	Acc@1  65.62 ( 64.22)	Acc@5  90.62 ( 89.75)
Epoch: [17][ 90/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.003)	Loss 1.2056e+00 (1.2623e+00)	Acc@1  66.41 ( 63.87)	Acc@5  91.41 ( 89.74)
Epoch: [17][100/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.3749e+00 (1.2655e+00)	Acc@1  58.59 ( 63.82)	Acc@5  89.84 ( 89.81)
Epoch: [17][110/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.1853e+00 (1.2653e+00)	Acc@1  66.41 ( 63.75)	Acc@5  89.84 ( 89.84)
Epoch: [17][120/391]	Time  0.047 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.2758e+00 (1.2633e+00)	Acc@1  66.41 ( 63.68)	Acc@5  93.75 ( 89.93)
Epoch: [17][130/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.1218e+00 (1.2665e+00)	Acc@1  67.19 ( 63.50)	Acc@5  92.97 ( 89.85)
Epoch: [17][140/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.2564e+00 (1.2699e+00)	Acc@1  64.84 ( 63.36)	Acc@5  91.41 ( 89.80)
Epoch: [17][150/391]	Time  0.047 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.3337e+00 (1.2756e+00)	Acc@1  59.38 ( 63.15)	Acc@5  88.28 ( 89.70)
Epoch: [17][160/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.2494e+00 (1.2760e+00)	Acc@1  60.16 ( 63.14)	Acc@5  91.41 ( 89.71)
Epoch: [17][170/391]	Time  0.036 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.3629e+00 (1.2787e+00)	Acc@1  66.41 ( 63.08)	Acc@5  84.38 ( 89.63)
Epoch: [17][180/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.2626e+00 (1.2809e+00)	Acc@1  64.06 ( 63.01)	Acc@5  92.19 ( 89.66)
Epoch: [17][190/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.2456e+00 (1.2840e+00)	Acc@1  63.28 ( 62.98)	Acc@5  91.41 ( 89.62)
Epoch: [17][200/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.2310e+00 (1.2840e+00)	Acc@1  64.06 ( 62.90)	Acc@5  89.84 ( 89.58)
Epoch: [17][210/391]	Time  0.045 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.4808e+00 (1.2863e+00)	Acc@1  63.28 ( 62.95)	Acc@5  85.16 ( 89.52)
Epoch: [17][220/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.2158e+00 (1.2881e+00)	Acc@1  66.41 ( 62.89)	Acc@5  94.53 ( 89.54)
Epoch: [17][230/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.2070e+00 (1.2867e+00)	Acc@1  61.72 ( 62.93)	Acc@5  91.41 ( 89.55)
Epoch: [17][240/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.3677e+00 (1.2869e+00)	Acc@1  61.72 ( 62.91)	Acc@5  86.72 ( 89.56)
Epoch: [17][250/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.5835e+00 (1.2889e+00)	Acc@1  58.59 ( 62.81)	Acc@5  83.59 ( 89.54)
Epoch: [17][260/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.3459e+00 (1.2914e+00)	Acc@1  65.62 ( 62.75)	Acc@5  87.50 ( 89.50)
Epoch: [17][270/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.2538e+00 (1.2914e+00)	Acc@1  62.50 ( 62.79)	Acc@5  93.75 ( 89.47)
Epoch: [17][280/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.2381e+00 (1.2904e+00)	Acc@1  59.38 ( 62.84)	Acc@5  90.62 ( 89.49)
Epoch: [17][290/391]	Time  0.045 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.5608e+00 (1.2928e+00)	Acc@1  54.69 ( 62.78)	Acc@5  83.59 ( 89.47)
Epoch: [17][300/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.2637e+00 (1.2923e+00)	Acc@1  61.72 ( 62.76)	Acc@5  92.19 ( 89.48)
Epoch: [17][310/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.2992e+00 (1.2924e+00)	Acc@1  62.50 ( 62.75)	Acc@5  90.62 ( 89.47)
Epoch: [17][320/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.3194e+00 (1.2919e+00)	Acc@1  63.28 ( 62.78)	Acc@5  92.97 ( 89.50)
Epoch: [17][330/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.1590e+00 (1.2945e+00)	Acc@1  62.50 ( 62.74)	Acc@5  91.41 ( 89.48)
Epoch: [17][340/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.3307e+00 (1.2949e+00)	Acc@1  60.94 ( 62.72)	Acc@5  87.50 ( 89.48)
Epoch: [17][350/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.6119e+00 (1.2952e+00)	Acc@1  57.81 ( 62.68)	Acc@5  82.81 ( 89.46)
Epoch: [17][360/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.5046e+00 (1.2965e+00)	Acc@1  60.16 ( 62.65)	Acc@5  89.06 ( 89.44)
Epoch: [17][370/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.1903e+00 (1.2958e+00)	Acc@1  64.84 ( 62.67)	Acc@5  90.62 ( 89.44)
Epoch: [17][380/391]	Time  0.046 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.1592e+00 (1.2978e+00)	Acc@1  67.97 ( 62.62)	Acc@5  90.62 ( 89.41)
Epoch: [17][390/391]	Time  0.029 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.1141e+00 (1.2999e+00)	Acc@1  62.50 ( 62.57)	Acc@5  95.00 ( 89.39)
## e[17] optimizer.zero_grad (sum) time: 0.28569507598876953
## e[17]       loss.backward (sum) time: 4.093339204788208
## e[17]      optimizer.step (sum) time: 1.929086446762085
## epoch[17] training(only) time: 16.354732513427734
# Switched to evaluate mode...
Test: [  0/100]	Time  0.148 ( 0.148)	Loss 1.7192e+00 (1.7192e+00)	Acc@1  61.00 ( 61.00)	Acc@5  82.00 ( 82.00)
Test: [ 10/100]	Time  0.022 ( 0.033)	Loss 1.9029e+00 (1.9263e+00)	Acc@1  51.00 ( 54.27)	Acc@5  88.00 ( 80.91)
Test: [ 20/100]	Time  0.022 ( 0.028)	Loss 1.8604e+00 (1.9113e+00)	Acc@1  47.00 ( 52.62)	Acc@5  84.00 ( 81.57)
Test: [ 30/100]	Time  0.021 ( 0.026)	Loss 1.7961e+00 (1.9382e+00)	Acc@1  51.00 ( 51.87)	Acc@5  85.00 ( 80.94)
Test: [ 40/100]	Time  0.024 ( 0.026)	Loss 2.0847e+00 (1.9594e+00)	Acc@1  52.00 ( 51.27)	Acc@5  77.00 ( 80.27)
Test: [ 50/100]	Time  0.024 ( 0.025)	Loss 1.8786e+00 (1.9853e+00)	Acc@1  57.00 ( 50.98)	Acc@5  80.00 ( 79.69)
Test: [ 60/100]	Time  0.024 ( 0.025)	Loss 1.9530e+00 (1.9878e+00)	Acc@1  47.00 ( 50.64)	Acc@5  82.00 ( 79.77)
Test: [ 70/100]	Time  0.020 ( 0.025)	Loss 1.9944e+00 (1.9971e+00)	Acc@1  50.00 ( 50.41)	Acc@5  82.00 ( 79.76)
Test: [ 80/100]	Time  0.022 ( 0.024)	Loss 2.1633e+00 (2.0066e+00)	Acc@1  52.00 ( 50.33)	Acc@5  74.00 ( 79.54)
Test: [ 90/100]	Time  0.025 ( 0.024)	Loss 2.1858e+00 (1.9975e+00)	Acc@1  47.00 ( 50.45)	Acc@5  73.00 ( 79.49)
 * Acc@1 50.830 Acc@5 79.630
### epoch[17] execution time: 18.807867288589478
EPOCH 18
i:   0, name:           module.stem.0.weight  changing lr from: 0.071012453525392968   to: 0.067844492669611026
i:   1, name:             module.stem.0.bias  changing lr from: 0.071400308933651083   to: 0.068266531260249799
i:   2, name:           module.stem.1.weight  changing lr from: 0.071782943887689715   to: 0.068683090632486718
i:   3, name:             module.stem.1.bias  changing lr from: 0.072160419590674318   to: 0.069094228015733436
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.072532797134279917   to: 0.069500000870223996
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.072900137463054238   to: 0.069900466835977212
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.073262501340933484   to: 0.070295683684498331
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.073619949319811334   to: 0.070685709273101374
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.073972541710067188   to: 0.071070601501738606
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.074320338552962509   to: 0.071450418272227520
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.074663399594818478   to: 0.071825217449770121
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.075001784262891738   to: 0.072195056826663731
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.075335551642867815   to: 0.072559994088105831
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.075664760457896232   to: 0.072920086779999949
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.075989469049093358   to: 0.073275392278672830
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.076309735357443287   to: 0.073625967762417144
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.076625616907028682   to: 0.073971870184776856
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.076937170789527887   to: 0.074313156249496234
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.077244453649916056   to: 0.074649882387056485
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.077547521673311276   to: 0.074982104732726873
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.077846430572909353   to: 0.075309879106060504
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.078141235578952833   to: 0.075633260991767662
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.078431991428682624   to: 0.075952305521902283
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.078718752357222754   to: 0.076267067459299856
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.079001572089350713   to: 0.076577601182207591
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.079280503832108051   to: 0.076883960670050405
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.079555600268208057   to: 0.077186199490277885
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.079826913550199066   to: 0.077484370786240875
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.080094495295343654   to: 0.077778527266047226
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.080358396581175925   to: 0.078068721192349227
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.080618667941700986   to: 0.078355004373017095
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.080875359364201649   to: 0.078637428152654468
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.081128520286619751   to: 0.078916043404914205
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.081378199595480413   to: 0.079190900525574356
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.081624445624329009   to: 0.079462049426335640
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.081867306152652530   to: 0.079729539529304269
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.082106828405257612   to: 0.079993419762124235
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.082343059052079004   to: 0.080253738553726139
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.082576044208393914   to: 0.080510543830659934
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.082805829435418116   to: 0.080763883013981005
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.083032459741261028   to: 0.081013803016660266
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.083255979582218559   to: 0.081260350241490142
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.083476432864382499   to: 0.081503570579459395
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.083693862945547426   to: 0.081743509408571502
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.083908312637395718   to: 0.081980211593081664
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.084119824207943394   to: 0.082213721483129526
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.084328439384229348   to: 0.082444082914744574
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.084534199355232181   to: 0.082671339210203601
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.084737144774998732   to: 0.082895533178719366
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.084937315765970134   to: 0.083116707117441013
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.085134751922491023   to: 0.083334902812748107
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.085329492314488858   to: 0.083550161541819823
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.085521575491310703   to: 0.083762524074463343
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.085711039485705298   to: 0.083972030675184398
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.085897921817939274   to: 0.084178721105485355
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.086082259500036257   to: 0.084382634626375630
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.086264089040129152   to: 0.084583810001080950
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.086443446446915109   to: 0.084782285497937690
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.086620367234204729   to: 0.084978098893460113
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.086794886425555620   to: 0.085171287475567903
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.086967038558983245   to: 0.085361888046963097
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.087136857691739955   to: 0.085549936928644946
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.087304377405155342   to: 0.085735469963552538
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.087469630809530768   to: 0.085918522520325474
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.087632650549081051   to: 0.086099129497172716
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.087793468806917296   to: 0.086277325325841120
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.087952117310064387   to: 0.086453143975674870
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.088108627334507972   to: 0.086626618957757792
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.088263029710265103   to: 0.086797783329130976
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.088415354826473558   to: 0.086966669697078211
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.088565632636495362   to: 0.087133310223472552
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.088713892663029412   to: 0.087297736629177280
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.088860164003229325   to: 0.087459980198495157
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.089004475333822497   to: 0.087620071783659881
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.089146854916226245   to: 0.087778041809364438
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.089287330601657930   to: 0.087933920277320859
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.089425929836235277   to: 0.088087736770846387
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.089562679666064030   to: 0.088239520459471324
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.089697606742309866   to: 0.088389300103564189
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.089830737326251894   to: 0.088537104058969848
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.089962097294314980   to: 0.088682960281656439
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.090091712143078678   to: 0.088826896332367844
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.090219606994260376   to: 0.088968939381277451
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.090345806599670578   to: 0.089109116212640477
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.090470335346138381   to: 0.089247453229441234
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.090593217260405284   to: 0.089383976458032657
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.090714476013985662   to: 0.089518711552765098
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.090834134927992291   to: 0.089651683800601942
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.090952216977925576   to: 0.089782918125719313
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.091068744798425028   to: 0.089912439094087915
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.091183740687981740   to: 0.090040270918034473
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.091297226613610935   to: 0.090166437460781068
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.091409224215483226   to: 0.090290962240960143
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.091519754811513976   to: 0.090413868437103764
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.091628839401909731   to: 0.090535178892105217
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.091736498673670799   to: 0.090654916117651474
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.091842753005049724   to: 0.090773102298625286
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.091947622469964518   to: 0.090889759297475253
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.092051126842366535   to: 0.091004908658552999
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.092153285600562115   to: 0.091118571612416002
i: 100, name:           module.conv10.weight  changing lr from: 0.092254117931487925   to: 0.091230769080095336
i: 101, name:             module.conv10.bias  changing lr from: 0.092353642734939401   to: 0.091341521677327217



# Switched to train mode...
Epoch: [18][  0/391]	Time  0.195 ( 0.195)	Data  0.150 ( 0.150)	Loss 1.2990e+00 (1.2990e+00)	Acc@1  64.84 ( 64.84)	Acc@5  89.06 ( 89.06)
Epoch: [18][ 10/391]	Time  0.044 ( 0.056)	Data  0.001 ( 0.014)	Loss 1.2895e+00 (1.2856e+00)	Acc@1  59.38 ( 62.78)	Acc@5  89.84 ( 89.49)
Epoch: [18][ 20/391]	Time  0.040 ( 0.049)	Data  0.002 ( 0.008)	Loss 1.4318e+00 (1.2693e+00)	Acc@1  59.38 ( 63.10)	Acc@5  87.50 ( 89.88)
Epoch: [18][ 30/391]	Time  0.043 ( 0.046)	Data  0.001 ( 0.006)	Loss 1.2953e+00 (1.2731e+00)	Acc@1  61.72 ( 62.98)	Acc@5  89.84 ( 89.89)
Epoch: [18][ 40/391]	Time  0.041 ( 0.045)	Data  0.001 ( 0.005)	Loss 1.2458e+00 (1.2697e+00)	Acc@1  67.19 ( 63.26)	Acc@5  89.06 ( 89.84)
Epoch: [18][ 50/391]	Time  0.041 ( 0.044)	Data  0.001 ( 0.004)	Loss 1.0572e+00 (1.2654e+00)	Acc@1  67.19 ( 63.53)	Acc@5  96.88 ( 90.04)
Epoch: [18][ 60/391]	Time  0.040 ( 0.044)	Data  0.001 ( 0.004)	Loss 1.4048e+00 (1.2659e+00)	Acc@1  60.94 ( 63.54)	Acc@5  88.28 ( 89.93)
Epoch: [18][ 70/391]	Time  0.045 ( 0.044)	Data  0.001 ( 0.003)	Loss 1.0922e+00 (1.2608e+00)	Acc@1  70.31 ( 63.52)	Acc@5  89.06 ( 90.11)
Epoch: [18][ 80/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.003)	Loss 1.2085e+00 (1.2590e+00)	Acc@1  64.06 ( 63.59)	Acc@5  89.84 ( 90.12)
Epoch: [18][ 90/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.003)	Loss 1.1828e+00 (1.2515e+00)	Acc@1  64.84 ( 63.80)	Acc@5  91.41 ( 90.26)
Epoch: [18][100/391]	Time  0.047 ( 0.043)	Data  0.001 ( 0.003)	Loss 1.3568e+00 (1.2531e+00)	Acc@1  60.94 ( 63.84)	Acc@5  88.28 ( 90.22)
Epoch: [18][110/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.2722e+00 (1.2501e+00)	Acc@1  64.06 ( 63.99)	Acc@5  89.06 ( 90.26)
Epoch: [18][120/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.1280e+00 (1.2478e+00)	Acc@1  67.19 ( 64.07)	Acc@5  91.41 ( 90.21)
Epoch: [18][130/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.3560e+00 (1.2435e+00)	Acc@1  64.06 ( 64.20)	Acc@5  87.50 ( 90.21)
Epoch: [18][140/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.2152e+00 (1.2416e+00)	Acc@1  68.75 ( 64.24)	Acc@5  89.84 ( 90.26)
Epoch: [18][150/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.0679e+00 (1.2444e+00)	Acc@1  70.31 ( 64.14)	Acc@5  92.97 ( 90.24)
Epoch: [18][160/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.0643e+00 (1.2389e+00)	Acc@1  73.44 ( 64.41)	Acc@5  91.41 ( 90.33)
Epoch: [18][170/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.0513e+00 (1.2372e+00)	Acc@1  71.09 ( 64.45)	Acc@5  92.19 ( 90.35)
Epoch: [18][180/391]	Time  0.047 ( 0.042)	Data  0.001 ( 0.002)	Loss 9.9968e-01 (1.2374e+00)	Acc@1  72.66 ( 64.48)	Acc@5  93.75 ( 90.36)
Epoch: [18][190/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.1771e+00 (1.2386e+00)	Acc@1  64.06 ( 64.47)	Acc@5  93.75 ( 90.33)
Epoch: [18][200/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.4557e+00 (1.2431e+00)	Acc@1  58.59 ( 64.40)	Acc@5  88.28 ( 90.26)
Epoch: [18][210/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.2654e+00 (1.2425e+00)	Acc@1  64.84 ( 64.42)	Acc@5  94.53 ( 90.29)
Epoch: [18][220/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.3917e+00 (1.2448e+00)	Acc@1  62.50 ( 64.29)	Acc@5  86.72 ( 90.29)
Epoch: [18][230/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.4302e+00 (1.2458e+00)	Acc@1  58.59 ( 64.26)	Acc@5  87.50 ( 90.22)
Epoch: [18][240/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.0953e+00 (1.2459e+00)	Acc@1  71.09 ( 64.21)	Acc@5  91.41 ( 90.24)
Epoch: [18][250/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.3019e+00 (1.2459e+00)	Acc@1  60.16 ( 64.13)	Acc@5  88.28 ( 90.24)
Epoch: [18][260/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 9.8983e-01 (1.2482e+00)	Acc@1  75.00 ( 64.05)	Acc@5  92.19 ( 90.18)
Epoch: [18][270/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.1741e+00 (1.2482e+00)	Acc@1  63.28 ( 64.03)	Acc@5  91.41 ( 90.18)
Epoch: [18][280/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.4302e+00 (1.2509e+00)	Acc@1  57.03 ( 63.94)	Acc@5  90.62 ( 90.13)
Epoch: [18][290/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.4325e+00 (1.2518e+00)	Acc@1  61.72 ( 63.94)	Acc@5  86.72 ( 90.14)
Epoch: [18][300/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.0400e+00 (1.2550e+00)	Acc@1  70.31 ( 63.86)	Acc@5  92.97 ( 90.07)
Epoch: [18][310/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.3067e+00 (1.2541e+00)	Acc@1  64.06 ( 63.91)	Acc@5  89.84 ( 90.07)
Epoch: [18][320/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.4208e+00 (1.2562e+00)	Acc@1  60.16 ( 63.84)	Acc@5  86.72 ( 90.01)
Epoch: [18][330/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.1974e+00 (1.2562e+00)	Acc@1  68.75 ( 63.84)	Acc@5  91.41 ( 89.98)
Epoch: [18][340/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.2987e+00 (1.2574e+00)	Acc@1  65.62 ( 63.82)	Acc@5  88.28 ( 89.96)
Epoch: [18][350/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.3818e+00 (1.2591e+00)	Acc@1  58.59 ( 63.80)	Acc@5  88.28 ( 89.94)
Epoch: [18][360/391]	Time  0.045 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.2646e+00 (1.2618e+00)	Acc@1  67.19 ( 63.71)	Acc@5  89.84 ( 89.92)
Epoch: [18][370/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.2930e+00 (1.2639e+00)	Acc@1  63.28 ( 63.70)	Acc@5  89.84 ( 89.86)
Epoch: [18][380/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.2007e+00 (1.2653e+00)	Acc@1  64.06 ( 63.65)	Acc@5  89.84 ( 89.84)
Epoch: [18][390/391]	Time  0.031 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.3787e+00 (1.2652e+00)	Acc@1  58.75 ( 63.65)	Acc@5  87.50 ( 89.84)
## e[18] optimizer.zero_grad (sum) time: 0.2876155376434326
## e[18]       loss.backward (sum) time: 4.1003947257995605
## e[18]      optimizer.step (sum) time: 1.902998924255371
## epoch[18] training(only) time: 16.401184797286987
# Switched to evaluate mode...
Test: [  0/100]	Time  0.164 ( 0.164)	Loss 1.6731e+00 (1.6731e+00)	Acc@1  52.00 ( 52.00)	Acc@5  80.00 ( 80.00)
Test: [ 10/100]	Time  0.023 ( 0.036)	Loss 1.9253e+00 (1.7739e+00)	Acc@1  49.00 ( 55.00)	Acc@5  84.00 ( 82.73)
Test: [ 20/100]	Time  0.024 ( 0.030)	Loss 1.5098e+00 (1.7187e+00)	Acc@1  56.00 ( 54.81)	Acc@5  85.00 ( 83.81)
Test: [ 30/100]	Time  0.024 ( 0.028)	Loss 1.8384e+00 (1.7249e+00)	Acc@1  46.00 ( 54.35)	Acc@5  79.00 ( 83.29)
Test: [ 40/100]	Time  0.024 ( 0.027)	Loss 1.9279e+00 (1.7202e+00)	Acc@1  52.00 ( 54.34)	Acc@5  79.00 ( 83.61)
Test: [ 50/100]	Time  0.025 ( 0.026)	Loss 1.5759e+00 (1.7294e+00)	Acc@1  55.00 ( 54.39)	Acc@5  82.00 ( 83.49)
Test: [ 60/100]	Time  0.021 ( 0.025)	Loss 1.5868e+00 (1.7189e+00)	Acc@1  57.00 ( 54.54)	Acc@5  84.00 ( 83.69)
Test: [ 70/100]	Time  0.024 ( 0.025)	Loss 1.6741e+00 (1.7079e+00)	Acc@1  59.00 ( 54.66)	Acc@5  84.00 ( 83.73)
Test: [ 80/100]	Time  0.023 ( 0.025)	Loss 1.9243e+00 (1.7121e+00)	Acc@1  60.00 ( 54.86)	Acc@5  80.00 ( 83.51)
Test: [ 90/100]	Time  0.024 ( 0.025)	Loss 2.0975e+00 (1.7074e+00)	Acc@1  52.00 ( 55.11)	Acc@5  78.00 ( 83.59)
 * Acc@1 55.270 Acc@5 83.690
### epoch[18] execution time: 18.899108409881592
EPOCH 19
i:   0, name:           module.stem.0.weight  changing lr from: 0.067844492669611026   to: 0.064598267368231238
i:   1, name:             module.stem.0.bias  changing lr from: 0.068266531260249799   to: 0.065053697509653230
i:   2, name:           module.stem.1.weight  changing lr from: 0.068683090632486718   to: 0.065503451237549623
i:   3, name:             module.stem.1.bias  changing lr from: 0.069094228015733436   to: 0.065947579425276473
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.069500000870223996   to: 0.066386133597904892
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.069900466835977212   to: 0.066819165863495664
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.070295683684498331   to: 0.067246728847750376
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.070685709273101374   to: 0.067668875631901299
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.071070601501738606   to: 0.068085659693706710
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.071450418272227520   to: 0.068497134851423211
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.071825217449770121   to: 0.068903355210631748
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.072195056826663731   to: 0.069304375113798125
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.072559994088105831   to: 0.069700249092453023
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.072920086779999949   to: 0.070091031821881783
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.073275392278672830   to: 0.070476778078216701
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.073625967762417144   to: 0.070857542697830692
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.073971870184776856   to: 0.071233380538932675
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.074313156249496234   to: 0.071604346445271069
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.074649882387056485   to: 0.071970495211853752
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.074982104732726873   to: 0.072331881552596941
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.075309879106060504   to: 0.072688560069819191
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.075633260991767662   to: 0.073040585225499208
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.075952305521902283   to: 0.073388011314220042
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.076267067459299856   to: 0.073730892437724752
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.076577601182207591   to: 0.074069282481012064
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.076883960670050405   to: 0.074403235089902667
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.077186199490277885   to: 0.074732803650010629
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.077484370786240875   to: 0.075058041267055717
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.077778527266047226   to: 0.075379000748456229
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.078068721192349227   to: 0.075695734586143426
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.078355004373017095   to: 0.076008294940541427
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.078637428152654468   to: 0.076316733625659161
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.078916043404914205   to: 0.076621102095241880
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.079190900525574356   to: 0.076921451429933507
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.079462049426335640   to: 0.077217832325401539
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.079729539529304269   to: 0.077510295081379563
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.079993419762124235   to: 0.077798889591583112
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.080253738553726139   to: 0.078083665334457569
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.080510543830659934   to: 0.078364671364717406
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.080763883013981005   to: 0.078641956305638638
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.081013803016660266   to: 0.078915568342067755
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.081260350241490142   to: 0.079185555214111331
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.081503570579459395   to: 0.079451964211473103
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.081743509408571502   to: 0.079714842168405797
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.081980211593081664   to: 0.079974235459246673
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.082213721483129526   to: 0.080230189994507428
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.082444082914744574   to: 0.080482751217489656
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.082671339210203601   to: 0.080731964101399184
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.082895533178719366   to: 0.080977873146932638
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.083116707117441013   to: 0.081220522380312035
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.083334902812748107   to: 0.081459955351743163
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.083550161541819823   to: 0.081696215134275038
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.083762524074463343   to: 0.081929344323038986
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.083972030675184398   to: 0.082159385034846127
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.084178721105485355   to: 0.082386378908123781
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.084382634626375630   to: 0.082610367103171295
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.084583810001080950   to: 0.082831390302717828
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.084782285497937690   to: 0.083049488712764061
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.084978098893460113   to: 0.083264702063691631
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.085171287475567903   to: 0.083477069611624544
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.085361888046963097   to: 0.083686630140027113
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.085549936928644946   to: 0.083893421961524398
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.085735469963552538   to: 0.084097482919931077
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.085918522520325474   to: 0.084298850392475755
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.086099129497172716   to: 0.084497561292208340
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.086277325325841120   to: 0.084693652070578093
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.086453143975674870   to: 0.084887158720171496
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.086626618957757792   to: 0.085078116777598772
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.086797783329130976   to: 0.085266561326518622
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.086966669697078211   to: 0.085452527000791687
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.087133310223472552   to: 0.085636047987753011
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.087297736629177280   to: 0.085817158031594648
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.087459980198495157   to: 0.085995890436850020
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.087620071783659881   to: 0.086172278071971684
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.087778041809364438   to: 0.086346353372995177
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.087933920277320859   to: 0.086518148347281137
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.088087736770846387   to: 0.086687694577329041
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.088239520459471324   to: 0.086855023224655978
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.088389300103564189   to: 0.087020165033733832
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.088537104058969848   to: 0.087183150335979245
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.088682960281656439   to: 0.087344009053790500
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.088826896332367844   to: 0.087502770704625935
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.088968939381277451   to: 0.087659464405118820
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.089109116212640477   to: 0.087814118875223904
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.089247453229441234   to: 0.087966762442390864
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.089383976458032657   to: 0.088117423045760437
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.089518711552765098   to: 0.088266128240379160
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.089651683800601942   to: 0.088412905201428638
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.089782918125719313   to: 0.088557780728465763
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.089912439094087915   to: 0.088700781249670457
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.090040270918034473   to: 0.088841932826097453
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.090166437460781068   to: 0.088981261155929248
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.090290962240960143   to: 0.089118791578727000
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.090413868437103764   to: 0.089254549079676893
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.090535178892105217   to: 0.089388558293829190
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.090654916117651474   to: 0.089520843510327450
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.090773102298625286   to: 0.089651428676625927
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.090889759297475253   to: 0.089780337402692575
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.091004908658552999   to: 0.089907592965195834
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.091118571612416002   to: 0.090033218311673352
i: 100, name:           module.conv10.weight  changing lr from: 0.091230769080095336   to: 0.090157236064680693
i: 101, name:             module.conv10.bias  changing lr from: 0.091341521677327217   to: 0.090279668525918441



# Switched to train mode...
Epoch: [19][  0/391]	Time  0.196 ( 0.196)	Data  0.148 ( 0.148)	Loss 1.0070e+00 (1.0070e+00)	Acc@1  68.75 ( 68.75)	Acc@5  96.88 ( 96.88)
Epoch: [19][ 10/391]	Time  0.040 ( 0.056)	Data  0.001 ( 0.014)	Loss 1.2125e+00 (1.1406e+00)	Acc@1  67.19 ( 67.61)	Acc@5  88.28 ( 91.05)
Epoch: [19][ 20/391]	Time  0.040 ( 0.049)	Data  0.001 ( 0.008)	Loss 1.1602e+00 (1.1608e+00)	Acc@1  64.84 ( 66.63)	Acc@5  90.62 ( 90.92)
Epoch: [19][ 30/391]	Time  0.042 ( 0.046)	Data  0.001 ( 0.006)	Loss 1.2439e+00 (1.1725e+00)	Acc@1  67.97 ( 66.36)	Acc@5  89.84 ( 91.03)
Epoch: [19][ 40/391]	Time  0.040 ( 0.045)	Data  0.001 ( 0.005)	Loss 1.1388e+00 (1.1671e+00)	Acc@1  64.84 ( 66.25)	Acc@5  93.75 ( 91.20)
Epoch: [19][ 50/391]	Time  0.041 ( 0.044)	Data  0.001 ( 0.004)	Loss 1.3150e+00 (1.1775e+00)	Acc@1  59.38 ( 66.10)	Acc@5  88.28 ( 91.12)
Epoch: [19][ 60/391]	Time  0.041 ( 0.044)	Data  0.001 ( 0.003)	Loss 1.3406e+00 (1.1870e+00)	Acc@1  63.28 ( 65.92)	Acc@5  88.28 ( 90.88)
Epoch: [19][ 70/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.003)	Loss 1.3153e+00 (1.1933e+00)	Acc@1  66.41 ( 65.68)	Acc@5  88.28 ( 90.72)
Epoch: [19][ 80/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.003)	Loss 1.2955e+00 (1.1993e+00)	Acc@1  64.06 ( 65.59)	Acc@5  87.50 ( 90.74)
Epoch: [19][ 90/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.003)	Loss 1.1225e+00 (1.1995e+00)	Acc@1  73.44 ( 65.78)	Acc@5  92.19 ( 90.75)
Epoch: [19][100/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.1397e+00 (1.1944e+00)	Acc@1  65.62 ( 65.78)	Acc@5  91.41 ( 90.77)
Epoch: [19][110/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.0817e+00 (1.2001e+00)	Acc@1  68.75 ( 65.57)	Acc@5  93.75 ( 90.68)
Epoch: [19][120/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.1008e+00 (1.1970e+00)	Acc@1  64.06 ( 65.51)	Acc@5  90.62 ( 90.68)
Epoch: [19][130/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.1744e+00 (1.1991e+00)	Acc@1  64.06 ( 65.31)	Acc@5  89.06 ( 90.76)
Epoch: [19][140/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.1245e+00 (1.2015e+00)	Acc@1  65.62 ( 65.17)	Acc@5  90.62 ( 90.75)
Epoch: [19][150/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.1462e+00 (1.2040e+00)	Acc@1  67.19 ( 65.11)	Acc@5  89.84 ( 90.67)
Epoch: [19][160/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.1602e+00 (1.2072e+00)	Acc@1  60.16 ( 65.01)	Acc@5  94.53 ( 90.61)
Epoch: [19][170/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.2194e+00 (1.2097e+00)	Acc@1  64.06 ( 64.94)	Acc@5  92.19 ( 90.55)
Epoch: [19][180/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.3728e+00 (1.2147e+00)	Acc@1  60.16 ( 64.85)	Acc@5  91.41 ( 90.55)
Epoch: [19][190/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.1660e+00 (1.2210e+00)	Acc@1  67.19 ( 64.74)	Acc@5  89.84 ( 90.41)
Epoch: [19][200/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.2320e+00 (1.2221e+00)	Acc@1  64.84 ( 64.70)	Acc@5  89.84 ( 90.39)
Epoch: [19][210/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.3158e+00 (1.2207e+00)	Acc@1  61.72 ( 64.70)	Acc@5  89.84 ( 90.41)
Epoch: [19][220/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.2979e+00 (1.2193e+00)	Acc@1  60.94 ( 64.73)	Acc@5  91.41 ( 90.44)
Epoch: [19][230/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.1239e+00 (1.2193e+00)	Acc@1  66.41 ( 64.74)	Acc@5  92.19 ( 90.47)
Epoch: [19][240/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.3912e+00 (1.2198e+00)	Acc@1  60.16 ( 64.76)	Acc@5  86.72 ( 90.39)
Epoch: [19][250/391]	Time  0.047 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.2625e+00 (1.2195e+00)	Acc@1  60.16 ( 64.70)	Acc@5  91.41 ( 90.40)
Epoch: [19][260/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.1787e+00 (1.2185e+00)	Acc@1  67.97 ( 64.75)	Acc@5  89.06 ( 90.40)
Epoch: [19][270/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.1443e+00 (1.2185e+00)	Acc@1  67.19 ( 64.80)	Acc@5  92.19 ( 90.38)
Epoch: [19][280/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.4112e+00 (1.2219e+00)	Acc@1  58.59 ( 64.74)	Acc@5  86.72 ( 90.34)
Epoch: [19][290/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.2298e+00 (1.2235e+00)	Acc@1  65.62 ( 64.70)	Acc@5  89.84 ( 90.34)
Epoch: [19][300/391]	Time  0.046 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.3718e+00 (1.2236e+00)	Acc@1  65.62 ( 64.71)	Acc@5  86.72 ( 90.31)
Epoch: [19][310/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.1508e+00 (1.2229e+00)	Acc@1  67.97 ( 64.71)	Acc@5  92.97 ( 90.35)
Epoch: [19][320/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.3715e+00 (1.2250e+00)	Acc@1  58.59 ( 64.61)	Acc@5  90.62 ( 90.34)
Epoch: [19][330/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.3076e+00 (1.2274e+00)	Acc@1  64.84 ( 64.53)	Acc@5  89.84 ( 90.34)
Epoch: [19][340/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.3408e+00 (1.2276e+00)	Acc@1  57.03 ( 64.49)	Acc@5  88.28 ( 90.34)
Epoch: [19][350/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.2446e+00 (1.2281e+00)	Acc@1  65.62 ( 64.49)	Acc@5  92.19 ( 90.33)
Epoch: [19][360/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.1150e+00 (1.2283e+00)	Acc@1  67.19 ( 64.51)	Acc@5  91.41 ( 90.32)
Epoch: [19][370/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.2525e+00 (1.2306e+00)	Acc@1  60.94 ( 64.43)	Acc@5  92.19 ( 90.28)
Epoch: [19][380/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.3587e+00 (1.2298e+00)	Acc@1  64.06 ( 64.44)	Acc@5  88.28 ( 90.29)
Epoch: [19][390/391]	Time  0.034 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.3981e+00 (1.2307e+00)	Acc@1  62.50 ( 64.38)	Acc@5  86.25 ( 90.30)
## e[19] optimizer.zero_grad (sum) time: 0.2860908508300781
## e[19]       loss.backward (sum) time: 4.192533731460571
## e[19]      optimizer.step (sum) time: 1.8392677307128906
## epoch[19] training(only) time: 16.501396417617798
# Switched to evaluate mode...
Test: [  0/100]	Time  0.151 ( 0.151)	Loss 1.6330e+00 (1.6330e+00)	Acc@1  61.00 ( 61.00)	Acc@5  83.00 ( 83.00)
Test: [ 10/100]	Time  0.022 ( 0.033)	Loss 1.8726e+00 (1.7274e+00)	Acc@1  54.00 ( 57.27)	Acc@5  83.00 ( 83.82)
Test: [ 20/100]	Time  0.019 ( 0.028)	Loss 1.4408e+00 (1.6923e+00)	Acc@1  58.00 ( 56.71)	Acc@5  88.00 ( 84.33)
Test: [ 30/100]	Time  0.024 ( 0.026)	Loss 1.7523e+00 (1.7097e+00)	Acc@1  52.00 ( 56.03)	Acc@5  86.00 ( 83.94)
Test: [ 40/100]	Time  0.026 ( 0.025)	Loss 1.6512e+00 (1.6792e+00)	Acc@1  58.00 ( 56.44)	Acc@5  85.00 ( 84.41)
Test: [ 50/100]	Time  0.018 ( 0.025)	Loss 1.4674e+00 (1.6844e+00)	Acc@1  66.00 ( 56.10)	Acc@5  87.00 ( 84.37)
Test: [ 60/100]	Time  0.019 ( 0.024)	Loss 1.6360e+00 (1.6657e+00)	Acc@1  53.00 ( 56.36)	Acc@5  88.00 ( 84.66)
Test: [ 70/100]	Time  0.020 ( 0.024)	Loss 1.4939e+00 (1.6710e+00)	Acc@1  57.00 ( 56.23)	Acc@5  89.00 ( 84.63)
Test: [ 80/100]	Time  0.023 ( 0.024)	Loss 1.6512e+00 (1.6718e+00)	Acc@1  63.00 ( 56.22)	Acc@5  82.00 ( 84.58)
Test: [ 90/100]	Time  0.025 ( 0.023)	Loss 1.9734e+00 (1.6572e+00)	Acc@1  50.00 ( 56.57)	Acc@5  81.00 ( 84.68)
 * Acc@1 56.840 Acc@5 84.830
### epoch[19] execution time: 18.88261914253235
EPOCH 20
i:   0, name:           module.stem.0.weight  changing lr from: 0.064598267368231238   to: 0.061288860534611772
i:   1, name:             module.stem.0.bias  changing lr from: 0.065053697509653230   to: 0.061776517876351203
i:   2, name:           module.stem.1.weight  changing lr from: 0.065503451237549623   to: 0.062258372242085892
i:   3, name:             module.stem.1.bias  changing lr from: 0.065947579425276473   to: 0.062734465571493453
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.066386133597904892   to: 0.063204840957727521
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.066819165863495664   to: 0.063669542558838152
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.067246728847750376   to: 0.064128615513242976
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.067668875631901299   to: 0.064582105859091854
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.068085659693706710   to: 0.065030060457373917
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.068497134851423211   to: 0.065472526918620419
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.068903355210631748   to: 0.065909553533061771
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.069304375113798125   to: 0.066341189204102549
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.069700249092453023   to: 0.066767483384981799
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.070091031821881783   to: 0.067188486018492075
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.070476778078216701   to: 0.067604247479633575
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.070857542697830692   to: 0.068014818521085291
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.071233380538932675   to: 0.068420250221378487
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.071604346445271069   to: 0.068820593935662547
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.071970495211853752   to: 0.069215901248956532
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.072331881552596941   to: 0.069606223931784325
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.072688560069819191   to: 0.069991613898094412
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.073040585225499208   to: 0.070372123165369407
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.073388011314220042   to: 0.070747803816833696
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.073730892437724752   to: 0.071118707965671032
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.074069282481012064   to: 0.071484887721167220
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.074403235089902667   to: 0.071846395156696205
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.074732803650010629   to: 0.072203282279470954
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.075058041267055717   to: 0.072555601001983758
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.075379000748456229   to: 0.072903403115062868
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.075695734586143426   to: 0.073246740262475712
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.076008294940541427   to: 0.073585663917011448
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.076316733625659161   to: 0.073920225357978417
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.076621102095241880   to: 0.074250475650053854
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.076921451429933507   to: 0.074576465623426666
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.077217832325401539   to: 0.074898245855175696
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.077510295081379563   to: 0.075215866651828292
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.077798889591583112   to: 0.075529378033046476
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.078083665334457569   to: 0.075838829716389541
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.078364671364717406   to: 0.076144271103104816
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.078641956305638638   to: 0.076445751264898970
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.078915568342067755   to: 0.076743318931645724
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.079185555214111331   to: 0.077037022479986172
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.079451964211473103   to: 0.077326909922780518
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.079714842168405797   to: 0.077613028899371633
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.079974235459246673   to: 0.077895426666622025
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.080230189994507428   to: 0.078174150090687913
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.080482751217489656   to: 0.078449245639495124
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.080731964101399184   to: 0.078720759375883437
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.080977873146932638   to: 0.078988736951386931
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.081220522380312035   to: 0.079253223600619552
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.081459955351743163   to: 0.079514264136236190
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.081696215134275038   to: 0.079771902944441100
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.081929344323038986   to: 0.080026183981016172
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.082159385034846127   to: 0.080277150767843378
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.082386378908123781   to: 0.080524846389896099
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.082610367103171295   to: 0.080769313492675646
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.082831390302717828   to: 0.081010594280070070
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.083049488712764061   to: 0.081248730512613346
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.083264702063691631   to: 0.081483763506124018
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.083477069611624544   to: 0.081715734130703072
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.083686630140027113   to: 0.081944682810072153
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.083893421961524398   to: 0.082170649521233485
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.084097482919931077   to: 0.082393673794433991
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.084298850392475755   to: 0.082613794713416927
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.084497561292208340   to: 0.082831050915944851
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.084693652070578093   to: 0.083045480594578641
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.084887158720171496   to: 0.083257121497697706
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.085078116777598772   to: 0.083466010930747722
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.085266561326518622   to: 0.083672185757702078
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.085452527000791687   to: 0.083875682402724500
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.085636047987753011   to: 0.084076536852020489
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.085817158031594648   to: 0.084274784655865909
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.085995890436850020   to: 0.084470460930801738
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.086172278071971684   to: 0.084663600361983962
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.086346353372995177   to: 0.084854237205678917
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.086518148347281137   to: 0.085042405291893997
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.086687694577329041   to: 0.085228138027134720
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.086855023224655978   to: 0.085411468397279255
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.087020165033733832   to: 0.085592428970561921
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.087183150335979245   to: 0.085771051900657938
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.087344009053790500   to: 0.085947368929861323
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.087502770704625935   to: 0.086121411392349176
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.087659464405118820   to: 0.086293210217525007
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.087814118875223904   to: 0.086462795933434825
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.087966762442390864   to: 0.086630198670249459
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.088117423045760437   to: 0.086795448163807354
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.088266128240379160   to: 0.086958573759212038
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.088412905201428638   to: 0.087119604414478885
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.088557780728465763   to: 0.087278568704226067
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.088700781249670457   to: 0.087435494823404791
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.088841932826097453   to: 0.087590410591064302
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.088981261155929248   to: 0.087743343454146916
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.089118791578727000   to: 0.087894320491309547
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.089254549079676893   to: 0.088043368416767021
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.089388558293829190   to: 0.088190513584153959
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.089520843510327450   to: 0.088335781990401555
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.089651428676625927   to: 0.088479199279625748
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.089780337402692575   to: 0.088620790747023767
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.089907592965195834   to: 0.088760581342775854
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.090033218311673352   to: 0.088898595675949654
i: 100, name:           module.conv10.weight  changing lr from: 0.090157236064680693   to: 0.089034858018404009
i: 101, name:             module.conv10.bias  changing lr from: 0.090279668525918441   to: 0.089169392308690434



# Switched to train mode...
Epoch: [20][  0/391]	Time  0.196 ( 0.196)	Data  0.148 ( 0.148)	Loss 1.0905e+00 (1.0905e+00)	Acc@1  68.75 ( 68.75)	Acc@5  92.19 ( 92.19)
Epoch: [20][ 10/391]	Time  0.043 ( 0.056)	Data  0.001 ( 0.014)	Loss 1.1501e+00 (1.2033e+00)	Acc@1  66.41 ( 64.49)	Acc@5  92.97 ( 91.69)
Epoch: [20][ 20/391]	Time  0.040 ( 0.050)	Data  0.001 ( 0.008)	Loss 1.4026e+00 (1.1784e+00)	Acc@1  61.72 ( 65.18)	Acc@5  89.84 ( 91.70)
Epoch: [20][ 30/391]	Time  0.042 ( 0.047)	Data  0.001 ( 0.006)	Loss 1.2400e+00 (1.1759e+00)	Acc@1  64.06 ( 65.52)	Acc@5  92.97 ( 91.66)
Epoch: [20][ 40/391]	Time  0.041 ( 0.046)	Data  0.001 ( 0.005)	Loss 1.0567e+00 (1.1774e+00)	Acc@1  68.75 ( 65.17)	Acc@5  94.53 ( 91.67)
Epoch: [20][ 50/391]	Time  0.041 ( 0.045)	Data  0.001 ( 0.004)	Loss 1.2303e+00 (1.1682e+00)	Acc@1  63.28 ( 65.64)	Acc@5  92.19 ( 91.74)
Epoch: [20][ 60/391]	Time  0.040 ( 0.044)	Data  0.001 ( 0.003)	Loss 9.7405e-01 (1.1705e+00)	Acc@1  75.78 ( 65.68)	Acc@5  92.19 ( 91.55)
Epoch: [20][ 70/391]	Time  0.042 ( 0.044)	Data  0.001 ( 0.003)	Loss 1.1500e+00 (1.1657e+00)	Acc@1  65.62 ( 65.89)	Acc@5  90.62 ( 91.46)
Epoch: [20][ 80/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.003)	Loss 1.1666e+00 (1.1689e+00)	Acc@1  67.19 ( 65.71)	Acc@5  93.75 ( 91.44)
Epoch: [20][ 90/391]	Time  0.039 ( 0.043)	Data  0.001 ( 0.003)	Loss 1.1968e+00 (1.1657e+00)	Acc@1  63.28 ( 65.71)	Acc@5  91.41 ( 91.48)
Epoch: [20][100/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.2337e+00 (1.1660e+00)	Acc@1  67.19 ( 65.81)	Acc@5  90.62 ( 91.50)
Epoch: [20][110/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.3094e+00 (1.1652e+00)	Acc@1  64.06 ( 65.93)	Acc@5  87.50 ( 91.45)
Epoch: [20][120/391]	Time  0.047 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.1196e+00 (1.1654e+00)	Acc@1  65.62 ( 65.87)	Acc@5  89.84 ( 91.41)
Epoch: [20][130/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.002)	Loss 9.7303e-01 (1.1673e+00)	Acc@1  69.53 ( 65.82)	Acc@5  93.75 ( 91.28)
Epoch: [20][140/391]	Time  0.047 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.1798e+00 (1.1679e+00)	Acc@1  67.19 ( 65.74)	Acc@5  91.41 ( 91.30)
Epoch: [20][150/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.2695e+00 (1.1715e+00)	Acc@1  60.94 ( 65.56)	Acc@5  86.72 ( 91.20)
Epoch: [20][160/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.3512e+00 (1.1741e+00)	Acc@1  67.97 ( 65.57)	Acc@5  88.28 ( 91.12)
Epoch: [20][170/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.1658e+00 (1.1784e+00)	Acc@1  61.72 ( 65.40)	Acc@5  92.19 ( 91.06)
Epoch: [20][180/391]	Time  0.044 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.1920e+00 (1.1767e+00)	Acc@1  66.41 ( 65.50)	Acc@5  93.75 ( 91.10)
Epoch: [20][190/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.2243e+00 (1.1786e+00)	Acc@1  63.28 ( 65.49)	Acc@5  91.41 ( 91.09)
Epoch: [20][200/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.2248e+00 (1.1832e+00)	Acc@1  63.28 ( 65.36)	Acc@5  91.41 ( 91.07)
Epoch: [20][210/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.1725e+00 (1.1833e+00)	Acc@1  66.41 ( 65.33)	Acc@5  87.50 ( 91.03)
Epoch: [20][220/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.0135e+00 (1.1793e+00)	Acc@1  69.53 ( 65.40)	Acc@5  91.41 ( 91.10)
Epoch: [20][230/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 9.9768e-01 (1.1765e+00)	Acc@1  69.53 ( 65.56)	Acc@5  92.97 ( 91.16)
Epoch: [20][240/391]	Time  0.049 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.3124e+00 (1.1798e+00)	Acc@1  64.06 ( 65.51)	Acc@5  86.72 ( 91.12)
Epoch: [20][250/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.2758e+00 (1.1816e+00)	Acc@1  66.41 ( 65.44)	Acc@5  89.84 ( 91.10)
Epoch: [20][260/391]	Time  0.039 ( 0.042)	Data  0.002 ( 0.002)	Loss 1.2502e+00 (1.1850e+00)	Acc@1  60.16 ( 65.34)	Acc@5  89.06 ( 91.04)
Epoch: [20][270/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.3295e+00 (1.1872e+00)	Acc@1  56.25 ( 65.28)	Acc@5  90.62 ( 91.00)
Epoch: [20][280/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.2043e+00 (1.1868e+00)	Acc@1  61.72 ( 65.33)	Acc@5  91.41 ( 91.01)
Epoch: [20][290/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.0367e+00 (1.1857e+00)	Acc@1  66.41 ( 65.38)	Acc@5  94.53 ( 91.01)
Epoch: [20][300/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.2255e+00 (1.1852e+00)	Acc@1  64.84 ( 65.37)	Acc@5  90.62 ( 91.03)
Epoch: [20][310/391]	Time  0.051 ( 0.042)	Data  0.002 ( 0.001)	Loss 1.1865e+00 (1.1862e+00)	Acc@1  63.28 ( 65.31)	Acc@5  92.19 ( 91.00)
Epoch: [20][320/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.1127e+00 (1.1857e+00)	Acc@1  65.62 ( 65.32)	Acc@5  89.06 ( 91.04)
Epoch: [20][330/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.1902e+00 (1.1872e+00)	Acc@1  64.84 ( 65.33)	Acc@5  91.41 ( 91.04)
Epoch: [20][340/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.4484e+00 (1.1880e+00)	Acc@1  63.28 ( 65.35)	Acc@5  87.50 ( 91.01)
Epoch: [20][350/391]	Time  0.045 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.0552e+00 (1.1886e+00)	Acc@1  72.66 ( 65.38)	Acc@5  92.97 ( 91.03)
Epoch: [20][360/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.2844e+00 (1.1912e+00)	Acc@1  64.06 ( 65.34)	Acc@5  91.41 ( 91.00)
Epoch: [20][370/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.2433e+00 (1.1918e+00)	Acc@1  60.94 ( 65.31)	Acc@5  90.62 ( 90.98)
Epoch: [20][380/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.2929e+00 (1.1929e+00)	Acc@1  65.62 ( 65.32)	Acc@5  87.50 ( 90.96)
Epoch: [20][390/391]	Time  0.029 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.1827e+00 (1.1960e+00)	Acc@1  72.50 ( 65.29)	Acc@5  88.75 ( 90.89)
## e[20] optimizer.zero_grad (sum) time: 0.2886950969696045
## e[20]       loss.backward (sum) time: 4.2191338539123535
## e[20]      optimizer.step (sum) time: 1.8603379726409912
## epoch[20] training(only) time: 16.535589933395386
# Switched to evaluate mode...
Test: [  0/100]	Time  0.155 ( 0.155)	Loss 1.5311e+00 (1.5311e+00)	Acc@1  63.00 ( 63.00)	Acc@5  85.00 ( 85.00)
Test: [ 10/100]	Time  0.022 ( 0.034)	Loss 1.7515e+00 (1.6370e+00)	Acc@1  56.00 ( 58.09)	Acc@5  87.00 ( 84.82)
Test: [ 20/100]	Time  0.019 ( 0.028)	Loss 1.3319e+00 (1.6008e+00)	Acc@1  66.00 ( 58.00)	Acc@5  87.00 ( 85.33)
Test: [ 30/100]	Time  0.020 ( 0.026)	Loss 1.8437e+00 (1.6265e+00)	Acc@1  45.00 ( 56.90)	Acc@5  83.00 ( 84.97)
Test: [ 40/100]	Time  0.022 ( 0.024)	Loss 1.7282e+00 (1.6176e+00)	Acc@1  59.00 ( 56.90)	Acc@5  85.00 ( 85.12)
Test: [ 50/100]	Time  0.023 ( 0.024)	Loss 1.4533e+00 (1.6197e+00)	Acc@1  56.00 ( 56.67)	Acc@5  91.00 ( 84.96)
Test: [ 60/100]	Time  0.021 ( 0.023)	Loss 1.5296e+00 (1.6057e+00)	Acc@1  59.00 ( 56.79)	Acc@5  84.00 ( 85.02)
Test: [ 70/100]	Time  0.022 ( 0.023)	Loss 1.6801e+00 (1.6087e+00)	Acc@1  57.00 ( 56.73)	Acc@5  84.00 ( 85.03)
Test: [ 80/100]	Time  0.029 ( 0.023)	Loss 1.7837e+00 (1.6145e+00)	Acc@1  50.00 ( 56.58)	Acc@5  81.00 ( 85.00)
Test: [ 90/100]	Time  0.023 ( 0.023)	Loss 2.2550e+00 (1.6120e+00)	Acc@1  45.00 ( 56.74)	Acc@5  75.00 ( 84.90)
 * Acc@1 56.820 Acc@5 84.870
### epoch[20] execution time: 18.882954120635986
EPOCH 21
i:   0, name:           module.stem.0.weight  changing lr from: 0.061288860534611772   to: 0.057931648642011363
i:   1, name:             module.stem.0.bias  changing lr from: 0.061776517876351203   to: 0.058449997167167284
i:   2, name:           module.stem.1.weight  changing lr from: 0.062258372242085892   to: 0.058962495448909392
i:   3, name:             module.stem.1.bias  changing lr from: 0.062734465571493453   to: 0.059469173748153650
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.063204840957727521   to: 0.059970064062653289
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.063669542558838152   to: 0.060465200016599330
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.064128615513242976   to: 0.060954616754964087
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.064582105859091854   to: 0.061438350842414127
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.065030060457373917   to: 0.061916440166625036
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.065472526918620419   to: 0.062388923845834957
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.065909553533061771   to: 0.062855842140479415
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.066341189204102549   to: 0.063317236368754234
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.066767483384981799   to: 0.063773148825958678
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.067188486018492075   to: 0.064223622707475503
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.067604247479633575   to: 0.064668702035249201
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.068014818521085291   to: 0.065108431587628288
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.068420250221378487   to: 0.065542856832441973
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.068820593935662547   to: 0.065972023863185722
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.069215901248956532   to: 0.066395979338194813
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.069606223931784325   to: 0.066814770422688283
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.069991613898094412   to: 0.067228444733570800
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.070372123165369407   to: 0.067637050286882994
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.070747803816833696   to: 0.068040635447794817
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.071118707965671032   to: 0.068439248883040524
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.071484887721167220   to: 0.068832939515696925
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.071846395156696205   to: 0.069221756482210434
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.072203282279470954   to: 0.069605749091581598
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.072555601001983758   to: 0.069984966786619376
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.072903403115062868   to: 0.070359459107180083
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.073246740262475712   to: 0.070729275655309440
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.073585663917011448   to: 0.071094466062209136
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.073920225357978417   to: 0.071455079956952022
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.074250475650053854   to: 0.071811166936872908
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.074576465623426666   to: 0.072162776539564669
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.074898245855175696   to: 0.072509958216412027
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.075215866651828292   to: 0.072852761307597935
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.075529378033046476   to: 0.073191235018519860
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.075838829716389541   to: 0.073525428397555548
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.076144271103104816   to: 0.073855390315120534
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.076445751264898970   to: 0.074181169443961290
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.076743318931645724   to: 0.074502814240630724
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.077037022479986172   to: 0.074820372928094181
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.077326909922780518   to: 0.075133893479416361
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.077613028899371633   to: 0.075443423602481838
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.077895426666622025   to: 0.075749010725702920
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.078174150090687913   to: 0.076050701984671218
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.078449245639495124   to: 0.076348544209710378
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.078720759375883437   to: 0.076642583914289658
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.078988736951386931   to: 0.076932867284259090
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.079253223600619552   to: 0.077219440167868927
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.079514264136236190   to: 0.077502348066537385
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.079771902944441100   to: 0.077781636126332099
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.080026183981016172   to: 0.078057349130132320
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.080277150767843378   to: 0.078329531490439933
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.080524846389896099   to: 0.078598227242808891
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.080769313492675646   to: 0.078863480039863543
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.081010594280070070   to: 0.079125333145878177
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.081248730512613346   to: 0.079383829431890610
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.081483763506124018   to: 0.079639011371323898
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.081715734130703072   to: 0.079890921036091689
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.081944682810072153   to: 0.080139600093163302
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.082170649521233485   to: 0.080385089801565779
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.082393673794433991   to: 0.080627431009801187
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.082613794713416927   to: 0.080866664153658119
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.082831050915944851   to: 0.081102829254397615
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.083045480594578641   to: 0.081335965917294140
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.083257121497697706   to: 0.081566113330513140
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.083466010930747722   to: 0.081793310264308028
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.083672185757702078   to: 0.082017595070519186
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.083875682402724500   to: 0.082239005682359270
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.084076536852020489   to: 0.082457579614469256
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.084274784655865909   to: 0.082673353963230306
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.084470460930801738   to: 0.082886365407317641
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.084663600361983962   to: 0.083096650208482614
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.084854237205678917   to: 0.083304244212550019
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.085042405291893997   to: 0.083509182850618688
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.085228138027134720   to: 0.083711501140452949
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.085411468397279255   to: 0.083911233688054088
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.085592428970561921   to: 0.084108414689400918
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.085771051900657938   to: 0.084303077932348841
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.085947368929861323   to: 0.084495256798677976
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.086121411392349176   to: 0.084684984266280613
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.086293210217525007   to: 0.084872292911479130
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.086462795933434825   to: 0.085057214911465714
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.086630198670249459   to: 0.085239782046855658
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.086795448163807354   to: 0.085420025704346605
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.086958573759212038   to: 0.085597976879475957
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.087119604414478885   to: 0.085773666179469576
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.087278568704226067   to: 0.085947123826174920
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.087435494823404791   to: 0.086118379659071986
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.087590410591064302   to: 0.086287463138356210
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.087743343454146916   to: 0.086454403348087031
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.087894320491309547   to: 0.086619228999396947
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.088043368416767021   to: 0.086781968433755352
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.088190513584153959   to: 0.086942649626282245
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.088335781990401555   to: 0.087101300189107181
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.088479199279625748   to: 0.087257947374768358
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.088620790747023767   to: 0.087412618079648022
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.088760581342775854   to: 0.087565338847439653
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.088898595675949654   to: 0.087716135872643153
i: 100, name:           module.conv10.weight  changing lr from: 0.089034858018404009   to: 0.087865035004084324
i: 101, name:             module.conv10.bias  changing lr from: 0.089169392308690434   to: 0.088012061748454828



# Switched to train mode...
Epoch: [21][  0/391]	Time  0.198 ( 0.198)	Data  0.148 ( 0.148)	Loss 1.0494e+00 (1.0494e+00)	Acc@1  67.97 ( 67.97)	Acc@5  96.09 ( 96.09)
Epoch: [21][ 10/391]	Time  0.044 ( 0.057)	Data  0.001 ( 0.014)	Loss 1.3427e+00 (1.1747e+00)	Acc@1  60.94 ( 64.06)	Acc@5  88.28 ( 91.19)
Epoch: [21][ 20/391]	Time  0.043 ( 0.050)	Data  0.001 ( 0.008)	Loss 1.0965e+00 (1.1285e+00)	Acc@1  70.31 ( 66.15)	Acc@5  92.97 ( 91.63)
Epoch: [21][ 30/391]	Time  0.041 ( 0.047)	Data  0.001 ( 0.006)	Loss 1.2214e+00 (1.1305e+00)	Acc@1  71.09 ( 66.63)	Acc@5  90.62 ( 91.86)
Epoch: [21][ 40/391]	Time  0.040 ( 0.045)	Data  0.001 ( 0.005)	Loss 1.2211e+00 (1.1340e+00)	Acc@1  65.62 ( 66.43)	Acc@5  91.41 ( 91.88)
Epoch: [21][ 50/391]	Time  0.042 ( 0.045)	Data  0.001 ( 0.004)	Loss 1.2684e+00 (1.1378e+00)	Acc@1  62.50 ( 66.45)	Acc@5  89.84 ( 91.70)
Epoch: [21][ 60/391]	Time  0.041 ( 0.044)	Data  0.001 ( 0.003)	Loss 1.1203e+00 (1.1356e+00)	Acc@1  64.06 ( 66.33)	Acc@5  94.53 ( 91.87)
Epoch: [21][ 70/391]	Time  0.043 ( 0.044)	Data  0.001 ( 0.003)	Loss 1.1402e+00 (1.1353e+00)	Acc@1  67.19 ( 66.38)	Acc@5  92.97 ( 91.84)
Epoch: [21][ 80/391]	Time  0.043 ( 0.044)	Data  0.001 ( 0.003)	Loss 1.1893e+00 (1.1348e+00)	Acc@1  60.94 ( 66.39)	Acc@5  88.28 ( 91.74)
Epoch: [21][ 90/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.003)	Loss 1.2365e+00 (1.1344e+00)	Acc@1  60.94 ( 66.55)	Acc@5  91.41 ( 91.74)
Epoch: [21][100/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.003)	Loss 1.2247e+00 (1.1397e+00)	Acc@1  61.72 ( 66.50)	Acc@5  92.97 ( 91.72)
Epoch: [21][110/391]	Time  0.044 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.3800e+00 (1.1463e+00)	Acc@1  53.12 ( 66.26)	Acc@5  87.50 ( 91.60)
Epoch: [21][120/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.0925e+00 (1.1448e+00)	Acc@1  69.53 ( 66.39)	Acc@5  91.41 ( 91.54)
Epoch: [21][130/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.1358e+00 (1.1452e+00)	Acc@1  67.19 ( 66.45)	Acc@5  93.75 ( 91.52)
Epoch: [21][140/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.3944e+00 (1.1468e+00)	Acc@1  62.50 ( 66.45)	Acc@5  88.28 ( 91.48)
Epoch: [21][150/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.2124e+00 (1.1497e+00)	Acc@1  67.19 ( 66.36)	Acc@5  90.62 ( 91.45)
Epoch: [21][160/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.1289e+00 (1.1508e+00)	Acc@1  67.19 ( 66.38)	Acc@5  91.41 ( 91.40)
Epoch: [21][170/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.2684e+00 (1.1493e+00)	Acc@1  65.62 ( 66.40)	Acc@5  88.28 ( 91.45)
Epoch: [21][180/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.0512e+00 (1.1515e+00)	Acc@1  71.09 ( 66.35)	Acc@5  94.53 ( 91.39)
Epoch: [21][190/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.1453e+00 (1.1538e+00)	Acc@1  64.84 ( 66.28)	Acc@5  90.62 ( 91.39)
Epoch: [21][200/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 9.8144e-01 (1.1554e+00)	Acc@1  71.88 ( 66.27)	Acc@5  93.75 ( 91.34)
Epoch: [21][210/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.2038e+00 (1.1559e+00)	Acc@1  63.28 ( 66.27)	Acc@5  91.41 ( 91.35)
Epoch: [21][220/391]	Time  0.044 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.1868e+00 (1.1560e+00)	Acc@1  62.50 ( 66.22)	Acc@5  89.06 ( 91.30)
Epoch: [21][230/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.1911e+00 (1.1602e+00)	Acc@1  68.75 ( 66.11)	Acc@5  91.41 ( 91.29)
Epoch: [21][240/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.3627e+00 (1.1606e+00)	Acc@1  64.84 ( 66.13)	Acc@5  90.62 ( 91.30)
Epoch: [21][250/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.2007e+00 (1.1595e+00)	Acc@1  64.06 ( 66.10)	Acc@5  92.19 ( 91.32)
Epoch: [21][260/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.2939e+00 (1.1605e+00)	Acc@1  64.06 ( 66.09)	Acc@5  89.84 ( 91.32)
Epoch: [21][270/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.2318e+00 (1.1601e+00)	Acc@1  60.16 ( 66.07)	Acc@5  90.62 ( 91.30)
Epoch: [21][280/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.1448e+00 (1.1602e+00)	Acc@1  67.97 ( 66.05)	Acc@5  89.06 ( 91.30)
Epoch: [21][290/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.1358e+00 (1.1620e+00)	Acc@1  67.19 ( 66.03)	Acc@5  90.62 ( 91.29)
Epoch: [21][300/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.2212e+00 (1.1616e+00)	Acc@1  63.28 ( 66.09)	Acc@5  90.62 ( 91.31)
Epoch: [21][310/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.0564e+00 (1.1605e+00)	Acc@1  65.62 ( 66.09)	Acc@5  91.41 ( 91.34)
Epoch: [21][320/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.1946e+00 (1.1620e+00)	Acc@1  67.97 ( 66.07)	Acc@5  92.19 ( 91.33)
Epoch: [21][330/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.0842e+00 (1.1624e+00)	Acc@1  63.28 ( 66.03)	Acc@5  93.75 ( 91.34)
Epoch: [21][340/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.1835e+00 (1.1639e+00)	Acc@1  65.62 ( 65.98)	Acc@5  88.28 ( 91.30)
Epoch: [21][350/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.1082e+00 (1.1617e+00)	Acc@1  64.06 ( 66.02)	Acc@5  92.19 ( 91.32)
Epoch: [21][360/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.2367e+00 (1.1636e+00)	Acc@1  64.06 ( 66.01)	Acc@5  87.50 ( 91.29)
Epoch: [21][370/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.3446e+00 (1.1643e+00)	Acc@1  60.16 ( 65.99)	Acc@5  88.28 ( 91.28)
Epoch: [21][380/391]	Time  0.045 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.2064e+00 (1.1645e+00)	Acc@1  63.28 ( 66.02)	Acc@5  92.19 ( 91.28)
Epoch: [21][390/391]	Time  0.031 ( 0.042)	Data  0.001 ( 0.001)	Loss 9.2441e-01 (1.1653e+00)	Acc@1  70.00 ( 65.97)	Acc@5  95.00 ( 91.26)
## e[21] optimizer.zero_grad (sum) time: 0.28609371185302734
## e[21]       loss.backward (sum) time: 4.1788411140441895
## e[21]      optimizer.step (sum) time: 1.8519608974456787
## epoch[21] training(only) time: 16.579314947128296
# Switched to evaluate mode...
Test: [  0/100]	Time  0.155 ( 0.155)	Loss 1.5163e+00 (1.5163e+00)	Acc@1  65.00 ( 65.00)	Acc@5  82.00 ( 82.00)
Test: [ 10/100]	Time  0.022 ( 0.035)	Loss 1.6797e+00 (1.6025e+00)	Acc@1  56.00 ( 59.36)	Acc@5  89.00 ( 85.73)
Test: [ 20/100]	Time  0.024 ( 0.029)	Loss 1.2935e+00 (1.5397e+00)	Acc@1  66.00 ( 60.48)	Acc@5  91.00 ( 86.43)
Test: [ 30/100]	Time  0.023 ( 0.026)	Loss 1.4973e+00 (1.5433e+00)	Acc@1  62.00 ( 59.97)	Acc@5  89.00 ( 86.26)
Test: [ 40/100]	Time  0.023 ( 0.025)	Loss 1.5109e+00 (1.5330e+00)	Acc@1  55.00 ( 59.41)	Acc@5  87.00 ( 86.59)
Test: [ 50/100]	Time  0.020 ( 0.024)	Loss 1.3512e+00 (1.5319e+00)	Acc@1  61.00 ( 59.22)	Acc@5  89.00 ( 86.29)
Test: [ 60/100]	Time  0.018 ( 0.024)	Loss 1.4121e+00 (1.5169e+00)	Acc@1  62.00 ( 59.34)	Acc@5  86.00 ( 86.52)
Test: [ 70/100]	Time  0.024 ( 0.024)	Loss 1.5899e+00 (1.5198e+00)	Acc@1  59.00 ( 59.21)	Acc@5  84.00 ( 86.38)
Test: [ 80/100]	Time  0.024 ( 0.023)	Loss 1.5435e+00 (1.5314e+00)	Acc@1  61.00 ( 59.07)	Acc@5  85.00 ( 86.25)
Test: [ 90/100]	Time  0.021 ( 0.023)	Loss 1.8247e+00 (1.5220e+00)	Acc@1  54.00 ( 59.36)	Acc@5  83.00 ( 86.27)
 * Acc@1 59.470 Acc@5 86.350
### epoch[21] execution time: 18.944193363189697
EPOCH 22
i:   0, name:           module.stem.0.weight  changing lr from: 0.057931648642011363   to: 0.054542230279991735
i:   1, name:             module.stem.0.bias  changing lr from: 0.058449997167167284   to: 0.055089366100652508
i:   2, name:           module.stem.1.weight  changing lr from: 0.058962495448909392   to: 0.055630691860597214
i:   3, name:             module.stem.1.bias  changing lr from: 0.059469173748153650   to: 0.056166223261340020
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.059970064062653289   to: 0.056695978405225736
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.060465200016599330   to: 0.057219977661529302
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.060954616754964087   to: 0.057738243537986761
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.061438350842414127   to: 0.058250800557571918
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.061916440166625036   to: 0.058757675140337598
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.062388923845834957   to: 0.059258895490145215
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.062855842140479415   to: 0.059754491486111463
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.063317236368754234   to: 0.060244494578605291
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.063773148825958678   to: 0.060728937689633146
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.064223622707475503   to: 0.061207855117455558
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.064668702035249201   to: 0.061681282445281864
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.065108431587628288   to: 0.062149256453895643
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.065542856832441973   to: 0.062611815038066385
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.065972023863185722   to: 0.063068997126608878
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.066395979338194813   to: 0.063520842605954725
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.066814770422688283   to: 0.063967392247105667
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.067228444733570800   to: 0.064408687635841830
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.067637050286882994   to: 0.064844771106062613
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.068040635447794817   to: 0.065275685676141226
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.068439248883040524   to: 0.065701474988178563
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.068832939515696925   to: 0.066122183250045222
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.069221756482210434   to: 0.066537855180104619
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.069605749091581598   to: 0.066948535954513069
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.069984966786619376   to: 0.067354271156997478
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.070359459107180083   to: 0.067755106731013093
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.070729275655309440   to: 0.068151088934188406
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.071094466062209136   to: 0.068542264294966682
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.071455079956952022   to: 0.068928679571357496
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.071811166936872908   to: 0.069310381711713651
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.072162776539564669   to: 0.069687417817453010
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.072509958216412027   to: 0.070059835107646823
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.072852761307597935   to: 0.070427680885398969
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.073191235018519860   to: 0.070791002505943834
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.073525428397555548   to: 0.071149847346392500
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.073855390315120534   to: 0.071504262777059777
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.074181169443961290   to: 0.071854296134307036
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.074502814240630724   to: 0.072199994694838149
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.074820372928094181   to: 0.072541405651388294
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.075133893479416361   to: 0.072878576089747224
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.075443423602481838   to: 0.073211552967061361
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.075749010725702920   to: 0.073540383091360503
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.076050701984671218   to: 0.073865113102257532
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.076348544209710378   to: 0.074185789452771086
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.076642583914289658   to: 0.074502458392223261
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.076932867284259090   to: 0.074815165950165935
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.077219440167868927   to: 0.075123957921291604
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.077502348066537385   to: 0.075428879851285657
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.077781636126332099   to: 0.075729977023579254
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.078057349130132320   to: 0.076027294446963031
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.078329531490439933   to: 0.076320876844024027
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.078598227242808891   to: 0.076610768640368934
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.078863480039863543   to: 0.076897013954598720
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.079125333145878177   to: 0.077179656589001097
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.079383829431890610   to: 0.077458740020928118
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.079639011371323898   to: 0.077734307394828173
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.079890921036091689   to: 0.078006401514901999
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.080139600093163302   to: 0.078275064838354655
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.080385089801565779   to: 0.078540339469215292
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.080627431009801187   to: 0.078802267152698655
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.080866664153658119   to: 0.079060889270082729
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.081102829254397615   to: 0.079316246834078341
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.081335965917294140   to: 0.079568380484667134
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.081566113330513140   to: 0.079817330485385599
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.081793310264308028   to: 0.080063136720033665
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.082017595070519186   to: 0.080305838689786982
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.082239005682359270   to: 0.080545475510693493
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.082457579614469256   to: 0.080782085911534782
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.082673353963230306   to: 0.081015708232034550
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.082886365407317641   to: 0.081246380421396300
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.083096650208482614   to: 0.081474140037153725
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.083304244212550019   to: 0.081699024244317839
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.083509182850618688   to: 0.081921069814805236
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.083711501140452949   to: 0.082140313127132991
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.083911233688054088   to: 0.082356790166365948
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.084108414689400918   to: 0.082570536524303101
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.084303077932348841   to: 0.082781587399889778
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.084495256798677976   to: 0.082989977599843667
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.084684984266280613   to: 0.083195741539482518
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.084872292911479130   to: 0.083398913243742379
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.085057214911465714   to: 0.083599526348375364
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.085239782046855658   to: 0.083797614101316586
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.085420025704346605   to: 0.083993209364210578
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.085597976879475957   to: 0.084186344614087236
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.085773666179469576   to: 0.084377051945178624
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.085947123826174920   to: 0.084565363070867844
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.086118379659071986   to: 0.084751309325761387
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.086287463138356210   to: 0.084934921667877555
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.086454403348087031   to: 0.085116230680942928
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.086619228999396947   to: 0.085295266576789763
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.086781968433755352   to: 0.085472059197847727
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.086942649626282245   to: 0.085646638019722707
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.087101300189107181   to: 0.085819032153857111
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.087257947374768358   to: 0.085989270350265157
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.087412618079648022   to: 0.086157381000337777
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.087565338847439653   to: 0.086323392139711144
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.087716135872643153   to: 0.086487331451194388
i: 100, name:           module.conv10.weight  changing lr from: 0.087865035004084324   to: 0.086649226267750679
i: 101, name:             module.conv10.bias  changing lr from: 0.088012061748454828   to: 0.086809103575527735



# Switched to train mode...
Epoch: [22][  0/391]	Time  0.193 ( 0.193)	Data  0.142 ( 0.142)	Loss 1.0352e+00 (1.0352e+00)	Acc@1  72.66 ( 72.66)	Acc@5  89.06 ( 89.06)
Epoch: [22][ 10/391]	Time  0.045 ( 0.056)	Data  0.001 ( 0.014)	Loss 1.1551e+00 (1.1372e+00)	Acc@1  68.75 ( 66.48)	Acc@5  93.75 ( 91.90)
Epoch: [22][ 20/391]	Time  0.042 ( 0.050)	Data  0.001 ( 0.008)	Loss 1.2218e+00 (1.1075e+00)	Acc@1  67.19 ( 67.41)	Acc@5  90.62 ( 92.15)
Epoch: [22][ 30/391]	Time  0.039 ( 0.047)	Data  0.001 ( 0.006)	Loss 1.1436e+00 (1.1046e+00)	Acc@1  66.41 ( 67.24)	Acc@5  92.97 ( 92.11)
Epoch: [22][ 40/391]	Time  0.040 ( 0.046)	Data  0.001 ( 0.004)	Loss 1.0467e+00 (1.1105e+00)	Acc@1  69.53 ( 67.40)	Acc@5  92.97 ( 92.05)
Epoch: [22][ 50/391]	Time  0.042 ( 0.045)	Data  0.001 ( 0.004)	Loss 1.1243e+00 (1.1135e+00)	Acc@1  71.09 ( 67.36)	Acc@5  90.62 ( 91.87)
Epoch: [22][ 60/391]	Time  0.043 ( 0.044)	Data  0.001 ( 0.003)	Loss 1.0345e+00 (1.1219e+00)	Acc@1  67.97 ( 67.17)	Acc@5  93.75 ( 91.80)
Epoch: [22][ 70/391]	Time  0.040 ( 0.044)	Data  0.001 ( 0.003)	Loss 1.2562e+00 (1.1276e+00)	Acc@1  63.28 ( 67.04)	Acc@5  91.41 ( 91.67)
Epoch: [22][ 80/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.003)	Loss 1.1042e+00 (1.1295e+00)	Acc@1  68.75 ( 66.85)	Acc@5  90.62 ( 91.70)
Epoch: [22][ 90/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.2952e+00 (1.1265e+00)	Acc@1  64.06 ( 66.98)	Acc@5  88.28 ( 91.79)
Epoch: [22][100/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.0799e+00 (1.1315e+00)	Acc@1  70.31 ( 66.92)	Acc@5  90.62 ( 91.70)
Epoch: [22][110/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.0969e+00 (1.1301e+00)	Acc@1  70.31 ( 66.88)	Acc@5  88.28 ( 91.67)
Epoch: [22][120/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.0819e+00 (1.1298e+00)	Acc@1  68.75 ( 66.80)	Acc@5  89.84 ( 91.63)
Epoch: [22][130/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.2873e+00 (1.1308e+00)	Acc@1  62.50 ( 66.70)	Acc@5  88.28 ( 91.60)
Epoch: [22][140/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.002)	Loss 9.4334e-01 (1.1279e+00)	Acc@1  71.09 ( 66.75)	Acc@5  94.53 ( 91.63)
Epoch: [22][150/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.3177e+00 (1.1342e+00)	Acc@1  60.94 ( 66.51)	Acc@5  89.84 ( 91.53)
Epoch: [22][160/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.0030e+00 (1.1307e+00)	Acc@1  71.88 ( 66.71)	Acc@5  94.53 ( 91.59)
Epoch: [22][170/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.1192e+00 (1.1312e+00)	Acc@1  64.06 ( 66.72)	Acc@5  93.75 ( 91.59)
Epoch: [22][180/391]	Time  0.046 ( 0.043)	Data  0.001 ( 0.002)	Loss 9.8971e-01 (1.1296e+00)	Acc@1  71.09 ( 66.85)	Acc@5  92.97 ( 91.57)
Epoch: [22][190/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.0175e+00 (1.1279e+00)	Acc@1  67.97 ( 66.95)	Acc@5  94.53 ( 91.60)
Epoch: [22][200/391]	Time  0.039 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.2897e+00 (1.1327e+00)	Acc@1  64.06 ( 66.83)	Acc@5  88.28 ( 91.57)
Epoch: [22][210/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.1025e+00 (1.1333e+00)	Acc@1  64.06 ( 66.81)	Acc@5  94.53 ( 91.59)
Epoch: [22][220/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.1641e+00 (1.1337e+00)	Acc@1  62.50 ( 66.80)	Acc@5  90.62 ( 91.55)
Epoch: [22][230/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.2895e+00 (1.1347e+00)	Acc@1  64.06 ( 66.80)	Acc@5  89.06 ( 91.52)
Epoch: [22][240/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.0320e+00 (1.1329e+00)	Acc@1  71.88 ( 66.86)	Acc@5  93.75 ( 91.57)
Epoch: [22][250/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.3637e+00 (1.1342e+00)	Acc@1  58.59 ( 66.83)	Acc@5  87.50 ( 91.52)
Epoch: [22][260/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.001)	Loss 9.9677e-01 (1.1329e+00)	Acc@1  69.53 ( 66.84)	Acc@5  92.19 ( 91.52)
Epoch: [22][270/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.1566e+00 (1.1314e+00)	Acc@1  65.62 ( 66.93)	Acc@5  92.97 ( 91.56)
Epoch: [22][280/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.2641e+00 (1.1343e+00)	Acc@1  60.16 ( 66.85)	Acc@5  86.72 ( 91.50)
Epoch: [22][290/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.1740e+00 (1.1347e+00)	Acc@1  64.84 ( 66.85)	Acc@5  89.06 ( 91.48)
Epoch: [22][300/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.001)	Loss 9.8733e-01 (1.1333e+00)	Acc@1  72.66 ( 66.91)	Acc@5  94.53 ( 91.51)
Epoch: [22][310/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.0153e+00 (1.1345e+00)	Acc@1  70.31 ( 66.85)	Acc@5  91.41 ( 91.50)
Epoch: [22][320/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.3536e+00 (1.1373e+00)	Acc@1  60.16 ( 66.76)	Acc@5  91.41 ( 91.50)
Epoch: [22][330/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.2003e+00 (1.1381e+00)	Acc@1  63.28 ( 66.76)	Acc@5  91.41 ( 91.46)
Epoch: [22][340/391]	Time  0.045 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.2453e+00 (1.1397e+00)	Acc@1  64.06 ( 66.68)	Acc@5  89.06 ( 91.44)
Epoch: [22][350/391]	Time  0.040 ( 0.042)	Data  0.002 ( 0.001)	Loss 1.4104e+00 (1.1429e+00)	Acc@1  60.16 ( 66.60)	Acc@5  90.62 ( 91.37)
Epoch: [22][360/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.2630e+00 (1.1437e+00)	Acc@1  64.84 ( 66.59)	Acc@5  82.81 ( 91.35)
Epoch: [22][370/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.3501e+00 (1.1432e+00)	Acc@1  60.16 ( 66.60)	Acc@5  91.41 ( 91.37)
Epoch: [22][380/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.0639e+00 (1.1429e+00)	Acc@1  66.41 ( 66.57)	Acc@5  91.41 ( 91.35)
Epoch: [22][390/391]	Time  0.029 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.3427e+00 (1.1419e+00)	Acc@1  57.50 ( 66.59)	Acc@5  92.50 ( 91.39)
## e[22] optimizer.zero_grad (sum) time: 0.2862381935119629
## e[22]       loss.backward (sum) time: 4.1601409912109375
## e[22]      optimizer.step (sum) time: 1.8632283210754395
## epoch[22] training(only) time: 16.508180379867554
# Switched to evaluate mode...
Test: [  0/100]	Time  0.157 ( 0.157)	Loss 1.5208e+00 (1.5208e+00)	Acc@1  61.00 ( 61.00)	Acc@5  85.00 ( 85.00)
Test: [ 10/100]	Time  0.024 ( 0.035)	Loss 1.8947e+00 (1.5851e+00)	Acc@1  51.00 ( 59.00)	Acc@5  83.00 ( 85.09)
Test: [ 20/100]	Time  0.024 ( 0.029)	Loss 1.2946e+00 (1.5521e+00)	Acc@1  57.00 ( 58.71)	Acc@5  90.00 ( 85.71)
Test: [ 30/100]	Time  0.019 ( 0.027)	Loss 1.5073e+00 (1.5598e+00)	Acc@1  59.00 ( 58.55)	Acc@5  85.00 ( 85.29)
Test: [ 40/100]	Time  0.019 ( 0.025)	Loss 1.6240e+00 (1.5581e+00)	Acc@1  56.00 ( 58.29)	Acc@5  84.00 ( 85.46)
Test: [ 50/100]	Time  0.022 ( 0.025)	Loss 1.3721e+00 (1.5516e+00)	Acc@1  60.00 ( 58.31)	Acc@5  86.00 ( 85.22)
Test: [ 60/100]	Time  0.017 ( 0.024)	Loss 1.5120e+00 (1.5377e+00)	Acc@1  59.00 ( 58.21)	Acc@5  84.00 ( 85.46)
Test: [ 70/100]	Time  0.024 ( 0.024)	Loss 1.5963e+00 (1.5333e+00)	Acc@1  57.00 ( 58.21)	Acc@5  85.00 ( 85.62)
Test: [ 80/100]	Time  0.023 ( 0.024)	Loss 1.6878e+00 (1.5356e+00)	Acc@1  57.00 ( 58.35)	Acc@5  81.00 ( 85.59)
Test: [ 90/100]	Time  0.017 ( 0.023)	Loss 1.8496e+00 (1.5290e+00)	Acc@1  56.00 ( 58.57)	Acc@5  82.00 ( 85.70)
 * Acc@1 58.790 Acc@5 85.820
### epoch[22] execution time: 18.891902446746826
EPOCH 23
i:   0, name:           module.stem.0.weight  changing lr from: 0.054542230279991735   to: 0.051136353678802732
i:   1, name:             module.stem.0.bias  changing lr from: 0.055089366100652508   to: 0.051710011572125542
i:   2, name:           module.stem.1.weight  changing lr from: 0.055630691860597214   to: 0.052277994581496824
i:   3, name:             module.stem.1.bias  changing lr from: 0.056166223261340020   to: 0.052840300868527638
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.056695978405225736   to: 0.053396931737493561
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.057219977661529302   to: 0.053947891476622378
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.057738243537986761   to: 0.054493187205473276
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.058250800557571918   to: 0.055032828728213690
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.058757675140337598   to: 0.055566828392604434
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.059258895490145215   to: 0.056095200954507533
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.059754491486111463   to: 0.056617963447736112
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.060244494578605291   to: 0.057135135059069045
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.060728937689633146   to: 0.057646737008258148
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.061207855117455558   to: 0.058152792432859750
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.061681282445281864   to: 0.058653326277726472
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.062149256453895643   to: 0.059148365189000011
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.062611815038066385   to: 0.059637937412449174
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.063068997126608878   to: 0.060122072696002532
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.063520842605954725   to: 0.060600802196328421
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.063967392247105667   to: 0.061074158389319767
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.064408687635841830   to: 0.061542174984345027
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.064844771106062613   to: 0.062004886842130694
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.065275685676141226   to: 0.062462329896144711
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.065701474988178563   to: 0.062914541077354225
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.066122183250045222   to: 0.063361558242234661
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.066537855180104619   to: 0.063803420103911115
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.066948535954513069   to: 0.064240166166316823
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.067354271156997478   to: 0.064671836661256879
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.067755106731013093   to: 0.065098472488268902
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.068151088934188406   to: 0.065520115157176137
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.068542264294966682   to: 0.065936806733231434
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.068928679571357496   to: 0.066348589784754400
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.069310381711713651   to: 0.066755507333166514
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.069687417817453010   to: 0.067157602805332881
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.070059835107646823   to: 0.067554919988121964
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.070427680885398969   to: 0.067947502985097594
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.070791002505943834   to: 0.068335396175260618
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.071149847346392500   to: 0.068718644173760446
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.071504262777059777   to: 0.069097291794499124
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.071854296134307036   to: 0.069471384014553800
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.072199994694838149   to: 0.069840965940345306
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.072541405651388294   to: 0.070206082775484166
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.072878576089747224   to: 0.070566779790226283
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.073211552967061361   to: 0.070923102292474588
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.073540383091360503   to: 0.071275095600263932
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.073865113102257532   to: 0.071622805015669450
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.074185789452771086   to: 0.071966275800080359
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.074502458392223261   to: 0.072305553150783797
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.074815165950165935   to: 0.072640682178804525
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.075123957921291604   to: 0.072971707887949197
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.075428879851285657   to: 0.073298675155004947
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.075729977023579254   to: 0.073621628711044537
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.076027294446963031   to: 0.073940613123791729
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.076320876844024027   to: 0.074255672781002327
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.076610768640368934   to: 0.074566851874818138
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.076897013954598720   to: 0.074874194387052256
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.077179656589001097   to: 0.075177744075366634
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.077458740020928118   to: 0.075477544460302859
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.077734307394828173   to: 0.075773638813130234
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.078006401514901999   to: 0.076066070144474945
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.078275064838354655   to: 0.076354881193697210
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.078540339469215292   to: 0.076640114418982941
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.078802267152698655   to: 0.076921811988118760
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.079060889270082729   to: 0.077200015769920305
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.079316246834078341   to: 0.077474767326284388
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.079568380484667134   to: 0.077746107904837353
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.079817330485385599   to: 0.078014078432152759
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.080063136720033665   to: 0.078278719507512307
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.080305838689786982   to: 0.078540071397185662
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.080545475510693493   to: 0.078798174029204998
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.080782085911534782   to: 0.079053066988611545
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.081015708232034550   to: 0.079304789513152271
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.081246380421396300   to: 0.079553380489405301
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.081474140037153725   to: 0.079798878449314214
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.081699024244317839   to: 0.080041321567111523
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.081921069814805236   to: 0.080280747656612750
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.082140313127132991   to: 0.080517194168863215
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.082356790166365948   to: 0.080750698190120263
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.082570536524303101   to: 0.080981296440154726
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.082781587399889778   to: 0.081209025270855481
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.082989977599843667   to: 0.081433920665121950
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.083195741539482518   to: 0.081656018236030484
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.083398913243742379   to: 0.081875353226259995
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.083599526348375364   to: 0.082091960507764017
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.083797614101316586   to: 0.082305874581676056
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.083993209364210578   to: 0.082517129578436113
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.084186344614087236   to: 0.082725759258126697
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.084377051945178624   to: 0.082931797011006669
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.084565363070867844   to: 0.083135275858232660
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.084751309325761387   to: 0.083336228452757358
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.084934921667877555   to: 0.083534687080394687
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.085116230680942928   to: 0.083730683661042860
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.085295266576789763   to: 0.083924249750055663
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.085472059197847727   to: 0.084115416539753796
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.085646638019722707   to: 0.084304214861067428
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.085819032153857111   to: 0.084490675185302677
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.085989270350265157   to: 0.084674827626023658
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.086157381000337777   to: 0.084856701941043555
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.086323392139711144   to: 0.085036327534517162
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.086487331451194388   to: 0.085213733459128596
i: 100, name:           module.conv10.weight  changing lr from: 0.086649226267750679   to: 0.085388948418367805
i: 101, name:             module.conv10.bias  changing lr from: 0.086809103575527735   to: 0.085562000768889646



# Switched to train mode...
Epoch: [23][  0/391]	Time  0.200 ( 0.200)	Data  0.154 ( 0.154)	Loss 1.0460e+00 (1.0460e+00)	Acc@1  70.31 ( 70.31)	Acc@5  90.62 ( 90.62)
Epoch: [23][ 10/391]	Time  0.040 ( 0.058)	Data  0.001 ( 0.015)	Loss 1.2301e+00 (1.0772e+00)	Acc@1  64.06 ( 68.47)	Acc@5  91.41 ( 91.69)
Epoch: [23][ 20/391]	Time  0.040 ( 0.050)	Data  0.001 ( 0.008)	Loss 1.1137e+00 (1.0833e+00)	Acc@1  63.28 ( 67.82)	Acc@5  92.97 ( 91.89)
Epoch: [23][ 30/391]	Time  0.041 ( 0.047)	Data  0.001 ( 0.006)	Loss 9.0040e-01 (1.0816e+00)	Acc@1  75.00 ( 67.97)	Acc@5  95.31 ( 92.31)
Epoch: [23][ 40/391]	Time  0.040 ( 0.046)	Data  0.001 ( 0.005)	Loss 9.8757e-01 (1.0692e+00)	Acc@1  75.00 ( 68.29)	Acc@5  92.19 ( 92.53)
Epoch: [23][ 50/391]	Time  0.042 ( 0.045)	Data  0.001 ( 0.004)	Loss 1.0747e+00 (1.0717e+00)	Acc@1  71.09 ( 68.61)	Acc@5  89.84 ( 92.51)
Epoch: [23][ 60/391]	Time  0.043 ( 0.045)	Data  0.002 ( 0.004)	Loss 1.0938e+00 (1.0751e+00)	Acc@1  71.88 ( 68.78)	Acc@5  89.06 ( 92.26)
Epoch: [23][ 70/391]	Time  0.043 ( 0.044)	Data  0.001 ( 0.003)	Loss 1.1951e+00 (1.0707e+00)	Acc@1  63.28 ( 68.76)	Acc@5  93.75 ( 92.37)
Epoch: [23][ 80/391]	Time  0.040 ( 0.044)	Data  0.001 ( 0.003)	Loss 9.7468e-01 (1.0742e+00)	Acc@1  69.53 ( 68.70)	Acc@5  93.75 ( 92.36)
Epoch: [23][ 90/391]	Time  0.044 ( 0.044)	Data  0.001 ( 0.003)	Loss 1.1929e+00 (1.0764e+00)	Acc@1  68.75 ( 68.60)	Acc@5  88.28 ( 92.31)
Epoch: [23][100/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.003)	Loss 9.0467e-01 (1.0731e+00)	Acc@1  75.00 ( 68.58)	Acc@5  95.31 ( 92.42)
Epoch: [23][110/391]	Time  0.039 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.1529e+00 (1.0717e+00)	Acc@1  67.19 ( 68.65)	Acc@5  93.75 ( 92.48)
Epoch: [23][120/391]	Time  0.045 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.1224e+00 (1.0755e+00)	Acc@1  71.09 ( 68.63)	Acc@5  92.19 ( 92.43)
Epoch: [23][130/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.1695e+00 (1.0789e+00)	Acc@1  67.19 ( 68.53)	Acc@5  92.97 ( 92.42)
Epoch: [23][140/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.0967e+00 (1.0825e+00)	Acc@1  65.62 ( 68.47)	Acc@5  95.31 ( 92.39)
Epoch: [23][150/391]	Time  0.055 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.0317e+00 (1.0823e+00)	Acc@1  72.66 ( 68.39)	Acc@5  89.84 ( 92.36)
Epoch: [23][160/391]	Time  0.044 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.1620e+00 (1.0859e+00)	Acc@1  67.97 ( 68.18)	Acc@5  92.97 ( 92.32)
Epoch: [23][170/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.0204e+00 (1.0867e+00)	Acc@1  68.75 ( 68.12)	Acc@5  92.19 ( 92.28)
Epoch: [23][180/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.1510e+00 (1.0891e+00)	Acc@1  64.84 ( 68.06)	Acc@5  92.97 ( 92.22)
Epoch: [23][190/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.0393e+00 (1.0903e+00)	Acc@1  72.66 ( 67.99)	Acc@5  91.41 ( 92.23)
Epoch: [23][200/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.1672e+00 (1.0901e+00)	Acc@1  65.62 ( 67.95)	Acc@5  96.09 ( 92.26)
Epoch: [23][210/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.1556e+00 (1.0945e+00)	Acc@1  64.84 ( 67.79)	Acc@5  92.19 ( 92.17)
Epoch: [23][220/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.1315e+00 (1.0917e+00)	Acc@1  67.97 ( 67.95)	Acc@5  91.41 ( 92.18)
Epoch: [23][230/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.1504e+00 (1.0931e+00)	Acc@1  68.75 ( 67.90)	Acc@5  90.62 ( 92.16)
Epoch: [23][240/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.3452e+00 (1.0964e+00)	Acc@1  57.03 ( 67.85)	Acc@5  86.72 ( 92.12)
Epoch: [23][250/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.1739e+00 (1.0988e+00)	Acc@1  66.41 ( 67.85)	Acc@5  89.06 ( 92.08)
Epoch: [23][260/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 9.7846e-01 (1.1010e+00)	Acc@1  73.44 ( 67.81)	Acc@5  91.41 ( 92.05)
Epoch: [23][270/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.0022e+00 (1.1015e+00)	Acc@1  70.31 ( 67.82)	Acc@5  92.19 ( 92.04)
Epoch: [23][280/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.0166e+00 (1.1024e+00)	Acc@1  68.75 ( 67.75)	Acc@5  95.31 ( 92.05)
Epoch: [23][290/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.2279e+00 (1.1011e+00)	Acc@1  62.50 ( 67.73)	Acc@5  92.97 ( 92.06)
Epoch: [23][300/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.0720e+00 (1.1029e+00)	Acc@1  67.97 ( 67.67)	Acc@5  92.97 ( 92.04)
Epoch: [23][310/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.2182e+00 (1.1032e+00)	Acc@1  61.72 ( 67.66)	Acc@5  89.84 ( 92.03)
Epoch: [23][320/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 9.7650e-01 (1.1015e+00)	Acc@1  73.44 ( 67.66)	Acc@5  93.75 ( 92.06)
Epoch: [23][330/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.1326e+00 (1.1027e+00)	Acc@1  64.06 ( 67.62)	Acc@5  94.53 ( 92.05)
Epoch: [23][340/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.3141e+00 (1.1028e+00)	Acc@1  57.03 ( 67.60)	Acc@5  90.62 ( 92.05)
Epoch: [23][350/391]	Time  0.046 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.1370e+00 (1.1043e+00)	Acc@1  67.97 ( 67.59)	Acc@5  92.97 ( 92.04)
Epoch: [23][360/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.2644e+00 (1.1053e+00)	Acc@1  66.41 ( 67.56)	Acc@5  89.06 ( 92.03)
Epoch: [23][370/391]	Time  0.050 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.2787e+00 (1.1057e+00)	Acc@1  65.62 ( 67.59)	Acc@5  85.94 ( 92.00)
Epoch: [23][380/391]	Time  0.054 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.1452e+00 (1.1070e+00)	Acc@1  71.09 ( 67.56)	Acc@5  90.62 ( 91.99)
Epoch: [23][390/391]	Time  0.028 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.5615e+00 (1.1077e+00)	Acc@1  52.50 ( 67.57)	Acc@5  82.50 ( 92.00)
## e[23] optimizer.zero_grad (sum) time: 0.2846360206604004
## e[23]       loss.backward (sum) time: 4.147223949432373
## e[23]      optimizer.step (sum) time: 1.8939006328582764
## epoch[23] training(only) time: 16.504454374313354
# Switched to evaluate mode...
Test: [  0/100]	Time  0.151 ( 0.151)	Loss 1.4596e+00 (1.4596e+00)	Acc@1  58.00 ( 58.00)	Acc@5  87.00 ( 87.00)
Test: [ 10/100]	Time  0.019 ( 0.034)	Loss 1.5217e+00 (1.5173e+00)	Acc@1  62.00 ( 59.55)	Acc@5  89.00 ( 85.82)
Test: [ 20/100]	Time  0.022 ( 0.029)	Loss 1.3317e+00 (1.5062e+00)	Acc@1  64.00 ( 59.57)	Acc@5  88.00 ( 86.62)
Test: [ 30/100]	Time  0.017 ( 0.026)	Loss 1.4817e+00 (1.5201e+00)	Acc@1  54.00 ( 58.81)	Acc@5  89.00 ( 86.10)
Test: [ 40/100]	Time  0.024 ( 0.025)	Loss 1.4733e+00 (1.5342e+00)	Acc@1  61.00 ( 58.17)	Acc@5  86.00 ( 86.15)
Test: [ 50/100]	Time  0.024 ( 0.025)	Loss 1.6213e+00 (1.5510e+00)	Acc@1  58.00 ( 57.80)	Acc@5  87.00 ( 85.67)
Test: [ 60/100]	Time  0.023 ( 0.024)	Loss 1.5900e+00 (1.5396e+00)	Acc@1  57.00 ( 58.11)	Acc@5  83.00 ( 85.74)
Test: [ 70/100]	Time  0.024 ( 0.024)	Loss 1.4765e+00 (1.5372e+00)	Acc@1  63.00 ( 58.48)	Acc@5  84.00 ( 85.62)
Test: [ 80/100]	Time  0.024 ( 0.024)	Loss 1.6218e+00 (1.5437e+00)	Acc@1  62.00 ( 58.37)	Acc@5  84.00 ( 85.63)
Test: [ 90/100]	Time  0.022 ( 0.024)	Loss 1.8754e+00 (1.5401e+00)	Acc@1  51.00 ( 58.76)	Acc@5  82.00 ( 85.71)
 * Acc@1 58.850 Acc@5 85.790
### epoch[23] execution time: 18.913999795913696
EPOCH 24
i:   0, name:           module.stem.0.weight  changing lr from: 0.051136353678802732   to: 0.047729843538492883
i:   1, name:             module.stem.0.bias  changing lr from: 0.051710011572125542   to: 0.048327406203646464
i:   2, name:           module.stem.1.weight  changing lr from: 0.052277994581496824   to: 0.048919530988329608
i:   3, name:             module.stem.1.bias  changing lr from: 0.052840300868527638   to: 0.049506195473080113
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.053396931737493561   to: 0.050087381196055658
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.053947891476622378   to: 0.050663073468658393
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.054493187205473276   to: 0.051233261197852466
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.055032828728213690   to: 0.051797936714979675
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.055566828392604434   to: 0.052357095610881504
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.056095200954507533   to: 0.052910736577138621
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.056617963447736112   to: 0.053458861253242840
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.057135135059069045   to: 0.054001474079519232
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.057646737008258148   to: 0.054538582155619776
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.058152792432859750   to: 0.055070195104414049
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.058653326277726472   to: 0.055596324941105203
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.059148365189000011   to: 0.056116985947404441
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.059637937412449174   to: 0.056632194550599514
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.060122072696002532   to: 0.057141969207358229
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.060600802196328421   to: 0.057646330292110248
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.061074158389319767   to: 0.058145299989855584
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.061542174984345027   to: 0.058638902193250887
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.062004886842130694   to: 0.059127162403829703
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.062462329896144711   to: 0.059610107637215463
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.062914541077354225   to: 0.060087766332190651
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.063361558242234661   to: 0.060560168263488957
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.063803420103911115   to: 0.061027344458180754
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.064240166166316823   to: 0.061489327115526515
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.064671836661256879   to: 0.061946149530175777
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.065098472488268902   to: 0.062397846018593106
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.065520115157176137   to: 0.062844451848595911
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.065936806733231434   to: 0.063286003171892688
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.066348589784754400   to: 0.063722536959513160
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.066755507333166514   to: 0.064154090940025443
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.067157602805332881   to: 0.064580703540438808
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.067554919988121964   to: 0.065002413829692990
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.067947502985097594   to: 0.065419261464639014
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.068335396175260618   to: 0.065831286638419140
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.068718644173760446   to: 0.066238530031156428
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.069097291794499124   to: 0.066641032762867286
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.069471384014553800   to: 0.067038836348513556
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.069840965940345306   to: 0.067431982655113229
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.070206082775484166   to: 0.067820513860831266
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.070566779790226283   to: 0.068204472415975034
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.070923102292474588   to: 0.068583901005821485
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.071275095600263932   to: 0.068958842515205163
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.071622805015669450   to: 0.069329339994798983
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.071966275800080359   to: 0.069695436629021751
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.072305553150783797   to: 0.070057175705509289
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.072640682178804525   to: 0.070414600586087131
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.072971707887949197   to: 0.070767754679186029
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.073298675155004947   to: 0.071116681413642913
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.073621628711044537   to: 0.071461424213832198
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.073940613123791729   to: 0.071802026476074074
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.074255672781002327   to: 0.072138531546268855
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.074566851874818138   to: 0.072470982698707470
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.074874194387052256   to: 0.072799423116010620
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.075177744075366634   to: 0.073123895870150779
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.075477544460302859   to: 0.073444443904512324
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.075773638813130234   to: 0.073761110016947504
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.076066070144474945   to: 0.074073936843786867
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.076354881193697210   to: 0.074382966844764697
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.076640114418982941   to: 0.074688242288821080
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.076921811988118760   to: 0.074989805240744084
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.077200015769920305   to: 0.075287697548616403
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.077474767326284388   to: 0.075581960832032821
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.077746107904837353   to: 0.075872636471055119
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.078014078432152759   to: 0.076159765595873410
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.078278719507512307   to: 0.076443389077143140
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.078540071397185662   to: 0.076723547516968874
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.078798174029204998   to: 0.077000281240506396
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.079053066988611545   to: 0.077273630288156397
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.079304789513152271   to: 0.077543634408323445
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.079553380489405301   to: 0.077810333050715608
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.079798878449314214   to: 0.078073765360160280
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.080041321567111523   to: 0.078333970170913370
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.080280747656612750   to: 0.078590986001439461
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.080517194168863215   to: 0.078844851049641743
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.080750698190120263   to: 0.079095603188521046
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.080981296440154726   to: 0.079343279962244315
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.081209025270855481   to: 0.079587918582603556
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.081433920665121950   to: 0.079829555925847132
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.081656018236030484   to: 0.080068228529865823
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.081875353226259995   to: 0.080303972591716871
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.082091960507764017   to: 0.080536823965469961
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.082305874581676056   to: 0.080766818160359605
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.082517129578436113   to: 0.080993990339229105
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.082725759258126697   to: 0.081218375317251734
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.082931797011006669   to: 0.081440007560915656
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.083135275858232660   to: 0.081658921187259259
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.083336228452757358   to: 0.081875149963344371
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.083534687080394687   to: 0.082088727305955234
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.083730683661042860   to: 0.082299686281511852
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.083924249750055663   to: 0.082508059606186221
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.084115416539753796   to: 0.082713879646211186
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.084304214861067428   to: 0.082917178418371387
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.084490675185302677   to: 0.083117987590666728
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.084674827626023658   to: 0.083316338483138852
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.084856701941043555   to: 0.083512262068851692
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.085036327534517162   to: 0.083705788975017473
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.085213733459128596   to: 0.083896949484259881
i: 100, name:           module.conv10.weight  changing lr from: 0.085388948418367805   to: 0.084085773536006575
i: 101, name:             module.conv10.bias  changing lr from: 0.085562000768889646   to: 0.084272290728003352



# Switched to train mode...
Epoch: [24][  0/391]	Time  0.189 ( 0.189)	Data  0.142 ( 0.142)	Loss 1.0996e+00 (1.0996e+00)	Acc@1  70.31 ( 70.31)	Acc@5  93.75 ( 93.75)
Epoch: [24][ 10/391]	Time  0.040 ( 0.056)	Data  0.001 ( 0.014)	Loss 1.1898e+00 (1.1121e+00)	Acc@1  60.94 ( 66.19)	Acc@5  92.19 ( 92.26)
Epoch: [24][ 20/391]	Time  0.041 ( 0.049)	Data  0.001 ( 0.008)	Loss 9.8108e-01 (1.0514e+00)	Acc@1  70.31 ( 68.19)	Acc@5  94.53 ( 92.41)
Epoch: [24][ 30/391]	Time  0.043 ( 0.047)	Data  0.001 ( 0.006)	Loss 1.1280e+00 (1.0523e+00)	Acc@1  66.41 ( 68.65)	Acc@5  95.31 ( 92.26)
Epoch: [24][ 40/391]	Time  0.040 ( 0.045)	Data  0.001 ( 0.004)	Loss 1.1984e+00 (1.0526e+00)	Acc@1  67.19 ( 68.62)	Acc@5  89.06 ( 92.38)
Epoch: [24][ 50/391]	Time  0.042 ( 0.044)	Data  0.001 ( 0.004)	Loss 1.1132e+00 (1.0492e+00)	Acc@1  62.50 ( 68.49)	Acc@5  94.53 ( 92.66)
Epoch: [24][ 60/391]	Time  0.039 ( 0.044)	Data  0.001 ( 0.003)	Loss 1.3091e+00 (1.0545e+00)	Acc@1  63.28 ( 68.58)	Acc@5  90.62 ( 92.64)
Epoch: [24][ 70/391]	Time  0.040 ( 0.044)	Data  0.001 ( 0.003)	Loss 9.4567e-01 (1.0611e+00)	Acc@1  75.00 ( 68.53)	Acc@5  92.19 ( 92.51)
Epoch: [24][ 80/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.003)	Loss 1.1580e+00 (1.0602e+00)	Acc@1  67.19 ( 68.37)	Acc@5  92.97 ( 92.53)
Epoch: [24][ 90/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.003)	Loss 9.1066e-01 (1.0603e+00)	Acc@1  74.22 ( 68.33)	Acc@5  92.97 ( 92.58)
Epoch: [24][100/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.1625e+00 (1.0643e+00)	Acc@1  66.41 ( 68.22)	Acc@5  89.84 ( 92.52)
Epoch: [24][110/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.1868e+00 (1.0592e+00)	Acc@1  65.62 ( 68.38)	Acc@5  93.75 ( 92.60)
Epoch: [24][120/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.0055e+00 (1.0568e+00)	Acc@1  68.75 ( 68.45)	Acc@5  93.75 ( 92.67)
Epoch: [24][130/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.002)	Loss 9.6822e-01 (1.0593e+00)	Acc@1  71.88 ( 68.48)	Acc@5  96.88 ( 92.64)
Epoch: [24][140/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.3086e+00 (1.0606e+00)	Acc@1  61.72 ( 68.51)	Acc@5  92.97 ( 92.66)
Epoch: [24][150/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.0924e+00 (1.0606e+00)	Acc@1  71.88 ( 68.53)	Acc@5  93.75 ( 92.69)
Epoch: [24][160/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.0800e+00 (1.0612e+00)	Acc@1  64.06 ( 68.51)	Acc@5  92.97 ( 92.69)
Epoch: [24][170/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 9.4626e-01 (1.0621e+00)	Acc@1  68.75 ( 68.49)	Acc@5  95.31 ( 92.61)
Epoch: [24][180/391]	Time  0.054 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.0818e+00 (1.0616e+00)	Acc@1  66.41 ( 68.53)	Acc@5  92.19 ( 92.58)
Epoch: [24][190/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.0059e+00 (1.0636e+00)	Acc@1  67.97 ( 68.42)	Acc@5  94.53 ( 92.59)
Epoch: [24][200/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.0117e+00 (1.0655e+00)	Acc@1  72.66 ( 68.40)	Acc@5  94.53 ( 92.53)
Epoch: [24][210/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.2128e+00 (1.0662e+00)	Acc@1  62.50 ( 68.39)	Acc@5  92.19 ( 92.50)
Epoch: [24][220/391]	Time  0.045 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.1693e+00 (1.0701e+00)	Acc@1  60.94 ( 68.30)	Acc@5  89.84 ( 92.42)
Epoch: [24][230/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.3556e+00 (1.0709e+00)	Acc@1  65.62 ( 68.37)	Acc@5  85.94 ( 92.39)
Epoch: [24][240/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.3439e+00 (1.0728e+00)	Acc@1  60.94 ( 68.31)	Acc@5  90.62 ( 92.37)
Epoch: [24][250/391]	Time  0.045 ( 0.042)	Data  0.001 ( 0.002)	Loss 9.7553e-01 (1.0753e+00)	Acc@1  71.88 ( 68.26)	Acc@5  89.84 ( 92.32)
Epoch: [24][260/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.1054e+00 (1.0771e+00)	Acc@1  70.31 ( 68.25)	Acc@5  92.19 ( 92.28)
Epoch: [24][270/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.2963e+00 (1.0778e+00)	Acc@1  59.38 ( 68.24)	Acc@5  92.97 ( 92.29)
Epoch: [24][280/391]	Time  0.045 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.1182e+00 (1.0796e+00)	Acc@1  67.19 ( 68.21)	Acc@5  90.62 ( 92.28)
Epoch: [24][290/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 9.0528e-01 (1.0808e+00)	Acc@1  75.78 ( 68.17)	Acc@5  93.75 ( 92.28)
Epoch: [24][300/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.001)	Loss 9.5693e-01 (1.0814e+00)	Acc@1  70.31 ( 68.16)	Acc@5  95.31 ( 92.27)
Epoch: [24][310/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.0486e+00 (1.0812e+00)	Acc@1  69.53 ( 68.18)	Acc@5  91.41 ( 92.26)
Epoch: [24][320/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.1543e+00 (1.0813e+00)	Acc@1  60.16 ( 68.17)	Acc@5  91.41 ( 92.26)
Epoch: [24][330/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.001)	Loss 9.4183e-01 (1.0813e+00)	Acc@1  72.66 ( 68.13)	Acc@5  95.31 ( 92.29)
Epoch: [24][340/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.2527e+00 (1.0820e+00)	Acc@1  63.28 ( 68.09)	Acc@5  90.62 ( 92.30)
Epoch: [24][350/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.0681e+00 (1.0818e+00)	Acc@1  70.31 ( 68.07)	Acc@5  90.62 ( 92.29)
Epoch: [24][360/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.1112e+00 (1.0808e+00)	Acc@1  66.41 ( 68.10)	Acc@5  92.19 ( 92.30)
Epoch: [24][370/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.0242e+00 (1.0830e+00)	Acc@1  68.75 ( 68.03)	Acc@5  92.97 ( 92.28)
Epoch: [24][380/391]	Time  0.045 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.0458e+00 (1.0837e+00)	Acc@1  67.97 ( 68.01)	Acc@5  92.97 ( 92.27)
Epoch: [24][390/391]	Time  0.028 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.2011e+00 (1.0854e+00)	Acc@1  66.25 ( 67.92)	Acc@5  85.00 ( 92.26)
## e[24] optimizer.zero_grad (sum) time: 0.2867391109466553
## e[24]       loss.backward (sum) time: 4.187004089355469
## e[24]      optimizer.step (sum) time: 1.850151777267456
## epoch[24] training(only) time: 16.493821620941162
# Switched to evaluate mode...
Test: [  0/100]	Time  0.150 ( 0.150)	Loss 1.4556e+00 (1.4556e+00)	Acc@1  63.00 ( 63.00)	Acc@5  87.00 ( 87.00)
Test: [ 10/100]	Time  0.021 ( 0.034)	Loss 1.9423e+00 (1.6332e+00)	Acc@1  52.00 ( 59.00)	Acc@5  85.00 ( 84.36)
Test: [ 20/100]	Time  0.021 ( 0.028)	Loss 1.2971e+00 (1.6195e+00)	Acc@1  65.00 ( 58.43)	Acc@5  87.00 ( 84.76)
Test: [ 30/100]	Time  0.021 ( 0.026)	Loss 1.5991e+00 (1.6455e+00)	Acc@1  53.00 ( 57.48)	Acc@5  88.00 ( 84.71)
Test: [ 40/100]	Time  0.024 ( 0.025)	Loss 1.6911e+00 (1.6416e+00)	Acc@1  51.00 ( 57.17)	Acc@5  88.00 ( 85.05)
Test: [ 50/100]	Time  0.023 ( 0.025)	Loss 1.4350e+00 (1.6381e+00)	Acc@1  58.00 ( 56.94)	Acc@5  86.00 ( 84.94)
Test: [ 60/100]	Time  0.022 ( 0.024)	Loss 1.5600e+00 (1.6214e+00)	Acc@1  58.00 ( 57.21)	Acc@5  89.00 ( 85.20)
Test: [ 70/100]	Time  0.018 ( 0.024)	Loss 1.5763e+00 (1.6200e+00)	Acc@1  58.00 ( 57.32)	Acc@5  82.00 ( 85.18)
Test: [ 80/100]	Time  0.018 ( 0.024)	Loss 1.6872e+00 (1.6169e+00)	Acc@1  56.00 ( 57.43)	Acc@5  85.00 ( 85.15)
Test: [ 90/100]	Time  0.019 ( 0.023)	Loss 1.8860e+00 (1.6123e+00)	Acc@1  52.00 ( 57.57)	Acc@5  84.00 ( 85.18)
 * Acc@1 57.850 Acc@5 85.350
### epoch[24] execution time: 18.873321771621704
EPOCH 25
i:   0, name:           module.stem.0.weight  changing lr from: 0.047729843538492883   to: 0.044338527502719036
i:   1, name:             module.stem.0.bias  changing lr from: 0.048327406203646464   to: 0.044957037501483943
i:   2, name:           module.stem.1.weight  changing lr from: 0.048919530988329608   to: 0.045570454475437429
i:   3, name:             module.stem.1.bias  changing lr from: 0.049506195473080113   to: 0.046178732364548405
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.050087381196055658   to: 0.046781829947759125
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.050663073468658393   to: 0.047379710632641632
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.051233261197852466   to: 0.047972342252257473
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.051797936714979675   to: 0.048559696869033553
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.052357095610881504   to: 0.049141750585467533
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.052910736577138621   to: 0.049718483361478209
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.053458861253242840   to: 0.050289878838217797
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.054001474079519232   to: 0.050855924168165485
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.054538582155619776   to: 0.051416609851323208
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.055070195104414049   to: 0.051971929577338011
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.055596324941105203   to: 0.052521880073377138
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.056116985947404441   to: 0.053066460957585798
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.056632194550599514   to: 0.053605674597959264
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.057141969207358229   to: 0.054139525976465687
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.057646330292110248   to: 0.054668022558257361
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.058145299989855584   to: 0.055191174165813053
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.058638902193250887   to: 0.055708992857856243
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.059127162403829703   to: 0.056221492812898066
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.059610107637215463   to: 0.056728690217256787
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.060087766332190651   to: 0.057230603157409535
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.060560168263488957   to: 0.057727251516534961
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.061027344458180754   to: 0.058218656875109270
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.061489327115526515   to: 0.058704842415421211
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.061946149530175777   to: 0.059185832829875731
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.062397846018593106   to: 0.059661654232958529
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.062844451848595911   to: 0.060132334076737494
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.063286003171892688   to: 0.060597901069780746
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.063722536959513160   to: 0.061058385099373828
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.064154090940025443   to: 0.061513817156921960
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.064580703540438808   to: 0.061964229266426765
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.065002413829692990   to: 0.062409654415929716
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.065419261464639014   to: 0.062850126491817926
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.065831286638419140   to: 0.063285680215891121
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.066238530031156428   to: 0.063716351085091077
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.066641032762867286   to: 0.064142175313798455
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.067038836348513556   to: 0.064563189778604577
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.067431982655113229   to: 0.064979431965468321
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.067820513860831266   to: 0.065390939919171776
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.068204472415975034   to: 0.065797752194989872
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.068583901005821485   to: 0.066199907812493450
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.068958842515205163   to: 0.066597446211406203
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.069329339994798983   to: 0.066990407209439565
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.069695436629021751   to: 0.067378830962031830
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.070057175705509289   to: 0.067762757923920017
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.070414600586087131   to: 0.068142228812475142
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.070767754679186029   to: 0.068517284572734927
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.071116681413642913   to: 0.068887966344068560
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.071461424213832198   to: 0.069254315428411761
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.071802026476074074   to: 0.069616373260011646
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.072138531546268855   to: 0.069974181376623368
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.072470982698707470   to: 0.070327781392102162
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.072799423116010620   to: 0.070677214970336563
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.073123895870150779   to: 0.071022523800470611
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.073444443904512324   to: 0.071363749573364069
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.073761110016947504   to: 0.071700933959242361
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.074073936843786867   to: 0.072034118586488546
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.074382966844764697   to: 0.072363345021532494
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.074688242288821080   to: 0.072688654749792955
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.074989805240744084   to: 0.073010089157630589
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.075287697548616403   to: 0.073327689515270827
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.075581960832032821   to: 0.073641496960657735
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.075872636471055119   to: 0.073951552484200697
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.076159765595873410   to: 0.074257896914377328
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.076443389077143140   to: 0.074560570904157797
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.076723547516968874   to: 0.074859614918216272
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.077000281240506396   to: 0.075155069220896986
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.077273630288156397   to: 0.075446973864903621
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.077543634408323445   to: 0.075735368680681411
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.077810333050715608   to: 0.076020293266462924
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.078073765360160280   to: 0.076301786978949446
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.078333970170913370   to: 0.076579888924601061
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.078590986001439461   to: 0.076854637951508958
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.078844851049641743   to: 0.077126072641825361
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.079095603188521046   to: 0.077394231304726627
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.079343279962244315   to: 0.077659151969886653
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.079587918582603556   to: 0.077920872381437897
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.079829555925847132   to: 0.078179429992398783
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.080068228529865823   to: 0.078434861959546742
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.080303972591716871   to: 0.078687205138717020
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.080536823965469961   to: 0.078936496080508206
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.080766818160359605   to: 0.079182771026375998
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.080993990339229105   to: 0.079426065905097737
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.081218375317251734   to: 0.079666416329590498
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.081440007560915656   to: 0.079903857594066666
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.081658921187259259   to: 0.080138424671511138
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.081875149963344371   to: 0.080370152211465207
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.082088727305955234   to: 0.080599074538102500
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.082299686281511852   to: 0.080825225648583410
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.082508059606186221   to: 0.081048639211674323
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.082713879646211186   to: 0.081269348566618757
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.082917178418371387   to: 0.081487386722248742
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.083117987590666728   to: 0.081702786356323762
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.083316338483138852   to: 0.081915579815086570
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.083512262068851692   to: 0.082125799113024769
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.083705788975017473   to: 0.082333475932827499
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.083896949484259881   to: 0.082538641625527598
i: 100, name:           module.conv10.weight  changing lr from: 0.084085773536006575   to: 0.082741327210819518
i: 101, name:             module.conv10.bias  changing lr from: 0.084272290728003352   to: 0.082941563377543381



# Switched to train mode...
Epoch: [25][  0/391]	Time  0.195 ( 0.195)	Data  0.149 ( 0.149)	Loss 9.8984e-01 (9.8984e-01)	Acc@1  75.78 ( 75.78)	Acc@5  92.19 ( 92.19)
Epoch: [25][ 10/391]	Time  0.042 ( 0.056)	Data  0.001 ( 0.014)	Loss 1.0399e+00 (1.0515e+00)	Acc@1  68.75 ( 69.82)	Acc@5  92.97 ( 92.33)
Epoch: [25][ 20/391]	Time  0.039 ( 0.049)	Data  0.001 ( 0.008)	Loss 8.6859e-01 (1.0500e+00)	Acc@1  73.44 ( 69.72)	Acc@5  93.75 ( 92.22)
Epoch: [25][ 30/391]	Time  0.043 ( 0.047)	Data  0.001 ( 0.006)	Loss 9.0050e-01 (1.0170e+00)	Acc@1  74.22 ( 70.14)	Acc@5  95.31 ( 92.74)
Epoch: [25][ 40/391]	Time  0.045 ( 0.046)	Data  0.001 ( 0.005)	Loss 9.0882e-01 (1.0109e+00)	Acc@1  70.31 ( 70.01)	Acc@5  96.09 ( 92.74)
Epoch: [25][ 50/391]	Time  0.040 ( 0.045)	Data  0.001 ( 0.004)	Loss 9.6517e-01 (9.9667e-01)	Acc@1  75.00 ( 70.57)	Acc@5  92.97 ( 92.97)
Epoch: [25][ 60/391]	Time  0.040 ( 0.045)	Data  0.001 ( 0.003)	Loss 8.9821e-01 (9.8835e-01)	Acc@1  70.31 ( 70.76)	Acc@5  95.31 ( 93.22)
Epoch: [25][ 70/391]	Time  0.038 ( 0.044)	Data  0.001 ( 0.003)	Loss 1.1114e+00 (9.9564e-01)	Acc@1  68.75 ( 70.68)	Acc@5  93.75 ( 93.20)
Epoch: [25][ 80/391]	Time  0.042 ( 0.044)	Data  0.001 ( 0.003)	Loss 9.0924e-01 (9.8575e-01)	Acc@1  73.44 ( 70.87)	Acc@5  92.19 ( 93.35)
Epoch: [25][ 90/391]	Time  0.042 ( 0.044)	Data  0.001 ( 0.003)	Loss 1.3481e+00 (9.9541e-01)	Acc@1  57.03 ( 70.58)	Acc@5  89.84 ( 93.19)
Epoch: [25][100/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.003)	Loss 1.0716e+00 (1.0017e+00)	Acc@1  71.88 ( 70.44)	Acc@5  91.41 ( 93.10)
Epoch: [25][110/391]	Time  0.044 ( 0.043)	Data  0.001 ( 0.002)	Loss 9.6387e-01 (1.0097e+00)	Acc@1  71.88 ( 70.26)	Acc@5  92.97 ( 93.03)
Epoch: [25][120/391]	Time  0.046 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.0144e+00 (1.0150e+00)	Acc@1  72.66 ( 70.13)	Acc@5  93.75 ( 93.02)
Epoch: [25][130/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.1671e+00 (1.0172e+00)	Acc@1  67.19 ( 69.97)	Acc@5  89.84 ( 93.05)
Epoch: [25][140/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.002)	Loss 8.8746e-01 (1.0177e+00)	Acc@1  73.44 ( 69.95)	Acc@5  94.53 ( 92.99)
Epoch: [25][150/391]	Time  0.045 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.2498e+00 (1.0203e+00)	Acc@1  64.06 ( 69.91)	Acc@5  89.06 ( 92.92)
Epoch: [25][160/391]	Time  0.039 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.2279e+00 (1.0213e+00)	Acc@1  64.06 ( 69.89)	Acc@5  90.62 ( 92.94)
Epoch: [25][170/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.0740e+00 (1.0267e+00)	Acc@1  65.62 ( 69.68)	Acc@5  94.53 ( 92.89)
Epoch: [25][180/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 8.7404e-01 (1.0302e+00)	Acc@1  68.75 ( 69.52)	Acc@5  96.09 ( 92.90)
Epoch: [25][190/391]	Time  0.044 ( 0.043)	Data  0.001 ( 0.002)	Loss 9.2227e-01 (1.0290e+00)	Acc@1  72.66 ( 69.51)	Acc@5  93.75 ( 92.92)
Epoch: [25][200/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.3856e+00 (1.0329e+00)	Acc@1  60.94 ( 69.39)	Acc@5  89.84 ( 92.84)
Epoch: [25][210/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.1423e+00 (1.0352e+00)	Acc@1  62.50 ( 69.31)	Acc@5  96.09 ( 92.85)
Epoch: [25][220/391]	Time  0.041 ( 0.042)	Data  0.002 ( 0.002)	Loss 9.5734e-01 (1.0366e+00)	Acc@1  67.19 ( 69.18)	Acc@5  94.53 ( 92.89)
Epoch: [25][230/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.2998e+00 (1.0387e+00)	Acc@1  64.06 ( 69.11)	Acc@5  88.28 ( 92.86)
Epoch: [25][240/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.0011e+00 (1.0399e+00)	Acc@1  64.06 ( 69.08)	Acc@5  92.97 ( 92.85)
Epoch: [25][250/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 9.7567e-01 (1.0431e+00)	Acc@1  69.53 ( 69.00)	Acc@5  92.19 ( 92.83)
Epoch: [25][260/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 8.4639e-01 (1.0446e+00)	Acc@1  71.09 ( 68.99)	Acc@5  97.66 ( 92.84)
Epoch: [25][270/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.002)	Loss 9.3909e-01 (1.0457e+00)	Acc@1  68.75 ( 68.95)	Acc@5  95.31 ( 92.85)
Epoch: [25][280/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 9.8657e-01 (1.0471e+00)	Acc@1  70.31 ( 68.93)	Acc@5  90.62 ( 92.79)
Epoch: [25][290/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.0731e+00 (1.0472e+00)	Acc@1  68.75 ( 68.88)	Acc@5  95.31 ( 92.77)
Epoch: [25][300/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.1553e+00 (1.0508e+00)	Acc@1  66.41 ( 68.79)	Acc@5  88.28 ( 92.74)
Epoch: [25][310/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.1504e+00 (1.0505e+00)	Acc@1  67.19 ( 68.85)	Acc@5  91.41 ( 92.75)
Epoch: [25][320/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.1357e+00 (1.0499e+00)	Acc@1  66.41 ( 68.90)	Acc@5  90.62 ( 92.75)
Epoch: [25][330/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.2039e+00 (1.0507e+00)	Acc@1  62.50 ( 68.87)	Acc@5  92.19 ( 92.74)
Epoch: [25][340/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.1570e+00 (1.0513e+00)	Acc@1  75.00 ( 68.86)	Acc@5  89.06 ( 92.74)
Epoch: [25][350/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.0652e+00 (1.0521e+00)	Acc@1  68.75 ( 68.87)	Acc@5  92.19 ( 92.70)
Epoch: [25][360/391]	Time  0.036 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.1844e+00 (1.0528e+00)	Acc@1  71.09 ( 68.87)	Acc@5  85.94 ( 92.68)
Epoch: [25][370/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.0480e+00 (1.0535e+00)	Acc@1  70.31 ( 68.85)	Acc@5  91.41 ( 92.67)
Epoch: [25][380/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.1172e+00 (1.0545e+00)	Acc@1  70.31 ( 68.81)	Acc@5  91.41 ( 92.67)
Epoch: [25][390/391]	Time  0.030 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.1305e+00 (1.0540e+00)	Acc@1  66.25 ( 68.82)	Acc@5  91.25 ( 92.67)
## e[25] optimizer.zero_grad (sum) time: 0.2872958183288574
## e[25]       loss.backward (sum) time: 4.144915342330933
## e[25]      optimizer.step (sum) time: 1.846431016921997
## epoch[25] training(only) time: 16.55014705657959
# Switched to evaluate mode...
Test: [  0/100]	Time  0.149 ( 0.149)	Loss 1.5191e+00 (1.5191e+00)	Acc@1  61.00 ( 61.00)	Acc@5  85.00 ( 85.00)
Test: [ 10/100]	Time  0.018 ( 0.034)	Loss 1.7975e+00 (1.6337e+00)	Acc@1  55.00 ( 58.64)	Acc@5  84.00 ( 85.55)
Test: [ 20/100]	Time  0.022 ( 0.028)	Loss 1.4152e+00 (1.6112e+00)	Acc@1  58.00 ( 58.57)	Acc@5  85.00 ( 85.67)
Test: [ 30/100]	Time  0.018 ( 0.026)	Loss 1.6509e+00 (1.6436e+00)	Acc@1  55.00 ( 57.48)	Acc@5  86.00 ( 85.52)
Test: [ 40/100]	Time  0.022 ( 0.025)	Loss 1.6270e+00 (1.6426e+00)	Acc@1  63.00 ( 57.49)	Acc@5  84.00 ( 85.63)
Test: [ 50/100]	Time  0.024 ( 0.024)	Loss 1.5188e+00 (1.6548e+00)	Acc@1  63.00 ( 57.33)	Acc@5  83.00 ( 85.02)
Test: [ 60/100]	Time  0.021 ( 0.024)	Loss 1.5621e+00 (1.6421e+00)	Acc@1  53.00 ( 57.38)	Acc@5  89.00 ( 85.11)
Test: [ 70/100]	Time  0.024 ( 0.024)	Loss 1.6026e+00 (1.6451e+00)	Acc@1  59.00 ( 57.48)	Acc@5  88.00 ( 85.24)
Test: [ 80/100]	Time  0.024 ( 0.024)	Loss 1.6620e+00 (1.6444e+00)	Acc@1  58.00 ( 57.72)	Acc@5  80.00 ( 85.14)
Test: [ 90/100]	Time  0.024 ( 0.023)	Loss 1.8770e+00 (1.6298e+00)	Acc@1  54.00 ( 58.24)	Acc@5  82.00 ( 85.30)
 * Acc@1 58.460 Acc@5 85.420
### epoch[25] execution time: 18.94159698486328
EPOCH 26
i:   0, name:           module.stem.0.weight  changing lr from: 0.044338527502719036   to: 0.040978162618878995
i:   1, name:             module.stem.0.bias  changing lr from: 0.044957037501483943   to: 0.041614336945434281
i:   2, name:           module.stem.1.weight  changing lr from: 0.045570454475437429   to: 0.042245876082637419
i:   3, name:             module.stem.1.bias  changing lr from: 0.046178732364548405   to: 0.042872707297176293
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.046781829947759125   to: 0.043494763633682855
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.047379710632641632   to: 0.044111983678748128
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.047972342252257473   to: 0.044724311332524525
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.048559696869033553   to: 0.045331695587745455
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.049141750585467533   to: 0.045934090315990786
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.049718483361478209   to: 0.046531454061026573
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.050289878838217797   to: 0.047123749839046707
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.050855924168165485   to: 0.047710944945644596
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.051416609851323208   to: 0.048293010769343440
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.051971929577338011   to: 0.048869922611514752
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.052521880073377138   to: 0.049441659512515765
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.053066460957585798   to: 0.050008204083878176
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.053605674597959264   to: 0.050569542346381863
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.054139525976465687   to: 0.051125663573850205
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.054668022558257361   to: 0.051676560142504463
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.055191174165813053   to: 0.052222227385718314
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.055708992857856243   to: 0.052762663454015146
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.056221492812898066   to: 0.053297869180153813
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.056728690217256787   to: 0.053827847949151297
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.057230603157409535   to: 0.054352605573093328
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.057727251516534961   to: 0.054872150170586997
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.058218656875109270   to: 0.055386492050712333
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.058704842415421211   to: 0.055895643601333013
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.059185832829875731   to: 0.056399619181629251
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.059661654232958529   to: 0.056898435018718732
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.060132334076737494   to: 0.057392109108235417
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.060597901069780746   to: 0.057880661118737790
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.061058385099373828   to: 0.058364112299822912
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.061513817156921960   to: 0.058842485393824077
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.061964229266426765   to: 0.059315804550974176
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.062409654415929716   to: 0.059784095247919312
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.062850126491817926   to: 0.060247384209470567
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.063285680215891121   to: 0.060705699333484520
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.063716351085091077   to: 0.061159069618766472
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.064142175313798455   to: 0.061607525095893047
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.064563189778604577   to: 0.062051096760853623
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.064979431965468321   to: 0.062489816511413387
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.065390939919171776   to: 0.062923717086103087
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.065797752194989872   to: 0.063352832005743459
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.066199907812493450   to: 0.063777195517415550
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.066597446211406203   to: 0.064196842540789806
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.066990407209439565   to: 0.064611808616730451
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.067378830962031830   to: 0.065022129858093469
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.067762757923920017   to: 0.065427842902639685
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.068142228812475142   to: 0.065828984867986037
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.068517284572734927   to: 0.066225593308521388
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.068887966344068560   to: 0.066617706174215127
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.069254315428411761   to: 0.067005361771248856
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.069616373260011646   to: 0.067388598724404586
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.069974181376623368   to: 0.067767455941143667
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.070327781392102162   to: 0.068141972577314289
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.070677214970336563   to: 0.068512188004426045
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.071022523800470611   to: 0.068878141778433391
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.071363749573364069   to: 0.069239873609970512
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.071700933959242361   to: 0.069597423335983094
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.072034118586488546   to: 0.069950830892703403
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.072363345021532494   to: 0.070300136289917908
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.072688654749792955   to: 0.070645379586477319
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.073010089157630589   to: 0.070986600867001273
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.073327689515270827   to: 0.071323840219731607
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.073641496960657735   to: 0.071657137715489302
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.073951552484200697   to: 0.071986533387692106
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.074257896914377328   to: 0.072312067213391160
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.074560570904157797   to: 0.072633779095286385
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.074859614918216272   to: 0.072951708844682064
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.075155069220896986   to: 0.073265896165344999
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.075446973864903621   to: 0.073576380638229341
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.075735368680681411   to: 0.073883201707033094
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.076020293266462924   to: 0.074186398664553108
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.076301786978949446   to: 0.074486010639805672
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.076579888924601061   to: 0.074782076585882179
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.076854637951508958   to: 0.075074635268509174
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.077126072641825361   to: 0.075363725255284231
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.077394231304726627   to: 0.075649384905559572
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.077659151969886653   to: 0.075931652360946553
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.077920872381437897   to: 0.076210565536415198
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.078179429992398783   to: 0.076486162111963560
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.078434861959546742   to: 0.076758479524833279
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.078687205138717020   to: 0.077027554962247807
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.078936496080508206   to: 0.077293425354651141
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.079182771026375998   to: 0.077556127369425729
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.079426065905097737   to: 0.077815697405068718
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.079666416329590498   to: 0.078072171585806691
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.079903857594066666   to: 0.078325585756629901
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.080138424671511138   to: 0.078575975478727411
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.080370152211465207   to: 0.078823376025305425
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.080599074538102500   to: 0.079067822377772046
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.080825225648583410   to: 0.079309349222271619
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.081048639211674323   to: 0.079547990946553376
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.081269348566618757   to: 0.079783781637158754
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.081487386722248742   to: 0.080016755076913221
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.081702786356323762   to: 0.080246944742708284
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.081915579815086570   to: 0.080474383803560479
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.082125799113024769   to: 0.080699105118934078
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.082333475932827499   to: 0.080921141237315447
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.082538641625527598   to: 0.081140524395026697
i: 100, name:           module.conv10.weight  changing lr from: 0.082741327210819518   to: 0.081357286515267482
i: 101, name:             module.conv10.bias  changing lr from: 0.082941563377543381   to: 0.081571459207373770



# Switched to train mode...
Epoch: [26][  0/391]	Time  0.199 ( 0.199)	Data  0.149 ( 0.149)	Loss 9.5717e-01 (9.5717e-01)	Acc@1  73.44 ( 73.44)	Acc@5  89.06 ( 89.06)
Epoch: [26][ 10/391]	Time  0.039 ( 0.056)	Data  0.001 ( 0.014)	Loss 1.2664e+00 (1.0265e+00)	Acc@1  65.62 ( 70.24)	Acc@5  89.06 ( 92.76)
Epoch: [26][ 20/391]	Time  0.040 ( 0.050)	Data  0.001 ( 0.008)	Loss 8.1723e-01 (1.0092e+00)	Acc@1  69.53 ( 70.65)	Acc@5  99.22 ( 93.12)
Epoch: [26][ 30/391]	Time  0.042 ( 0.047)	Data  0.001 ( 0.006)	Loss 1.2989e+00 (9.9837e-01)	Acc@1  63.28 ( 70.94)	Acc@5  84.38 ( 92.99)
Epoch: [26][ 40/391]	Time  0.042 ( 0.046)	Data  0.001 ( 0.005)	Loss 8.7181e-01 (1.0078e+00)	Acc@1  73.44 ( 70.29)	Acc@5  96.09 ( 92.85)
Epoch: [26][ 50/391]	Time  0.042 ( 0.045)	Data  0.001 ( 0.004)	Loss 8.5202e-01 (1.0030e+00)	Acc@1  75.00 ( 70.19)	Acc@5  93.75 ( 92.91)
Epoch: [26][ 60/391]	Time  0.043 ( 0.044)	Data  0.001 ( 0.003)	Loss 8.6619e-01 (9.9980e-01)	Acc@1  70.31 ( 70.38)	Acc@5  96.88 ( 93.05)
Epoch: [26][ 70/391]	Time  0.040 ( 0.044)	Data  0.002 ( 0.003)	Loss 8.6223e-01 (9.9480e-01)	Acc@1  74.22 ( 70.57)	Acc@5  93.75 ( 93.05)
Epoch: [26][ 80/391]	Time  0.045 ( 0.044)	Data  0.001 ( 0.003)	Loss 9.7360e-01 (9.9853e-01)	Acc@1  74.22 ( 70.64)	Acc@5  92.19 ( 93.00)
Epoch: [26][ 90/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.003)	Loss 1.0435e+00 (1.0044e+00)	Acc@1  70.31 ( 70.57)	Acc@5  92.19 ( 92.94)
Epoch: [26][100/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.003)	Loss 1.0986e+00 (1.0048e+00)	Acc@1  65.62 ( 70.46)	Acc@5  92.19 ( 92.98)
Epoch: [26][110/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.1440e+00 (1.0062e+00)	Acc@1  67.19 ( 70.45)	Acc@5  88.28 ( 92.92)
Epoch: [26][120/391]	Time  0.046 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.2043e+00 (1.0065e+00)	Acc@1  67.97 ( 70.50)	Acc@5  89.84 ( 92.90)
Epoch: [26][130/391]	Time  0.045 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.5020e+00 (1.0118e+00)	Acc@1  61.72 ( 70.28)	Acc@5  87.50 ( 92.92)
Epoch: [26][140/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.2280e+00 (1.0092e+00)	Acc@1  67.97 ( 70.30)	Acc@5  89.06 ( 92.95)
Epoch: [26][150/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 9.6756e-01 (1.0062e+00)	Acc@1  66.41 ( 70.23)	Acc@5  94.53 ( 93.01)
Epoch: [26][160/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.0536e+00 (1.0074e+00)	Acc@1  65.62 ( 70.11)	Acc@5  89.06 ( 93.01)
Epoch: [26][170/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 9.8671e-01 (1.0086e+00)	Acc@1  74.22 ( 70.16)	Acc@5  94.53 ( 93.03)
Epoch: [26][180/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.0337e+00 (1.0068e+00)	Acc@1  66.41 ( 70.14)	Acc@5  95.31 ( 93.10)
Epoch: [26][190/391]	Time  0.039 ( 0.043)	Data  0.002 ( 0.002)	Loss 1.1239e+00 (1.0095e+00)	Acc@1  69.53 ( 70.09)	Acc@5  92.19 ( 93.12)
Epoch: [26][200/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 9.8083e-01 (1.0102e+00)	Acc@1  69.53 ( 70.09)	Acc@5  96.09 ( 93.17)
Epoch: [26][210/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.1248e+00 (1.0109e+00)	Acc@1  66.41 ( 70.05)	Acc@5  91.41 ( 93.15)
Epoch: [26][220/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 9.6820e-01 (1.0101e+00)	Acc@1  67.97 ( 70.04)	Acc@5  94.53 ( 93.15)
Epoch: [26][230/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.0207e+00 (1.0135e+00)	Acc@1  68.75 ( 69.93)	Acc@5  95.31 ( 93.13)
Epoch: [26][240/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.2146e+00 (1.0167e+00)	Acc@1  65.62 ( 69.83)	Acc@5  87.50 ( 93.09)
Epoch: [26][250/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 9.6486e-01 (1.0177e+00)	Acc@1  71.88 ( 69.81)	Acc@5  94.53 ( 93.06)
Epoch: [26][260/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 9.4034e-01 (1.0175e+00)	Acc@1  71.88 ( 69.81)	Acc@5  94.53 ( 93.08)
Epoch: [26][270/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.4686e+00 (1.0195e+00)	Acc@1  57.03 ( 69.77)	Acc@5  89.84 ( 93.08)
Epoch: [26][280/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.1093e+00 (1.0215e+00)	Acc@1  69.53 ( 69.73)	Acc@5  91.41 ( 93.06)
Epoch: [26][290/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.2293e+00 (1.0233e+00)	Acc@1  65.62 ( 69.70)	Acc@5  95.31 ( 93.07)
Epoch: [26][300/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.0456e+00 (1.0240e+00)	Acc@1  72.66 ( 69.73)	Acc@5  94.53 ( 93.04)
Epoch: [26][310/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.1229e+00 (1.0248e+00)	Acc@1  69.53 ( 69.70)	Acc@5  92.19 ( 93.03)
Epoch: [26][320/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.0623e+00 (1.0256e+00)	Acc@1  71.09 ( 69.69)	Acc@5  92.97 ( 93.02)
Epoch: [26][330/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.0054e+00 (1.0257e+00)	Acc@1  73.44 ( 69.71)	Acc@5  93.75 ( 93.02)
Epoch: [26][340/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.1112e+00 (1.0282e+00)	Acc@1  64.06 ( 69.65)	Acc@5  89.84 ( 92.94)
Epoch: [26][350/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.0413e+00 (1.0283e+00)	Acc@1  64.06 ( 69.63)	Acc@5  94.53 ( 92.94)
Epoch: [26][360/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.1261e+00 (1.0300e+00)	Acc@1  66.41 ( 69.61)	Acc@5  92.97 ( 92.94)
Epoch: [26][370/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.0804e+00 (1.0310e+00)	Acc@1  66.41 ( 69.56)	Acc@5  90.62 ( 92.94)
Epoch: [26][380/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.0019e+00 (1.0309e+00)	Acc@1  71.88 ( 69.57)	Acc@5  93.75 ( 92.94)
Epoch: [26][390/391]	Time  0.027 ( 0.042)	Data  0.001 ( 0.001)	Loss 8.6628e-01 (1.0326e+00)	Acc@1  70.00 ( 69.53)	Acc@5  93.75 ( 92.91)
## e[26] optimizer.zero_grad (sum) time: 0.2845296859741211
## e[26]       loss.backward (sum) time: 4.144999027252197
## e[26]      optimizer.step (sum) time: 1.860412359237671
## epoch[26] training(only) time: 16.522565364837646
# Switched to evaluate mode...
Test: [  0/100]	Time  0.156 ( 0.156)	Loss 1.7406e+00 (1.7406e+00)	Acc@1  60.00 ( 60.00)	Acc@5  84.00 ( 84.00)
Test: [ 10/100]	Time  0.024 ( 0.034)	Loss 1.6691e+00 (1.7352e+00)	Acc@1  55.00 ( 57.09)	Acc@5  89.00 ( 85.00)
Test: [ 20/100]	Time  0.024 ( 0.029)	Loss 1.5866e+00 (1.6890e+00)	Acc@1  59.00 ( 58.05)	Acc@5  89.00 ( 85.24)
Test: [ 30/100]	Time  0.023 ( 0.027)	Loss 1.5522e+00 (1.7002e+00)	Acc@1  61.00 ( 57.77)	Acc@5  91.00 ( 85.26)
Test: [ 40/100]	Time  0.023 ( 0.026)	Loss 1.6702e+00 (1.6889e+00)	Acc@1  62.00 ( 57.66)	Acc@5  85.00 ( 85.34)
Test: [ 50/100]	Time  0.024 ( 0.025)	Loss 1.7956e+00 (1.6940e+00)	Acc@1  59.00 ( 57.37)	Acc@5  81.00 ( 85.04)
Test: [ 60/100]	Time  0.024 ( 0.024)	Loss 1.6611e+00 (1.6768e+00)	Acc@1  53.00 ( 57.49)	Acc@5  85.00 ( 85.33)
Test: [ 70/100]	Time  0.025 ( 0.024)	Loss 1.7649e+00 (1.6810e+00)	Acc@1  54.00 ( 57.44)	Acc@5  87.00 ( 85.31)
Test: [ 80/100]	Time  0.030 ( 0.024)	Loss 1.7179e+00 (1.6851e+00)	Acc@1  58.00 ( 57.35)	Acc@5  86.00 ( 85.26)
Test: [ 90/100]	Time  0.019 ( 0.023)	Loss 2.0159e+00 (1.6719e+00)	Acc@1  51.00 ( 57.51)	Acc@5  77.00 ( 85.33)
 * Acc@1 57.740 Acc@5 85.370
### epoch[26] execution time: 18.90210247039795
EPOCH 27
i:   0, name:           module.stem.0.weight  changing lr from: 0.040978162618878995   to: 0.037664362126255110
i:   1, name:             module.stem.0.bias  changing lr from: 0.041614336945434281   to: 0.038314609334661631
i:   2, name:           module.stem.1.weight  changing lr from: 0.042245876082637419   to: 0.038960796314180687
i:   3, name:             module.stem.1.bias  changing lr from: 0.042872707297176293   to: 0.039602820699736502
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.043494763633682855   to: 0.040240586889922769
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.044111983678748128   to: 0.040874005786416721
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.044724311332524525   to: 0.041502994541199580
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.045331695587745455   to: 0.042127476311442681
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.045934090315990786   to: 0.042747380021914083
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.046531454061026573   to: 0.043362640134757449
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.047123749839046707   to: 0.043973196426491591
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.047710944945644596   to: 0.044578993772077219
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.048293010769343440   to: 0.045179981935895119
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.048869922611514752   to: 0.045776115369479814
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.049441659512515765   to: 0.046367353015850626
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.050008204083878176   to: 0.046953658120283265
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.050569542346381863   to: 0.047534998047363719
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.051125663573850205   to: 0.048111344104167952
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.051676560142504463   to: 0.048682671369410659
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.052222227385718314   to: 0.049248958528407799
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.052762663454015146   to: 0.049810187713699001
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.053297869180153813   to: 0.050366344351177240
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.053827847949151297   to: 0.050917417011574928
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.054352605573093328   to: 0.051463397267157644
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.054872150170586997   to: 0.052004279553478611
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.055386492050712333   to: 0.052540061036049204
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.055895643601333013   to: 0.053070741481783257
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.056399619181629251   to: 0.053596323135075424
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.056898435018718732   to: 0.054116810598375899
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.057392109108235417   to: 0.054632210717127122
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.057880661118737790   to: 0.055142532468929806
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.058364112299822912   to: 0.055647786856809690
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.058842485393824077   to: 0.056147986806457474
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.059315804550974176   to: 0.056643147067318655
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.059784095247919312   to: 0.057133284117411913
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.060247384209470567   to: 0.057618416071757828
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.060705699333484520   to: 0.058098562594302419
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.061159069618766472   to: 0.058573744813222840
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.061607525095893047   to: 0.059043985239505430
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.062051096760853623   to: 0.059509307688688839
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.062489816511413387   to: 0.059969737205668221
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.062923717086103087   to: 0.060425299992458652
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.063352832005743459   to: 0.060876023338818946
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.063777195517415550   to: 0.061321935555639931
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.064196842540789806   to: 0.061763065911003334
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.064611808616730451   to: 0.062199444568820567
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.065022129858093469   to: 0.062631102529962929
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.065427842902639685   to: 0.063058071575797681
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.065828984867986037   to: 0.063480384214046323
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.066225593308521388   to: 0.063898073626884419
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.066617706174215127   to: 0.064311173621204351
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.067005361771248856   to: 0.064719718580965105
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.067388598724404586   to: 0.065123743421554761
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.067767455941143667   to: 0.065523283546094782
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.068141972577314289   to: 0.065918374803616148
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.068512188004426045   to: 0.066309053449040145
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.068878141778433391   to: 0.066695356104899239
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.069239873609970512   to: 0.067077319724734102
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.069597423335983094   to: 0.067454981558106461
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.069950830892703403   to: 0.067828379117168144
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.070300136289917908   to: 0.068197550144729405
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.070645379586477319   to: 0.068562532583770971
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.070986600867001273   to: 0.068923364548346230
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.071323840219731607   to: 0.069280084295822039
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.071657137715489302   to: 0.069632730200407542
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.071986533387692106   to: 0.069981340727923128
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.072312067213391160   to: 0.070325954411762176
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.072633779095286385   to: 0.070666609830000768
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.072951708844682064   to: 0.071003345583611391
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.073265896165344999   to: 0.071336200275738351
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.073576380638229341   to: 0.071665212491994340
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.073883201707033094   to: 0.071990420781738437
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.074186398664553108   to: 0.072311863640297749
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.074486010639805672   to: 0.072629579492095614
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.074782076585882179   to: 0.072943606674651426
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.075074635268509174   to: 0.073253983423417268
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.075363725255284231   to: 0.073560747857418604
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.075649384905559572   to: 0.073863937965667190
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.075931652360946553   to: 0.074163591594315251
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.076210565536415198   to: 0.074459746434521606
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.076486162111963560   to: 0.074752440011000496
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.076758479524833279   to: 0.075041709671226323
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.077027554962247807   to: 0.075327592575266986
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.077293425354651141   to: 0.075610125686220608
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.077556127369425729   to: 0.075889345761230742
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.077815697405068718   to: 0.076165289343056261
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.078072171585806691   to: 0.076437992752172793
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.078325585756629901   to: 0.076707492079384057
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.078575975478727411   to: 0.076973823178921152
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.078823376025305425   to: 0.077237021662009631
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.079067822377772046   to: 0.077497122890884673
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.079309349222271619   to: 0.077754161973234731
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.079547990946553376   to: 0.078008173757056168
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.079783781637158754   to: 0.078259192825900284
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.080016755076913221   to: 0.078507253494496526
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.080246944742708284   to: 0.078752389804734868
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.080474383803560479   to: 0.078994635521992096
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.080699105118934078   to: 0.079234024131786582
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.080921141237315447   to: 0.079470588836746792
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.081140524395026697   to: 0.079704362553879901
i: 100, name:           module.conv10.weight  changing lr from: 0.081357286515267482   to: 0.079935377912126751
i: 101, name:             module.conv10.bias  changing lr from: 0.081571459207373770   to: 0.080163667250190085



# Switched to train mode...
Epoch: [27][  0/391]	Time  0.196 ( 0.196)	Data  0.148 ( 0.148)	Loss 8.4920e-01 (8.4920e-01)	Acc@1  75.00 ( 75.00)	Acc@5  94.53 ( 94.53)
Epoch: [27][ 10/391]	Time  0.040 ( 0.056)	Data  0.001 ( 0.014)	Loss 1.0698e+00 (9.2738e-01)	Acc@1  72.66 ( 72.44)	Acc@5  89.06 ( 93.89)
Epoch: [27][ 20/391]	Time  0.036 ( 0.048)	Data  0.001 ( 0.008)	Loss 9.0211e-01 (9.4869e-01)	Acc@1  67.19 ( 71.32)	Acc@5  95.31 ( 93.97)
Epoch: [27][ 30/391]	Time  0.043 ( 0.046)	Data  0.001 ( 0.006)	Loss 9.1490e-01 (9.6252e-01)	Acc@1  69.53 ( 70.97)	Acc@5  95.31 ( 93.75)
Epoch: [27][ 40/391]	Time  0.041 ( 0.045)	Data  0.001 ( 0.005)	Loss 9.6388e-01 (9.4699e-01)	Acc@1  67.19 ( 71.19)	Acc@5  94.53 ( 94.09)
Epoch: [27][ 50/391]	Time  0.042 ( 0.044)	Data  0.001 ( 0.004)	Loss 1.0131e+00 (9.5352e-01)	Acc@1  74.22 ( 71.40)	Acc@5  91.41 ( 93.95)
Epoch: [27][ 60/391]	Time  0.042 ( 0.044)	Data  0.001 ( 0.003)	Loss 8.8492e-01 (9.5480e-01)	Acc@1  71.88 ( 71.34)	Acc@5  93.75 ( 93.88)
Epoch: [27][ 70/391]	Time  0.043 ( 0.044)	Data  0.001 ( 0.003)	Loss 7.9251e-01 (9.5581e-01)	Acc@1  73.44 ( 71.51)	Acc@5  96.09 ( 93.69)
Epoch: [27][ 80/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.003)	Loss 1.1406e+00 (9.6317e-01)	Acc@1  68.75 ( 71.46)	Acc@5  93.75 ( 93.54)
Epoch: [27][ 90/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.003)	Loss 9.2900e-01 (9.6289e-01)	Acc@1  71.88 ( 71.35)	Acc@5  96.88 ( 93.54)
Epoch: [27][100/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.002)	Loss 9.1556e-01 (9.6503e-01)	Acc@1  73.44 ( 71.32)	Acc@5  96.09 ( 93.49)
Epoch: [27][110/391]	Time  0.044 ( 0.043)	Data  0.001 ( 0.002)	Loss 9.0969e-01 (9.6283e-01)	Acc@1  71.09 ( 71.42)	Acc@5  94.53 ( 93.50)
Epoch: [27][120/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 9.1598e-01 (9.6507e-01)	Acc@1  71.09 ( 71.41)	Acc@5  96.09 ( 93.47)
Epoch: [27][130/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.0281e+00 (9.7176e-01)	Acc@1  66.41 ( 71.24)	Acc@5  91.41 ( 93.40)
Epoch: [27][140/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 8.4712e-01 (9.7299e-01)	Acc@1  73.44 ( 71.21)	Acc@5  96.88 ( 93.38)
Epoch: [27][150/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.002)	Loss 9.3112e-01 (9.7907e-01)	Acc@1  72.66 ( 70.99)	Acc@5  92.97 ( 93.39)
Epoch: [27][160/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.0148e+00 (9.8394e-01)	Acc@1  71.88 ( 70.83)	Acc@5  89.84 ( 93.28)
Epoch: [27][170/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.002)	Loss 7.7853e-01 (9.8453e-01)	Acc@1  77.34 ( 70.79)	Acc@5  93.75 ( 93.31)
Epoch: [27][180/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.1589e+00 (9.8655e-01)	Acc@1  64.84 ( 70.73)	Acc@5  92.19 ( 93.29)
Epoch: [27][190/391]	Time  0.037 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.0947e+00 (9.8720e-01)	Acc@1  64.84 ( 70.66)	Acc@5  92.97 ( 93.30)
Epoch: [27][200/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.1411e+00 (9.8940e-01)	Acc@1  69.53 ( 70.65)	Acc@5  91.41 ( 93.28)
Epoch: [27][210/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 9.0595e-01 (9.9012e-01)	Acc@1  69.53 ( 70.63)	Acc@5  96.09 ( 93.31)
Epoch: [27][220/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.0832e+00 (9.9063e-01)	Acc@1  72.66 ( 70.62)	Acc@5  91.41 ( 93.29)
Epoch: [27][230/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.2147e+00 (9.9467e-01)	Acc@1  67.97 ( 70.47)	Acc@5  91.41 ( 93.24)
Epoch: [27][240/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 7.7969e-01 (9.9272e-01)	Acc@1  75.00 ( 70.49)	Acc@5  93.75 ( 93.25)
Epoch: [27][250/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 8.9175e-01 (9.9244e-01)	Acc@1  73.44 ( 70.52)	Acc@5  95.31 ( 93.24)
Epoch: [27][260/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 9.6916e-01 (9.9317e-01)	Acc@1  70.31 ( 70.52)	Acc@5  92.97 ( 93.24)
Epoch: [27][270/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.0798e+00 (9.9427e-01)	Acc@1  67.19 ( 70.48)	Acc@5  93.75 ( 93.23)
Epoch: [27][280/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 8.4024e-01 (9.9585e-01)	Acc@1  75.78 ( 70.46)	Acc@5  94.53 ( 93.21)
Epoch: [27][290/391]	Time  0.046 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.0623e+00 (9.9944e-01)	Acc@1  69.53 ( 70.34)	Acc@5  90.62 ( 93.15)
Epoch: [27][300/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.1289e+00 (1.0010e+00)	Acc@1  60.94 ( 70.26)	Acc@5  95.31 ( 93.17)
Epoch: [27][310/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.0334e+00 (1.0010e+00)	Acc@1  70.31 ( 70.24)	Acc@5  92.19 ( 93.17)
Epoch: [27][320/391]	Time  0.045 ( 0.042)	Data  0.001 ( 0.001)	Loss 9.6066e-01 (1.0034e+00)	Acc@1  73.44 ( 70.22)	Acc@5  92.19 ( 93.14)
Epoch: [27][330/391]	Time  0.045 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.1272e+00 (1.0054e+00)	Acc@1  64.84 ( 70.18)	Acc@5  92.97 ( 93.12)
Epoch: [27][340/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.1600e+00 (1.0061e+00)	Acc@1  70.31 ( 70.16)	Acc@5  91.41 ( 93.09)
Epoch: [27][350/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.0995e+00 (1.0064e+00)	Acc@1  64.84 ( 70.13)	Acc@5  96.88 ( 93.11)
Epoch: [27][360/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 8.5165e-01 (1.0052e+00)	Acc@1  71.09 ( 70.16)	Acc@5  95.31 ( 93.13)
Epoch: [27][370/391]	Time  0.046 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.1458e+00 (1.0069e+00)	Acc@1  67.19 ( 70.13)	Acc@5  92.19 ( 93.10)
Epoch: [27][380/391]	Time  0.046 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.1149e+00 (1.0086e+00)	Acc@1  63.28 ( 70.07)	Acc@5  96.09 ( 93.09)
Epoch: [27][390/391]	Time  0.034 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.1410e+00 (1.0088e+00)	Acc@1  63.75 ( 70.08)	Acc@5  91.25 ( 93.10)
## e[27] optimizer.zero_grad (sum) time: 0.2842891216278076
## e[27]       loss.backward (sum) time: 4.130996465682983
## e[27]      optimizer.step (sum) time: 1.860490322113037
## epoch[27] training(only) time: 16.476764917373657
# Switched to evaluate mode...
Test: [  0/100]	Time  0.157 ( 0.157)	Loss 1.3269e+00 (1.3269e+00)	Acc@1  63.00 ( 63.00)	Acc@5  89.00 ( 89.00)
Test: [ 10/100]	Time  0.024 ( 0.035)	Loss 1.6406e+00 (1.5706e+00)	Acc@1  63.00 ( 61.27)	Acc@5  89.00 ( 86.18)
Test: [ 20/100]	Time  0.024 ( 0.029)	Loss 1.2514e+00 (1.5165e+00)	Acc@1  59.00 ( 60.86)	Acc@5  89.00 ( 86.95)
Test: [ 30/100]	Time  0.019 ( 0.026)	Loss 1.5876e+00 (1.5329e+00)	Acc@1  57.00 ( 60.39)	Acc@5  86.00 ( 86.23)
Test: [ 40/100]	Time  0.019 ( 0.024)	Loss 1.6135e+00 (1.5357e+00)	Acc@1  60.00 ( 60.17)	Acc@5  84.00 ( 86.20)
Test: [ 50/100]	Time  0.023 ( 0.024)	Loss 1.5841e+00 (1.5480e+00)	Acc@1  59.00 ( 60.06)	Acc@5  86.00 ( 86.04)
Test: [ 60/100]	Time  0.022 ( 0.023)	Loss 1.5280e+00 (1.5371e+00)	Acc@1  61.00 ( 60.38)	Acc@5  85.00 ( 86.18)
Test: [ 70/100]	Time  0.018 ( 0.023)	Loss 1.3672e+00 (1.5379e+00)	Acc@1  64.00 ( 60.51)	Acc@5  91.00 ( 86.18)
Test: [ 80/100]	Time  0.023 ( 0.023)	Loss 1.7578e+00 (1.5353e+00)	Acc@1  57.00 ( 60.46)	Acc@5  80.00 ( 86.32)
Test: [ 90/100]	Time  0.019 ( 0.023)	Loss 1.8868e+00 (1.5313e+00)	Acc@1  52.00 ( 60.42)	Acc@5  84.00 ( 86.33)
 * Acc@1 60.630 Acc@5 86.570
### epoch[27] execution time: 18.79166316986084
EPOCH 28
i:   0, name:           module.stem.0.weight  changing lr from: 0.037664362126255110   to: 0.034412522912332426
i:   1, name:             module.stem.0.bias  changing lr from: 0.038314609334661631   to: 0.035072962713554805
i:   2, name:           module.stem.1.weight  changing lr from: 0.038960796314180687   to: 0.035730037456447504
i:   3, name:             module.stem.1.bias  changing lr from: 0.039602820699736502   to: 0.036383612309236701
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.040240586889922769   to: 0.037033560223358498
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.040874005786416721   to: 0.037679761650102686
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.041502994541199580   to: 0.038322104265076463
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.042127476311442681   to: 0.038960482700391284
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.042747380021914083   to: 0.039594798284466097
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.043362640134757449   to: 0.040224958789334866
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.043973196426491591   to: 0.040850878185338703
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.044578993772077219   to: 0.041472476403078468
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.045179981935895119   to: 0.042089679102498230
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.045776115369479814   to: 0.042702417448967127
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.046367353015850626   to: 0.043310627896222649
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.046953658120283265   to: 0.043914251976037065
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.047534998047363719   to: 0.044513236094465301
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.048111344104167952   to: 0.045107531334532235
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.048682671369410659   to: 0.045697093265215143
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.049248958528407799   to: 0.046281881756577214
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.049810187713699001   to: 0.046861860800906957
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.050366344351177240   to: 0.047436998339719205
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.050917417011574928   to: 0.048007266096472934
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.051463397267157644   to: 0.048572639414862222
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.052004279553478611   to: 0.049133097102537771
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.052540061036049204   to: 0.049688621280116758
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.053070741481783257   to: 0.050239197235340996
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.053596323135075424   to: 0.050784813282244490
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.054116810598375899   to: 0.051325460625193157
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.054632210717127122   to: 0.051861133227661296
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.055142532468929806   to: 0.052391827685611604
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.055647786856809690   to: 0.052917543105347464
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.056147986806457474   to: 0.053438280985708346
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.056643147067318655   to: 0.053954045104481443
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.057133284117411913   to: 0.054464841408905257
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.057618416071757828   to: 0.054970677910142707
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.058098562594302419   to: 0.055471564581604654
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.058573744813222840   to: 0.055967513261005908
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.059043985239505430   to: 0.056458537556039870
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.059509307688688839   to: 0.056944652753558971
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.059969737205668221   to: 0.057425875732151910
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.060425299992458652   to: 0.057902224878010271
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.060876023338818946   to: 0.058373720003980036
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.061321935555639931   to: 0.058840382271696516
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.061763065911003334   to: 0.059302234116702546
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.062199444568820567   to: 0.059759299176453839
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.062631102529962929   to: 0.060211602221116448
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.063058071575797681   to: 0.060659169087064937
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.063480384214046323   to: 0.061102026612991446
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.063898073626884419   to: 0.061540202578538844
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.064311173621204351   to: 0.061973725645373103
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.064719718580965105   to: 0.062402625300612781
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.065123743421554761   to: 0.062826931802535457
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.065523283546094782   to: 0.063246676128483614
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.065918374803616148   to: 0.063661889924894355
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.066309053449040145   to: 0.064072605459379470
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.066695356104899239   to: 0.064478855574785277
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.067077319724734102   to: 0.064880673645162687
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.067454981558106461   to: 0.065278093533580966
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.067828379117168144   to: 0.065671149551719710
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.068197550144729405   to: 0.066059876421176930
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.068562532583770971   to: 0.066444309236431465
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.068923364548346230   to: 0.066824483429401033
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.069280084295822039   to: 0.067200434735538370
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.069632730200407542   to: 0.067572199161410440
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.069981340727923128   to: 0.067939812953706505
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.070325954411762176   to: 0.068303312569623284
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.070666609830000768   to: 0.068662734648576848
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.071003345583611391   to: 0.069018115985192682
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.071336200275738351   to: 0.069369493503526405
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.071665212491994340   to: 0.069716904232469956
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.071990420781738437   to: 0.070060385282298937
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.072311863640297749   to: 0.070399973822318551
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.072629579492095614   to: 0.070735707059566819
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.072943606674651426   to: 0.071067622218535395
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.073253983423417268   to: 0.071395756521869275
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.073560747857418604   to: 0.071720147172008392
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.073863937965667190   to: 0.072040831333734845
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.074163591594315251   to: 0.072357846117591329
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.074459746434521606   to: 0.072671228564137144
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.074752440011000496   to: 0.072981015629009091
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.075041709671226323   to: 0.073287244168756538
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.075327592575266986   to: 0.073589950927419823
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.075610125686220608   to: 0.073889172523823307
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.075889345761230742   to: 0.074184945439554714
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.076165289343056261   to: 0.074477306007603702
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.076437992752172793   to: 0.074766290401633281
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.076707492079384057   to: 0.075051934625859199
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.076973823178921152   to: 0.075334274505512319
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.077237021662009631   to: 0.075613345677861044
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.077497122890884673   to: 0.075889183583770836
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.077754161973234731   to: 0.076161823459778774
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.078008173757056168   to: 0.076431300330662547
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.078259192825900284   to: 0.076697649002483131
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.078507253494496526   to: 0.076960904056081691
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.078752389804734868   to: 0.077221099841011873
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.078994635521992096   to: 0.077478270469889296
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.079234024131786582   to: 0.077732449813140606
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.079470588836746792   to: 0.077983671494135209
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.079704362553879901   to: 0.078231968884683645
i: 100, name:           module.conv10.weight  changing lr from: 0.079935377912126751   to: 0.078477375100886468
i: 101, name:             module.conv10.bias  changing lr from: 0.080163667250190085   to: 0.078719922999319014



# Switched to train mode...
Epoch: [28][  0/391]	Time  0.197 ( 0.197)	Data  0.150 ( 0.150)	Loss 9.0928e-01 (9.0928e-01)	Acc@1  72.66 ( 72.66)	Acc@5  93.75 ( 93.75)
Epoch: [28][ 10/391]	Time  0.044 ( 0.057)	Data  0.001 ( 0.014)	Loss 8.4336e-01 (9.4574e-01)	Acc@1  71.88 ( 70.53)	Acc@5  96.09 ( 94.82)
Epoch: [28][ 20/391]	Time  0.043 ( 0.050)	Data  0.001 ( 0.008)	Loss 8.4590e-01 (9.4492e-01)	Acc@1  75.78 ( 71.69)	Acc@5  97.66 ( 94.72)
Epoch: [28][ 30/391]	Time  0.040 ( 0.047)	Data  0.001 ( 0.006)	Loss 8.5688e-01 (9.4355e-01)	Acc@1  71.88 ( 71.62)	Acc@5  92.97 ( 94.68)
Epoch: [28][ 40/391]	Time  0.038 ( 0.045)	Data  0.001 ( 0.005)	Loss 8.0357e-01 (9.4376e-01)	Acc@1  80.47 ( 71.61)	Acc@5  96.88 ( 94.63)
Epoch: [28][ 50/391]	Time  0.040 ( 0.044)	Data  0.001 ( 0.004)	Loss 9.8848e-01 (9.4893e-01)	Acc@1  72.66 ( 71.49)	Acc@5  90.62 ( 94.50)
Epoch: [28][ 60/391]	Time  0.038 ( 0.043)	Data  0.001 ( 0.004)	Loss 9.5558e-01 (9.5519e-01)	Acc@1  67.97 ( 71.32)	Acc@5  95.31 ( 94.33)
Epoch: [28][ 70/391]	Time  0.039 ( 0.043)	Data  0.001 ( 0.003)	Loss 9.4340e-01 (9.6023e-01)	Acc@1  70.31 ( 71.31)	Acc@5  94.53 ( 94.23)
Epoch: [28][ 80/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.003)	Loss 1.0333e+00 (9.6264e-01)	Acc@1  70.31 ( 71.31)	Acc@5  92.97 ( 94.17)
Epoch: [28][ 90/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.003)	Loss 7.5121e-01 (9.6368e-01)	Acc@1  75.78 ( 71.32)	Acc@5  96.88 ( 94.06)
Epoch: [28][100/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.003)	Loss 1.0042e+00 (9.6657e-01)	Acc@1  71.88 ( 71.34)	Acc@5  90.62 ( 94.00)
Epoch: [28][110/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.002)	Loss 9.8741e-01 (9.6246e-01)	Acc@1  71.09 ( 71.44)	Acc@5  92.97 ( 94.06)
Epoch: [28][120/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 9.2954e-01 (9.6322e-01)	Acc@1  71.09 ( 71.41)	Acc@5  92.97 ( 93.97)
Epoch: [28][130/391]	Time  0.045 ( 0.042)	Data  0.001 ( 0.002)	Loss 8.3007e-01 (9.6591e-01)	Acc@1  78.91 ( 71.48)	Acc@5  92.97 ( 93.88)
Epoch: [28][140/391]	Time  0.037 ( 0.042)	Data  0.001 ( 0.002)	Loss 9.7187e-01 (9.6893e-01)	Acc@1  70.31 ( 71.37)	Acc@5  92.19 ( 93.82)
Epoch: [28][150/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.0464e+00 (9.6968e-01)	Acc@1  70.31 ( 71.36)	Acc@5  90.62 ( 93.80)
Epoch: [28][160/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 8.8152e-01 (9.6556e-01)	Acc@1  70.31 ( 71.47)	Acc@5  95.31 ( 93.84)
Epoch: [28][170/391]	Time  0.045 ( 0.042)	Data  0.001 ( 0.002)	Loss 8.9683e-01 (9.6223e-01)	Acc@1  74.22 ( 71.57)	Acc@5  92.19 ( 93.81)
Epoch: [28][180/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 9.3809e-01 (9.5979e-01)	Acc@1  72.66 ( 71.56)	Acc@5  95.31 ( 93.86)
Epoch: [28][190/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.0579e+00 (9.6375e-01)	Acc@1  70.31 ( 71.49)	Acc@5  91.41 ( 93.87)
Epoch: [28][200/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 8.9539e-01 (9.6413e-01)	Acc@1  73.44 ( 71.45)	Acc@5  93.75 ( 93.84)
Epoch: [28][210/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.2239e+00 (9.6375e-01)	Acc@1  63.28 ( 71.42)	Acc@5  93.75 ( 93.87)
Epoch: [28][220/391]	Time  0.045 ( 0.042)	Data  0.001 ( 0.002)	Loss 9.1897e-01 (9.6372e-01)	Acc@1  71.09 ( 71.45)	Acc@5  97.66 ( 93.89)
Epoch: [28][230/391]	Time  0.046 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.0272e+00 (9.6770e-01)	Acc@1  64.06 ( 71.36)	Acc@5  96.09 ( 93.81)
Epoch: [28][240/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 8.3356e-01 (9.6585e-01)	Acc@1  74.22 ( 71.44)	Acc@5  94.53 ( 93.81)
Epoch: [28][250/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 7.8012e-01 (9.6639e-01)	Acc@1  73.44 ( 71.44)	Acc@5  97.66 ( 93.76)
Epoch: [28][260/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.1702e+00 (9.6527e-01)	Acc@1  67.97 ( 71.52)	Acc@5  89.06 ( 93.76)
Epoch: [28][270/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.1852e+00 (9.6633e-01)	Acc@1  65.62 ( 71.46)	Acc@5  90.62 ( 93.76)
Epoch: [28][280/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 9.2937e-01 (9.6582e-01)	Acc@1  74.22 ( 71.47)	Acc@5  93.75 ( 93.78)
Epoch: [28][290/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 8.5958e-01 (9.6621e-01)	Acc@1  73.44 ( 71.43)	Acc@5  96.09 ( 93.79)
Epoch: [28][300/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.0078e+00 (9.6613e-01)	Acc@1  70.31 ( 71.41)	Acc@5  92.97 ( 93.80)
Epoch: [28][310/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.1488e+00 (9.6869e-01)	Acc@1  65.62 ( 71.31)	Acc@5  90.62 ( 93.77)
Epoch: [28][320/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.1088e+00 (9.6890e-01)	Acc@1  63.28 ( 71.29)	Acc@5  93.75 ( 93.78)
Epoch: [28][330/391]	Time  0.046 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.0072e+00 (9.6893e-01)	Acc@1  72.66 ( 71.31)	Acc@5  92.19 ( 93.75)
Epoch: [28][340/391]	Time  0.036 ( 0.042)	Data  0.001 ( 0.002)	Loss 7.4977e-01 (9.7002e-01)	Acc@1  75.00 ( 71.25)	Acc@5  96.88 ( 93.76)
Epoch: [28][350/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.1060e+00 (9.7071e-01)	Acc@1  67.19 ( 71.22)	Acc@5  92.97 ( 93.75)
Epoch: [28][360/391]	Time  0.039 ( 0.042)	Data  0.002 ( 0.002)	Loss 1.0666e+00 (9.7056e-01)	Acc@1  74.22 ( 71.25)	Acc@5  91.41 ( 93.75)
Epoch: [28][370/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 8.1272e-01 (9.7087e-01)	Acc@1  75.00 ( 71.20)	Acc@5  93.75 ( 93.76)
Epoch: [28][380/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.001)	Loss 1.0191e+00 (9.7276e-01)	Acc@1  71.88 ( 71.17)	Acc@5  91.41 ( 93.74)
Epoch: [28][390/391]	Time  0.029 ( 0.041)	Data  0.001 ( 0.001)	Loss 8.2617e-01 (9.7259e-01)	Acc@1  75.00 ( 71.17)	Acc@5  96.25 ( 93.75)
## e[28] optimizer.zero_grad (sum) time: 0.2871439456939697
## e[28]       loss.backward (sum) time: 4.058810234069824
## e[28]      optimizer.step (sum) time: 1.9226784706115723
## epoch[28] training(only) time: 16.262761116027832
# Switched to evaluate mode...
Test: [  0/100]	Time  0.160 ( 0.160)	Loss 1.6287e+00 (1.6287e+00)	Acc@1  63.00 ( 63.00)	Acc@5  85.00 ( 85.00)
Test: [ 10/100]	Time  0.024 ( 0.035)	Loss 1.5791e+00 (1.5875e+00)	Acc@1  58.00 ( 60.45)	Acc@5  86.00 ( 85.09)
Test: [ 20/100]	Time  0.023 ( 0.029)	Loss 1.4963e+00 (1.5737e+00)	Acc@1  61.00 ( 60.19)	Acc@5  84.00 ( 85.67)
Test: [ 30/100]	Time  0.024 ( 0.027)	Loss 1.7869e+00 (1.6073e+00)	Acc@1  50.00 ( 59.32)	Acc@5  88.00 ( 85.55)
Test: [ 40/100]	Time  0.023 ( 0.026)	Loss 1.7075e+00 (1.6139e+00)	Acc@1  54.00 ( 59.05)	Acc@5  82.00 ( 85.54)
Test: [ 50/100]	Time  0.019 ( 0.025)	Loss 1.2045e+00 (1.6152e+00)	Acc@1  62.00 ( 58.94)	Acc@5  91.00 ( 85.27)
Test: [ 60/100]	Time  0.019 ( 0.024)	Loss 1.5327e+00 (1.5935e+00)	Acc@1  56.00 ( 58.84)	Acc@5  85.00 ( 85.54)
Test: [ 70/100]	Time  0.018 ( 0.024)	Loss 1.5986e+00 (1.5973e+00)	Acc@1  61.00 ( 58.75)	Acc@5  83.00 ( 85.69)
Test: [ 80/100]	Time  0.018 ( 0.023)	Loss 1.6039e+00 (1.6007e+00)	Acc@1  65.00 ( 58.69)	Acc@5  83.00 ( 85.56)
Test: [ 90/100]	Time  0.023 ( 0.023)	Loss 1.9212e+00 (1.5945e+00)	Acc@1  52.00 ( 58.86)	Acc@5  78.00 ( 85.57)
 * Acc@1 59.010 Acc@5 85.750
### epoch[28] execution time: 18.628551483154297
EPOCH 29
i:   0, name:           module.stem.0.weight  changing lr from: 0.034412522912332426   to: 0.031237753974350746
i:   1, name:             module.stem.0.bias  changing lr from: 0.035072962713554805   to: 0.031904239198440175
i:   2, name:           module.stem.1.weight  changing lr from: 0.035730037456447504   to: 0.032568176699762141
i:   3, name:             module.stem.1.bias  changing lr from: 0.036383612309236701   to: 0.033229396519150793
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.037033560223358498   to: 0.033887737519025476
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.037679761650102686   to: 0.034543047079952725
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.038322104265076463   to: 0.035195180804796368
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.038960482700391284   to: 0.035844002230416248
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.039594798284466097   to: 0.036489382546863534
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.040224958789334866   to: 0.037131200324008941
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.040850878185338703   to: 0.037769341245530226
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.041472476403078468   to: 0.038403697850175791
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.042089679102498230   to: 0.039034169280213089
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.042702417448967127   to: 0.039660661036963508
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.043310627896222649   to: 0.040283084743318667
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.043914251976037065   to: 0.040901357913128086
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.044513236094465301   to: 0.041515403727342304
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.045107531334532235   to: 0.042125150816792946
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.045697093265215143   to: 0.042730533051486080
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.046281881756577214   to: 0.043331489336283530
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.046861860800906957   to: 0.043927963412843690
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.047436998339719205   to: 0.044519903667692137
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.048007266096472934   to: 0.045107262946290166
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.048572639414862222   to: 0.045689998372968992
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.049133097102537771   to: 0.046268071176596648
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.049688621280116758   to: 0.046841446521843633
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.050239197235340996   to: 0.047410093345914554
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.050784813282244490   to: 0.047973984200612330
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.051325460625193157   to: 0.048533095099602686
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.051861133227661296   to: 0.049087405370746934
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.052391827685611604   to: 0.049636897513372781
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.052917543105347464   to: 0.050181557060353557
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.053438280985708346   to: 0.050721372444867678
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.053954045104481443   to: 0.051256334871712085
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.054464841408905257   to: 0.051786438193044508
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.054970677910142707   to: 0.052311678788431737
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.055471564581604654   to: 0.052832055449082517
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.055967513261005908   to: 0.053347569266145978
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.056458537556039870   to: 0.053858223522958340
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.056944652753558971   to: 0.054364023591122856
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.057425875732151910   to: 0.054864976830310302
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.057902224878010271   to: 0.055361092491669053
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.058373720003980036   to: 0.055852381624736561
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.058840382271696516   to: 0.056338856987746190
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.059302234116702546   to: 0.056820532961225190
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.059759299176453839   to: 0.057297425464782864
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.060211602221116448   to: 0.057769551876989213
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.060659169087064937   to: 0.058236930958247737
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.061102026612991446   to: 0.058699582776567276
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.061540202578538844   to: 0.059157528636141168
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.061973725645373103   to: 0.059610791008643506
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.062402625300612781   to: 0.060059393467154880
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.062826931802535457   to: 0.060503360622632341
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.063246676128483614   to: 0.060942718062840330
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.063661889924894355   to: 0.061377492293661733
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.064072605459379470   to: 0.061807710682709988
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.064478855574785277   to: 0.062233401405166311
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.064880673645162687   to: 0.062654593391766711
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.065278093533580966   to: 0.063071316278867237
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.065671149551719710   to: 0.063483600360516340
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.066059876421176930   to: 0.063891476542466741
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.066444309236431465   to: 0.064294976298059942
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.066824483429401033   to: 0.064694131625919207
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.067200434735538370   to: 0.065088975009388414
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.067572199161410440   to: 0.065479539377656229
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.067939812953706505   to: 0.065865858068506686
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.068303312569623284   to: 0.066247964792639238
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.068662734648576848   to: 0.066625893599502745
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.069018115985192682   to: 0.066999678844590141
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.069369493503526405   to: 0.067369355158141547
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.069716904232469956   to: 0.067734957415205618
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.070060385282298937   to: 0.068096520707010375
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.070399973822318551   to: 0.068454080313596441
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.070735707059566819   to: 0.068807671677666479
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.071067622218535395   to: 0.069157330379607557
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.071395756521869275   to: 0.069503092113642473
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.071720147172008392   to: 0.069844992665069522
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.072040831333734845   to: 0.070183067888550013
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.072357846117591329   to: 0.070517353687405235
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.072671228564137144   to: 0.070847885993885071
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.072981015629009091   to: 0.071174700750371897
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.073287244168756538   to: 0.071497833891485230
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.073589950927419823   to: 0.071817321327052583
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.073889172523823307   to: 0.072133198925914285
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.074184945439554714   to: 0.072445502500530209
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.074477306007603702   to: 0.072754267792358315
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.074766290401633281   to: 0.073059530457974822
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.075051934625859199   to: 0.073361326055908144
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.075334274505512319   to: 0.073659690034158509
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.075613345677861044   to: 0.073954657718376962
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.075889183583770836   to: 0.074246264300677753
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.076161823459778774   to: 0.074534544829059746
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.076431300330662547   to: 0.074819534197412371
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.076697649002483131   to: 0.075101267136083491
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.076960904056081691   to: 0.075379778202986580
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.077221099841011873   to: 0.075655101775225650
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.077478270469889296   to: 0.075927272041217506
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.077732449813140606   to: 0.076196322993290988
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.077983671494135209   to: 0.076462288420743929
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.078231968884683645   to: 0.076725201903339271
i: 100, name:           module.conv10.weight  changing lr from: 0.078477375100886468   to: 0.076985096805222461
i: 101, name:             module.conv10.bias  changing lr from: 0.078719922999319014   to: 0.077242006269242477



# Switched to train mode...
Epoch: [29][  0/391]	Time  0.199 ( 0.199)	Data  0.151 ( 0.151)	Loss 1.1063e+00 (1.1063e+00)	Acc@1  65.62 ( 65.62)	Acc@5  92.97 ( 92.97)
Epoch: [29][ 10/391]	Time  0.043 ( 0.057)	Data  0.001 ( 0.015)	Loss 7.6954e-01 (9.1969e-01)	Acc@1  77.34 ( 72.44)	Acc@5  95.31 ( 94.53)
Epoch: [29][ 20/391]	Time  0.042 ( 0.049)	Data  0.001 ( 0.008)	Loss 7.9438e-01 (8.7267e-01)	Acc@1  74.22 ( 74.11)	Acc@5  96.09 ( 94.83)
Epoch: [29][ 30/391]	Time  0.041 ( 0.047)	Data  0.001 ( 0.006)	Loss 9.1293e-01 (8.7791e-01)	Acc@1  72.66 ( 73.92)	Acc@5  95.31 ( 94.81)
Epoch: [29][ 40/391]	Time  0.047 ( 0.046)	Data  0.001 ( 0.005)	Loss 8.9520e-01 (8.7620e-01)	Acc@1  74.22 ( 73.91)	Acc@5  92.97 ( 94.93)
Epoch: [29][ 50/391]	Time  0.041 ( 0.045)	Data  0.001 ( 0.004)	Loss 9.5161e-01 (8.8646e-01)	Acc@1  71.88 ( 73.50)	Acc@5  92.97 ( 94.70)
Epoch: [29][ 60/391]	Time  0.042 ( 0.044)	Data  0.001 ( 0.003)	Loss 9.9519e-01 (8.8077e-01)	Acc@1  67.19 ( 73.50)	Acc@5  96.88 ( 94.92)
Epoch: [29][ 70/391]	Time  0.039 ( 0.044)	Data  0.001 ( 0.003)	Loss 8.9646e-01 (8.8204e-01)	Acc@1  73.44 ( 73.62)	Acc@5  93.75 ( 94.95)
Epoch: [29][ 80/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.003)	Loss 8.0941e-01 (8.9069e-01)	Acc@1  76.56 ( 73.41)	Acc@5  97.66 ( 94.96)
Epoch: [29][ 90/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.003)	Loss 8.3131e-01 (8.9534e-01)	Acc@1  70.31 ( 73.21)	Acc@5  96.88 ( 94.86)
Epoch: [29][100/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 8.8632e-01 (9.1267e-01)	Acc@1  68.75 ( 72.73)	Acc@5  96.09 ( 94.53)
Epoch: [29][110/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.0779e+00 (9.1330e-01)	Acc@1  67.97 ( 72.57)	Acc@5  93.75 ( 94.53)
Epoch: [29][120/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 8.6359e-01 (9.1968e-01)	Acc@1  73.44 ( 72.46)	Acc@5  95.31 ( 94.42)
Epoch: [29][130/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 9.3497e-01 (9.2576e-01)	Acc@1  69.53 ( 72.32)	Acc@5  96.09 ( 94.35)
Epoch: [29][140/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 8.4396e-01 (9.2468e-01)	Acc@1  75.00 ( 72.26)	Acc@5  92.97 ( 94.37)
Epoch: [29][150/391]	Time  0.049 ( 0.042)	Data  0.001 ( 0.002)	Loss 7.3789e-01 (9.2369e-01)	Acc@1  76.56 ( 72.34)	Acc@5  98.44 ( 94.37)
Epoch: [29][160/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 9.7920e-01 (9.2070e-01)	Acc@1  72.66 ( 72.42)	Acc@5  92.19 ( 94.38)
Epoch: [29][170/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.002)	Loss 9.7344e-01 (9.2083e-01)	Acc@1  71.09 ( 72.40)	Acc@5  94.53 ( 94.38)
Epoch: [29][180/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 9.9434e-01 (9.2333e-01)	Acc@1  71.09 ( 72.38)	Acc@5  93.75 ( 94.38)
Epoch: [29][190/391]	Time  0.037 ( 0.042)	Data  0.001 ( 0.002)	Loss 8.6657e-01 (9.2615e-01)	Acc@1  73.44 ( 72.28)	Acc@5  96.09 ( 94.37)
Epoch: [29][200/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.3668e+00 (9.2956e-01)	Acc@1  61.72 ( 72.15)	Acc@5  90.62 ( 94.32)
Epoch: [29][210/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 9.0718e-01 (9.3145e-01)	Acc@1  72.66 ( 72.09)	Acc@5  95.31 ( 94.30)
Epoch: [29][220/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.1206e+00 (9.3571e-01)	Acc@1  64.84 ( 71.97)	Acc@5  92.97 ( 94.26)
Epoch: [29][230/391]	Time  0.045 ( 0.042)	Data  0.001 ( 0.002)	Loss 8.6583e-01 (9.3663e-01)	Acc@1  72.66 ( 71.98)	Acc@5  95.31 ( 94.23)
Epoch: [29][240/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 8.5018e-01 (9.3691e-01)	Acc@1  72.66 ( 72.02)	Acc@5  95.31 ( 94.21)
Epoch: [29][250/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.0362e+00 (9.3998e-01)	Acc@1  67.19 ( 71.89)	Acc@5  92.19 ( 94.17)
Epoch: [29][260/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 9.7588e-01 (9.4112e-01)	Acc@1  72.66 ( 71.85)	Acc@5  95.31 ( 94.15)
Epoch: [29][270/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.0076e+00 (9.4194e-01)	Acc@1  70.31 ( 71.81)	Acc@5  94.53 ( 94.12)
Epoch: [29][280/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.001)	Loss 9.0778e-01 (9.4112e-01)	Acc@1  73.44 ( 71.81)	Acc@5  96.09 ( 94.14)
Epoch: [29][290/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.0528e+00 (9.4327e-01)	Acc@1  67.19 ( 71.78)	Acc@5  92.19 ( 94.09)
Epoch: [29][300/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.1338e+00 (9.4473e-01)	Acc@1  67.19 ( 71.74)	Acc@5  92.97 ( 94.11)
Epoch: [29][310/391]	Time  0.046 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.0920e+00 (9.4871e-01)	Acc@1  68.75 ( 71.62)	Acc@5  90.62 ( 94.03)
Epoch: [29][320/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 9.0976e-01 (9.5033e-01)	Acc@1  70.31 ( 71.60)	Acc@5  96.88 ( 94.00)
Epoch: [29][330/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.001)	Loss 9.5023e-01 (9.5090e-01)	Acc@1  71.09 ( 71.60)	Acc@5  96.88 ( 94.01)
Epoch: [29][340/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.001)	Loss 9.9822e-01 (9.5218e-01)	Acc@1  69.53 ( 71.55)	Acc@5  92.97 ( 94.02)
Epoch: [29][350/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.001)	Loss 9.2045e-01 (9.5447e-01)	Acc@1  75.00 ( 71.53)	Acc@5  92.97 ( 93.98)
Epoch: [29][360/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.001)	Loss 9.5966e-01 (9.5510e-01)	Acc@1  67.97 ( 71.48)	Acc@5  95.31 ( 93.97)
Epoch: [29][370/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.001)	Loss 8.1982e-01 (9.5662e-01)	Acc@1  75.78 ( 71.44)	Acc@5  96.09 ( 93.93)
Epoch: [29][380/391]	Time  0.046 ( 0.042)	Data  0.001 ( 0.001)	Loss 8.5961e-01 (9.5694e-01)	Acc@1  72.66 ( 71.43)	Acc@5  93.75 ( 93.93)
Epoch: [29][390/391]	Time  0.029 ( 0.042)	Data  0.001 ( 0.001)	Loss 9.7238e-01 (9.5797e-01)	Acc@1  70.00 ( 71.38)	Acc@5  93.75 ( 93.93)
## e[29] optimizer.zero_grad (sum) time: 0.2856311798095703
## e[29]       loss.backward (sum) time: 4.131350994110107
## e[29]      optimizer.step (sum) time: 1.8612477779388428
## epoch[29] training(only) time: 16.431131839752197
# Switched to evaluate mode...
Test: [  0/100]	Time  0.151 ( 0.151)	Loss 1.4402e+00 (1.4402e+00)	Acc@1  65.00 ( 65.00)	Acc@5  87.00 ( 87.00)
Test: [ 10/100]	Time  0.023 ( 0.032)	Loss 1.6077e+00 (1.5192e+00)	Acc@1  54.00 ( 60.09)	Acc@5  90.00 ( 86.64)
Test: [ 20/100]	Time  0.025 ( 0.028)	Loss 1.2664e+00 (1.4900e+00)	Acc@1  66.00 ( 60.57)	Acc@5  89.00 ( 87.05)
Test: [ 30/100]	Time  0.022 ( 0.026)	Loss 1.6050e+00 (1.5197e+00)	Acc@1  52.00 ( 60.81)	Acc@5  84.00 ( 86.23)
Test: [ 40/100]	Time  0.023 ( 0.025)	Loss 1.6057e+00 (1.5116e+00)	Acc@1  61.00 ( 60.63)	Acc@5  85.00 ( 86.39)
Test: [ 50/100]	Time  0.018 ( 0.024)	Loss 1.5841e+00 (1.5121e+00)	Acc@1  66.00 ( 60.67)	Acc@5  89.00 ( 86.51)
Test: [ 60/100]	Time  0.024 ( 0.024)	Loss 1.4791e+00 (1.4994e+00)	Acc@1  59.00 ( 60.75)	Acc@5  83.00 ( 86.52)
Test: [ 70/100]	Time  0.024 ( 0.024)	Loss 1.4267e+00 (1.5051e+00)	Acc@1  67.00 ( 60.77)	Acc@5  88.00 ( 86.39)
Test: [ 80/100]	Time  0.024 ( 0.024)	Loss 1.6304e+00 (1.5106e+00)	Acc@1  58.00 ( 60.77)	Acc@5  83.00 ( 86.43)
Test: [ 90/100]	Time  0.024 ( 0.024)	Loss 1.7580e+00 (1.5022e+00)	Acc@1  55.00 ( 60.84)	Acc@5  85.00 ( 86.62)
 * Acc@1 61.120 Acc@5 86.800
### epoch[29] execution time: 18.887190103530884
EPOCH 30
i:   0, name:           module.stem.0.weight  changing lr from: 0.031237753974350746   to: 0.028154806218479014
i:   1, name:             module.stem.0.bias  changing lr from: 0.031904239198440175   to: 0.028822947021865816
i:   2, name:           module.stem.1.weight  changing lr from: 0.032568176699762141   to: 0.029489480366081306
i:   3, name:             module.stem.1.bias  changing lr from: 0.033229396519150793   to: 0.030154198729653026
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.033887737519025476   to: 0.030816904452948591
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.034543047079952725   to: 0.031477409418263692
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.035195180804796368   to: 0.032135534736977403
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.035844002230416248   to: 0.032791110443810882
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.036489382546863534   to: 0.033443975198206841
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.037131200324008941   to: 0.034093975992830955
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.037769341245530226   to: 0.034740967869181162
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.038403697850175791   to: 0.035384813640277075
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.039034169280213089   to: 0.036025383620389005
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.039660661036963508   to: 0.036662555361755521
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.040283084743318667   to: 0.037296213398227335
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.040901357913128086   to: 0.037926248995767242
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.041515403727342304   to: 0.038552559909726759
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.042125150816792946   to: 0.039175050148813791
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.042730533051486080   to: 0.039793629745658365
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.043331489336283530   to: 0.040408214533878384
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.043927963412843690   to: 0.041018725931542308
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.044519903667692137   to: 0.041625090730921466
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.045107262946290166   to: 0.042227240894420683
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.045689998372968992   to: 0.042825113356573553
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.046268071176596648   to: 0.043418649831985269
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.046841446521843633   to: 0.044007796629104458
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.047410093345914554   to: 0.044592504469703614
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.047973984200612330   to: 0.045172728313946475
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.048533095099602686   to: 0.045748427190919816
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.049087405370746934   to: 0.046319564034506516
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.049636897513372781   to: 0.046886105524476779
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.050181557060353557   to: 0.047448021932674250
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.050721372444867678   to: 0.048005286974174055
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.051256334871712085   to: 0.048557877663290457
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.051786438193044508   to: 0.049105774174312625
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.052311678788431737   to: 0.049648959706847566
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.052832055449082517   to: 0.050187420355651179
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.053347569266145978   to: 0.050721144984828617
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.053858223522958340   to: 0.051250125106287507
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.054364023591122856   to: 0.051774354762328445
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.054864976830310302   to: 0.052293830412259192
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.055361092491669053   to: 0.052808550822920547
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.055852381624736561   to: 0.053318516963013575
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.056338856987746190   to: 0.053823731901120324
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.056820532961225190   to: 0.054324200707310921
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.057297425464782864   to: 0.054819930358233494
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.057769551876989213   to: 0.055310929645583685
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.058236930958247737   to: 0.055797209087854516
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.058699582776567276   to: 0.056278780845267079
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.059157528636141168   to: 0.056755658637787136
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.059610791008643506   to: 0.057227857666132878
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.060059393467154880   to: 0.057695394535682065
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.060503360622632341   to: 0.058158287183189064
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.060942718062840330   to: 0.058616554806223888
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.061377492293661733   to: 0.059070217795247786
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.061807710682709988   to: 0.059519297668241711
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.062233401405166311   to: 0.059963817007806924
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.062654593391766711   to: 0.060403799400657633
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.063071316278867237   to: 0.060839269379429239
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.063483600360516340   to: 0.061270252366726279
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.063891476542466741   to: 0.061696774621337470
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.064294976298059942   to: 0.062118863186546205
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.064694131625919207   to: 0.062536545840467306
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.065088975009388414   to: 0.062949851048342900
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.065479539377656229   to: 0.063358807916731458
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.065865858068506686   to: 0.063763446149527031
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.066247964792639238   to: 0.064163796005746135
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.066625893599502745   to: 0.064559888259022702
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.066999678844590141   to: 0.064951754158752803
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.067369355158141547   to: 0.065339425392832259
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.067734957415205618   to: 0.065722934051932663
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.068096520707010375   to: 0.066102312595261989
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.068454080313596441   to: 0.066477593817758890
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.068807671677666479   to: 0.066848810818669585
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.069157330379607557   to: 0.067215996971459954
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.069503092113642473   to: 0.067579185895014646
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.069844992665069522   to: 0.067938411426078413
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.070183067888550013   to: 0.068293707592894867
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.070517353687405235   to: 0.068645108590000420
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.070847885993885071   to: 0.068992648754131553
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.071174700750371897   to: 0.069336362541205260
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.071497833891485230   to: 0.069676284504334149
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.071817321327052583   to: 0.070012449272838229
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.072133198925914285   to: 0.070344891532217277
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.072445502500530209   to: 0.070673646005048107
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.072754267792358315   to: 0.070998747432773401
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.073059530457974822   to: 0.071320230558348380
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.073361326055908144   to: 0.071638130109713871
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.073659690034158509   to: 0.071952480784065062
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.073954657718376962   to: 0.072263317232885663
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.074246264300677753   to: 0.072570674047719094
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.074534544829059746   to: 0.072874585746648693
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.074819534197412371   to: 0.073175086761460242
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.075101267136083491   to: 0.073472211425460315
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.075379778202986580   to: 0.073765993961925930
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.075655101775225650   to: 0.074056468473160914
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.075927272041217506   to: 0.074343668930135554
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.076196322993290988   to: 0.074627629162687087
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.076462288420743929   to: 0.074908382850258901
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.076725201903339271   to: 0.075185963513157678
i: 100, name:           module.conv10.weight  changing lr from: 0.076985096805222461   to: 0.075460404504307729
i: 101, name:             module.conv10.bias  changing lr from: 0.077242006269242477   to: 0.075731739001483431



# Switched to train mode...
Epoch: [30][  0/391]	Time  0.207 ( 0.207)	Data  0.158 ( 0.158)	Loss 9.4318e-01 (9.4318e-01)	Acc@1  75.78 ( 75.78)	Acc@5  92.19 ( 92.19)
Epoch: [30][ 10/391]	Time  0.041 ( 0.056)	Data  0.001 ( 0.015)	Loss 8.5361e-01 (8.1441e-01)	Acc@1  74.22 ( 76.70)	Acc@5  94.53 ( 95.45)
Epoch: [30][ 20/391]	Time  0.037 ( 0.048)	Data  0.001 ( 0.009)	Loss 8.3644e-01 (8.3773e-01)	Acc@1  71.09 ( 74.78)	Acc@5  97.66 ( 95.72)
Epoch: [30][ 30/391]	Time  0.043 ( 0.046)	Data  0.001 ( 0.006)	Loss 1.0004e+00 (8.3703e-01)	Acc@1  67.19 ( 74.82)	Acc@5  92.19 ( 95.51)
Epoch: [30][ 40/391]	Time  0.047 ( 0.045)	Data  0.001 ( 0.005)	Loss 1.0609e+00 (8.4979e-01)	Acc@1  67.97 ( 74.09)	Acc@5  92.97 ( 95.56)
Epoch: [30][ 50/391]	Time  0.043 ( 0.044)	Data  0.001 ( 0.004)	Loss 8.8805e-01 (8.3864e-01)	Acc@1  71.88 ( 74.69)	Acc@5  94.53 ( 95.66)
Epoch: [30][ 60/391]	Time  0.043 ( 0.044)	Data  0.001 ( 0.004)	Loss 9.6563e-01 (8.4146e-01)	Acc@1  69.53 ( 74.64)	Acc@5  95.31 ( 95.63)
Epoch: [30][ 70/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.003)	Loss 1.1123e+00 (8.4300e-01)	Acc@1  70.31 ( 74.61)	Acc@5  92.19 ( 95.47)
Epoch: [30][ 80/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.003)	Loss 7.7530e-01 (8.4677e-01)	Acc@1  75.78 ( 74.49)	Acc@5  96.09 ( 95.48)
Epoch: [30][ 90/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.003)	Loss 9.8924e-01 (8.5484e-01)	Acc@1  71.09 ( 74.19)	Acc@5  94.53 ( 95.31)
Epoch: [30][100/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.003)	Loss 9.7366e-01 (8.6442e-01)	Acc@1  71.88 ( 73.93)	Acc@5  92.19 ( 95.13)
Epoch: [30][110/391]	Time  0.044 ( 0.043)	Data  0.001 ( 0.002)	Loss 7.7333e-01 (8.6433e-01)	Acc@1  75.78 ( 73.97)	Acc@5  96.09 ( 95.11)
Epoch: [30][120/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.2797e+00 (8.7040e-01)	Acc@1  64.06 ( 73.72)	Acc@5  88.28 ( 95.05)
Epoch: [30][130/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.002)	Loss 9.5416e-01 (8.7283e-01)	Acc@1  72.66 ( 73.57)	Acc@5  92.97 ( 95.08)
Epoch: [30][140/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 9.5362e-01 (8.7456e-01)	Acc@1  69.53 ( 73.50)	Acc@5  94.53 ( 95.06)
Epoch: [30][150/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.0034e+00 (8.8123e-01)	Acc@1  69.53 ( 73.33)	Acc@5  94.53 ( 94.95)
Epoch: [30][160/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 9.6434e-01 (8.8557e-01)	Acc@1  74.22 ( 73.30)	Acc@5  92.97 ( 94.85)
Epoch: [30][170/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 8.0761e-01 (8.8834e-01)	Acc@1  77.34 ( 73.23)	Acc@5  93.75 ( 94.77)
Epoch: [30][180/391]	Time  0.048 ( 0.042)	Data  0.001 ( 0.002)	Loss 8.8690e-01 (8.9327e-01)	Acc@1  68.75 ( 73.12)	Acc@5  96.09 ( 94.67)
Epoch: [30][190/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 9.4292e-01 (8.9723e-01)	Acc@1  71.09 ( 72.99)	Acc@5  93.75 ( 94.60)
Epoch: [30][200/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 7.1775e-01 (9.0036e-01)	Acc@1  78.12 ( 72.92)	Acc@5  96.88 ( 94.55)
Epoch: [30][210/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.0202e+00 (9.0253e-01)	Acc@1  73.44 ( 72.84)	Acc@5  94.53 ( 94.56)
Epoch: [30][220/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 9.0592e-01 (9.0665e-01)	Acc@1  74.22 ( 72.75)	Acc@5  93.75 ( 94.47)
Epoch: [30][230/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.002)	Loss 7.6563e-01 (9.0655e-01)	Acc@1  78.12 ( 72.83)	Acc@5  96.88 ( 94.45)
Epoch: [30][240/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.1450e+00 (9.0868e-01)	Acc@1  63.28 ( 72.74)	Acc@5  91.41 ( 94.43)
Epoch: [30][250/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.1667e+00 (9.1381e-01)	Acc@1  63.28 ( 72.59)	Acc@5  92.97 ( 94.34)
Epoch: [30][260/391]	Time  0.042 ( 0.042)	Data  0.002 ( 0.002)	Loss 8.8796e-01 (9.1646e-01)	Acc@1  73.44 ( 72.47)	Acc@5  94.53 ( 94.32)
Epoch: [30][270/391]	Time  0.045 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.0289e+00 (9.1782e-01)	Acc@1  65.62 ( 72.41)	Acc@5  91.41 ( 94.28)
Epoch: [30][280/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 7.2223e-01 (9.1684e-01)	Acc@1  82.03 ( 72.48)	Acc@5  96.88 ( 94.31)
Epoch: [30][290/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.0476e+00 (9.1805e-01)	Acc@1  67.97 ( 72.47)	Acc@5  91.41 ( 94.29)
Epoch: [30][300/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.002)	Loss 8.0060e-01 (9.1888e-01)	Acc@1  71.09 ( 72.40)	Acc@5  97.66 ( 94.30)
Epoch: [30][310/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 8.9432e-01 (9.1835e-01)	Acc@1  71.09 ( 72.43)	Acc@5  95.31 ( 94.29)
Epoch: [30][320/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.0514e+00 (9.2017e-01)	Acc@1  68.75 ( 72.40)	Acc@5  91.41 ( 94.25)
Epoch: [30][330/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 8.9152e-01 (9.2004e-01)	Acc@1  72.66 ( 72.38)	Acc@5  93.75 ( 94.25)
Epoch: [30][340/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.001)	Loss 8.6114e-01 (9.2261e-01)	Acc@1  75.00 ( 72.31)	Acc@5  92.97 ( 94.22)
Epoch: [30][350/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 7.9511e-01 (9.2463e-01)	Acc@1  78.91 ( 72.27)	Acc@5  93.75 ( 94.16)
Epoch: [30][360/391]	Time  0.045 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.0405e+00 (9.2559e-01)	Acc@1  67.19 ( 72.25)	Acc@5  92.97 ( 94.15)
Epoch: [30][370/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.001)	Loss 9.3176e-01 (9.2551e-01)	Acc@1  69.53 ( 72.26)	Acc@5  91.41 ( 94.15)
Epoch: [30][380/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 9.1129e-01 (9.2630e-01)	Acc@1  76.56 ( 72.24)	Acc@5  95.31 ( 94.14)
Epoch: [30][390/391]	Time  0.029 ( 0.042)	Data  0.001 ( 0.001)	Loss 7.9683e-01 (9.2718e-01)	Acc@1  75.00 ( 72.21)	Acc@5  95.00 ( 94.15)
## e[30] optimizer.zero_grad (sum) time: 0.2858889102935791
## e[30]       loss.backward (sum) time: 4.100275754928589
## e[30]      optimizer.step (sum) time: 1.910224437713623
## epoch[30] training(only) time: 16.397778272628784
# Switched to evaluate mode...
Test: [  0/100]	Time  0.150 ( 0.150)	Loss 1.4246e+00 (1.4246e+00)	Acc@1  61.00 ( 61.00)	Acc@5  87.00 ( 87.00)
Test: [ 10/100]	Time  0.024 ( 0.035)	Loss 1.5863e+00 (1.5381e+00)	Acc@1  57.00 ( 61.64)	Acc@5  89.00 ( 86.45)
Test: [ 20/100]	Time  0.023 ( 0.029)	Loss 1.3584e+00 (1.5110e+00)	Acc@1  61.00 ( 60.71)	Acc@5  91.00 ( 87.00)
Test: [ 30/100]	Time  0.022 ( 0.027)	Loss 1.6410e+00 (1.5317e+00)	Acc@1  62.00 ( 59.97)	Acc@5  85.00 ( 86.61)
Test: [ 40/100]	Time  0.023 ( 0.025)	Loss 1.5606e+00 (1.5165e+00)	Acc@1  61.00 ( 59.66)	Acc@5  84.00 ( 86.90)
Test: [ 50/100]	Time  0.024 ( 0.025)	Loss 1.3485e+00 (1.5270e+00)	Acc@1  57.00 ( 59.24)	Acc@5  89.00 ( 86.76)
Test: [ 60/100]	Time  0.024 ( 0.025)	Loss 1.4474e+00 (1.5132e+00)	Acc@1  63.00 ( 59.66)	Acc@5  86.00 ( 87.11)
Test: [ 70/100]	Time  0.024 ( 0.025)	Loss 1.4326e+00 (1.5061e+00)	Acc@1  61.00 ( 59.87)	Acc@5  86.00 ( 87.08)
Test: [ 80/100]	Time  0.024 ( 0.024)	Loss 1.4264e+00 (1.5058e+00)	Acc@1  65.00 ( 60.10)	Acc@5  85.00 ( 87.05)
Test: [ 90/100]	Time  0.024 ( 0.024)	Loss 1.9585e+00 (1.4987e+00)	Acc@1  53.00 ( 60.23)	Acc@5  80.00 ( 87.12)
 * Acc@1 60.430 Acc@5 87.180
### epoch[30] execution time: 18.871315002441406
EPOCH 31
i:   0, name:           module.stem.0.weight  changing lr from: 0.028154806218479014   to: 0.025178003922785554
i:   1, name:             module.stem.0.bias  changing lr from: 0.028822947021865816   to: 0.025843194105596646
i:   2, name:           module.stem.1.weight  changing lr from: 0.029489480366081306   to: 0.026507839539321398
i:   3, name:             module.stem.1.bias  changing lr from: 0.030154198729653026   to: 0.027171692982877083
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.030816904452948591   to: 0.027834518080325905
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.031477409418263692   to: 0.028496089029063643
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.032135534736977403   to: 0.029156190254225268
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.032791110443810882   to: 0.029814616089436904
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.033443975198206841   to: 0.030471170464018562
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.034093975992830955   to: 0.031125666596720031
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.034740967869181162   to: 0.031777926696051631
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.035384813640277075   to: 0.032427781667251923
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.036025383620389005   to: 0.033075070825917714
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.036662555361755521   to: 0.033719641618305270
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.037296213398227335   to: 0.034361349348297231
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.037926248995767242   to: 0.035000056911016673
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.038552559909726759   to: 0.035635634533056841
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.039175050148813791   to: 0.036267959519285700
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.039793629745658365   to: 0.036896916006172745
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.040408214533878384   to: 0.037522394721577944
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.041018725931542308   to: 0.038144292750934131
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.041625090730921466   to: 0.038762513309747143
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.042227240894420683   to: 0.039376965522331685
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.042825113356573553   to: 0.039987564206695185
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.043418649831985269   to: 0.040594229665477155
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.044007796629104458   to: 0.041196887482846965
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.044592504469703614   to: 0.041795468327259618
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.045172728313946475   to: 0.042389907759965720
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.045748427190919816   to: 0.042980146049169103
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.046319564034506516   to: 0.043566127989723313
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.046886105524476779   to: 0.044147802728256781
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.047448021932674250   to: 0.044725123593614607
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.048005286974174055   to: 0.045298047932503950
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.048557877663290457   to: 0.045866536950229679
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.049105774174312625   to: 0.046430555556405878
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.049648959706847566   to: 0.046990072215529179
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.050187420355651179   to: 0.047545058802299978
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.050721144984828617   to: 0.048095490461577371
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.051250125106287507   to: 0.048641345472854931
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.051774354762328445   to: 0.049182605119144712
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.052293830412259192   to: 0.049719253560157869
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.052808550822920547   to: 0.050251277709671333
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.053318516963013575   to: 0.050778667116971134
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.053823731901120324   to: 0.051301413852264499
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.054324200707310921   to: 0.051819512395953671
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.054819930358233494   to: 0.052332959531666813
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.055310929645583685   to: 0.052841754242941789
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.055797209087854516   to: 0.053345897613461694
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.056278780845267079   to: 0.053845392730741154
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.056755658637787136   to: 0.054340244593165533
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.057227857666132878   to: 0.054830460020286298
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.057695394535682065   to: 0.055316047566277608
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.058158287183189064   to: 0.055797017436461628
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.058616554806223888   to: 0.056273381406811387
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.059070217795247786   to: 0.056745152746342280
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.059519297668241711   to: 0.057212346142304853
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.059963817007806924   to: 0.057674977628094405
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.060403799400657633   to: 0.058133064513793312
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.060839269379429239   to: 0.058586625319265666
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.061270252366726279   to: 0.059035679709724224
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.061696774621337470   to: 0.059480248433692963
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.062118863186546205   to: 0.059920353263289074
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.062536545840467306   to: 0.060356016936751404
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.062949851048342900   to: 0.060787263103143196
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.063358807916731458   to: 0.061214116269159673
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.063763446149527031   to: 0.061636601747972170
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.064163796005746135   to: 0.062054745610042789
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.064559888259022702   to: 0.062468574635845091
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.064951754158752803   to: 0.062878116270428233
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.065339425392832259   to: 0.063283398579763533
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.065722934051932663   to: 0.063684450208814511
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.066102312595261989   to: 0.064081300341272282
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.066477593817758890   to: 0.064473978660901252
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.066848810818669585   to: 0.064862515314439900
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.067215996971459954   to: 0.065246940876004592
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.067579185895014646   to: 0.065627286312944941
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.067938411426078413   to: 0.066003582953101117
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.068293707592894867   to: 0.066375862453414688
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.068645108590000420   to: 0.066744156769846685
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.068992648754131553   to: 0.067108498128557223
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.069336362541205260   to: 0.067468918998302527
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.069676284504334149   to: 0.067825452064007349
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.070012449272838229   to: 0.068178130201470719
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.070344891532217277   to: 0.068526986453165725
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.070673646005048107   to: 0.068872054005093872
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.070998747432773401   to: 0.069213366164656828
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.071320230558348380   to: 0.069550956339509293
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.071638130109713871   to: 0.069884858017357249
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.071952480784065062   to: 0.070215104746667978
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.072263317232885663   to: 0.070541730118258580
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.072570674047719094   to: 0.070864767747731136
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.072874585746648693   to: 0.071184251258723394
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.073175086761460242   to: 0.071500214266945403
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.073472211425460315   to: 0.071812690364972787
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.073765993961925930   to: 0.072121713107768978
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.074056468473160914   to: 0.072427315998909031
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.074343668930135554   to: 0.072729532477479111
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.074627629162687087   to: 0.073028395905626223
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.074908382850258901   to: 0.073323939556733678
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.075185963513157678   to: 0.073616196604198686
i: 100, name:           module.conv10.weight  changing lr from: 0.075460404504307729   to: 0.073905200110789313
i: 101, name:             module.conv10.bias  changing lr from: 0.075731739001483431   to: 0.074190983018558629



# Switched to train mode...
Epoch: [31][  0/391]	Time  0.191 ( 0.191)	Data  0.143 ( 0.143)	Loss 8.1657e-01 (8.1657e-01)	Acc@1  76.56 ( 76.56)	Acc@5  97.66 ( 97.66)
Epoch: [31][ 10/391]	Time  0.042 ( 0.056)	Data  0.001 ( 0.014)	Loss 1.0146e+00 (8.9802e-01)	Acc@1  71.88 ( 71.45)	Acc@5  94.53 ( 95.10)
Epoch: [31][ 20/391]	Time  0.039 ( 0.049)	Data  0.001 ( 0.008)	Loss 6.9861e-01 (8.5847e-01)	Acc@1  79.69 ( 73.25)	Acc@5  96.09 ( 95.46)
Epoch: [31][ 30/391]	Time  0.040 ( 0.046)	Data  0.001 ( 0.006)	Loss 8.9518e-01 (8.6193e-01)	Acc@1  73.44 ( 73.56)	Acc@5  94.53 ( 95.19)
Epoch: [31][ 40/391]	Time  0.040 ( 0.045)	Data  0.001 ( 0.004)	Loss 1.0982e+00 (8.6396e-01)	Acc@1  62.50 ( 73.30)	Acc@5  91.41 ( 95.27)
Epoch: [31][ 50/391]	Time  0.042 ( 0.045)	Data  0.001 ( 0.004)	Loss 7.8862e-01 (8.5820e-01)	Acc@1  77.34 ( 73.67)	Acc@5  97.66 ( 95.36)
Epoch: [31][ 60/391]	Time  0.041 ( 0.044)	Data  0.001 ( 0.003)	Loss 1.0288e+00 (8.6692e-01)	Acc@1  69.53 ( 73.40)	Acc@5  96.09 ( 95.30)
Epoch: [31][ 70/391]	Time  0.041 ( 0.044)	Data  0.001 ( 0.003)	Loss 8.1749e-01 (8.6499e-01)	Acc@1  74.22 ( 73.59)	Acc@5  96.09 ( 95.24)
Epoch: [31][ 80/391]	Time  0.042 ( 0.044)	Data  0.001 ( 0.003)	Loss 8.5749e-01 (8.6405e-01)	Acc@1  71.88 ( 73.72)	Acc@5  94.53 ( 95.10)
Epoch: [31][ 90/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.003)	Loss 7.4098e-01 (8.7160e-01)	Acc@1  77.34 ( 73.56)	Acc@5  97.66 ( 95.00)
Epoch: [31][100/391]	Time  0.045 ( 0.043)	Data  0.001 ( 0.002)	Loss 8.6727e-01 (8.7327e-01)	Acc@1  71.09 ( 73.48)	Acc@5  96.88 ( 94.96)
Epoch: [31][110/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 8.1133e-01 (8.7251e-01)	Acc@1  75.00 ( 73.43)	Acc@5  96.09 ( 95.00)
Epoch: [31][120/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 8.3341e-01 (8.7414e-01)	Acc@1  74.22 ( 73.34)	Acc@5  96.09 ( 94.97)
Epoch: [31][130/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 8.5888e-01 (8.7337e-01)	Acc@1  70.31 ( 73.39)	Acc@5  96.88 ( 95.00)
Epoch: [31][140/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 9.0415e-01 (8.7929e-01)	Acc@1  72.66 ( 73.29)	Acc@5  91.41 ( 94.89)
Epoch: [31][150/391]	Time  0.039 ( 0.043)	Data  0.001 ( 0.002)	Loss 9.7106e-01 (8.8214e-01)	Acc@1  73.44 ( 73.36)	Acc@5  93.75 ( 94.86)
Epoch: [31][160/391]	Time  0.045 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.0798e+00 (8.8800e-01)	Acc@1  67.19 ( 73.25)	Acc@5  93.75 ( 94.83)
Epoch: [31][170/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 9.4476e-01 (8.8972e-01)	Acc@1  66.41 ( 73.13)	Acc@5  95.31 ( 94.80)
Epoch: [31][180/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.0498e+00 (8.9043e-01)	Acc@1  70.31 ( 73.14)	Acc@5  92.97 ( 94.81)
Epoch: [31][190/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.002)	Loss 7.0798e-01 (8.9139e-01)	Acc@1  74.22 ( 73.15)	Acc@5  97.66 ( 94.80)
Epoch: [31][200/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 9.4934e-01 (8.9448e-01)	Acc@1  69.53 ( 73.04)	Acc@5  92.19 ( 94.66)
Epoch: [31][210/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 9.2170e-01 (8.9508e-01)	Acc@1  70.31 ( 72.97)	Acc@5  95.31 ( 94.69)
Epoch: [31][220/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 8.0495e-01 (8.9803e-01)	Acc@1  75.78 ( 72.92)	Acc@5  96.09 ( 94.62)
Epoch: [31][230/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.0524e+00 (9.0046e-01)	Acc@1  69.53 ( 72.86)	Acc@5  93.75 ( 94.61)
Epoch: [31][240/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.002)	Loss 8.8754e-01 (9.0004e-01)	Acc@1  78.91 ( 72.88)	Acc@5  93.75 ( 94.60)
Epoch: [31][250/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.002)	Loss 8.3583e-01 (9.0157e-01)	Acc@1  75.78 ( 72.86)	Acc@5  95.31 ( 94.59)
Epoch: [31][260/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 8.8738e-01 (8.9967e-01)	Acc@1  75.00 ( 72.94)	Acc@5  92.97 ( 94.61)
Epoch: [31][270/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.002)	Loss 9.5339e-01 (8.9885e-01)	Acc@1  71.09 ( 72.97)	Acc@5  94.53 ( 94.61)
Epoch: [31][280/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.1503e+00 (8.9855e-01)	Acc@1  60.16 ( 72.95)	Acc@5  89.06 ( 94.60)
Epoch: [31][290/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 8.9502e-01 (8.9750e-01)	Acc@1  76.56 ( 73.01)	Acc@5  94.53 ( 94.59)
Epoch: [31][300/391]	Time  0.046 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.0006e+00 (9.0082e-01)	Acc@1  75.78 ( 72.93)	Acc@5  90.62 ( 94.55)
Epoch: [31][310/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.001)	Loss 8.9068e-01 (9.0203e-01)	Acc@1  75.00 ( 72.88)	Acc@5  95.31 ( 94.53)
Epoch: [31][320/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.001)	Loss 9.5830e-01 (9.0508e-01)	Acc@1  68.75 ( 72.78)	Acc@5  94.53 ( 94.49)
Epoch: [31][330/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.001)	Loss 8.5660e-01 (9.0506e-01)	Acc@1  68.75 ( 72.74)	Acc@5  98.44 ( 94.51)
Epoch: [31][340/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.001)	Loss 9.9407e-01 (9.0749e-01)	Acc@1  68.75 ( 72.68)	Acc@5  94.53 ( 94.48)
Epoch: [31][350/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.001)	Loss 9.0287e-01 (9.1081e-01)	Acc@1  75.00 ( 72.60)	Acc@5  94.53 ( 94.44)
Epoch: [31][360/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.001)	Loss 8.5414e-01 (9.1143e-01)	Acc@1  78.91 ( 72.56)	Acc@5  93.75 ( 94.43)
Epoch: [31][370/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.0179e+00 (9.1429e-01)	Acc@1  71.09 ( 72.50)	Acc@5  93.75 ( 94.40)
Epoch: [31][380/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 9.2971e-01 (9.1447e-01)	Acc@1  68.75 ( 72.50)	Acc@5  91.41 ( 94.40)
Epoch: [31][390/391]	Time  0.030 ( 0.042)	Data  0.001 ( 0.001)	Loss 8.9066e-01 (9.1393e-01)	Acc@1  73.75 ( 72.51)	Acc@5  96.25 ( 94.41)
## e[31] optimizer.zero_grad (sum) time: 0.28525829315185547
## e[31]       loss.backward (sum) time: 4.2085607051849365
## e[31]      optimizer.step (sum) time: 1.8452763557434082
## epoch[31] training(only) time: 16.61928415298462
# Switched to evaluate mode...
Test: [  0/100]	Time  0.150 ( 0.150)	Loss 1.3829e+00 (1.3829e+00)	Acc@1  68.00 ( 68.00)	Acc@5  85.00 ( 85.00)
Test: [ 10/100]	Time  0.021 ( 0.033)	Loss 1.5090e+00 (1.5726e+00)	Acc@1  62.00 ( 61.55)	Acc@5  89.00 ( 86.09)
Test: [ 20/100]	Time  0.021 ( 0.028)	Loss 1.2509e+00 (1.4975e+00)	Acc@1  63.00 ( 61.76)	Acc@5  91.00 ( 87.52)
Test: [ 30/100]	Time  0.024 ( 0.027)	Loss 1.6412e+00 (1.5030e+00)	Acc@1  54.00 ( 61.10)	Acc@5  87.00 ( 87.55)
Test: [ 40/100]	Time  0.023 ( 0.025)	Loss 1.5437e+00 (1.4967e+00)	Acc@1  62.00 ( 61.02)	Acc@5  88.00 ( 87.85)
Test: [ 50/100]	Time  0.023 ( 0.024)	Loss 1.2914e+00 (1.4954e+00)	Acc@1  67.00 ( 61.04)	Acc@5  86.00 ( 87.41)
Test: [ 60/100]	Time  0.018 ( 0.023)	Loss 1.5068e+00 (1.4782e+00)	Acc@1  63.00 ( 61.13)	Acc@5  86.00 ( 87.52)
Test: [ 70/100]	Time  0.024 ( 0.023)	Loss 1.5544e+00 (1.4820e+00)	Acc@1  62.00 ( 61.13)	Acc@5  86.00 ( 87.42)
Test: [ 80/100]	Time  0.023 ( 0.023)	Loss 1.6292e+00 (1.4853e+00)	Acc@1  60.00 ( 61.15)	Acc@5  86.00 ( 87.49)
Test: [ 90/100]	Time  0.024 ( 0.023)	Loss 1.8754e+00 (1.4738e+00)	Acc@1  51.00 ( 61.52)	Acc@5  84.00 ( 87.74)
 * Acc@1 61.620 Acc@5 87.840
### epoch[31] execution time: 18.984227180480957
EPOCH 32
i:   0, name:           module.stem.0.weight  changing lr from: 0.025178003922785554   to: 0.022321178182447728
i:   1, name:             module.stem.0.bias  changing lr from: 0.025843194105596646   to: 0.022978623466462275
i:   2, name:           module.stem.1.weight  changing lr from: 0.026507839539321398   to: 0.023636707388760666
i:   3, name:             module.stem.1.bias  changing lr from: 0.027171692982877083   to: 0.024295141160509067
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.027834518080325905   to: 0.024953647863799878
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.028496089029063643   to: 0.025611962113519661
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.029156190254225268   to: 0.026269829724213246
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.029814616089436904   to: 0.026927007382186521
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.030471170464018562   to: 0.027583262323057731
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.031125666596720031   to: 0.028238372014938468
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.031777926696051631   to: 0.028892123847398612
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.032427781667251923   to: 0.029544314826343832
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.033075070825917714   to: 0.030194751274911537
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.033719641618305270   to: 0.030843248540469839
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.034361349348297231   to: 0.031489630707783843
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.035000056911016673   to: 0.032133730318396440
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.035635634533056841   to: 0.032775388096252821
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.036267959519285700   to: 0.033414452679584393
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.036896916006172745   to: 0.034050780359051923
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.037522394721577944   to: 0.034684234822136714
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.038144292750934131   to: 0.035314686903755686
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.038762513309747143   to: 0.035942014343066798
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.039376965522331685   to: 0.036566101546420753
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.039987564206695185   to: 0.037186839356407049
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.040594229665477155   to: 0.037804124826934342
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.041196887482846965   to: 0.038417861004277874
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.041795468327259618   to: 0.039027956714021268
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.042389907759965720   to: 0.039634326353813698
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.042980146049169103   to: 0.040236889691859165
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.043566127989723313   to: 0.040835571671049654
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.044147802728256781   to: 0.041430302218651113
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.044725123593614607   to: 0.042021016061447369
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.045298047932503950   to: 0.042607652546244462
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.045866536950229679   to: 0.043190155465635711
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.046430555556405878   to: 0.043768472888926019
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.046990072215529179   to: 0.044342556998112168
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.047545058802299978   to: 0.044912363928814800
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.048095490461577371   to: 0.045477853616057211
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.048641345472854931   to: 0.046038989644784832
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.049182605119144712   to: 0.046595739105019823
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.049719253560157869   to: 0.047148072451544475
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.050251277709671333   to: 0.047695963368007764
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.050778667116971134   to: 0.048239388635349149
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.051301413852264499   to: 0.048778328004435240
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.051819512395953671   to: 0.049312764072804487
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.052332959531666813   to: 0.049842682165416985
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.052841754242941789   to: 0.050368070219306504
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.053345897613461694   to: 0.050888918672034281
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.053845392730741154   to: 0.051405220353843296
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.054340244593165533   to: 0.051916970383415695
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.054830460020286298   to: 0.052424166067134750
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.055316047566277608   to: 0.052926806801756425
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.055797017436461628   to: 0.053424893980395655
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.056273381406811387   to: 0.053918430901734975
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.056745152746342280   to: 0.054407422682364204
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.057212346142304853   to: 0.054891876172161583
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.057674977628094405   to: 0.055371799872629184
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.058133064513793312   to: 0.055847203858096155
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.058586625319265666   to: 0.056318099699705818
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.059035679709724224   to: 0.056784500392103900
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.059480248433692963   to: 0.057246420282747915
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.059920353263289074   to: 0.057703875003757787
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.060356016936751404   to: 0.058156881406231570
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.060787263103143196   to: 0.058605457496950446
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.061214116269159673   to: 0.059049622377399594
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.061636601747972170   to: 0.059489396185033266
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.062054745610042789   to: 0.059924800036713959
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.062468574635845091   to: 0.060355855974257300
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.062878116270428233   to: 0.060782586912016615
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.063283398579763533   to: 0.061205016586441612
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.063684450208814511   to: 0.061623169507548814
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.064081300341272282   to: 0.062037070912241511
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.064473978660901252   to: 0.062446746719420188
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.064862515314439900   to: 0.062852223486824371
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.065246940876004592   to: 0.063253528369550102
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.065627286312944941   to: 0.063650689080187242
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.066003582953101117   to: 0.064043733850523643
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.066375862453414688   to: 0.064432691394763736
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.066744156769846685   to: 0.064817590874211226
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.067108498128557223   to: 0.065198461863367002
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.067468918998302527   to: 0.065575334317393805
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.067825452064007349   to: 0.065948238540902468
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.068178130201470719   to: 0.066317205158013925
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.068526986453165725   to: 0.066682265083653755
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.068872054005093872   to: 0.067043449496036897
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.069213366164656828   to: 0.067400789810301731
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.069550956339509293   to: 0.067754317653253224
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.069884858017357249   to: 0.068104064839177150
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.070215104746667978   to: 0.068450063346687615
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.070541730118258580   to: 0.068792345296571744
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.070864767747731136   to: 0.069130942930596559
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.071184251258723394   to: 0.069465888591243669
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.071500214266945403   to: 0.069797214702339239
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.071812690364972787   to: 0.070124953750546989
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.072121713107768978   to: 0.070449138267693556
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.072427315998909031   to: 0.070769800813895944
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.072729532477479111   to: 0.071086973961462588
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.073028395905626223   to: 0.071400690279539561
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.073323939556733678   to: 0.071710982319474981
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.073616196604198686   to: 0.072017882600875271
i: 100, name:           module.conv10.weight  changing lr from: 0.073905200110789313   to: 0.072321423598328063
i: 101, name:             module.conv10.bias  changing lr from: 0.074190983018558629   to: 0.072621637728766827



# Switched to train mode...
Epoch: [32][  0/391]	Time  0.188 ( 0.188)	Data  0.143 ( 0.143)	Loss 8.1849e-01 (8.1849e-01)	Acc@1  75.00 ( 75.00)	Acc@5  98.44 ( 98.44)
Epoch: [32][ 10/391]	Time  0.041 ( 0.056)	Data  0.001 ( 0.014)	Loss 6.5843e-01 (7.8860e-01)	Acc@1  77.34 ( 75.85)	Acc@5  96.09 ( 96.45)
Epoch: [32][ 20/391]	Time  0.041 ( 0.050)	Data  0.001 ( 0.008)	Loss 7.1235e-01 (7.8777e-01)	Acc@1  79.69 ( 76.23)	Acc@5  98.44 ( 96.43)
Epoch: [32][ 30/391]	Time  0.040 ( 0.047)	Data  0.001 ( 0.006)	Loss 7.5501e-01 (7.9975e-01)	Acc@1  78.91 ( 75.53)	Acc@5  94.53 ( 96.27)
Epoch: [32][ 40/391]	Time  0.043 ( 0.046)	Data  0.001 ( 0.004)	Loss 8.5461e-01 (8.1421e-01)	Acc@1  75.00 ( 75.50)	Acc@5  95.31 ( 95.83)
Epoch: [32][ 50/391]	Time  0.040 ( 0.045)	Data  0.001 ( 0.004)	Loss 7.8681e-01 (8.1890e-01)	Acc@1  79.69 ( 75.37)	Acc@5  96.09 ( 95.83)
Epoch: [32][ 60/391]	Time  0.046 ( 0.044)	Data  0.001 ( 0.003)	Loss 8.9566e-01 (8.1713e-01)	Acc@1  71.09 ( 75.12)	Acc@5  92.97 ( 95.82)
Epoch: [32][ 70/391]	Time  0.042 ( 0.044)	Data  0.001 ( 0.003)	Loss 9.4144e-01 (8.2216e-01)	Acc@1  72.66 ( 75.25)	Acc@5  92.97 ( 95.61)
Epoch: [32][ 80/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.003)	Loss 7.1630e-01 (8.2260e-01)	Acc@1  79.69 ( 75.20)	Acc@5  95.31 ( 95.65)
Epoch: [32][ 90/391]	Time  0.039 ( 0.043)	Data  0.001 ( 0.003)	Loss 7.2798e-01 (8.2864e-01)	Acc@1  74.22 ( 74.94)	Acc@5  96.09 ( 95.53)
Epoch: [32][100/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.002)	Loss 8.7662e-01 (8.3012e-01)	Acc@1  69.53 ( 74.78)	Acc@5  95.31 ( 95.52)
Epoch: [32][110/391]	Time  0.044 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.0139e+00 (8.3166e-01)	Acc@1  64.84 ( 74.69)	Acc@5  91.41 ( 95.46)
Epoch: [32][120/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 8.5454e-01 (8.3754e-01)	Acc@1  71.09 ( 74.57)	Acc@5  92.97 ( 95.34)
Epoch: [32][130/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.002)	Loss 8.0337e-01 (8.4159e-01)	Acc@1  78.12 ( 74.48)	Acc@5  95.31 ( 95.32)
Epoch: [32][140/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.0498e+00 (8.5066e-01)	Acc@1  71.09 ( 74.33)	Acc@5  92.97 ( 95.16)
Epoch: [32][150/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.002)	Loss 6.8436e-01 (8.5131e-01)	Acc@1  75.00 ( 74.28)	Acc@5  97.66 ( 95.16)
Epoch: [32][160/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.002)	Loss 9.2101e-01 (8.5152e-01)	Acc@1  72.66 ( 74.32)	Acc@5  91.41 ( 95.16)
Epoch: [32][170/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.002)	Loss 8.7008e-01 (8.5403e-01)	Acc@1  71.88 ( 74.36)	Acc@5  93.75 ( 95.10)
Epoch: [32][180/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.002)	Loss 9.0574e-01 (8.5532e-01)	Acc@1  75.00 ( 74.29)	Acc@5  94.53 ( 95.04)
Epoch: [32][190/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 9.7401e-01 (8.6235e-01)	Acc@1  74.22 ( 74.20)	Acc@5  95.31 ( 94.91)
Epoch: [32][200/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 9.9331e-01 (8.6649e-01)	Acc@1  68.75 ( 74.13)	Acc@5  94.53 ( 94.88)
Epoch: [32][210/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.5654e-01 (8.6696e-01)	Acc@1  82.81 ( 74.08)	Acc@5  95.31 ( 94.87)
Epoch: [32][220/391]	Time  0.045 ( 0.042)	Data  0.001 ( 0.002)	Loss 9.2156e-01 (8.6615e-01)	Acc@1  75.00 ( 74.12)	Acc@5  93.75 ( 94.87)
Epoch: [32][230/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 9.2537e-01 (8.6835e-01)	Acc@1  73.44 ( 74.03)	Acc@5  94.53 ( 94.85)
Epoch: [32][240/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 8.6323e-01 (8.7006e-01)	Acc@1  75.78 ( 73.99)	Acc@5  95.31 ( 94.80)
Epoch: [32][250/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.0458e+00 (8.7082e-01)	Acc@1  71.88 ( 73.98)	Acc@5  91.41 ( 94.78)
Epoch: [32][260/391]	Time  0.037 ( 0.042)	Data  0.001 ( 0.002)	Loss 7.1733e-01 (8.7169e-01)	Acc@1  78.12 ( 73.90)	Acc@5  96.09 ( 94.79)
Epoch: [32][270/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 9.0947e-01 (8.7026e-01)	Acc@1  75.78 ( 73.92)	Acc@5  95.31 ( 94.81)
Epoch: [32][280/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 7.8888e-01 (8.7090e-01)	Acc@1  75.78 ( 73.88)	Acc@5  94.53 ( 94.80)
Epoch: [32][290/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.002)	Loss 9.1259e-01 (8.7328e-01)	Acc@1  71.09 ( 73.78)	Acc@5  96.09 ( 94.78)
Epoch: [32][300/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.9068e-01 (8.7521e-01)	Acc@1  79.69 ( 73.75)	Acc@5  95.31 ( 94.73)
Epoch: [32][310/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.0529e+00 (8.7766e-01)	Acc@1  69.53 ( 73.69)	Acc@5  90.62 ( 94.69)
Epoch: [32][320/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 8.5542e-01 (8.8036e-01)	Acc@1  74.22 ( 73.61)	Acc@5  96.09 ( 94.66)
Epoch: [32][330/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 7.2128e-01 (8.8103e-01)	Acc@1  76.56 ( 73.60)	Acc@5  96.88 ( 94.67)
Epoch: [32][340/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.001)	Loss 7.8933e-01 (8.8137e-01)	Acc@1  75.78 ( 73.56)	Acc@5  96.09 ( 94.66)
Epoch: [32][350/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.0425e+00 (8.8229e-01)	Acc@1  69.53 ( 73.54)	Acc@5  94.53 ( 94.65)
Epoch: [32][360/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.0393e+00 (8.8499e-01)	Acc@1  71.09 ( 73.49)	Acc@5  92.19 ( 94.60)
Epoch: [32][370/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 8.8136e-01 (8.8582e-01)	Acc@1  71.88 ( 73.45)	Acc@5  93.75 ( 94.58)
Epoch: [32][380/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.001)	Loss 8.1494e-01 (8.8690e-01)	Acc@1  72.66 ( 73.41)	Acc@5  97.66 ( 94.57)
Epoch: [32][390/391]	Time  0.029 ( 0.042)	Data  0.001 ( 0.001)	Loss 8.8473e-01 (8.8729e-01)	Acc@1  70.00 ( 73.41)	Acc@5  97.50 ( 94.57)
## e[32] optimizer.zero_grad (sum) time: 0.2858288288116455
## e[32]       loss.backward (sum) time: 4.127503156661987
## e[32]      optimizer.step (sum) time: 1.8749442100524902
## epoch[32] training(only) time: 16.383225202560425
# Switched to evaluate mode...
Test: [  0/100]	Time  0.153 ( 0.153)	Loss 1.3271e+00 (1.3271e+00)	Acc@1  64.00 ( 64.00)	Acc@5  86.00 ( 86.00)
Test: [ 10/100]	Time  0.019 ( 0.033)	Loss 1.4678e+00 (1.4041e+00)	Acc@1  66.00 ( 65.09)	Acc@5  89.00 ( 87.36)
Test: [ 20/100]	Time  0.022 ( 0.028)	Loss 1.2238e+00 (1.4014e+00)	Acc@1  66.00 ( 64.52)	Acc@5  90.00 ( 88.24)
Test: [ 30/100]	Time  0.021 ( 0.025)	Loss 1.5032e+00 (1.4267e+00)	Acc@1  60.00 ( 63.52)	Acc@5  88.00 ( 88.00)
Test: [ 40/100]	Time  0.024 ( 0.024)	Loss 1.5776e+00 (1.4162e+00)	Acc@1  58.00 ( 63.29)	Acc@5  90.00 ( 88.24)
Test: [ 50/100]	Time  0.022 ( 0.023)	Loss 1.3865e+00 (1.4192e+00)	Acc@1  67.00 ( 63.08)	Acc@5  85.00 ( 88.00)
Test: [ 60/100]	Time  0.021 ( 0.023)	Loss 1.3171e+00 (1.4040e+00)	Acc@1  71.00 ( 63.39)	Acc@5  85.00 ( 88.26)
Test: [ 70/100]	Time  0.024 ( 0.023)	Loss 1.5701e+00 (1.4122e+00)	Acc@1  62.00 ( 63.41)	Acc@5  88.00 ( 88.24)
Test: [ 80/100]	Time  0.031 ( 0.023)	Loss 1.5637e+00 (1.4233e+00)	Acc@1  57.00 ( 63.05)	Acc@5  83.00 ( 88.11)
Test: [ 90/100]	Time  0.021 ( 0.023)	Loss 1.7003e+00 (1.4097e+00)	Acc@1  55.00 ( 63.42)	Acc@5  85.00 ( 88.24)
 * Acc@1 63.690 Acc@5 88.420
### epoch[32] execution time: 18.71596384048462
EPOCH 33
i:   0, name:           module.stem.0.weight  changing lr from: 0.022321178182447728   to: 0.019597602646433312
i:   1, name:             module.stem.0.bias  changing lr from: 0.022978623466462275   to: 0.020242350750805591
i:   2, name:           module.stem.1.weight  changing lr from: 0.023636707388760666   to: 0.020889038468312839
i:   3, name:             module.stem.1.bias  changing lr from: 0.024295141160509067   to: 0.021537334014075010
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.024953647863799878   to: 0.022186918400243116
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.025611962113519661   to: 0.022837485098150173
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.026269829724213246   to: 0.023488739703830298
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.026927007382186521   to: 0.024140399607280295
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.027583262323057731   to: 0.024792193665799035
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.028238372014938468   to: 0.025443861881702973
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.028892123847398612   to: 0.026095155084682138
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.029544314826343832   to: 0.026745834619029119
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.030194751274911537   to: 0.027395672035943675
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.030843248540469839   to: 0.028044448791088805
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.031489630707783843   to: 0.028691955947547615
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.032133730318396440   to: 0.029337993884308133
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.032775388096252821   to: 0.029982372010379645
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.033414452679584393   to: 0.030624908484625981
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.034050780359051923   to: 0.031265429941380651
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.034684234822136714   to: 0.031903771221892856
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.035314686903755686   to: 0.032539775111637213
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.035942014343066798   to: 0.033173292083505654
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.036566101546420753   to: 0.033804180046886442
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.037186839356407049   to: 0.034432304102623726
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.037804124826934342   to: 0.035057536303839190
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.038417861004277874   to: 0.035679755422588035
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.039027956714021268   to: 0.036298846722311907
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.039634326353813698   to: 0.036914701736043352
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.040236889691859165   to: 0.037527218050309015
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.040835571671049654   to: 0.038136299094671401
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.041430302218651113   to: 0.038741853936844109
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.042021016061447369   to: 0.039343797083309331
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.042607652546244462   to: 0.039942048285361666
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.043190155465635711   to: 0.040536532350498596
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.043768472888926019   to: 0.041127178959073800
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.044342556998112168   to: 0.041713922486126639
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.044912363928814800   to: 0.042296701828298401
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.045477853616057211   to: 0.042875460235743366
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.046038989644784832   to: 0.043450145148940966
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.046595739105019823   to: 0.044020708040314001
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.047148072451544475   to: 0.044587104260556107
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.047695963368007764   to: 0.045149292889571237
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.048239388635349149   to: 0.045707236591926825
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.048778328004435240   to: 0.046260901476722426
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.049312764072804487   to: 0.046810256961774800
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.049842682165416985   to: 0.047355275642021084
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.050368070219306504   to: 0.047895933162041208
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.050888918672034281   to: 0.048432208092602187
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.051405220353843296   to: 0.048964081811126173
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.051916970383415695   to: 0.049491538385985842
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.052424166067134750   to: 0.050014564464531334
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.052926806801756425   to: 0.050533149164753301
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.053424893980395655   to: 0.051047283970488938
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.053918430901734975   to: 0.051556962630077488
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.054407422682364204   to: 0.052062181058374429
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.054891876172161583   to: 0.052562937242033383
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.055371799872629184   to: 0.053059231147967970
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.055847203858096155   to: 0.053551064634905110
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.056318099699705818   to: 0.054038441367944945
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.056784500392103900   to: 0.054521366736042048
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.057246420282747915   to: 0.054999847772326055
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.057703875003757787   to: 0.055473893077179662
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.058156881406231570   to: 0.055943512743994894
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.058605457496950446   to: 0.056408718287529351
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.059049622377399594   to: 0.056869522574786308
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.059489396185033266   to: 0.057325939758343714
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.059924800036713959   to: 0.057777985212059284
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.060355855974257300   to: 0.058225675469079724
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.060782586912016615   to: 0.058669028162085114
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.061205016586441612   to: 0.059108061965699399
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.061623169507548814   to: 0.059542796541001287
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.062037070912241511   to: 0.059973252482069819
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.062446746719420188   to: 0.060399451264502205
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.062852223486824371   to: 0.060821415195841291
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.063253528369550102   to: 0.061239167367853321
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.063650689080187242   to: 0.061652731610596770
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.064043733850523643   to: 0.062062132448225685
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.064432691394763736   to: 0.062467395056471364
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.064817590874211226   to: 0.062868545221749089
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.065198461863367002   to: 0.063265609301836695
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.065575334317393805   to: 0.063658614188073809
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.065948238540902468   to: 0.064047587269032619
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.066317205158013925   to: 0.064432556395611004
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.066682265083653755   to: 0.064813549847501623
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.067043449496036897   to: 0.065190596300990819
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.067400789810301731   to: 0.065563724798043496
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.067754317653253224   to: 0.065932964716630460
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.068104064839177150   to: 0.066298345742256418
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.068450063346687615   to: 0.066659897840648394
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.068792345296571744   to: 0.067017651231564737
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.069130942930596559   to: 0.067371636363686663
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.069465888591243669   to: 0.067721883890555321
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.069797214702339239   to: 0.068068424647518236
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.070124953750546989   to: 0.068411289629650290
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.070449138267693556   to: 0.068750509970615645
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.070769800813895944   to: 0.069086116922437310
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.071086973961462588   to: 0.069418141836143296
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.071400690279539561   to: 0.069746616143257764
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.071710982319474981   to: 0.070071571338108027
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.072017882600875271   to: 0.070393038960918114
i: 100, name:           module.conv10.weight  changing lr from: 0.072321423598328063   to: 0.070711050581660981
i: 101, name:             module.conv10.bias  changing lr from: 0.072621637728766827   to: 0.071025637784642381



# Switched to train mode...
Epoch: [33][  0/391]	Time  0.188 ( 0.188)	Data  0.143 ( 0.143)	Loss 8.7988e-01 (8.7988e-01)	Acc@1  71.88 ( 71.88)	Acc@5  96.88 ( 96.88)
Epoch: [33][ 10/391]	Time  0.040 ( 0.056)	Data  0.001 ( 0.014)	Loss 9.1221e-01 (8.2253e-01)	Acc@1  73.44 ( 75.57)	Acc@5  92.97 ( 95.53)
Epoch: [33][ 20/391]	Time  0.039 ( 0.048)	Data  0.001 ( 0.008)	Loss 8.0324e-01 (7.9599e-01)	Acc@1  77.34 ( 76.53)	Acc@5  93.75 ( 95.61)
Epoch: [33][ 30/391]	Time  0.040 ( 0.046)	Data  0.001 ( 0.006)	Loss 1.0234e+00 (8.0256e-01)	Acc@1  70.31 ( 76.39)	Acc@5  92.19 ( 95.31)
Epoch: [33][ 40/391]	Time  0.039 ( 0.044)	Data  0.001 ( 0.005)	Loss 9.5161e-01 (8.1466e-01)	Acc@1  66.41 ( 75.88)	Acc@5  93.75 ( 95.26)
Epoch: [33][ 50/391]	Time  0.040 ( 0.044)	Data  0.001 ( 0.004)	Loss 9.9986e-01 (8.1516e-01)	Acc@1  67.97 ( 75.72)	Acc@5  95.31 ( 95.39)
Epoch: [33][ 60/391]	Time  0.041 ( 0.044)	Data  0.001 ( 0.003)	Loss 6.7449e-01 (8.1869e-01)	Acc@1  82.03 ( 75.44)	Acc@5  95.31 ( 95.31)
Epoch: [33][ 70/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.003)	Loss 9.2459e-01 (8.1903e-01)	Acc@1  71.09 ( 75.34)	Acc@5  95.31 ( 95.43)
Epoch: [33][ 80/391]	Time  0.044 ( 0.043)	Data  0.001 ( 0.003)	Loss 8.1774e-01 (8.2691e-01)	Acc@1  76.56 ( 75.22)	Acc@5  92.97 ( 95.30)
Epoch: [33][ 90/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.003)	Loss 9.4007e-01 (8.3270e-01)	Acc@1  70.31 ( 75.10)	Acc@5  93.75 ( 95.24)
Epoch: [33][100/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.002)	Loss 8.4853e-01 (8.3170e-01)	Acc@1  73.44 ( 75.05)	Acc@5  94.53 ( 95.30)
Epoch: [33][110/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.002)	Loss 6.4866e-01 (8.3302e-01)	Acc@1  80.47 ( 75.01)	Acc@5  96.88 ( 95.27)
Epoch: [33][120/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 9.5316e-01 (8.3774e-01)	Acc@1  68.75 ( 74.77)	Acc@5  95.31 ( 95.25)
Epoch: [33][130/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.0122e+00 (8.3862e-01)	Acc@1  71.88 ( 74.71)	Acc@5  93.75 ( 95.23)
Epoch: [33][140/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 7.9128e-01 (8.3861e-01)	Acc@1  78.12 ( 74.70)	Acc@5  93.75 ( 95.26)
Epoch: [33][150/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.0494e+00 (8.3887e-01)	Acc@1  68.75 ( 74.69)	Acc@5  95.31 ( 95.26)
Epoch: [33][160/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 9.1515e-01 (8.4142e-01)	Acc@1  71.09 ( 74.60)	Acc@5  92.97 ( 95.26)
Epoch: [33][170/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 9.2144e-01 (8.4705e-01)	Acc@1  68.75 ( 74.49)	Acc@5  96.09 ( 95.14)
Epoch: [33][180/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 8.3108e-01 (8.4887e-01)	Acc@1  71.09 ( 74.39)	Acc@5  96.09 ( 95.11)
Epoch: [33][190/391]	Time  0.037 ( 0.042)	Data  0.001 ( 0.002)	Loss 9.9022e-01 (8.5103e-01)	Acc@1  71.09 ( 74.29)	Acc@5  92.19 ( 95.12)
Epoch: [33][200/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.1009e+00 (8.5117e-01)	Acc@1  73.44 ( 74.36)	Acc@5  89.84 ( 95.11)
Epoch: [33][210/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 9.4108e-01 (8.5198e-01)	Acc@1  71.88 ( 74.38)	Acc@5  93.75 ( 95.07)
Epoch: [33][220/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.0908e+00 (8.5428e-01)	Acc@1  68.75 ( 74.30)	Acc@5  90.62 ( 95.02)
Epoch: [33][230/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 7.0346e-01 (8.5148e-01)	Acc@1  76.56 ( 74.40)	Acc@5  96.88 ( 95.01)
Epoch: [33][240/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 8.3070e-01 (8.5289e-01)	Acc@1  72.66 ( 74.34)	Acc@5  95.31 ( 94.98)
Epoch: [33][250/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 8.0425e-01 (8.5103e-01)	Acc@1  75.00 ( 74.38)	Acc@5  96.88 ( 95.00)
Epoch: [33][260/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 8.8998e-01 (8.5319e-01)	Acc@1  69.53 ( 74.30)	Acc@5  94.53 ( 94.99)
Epoch: [33][270/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 9.3248e-01 (8.5167e-01)	Acc@1  73.44 ( 74.33)	Acc@5  94.53 ( 95.02)
Epoch: [33][280/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.002)	Loss 8.5728e-01 (8.5316e-01)	Acc@1  72.66 ( 74.29)	Acc@5  96.09 ( 95.02)
Epoch: [33][290/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 8.6918e-01 (8.5523e-01)	Acc@1  75.78 ( 74.24)	Acc@5  96.88 ( 94.99)
Epoch: [33][300/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 8.2682e-01 (8.5470e-01)	Acc@1  76.56 ( 74.28)	Acc@5  93.75 ( 94.97)
Epoch: [33][310/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 7.5301e-01 (8.5510e-01)	Acc@1  75.78 ( 74.27)	Acc@5  96.09 ( 94.97)
Epoch: [33][320/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 7.9245e-01 (8.5301e-01)	Acc@1  73.44 ( 74.29)	Acc@5  94.53 ( 94.99)
Epoch: [33][330/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.001)	Loss 7.5651e-01 (8.5540e-01)	Acc@1  78.91 ( 74.20)	Acc@5  98.44 ( 94.98)
Epoch: [33][340/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.001)	Loss 8.3837e-01 (8.5580e-01)	Acc@1  75.78 ( 74.18)	Acc@5  93.75 ( 94.98)
Epoch: [33][350/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.001)	Loss 8.9392e-01 (8.5808e-01)	Acc@1  71.88 ( 74.09)	Acc@5  93.75 ( 94.97)
Epoch: [33][360/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 9.3991e-01 (8.5914e-01)	Acc@1  70.31 ( 74.07)	Acc@5  95.31 ( 94.94)
Epoch: [33][370/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.001)	Loss 9.8730e-01 (8.6038e-01)	Acc@1  71.88 ( 74.03)	Acc@5  93.75 ( 94.93)
Epoch: [33][380/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.1949e+00 (8.6139e-01)	Acc@1  67.19 ( 74.02)	Acc@5  90.62 ( 94.91)
Epoch: [33][390/391]	Time  0.029 ( 0.041)	Data  0.001 ( 0.001)	Loss 9.1655e-01 (8.6256e-01)	Acc@1  65.00 ( 73.95)	Acc@5  93.75 ( 94.90)
## e[33] optimizer.zero_grad (sum) time: 0.2848937511444092
## e[33]       loss.backward (sum) time: 4.103742837905884
## e[33]      optimizer.step (sum) time: 1.8818261623382568
## epoch[33] training(only) time: 16.30506205558777
# Switched to evaluate mode...
Test: [  0/100]	Time  0.154 ( 0.154)	Loss 1.1747e+00 (1.1747e+00)	Acc@1  63.00 ( 63.00)	Acc@5  91.00 ( 91.00)
Test: [ 10/100]	Time  0.020 ( 0.034)	Loss 1.6543e+00 (1.5474e+00)	Acc@1  57.00 ( 61.36)	Acc@5  90.00 ( 86.55)
Test: [ 20/100]	Time  0.021 ( 0.028)	Loss 1.3185e+00 (1.5362e+00)	Acc@1  65.00 ( 61.19)	Acc@5  85.00 ( 86.52)
Test: [ 30/100]	Time  0.021 ( 0.026)	Loss 1.7253e+00 (1.5488e+00)	Acc@1  53.00 ( 60.71)	Acc@5  86.00 ( 86.23)
Test: [ 40/100]	Time  0.024 ( 0.025)	Loss 1.7199e+00 (1.5565e+00)	Acc@1  55.00 ( 60.37)	Acc@5  88.00 ( 86.46)
Test: [ 50/100]	Time  0.024 ( 0.025)	Loss 1.5273e+00 (1.5731e+00)	Acc@1  62.00 ( 59.69)	Acc@5  87.00 ( 86.14)
Test: [ 60/100]	Time  0.020 ( 0.024)	Loss 1.5796e+00 (1.5585e+00)	Acc@1  56.00 ( 59.70)	Acc@5  84.00 ( 86.52)
Test: [ 70/100]	Time  0.020 ( 0.024)	Loss 1.6766e+00 (1.5588e+00)	Acc@1  61.00 ( 59.80)	Acc@5  80.00 ( 86.49)
Test: [ 80/100]	Time  0.024 ( 0.024)	Loss 1.7171e+00 (1.5767e+00)	Acc@1  59.00 ( 59.62)	Acc@5  85.00 ( 86.28)
Test: [ 90/100]	Time  0.018 ( 0.023)	Loss 1.9952e+00 (1.5731e+00)	Acc@1  50.00 ( 59.89)	Acc@5  85.00 ( 86.37)
 * Acc@1 60.190 Acc@5 86.610
### epoch[33] execution time: 18.67325758934021
EPOCH 34
i:   0, name:           module.stem.0.weight  changing lr from: 0.019597602646433312   to: 0.017019931844240544
i:   1, name:             module.stem.0.bias  changing lr from: 0.020242350750805591   to: 0.017646904183536174
i:   2, name:           module.stem.1.weight  changing lr from: 0.020889038468312839   to: 0.018277230265554358
i:   3, name:             module.stem.1.bias  changing lr from: 0.021537334014075010   to: 0.018910534290135752
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.022186918400243116   to: 0.019546454097042126
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.022837485098150173   to: 0.020184640836026863
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.023488739703830298   to: 0.020824758638202597
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.024140399607280295   to: 0.021466484289233319
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.024792193665799035   to: 0.022109506904831069
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.025443861881702973   to: 0.022753527608991572
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.026095155084682138   to: 0.023398259215362201
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.026745834619029119   to: 0.024043425912095896
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.027395672035943675   to: 0.024688762950507450
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.028044448791088805   to: 0.025334016337816054
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.028691955947547615   to: 0.025978942534223805
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.029337993884308133   to: 0.026623308154552595
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.029982372010379645   to: 0.027266889674631752
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.030624908484625981   to: 0.027909473142605543
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.031265429941380651   to: 0.028550853895303666
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.031903771221892856   to: 0.029190836279797284
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.032539775111637213   to: 0.029829233380241682
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.033173292083505654   to: 0.030465866750088590
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.033804180046886442   to: 0.031100566149732656
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.034432304102623726   to: 0.031733169289641677
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.035057536303839190   to: 0.032363521579004184
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.035679755422588035   to: 0.032991475879915112
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.036298846722311907   to: 0.033616892267107359
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.036914701736043352   to: 0.034239637793226023
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.037527218050309015   to: 0.034859586259630940
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.038136299094671401   to: 0.035476617992704088
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.038741853936844109   to: 0.036090619625629809
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.039343797083309331   to: 0.036701483885607622
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.039942048285361666   to: 0.037309109386450316
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.040536532350498596   to: 0.037913400426513824
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.041127178959073800   to: 0.038514266791899343
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.041713922486126639   to: 0.039111623564863238
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.042296701828298401   to: 0.039705390937365637
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.042875460235743366   to: 0.040295494029684423
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.043450145148940966   to: 0.040881862714017864
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.044020708040314001   to: 0.041464431442996372
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.044587104260556107   to: 0.042043139083020334
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.045149292889571237   to: 0.042617928752339995
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.045707236591926825   to: 0.043188747663789745
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.046260901476722426   to: 0.043755546972089554
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.046810256961774800   to: 0.044318281625623124
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.047355275642021084   to: 0.044876910222602900
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.047895933162041208   to: 0.045431394871529987
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.048432208092602187   to: 0.045981701055858165
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.048964081811126173   to: 0.046527797502768968
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.049491538385985842   to: 0.047069656055966594
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.050014564464531334   to: 0.047607251552400157
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.050533149164753301   to: 0.048140561702821959
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.051047283970488938   to: 0.048669566976090532
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.051556962630077488   to: 0.049194250487127694
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.052062181058374429   to: 0.049714597888440071
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.052562937242033383   to: 0.050230597265115376
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.053059231147967970   to: 0.050742239033206238
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.053551064634905110   to: 0.051249515841413587
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.054038441367944945   to: 0.051752422475984189
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.054521366736042048   to: 0.052250955768737034
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.054999847772326055   to: 0.052745114508135515
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.055473893077179662   to: 0.053234899353322596
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.055943512743994894   to: 0.053720312751038141
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.056408718287529351   to: 0.054201358855339013
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.056869522574786308   to: 0.054678043450043526
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.057325939758343714   to: 0.055150373873823814
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.057777985212059284   to: 0.055618358947870400
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.058225675469079724   to: 0.056082008906055705
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.058669028162085114   to: 0.056541335327523951
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.059108061965699399   to: 0.056996351071636711
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.059542796541001287   to: 0.057447070215205023
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.059973252482069819   to: 0.057893507991940124
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.060399451264502205   to: 0.058335680734056865
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.060821415195841291   to: 0.058773605815964872
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.061239167367853321   to: 0.059207301599984552
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.061652731610596770   to: 0.059636787384026058
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.062062132448225685   to: 0.060062083351171053
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.062467395056471364   to: 0.060483210521098708
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.062868545221749089   to: 0.060900190703298634
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.063265609301836695   to: 0.061313046452014880
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.063658614188073809   to: 0.061721801022866653
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.064047587269032619   to: 0.062126478331092985
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.064432556395611004   to: 0.062527102911369467
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.064813549847501623   to: 0.062923699879147227
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.065190596300990819   to: 0.063316294893464825
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.065563724798043496   to: 0.063704914121186201
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.065932964716630460   to: 0.064089584202617664
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.066298345742256418   to: 0.064470332218459769
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.066659897840648394   to: 0.064847185658049769
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.067017651231564737   to: 0.065220172388852471
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.067371636363686663   to: 0.065589320627158373
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.067721883890555321   to: 0.065954658909948505
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.068068424647518236   to: 0.066316216067887818
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.068411289629650290   to: 0.066674021199408420
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.068750509970615645   to: 0.067028103645846882
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.069086116922437310   to: 0.067378492967599304
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.069418141836143296   to: 0.067725218921259878
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.069746616143257764   to: 0.068068311437709708
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.070071571338108027   to: 0.068407800601122615
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.070393038960918114   to: 0.068743716628857296
i: 100, name:           module.conv10.weight  changing lr from: 0.070711050581660981   to: 0.069076089852204522
i: 101, name:             module.conv10.bias  changing lr from: 0.071025637784642381   to: 0.069404950697960252



# Switched to train mode...
Epoch: [34][  0/391]	Time  0.208 ( 0.208)	Data  0.157 ( 0.157)	Loss 7.5270e-01 (7.5270e-01)	Acc@1  75.78 ( 75.78)	Acc@5  94.53 ( 94.53)
Epoch: [34][ 10/391]	Time  0.040 ( 0.057)	Data  0.001 ( 0.015)	Loss 7.4312e-01 (7.9085e-01)	Acc@1  72.66 ( 76.49)	Acc@5  97.66 ( 95.45)
Epoch: [34][ 20/391]	Time  0.040 ( 0.050)	Data  0.001 ( 0.008)	Loss 8.1355e-01 (8.1408e-01)	Acc@1  74.22 ( 75.93)	Acc@5  94.53 ( 95.24)
Epoch: [34][ 30/391]	Time  0.042 ( 0.048)	Data  0.001 ( 0.006)	Loss 5.3306e-01 (8.1357e-01)	Acc@1  84.38 ( 75.60)	Acc@5  98.44 ( 95.29)
Epoch: [34][ 40/391]	Time  0.038 ( 0.046)	Data  0.001 ( 0.005)	Loss 6.6624e-01 (8.0667e-01)	Acc@1  81.25 ( 75.63)	Acc@5  95.31 ( 95.54)
Epoch: [34][ 50/391]	Time  0.042 ( 0.045)	Data  0.001 ( 0.004)	Loss 7.7715e-01 (8.0015e-01)	Acc@1  74.22 ( 75.67)	Acc@5  97.66 ( 95.65)
Epoch: [34][ 60/391]	Time  0.041 ( 0.044)	Data  0.001 ( 0.004)	Loss 6.6872e-01 (7.9959e-01)	Acc@1  82.03 ( 75.78)	Acc@5  97.66 ( 95.59)
Epoch: [34][ 70/391]	Time  0.037 ( 0.044)	Data  0.001 ( 0.003)	Loss 8.4818e-01 (8.0268e-01)	Acc@1  75.00 ( 75.55)	Acc@5  96.88 ( 95.66)
Epoch: [34][ 80/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.003)	Loss 8.2920e-01 (8.0489e-01)	Acc@1  76.56 ( 75.46)	Acc@5  96.88 ( 95.57)
Epoch: [34][ 90/391]	Time  0.044 ( 0.043)	Data  0.001 ( 0.003)	Loss 9.0572e-01 (8.0791e-01)	Acc@1  69.53 ( 75.33)	Acc@5  96.88 ( 95.56)
Epoch: [34][100/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.003)	Loss 6.2333e-01 (8.0807e-01)	Acc@1  80.47 ( 75.41)	Acc@5  98.44 ( 95.56)
Epoch: [34][110/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.002)	Loss 7.2701e-01 (8.0515e-01)	Acc@1  73.44 ( 75.51)	Acc@5  97.66 ( 95.56)
Epoch: [34][120/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.002)	Loss 8.7802e-01 (8.1000e-01)	Acc@1  71.09 ( 75.36)	Acc@5  96.88 ( 95.56)
Epoch: [34][130/391]	Time  0.039 ( 0.043)	Data  0.001 ( 0.002)	Loss 9.0035e-01 (8.1224e-01)	Acc@1  70.31 ( 75.32)	Acc@5  96.09 ( 95.54)
Epoch: [34][140/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.002)	Loss 6.9102e-01 (8.1106e-01)	Acc@1  80.47 ( 75.37)	Acc@5  98.44 ( 95.59)
Epoch: [34][150/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 9.3074e-01 (8.1356e-01)	Acc@1  72.66 ( 75.29)	Acc@5  90.62 ( 95.53)
Epoch: [34][160/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 7.1417e-01 (8.1510e-01)	Acc@1  76.56 ( 75.29)	Acc@5  96.09 ( 95.52)
Epoch: [34][170/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.9794e-01 (8.1265e-01)	Acc@1  82.03 ( 75.40)	Acc@5  97.66 ( 95.56)
Epoch: [34][180/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 8.3907e-01 (8.1412e-01)	Acc@1  70.31 ( 75.35)	Acc@5  96.09 ( 95.54)
Epoch: [34][190/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 7.1293e-01 (8.1322e-01)	Acc@1  78.12 ( 75.41)	Acc@5  96.09 ( 95.52)
Epoch: [34][200/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 7.1889e-01 (8.1123e-01)	Acc@1  75.00 ( 75.45)	Acc@5  93.75 ( 95.50)
Epoch: [34][210/391]	Time  0.043 ( 0.042)	Data  0.002 ( 0.002)	Loss 6.7822e-01 (8.1356e-01)	Acc@1  78.91 ( 75.39)	Acc@5  98.44 ( 95.48)
Epoch: [34][220/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 8.8468e-01 (8.1626e-01)	Acc@1  75.78 ( 75.31)	Acc@5  94.53 ( 95.43)
Epoch: [34][230/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 8.6014e-01 (8.1837e-01)	Acc@1  75.78 ( 75.27)	Acc@5  96.09 ( 95.37)
Epoch: [34][240/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 8.9138e-01 (8.2048e-01)	Acc@1  70.31 ( 75.18)	Acc@5  95.31 ( 95.36)
Epoch: [34][250/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 8.6302e-01 (8.2301e-01)	Acc@1  75.00 ( 75.07)	Acc@5  92.97 ( 95.30)
Epoch: [34][260/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.0106e+00 (8.2370e-01)	Acc@1  72.66 ( 75.08)	Acc@5  92.19 ( 95.29)
Epoch: [34][270/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 7.9840e-01 (8.2476e-01)	Acc@1  76.56 ( 75.06)	Acc@5  96.09 ( 95.29)
Epoch: [34][280/391]	Time  0.040 ( 0.042)	Data  0.002 ( 0.002)	Loss 9.0991e-01 (8.2684e-01)	Acc@1  73.44 ( 74.98)	Acc@5  92.19 ( 95.26)
Epoch: [34][290/391]	Time  0.045 ( 0.042)	Data  0.001 ( 0.001)	Loss 8.0423e-01 (8.2731e-01)	Acc@1  78.12 ( 74.98)	Acc@5  95.31 ( 95.25)
Epoch: [34][300/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.001)	Loss 9.8350e-01 (8.3055e-01)	Acc@1  69.53 ( 74.88)	Acc@5  92.19 ( 95.19)
Epoch: [34][310/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.0301e+00 (8.3336e-01)	Acc@1  70.31 ( 74.79)	Acc@5  89.06 ( 95.15)
Epoch: [34][320/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 8.2182e-01 (8.3334e-01)	Acc@1  75.78 ( 74.81)	Acc@5  94.53 ( 95.14)
Epoch: [34][330/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.0114e+00 (8.3532e-01)	Acc@1  71.88 ( 74.79)	Acc@5  92.19 ( 95.13)
Epoch: [34][340/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.001)	Loss 1.0435e+00 (8.3669e-01)	Acc@1  71.88 ( 74.75)	Acc@5  92.19 ( 95.11)
Epoch: [34][350/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 8.2396e-01 (8.3801e-01)	Acc@1  77.34 ( 74.71)	Acc@5  94.53 ( 95.10)
Epoch: [34][360/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.001)	Loss 7.3547e-01 (8.3781e-01)	Acc@1  77.34 ( 74.74)	Acc@5  96.09 ( 95.11)
Epoch: [34][370/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.001)	Loss 6.6739e-01 (8.3758e-01)	Acc@1  82.03 ( 74.77)	Acc@5  96.09 ( 95.11)
Epoch: [34][380/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.001)	Loss 7.8054e-01 (8.3905e-01)	Acc@1  79.69 ( 74.74)	Acc@5  94.53 ( 95.08)
Epoch: [34][390/391]	Time  0.029 ( 0.042)	Data  0.001 ( 0.001)	Loss 9.2636e-01 (8.3978e-01)	Acc@1  72.50 ( 74.70)	Acc@5  91.25 ( 95.08)
## e[34] optimizer.zero_grad (sum) time: 0.28514719009399414
## e[34]       loss.backward (sum) time: 4.133490085601807
## e[34]      optimizer.step (sum) time: 1.8697233200073242
## epoch[34] training(only) time: 16.439429759979248
# Switched to evaluate mode...
Test: [  0/100]	Time  0.150 ( 0.150)	Loss 1.2455e+00 (1.2455e+00)	Acc@1  65.00 ( 65.00)	Acc@5  85.00 ( 85.00)
Test: [ 10/100]	Time  0.025 ( 0.035)	Loss 1.3434e+00 (1.4941e+00)	Acc@1  60.00 ( 61.18)	Acc@5  94.00 ( 88.00)
Test: [ 20/100]	Time  0.022 ( 0.030)	Loss 1.2727e+00 (1.4652e+00)	Acc@1  60.00 ( 61.43)	Acc@5  90.00 ( 88.57)
Test: [ 30/100]	Time  0.024 ( 0.027)	Loss 1.4208e+00 (1.4867e+00)	Acc@1  66.00 ( 61.45)	Acc@5  87.00 ( 87.81)
Test: [ 40/100]	Time  0.024 ( 0.026)	Loss 1.3751e+00 (1.4591e+00)	Acc@1  61.00 ( 61.88)	Acc@5  88.00 ( 88.12)
Test: [ 50/100]	Time  0.018 ( 0.025)	Loss 1.3526e+00 (1.4719e+00)	Acc@1  69.00 ( 62.00)	Acc@5  85.00 ( 87.71)
Test: [ 60/100]	Time  0.024 ( 0.025)	Loss 1.5414e+00 (1.4553e+00)	Acc@1  65.00 ( 62.30)	Acc@5  86.00 ( 87.84)
Test: [ 70/100]	Time  0.024 ( 0.025)	Loss 1.4589e+00 (1.4595e+00)	Acc@1  67.00 ( 62.32)	Acc@5  89.00 ( 87.85)
Test: [ 80/100]	Time  0.023 ( 0.025)	Loss 1.7680e+00 (1.4693e+00)	Acc@1  58.00 ( 62.20)	Acc@5  85.00 ( 87.65)
Test: [ 90/100]	Time  0.018 ( 0.024)	Loss 1.8940e+00 (1.4632e+00)	Acc@1  57.00 ( 62.34)	Acc@5  84.00 ( 87.76)
 * Acc@1 62.510 Acc@5 87.890
### epoch[34] execution time: 18.881701231002808
EPOCH 35
i:   0, name:           module.stem.0.weight  changing lr from: 0.017019931844240544   to: 0.014600142389248290
i:   1, name:             module.stem.0.bias  changing lr from: 0.017646904183536174   to: 0.015204167206735463
i:   2, name:           module.stem.1.weight  changing lr from: 0.018277230265554358   to: 0.015813067264236137
i:   3, name:             module.stem.1.bias  changing lr from: 0.018910534290135752   to: 0.016426422203285863
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.019546454097042126   to: 0.017043826040319843
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.020184640836026863   to: 0.017664886853320967
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.020824758638202597   to: 0.018289226467221094
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.021466484289233319   to: 0.018916480138756808
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.022109506904831069   to: 0.019546296241423473
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.022753527608991572   to: 0.020178335951118221
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.023398259215362201   to: 0.020812272933011924
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.024043425912095896   to: 0.021447793030143304
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.024688762950507450   to: 0.022084593954183336
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.025334016337816054   to: 0.022722384978777328
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.025978942534223805   to: 0.023360886635832492
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.026623308154552595   to: 0.023999830415083148
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.027266889674631752   to: 0.024638958467230618
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.027909473142605543   to: 0.025278023310924699
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.028550853895303666   to: 0.025916787543821929
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.029190836279797284   to: 0.026555023557930338
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.029829233380241682   to: 0.027192513259422759
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.030465866750088590   to: 0.027829047793078709
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.031100566149732656   to: 0.028464427271490601
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.031733169289641677   to: 0.029098460509151394
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.032363521579004184   to: 0.029730964761520186
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.032991475879915112   to: 0.030361765469145426
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.033616892267107359   to: 0.030990696006908514
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.034239637793226023   to: 0.031617597438436097
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.034859586259630940   to: 0.032242318275714700
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.035476617992704088   to: 0.032864714243929005
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.036090619625629809   to: 0.033484648051533221
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.036701483885607622   to: 0.034101989165554396
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.037309109386450316   to: 0.034716613592116030
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.037913400426513824   to: 0.035328403662162132
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.038514266791899343   to: 0.035937247822353129
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.039111623564863238   to: 0.036543040431097677
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.039705390937365637   to: 0.037145681559678012
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.040295494029684423   to: 0.037745076798419736
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.040881862714017864   to: 0.038341137067852117
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.041464431442996372   to: 0.038933778434799671
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.042043139083020334   to: 0.039522921933341594
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.042617928752339995   to: 0.040108493390571633
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.043188747663789745   to: 0.040690423257087556
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.043755546972089554   to: 0.041268646442136681
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.044318281625623124   to: 0.041843102153340736
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.044876910222602900   to: 0.042413733740921833
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.045431394871529987   to: 0.042980488546348727
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.045981701055858165   to: 0.043543317755321789
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.046527797502768968   to: 0.044102176255012795
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.047069656055966594   to: 0.044657022495475804
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.047607251552400157   to: 0.045207818355143564
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.048140561702821959   to: 0.045754529010324202
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.048669566976090532   to: 0.046297122808612097
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.049194250487127694   to: 0.046835571146127013
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.049714597888440071   to: 0.047369848348495391
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.050230597265115376   to: 0.047899931555487947
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.050742239033206238   to: 0.048425800609228548
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.051249515841413587   to: 0.048947437945888850
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.051752422475984189   to: 0.049464828490784936
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.052250955768737034   to: 0.049977959556791830
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.052745114508135515   to: 0.050486820745993671
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.053234899353322596   to: 0.050991403854487111
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.053720312751038141   to: 0.051491702780257421
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.054201358855339013   to: 0.051987713434047261
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.054678043450043526   to: 0.052479433653139465
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.055150373873823814   to: 0.052966863117976472
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.055618358947870400   to: 0.053450003271539641
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.056082008906055705   to: 0.053928857241413664
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.056541335327523951   to: 0.054403429764462524
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.056996351071636711   to: 0.054873727114043806
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.057447070215205023   to: 0.055339757029691274
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.057893507991940124   to: 0.055801528649194847
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.058335680734056865   to: 0.056259052443010708
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.058773605815964872   to: 0.056712340150933661
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.059207301599984552   to: 0.057161404720966917
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.059636787384026058   to: 0.057606260250324538
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.060062083351171053   to: 0.058046921928504316
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.060483210521098708   to: 0.058483405982369223
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.060900190703298634   to: 0.058915729623178051
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.061313046452014880   to: 0.059343910995506337
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.061721801022866653   to: 0.059767969128000302
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.062126478331092985   to: 0.060187923885908490
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.062527102911369467   to: 0.060603795925336240
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.062923699879147227   to: 0.061015606649170141
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.063316294893464825   to: 0.061423378164620637
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.063704914121186201   to: 0.061827133242332445
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.064089584202617664   to: 0.062226895277013632
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.064470332218459769   to: 0.062622688249535402
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.064847185658049769   to: 0.063014536690456299
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.065220172388852471   to: 0.063402465644925118
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.065589320627158373   to: 0.063786500638918706
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.065954658909948505   to: 0.064166667646771675
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.066316216067887818   to: 0.064542993059956061
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.066674021199408420   to: 0.064915503657070703
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.067028103645846882   to: 0.065284226575000812
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.067378492967599304   to: 0.065649189281208900
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.067725218921259878   to: 0.066010419547120683
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.068068311437709708   to: 0.066367945422569088
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.068407800601122615   to: 0.066721795211261453
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.068743716628857296   to: 0.067071997447235784
i: 100, name:           module.conv10.weight  changing lr from: 0.069076089852204522   to: 0.067418580872273051
i: 101, name:             module.conv10.bias  changing lr from: 0.069404950697960252   to: 0.067761574414233139



# Switched to train mode...
Epoch: [35][  0/391]	Time  0.202 ( 0.202)	Data  0.153 ( 0.153)	Loss 7.1965e-01 (7.1965e-01)	Acc@1  77.34 ( 77.34)	Acc@5  96.09 ( 96.09)
Epoch: [35][ 10/391]	Time  0.042 ( 0.056)	Data  0.001 ( 0.015)	Loss 6.6710e-01 (7.4779e-01)	Acc@1  76.56 ( 77.41)	Acc@5  96.88 ( 96.45)
Epoch: [35][ 20/391]	Time  0.041 ( 0.049)	Data  0.001 ( 0.008)	Loss 8.7575e-01 (7.7830e-01)	Acc@1  70.31 ( 75.89)	Acc@5  95.31 ( 96.28)
Epoch: [35][ 30/391]	Time  0.039 ( 0.046)	Data  0.001 ( 0.006)	Loss 8.6057e-01 (7.8268e-01)	Acc@1  75.00 ( 75.96)	Acc@5  95.31 ( 96.12)
Epoch: [35][ 40/391]	Time  0.043 ( 0.045)	Data  0.001 ( 0.005)	Loss 8.1411e-01 (7.9638e-01)	Acc@1  75.00 ( 75.80)	Acc@5  94.53 ( 95.92)
Epoch: [35][ 50/391]	Time  0.039 ( 0.044)	Data  0.001 ( 0.004)	Loss 9.1156e-01 (7.9440e-01)	Acc@1  67.97 ( 75.75)	Acc@5  96.09 ( 96.06)
Epoch: [35][ 60/391]	Time  0.040 ( 0.044)	Data  0.001 ( 0.004)	Loss 8.9774e-01 (7.9544e-01)	Acc@1  71.88 ( 75.77)	Acc@5  95.31 ( 95.98)
Epoch: [35][ 70/391]	Time  0.040 ( 0.044)	Data  0.001 ( 0.003)	Loss 7.5602e-01 (8.0087e-01)	Acc@1  74.22 ( 75.78)	Acc@5  98.44 ( 95.93)
Epoch: [35][ 80/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.003)	Loss 9.3398e-01 (8.0153e-01)	Acc@1  75.00 ( 75.76)	Acc@5  92.19 ( 95.89)
Epoch: [35][ 90/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.003)	Loss 1.0192e+00 (8.0284e-01)	Acc@1  75.78 ( 75.78)	Acc@5  92.97 ( 95.89)
Epoch: [35][100/391]	Time  0.039 ( 0.043)	Data  0.001 ( 0.003)	Loss 8.6735e-01 (8.0698e-01)	Acc@1  68.75 ( 75.63)	Acc@5  96.09 ( 95.78)
Epoch: [35][110/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.002)	Loss 7.4143e-01 (8.0647e-01)	Acc@1  76.56 ( 75.60)	Acc@5  96.88 ( 95.76)
Epoch: [35][120/391]	Time  0.039 ( 0.043)	Data  0.001 ( 0.002)	Loss 7.2105e-01 (8.0736e-01)	Acc@1  79.69 ( 75.63)	Acc@5  95.31 ( 95.68)
Epoch: [35][130/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 7.0134e-01 (8.0749e-01)	Acc@1  80.47 ( 75.58)	Acc@5  96.09 ( 95.67)
Epoch: [35][140/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 7.7886e-01 (8.0640e-01)	Acc@1  76.56 ( 75.50)	Acc@5  93.75 ( 95.73)
Epoch: [35][150/391]	Time  0.052 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.5825e-01 (8.0334e-01)	Acc@1  82.03 ( 75.66)	Acc@5  98.44 ( 95.74)
Epoch: [35][160/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.002)	Loss 9.2607e-01 (8.0407e-01)	Acc@1  70.31 ( 75.60)	Acc@5  93.75 ( 95.70)
Epoch: [35][170/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.8718e-01 (8.0183e-01)	Acc@1  76.56 ( 75.70)	Acc@5  97.66 ( 95.68)
Epoch: [35][180/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 9.1076e-01 (8.0054e-01)	Acc@1  70.31 ( 75.75)	Acc@5  96.88 ( 95.64)
Epoch: [35][190/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 8.9055e-01 (7.9996e-01)	Acc@1  69.53 ( 75.78)	Acc@5  95.31 ( 95.66)
Epoch: [35][200/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.9918e-01 (8.0011e-01)	Acc@1  78.12 ( 75.82)	Acc@5  97.66 ( 95.62)
Epoch: [35][210/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 8.2149e-01 (8.0357e-01)	Acc@1  77.34 ( 75.72)	Acc@5  94.53 ( 95.54)
Epoch: [35][220/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 8.5800e-01 (8.0441e-01)	Acc@1  71.88 ( 75.69)	Acc@5  96.88 ( 95.55)
Epoch: [35][230/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 8.7040e-01 (8.0490e-01)	Acc@1  72.66 ( 75.71)	Acc@5  96.09 ( 95.54)
Epoch: [35][240/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 8.4487e-01 (8.0668e-01)	Acc@1  75.78 ( 75.66)	Acc@5  93.75 ( 95.52)
Epoch: [35][250/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 9.4847e-01 (8.0825e-01)	Acc@1  75.78 ( 75.62)	Acc@5  93.75 ( 95.50)
Epoch: [35][260/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 7.7146e-01 (8.0824e-01)	Acc@1  76.56 ( 75.60)	Acc@5  93.75 ( 95.49)
Epoch: [35][270/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 7.1060e-01 (8.0814e-01)	Acc@1  80.47 ( 75.59)	Acc@5  96.88 ( 95.51)
Epoch: [35][280/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 7.1528e-01 (8.0919e-01)	Acc@1  79.69 ( 75.55)	Acc@5  95.31 ( 95.51)
Epoch: [35][290/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 8.0386e-01 (8.0966e-01)	Acc@1  76.56 ( 75.51)	Acc@5  96.09 ( 95.51)
Epoch: [35][300/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.8771e-01 (8.0999e-01)	Acc@1  79.69 ( 75.47)	Acc@5  97.66 ( 95.49)
Epoch: [35][310/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 8.4908e-01 (8.1099e-01)	Acc@1  74.22 ( 75.45)	Acc@5  94.53 ( 95.49)
Epoch: [35][320/391]	Time  0.036 ( 0.042)	Data  0.001 ( 0.001)	Loss 6.3754e-01 (8.0986e-01)	Acc@1  82.81 ( 75.45)	Acc@5  97.66 ( 95.53)
Epoch: [35][330/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.001)	Loss 8.3915e-01 (8.1125e-01)	Acc@1  76.56 ( 75.38)	Acc@5  92.97 ( 95.51)
Epoch: [35][340/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 8.9594e-01 (8.1143e-01)	Acc@1  71.09 ( 75.38)	Acc@5  95.31 ( 95.50)
Epoch: [35][350/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.001)	Loss 8.9054e-01 (8.1165e-01)	Acc@1  73.44 ( 75.35)	Acc@5  92.97 ( 95.52)
Epoch: [35][360/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.001)	Loss 8.7075e-01 (8.1203e-01)	Acc@1  72.66 ( 75.38)	Acc@5  95.31 ( 95.52)
Epoch: [35][370/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 7.4614e-01 (8.1344e-01)	Acc@1  81.25 ( 75.34)	Acc@5  92.97 ( 95.50)
Epoch: [35][380/391]	Time  0.054 ( 0.042)	Data  0.001 ( 0.001)	Loss 7.6000e-01 (8.1490e-01)	Acc@1  78.12 ( 75.28)	Acc@5  97.66 ( 95.50)
Epoch: [35][390/391]	Time  0.037 ( 0.041)	Data  0.001 ( 0.001)	Loss 9.0427e-01 (8.1674e-01)	Acc@1  68.75 ( 75.23)	Acc@5  95.00 ( 95.48)
## e[35] optimizer.zero_grad (sum) time: 0.2849922180175781
## e[35]       loss.backward (sum) time: 4.09529185295105
## e[35]      optimizer.step (sum) time: 1.8600795269012451
## epoch[35] training(only) time: 16.29814386367798
# Switched to evaluate mode...
Test: [  0/100]	Time  0.152 ( 0.152)	Loss 1.3390e+00 (1.3390e+00)	Acc@1  63.00 ( 63.00)	Acc@5  90.00 ( 90.00)
Test: [ 10/100]	Time  0.022 ( 0.033)	Loss 1.3744e+00 (1.5070e+00)	Acc@1  61.00 ( 62.82)	Acc@5  93.00 ( 88.00)
Test: [ 20/100]	Time  0.024 ( 0.027)	Loss 1.1371e+00 (1.4819e+00)	Acc@1  67.00 ( 62.86)	Acc@5  90.00 ( 88.19)
Test: [ 30/100]	Time  0.024 ( 0.026)	Loss 1.6179e+00 (1.5074e+00)	Acc@1  60.00 ( 62.10)	Acc@5  85.00 ( 88.03)
Test: [ 40/100]	Time  0.024 ( 0.025)	Loss 1.7273e+00 (1.5021e+00)	Acc@1  62.00 ( 62.22)	Acc@5  86.00 ( 87.78)
Test: [ 50/100]	Time  0.021 ( 0.025)	Loss 1.6137e+00 (1.5199e+00)	Acc@1  62.00 ( 61.92)	Acc@5  87.00 ( 87.35)
Test: [ 60/100]	Time  0.022 ( 0.024)	Loss 1.6920e+00 (1.5182e+00)	Acc@1  57.00 ( 61.70)	Acc@5  88.00 ( 87.43)
Test: [ 70/100]	Time  0.021 ( 0.024)	Loss 1.4185e+00 (1.5185e+00)	Acc@1  61.00 ( 61.72)	Acc@5  91.00 ( 87.49)
Test: [ 80/100]	Time  0.024 ( 0.024)	Loss 1.6364e+00 (1.5199e+00)	Acc@1  64.00 ( 61.40)	Acc@5  84.00 ( 87.57)
Test: [ 90/100]	Time  0.021 ( 0.024)	Loss 1.9951e+00 (1.5129e+00)	Acc@1  54.00 ( 61.63)	Acc@5  81.00 ( 87.66)
 * Acc@1 61.870 Acc@5 87.800
### epoch[35] execution time: 18.743319034576416
EPOCH 36
i:   0, name:           module.stem.0.weight  changing lr from: 0.014600142389248290   to: 0.012349477331863180
i:   1, name:             module.stem.0.bias  changing lr from: 0.015204167206735463   to: 0.012925324070447330
i:   2, name:           module.stem.1.weight  changing lr from: 0.015813067264236137   to: 0.013507667772669579
i:   3, name:             module.stem.1.bias  changing lr from: 0.016426422203285863   to: 0.014096043499414113
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.017043826040319843   to: 0.014690001287931537
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.017664886853320967   to: 0.015289105864714974
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.018289226467221094   to: 0.015892936354088595
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.018916480138756808   to: 0.016501085983402775
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.019546296241423473   to: 0.017113161785663689
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.020178335951118221   to: 0.017728784300362295
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.020812272933011924   to: 0.018347587273208388
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.021447793030143304   to: 0.018969217355420193
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.022084593954183336   to: 0.019593333803166340
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.022722384978777328   to: 0.020219608177709132
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.023360886635832492   to: 0.020847724046750268
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.023999830415083148   to: 0.021477376687437599
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.024638958467230618   to: 0.022108272791449599
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.025278023310924699   to: 0.022740130172537027
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.025916787543821929   to: 0.023372677476864192
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.026555023557930338   to: 0.024005653896459228
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.027192513259422759   to: 0.024638808886051067
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.027829047793078709   to: 0.025271901883541684
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.028464427271490601   to: 0.025904702034334218
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.029098460509151394   to: 0.026536987919712363
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.029730964761520186   to: 0.027168547289442686
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.030361765469145426   to: 0.027799176798748639
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.030990696006908514   to: 0.028428681749785190
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.031617597438436097   to: 0.029056875837723567
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.032242318275714700   to: 0.029683580901537360
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.032864714243929005   to: 0.030308626679565437
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.033484648051533221   to: 0.030931850569911365
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.034101989165554396   to: 0.031553097395725496
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.034716613592116030   to: 0.032172219175402174
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.035328403662162132   to: 0.032789074897713121
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.035937247822353129   to: 0.033403530301886919
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.036543040431097677   to: 0.034015457662634245
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.037145681559678012   to: 0.034624735580109436
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.037745076798419736   to: 0.035231248774790523
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.038341137067852117   to: 0.035834887887252038
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.038933778434799671   to: 0.036435549282797866
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.039522921933341594   to: 0.037033134860915397
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.040108493390571633   to: 0.037627551869506094
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.040690423257087556   to: 0.038218712723842418
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.041268646442136681   to: 0.038806534830196943
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.041843102153340736   to: 0.039390940414084467
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.042413733740921833   to: 0.039971856353055259
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.042980488546348727   to: 0.040549214013973239
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.043543317755321789   to: 0.041122949094711203
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.044102176255012795   to: 0.041693001470191497
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.044657022495475804   to: 0.042259315042699475
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.045207818355143564   to: 0.042821837596394602
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.045754529010324202   to: 0.043380520655942667
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.046297122808612097   to: 0.043935319349191607
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.046835571146127013   to: 0.044486192273812036
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.047369848348495391   to: 0.045033101367823153
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.047899931555487947   to: 0.045576011783923717
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.048425800609228548   to: 0.046114891767548162
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.048947437945888850   to: 0.046649712538566833
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.049464828490784936   to: 0.047180448176550177
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.049977959556791830   to: 0.047707075509516146
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.050486820745993671   to: 0.048229574006081022
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.050991403854487111   to: 0.048747925670933723
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.051491702780257421   to: 0.049262114943554418
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.051987713434047261   to: 0.049772128600099080
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.052479433653139465   to: 0.050277955658371974
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.052966863117976472   to: 0.050779587285809231
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.053450003271539641   to: 0.051277016710397243
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.053928857241413664   to: 0.051770239134450668
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.054403429764462524   to: 0.052259251651176286
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.054873727114043806   to: 0.052744053163948923
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.055339757029691274   to: 0.053224644308228208
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.055801528649194847   to: 0.053701027376044722
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.056259052443010708   to: 0.054173206242986362
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.056712340150933661   to: 0.054641186297616086
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.057161404720966917   to: 0.055104974373254345
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.057606260250324538   to: 0.055564578682059711
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.058046921928504316   to: 0.056020008751343636
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.058483405982369223   to: 0.056471275362055297
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.058915729623178051   to: 0.056918390489375408
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.059343910995506337   to: 0.057361367245357189
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.059767969128000302   to: 0.057800219823555869
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.060187923885908490   to: 0.058234963445588130
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.060603795925336240   to: 0.058665614309564851
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.061015606649170141   to: 0.059092189540341469
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.061423378164620637   to: 0.059514707141531779
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.061827133242332445   to: 0.059933185949232207
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.062226895277013632   to: 0.060347645587404797
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.062622688249535402   to: 0.060758106424868563
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.063014536690456299   to: 0.061164589533849879
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.063402465644925118   to: 0.061567116650044024
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.063786500638918706   to: 0.061965710134141129
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.064166667646771675   to: 0.062360392934770963
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.064542993059956061   to: 0.062751188552822218
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.064915503657070703   to: 0.063138121007092957
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.065284226575000812   to: 0.063521214801230449
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.065649189281208900   to: 0.063900494891918971
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.066010419547120683   to: 0.064275986658276454
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.066367945422569088   to: 0.064647715872420547
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.066721795211261453   to: 0.065015708671166753
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.067071997447235784   to: 0.065379991528822040
i: 100, name:           module.conv10.weight  changing lr from: 0.067418580872273051   to: 0.065740591231038190
i: 101, name:             module.conv10.bias  changing lr from: 0.067761574414233139   to: 0.066097534849690415



# Switched to train mode...
Epoch: [36][  0/391]	Time  0.197 ( 0.197)	Data  0.144 ( 0.144)	Loss 8.5057e-01 (8.5057e-01)	Acc@1  75.78 ( 75.78)	Acc@5  95.31 ( 95.31)
Epoch: [36][ 10/391]	Time  0.042 ( 0.056)	Data  0.001 ( 0.014)	Loss 6.0393e-01 (7.1960e-01)	Acc@1  78.91 ( 77.63)	Acc@5  98.44 ( 96.80)
Epoch: [36][ 20/391]	Time  0.043 ( 0.050)	Data  0.001 ( 0.008)	Loss 7.0000e-01 (7.4071e-01)	Acc@1  76.56 ( 77.01)	Acc@5  97.66 ( 96.73)
Epoch: [36][ 30/391]	Time  0.043 ( 0.047)	Data  0.001 ( 0.006)	Loss 5.8509e-01 (7.2686e-01)	Acc@1  85.94 ( 77.55)	Acc@5  98.44 ( 96.77)
Epoch: [36][ 40/391]	Time  0.041 ( 0.046)	Data  0.001 ( 0.005)	Loss 7.3311e-01 (7.3367e-01)	Acc@1  76.56 ( 77.69)	Acc@5  96.88 ( 96.63)
Epoch: [36][ 50/391]	Time  0.043 ( 0.045)	Data  0.001 ( 0.004)	Loss 8.2001e-01 (7.3382e-01)	Acc@1  79.69 ( 77.67)	Acc@5  92.97 ( 96.46)
Epoch: [36][ 60/391]	Time  0.040 ( 0.044)	Data  0.001 ( 0.003)	Loss 9.8790e-01 (7.3989e-01)	Acc@1  73.44 ( 77.56)	Acc@5  92.97 ( 96.32)
Epoch: [36][ 70/391]	Time  0.043 ( 0.044)	Data  0.001 ( 0.003)	Loss 7.5527e-01 (7.3993e-01)	Acc@1  78.12 ( 77.51)	Acc@5  94.53 ( 96.26)
Epoch: [36][ 80/391]	Time  0.042 ( 0.044)	Data  0.001 ( 0.003)	Loss 9.0064e-01 (7.4191e-01)	Acc@1  69.53 ( 77.43)	Acc@5  95.31 ( 96.24)
Epoch: [36][ 90/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.003)	Loss 7.3491e-01 (7.4449e-01)	Acc@1  78.12 ( 77.35)	Acc@5  95.31 ( 96.21)
Epoch: [36][100/391]	Time  0.048 ( 0.043)	Data  0.001 ( 0.002)	Loss 7.2884e-01 (7.4955e-01)	Acc@1  82.81 ( 77.23)	Acc@5  96.09 ( 96.14)
Epoch: [36][110/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.002)	Loss 7.0460e-01 (7.5088e-01)	Acc@1  78.91 ( 77.25)	Acc@5  96.88 ( 96.15)
Epoch: [36][120/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 7.0345e-01 (7.5038e-01)	Acc@1  78.12 ( 77.27)	Acc@5  97.66 ( 96.15)
Epoch: [36][130/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.002)	Loss 7.7865e-01 (7.5402e-01)	Acc@1  76.56 ( 77.18)	Acc@5  96.09 ( 96.08)
Epoch: [36][140/391]	Time  0.045 ( 0.043)	Data  0.001 ( 0.002)	Loss 8.1407e-01 (7.5867e-01)	Acc@1  72.66 ( 77.01)	Acc@5  94.53 ( 96.02)
Epoch: [36][150/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.002)	Loss 7.7481e-01 (7.5733e-01)	Acc@1  76.56 ( 77.02)	Acc@5  96.88 ( 96.07)
Epoch: [36][160/391]	Time  0.044 ( 0.043)	Data  0.001 ( 0.002)	Loss 7.8988e-01 (7.5781e-01)	Acc@1  75.00 ( 77.04)	Acc@5  97.66 ( 96.08)
Epoch: [36][170/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.002)	Loss 8.8665e-01 (7.6166e-01)	Acc@1  72.66 ( 76.92)	Acc@5  95.31 ( 96.04)
Epoch: [36][180/391]	Time  0.049 ( 0.043)	Data  0.001 ( 0.002)	Loss 8.4838e-01 (7.6206e-01)	Acc@1  77.34 ( 76.92)	Acc@5  96.09 ( 96.07)
Epoch: [36][190/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.002)	Loss 8.2723e-01 (7.6561e-01)	Acc@1  74.22 ( 76.87)	Acc@5  92.97 ( 96.00)
Epoch: [36][200/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.002)	Loss 1.0338e+00 (7.6645e-01)	Acc@1  64.84 ( 76.71)	Acc@5  94.53 ( 96.02)
Epoch: [36][210/391]	Time  0.047 ( 0.043)	Data  0.001 ( 0.002)	Loss 7.8096e-01 (7.6627e-01)	Acc@1  75.00 ( 76.71)	Acc@5  97.66 ( 96.04)
Epoch: [36][220/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 7.8633e-01 (7.7029e-01)	Acc@1  71.09 ( 76.53)	Acc@5  96.88 ( 95.98)
Epoch: [36][230/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.002)	Loss 8.2822e-01 (7.7124e-01)	Acc@1  74.22 ( 76.45)	Acc@5  95.31 ( 95.96)
Epoch: [36][240/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.002)	Loss 7.8727e-01 (7.7263e-01)	Acc@1  76.56 ( 76.40)	Acc@5  96.09 ( 95.96)
Epoch: [36][250/391]	Time  0.045 ( 0.043)	Data  0.001 ( 0.002)	Loss 7.6487e-01 (7.7459e-01)	Acc@1  78.12 ( 76.40)	Acc@5  93.75 ( 95.91)
Epoch: [36][260/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.002)	Loss 8.9214e-01 (7.7608e-01)	Acc@1  71.09 ( 76.34)	Acc@5  94.53 ( 95.88)
Epoch: [36][270/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 7.0336e-01 (7.7660e-01)	Acc@1  76.56 ( 76.29)	Acc@5  95.31 ( 95.85)
Epoch: [36][280/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.002)	Loss 6.9188e-01 (7.7480e-01)	Acc@1  75.78 ( 76.31)	Acc@5  97.66 ( 95.86)
Epoch: [36][290/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 8.5988e-01 (7.7561e-01)	Acc@1  76.56 ( 76.31)	Acc@5  91.41 ( 95.83)
Epoch: [36][300/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 8.6837e-01 (7.7628e-01)	Acc@1  71.09 ( 76.26)	Acc@5  95.31 ( 95.85)
Epoch: [36][310/391]	Time  0.041 ( 0.042)	Data  0.002 ( 0.002)	Loss 7.9348e-01 (7.7532e-01)	Acc@1  78.91 ( 76.34)	Acc@5  92.97 ( 95.84)
Epoch: [36][320/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.001)	Loss 9.5836e-01 (7.7781e-01)	Acc@1  74.22 ( 76.29)	Acc@5  95.31 ( 95.80)
Epoch: [36][330/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.001)	Loss 6.6046e-01 (7.7911e-01)	Acc@1  82.03 ( 76.27)	Acc@5  96.09 ( 95.79)
Epoch: [36][340/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.001)	Loss 8.5197e-01 (7.8016e-01)	Acc@1  72.66 ( 76.29)	Acc@5  95.31 ( 95.76)
Epoch: [36][350/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 8.8618e-01 (7.8206e-01)	Acc@1  71.88 ( 76.23)	Acc@5  96.88 ( 95.77)
Epoch: [36][360/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.001)	Loss 7.9900e-01 (7.8433e-01)	Acc@1  71.88 ( 76.16)	Acc@5  98.44 ( 95.73)
Epoch: [36][370/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 8.1181e-01 (7.8531e-01)	Acc@1  78.12 ( 76.13)	Acc@5  91.41 ( 95.71)
Epoch: [36][380/391]	Time  0.045 ( 0.042)	Data  0.001 ( 0.001)	Loss 7.2627e-01 (7.8636e-01)	Acc@1  81.25 ( 76.09)	Acc@5  97.66 ( 95.72)
Epoch: [36][390/391]	Time  0.028 ( 0.042)	Data  0.001 ( 0.001)	Loss 6.4968e-01 (7.8641e-01)	Acc@1  78.75 ( 76.06)	Acc@5  96.25 ( 95.72)
## e[36] optimizer.zero_grad (sum) time: 0.2849247455596924
## e[36]       loss.backward (sum) time: 4.190328359603882
## e[36]      optimizer.step (sum) time: 1.8296270370483398
## epoch[36] training(only) time: 16.572293758392334
# Switched to evaluate mode...
Test: [  0/100]	Time  0.150 ( 0.150)	Loss 1.2952e+00 (1.2952e+00)	Acc@1  68.00 ( 68.00)	Acc@5  86.00 ( 86.00)
Test: [ 10/100]	Time  0.024 ( 0.034)	Loss 1.5283e+00 (1.5023e+00)	Acc@1  61.00 ( 61.73)	Acc@5  90.00 ( 87.27)
Test: [ 20/100]	Time  0.024 ( 0.029)	Loss 1.3668e+00 (1.4903e+00)	Acc@1  66.00 ( 63.00)	Acc@5  91.00 ( 87.29)
Test: [ 30/100]	Time  0.022 ( 0.027)	Loss 1.5934e+00 (1.5011e+00)	Acc@1  55.00 ( 62.65)	Acc@5  86.00 ( 87.16)
Test: [ 40/100]	Time  0.022 ( 0.025)	Loss 1.6097e+00 (1.4834e+00)	Acc@1  62.00 ( 62.37)	Acc@5  88.00 ( 87.34)
Test: [ 50/100]	Time  0.021 ( 0.025)	Loss 1.6556e+00 (1.4931e+00)	Acc@1  60.00 ( 62.24)	Acc@5  83.00 ( 87.16)
Test: [ 60/100]	Time  0.024 ( 0.024)	Loss 1.5058e+00 (1.4669e+00)	Acc@1  59.00 ( 62.41)	Acc@5  88.00 ( 87.64)
Test: [ 70/100]	Time  0.026 ( 0.024)	Loss 1.4125e+00 (1.4664e+00)	Acc@1  67.00 ( 62.58)	Acc@5  88.00 ( 87.65)
Test: [ 80/100]	Time  0.021 ( 0.023)	Loss 1.5126e+00 (1.4652e+00)	Acc@1  58.00 ( 62.54)	Acc@5  84.00 ( 87.64)
Test: [ 90/100]	Time  0.024 ( 0.024)	Loss 2.0380e+00 (1.4594e+00)	Acc@1  53.00 ( 62.79)	Acc@5  79.00 ( 87.68)
 * Acc@1 63.180 Acc@5 87.890
### epoch[36] execution time: 19.007725954055786
EPOCH 37
i:   0, name:           module.stem.0.weight  changing lr from: 0.012349477331863180   to: 0.010278393921015021
i:   1, name:             module.stem.0.bias  changing lr from: 0.012925324070447330   to: 0.010820808624770743
i:   2, name:           module.stem.1.weight  changing lr from: 0.013507667772669579   to: 0.011371433757897682
i:   3, name:             module.stem.1.bias  changing lr from: 0.014096043499414113   to: 0.011929760340165234
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.014690001287931537   to: 0.012495294809443381
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.015289105864714974   to: 0.013067558771401911
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.015892936354088595   to: 0.013646088741366386
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.016501085983402775   to: 0.014230435879436794
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.017113161785663689   to: 0.014820165719898561
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.017728784300362295   to: 0.015414857895883722
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.018347587273208388   to: 0.016014105860171275
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.018969217355420193   to: 0.016617516602951569
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.019593333803166340   to: 0.017224710367318107
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.020219608177709132   to: 0.017835320363193016
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.020847724046750268   to: 0.018448992480337469
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.021477376687437599   to: 0.019065385001047847
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.022108272791449599   to: 0.019684168313089251
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.022740130172537027   to: 0.020305024623373635
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.023372677476864192   to: 0.020927647672846023
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.024005653896459228   to: 0.021551742453002978
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.024638808886051067   to: 0.022177024924429252
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.025271901883541684   to: 0.022803221737703695
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.025904702034334218   to: 0.023430069956991789
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.026536987919712363   to: 0.024057316786611618
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.027168547289442686   to: 0.024684719300830840
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.027799176798748639   to: 0.025312044177125011
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.028428681749785190   to: 0.025939067433102286
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.029056875837723567   to: 0.026565574167276271
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.029683580901537360   to: 0.027191358303845836
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.030308626679565437   to: 0.027816222341621084
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.030931850569911365   to: 0.028439977107214832
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.031553097395725496   to: 0.029062441512602011
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.032172219175402174   to: 0.029683442317131825
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.032789074897713121   to: 0.030302813894063380
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.033403530301886919   to: 0.030920398001680269
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.034015457662634245   to: 0.031536043559027532
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.034624735580109436   to: 0.032149606426301526
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.035231248774790523   to: 0.032760949189912500
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.035834887887252038   to: 0.033369940952229428
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.036435549282797866   to: 0.033976457126007054
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.037033134860915397   to: 0.034580379233486780
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.037627551869506094   to: 0.035181594710154793
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.038218712723842418   to: 0.035779996713133810
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.038806534830196943   to: 0.036375483934178464
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.039390940414084467   to: 0.036967960417237877
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.039971856353055259   to: 0.037557335380544156
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.040549214013973239   to: 0.038143523043180132
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.041122949094711203   to: 0.038726442456076211
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.041693001470191497   to: 0.039306017337380768
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.042259315042699475   to: 0.039882175912146878
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.042821837596394602   to: 0.040454850756273475
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.043380520655942667   to: 0.041023978644637492
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.043935319349191607   to: 0.041589500403350500
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.044486192273812036   to: 0.042151360766071636
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.045033101367823153   to: 0.042709508234306859
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.045576011783923717   to: 0.043263894941622548
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.046114891767548162   to: 0.043814476521701673
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.046649712538566833   to: 0.044361211980167847
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.047180448176550177   to: 0.044904063570103611
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.047707075509516146   to: 0.045442996671187369
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.048229574006081022   to: 0.045977979672374221
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.048747925670933723   to: 0.046508983858044667
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.049262114943554418   to: 0.047035983297545818
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.049772128600099080   to: 0.047558954738049559
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.050277955658371974   to: 0.048077877500652642
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.050779587285809231   to: 0.048592733379643455
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.051277016710397243   to: 0.049103506544861467
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.051770239134450668   to: 0.049610183447074983
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.052259251651176286   to: 0.050112752726304610
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.052744053163948923   to: 0.050611205123019316
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.053224644308228208   to: 0.051105533392134056
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.053701027376044722   to: 0.051595732219737400
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.054173206242986362   to: 0.052081798142480179
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.054641186297616086   to: 0.052563729469555204
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.055104974373254345   to: 0.053041526207201255
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.055564578682059711   to: 0.053515189985663569
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.056020008751343636   to: 0.053984723988545716
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.056471275362055297   to: 0.054450132884487835
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.056918390489375408   to: 0.054911422761108067
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.057361367245357189   to: 0.055368601061144766
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.057800219823555869   to: 0.055821676520738051
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.058234963445588130   to: 0.056270659109791545
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.058665614309564851   to: 0.056715559974354526
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.059092189540341469   to: 0.057156391380968001
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.059514707141531779   to: 0.057593166662917444
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.059933185949232207   to: 0.058025900168338002
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.060347645587404797   to: 0.058454607210117505
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.060758106424868563   to: 0.058879304017545153
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.061164589533849879   to: 0.059300007689654113
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.061567116650044024   to: 0.059716736150207811
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.061965710134141129   to: 0.060129508104280888
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.062360392934770963   to: 0.060538342996386899
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.062751188552822218   to: 0.060943260970105974
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.063138121007092957   to: 0.061344282829166701
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.063521214801230449   to: 0.061741429999938084
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.063900494891918971   to: 0.062134724495288007
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.064275986658276454   to: 0.062524188879766046
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.064647715872420547   to: 0.062909846236069461
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.065015708671166753   to: 0.063291720132752333
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.065379991528822040   to: 0.063669834593138797
i: 100, name:           module.conv10.weight  changing lr from: 0.065740591231038190   to: 0.064044214065402616
i: 101, name:             module.conv10.bias  changing lr from: 0.066097534849690415   to: 0.064414883393775643



# Switched to train mode...
Epoch: [37][  0/391]	Time  0.190 ( 0.190)	Data  0.143 ( 0.143)	Loss 4.9969e-01 (4.9969e-01)	Acc@1  85.16 ( 85.16)	Acc@5  98.44 ( 98.44)
Epoch: [37][ 10/391]	Time  0.045 ( 0.056)	Data  0.001 ( 0.014)	Loss 5.8864e-01 (6.7237e-01)	Acc@1  80.47 ( 79.33)	Acc@5  97.66 ( 97.16)
Epoch: [37][ 20/391]	Time  0.043 ( 0.049)	Data  0.001 ( 0.008)	Loss 8.1748e-01 (6.8305e-01)	Acc@1  77.34 ( 78.76)	Acc@5  95.31 ( 96.95)
Epoch: [37][ 30/391]	Time  0.042 ( 0.047)	Data  0.001 ( 0.006)	Loss 5.2536e-01 (6.7395e-01)	Acc@1  84.38 ( 79.26)	Acc@5  98.44 ( 96.93)
Epoch: [37][ 40/391]	Time  0.044 ( 0.045)	Data  0.001 ( 0.005)	Loss 8.9894e-01 (6.8253e-01)	Acc@1  73.44 ( 79.25)	Acc@5  96.09 ( 96.74)
Epoch: [37][ 50/391]	Time  0.043 ( 0.044)	Data  0.000 ( 0.004)	Loss 7.0101e-01 (6.9594e-01)	Acc@1  84.38 ( 79.03)	Acc@5  97.66 ( 96.54)
Epoch: [37][ 60/391]	Time  0.040 ( 0.044)	Data  0.001 ( 0.003)	Loss 8.0250e-01 (6.9828e-01)	Acc@1  71.88 ( 79.02)	Acc@5  96.09 ( 96.45)
Epoch: [37][ 70/391]	Time  0.040 ( 0.044)	Data  0.001 ( 0.003)	Loss 7.4987e-01 (6.9840e-01)	Acc@1  75.78 ( 78.88)	Acc@5  96.09 ( 96.47)
Epoch: [37][ 80/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.003)	Loss 5.1744e-01 (7.0393e-01)	Acc@1  85.16 ( 78.74)	Acc@5  99.22 ( 96.50)
Epoch: [37][ 90/391]	Time  0.039 ( 0.043)	Data  0.001 ( 0.003)	Loss 7.2682e-01 (7.0534e-01)	Acc@1  79.69 ( 78.77)	Acc@5  95.31 ( 96.41)
Epoch: [37][100/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.003)	Loss 9.0278e-01 (7.0446e-01)	Acc@1  67.97 ( 78.73)	Acc@5  96.09 ( 96.47)
Epoch: [37][110/391]	Time  0.045 ( 0.043)	Data  0.001 ( 0.002)	Loss 7.4184e-01 (7.0790e-01)	Acc@1  74.22 ( 78.49)	Acc@5 100.00 ( 96.52)
Epoch: [37][120/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 7.8786e-01 (7.1026e-01)	Acc@1  77.34 ( 78.36)	Acc@5  98.44 ( 96.49)
Epoch: [37][130/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 8.1693e-01 (7.1905e-01)	Acc@1  74.22 ( 78.07)	Acc@5  94.53 ( 96.40)
Epoch: [37][140/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.7436e-01 (7.2190e-01)	Acc@1  80.47 ( 78.02)	Acc@5  96.09 ( 96.33)
Epoch: [37][150/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.1882e-01 (7.2494e-01)	Acc@1  80.47 ( 77.90)	Acc@5  97.66 ( 96.30)
Epoch: [37][160/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 7.2612e-01 (7.2775e-01)	Acc@1  77.34 ( 77.85)	Acc@5  96.88 ( 96.24)
Epoch: [37][170/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.5974e-01 (7.3049e-01)	Acc@1  76.56 ( 77.74)	Acc@5  96.88 ( 96.22)
Epoch: [37][180/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.3612e-01 (7.3128e-01)	Acc@1  76.56 ( 77.68)	Acc@5  98.44 ( 96.23)
Epoch: [37][190/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.2300e-01 (7.3639e-01)	Acc@1  81.25 ( 77.53)	Acc@5  98.44 ( 96.17)
Epoch: [37][200/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 8.7159e-01 (7.3731e-01)	Acc@1  75.00 ( 77.54)	Acc@5  93.75 ( 96.15)
Epoch: [37][210/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 7.1685e-01 (7.4033e-01)	Acc@1  78.91 ( 77.47)	Acc@5  96.88 ( 96.08)
Epoch: [37][220/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 9.2564e-01 (7.4216e-01)	Acc@1  72.66 ( 77.42)	Acc@5  95.31 ( 96.07)
Epoch: [37][230/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.002)	Loss 9.2245e-01 (7.4652e-01)	Acc@1  71.88 ( 77.30)	Acc@5  92.97 ( 96.02)
Epoch: [37][240/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.5885e-01 (7.4681e-01)	Acc@1  81.25 ( 77.27)	Acc@5  97.66 ( 96.06)
Epoch: [37][250/391]	Time  0.046 ( 0.042)	Data  0.001 ( 0.002)	Loss 7.7944e-01 (7.4883e-01)	Acc@1  82.81 ( 77.25)	Acc@5  92.97 ( 96.02)
Epoch: [37][260/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 7.9479e-01 (7.5041e-01)	Acc@1  75.78 ( 77.20)	Acc@5  97.66 ( 96.05)
Epoch: [37][270/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 7.1438e-01 (7.4986e-01)	Acc@1  80.47 ( 77.23)	Acc@5  96.88 ( 96.05)
Epoch: [37][280/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.1725e-01 (7.5030e-01)	Acc@1  82.81 ( 77.17)	Acc@5  98.44 ( 96.08)
Epoch: [37][290/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.7237e-01 (7.5057e-01)	Acc@1  80.47 ( 77.15)	Acc@5  95.31 ( 96.05)
Epoch: [37][300/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 9.6421e-01 (7.5118e-01)	Acc@1  67.19 ( 77.15)	Acc@5  94.53 ( 96.03)
Epoch: [37][310/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 7.5306e-01 (7.5314e-01)	Acc@1  78.12 ( 77.06)	Acc@5  95.31 ( 96.02)
Epoch: [37][320/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 9.7824e-01 (7.5467e-01)	Acc@1  68.75 ( 77.01)	Acc@5  94.53 ( 96.01)
Epoch: [37][330/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 7.1411e-01 (7.5708e-01)	Acc@1  76.56 ( 76.91)	Acc@5  98.44 ( 96.01)
Epoch: [37][340/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.0253e-01 (7.5818e-01)	Acc@1  79.69 ( 76.89)	Acc@5  97.66 ( 95.99)
Epoch: [37][350/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.001)	Loss 8.0089e-01 (7.5948e-01)	Acc@1  73.44 ( 76.87)	Acc@5  92.97 ( 95.96)
Epoch: [37][360/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.001)	Loss 8.7317e-01 (7.6075e-01)	Acc@1  72.66 ( 76.84)	Acc@5  96.88 ( 95.95)
Epoch: [37][370/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 7.9119e-01 (7.6313e-01)	Acc@1  75.00 ( 76.77)	Acc@5  93.75 ( 95.93)
Epoch: [37][380/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 6.8754e-01 (7.6507e-01)	Acc@1  78.12 ( 76.73)	Acc@5  97.66 ( 95.91)
Epoch: [37][390/391]	Time  0.029 ( 0.042)	Data  0.001 ( 0.001)	Loss 8.0080e-01 (7.6702e-01)	Acc@1  71.25 ( 76.67)	Acc@5  97.50 ( 95.89)
## e[37] optimizer.zero_grad (sum) time: 0.28489017486572266
## e[37]       loss.backward (sum) time: 4.093235731124878
## e[37]      optimizer.step (sum) time: 1.9049932956695557
## epoch[37] training(only) time: 16.392364501953125
# Switched to evaluate mode...
Test: [  0/100]	Time  0.151 ( 0.151)	Loss 1.3283e+00 (1.3283e+00)	Acc@1  67.00 ( 67.00)	Acc@5  90.00 ( 90.00)
Test: [ 10/100]	Time  0.022 ( 0.034)	Loss 1.4188e+00 (1.5465e+00)	Acc@1  64.00 ( 61.55)	Acc@5  92.00 ( 86.82)
Test: [ 20/100]	Time  0.023 ( 0.028)	Loss 1.1553e+00 (1.4559e+00)	Acc@1  70.00 ( 63.14)	Acc@5  93.00 ( 88.52)
Test: [ 30/100]	Time  0.019 ( 0.026)	Loss 1.6436e+00 (1.4848e+00)	Acc@1  58.00 ( 62.10)	Acc@5  90.00 ( 88.42)
Test: [ 40/100]	Time  0.022 ( 0.024)	Loss 1.4880e+00 (1.4742e+00)	Acc@1  65.00 ( 62.34)	Acc@5  88.00 ( 88.44)
Test: [ 50/100]	Time  0.024 ( 0.024)	Loss 1.4864e+00 (1.4877e+00)	Acc@1  68.00 ( 62.18)	Acc@5  92.00 ( 88.14)
Test: [ 60/100]	Time  0.024 ( 0.024)	Loss 1.6690e+00 (1.4769e+00)	Acc@1  55.00 ( 62.30)	Acc@5  88.00 ( 88.26)
Test: [ 70/100]	Time  0.024 ( 0.024)	Loss 1.3933e+00 (1.4683e+00)	Acc@1  69.00 ( 62.65)	Acc@5  88.00 ( 88.38)
Test: [ 80/100]	Time  0.024 ( 0.024)	Loss 1.4721e+00 (1.4744e+00)	Acc@1  65.00 ( 62.56)	Acc@5  84.00 ( 88.21)
Test: [ 90/100]	Time  0.021 ( 0.024)	Loss 2.0232e+00 (1.4693e+00)	Acc@1  59.00 ( 62.70)	Acc@5  81.00 ( 88.21)
 * Acc@1 62.970 Acc@5 88.260
### epoch[37] execution time: 18.83101773262024
EPOCH 38
i:   0, name:           module.stem.0.weight  changing lr from: 0.010278393921015021   to: 0.008396515016716099
i:   1, name:             module.stem.0.bias  changing lr from: 0.010820808624770743   to: 0.008900256547713335
i:   2, name:           module.stem.1.weight  changing lr from: 0.011371433757897682   to: 0.009414003911999192
i:   3, name:             module.stem.1.bias  changing lr from: 0.011929760340165234   to: 0.009937205226997942
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.012495294809443381   to: 0.010469324283703119
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.013067558771401911   to: 0.011009840344671468
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.013646088741366386   to: 0.011558247930092962
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.014230435879436794   to: 0.012114056593271711
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.014820165719898561   to: 0.012676790686766148
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.015414857895883722   to: 0.013245989120355552
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.016014105860171275   to: 0.013821205111922197
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.016617516602951569   to: 0.014402005932265278
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.017224710367318107   to: 0.014987972644791604
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.017835320363193016   to: 0.015578699840964098
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.018448992480337469   to: 0.016173795372324100
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.019065385001047847   to: 0.016772880079846758
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.019684168313089251   to: 0.017375587521330366
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.020305024623373635   to: 0.017981563697470178
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.020927647672846023   to: 0.018590466777215237
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.021551742453002978   to: 0.019201966822961027
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.022177024924429252   to: 0.019815745516086211
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.022803221737703695   to: 0.020431495883299761
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.023430069956991789   to: 0.021048922024225772
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.024057316786611618   to: 0.021667738840616499
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.024684719300830840   to: 0.022287671767549179
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.025312044177125011   to: 0.022908456506930054
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.025939067433102286   to: 0.023529838763598300
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.026565574167276271   to: 0.024151573984294225
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.027191358303845836   to: 0.024773427099729180
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.027816222341621084   to: 0.025395172269969613
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.028439977107214832   to: 0.026016592633324388
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.029062441512602011   to: 0.026637480058903231
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.029683442317131825   to: 0.027257634902992312
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.030302813894063380   to: 0.027876865769376070
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.030920398001680269   to: 0.028494989273714799
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.031536043559027532   to: 0.029111829812072682
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.032149606426301526   to: 0.029727219333674462
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.032760949189912500   to: 0.030340997117955945
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.033369940952229428   to: 0.030953009555959365
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.033976457126007054   to: 0.031563109936113429
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.034580379233486780   to: 0.032171158234426192
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.035181594710154793   to: 0.032777020909108716
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.035779996713133810   to: 0.033380570699637846
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.036375483934178464   to: 0.033981686430258222
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.036967960417237877   to: 0.034580252817914679
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.037557335380544156   to: 0.035176160284600071
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.038143523043180132   to: 0.035769304774095519
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.038726442456076211   to: 0.036359587573075586
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.039306017337380768   to: 0.036946915136543385
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.039882175912146878   to: 0.037531198917557622
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.040454850756273475   to: 0.038112355201207447
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.041023978644637492   to: 0.038690304942787808
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.041589500403350500   to: 0.039264973610124126
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.042151360766071636   to: 0.039836291029991699
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.042709508234306859   to: 0.040404191238572654
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.043263894941622548   to: 0.040968612335890150
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.043814476521701673   to: 0.041529496344158347
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.044361211980167847   to: 0.042086789069983616
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.044904063570103611   to: 0.042640439970351496
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.045442996671187369   to: 0.043190402022332264
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.045977979672374221   to: 0.043736631596437162
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.046508983858044667   to: 0.044279088333555816
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.047035983297545818   to: 0.044817735025405141
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.047558954738049559   to: 0.045352537498419311
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.048077877500652642   to: 0.045883464501010163
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.048592733379643455   to: 0.046410487594126831
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.049103506544861467   to: 0.046933581045043818
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.049610183447074983   to: 0.047452721724306340
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.050112752726304610   to: 0.047967889005762453
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.050611205123019316   to: 0.048479064669611188
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.051105533392134056   to: 0.048986232808397166
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.051595732219737400   to: 0.049489379735881418
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.052081798142480179   to: 0.049988493898720399
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.052563729469555204   to: 0.050483565790884005
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.053041526207201255   to: 0.050974587870745908
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.053515189985663569   to: 0.051461554480778750
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.053984723988545716   to: 0.051944461769788820
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.054450132884487835   to: 0.052423307617624773
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.054911422761108067   to: 0.052898091562296828
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.055368601061144766   to: 0.053368814729442986
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.055821676520738051   to: 0.053835479764080221
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.056270659109791545   to: 0.054298090764579865
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.056715559974354526   to: 0.054756653218806933
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.057156391380968001   to: 0.055211173942364682
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.057593166662917444   to: 0.055661661018886366
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.058025900168338002   to: 0.056108123742317918
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.058454607210117505   to: 0.056550572561135416
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.058879304017545153   to: 0.056989019024443421
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.059300007689654113   to: 0.057423475729900544
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.059716736150207811   to: 0.057853956273420097
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.060129508104280888   to: 0.058280475200594865
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.060538342996386899   to: 0.058703047959795987
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.060943260970105974   to: 0.059121690856897113
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.061344282829166701   to: 0.059536421011576329
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.061741429999938084   to: 0.059947256315148835
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.062134724495288007   to: 0.060354215389885439
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.062524188879766046   to: 0.060757317549772032
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.062909846236069461   to: 0.061156582762667049
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.063291720132752333   to: 0.061552031613814229
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.063669834593138797   to: 0.061943685270670068
i: 100, name:           module.conv10.weight  changing lr from: 0.064044214065402616   to: 0.062331565449005213
i: 101, name:             module.conv10.bias  changing lr from: 0.064414883393775643   to: 0.062715694380241077



# Switched to train mode...
Epoch: [38][  0/391]	Time  0.194 ( 0.194)	Data  0.143 ( 0.143)	Loss 6.1379e-01 (6.1379e-01)	Acc@1  84.38 ( 84.38)	Acc@5  96.88 ( 96.88)
Epoch: [38][ 10/391]	Time  0.040 ( 0.056)	Data  0.001 ( 0.014)	Loss 7.1026e-01 (7.2090e-01)	Acc@1  75.00 ( 77.34)	Acc@5  99.22 ( 97.09)
Epoch: [38][ 20/391]	Time  0.041 ( 0.049)	Data  0.001 ( 0.008)	Loss 6.7094e-01 (7.0908e-01)	Acc@1  78.91 ( 77.83)	Acc@5  98.44 ( 97.28)
Epoch: [38][ 30/391]	Time  0.041 ( 0.046)	Data  0.001 ( 0.006)	Loss 7.2307e-01 (6.8425e-01)	Acc@1  75.78 ( 78.63)	Acc@5  96.88 ( 97.28)
Epoch: [38][ 40/391]	Time  0.043 ( 0.045)	Data  0.001 ( 0.004)	Loss 8.6693e-01 (6.9072e-01)	Acc@1  71.09 ( 78.47)	Acc@5  93.75 ( 96.99)
Epoch: [38][ 50/391]	Time  0.043 ( 0.045)	Data  0.001 ( 0.004)	Loss 6.7942e-01 (7.0184e-01)	Acc@1  82.81 ( 78.26)	Acc@5  96.09 ( 96.81)
Epoch: [38][ 60/391]	Time  0.040 ( 0.044)	Data  0.001 ( 0.003)	Loss 8.0670e-01 (7.0471e-01)	Acc@1  76.56 ( 78.27)	Acc@5  94.53 ( 96.71)
Epoch: [38][ 70/391]	Time  0.045 ( 0.044)	Data  0.001 ( 0.003)	Loss 8.2259e-01 (7.1362e-01)	Acc@1  74.22 ( 77.99)	Acc@5  94.53 ( 96.57)
Epoch: [38][ 80/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.003)	Loss 8.4279e-01 (7.1918e-01)	Acc@1  74.22 ( 77.95)	Acc@5  96.09 ( 96.46)
Epoch: [38][ 90/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.003)	Loss 8.5992e-01 (7.2104e-01)	Acc@1  75.78 ( 77.99)	Acc@5  92.97 ( 96.44)
Epoch: [38][100/391]	Time  0.041 ( 0.043)	Data  0.002 ( 0.002)	Loss 8.0837e-01 (7.2225e-01)	Acc@1  75.00 ( 77.92)	Acc@5  95.31 ( 96.42)
Epoch: [38][110/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.002)	Loss 9.4074e-01 (7.2414e-01)	Acc@1  69.53 ( 77.83)	Acc@5  95.31 ( 96.40)
Epoch: [38][120/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 7.8288e-01 (7.2571e-01)	Acc@1  79.69 ( 77.78)	Acc@5  94.53 ( 96.31)
Epoch: [38][130/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 6.8997e-01 (7.2945e-01)	Acc@1  78.12 ( 77.73)	Acc@5  96.88 ( 96.28)
Epoch: [38][140/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.002)	Loss 6.4910e-01 (7.3382e-01)	Acc@1  82.81 ( 77.71)	Acc@5  96.88 ( 96.22)
Epoch: [38][150/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.002)	Loss 6.8391e-01 (7.3523e-01)	Acc@1  78.91 ( 77.65)	Acc@5  98.44 ( 96.21)
Epoch: [38][160/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 7.0320e-01 (7.3246e-01)	Acc@1  79.69 ( 77.72)	Acc@5  96.88 ( 96.24)
Epoch: [38][170/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.002)	Loss 8.0768e-01 (7.3428e-01)	Acc@1  72.66 ( 77.65)	Acc@5  93.75 ( 96.20)
Epoch: [38][180/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.002)	Loss 7.6523e-01 (7.3377e-01)	Acc@1  75.78 ( 77.64)	Acc@5  97.66 ( 96.20)
Epoch: [38][190/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.5419e-01 (7.3290e-01)	Acc@1  81.25 ( 77.57)	Acc@5  97.66 ( 96.21)
Epoch: [38][200/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 8.2933e-01 (7.3439e-01)	Acc@1  71.88 ( 77.50)	Acc@5  93.75 ( 96.21)
Epoch: [38][210/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 8.7814e-01 (7.3468e-01)	Acc@1  72.66 ( 77.46)	Acc@5  96.09 ( 96.23)
Epoch: [38][220/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 7.2933e-01 (7.3331e-01)	Acc@1  79.69 ( 77.51)	Acc@5  95.31 ( 96.27)
Epoch: [38][230/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.002)	Loss 8.6152e-01 (7.3161e-01)	Acc@1  74.22 ( 77.56)	Acc@5  96.09 ( 96.31)
Epoch: [38][240/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.2595e-01 (7.3141e-01)	Acc@1  76.56 ( 77.59)	Acc@5  98.44 ( 96.33)
Epoch: [38][250/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.0058e-01 (7.3369e-01)	Acc@1  79.69 ( 77.48)	Acc@5 100.00 ( 96.33)
Epoch: [38][260/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 8.9220e-01 (7.3517e-01)	Acc@1  69.53 ( 77.41)	Acc@5  94.53 ( 96.32)
Epoch: [38][270/391]	Time  0.046 ( 0.042)	Data  0.001 ( 0.001)	Loss 8.5765e-01 (7.3714e-01)	Acc@1  69.53 ( 77.27)	Acc@5  96.09 ( 96.33)
Epoch: [38][280/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 7.0976e-01 (7.3730e-01)	Acc@1  75.78 ( 77.25)	Acc@5  96.09 ( 96.33)
Epoch: [38][290/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.001)	Loss 5.2398e-01 (7.3896e-01)	Acc@1  85.94 ( 77.17)	Acc@5  97.66 ( 96.32)
Epoch: [38][300/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.001)	Loss 7.0749e-01 (7.3723e-01)	Acc@1  78.12 ( 77.23)	Acc@5  98.44 ( 96.35)
Epoch: [38][310/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.001)	Loss 9.5360e-01 (7.3627e-01)	Acc@1  71.09 ( 77.23)	Acc@5  93.75 ( 96.35)
Epoch: [38][320/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.001)	Loss 5.6220e-01 (7.3588e-01)	Acc@1  79.69 ( 77.24)	Acc@5  99.22 ( 96.36)
Epoch: [38][330/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.001)	Loss 7.6147e-01 (7.3760e-01)	Acc@1  77.34 ( 77.20)	Acc@5  96.09 ( 96.32)
Epoch: [38][340/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.001)	Loss 7.9383e-01 (7.3853e-01)	Acc@1  78.91 ( 77.18)	Acc@5  95.31 ( 96.31)
Epoch: [38][350/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.001)	Loss 6.2850e-01 (7.3867e-01)	Acc@1  76.56 ( 77.18)	Acc@5  99.22 ( 96.30)
Epoch: [38][360/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.001)	Loss 7.8723e-01 (7.4059e-01)	Acc@1  76.56 ( 77.13)	Acc@5  96.09 ( 96.28)
Epoch: [38][370/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 9.3663e-01 (7.4260e-01)	Acc@1  72.66 ( 77.10)	Acc@5  95.31 ( 96.27)
Epoch: [38][380/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.001)	Loss 6.8416e-01 (7.4479e-01)	Acc@1  77.34 ( 77.06)	Acc@5  94.53 ( 96.23)
Epoch: [38][390/391]	Time  0.029 ( 0.042)	Data  0.001 ( 0.001)	Loss 8.9452e-01 (7.4636e-01)	Acc@1  75.00 ( 77.05)	Acc@5  92.50 ( 96.20)
## e[38] optimizer.zero_grad (sum) time: 0.28533387184143066
## e[38]       loss.backward (sum) time: 4.159278869628906
## e[38]      optimizer.step (sum) time: 1.8445000648498535
## epoch[38] training(only) time: 16.453184366226196
# Switched to evaluate mode...
Test: [  0/100]	Time  0.163 ( 0.163)	Loss 1.3519e+00 (1.3519e+00)	Acc@1  68.00 ( 68.00)	Acc@5  88.00 ( 88.00)
Test: [ 10/100]	Time  0.024 ( 0.035)	Loss 1.7445e+00 (1.5885e+00)	Acc@1  58.00 ( 63.36)	Acc@5  86.00 ( 86.55)
Test: [ 20/100]	Time  0.024 ( 0.030)	Loss 1.1457e+00 (1.5009e+00)	Acc@1  66.00 ( 63.48)	Acc@5  92.00 ( 87.71)
Test: [ 30/100]	Time  0.023 ( 0.027)	Loss 1.5636e+00 (1.5164e+00)	Acc@1  59.00 ( 62.52)	Acc@5  89.00 ( 87.58)
Test: [ 40/100]	Time  0.022 ( 0.026)	Loss 1.5920e+00 (1.5022e+00)	Acc@1  61.00 ( 62.51)	Acc@5  87.00 ( 87.66)
Test: [ 50/100]	Time  0.021 ( 0.025)	Loss 1.5796e+00 (1.4979e+00)	Acc@1  60.00 ( 62.55)	Acc@5  87.00 ( 87.43)
Test: [ 60/100]	Time  0.024 ( 0.025)	Loss 1.4718e+00 (1.4829e+00)	Acc@1  61.00 ( 62.39)	Acc@5  91.00 ( 87.59)
Test: [ 70/100]	Time  0.022 ( 0.024)	Loss 1.4082e+00 (1.4740e+00)	Acc@1  62.00 ( 62.77)	Acc@5  89.00 ( 87.73)
Test: [ 80/100]	Time  0.029 ( 0.024)	Loss 1.5210e+00 (1.4786e+00)	Acc@1  62.00 ( 62.59)	Acc@5  87.00 ( 87.73)
Test: [ 90/100]	Time  0.024 ( 0.024)	Loss 1.9039e+00 (1.4699e+00)	Acc@1  60.00 ( 62.89)	Acc@5  83.00 ( 87.75)
 * Acc@1 63.030 Acc@5 87.890
### epoch[38] execution time: 18.946365118026733
EPOCH 39
i:   0, name:           module.stem.0.weight  changing lr from: 0.008396515016716099   to: 0.006712584379435493
i:   1, name:             module.stem.0.bias  changing lr from: 0.008900256547713335   to: 0.007172461227534282
i:   2, name:           module.stem.1.weight  changing lr from: 0.009414003911999192   to: 0.007644210162291009
i:   3, name:             module.stem.1.bias  changing lr from: 0.009937205226997942   to: 0.008127238169718536
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.010469324283703119   to: 0.008620967952089536
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.011009840344671468   to: 0.009124837786484128
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.011558247930092962   to: 0.009638301366807298
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.012114056593271711   to: 0.010160827630853880
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.012676790686766148   to: 0.010691900573903245
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.013245989120355552   to: 0.011231019050234915
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.013821205111922197   to: 0.011777696563869417
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.014402005932265278   to: 0.012331461049756482
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.014987972644791604   to: 0.012891854646553329
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.015578699840964098   to: 0.013458433462062287
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.016173795372324100   to: 0.014030767332324657
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.016772880079846758   to: 0.014608439575301935
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.017375587521330366   to: 0.015191046740010261
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.017981563697470178   to: 0.015778198351914869
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.018590466777215237   to: 0.016369516655332882
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.019201966822961027   to: 0.016964636353539536
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.019815745516086211   to: 0.017563204347221178
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.020431495883299761   to: 0.018164879471870572
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.021048922024225772   to: 0.018769332234673679
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.021667738840616499   to: 0.019376244551395000
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.022287671767549179   to: 0.019985309483727134
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.022908456506930054   to: 0.020596230977532434
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.023529838763598300   to: 0.021208723602368702
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.024151573984294225   to: 0.021822512292657272
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.024773427099729180   to: 0.022437332090819263
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.025395172269969613   to: 0.023052927892677041
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.026016592633324388   to: 0.023669054195389012
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.026637480058903231   to: 0.024285474848160876
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.027257634902992312   to: 0.024901962805950001
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.027876865769376070   to: 0.025518299886358942
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.028494989273714799   to: 0.026134276529890667
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.029111829812072682   to: 0.026749691563719254
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.029727219333674462   to: 0.027364351969110540
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.030340997117955945   to: 0.027978072652609966
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.030953009555959365   to: 0.028590676221098468
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.031563109936113429   to: 0.029201992760802410
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.032171158234426192   to: 0.029811859620329336
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.032777020909108716   to: 0.030420121197788419
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.033380570699637846   to: 0.031026628732042000
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.033981686430258222   to: 0.031631240098124465
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.034580252817914679   to: 0.032233819606852961
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.035176160284600071   to: 0.032834237808646353
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.035769304774095519   to: 0.033432371301558787
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.036359587573075586   to: 0.034028102543527471
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.036946915136543385   to: 0.034621319668825326
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.037531198917557622   to: 0.035211916308704072
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.038112355201207447   to: 0.035799791416205637
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.038690304942787808   to: 0.036384849095115003
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.039264973610124126   to: 0.036966998433022362
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.039836291029991699   to: 0.037546153338457421
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.040404191238572654   to: 0.038122232382054984
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.040968612335890150   to: 0.038695158641706418
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.041529496344158347   to: 0.039264859551649503
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.042086789069983616   to: 0.039831266755444517
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.042640439970351496   to: 0.040394315962783083
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.043190402022332264   to: 0.040953946810073069
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.043736631596437162   to: 0.041510102724741489
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.044279088333555816   to: 0.042062730793194628
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.044817735025405141   to: 0.042611781632374113
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.045352537498419311   to: 0.043157209264845481
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.045883464501010163   to: 0.043698970997355313
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.046410487594126831   to: 0.044237027302791901
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.046933581045043818   to: 0.044771341705483553
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.047452721724306340   to: 0.045301880669768368
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.047967889005762453   to: 0.045828613491769171
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.048479064669611188   to: 0.046351512194306325
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.048986232808397166   to: 0.046870551424882084
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.049489379735881418   to: 0.047385708356669283
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.049988493898720399   to: 0.047896962592438141
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.050483565790884005   to: 0.048404296071354297
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.050974587870745908   to: 0.048907692978582912
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.051461554480778750   to: 0.049407139657632444
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.051944461769788820   to: 0.049902624525373897
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.052423307617624773   to: 0.050394137989670518
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.052898091562296828   to: 0.050881672369554959
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.053368814729442986   to: 0.051365221817890383
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.053835479764080221   to: 0.051844782246453558
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.054298090764579865   to: 0.052320351253378750
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.054756653218806933   to: 0.052791928052901706
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.055211173942364682   to: 0.053259513407344319
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.055661661018886366   to: 0.053723109561281172
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.056108123742317918   to: 0.054182720177830761
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.056550572561135416   to: 0.054638350277013914
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.056989019024443421   to: 0.055090006176124633
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.057423475729900544   to: 0.055537695432057992
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.057853956273420097   to: 0.055981426785541868
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.058280475200594865   to: 0.056421210107219823
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.058703047959795987   to: 0.056857056345533369
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.059121690856897113   to: 0.057288977476353732
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.059536421011576329   to: 0.057716986454312807
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.059947256315148835   to: 0.058141097165785853
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.060354215389885439   to: 0.058561324383477845
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.060757317549772032   to: 0.058977683722567759
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.061156582762667049   to: 0.059390191598365165
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.061552031613814229   to: 0.059798865185435229
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.061943685270670068   to: 0.060203722378148694
i: 100, name:           module.conv10.weight  changing lr from: 0.062331565449005213   to: 0.060604781752614995
i: 101, name:             module.conv10.bias  changing lr from: 0.062715694380241077   to: 0.061002062529957046



# Switched to train mode...
Epoch: [39][  0/391]	Time  0.202 ( 0.202)	Data  0.149 ( 0.149)	Loss 7.7948e-01 (7.7948e-01)	Acc@1  72.66 ( 72.66)	Acc@5  97.66 ( 97.66)
Epoch: [39][ 10/391]	Time  0.038 ( 0.056)	Data  0.001 ( 0.014)	Loss 6.2158e-01 (6.9921e-01)	Acc@1  80.47 ( 78.48)	Acc@5  99.22 ( 97.30)
Epoch: [39][ 20/391]	Time  0.038 ( 0.048)	Data  0.001 ( 0.008)	Loss 6.9248e-01 (7.0252e-01)	Acc@1  78.12 ( 78.27)	Acc@5  95.31 ( 96.95)
Epoch: [39][ 30/391]	Time  0.043 ( 0.046)	Data  0.001 ( 0.006)	Loss 6.4444e-01 (6.9135e-01)	Acc@1  82.03 ( 79.03)	Acc@5  95.31 ( 96.90)
Epoch: [39][ 40/391]	Time  0.039 ( 0.044)	Data  0.001 ( 0.005)	Loss 6.8805e-01 (6.8957e-01)	Acc@1  80.47 ( 79.29)	Acc@5  96.88 ( 96.86)
Epoch: [39][ 50/391]	Time  0.039 ( 0.043)	Data  0.001 ( 0.004)	Loss 7.0273e-01 (6.9444e-01)	Acc@1  78.91 ( 79.21)	Acc@5  97.66 ( 96.78)
Epoch: [39][ 60/391]	Time  0.044 ( 0.043)	Data  0.001 ( 0.004)	Loss 6.0864e-01 (6.9723e-01)	Acc@1  81.25 ( 79.11)	Acc@5  97.66 ( 96.72)
Epoch: [39][ 70/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.003)	Loss 5.7647e-01 (6.9638e-01)	Acc@1  84.38 ( 79.16)	Acc@5  97.66 ( 96.78)
Epoch: [39][ 80/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.003)	Loss 7.4257e-01 (6.9579e-01)	Acc@1  75.00 ( 79.06)	Acc@5  96.88 ( 96.76)
Epoch: [39][ 90/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.003)	Loss 7.3231e-01 (6.9470e-01)	Acc@1  78.91 ( 78.96)	Acc@5  96.88 ( 96.81)
Epoch: [39][100/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.003)	Loss 9.1639e-01 (6.9174e-01)	Acc@1  73.44 ( 79.00)	Acc@5  96.88 ( 96.90)
Epoch: [39][110/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.7036e-01 (6.9062e-01)	Acc@1  78.91 ( 78.96)	Acc@5  96.88 ( 96.89)
Epoch: [39][120/391]	Time  0.046 ( 0.042)	Data  0.001 ( 0.002)	Loss 7.5097e-01 (6.9239e-01)	Acc@1  75.78 ( 78.82)	Acc@5  92.97 ( 96.85)
Epoch: [39][130/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.0672e-01 (6.9235e-01)	Acc@1  78.12 ( 78.75)	Acc@5  96.09 ( 96.85)
Epoch: [39][140/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 8.4817e-01 (6.9548e-01)	Acc@1  73.44 ( 78.63)	Acc@5  96.88 ( 96.83)
Epoch: [39][150/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 7.8761e-01 (6.9466e-01)	Acc@1  77.34 ( 78.66)	Acc@5  96.09 ( 96.80)
Epoch: [39][160/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 8.0417e-01 (6.9668e-01)	Acc@1  78.12 ( 78.64)	Acc@5  95.31 ( 96.73)
Epoch: [39][170/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 7.2760e-01 (6.9642e-01)	Acc@1  76.56 ( 78.59)	Acc@5  93.75 ( 96.74)
Epoch: [39][180/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 7.4388e-01 (6.9780e-01)	Acc@1  78.91 ( 78.52)	Acc@5  95.31 ( 96.74)
Epoch: [39][190/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 7.4959e-01 (7.0196e-01)	Acc@1  74.22 ( 78.42)	Acc@5  95.31 ( 96.68)
Epoch: [39][200/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 8.3677e-01 (7.0403e-01)	Acc@1  77.34 ( 78.40)	Acc@5  94.53 ( 96.60)
Epoch: [39][210/391]	Time  0.046 ( 0.042)	Data  0.001 ( 0.002)	Loss 7.7736e-01 (7.0788e-01)	Acc@1  75.78 ( 78.27)	Acc@5  97.66 ( 96.56)
Epoch: [39][220/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.1040e-01 (7.0806e-01)	Acc@1  80.47 ( 78.23)	Acc@5  99.22 ( 96.54)
Epoch: [39][230/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 9.3432e-01 (7.1089e-01)	Acc@1  73.44 ( 78.14)	Acc@5  95.31 ( 96.53)
Epoch: [39][240/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.0491e-01 (7.1157e-01)	Acc@1  82.03 ( 78.09)	Acc@5  98.44 ( 96.54)
Epoch: [39][250/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.9070e-01 (7.1091e-01)	Acc@1  75.78 ( 78.11)	Acc@5  96.09 ( 96.51)
Epoch: [39][260/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 8.6345e-01 (7.1510e-01)	Acc@1  72.66 ( 77.92)	Acc@5  93.75 ( 96.44)
Epoch: [39][270/391]	Time  0.047 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.6414e-01 (7.1739e-01)	Acc@1  77.34 ( 77.86)	Acc@5  99.22 ( 96.45)
Epoch: [39][280/391]	Time  0.042 ( 0.042)	Data  0.002 ( 0.002)	Loss 8.4804e-01 (7.1877e-01)	Acc@1  76.56 ( 77.83)	Acc@5  96.88 ( 96.45)
Epoch: [39][290/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.6803e-01 (7.1900e-01)	Acc@1  79.69 ( 77.84)	Acc@5  97.66 ( 96.45)
Epoch: [39][300/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.9288e-01 (7.1990e-01)	Acc@1  83.59 ( 77.75)	Acc@5  99.22 ( 96.45)
Epoch: [39][310/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.5276e-01 (7.1989e-01)	Acc@1  83.59 ( 77.81)	Acc@5  99.22 ( 96.47)
Epoch: [39][320/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 7.4937e-01 (7.1954e-01)	Acc@1  77.34 ( 77.82)	Acc@5  96.88 ( 96.49)
Epoch: [39][330/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 5.8835e-01 (7.1950e-01)	Acc@1  81.25 ( 77.85)	Acc@5  98.44 ( 96.48)
Epoch: [39][340/391]	Time  0.046 ( 0.042)	Data  0.001 ( 0.001)	Loss 7.2841e-01 (7.2059e-01)	Acc@1  79.69 ( 77.84)	Acc@5  96.09 ( 96.46)
Epoch: [39][350/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.001)	Loss 8.0641e-01 (7.2005e-01)	Acc@1  72.66 ( 77.85)	Acc@5  95.31 ( 96.47)
Epoch: [39][360/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.001)	Loss 7.8343e-01 (7.2161e-01)	Acc@1  72.66 ( 77.81)	Acc@5  95.31 ( 96.46)
Epoch: [39][370/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.001)	Loss 8.7260e-01 (7.2181e-01)	Acc@1  71.09 ( 77.80)	Acc@5  94.53 ( 96.43)
Epoch: [39][380/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.001)	Loss 7.8129e-01 (7.2340e-01)	Acc@1  82.03 ( 77.77)	Acc@5  93.75 ( 96.39)
Epoch: [39][390/391]	Time  0.029 ( 0.042)	Data  0.001 ( 0.001)	Loss 8.0781e-01 (7.2418e-01)	Acc@1  72.50 ( 77.73)	Acc@5  96.25 ( 96.40)
## e[39] optimizer.zero_grad (sum) time: 0.287520170211792
## e[39]       loss.backward (sum) time: 4.117673635482788
## e[39]      optimizer.step (sum) time: 1.914161205291748
## epoch[39] training(only) time: 16.469783306121826
# Switched to evaluate mode...
Test: [  0/100]	Time  0.157 ( 0.157)	Loss 1.2441e+00 (1.2441e+00)	Acc@1  69.00 ( 69.00)	Acc@5  90.00 ( 90.00)
Test: [ 10/100]	Time  0.024 ( 0.035)	Loss 1.4257e+00 (1.5075e+00)	Acc@1  66.00 ( 63.18)	Acc@5  89.00 ( 87.73)
Test: [ 20/100]	Time  0.021 ( 0.029)	Loss 1.1710e+00 (1.4430e+00)	Acc@1  67.00 ( 63.43)	Acc@5  92.00 ( 88.38)
Test: [ 30/100]	Time  0.022 ( 0.027)	Loss 1.6078e+00 (1.4671e+00)	Acc@1  63.00 ( 62.77)	Acc@5  89.00 ( 87.87)
Test: [ 40/100]	Time  0.023 ( 0.025)	Loss 1.7033e+00 (1.4629e+00)	Acc@1  57.00 ( 62.80)	Acc@5  89.00 ( 88.02)
Test: [ 50/100]	Time  0.026 ( 0.025)	Loss 1.4975e+00 (1.4715e+00)	Acc@1  63.00 ( 62.84)	Acc@5  87.00 ( 87.84)
Test: [ 60/100]	Time  0.018 ( 0.024)	Loss 1.6421e+00 (1.4605e+00)	Acc@1  65.00 ( 63.13)	Acc@5  84.00 ( 88.15)
Test: [ 70/100]	Time  0.019 ( 0.024)	Loss 1.5319e+00 (1.4607e+00)	Acc@1  60.00 ( 63.13)	Acc@5  91.00 ( 88.31)
Test: [ 80/100]	Time  0.022 ( 0.023)	Loss 1.5864e+00 (1.4726e+00)	Acc@1  63.00 ( 62.91)	Acc@5  84.00 ( 88.05)
Test: [ 90/100]	Time  0.021 ( 0.023)	Loss 1.9180e+00 (1.4617e+00)	Acc@1  58.00 ( 63.15)	Acc@5  84.00 ( 88.15)
 * Acc@1 63.500 Acc@5 88.160
### epoch[39] execution time: 18.844545602798462
EPOCH 40
i:   0, name:           module.stem.0.weight  changing lr from: 0.006712584379435493   to: 0.005234426044027662
i:   1, name:             module.stem.0.bias  changing lr from: 0.007172461227534282   to: 0.005645333501572674
i:   2, name:           module.stem.1.weight  changing lr from: 0.007644210162291009   to: 0.006070037821654799
i:   3, name:             module.stem.1.bias  changing lr from: 0.008127238169718536   to: 0.006507907289942610
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.008620967952089536   to: 0.006958325712136919
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.009124837786484128   to: 0.007420692346008445
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.009638301366807298   to: 0.007894421811782553
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.010160827630853880   to: 0.008378943982703085
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.010691900573903245   to: 0.008873703857502691
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.011231019050234915   to: 0.009378161416407699
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.011777696563869417   to: 0.009891791462209393
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.012331461049756482   to: 0.010414083447842899
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.012891854646553329   to: 0.010944541291827085
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.013458433462062287   to: 0.011482683182836545
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.014030767332324657   to: 0.012028041374596714
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.014608439575301935   to: 0.012580161972218680
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.015191046740010261   to: 0.013138604711017486
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.015778198351914869   to: 0.013702942728790912
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.016369516655332882   to: 0.014272762332469453
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.016964636353539536   to: 0.014847662759988160
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.017563204347221178   to: 0.015427255938171715
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.018164879471870572   to: 0.016011166237369673
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.018769332234673679   to: 0.016599030223526053
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.019376244551395000   to: 0.017190496408318195
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.019985309483727134   to: 0.017785224997953087
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.020596230977532434   to: 0.018382887641165063
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.021208723602368702   to: 0.018983167176917067
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.021822512292657272   to: 0.019585757382268931
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.022437332090819263   to: 0.020190362720837837
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.023052927892677041   to: 0.020796698092242313
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.023669054195389012   to: 0.021404488582887717
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.024285474848160876   to: 0.022013469218420664
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.024901962805950001   to: 0.022623384718149866
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.025518299886358942   to: 0.023233989251704758
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.026134276529890667   to: 0.023845046198176890
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.026749691563719254   to: 0.024456327907965189
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.027364351969110540   to: 0.025067615467524104
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.027978072652609966   to: 0.025678698467191858
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.028590676221098468   to: 0.026289374772257269
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.029201992760802410   to: 0.026899450297404294
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.029811859620329336   to: 0.027508738784657163
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.030420121197788419   to: 0.028117061584932202
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.031026628732042000   to: 0.028724247443287960
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.031631240098124465   to: 0.029330132287951585
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.032233819606852961   to: 0.029934559023185727
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.032834237808646353   to: 0.030537377326049355
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.033432371301558787   to: 0.031138443447093673
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.034028102543527471   to: 0.031737620015025177
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.034621319668825326   to: 0.032334775845357294
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.035211916308704072   to: 0.032929785753064211
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.035799791416205637   to: 0.033522530369241819
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.036384849095115003   to: 0.034112895961773519
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.036966998433022362   to: 0.034700774259991983
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.037546153338457421   to: 0.035286062283321276
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.038122232382054984   to: 0.035868662173878442
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.038695158641706418   to: 0.036448481033008011
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.039264859551649503   to: 0.037025430761718971
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.039831266755444517   to: 0.037599427904988228
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.040394315962783083   to: 0.038170393499891930
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.040953946810073069   to: 0.038738252927521484
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.041510102724741489   to: 0.039302935768638983
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.042062730793194628   to: 0.039864375663022901
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.042611781632374113   to: 0.040422510172453227
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.043157209264845481   to: 0.040977280647282704
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.043698970997355313   to: 0.041528632096538953
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.044237027302791901   to: 0.042076513061500620
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.044771341705483553   to: 0.042620875492689239
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.045301880669768368   to: 0.043161674630217195
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.045828613491769171   to: 0.043698868887431616
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.046351512194306325   to: 0.044232419737792371
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.046870551424882084   to: 0.044762291604922753
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.047385708356669283   to: 0.045288451755769968
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.047896962592438141   to: 0.045810870196813014
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.048404296071354297   to: 0.046329519573254666
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.048907692978582912   to: 0.046844375071134987
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.049407139657632444   to: 0.047355414322302884
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.049902624525373897   to: 0.047862617312183428
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.050394137989670518   to: 0.048365966290277923
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.050881672369554959   to: 0.048865445683334841
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.051365221817890383   to: 0.049361042011129903
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.051844782246453558   to: 0.049852743804793459
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.052320351253378750   to: 0.050340541527625376
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.052791928052901706   to: 0.050824427498336475
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.053259513407344319   to: 0.051304395816657668
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.053723109561281172   to: 0.051780442291257847
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.054182720177830761   to: 0.052252564369912768
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.054638350277013914   to: 0.052720761071867697
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.055090006176124633   to: 0.053185032922337699
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.055537695432057992   to: 0.053645381889090016
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.055981426785541868   to: 0.054101811321054294
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.056421210107219823   to: 0.054554325888906789
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.056857056345533369   to: 0.055002931527576029
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.057288977476353732   to: 0.055447635380618546
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.057716986454312807   to: 0.055888445746413266
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.058141097165785853   to: 0.056325372026125579
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.058561324383477845   to: 0.056758424673391698
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.058977683722567759   to: 0.057187615145675955
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.059390191598365165   to: 0.057612955857253928
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.059798865185435229   to: 0.058034460133775667
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.060203722378148694   to: 0.058452142168364342
i: 100, name:           module.conv10.weight  changing lr from: 0.060604781752614995   to: 0.058866016979206084
i: 101, name:             module.conv10.bias  changing lr from: 0.061002062529957046   to: 0.059276100368588651



# Switched to train mode...
Epoch: [40][  0/391]	Time  0.189 ( 0.189)	Data  0.142 ( 0.142)	Loss 6.2896e-01 (6.2896e-01)	Acc@1  76.56 ( 76.56)	Acc@5  98.44 ( 98.44)
Epoch: [40][ 10/391]	Time  0.042 ( 0.056)	Data  0.001 ( 0.014)	Loss 7.0126e-01 (6.7297e-01)	Acc@1  74.22 ( 79.05)	Acc@5  96.09 ( 97.66)
Epoch: [40][ 20/391]	Time  0.044 ( 0.049)	Data  0.001 ( 0.008)	Loss 6.6965e-01 (6.7611e-01)	Acc@1  78.12 ( 78.91)	Acc@5  96.88 ( 97.10)
Epoch: [40][ 30/391]	Time  0.045 ( 0.047)	Data  0.001 ( 0.006)	Loss 5.5830e-01 (6.5213e-01)	Acc@1  83.59 ( 79.76)	Acc@5  98.44 ( 97.28)
Epoch: [40][ 40/391]	Time  0.040 ( 0.046)	Data  0.001 ( 0.004)	Loss 6.1688e-01 (6.6157e-01)	Acc@1  80.47 ( 79.59)	Acc@5  97.66 ( 97.26)
Epoch: [40][ 50/391]	Time  0.040 ( 0.045)	Data  0.001 ( 0.004)	Loss 6.2971e-01 (6.5956e-01)	Acc@1  82.81 ( 79.79)	Acc@5  97.66 ( 97.21)
Epoch: [40][ 60/391]	Time  0.039 ( 0.044)	Data  0.001 ( 0.003)	Loss 6.4347e-01 (6.6654e-01)	Acc@1  80.47 ( 79.62)	Acc@5  98.44 ( 97.17)
Epoch: [40][ 70/391]	Time  0.040 ( 0.044)	Data  0.001 ( 0.003)	Loss 5.7223e-01 (6.7392e-01)	Acc@1  85.16 ( 79.43)	Acc@5  96.88 ( 97.07)
Epoch: [40][ 80/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.003)	Loss 5.7438e-01 (6.7298e-01)	Acc@1  81.25 ( 79.45)	Acc@5  98.44 ( 97.08)
Epoch: [40][ 90/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.003)	Loss 5.9884e-01 (6.7223e-01)	Acc@1  80.47 ( 79.41)	Acc@5  97.66 ( 97.09)
Epoch: [40][100/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.002)	Loss 5.9207e-01 (6.6705e-01)	Acc@1  79.69 ( 79.56)	Acc@5  96.09 ( 97.10)
Epoch: [40][110/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 6.7627e-01 (6.6846e-01)	Acc@1  77.34 ( 79.53)	Acc@5  98.44 ( 97.05)
Epoch: [40][120/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.002)	Loss 6.6041e-01 (6.7180e-01)	Acc@1  77.34 ( 79.40)	Acc@5  96.88 ( 96.98)
Epoch: [40][130/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.002)	Loss 6.8549e-01 (6.7368e-01)	Acc@1  80.47 ( 79.34)	Acc@5  97.66 ( 96.97)
Epoch: [40][140/391]	Time  0.039 ( 0.043)	Data  0.001 ( 0.002)	Loss 7.9296e-01 (6.7243e-01)	Acc@1  76.56 ( 79.31)	Acc@5  96.09 ( 97.00)
Epoch: [40][150/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.9608e-01 (6.7143e-01)	Acc@1  81.25 ( 79.35)	Acc@5  96.88 ( 97.03)
Epoch: [40][160/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.8578e-01 (6.7259e-01)	Acc@1  85.94 ( 79.35)	Acc@5  96.88 ( 97.02)
Epoch: [40][170/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.8609e-01 (6.7271e-01)	Acc@1  85.94 ( 79.46)	Acc@5  96.09 ( 96.99)
Epoch: [40][180/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.3834e-01 (6.7307e-01)	Acc@1  83.59 ( 79.41)	Acc@5  98.44 ( 97.02)
Epoch: [40][190/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.3989e-01 (6.7334e-01)	Acc@1  84.38 ( 79.32)	Acc@5  97.66 ( 96.99)
Epoch: [40][200/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.4918e-01 (6.7597e-01)	Acc@1  76.56 ( 79.22)	Acc@5  99.22 ( 96.98)
Epoch: [40][210/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.6895e-01 (6.7787e-01)	Acc@1  77.34 ( 79.12)	Acc@5  96.09 ( 96.95)
Epoch: [40][220/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.6997e-01 (6.7608e-01)	Acc@1  80.47 ( 79.13)	Acc@5  99.22 ( 96.97)
Epoch: [40][230/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.8806e-01 (6.7811e-01)	Acc@1  80.47 ( 79.04)	Acc@5  94.53 ( 96.93)
Epoch: [40][240/391]	Time  0.044 ( 0.042)	Data  0.002 ( 0.002)	Loss 1.0073e+00 (6.8374e-01)	Acc@1  67.19 ( 78.87)	Acc@5  94.53 ( 96.87)
Epoch: [40][250/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.8333e-01 (6.8447e-01)	Acc@1  80.47 ( 78.89)	Acc@5  98.44 ( 96.87)
Epoch: [40][260/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.1195e-01 (6.8783e-01)	Acc@1  81.25 ( 78.79)	Acc@5  97.66 ( 96.80)
Epoch: [40][270/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.6797e-01 (6.9001e-01)	Acc@1  80.47 ( 78.71)	Acc@5  98.44 ( 96.77)
Epoch: [40][280/391]	Time  0.045 ( 0.042)	Data  0.001 ( 0.002)	Loss 8.3470e-01 (6.9304e-01)	Acc@1  71.09 ( 78.63)	Acc@5  95.31 ( 96.76)
Epoch: [40][290/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 7.1243e-01 (6.9281e-01)	Acc@1  77.34 ( 78.63)	Acc@5  96.09 ( 96.75)
Epoch: [40][300/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.6823e-01 (6.9463e-01)	Acc@1  78.12 ( 78.52)	Acc@5 100.00 ( 96.76)
Epoch: [40][310/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 6.5050e-01 (6.9555e-01)	Acc@1  81.25 ( 78.52)	Acc@5  96.88 ( 96.76)
Epoch: [40][320/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.001)	Loss 6.7338e-01 (6.9526e-01)	Acc@1  78.12 ( 78.52)	Acc@5  98.44 ( 96.77)
Epoch: [40][330/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.001)	Loss 6.2678e-01 (6.9668e-01)	Acc@1  82.03 ( 78.50)	Acc@5  97.66 ( 96.76)
Epoch: [40][340/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.001)	Loss 7.3026e-01 (6.9733e-01)	Acc@1  75.78 ( 78.47)	Acc@5  96.88 ( 96.75)
Epoch: [40][350/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 6.8834e-01 (6.9762e-01)	Acc@1  78.12 ( 78.46)	Acc@5  98.44 ( 96.75)
Epoch: [40][360/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.001)	Loss 7.1495e-01 (6.9844e-01)	Acc@1  79.69 ( 78.45)	Acc@5  96.88 ( 96.73)
Epoch: [40][370/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.001)	Loss 8.0175e-01 (6.9937e-01)	Acc@1  78.12 ( 78.43)	Acc@5  92.97 ( 96.71)
Epoch: [40][380/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 6.1354e-01 (6.9940e-01)	Acc@1  78.12 ( 78.39)	Acc@5  96.09 ( 96.72)
Epoch: [40][390/391]	Time  0.027 ( 0.042)	Data  0.001 ( 0.001)	Loss 7.7450e-01 (7.0136e-01)	Acc@1  80.00 ( 78.35)	Acc@5  95.00 ( 96.70)
## e[40] optimizer.zero_grad (sum) time: 0.28538060188293457
## e[40]       loss.backward (sum) time: 4.126287937164307
## e[40]      optimizer.step (sum) time: 1.8568859100341797
## epoch[40] training(only) time: 16.416722059249878
# Switched to evaluate mode...
Test: [  0/100]	Time  0.151 ( 0.151)	Loss 1.2864e+00 (1.2864e+00)	Acc@1  68.00 ( 68.00)	Acc@5  89.00 ( 89.00)
Test: [ 10/100]	Time  0.023 ( 0.034)	Loss 1.6299e+00 (1.5275e+00)	Acc@1  60.00 ( 63.18)	Acc@5  90.00 ( 87.64)
Test: [ 20/100]	Time  0.021 ( 0.029)	Loss 1.2177e+00 (1.4559e+00)	Acc@1  69.00 ( 63.71)	Acc@5  91.00 ( 88.57)
Test: [ 30/100]	Time  0.022 ( 0.026)	Loss 1.6983e+00 (1.4815e+00)	Acc@1  57.00 ( 62.94)	Acc@5  90.00 ( 88.39)
Test: [ 40/100]	Time  0.021 ( 0.025)	Loss 1.4540e+00 (1.4838e+00)	Acc@1  67.00 ( 63.27)	Acc@5  89.00 ( 88.22)
Test: [ 50/100]	Time  0.020 ( 0.025)	Loss 1.4380e+00 (1.4814e+00)	Acc@1  69.00 ( 63.45)	Acc@5  87.00 ( 88.00)
Test: [ 60/100]	Time  0.018 ( 0.024)	Loss 1.3089e+00 (1.4605e+00)	Acc@1  62.00 ( 63.52)	Acc@5  88.00 ( 88.26)
Test: [ 70/100]	Time  0.018 ( 0.023)	Loss 1.4905e+00 (1.4620e+00)	Acc@1  61.00 ( 63.42)	Acc@5  88.00 ( 88.17)
Test: [ 80/100]	Time  0.022 ( 0.023)	Loss 1.5347e+00 (1.4627e+00)	Acc@1  63.00 ( 63.42)	Acc@5  86.00 ( 88.11)
Test: [ 90/100]	Time  0.024 ( 0.023)	Loss 2.0530e+00 (1.4551e+00)	Acc@1  56.00 ( 63.62)	Acc@5  84.00 ( 88.23)
 * Acc@1 63.870 Acc@5 88.450
### epoch[40] execution time: 18.818726301193237
EPOCH 41
i:   0, name:           module.stem.0.weight  changing lr from: 0.005234426044027662   to: 0.003968907966975204
i:   1, name:             module.stem.0.bias  changing lr from: 0.005645333501572674   to: 0.004325865435899644
i:   2, name:           module.stem.1.weight  changing lr from: 0.006070037821654799   to: 0.004698589558789484
i:   3, name:             module.stem.1.bias  changing lr from: 0.006507907289942610   to: 0.005086413034663916
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.006958325712136919   to: 0.005488683622030876
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.007420692346008445   to: 0.005904764157897851
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.007894421811782553   to: 0.006334032549510598
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.008378943982703085   to: 0.006775881740913463
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.008873703857502691   to: 0.007229719656312549
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.009378161416407699   to: 0.007694969122115341
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.009891791462209393   to: 0.008171067769416340
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.010414083447842899   to: 0.008657467918599226
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.010944541291827085   to: 0.009153636447630502
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.011482683182836545   to: 0.009659054645528745
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.012028041374596714   to: 0.010173218052406129
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.012580161972218680   to: 0.010695636287395994
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.013138604711017486   to: 0.011225832865700103
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.013702942728790912   to: 0.011763345005914676
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.014272762332469453   to: 0.012307723428720430
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.014847662759988160   to: 0.012858532147954738
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.015427255938171715   to: 0.013415348255017466
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.016011166237369673   to: 0.013977761697500580
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.016599030223526053   to: 0.014545375052872234
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.017190496408318195   to: 0.015117803297990319
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.017785224997953087   to: 0.015694673575166972
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.018382887641165063   to: 0.016275624955455609
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.018983167176917067   to: 0.016860308199783947
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.019585757382268931   to: 0.017448385518512018
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.020190362720837837   to: 0.018039530329950648
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.020796698092242313   to: 0.018633427018336386
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.021404488582887717   to: 0.019229770691720289
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.022013469218420664   to: 0.019828266940192490
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.022623384718149866   to: 0.020428631594830195
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.023233989251704758   to: 0.021030590487725178
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.023845046198176890   to: 0.021633879213416758
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.024456327907965189   to: 0.022238242892027971
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.025067615467524104   to: 0.022843435934376002
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.025678698467191858   to: 0.023449221809303311
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.026289374772257269   to: 0.024055372813452214
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.026899450297404294   to: 0.024661669843683572
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.027508738784657163   to: 0.025267902172320514
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.028117061584932202   to: 0.025873867225377795
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.028724247443287960   to: 0.026479370363919896
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.029330132287951585   to: 0.027084224668674595
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.029934559023185727   to: 0.027688250728012034
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.030537377326049355   to: 0.028291276429385594
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.031138443447093673   to: 0.028893136754316564
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.031737620015025177   to: 0.029493673576992743
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.032334775845357294   to: 0.030092735466537818
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.032929785753064211   to: 0.030690177492999418
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.033522530369241819   to: 0.031285861037091647
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.034112895961773519   to: 0.031879653603719783
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.034700774259991983   to: 0.032471428639305605
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.035286062283321276   to: 0.033061065352923850
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.035868662173878442   to: 0.033648448541252950
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.036448481033008011   to: 0.034233468417336044
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.037025430761718971   to: 0.034816020443142914
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.037599427904988228   to: 0.035396005165916476
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.038170393499891930   to: 0.035973328058283363
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.038738252927521484   to: 0.036547899362102412
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.039302935768638983   to: 0.037119633936021648
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.039864375663022901   to: 0.037688451106708952
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.040422510172453227   to: 0.038254274523719316
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.040977280647282704   to: 0.038817032017957664
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.041528632096538953   to: 0.039376655463693636
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.042076513061500620   to: 0.039933080644082047
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.042620875492689239   to: 0.040486247120140408
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.043161674630217195   to: 0.041036098103132836
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.043698868887431616   to: 0.041582580330308420
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.044232419737792371   to: 0.042125643943939584
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.044762291604922753   to: 0.042665242373606020
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.045288451755769968   to: 0.043201332221666937
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.045810870196813014   to: 0.043733873151865624
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.046329519573254666   to: 0.044262827781007145
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.046844375071134987   to: 0.044788161573651751
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.047355414322302884   to: 0.045309842739764128
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.047862617312183428   to: 0.045827842135259984
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.048365966290277923   to: 0.046342133165389848
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.048865445683334841   to: 0.046852691690901144
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.049361042011129903   to: 0.047359495936918974
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.049852743804793459   to: 0.047862526404485892
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.050340541527625376   to: 0.048361765784702443
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.050824427498336475   to: 0.048857198875408965
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.051304395816657668   to: 0.049348812500350933
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.051780442291257847   to: 0.049836595430769397
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.052252564369912768   to: 0.050320538309359938
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.052720761071867697   to: 0.050800633576542728
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.053185032922337699   to: 0.051276875398987953
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.053645381889090016   to: 0.051749259600341185
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.054101811321054294   to: 0.052217783594093785
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.054554325888906789   to: 0.052682446318544622
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.055002931527576029   to: 0.053143248173799812
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.055447635380618546   to: 0.053600190960758257
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.055888445746413266   to: 0.054053277822031211
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.056325372026125579   to: 0.054502513184745707
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.056758424673391698   to: 0.054947902705181385
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.057187615145675955   to: 0.055389453215192654
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.057612955857253928   to: 0.055827172670367436
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.058034460133775667   to: 0.056261070099875882
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.058452142168364342   to: 0.056691155557962752
i: 100, name:           module.conv10.weight  changing lr from: 0.058866016979206084   to: 0.057117440077038256
i: 101, name:             module.conv10.bias  changing lr from: 0.059276100368588651   to: 0.057539935622322916



# Switched to train mode...
Epoch: [41][  0/391]	Time  0.189 ( 0.189)	Data  0.144 ( 0.144)	Loss 6.9530e-01 (6.9530e-01)	Acc@1  81.25 ( 81.25)	Acc@5  94.53 ( 94.53)
Epoch: [41][ 10/391]	Time  0.040 ( 0.055)	Data  0.001 ( 0.014)	Loss 7.1278e-01 (6.6598e-01)	Acc@1  80.47 ( 79.05)	Acc@5  94.53 ( 97.02)
Epoch: [41][ 20/391]	Time  0.042 ( 0.049)	Data  0.001 ( 0.008)	Loss 5.7325e-01 (6.5490e-01)	Acc@1  82.81 ( 79.39)	Acc@5  97.66 ( 97.10)
Epoch: [41][ 30/391]	Time  0.040 ( 0.046)	Data  0.001 ( 0.006)	Loss 8.6963e-01 (6.5971e-01)	Acc@1  72.66 ( 79.18)	Acc@5  92.97 ( 96.98)
Epoch: [41][ 40/391]	Time  0.044 ( 0.045)	Data  0.001 ( 0.004)	Loss 7.1895e-01 (6.6309e-01)	Acc@1  78.12 ( 78.96)	Acc@5  95.31 ( 96.97)
Epoch: [41][ 50/391]	Time  0.040 ( 0.044)	Data  0.001 ( 0.004)	Loss 4.7741e-01 (6.5709e-01)	Acc@1  84.38 ( 79.30)	Acc@5  98.44 ( 97.07)
Epoch: [41][ 60/391]	Time  0.048 ( 0.044)	Data  0.001 ( 0.003)	Loss 5.4280e-01 (6.5780e-01)	Acc@1  85.16 ( 79.44)	Acc@5  97.66 ( 97.05)
Epoch: [41][ 70/391]	Time  0.039 ( 0.044)	Data  0.001 ( 0.003)	Loss 7.6390e-01 (6.5745e-01)	Acc@1  73.44 ( 79.50)	Acc@5  96.88 ( 97.05)
Epoch: [41][ 80/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.003)	Loss 7.3333e-01 (6.5588e-01)	Acc@1  75.00 ( 79.36)	Acc@5  93.75 ( 97.03)
Epoch: [41][ 90/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.003)	Loss 7.0514e-01 (6.6396e-01)	Acc@1  76.56 ( 79.11)	Acc@5  94.53 ( 96.93)
Epoch: [41][100/391]	Time  0.044 ( 0.043)	Data  0.001 ( 0.002)	Loss 8.0945e-01 (6.6277e-01)	Acc@1  78.12 ( 79.18)	Acc@5  97.66 ( 96.98)
Epoch: [41][110/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.002)	Loss 5.4936e-01 (6.6265e-01)	Acc@1  83.59 ( 79.21)	Acc@5  98.44 ( 96.99)
Epoch: [41][120/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.002)	Loss 5.8167e-01 (6.6032e-01)	Acc@1  80.47 ( 79.33)	Acc@5  98.44 ( 97.00)
Epoch: [41][130/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.3488e-01 (6.6058e-01)	Acc@1  81.25 ( 79.35)	Acc@5  97.66 ( 96.96)
Epoch: [41][140/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.3838e-01 (6.5931e-01)	Acc@1  78.12 ( 79.45)	Acc@5  98.44 ( 97.00)
Epoch: [41][150/391]	Time  0.053 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.2684e-01 (6.5713e-01)	Acc@1  81.25 ( 79.54)	Acc@5  97.66 ( 97.00)
Epoch: [41][160/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.3165e-01 (6.5551e-01)	Acc@1  81.25 ( 79.64)	Acc@5  96.88 ( 96.99)
Epoch: [41][170/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.8535e-01 (6.5300e-01)	Acc@1  80.47 ( 79.81)	Acc@5  97.66 ( 97.02)
Epoch: [41][180/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.1225e-01 (6.5503e-01)	Acc@1  82.81 ( 79.75)	Acc@5 100.00 ( 97.00)
Epoch: [41][190/391]	Time  0.037 ( 0.042)	Data  0.001 ( 0.002)	Loss 4.6866e-01 (6.5682e-01)	Acc@1  85.16 ( 79.67)	Acc@5  98.44 ( 96.99)
Epoch: [41][200/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 7.3795e-01 (6.5740e-01)	Acc@1  77.34 ( 79.66)	Acc@5  94.53 ( 96.96)
Epoch: [41][210/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.3250e-01 (6.5746e-01)	Acc@1  83.59 ( 79.64)	Acc@5  97.66 ( 96.98)
Epoch: [41][220/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.8612e-01 (6.5647e-01)	Acc@1  78.91 ( 79.70)	Acc@5  97.66 ( 96.98)
Epoch: [41][230/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.4122e-01 (6.5870e-01)	Acc@1  80.47 ( 79.62)	Acc@5  96.88 ( 96.95)
Epoch: [41][240/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.1374e-01 (6.5786e-01)	Acc@1  82.03 ( 79.66)	Acc@5  96.09 ( 96.93)
Epoch: [41][250/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 7.0630e-01 (6.6006e-01)	Acc@1  79.69 ( 79.58)	Acc@5  95.31 ( 96.90)
Epoch: [41][260/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.8104e-01 (6.6307e-01)	Acc@1  80.47 ( 79.45)	Acc@5  96.88 ( 96.88)
Epoch: [41][270/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.3611e-01 (6.6412e-01)	Acc@1  81.25 ( 79.43)	Acc@5  97.66 ( 96.88)
Epoch: [41][280/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.001)	Loss 7.7628e-01 (6.6524e-01)	Acc@1  77.34 ( 79.43)	Acc@5  96.88 ( 96.87)
Epoch: [41][290/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 5.7103e-01 (6.6716e-01)	Acc@1  81.25 ( 79.38)	Acc@5  98.44 ( 96.87)
Epoch: [41][300/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.001)	Loss 6.8973e-01 (6.6842e-01)	Acc@1  77.34 ( 79.33)	Acc@5  97.66 ( 96.88)
Epoch: [41][310/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.001)	Loss 8.1724e-01 (6.6955e-01)	Acc@1  75.78 ( 79.31)	Acc@5  94.53 ( 96.88)
Epoch: [41][320/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.001)	Loss 6.3382e-01 (6.6992e-01)	Acc@1  78.12 ( 79.32)	Acc@5  98.44 ( 96.88)
Epoch: [41][330/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.001)	Loss 5.3841e-01 (6.6971e-01)	Acc@1  82.81 ( 79.34)	Acc@5  96.88 ( 96.87)
Epoch: [41][340/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.001)	Loss 5.2265e-01 (6.7057e-01)	Acc@1  79.69 ( 79.29)	Acc@5  98.44 ( 96.87)
Epoch: [41][350/391]	Time  0.045 ( 0.042)	Data  0.001 ( 0.001)	Loss 7.6814e-01 (6.7247e-01)	Acc@1  83.59 ( 79.26)	Acc@5  92.19 ( 96.83)
Epoch: [41][360/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.001)	Loss 6.8838e-01 (6.7237e-01)	Acc@1  83.59 ( 79.27)	Acc@5  96.88 ( 96.83)
Epoch: [41][370/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.001)	Loss 7.2889e-01 (6.7273e-01)	Acc@1  73.44 ( 79.22)	Acc@5  96.88 ( 96.83)
Epoch: [41][380/391]	Time  0.049 ( 0.042)	Data  0.001 ( 0.001)	Loss 6.5590e-01 (6.7352e-01)	Acc@1  78.12 ( 79.23)	Acc@5  96.88 ( 96.82)
Epoch: [41][390/391]	Time  0.034 ( 0.042)	Data  0.001 ( 0.001)	Loss 8.2603e-01 (6.7532e-01)	Acc@1  76.25 ( 79.20)	Acc@5  96.25 ( 96.79)
## e[41] optimizer.zero_grad (sum) time: 0.28431272506713867
## e[41]       loss.backward (sum) time: 4.105055570602417
## e[41]      optimizer.step (sum) time: 1.8706505298614502
## epoch[41] training(only) time: 16.402881145477295
# Switched to evaluate mode...
Test: [  0/100]	Time  0.155 ( 0.155)	Loss 1.3778e+00 (1.3778e+00)	Acc@1  63.00 ( 63.00)	Acc@5  86.00 ( 86.00)
Test: [ 10/100]	Time  0.022 ( 0.035)	Loss 1.4574e+00 (1.4538e+00)	Acc@1  58.00 ( 64.64)	Acc@5  93.00 ( 88.36)
Test: [ 20/100]	Time  0.023 ( 0.030)	Loss 1.3196e+00 (1.4222e+00)	Acc@1  69.00 ( 64.90)	Acc@5  90.00 ( 89.14)
Test: [ 30/100]	Time  0.021 ( 0.027)	Loss 1.6022e+00 (1.4547e+00)	Acc@1  65.00 ( 64.16)	Acc@5  88.00 ( 88.68)
Test: [ 40/100]	Time  0.024 ( 0.026)	Loss 1.8210e+00 (1.4622e+00)	Acc@1  53.00 ( 63.73)	Acc@5  84.00 ( 88.32)
Test: [ 50/100]	Time  0.022 ( 0.025)	Loss 1.4555e+00 (1.4717e+00)	Acc@1  68.00 ( 63.69)	Acc@5  87.00 ( 88.10)
Test: [ 60/100]	Time  0.021 ( 0.025)	Loss 1.5335e+00 (1.4531e+00)	Acc@1  60.00 ( 63.70)	Acc@5  84.00 ( 88.36)
Test: [ 70/100]	Time  0.018 ( 0.024)	Loss 1.4518e+00 (1.4564e+00)	Acc@1  65.00 ( 63.72)	Acc@5  88.00 ( 88.46)
Test: [ 80/100]	Time  0.017 ( 0.024)	Loss 1.4332e+00 (1.4644e+00)	Acc@1  66.00 ( 63.54)	Acc@5  87.00 ( 88.36)
Test: [ 90/100]	Time  0.024 ( 0.024)	Loss 1.9078e+00 (1.4486e+00)	Acc@1  64.00 ( 63.97)	Acc@5  82.00 ( 88.47)
 * Acc@1 64.240 Acc@5 88.700
### epoch[41] execution time: 18.81371545791626
EPOCH 42
i:   0, name:           module.stem.0.weight  changing lr from: 0.003968907966975204   to: 0.002921910115851916
i:   1, name:             module.stem.0.bias  changing lr from: 0.004325865435899644   to: 0.003220098311632024
i:   2, name:           module.stem.1.weight  changing lr from: 0.004698589558789484   to: 0.003536053350956108
i:   3, name:             module.stem.1.bias  changing lr from: 0.005086413034663916   to: 0.003869076159056599
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.005488683622030876   to: 0.004218481971524157
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.005904764157897851   to: 0.004583600454169278
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.006334032549510598   to: 0.004963775789528468
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.006775881740913463   to: 0.005358366732373109
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.007229719656312549   to: 0.005766746636460168
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.007694969122115341   to: 0.006188303454649119
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.008171067769416340   to: 0.006622439714398692
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.008657467918599226   to: 0.007068572470550482
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.009153636447630502   to: 0.007526133237203580
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.009659054645528745   to: 0.007994567900386478
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.010173218052406129   to: 0.008473336613137029
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.010695636287395994   to: 0.008961913674511511
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.011225832865700103   to: 0.009459787393956153
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.011763345005914676   to: 0.009966459942392120
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.012307723428720430   to: 0.010481447191284861
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.012858532147954738   to: 0.011004278540893440
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.013415348255017466   to: 0.011534496738822481
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.013977761697500580   to: 0.012071657689930942
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.014545375052872234   to: 0.012615330258585661
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.015117803297990319   to: 0.013165096064185200
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.015694673575166972   to: 0.013720549270820191
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.016275624955455609   to: 0.014281296371879103
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.016860308199783947   to: 0.014846955970355576
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.017448385518512018   to: 0.015417158555561632
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.018039530329950648   to: 0.015991546276903107
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.018633427018336386   to: 0.016569772715327429
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.019229770691720289   to: 0.017151502653010971
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.019828266940192490   to: 0.017736411841812016
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.020428631594830195   to: 0.018324186770975692
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.021030590487725178   to: 0.018914524434541953
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.021633879213416758   to: 0.019507132098871650
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.022238242892027971   to: 0.020101727070673980
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.022843435934376002   to: 0.020698036465887276
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.023449221809303311   to: 0.021295796979736076
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.024055372813452214   to: 0.021894754658260209
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.024661669843683572   to: 0.022494664671585785
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.025267902172320514   to: 0.023095291089183775
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.025873867225377795   to: 0.023696406657339276
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.026479370363919896   to: 0.024297792579032619
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.027084224668674595   to: 0.024899238296414650
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.027688250728012034   to: 0.025500541276038326
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.028291276429385594   to: 0.026101506796992420
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.028893136754316564   to: 0.026701947742065649
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.029493673576992743   to: 0.027301684392055461
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.030092735466537818   to: 0.027900544223319806
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.030690177492999418   to: 0.028498361708658351
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.031285861037091647   to: 0.029094978121595907
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.031879653603719783   to: 0.029690241344130230
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.032471428639305605   to: 0.030284005677994857
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.033061065352923850   to: 0.030876131659477904
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.033648448541252950   to: 0.031466485877828729
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.034233468417336044   to: 0.032054940797274931
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.034816020443142914   to: 0.032641374582665354
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.035396005165916476   to: 0.033225670928746377
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.035973328058283363   to: 0.033807718893072783
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.036547899362102412   to: 0.034387412732547397
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.037119633936021648   to: 0.034964651743579288
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.037688451106708952   to: 0.035539340105843399
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.038254274523719316   to: 0.036111386729621130
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.038817032017957664   to: 0.036680705106696243
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.039376655463693636   to: 0.037247213164776673
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.039933080644082047   to: 0.037810833125409227
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.040486247120140408   to: 0.038371491365350910
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.041036098103132836   to: 0.038929118281357512
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.041582580330308420   to: 0.039483648158347845
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.042125643943939584   to: 0.040035019040898984
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.042665242373606020   to: 0.040583172608026845
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.043201332221666937   to: 0.041128054051203046
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.043733873151865624   to: 0.041669611955559342
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.044262827781007145   to: 0.042207798184227457
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.044788161573651751   to: 0.042742567765762851
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.045309842739764128   to: 0.043273878784598374
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.045827842135259984   to: 0.043801692274474141
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.046342133165389848   to: 0.044325972114788260
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.046852691690901144   to: 0.044846684929813523
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.047359495936918974   to: 0.045363799990723999
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.047862526404485892   to: 0.045877289120375302
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.048361765784702443   to: 0.046387126600782876
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.048857198875408965   to: 0.046893289083241557
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.049348812500350933   to: 0.047395755501030479
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.049836595430769397   to: 0.047894506984647145
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.050320538309359938   to: 0.048389526779515225
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.050800633576542728   to: 0.048880800166110107
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.051276875398987953   to: 0.049368314382447459
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.051749259600341185   to: 0.049852058548880092
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.052217783594093785   to: 0.050332023595148837
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.052682446318544622   to: 0.050808202189633916
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.053143248173799812   to: 0.051280588670753795
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.053600190960758257   to: 0.051749178980459221
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.054053277822031211   to: 0.052213970599770537
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.054502513184745707   to: 0.052674962486307486
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.054947902705181385   to: 0.053132155013761208
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.055389453215192654   to: 0.053585549913258861
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.055827172670367436   to: 0.054035150216572396
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.056261070099875882   to: 0.054480960201123169
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.056691155557962752   to: 0.054922985336735730
i: 100, name:           module.conv10.weight  changing lr from: 0.057117440077038256   to: 0.055361232234094448
i: 101, name:             module.conv10.bias  changing lr from: 0.057539935622322916   to: 0.055795708594857302



# Switched to train mode...
Epoch: [42][  0/391]	Time  0.186 ( 0.186)	Data  0.140 ( 0.140)	Loss 5.3798e-01 (5.3798e-01)	Acc@1  81.25 ( 81.25)	Acc@5  98.44 ( 98.44)
Epoch: [42][ 10/391]	Time  0.042 ( 0.056)	Data  0.001 ( 0.014)	Loss 6.2668e-01 (6.4808e-01)	Acc@1  82.03 ( 79.55)	Acc@5  96.09 ( 97.51)
Epoch: [42][ 20/391]	Time  0.041 ( 0.049)	Data  0.001 ( 0.008)	Loss 5.2708e-01 (6.3724e-01)	Acc@1  85.16 ( 80.02)	Acc@5  96.88 ( 97.40)
Epoch: [42][ 30/391]	Time  0.039 ( 0.046)	Data  0.001 ( 0.006)	Loss 5.6959e-01 (6.3492e-01)	Acc@1  81.25 ( 80.04)	Acc@5  98.44 ( 97.43)
Epoch: [42][ 40/391]	Time  0.041 ( 0.044)	Data  0.001 ( 0.005)	Loss 7.3019e-01 (6.3973e-01)	Acc@1  78.91 ( 79.71)	Acc@5  96.88 ( 97.26)
Epoch: [42][ 50/391]	Time  0.040 ( 0.044)	Data  0.002 ( 0.004)	Loss 5.1815e-01 (6.3808e-01)	Acc@1  84.38 ( 80.01)	Acc@5 100.00 ( 97.40)
Epoch: [42][ 60/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.003)	Loss 5.6264e-01 (6.3719e-01)	Acc@1  82.03 ( 80.15)	Acc@5  97.66 ( 97.30)
Epoch: [42][ 70/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.003)	Loss 3.4083e-01 (6.3086e-01)	Acc@1  89.84 ( 80.51)	Acc@5 100.00 ( 97.28)
Epoch: [42][ 80/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.003)	Loss 6.5587e-01 (6.2898e-01)	Acc@1  83.59 ( 80.70)	Acc@5  96.88 ( 97.24)
Epoch: [42][ 90/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.003)	Loss 6.4309e-01 (6.2199e-01)	Acc@1  82.03 ( 80.86)	Acc@5  97.66 ( 97.34)
Epoch: [42][100/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.7738e-01 (6.2089e-01)	Acc@1  82.81 ( 80.96)	Acc@5  97.66 ( 97.37)
Epoch: [42][110/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.6930e-01 (6.2039e-01)	Acc@1  78.12 ( 80.96)	Acc@5  97.66 ( 97.40)
Epoch: [42][120/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.3775e-01 (6.2468e-01)	Acc@1  77.34 ( 80.77)	Acc@5  99.22 ( 97.37)
Epoch: [42][130/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.0056e-01 (6.2434e-01)	Acc@1  84.38 ( 80.78)	Acc@5  96.88 ( 97.32)
Epoch: [42][140/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.4452e-01 (6.3012e-01)	Acc@1  79.69 ( 80.64)	Acc@5  96.88 ( 97.24)
Epoch: [42][150/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.7792e-01 (6.3075e-01)	Acc@1  78.12 ( 80.58)	Acc@5  96.09 ( 97.21)
Epoch: [42][160/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.5110e-01 (6.2762e-01)	Acc@1  83.59 ( 80.61)	Acc@5  98.44 ( 97.25)
Epoch: [42][170/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 7.7112e-01 (6.3077e-01)	Acc@1  72.66 ( 80.51)	Acc@5  94.53 ( 97.19)
Epoch: [42][180/391]	Time  0.049 ( 0.042)	Data  0.001 ( 0.002)	Loss 7.5660e-01 (6.3243e-01)	Acc@1  74.22 ( 80.43)	Acc@5  96.09 ( 97.20)
Epoch: [42][190/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 7.2049e-01 (6.3609e-01)	Acc@1  78.91 ( 80.35)	Acc@5  94.53 ( 97.22)
Epoch: [42][200/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.0296e-01 (6.3544e-01)	Acc@1  81.25 ( 80.40)	Acc@5  96.09 ( 97.23)
Epoch: [42][210/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.9454e-01 (6.3772e-01)	Acc@1  78.12 ( 80.35)	Acc@5  97.66 ( 97.19)
Epoch: [42][220/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.7738e-01 (6.3813e-01)	Acc@1  85.16 ( 80.38)	Acc@5  96.09 ( 97.19)
Epoch: [42][230/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.6603e-01 (6.3966e-01)	Acc@1  83.59 ( 80.33)	Acc@5  94.53 ( 97.15)
Epoch: [42][240/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.6713e-01 (6.4011e-01)	Acc@1  82.81 ( 80.33)	Acc@5  98.44 ( 97.13)
Epoch: [42][250/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.9533e-01 (6.4022e-01)	Acc@1  75.78 ( 80.33)	Acc@5  97.66 ( 97.12)
Epoch: [42][260/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 7.7631e-01 (6.4190e-01)	Acc@1  75.78 ( 80.23)	Acc@5  96.09 ( 97.14)
Epoch: [42][270/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.6908e-01 (6.4256e-01)	Acc@1  78.12 ( 80.19)	Acc@5  95.31 ( 97.15)
Epoch: [42][280/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.7217e-01 (6.4378e-01)	Acc@1  77.34 ( 80.14)	Acc@5  99.22 ( 97.16)
Epoch: [42][290/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.001)	Loss 5.2936e-01 (6.4482e-01)	Acc@1  81.25 ( 80.05)	Acc@5  99.22 ( 97.16)
Epoch: [42][300/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 8.9844e-01 (6.4788e-01)	Acc@1  74.22 ( 79.98)	Acc@5  96.88 ( 97.12)
Epoch: [42][310/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.001)	Loss 6.2978e-01 (6.4984e-01)	Acc@1  82.81 ( 79.93)	Acc@5  98.44 ( 97.11)
Epoch: [42][320/391]	Time  0.043 ( 0.042)	Data  0.000 ( 0.001)	Loss 6.4315e-01 (6.5199e-01)	Acc@1  79.69 ( 79.88)	Acc@5  98.44 ( 97.08)
Epoch: [42][330/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 6.8312e-01 (6.5399e-01)	Acc@1  80.47 ( 79.81)	Acc@5  97.66 ( 97.05)
Epoch: [42][340/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.001)	Loss 6.4944e-01 (6.5610e-01)	Acc@1  82.81 ( 79.77)	Acc@5  96.09 ( 97.04)
Epoch: [42][350/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.001)	Loss 6.5564e-01 (6.5590e-01)	Acc@1  82.03 ( 79.82)	Acc@5  95.31 ( 97.03)
Epoch: [42][360/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.001)	Loss 5.3646e-01 (6.5736e-01)	Acc@1  79.69 ( 79.75)	Acc@5  98.44 ( 97.03)
Epoch: [42][370/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 7.0644e-01 (6.5840e-01)	Acc@1  79.69 ( 79.74)	Acc@5  96.09 ( 97.02)
Epoch: [42][380/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 5.1729e-01 (6.5887e-01)	Acc@1  83.59 ( 79.74)	Acc@5  98.44 ( 97.01)
Epoch: [42][390/391]	Time  0.029 ( 0.042)	Data  0.001 ( 0.001)	Loss 7.8028e-01 (6.5979e-01)	Acc@1  73.75 ( 79.67)	Acc@5  96.25 ( 97.01)
## e[42] optimizer.zero_grad (sum) time: 0.2862720489501953
## e[42]       loss.backward (sum) time: 4.1104230880737305
## e[42]      optimizer.step (sum) time: 1.9015049934387207
## epoch[42] training(only) time: 16.390252828598022
# Switched to evaluate mode...
Test: [  0/100]	Time  0.157 ( 0.157)	Loss 1.3378e+00 (1.3378e+00)	Acc@1  70.00 ( 70.00)	Acc@5  88.00 ( 88.00)
Test: [ 10/100]	Time  0.021 ( 0.034)	Loss 1.3542e+00 (1.4202e+00)	Acc@1  65.00 ( 65.73)	Acc@5  87.00 ( 88.45)
Test: [ 20/100]	Time  0.024 ( 0.028)	Loss 1.1154e+00 (1.4098e+00)	Acc@1  71.00 ( 65.81)	Acc@5  94.00 ( 88.67)
Test: [ 30/100]	Time  0.022 ( 0.027)	Loss 1.7465e+00 (1.4447e+00)	Acc@1  56.00 ( 64.87)	Acc@5  89.00 ( 88.42)
Test: [ 40/100]	Time  0.024 ( 0.026)	Loss 1.2717e+00 (1.4520e+00)	Acc@1  66.00 ( 64.29)	Acc@5  92.00 ( 88.49)
Test: [ 50/100]	Time  0.021 ( 0.025)	Loss 1.5061e+00 (1.4605e+00)	Acc@1  61.00 ( 63.73)	Acc@5  90.00 ( 88.43)
Test: [ 60/100]	Time  0.021 ( 0.025)	Loss 1.5071e+00 (1.4320e+00)	Acc@1  60.00 ( 64.08)	Acc@5  87.00 ( 88.79)
Test: [ 70/100]	Time  0.024 ( 0.025)	Loss 1.3198e+00 (1.4421e+00)	Acc@1  70.00 ( 64.21)	Acc@5  87.00 ( 88.59)
Test: [ 80/100]	Time  0.024 ( 0.024)	Loss 1.3939e+00 (1.4504e+00)	Acc@1  64.00 ( 64.14)	Acc@5  88.00 ( 88.51)
Test: [ 90/100]	Time  0.022 ( 0.024)	Loss 1.6480e+00 (1.4373e+00)	Acc@1  58.00 ( 64.35)	Acc@5  89.00 ( 88.75)
 * Acc@1 64.520 Acc@5 88.800
### epoch[42] execution time: 18.851670026779175
EPOCH 43
i:   0, name:           module.stem.0.weight  changing lr from: 0.002921910115851916   to: 0.002098297149271610
i:   1, name:             module.stem.0.bias  changing lr from: 0.003220098311632024   to: 0.002333094964484710
i:   2, name:           module.stem.1.weight  changing lr from: 0.003536053350956108   to: 0.002587674563812297
i:   3, name:             module.stem.1.bias  changing lr from: 0.003869076159056599   to: 0.002861309620877366
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.004218481971524157   to: 0.003153287059193027
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.004583600454169278   to: 0.003462907286975191
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.004963775789528468   to: 0.003789484392097053
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.005358366732373109   to: 0.004132346299805383
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.005766746636460168   to: 0.004490834895694761
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.006188303454649119   to: 0.004864306116315714
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.006622439714398692   to: 0.005252130009676380
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.007068572470550482   to: 0.005653690767784696
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.007526133237203580   to: 0.006068386733268882
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.007994567900386478   to: 0.006495630382009681
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.008473336613137029   to: 0.006934848283615996
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.008961913674511511   to: 0.007385481041478670
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.009459787393956153   to: 0.007846983214043025
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.009966459942392120   to: 0.008318823218851679
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.010481447191284861   to: 0.008800483220821852
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.011004278540893440   to: 0.009291459006139775
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.011534496738822481   to: 0.009791259843074777
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.012071657689930942   to: 0.010299408330940840
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.012615330258585661   to: 0.010815440238360025
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.013165096064185200   to: 0.011338904331914063
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.013720549270820191   to: 0.011869362196203936
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.014281296371879103   to: 0.012406388046274371
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.014846955970355576   to: 0.012949568533300863
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.015417158555561632   to: 0.013498502544379315
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.015991546276903107   to: 0.014052800997204427
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.016569772715327429   to: 0.014612086630371425
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.017151502653010971   to: 0.015175993789986804
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.017736411841812016   to: 0.015744168213227765
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.018324186770975692   to: 0.016316266809444903
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.018914524434541953   to: 0.016891957439362382
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.019507132098871650   to: 0.017470918692889359
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.020101727070673980   to: 0.018052839666019227
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.020698036465887276   to: 0.018637419737258489
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.021295796979736076   to: 0.019224368343992555
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.021894754658260209   to: 0.019813404759165477
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.022494664671585785   to: 0.020404257868619671
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.023095291089183775   to: 0.020996665949414746
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.023696406657339276   to: 0.021590376449417088
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.024297792579032619   to: 0.022185145768427506
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.024899238296414650   to: 0.022780739041091048
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.025500541276038326   to: 0.023376929921809959
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.026101506796992420   to: 0.023973500371861772
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.026701947742065649   to: 0.024570240448903054
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.027301684392055461   to: 0.025166948099023246
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.027900544223319806   to: 0.025763428951493941
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.028498361708658351   to: 0.026359496116344461
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.029094978121595907   to: 0.026954969984878809
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.029690241344130230   to: 0.027549678033235315
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.030284005677994857   to: 0.028143454629077282
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.030876131659477904   to: 0.028736140841490756
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.031466485877828729   to: 0.029327584254154028
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.032054940797274931   to: 0.029917638781832859
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.032641374582665354   to: 0.030506164490246259
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.033225670928746377   to: 0.031093027419337241
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.033807718893072783   to: 0.031678099409976082
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.034387412732547397   to: 0.032261257934114065
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.034964651743579288   to: 0.032842385928400324
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.035539340105843399   to: 0.033421371631265684
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.036111386729621130   to: 0.033998108423473082
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.036680705106696243   to: 0.034572494672126995
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.037247213164776673   to: 0.035144433578130109
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.037810833125409227   to: 0.035713833027070228
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.038371491365350910   to: 0.036280605443515912
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.038929118281357512   to: 0.036844667648695616
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.039483648158347845   to: 0.037405940721531618
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.040035019040898984   to: 0.037964349862996030
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.040583172608026845   to: 0.038519824263754318
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.041128054051203046   to: 0.039072296975057742
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.041669611955559342   to: 0.039621704782845095
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.042207798184227457   to: 0.040167988085010757
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.042742567765762851   to: 0.040711090771795272
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.043273878784598374   to: 0.041250960109252055
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.043801692274474141   to: 0.041787546625742952
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.044325972114788260   to: 0.042320804001413886
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.044846684929813523   to: 0.042850688960600930
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.045363799990723999   to: 0.043377161167116075
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.045877289120375302   to: 0.043900183122360853
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.046387126600782876   to: 0.044419720066216625
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.046893289083241557   to: 0.044935739880658049
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.047395755501030479   to: 0.045448212996037581
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.047894506984647145   to: 0.045957112299987453
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.048389526779515225   to: 0.046462413048886382
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.048880800166110107   to: 0.046964092781837198
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.049368314382447459   to: 0.047462131237102856
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.049852058548880092   to: 0.047956510270947363
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.050332023595148837   to: 0.048447213778829122
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.050808202189633916   to: 0.048934227618894016
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.051280588670753795   to: 0.049417539537716368
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.051749178980459221   to: 0.049897139098235892
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.052213970599770537   to: 0.050373017609839456
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.052674962486307486   to: 0.050845168060537162
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.053132155013761208   to: 0.051313585051182289
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.053585549913258861   to: 0.051778264731685876
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.054035150216572396   to: 0.052239204739177064
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.054480960201123169   to: 0.052696404138060586
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.054922985336735730   to: 0.053149863361924447
i: 100, name:           module.conv10.weight  changing lr from: 0.055361232234094448   to: 0.053599584157250635
i: 101, name:             module.conv10.bias  changing lr from: 0.055795708594857302   to: 0.054045569528882891



# Switched to train mode...
Epoch: [43][  0/391]	Time  0.200 ( 0.200)	Data  0.151 ( 0.151)	Loss 5.3396e-01 (5.3396e-01)	Acc@1  82.03 ( 82.03)	Acc@5  97.66 ( 97.66)
Epoch: [43][ 10/391]	Time  0.040 ( 0.056)	Data  0.001 ( 0.014)	Loss 5.3700e-01 (6.0494e-01)	Acc@1  81.25 ( 82.60)	Acc@5  97.66 ( 97.23)
Epoch: [43][ 20/391]	Time  0.040 ( 0.049)	Data  0.001 ( 0.008)	Loss 5.1288e-01 (5.9642e-01)	Acc@1  83.59 ( 82.44)	Acc@5  99.22 ( 97.62)
Epoch: [43][ 30/391]	Time  0.040 ( 0.047)	Data  0.001 ( 0.006)	Loss 6.7691e-01 (6.0554e-01)	Acc@1  78.12 ( 81.68)	Acc@5  99.22 ( 97.58)
Epoch: [43][ 40/391]	Time  0.044 ( 0.046)	Data  0.001 ( 0.005)	Loss 5.7066e-01 (5.9339e-01)	Acc@1  79.69 ( 81.54)	Acc@5  97.66 ( 97.64)
Epoch: [43][ 50/391]	Time  0.040 ( 0.045)	Data  0.001 ( 0.004)	Loss 5.6740e-01 (5.8910e-01)	Acc@1  78.12 ( 81.45)	Acc@5  97.66 ( 97.66)
Epoch: [43][ 60/391]	Time  0.039 ( 0.044)	Data  0.001 ( 0.003)	Loss 5.6297e-01 (5.9893e-01)	Acc@1  82.81 ( 81.17)	Acc@5  98.44 ( 97.54)
Epoch: [43][ 70/391]	Time  0.040 ( 0.044)	Data  0.001 ( 0.003)	Loss 4.3138e-01 (5.9485e-01)	Acc@1  85.94 ( 81.47)	Acc@5  99.22 ( 97.57)
Epoch: [43][ 80/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.003)	Loss 6.2955e-01 (6.0176e-01)	Acc@1  83.59 ( 81.24)	Acc@5  98.44 ( 97.44)
Epoch: [43][ 90/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.003)	Loss 5.6313e-01 (6.0228e-01)	Acc@1  82.81 ( 81.22)	Acc@5  96.88 ( 97.39)
Epoch: [43][100/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.002)	Loss 6.3454e-01 (6.0716e-01)	Acc@1  80.47 ( 81.10)	Acc@5  97.66 ( 97.39)
Epoch: [43][110/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.002)	Loss 5.7221e-01 (6.0602e-01)	Acc@1  82.03 ( 81.21)	Acc@5  98.44 ( 97.39)
Epoch: [43][120/391]	Time  0.038 ( 0.043)	Data  0.001 ( 0.002)	Loss 5.1255e-01 (6.0760e-01)	Acc@1  86.72 ( 81.17)	Acc@5  99.22 ( 97.38)
Epoch: [43][130/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 5.9418e-01 (6.0688e-01)	Acc@1  83.59 ( 81.12)	Acc@5  97.66 ( 97.42)
Epoch: [43][140/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.2054e-01 (6.1033e-01)	Acc@1  83.59 ( 81.12)	Acc@5  96.09 ( 97.34)
Epoch: [43][150/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.9120e-01 (6.0928e-01)	Acc@1  78.91 ( 81.12)	Acc@5  98.44 ( 97.36)
Epoch: [43][160/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 7.1037e-01 (6.1314e-01)	Acc@1  82.03 ( 81.06)	Acc@5  95.31 ( 97.32)
Epoch: [43][170/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.7617e-01 (6.1506e-01)	Acc@1  82.81 ( 80.99)	Acc@5  97.66 ( 97.30)
Epoch: [43][180/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.5590e-01 (6.1298e-01)	Acc@1  80.47 ( 81.00)	Acc@5  96.09 ( 97.31)
Epoch: [43][190/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.7471e-01 (6.1432e-01)	Acc@1  78.12 ( 81.00)	Acc@5  99.22 ( 97.30)
Epoch: [43][200/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.7522e-01 (6.1332e-01)	Acc@1  78.91 ( 81.02)	Acc@5  98.44 ( 97.33)
Epoch: [43][210/391]	Time  0.047 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.4397e-01 (6.1314e-01)	Acc@1  83.59 ( 81.06)	Acc@5  98.44 ( 97.29)
Epoch: [43][220/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 7.6156e-01 (6.1204e-01)	Acc@1  75.00 ( 81.06)	Acc@5  94.53 ( 97.31)
Epoch: [43][230/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.1086e-01 (6.1378e-01)	Acc@1  82.03 ( 80.97)	Acc@5  96.09 ( 97.30)
Epoch: [43][240/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.2178e-01 (6.1599e-01)	Acc@1  82.03 ( 80.88)	Acc@5  99.22 ( 97.30)
Epoch: [43][250/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 7.6991e-01 (6.1634e-01)	Acc@1  73.44 ( 80.89)	Acc@5  96.09 ( 97.28)
Epoch: [43][260/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.3543e-01 (6.1569e-01)	Acc@1  82.03 ( 80.90)	Acc@5  97.66 ( 97.27)
Epoch: [43][270/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.7832e-01 (6.1644e-01)	Acc@1  81.25 ( 80.86)	Acc@5  97.66 ( 97.27)
Epoch: [43][280/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.4144e-01 (6.1777e-01)	Acc@1  84.38 ( 80.81)	Acc@5  98.44 ( 97.26)
Epoch: [43][290/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 6.3580e-01 (6.1887e-01)	Acc@1  79.69 ( 80.78)	Acc@5  96.88 ( 97.28)
Epoch: [43][300/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 7.6017e-01 (6.1979e-01)	Acc@1  73.44 ( 80.75)	Acc@5  95.31 ( 97.27)
Epoch: [43][310/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.001)	Loss 6.6193e-01 (6.2019e-01)	Acc@1  78.91 ( 80.75)	Acc@5  97.66 ( 97.28)
Epoch: [43][320/391]	Time  0.047 ( 0.042)	Data  0.001 ( 0.001)	Loss 6.0861e-01 (6.2166e-01)	Acc@1  82.81 ( 80.70)	Acc@5  98.44 ( 97.27)
Epoch: [43][330/391]	Time  0.046 ( 0.042)	Data  0.001 ( 0.001)	Loss 5.8329e-01 (6.2462e-01)	Acc@1  82.81 ( 80.61)	Acc@5  94.53 ( 97.25)
Epoch: [43][340/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.001)	Loss 6.5359e-01 (6.2483e-01)	Acc@1  82.03 ( 80.60)	Acc@5  96.88 ( 97.25)
Epoch: [43][350/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 5.9436e-01 (6.2568e-01)	Acc@1  76.56 ( 80.59)	Acc@5  98.44 ( 97.26)
Epoch: [43][360/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 6.9973e-01 (6.2691e-01)	Acc@1  77.34 ( 80.60)	Acc@5  98.44 ( 97.25)
Epoch: [43][370/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 6.2066e-01 (6.2733e-01)	Acc@1  81.25 ( 80.58)	Acc@5  96.09 ( 97.25)
Epoch: [43][380/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 6.4206e-01 (6.2891e-01)	Acc@1  80.47 ( 80.53)	Acc@5  96.88 ( 97.25)
Epoch: [43][390/391]	Time  0.032 ( 0.042)	Data  0.001 ( 0.001)	Loss 9.3149e-01 (6.2991e-01)	Acc@1  71.25 ( 80.50)	Acc@5  96.25 ( 97.25)
## e[43] optimizer.zero_grad (sum) time: 0.2856597900390625
## e[43]       loss.backward (sum) time: 4.162370920181274
## e[43]      optimizer.step (sum) time: 1.881655216217041
## epoch[43] training(only) time: 16.45256543159485
# Switched to evaluate mode...
Test: [  0/100]	Time  0.151 ( 0.151)	Loss 1.1717e+00 (1.1717e+00)	Acc@1  71.00 ( 71.00)	Acc@5  89.00 ( 89.00)
Test: [ 10/100]	Time  0.024 ( 0.035)	Loss 1.3048e+00 (1.4488e+00)	Acc@1  67.00 ( 66.00)	Acc@5  92.00 ( 88.27)
Test: [ 20/100]	Time  0.024 ( 0.030)	Loss 1.1303e+00 (1.4183e+00)	Acc@1  74.00 ( 65.24)	Acc@5  92.00 ( 88.81)
Test: [ 30/100]	Time  0.024 ( 0.028)	Loss 1.6734e+00 (1.4347e+00)	Acc@1  55.00 ( 64.19)	Acc@5  89.00 ( 88.61)
Test: [ 40/100]	Time  0.024 ( 0.027)	Loss 1.4115e+00 (1.4372e+00)	Acc@1  64.00 ( 64.17)	Acc@5  90.00 ( 88.85)
Test: [ 50/100]	Time  0.027 ( 0.026)	Loss 1.3817e+00 (1.4330e+00)	Acc@1  69.00 ( 64.31)	Acc@5  92.00 ( 88.90)
Test: [ 60/100]	Time  0.022 ( 0.026)	Loss 1.3174e+00 (1.4093e+00)	Acc@1  65.00 ( 64.75)	Acc@5  88.00 ( 89.28)
Test: [ 70/100]	Time  0.024 ( 0.025)	Loss 1.5713e+00 (1.4019e+00)	Acc@1  63.00 ( 65.07)	Acc@5  87.00 ( 89.21)
Test: [ 80/100]	Time  0.024 ( 0.025)	Loss 1.4356e+00 (1.4118e+00)	Acc@1  60.00 ( 64.81)	Acc@5  88.00 ( 89.16)
Test: [ 90/100]	Time  0.021 ( 0.025)	Loss 1.7122e+00 (1.3984e+00)	Acc@1  61.00 ( 65.04)	Acc@5  84.00 ( 89.36)
 * Acc@1 65.270 Acc@5 89.490
### epoch[43] execution time: 18.983022212982178
EPOCH 44
i:   0, name:           module.stem.0.weight  changing lr from: 0.002098297149271610   to: 0.001501895814259612
i:   1, name:             module.stem.0.bias  changing lr from: 0.002333094964484710   to: 0.001668916604206632
i:   2, name:           module.stem.1.weight  changing lr from: 0.002587674563812297   to: 0.001857732284312052
i:   3, name:             module.stem.1.bias  changing lr from: 0.002861309620877366   to: 0.002067594511440428
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.003153287059193027   to: 0.002297766799711914
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.003462907286975191   to: 0.002547524884396939
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.003789484392097053   to: 0.002816157039088812
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.004132346299805383   to: 0.003102964349027409
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.004490834895694761   to: 0.003407260943320477
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.004864306116315714   to: 0.003728374188685634
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.005252130009676380   to: 0.004065644847215921
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.005653690767784696   to: 0.004418427200554508
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.006068386733268882   to: 0.004786089142750576
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.006495630382009681   to: 0.005168012243958541
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.006934848283615996   to: 0.005563591787035454
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.007385481041478670   to: 0.005972236778989342
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.007846983214043025   to: 0.006393369939130588
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.008318823218851679   to: 0.006826427665683737
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.008800483220821852   to: 0.007270859982523630
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.009291459006139775   to: 0.007726130467611835
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.009791259843074777   to: 0.008191716164623108
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.010299408330940840   to: 0.008667107479170655
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.010815440238360025   to: 0.009151808060959353
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.011338904331914063   to: 0.009645334673121581
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.011869362196203936   to: 0.010147217049917934
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.012406388046274371   to: 0.010656997743916152
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.012949568533300863   to: 0.011174231963695835
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.013498502544379315   to: 0.011698487403063972
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.014052800997204427   to: 0.012229344062705604
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.014612086630371425   to: 0.012766394065137597
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.015175993789986804   to: 0.013309241463778522
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.015744168213227765   to: 0.013857502046896446
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.016316266809444903   to: 0.014410803137146287
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.016891957439362382   to: 0.014968783387362416
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.017470918692889359   to: 0.015531092573227451
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.018052839666019227   to: 0.016097391383395859
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.018637419737258489   to: 0.016667351207610991
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.019224368343992555   to: 0.017240653923316841
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.019813404759165477   to: 0.017816991681228769
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.020404257868619671   to: 0.018396066690294928
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.020996665949414746   to: 0.018977591002446611
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.021590376449417088   to: 0.019561286297506537
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.022185145768427506   to: 0.020146883668594351
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.022780739041091048   to: 0.020734123408342887
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.023376929921809959   to: 0.021322754796211596
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.023973500371861772   to: 0.021912535887161150
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.024570240448903054   to: 0.022503233301929229
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.025166948099023246   to: 0.023094622019127410
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.025763428951493941   to: 0.023686485169357716
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.026359496116344461   to: 0.024278613831529919
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.026954969984878809   to: 0.024870806831542025
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.027549678033235315   to: 0.025462870543470312
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.028143454629077282   to: 0.026054618693399447
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.028736140841490756   to: 0.026645872166009291
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.029327584254154028   to: 0.027236458814020193
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.029917638781832859   to: 0.027826213270587232
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.030506164490246259   to: 0.028414976764721125
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.031093027419337241   to: 0.029002596939802519
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.031678099409976082   to: 0.029588927675246547
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.032261257934114065   to: 0.030173828911364012
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.032842385928400324   to: 0.030757166477457992
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.033421371631265684   to: 0.031338811923184690
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.033998108423473082   to: 0.031918642353201035
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.034572494672126995   to: 0.032496540265113748
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.035144433578130109   to: 0.033072393390738045
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.035713833027070228   to: 0.033646094540668359
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.036280605443515912   to: 0.034217541452157364
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.036844667648695616   to: 0.034786636640294744
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.037405940721531618   to: 0.035353287252472630
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.037964349862996030   to: 0.035917404926119521
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.038519824263754318   to: 0.036478905649681530
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.039072296975057742   to: 0.037037709626825045
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.039621704782845095   to: 0.037593741143832980
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.040167988085010757   to: 0.038146928440162202
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.040711090771795272   to: 0.038697203582128567
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.041250960109252055   to: 0.039244502339682352
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.041787546625742952   to: 0.039788764066235632
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.042320804001413886   to: 0.040329931581500174
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.042850688960600930   to: 0.040867951057294225
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.043377161167116075   to: 0.041402771906273284
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.043900183122360853   to: 0.041934346673539950
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.044419720066216625   to: 0.042462630931086397
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.044935739880658049   to: 0.042987583175021805
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.045448212996037581   to: 0.043509164725536759
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.045957112299987453   to: 0.044027339629555219
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.046462413048886382   to: 0.044542074566025283
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.046964092781837198   to: 0.045053338753798237
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.047462131237102856   to: 0.045561103862046086
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.047956510270947363   to: 0.046065343923167128
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.048447213778829122   to: 0.046566035248129092
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.048934227618894016   to: 0.047063156344199428
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.049417539537716368   to: 0.047556687835012428
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.049897139098235892   to: 0.048046612382922946
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.050373017609839456   to: 0.048532914613596718
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.050845168060537162   to: 0.049015581042787790
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.051313585051182289   to: 0.049494600005253395
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.051778264731685876   to: 0.049969961585757797
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.052239204739177064   to: 0.050441657552116465
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.052696404138060586   to: 0.050909681290232295
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.053149863361924447   to: 0.051374027741077188
i: 100, name:           module.conv10.weight  changing lr from: 0.053599584157250635   to: 0.051834693339571386
i: 101, name:             module.conv10.bias  changing lr from: 0.054045569528882891   to: 0.052291675955314913



# Switched to train mode...
Epoch: [44][  0/391]	Time  0.190 ( 0.190)	Data  0.145 ( 0.145)	Loss 5.1555e-01 (5.1555e-01)	Acc@1  82.81 ( 82.81)	Acc@5  98.44 ( 98.44)
Epoch: [44][ 10/391]	Time  0.040 ( 0.055)	Data  0.001 ( 0.014)	Loss 5.6582e-01 (5.6006e-01)	Acc@1  81.25 ( 82.32)	Acc@5  99.22 ( 97.66)
Epoch: [44][ 20/391]	Time  0.041 ( 0.050)	Data  0.001 ( 0.008)	Loss 5.0687e-01 (5.5523e-01)	Acc@1  83.59 ( 83.07)	Acc@5  97.66 ( 97.62)
Epoch: [44][ 30/391]	Time  0.040 ( 0.047)	Data  0.001 ( 0.006)	Loss 5.6237e-01 (5.6401e-01)	Acc@1  78.12 ( 82.41)	Acc@5 100.00 ( 97.76)
Epoch: [44][ 40/391]	Time  0.040 ( 0.046)	Data  0.001 ( 0.004)	Loss 5.5354e-01 (5.8088e-01)	Acc@1  82.03 ( 81.75)	Acc@5  98.44 ( 97.66)
Epoch: [44][ 50/391]	Time  0.040 ( 0.045)	Data  0.001 ( 0.004)	Loss 4.4883e-01 (5.7976e-01)	Acc@1  86.72 ( 81.72)	Acc@5  99.22 ( 97.64)
Epoch: [44][ 60/391]	Time  0.042 ( 0.044)	Data  0.001 ( 0.003)	Loss 4.9225e-01 (5.7664e-01)	Acc@1  85.16 ( 81.86)	Acc@5  96.88 ( 97.67)
Epoch: [44][ 70/391]	Time  0.040 ( 0.044)	Data  0.001 ( 0.003)	Loss 6.3350e-01 (5.7234e-01)	Acc@1  79.69 ( 82.15)	Acc@5  96.09 ( 97.67)
Epoch: [44][ 80/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.003)	Loss 4.8113e-01 (5.7391e-01)	Acc@1  85.16 ( 82.13)	Acc@5  97.66 ( 97.67)
Epoch: [44][ 90/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.003)	Loss 5.7080e-01 (5.7774e-01)	Acc@1  84.38 ( 82.02)	Acc@5  97.66 ( 97.56)
Epoch: [44][100/391]	Time  0.047 ( 0.043)	Data  0.001 ( 0.002)	Loss 4.6353e-01 (5.8071e-01)	Acc@1  88.28 ( 82.02)	Acc@5  97.66 ( 97.47)
Epoch: [44][110/391]	Time  0.038 ( 0.043)	Data  0.001 ( 0.002)	Loss 5.9243e-01 (5.8581e-01)	Acc@1  79.69 ( 81.86)	Acc@5  98.44 ( 97.51)
Epoch: [44][120/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.002)	Loss 5.4395e-01 (5.9008e-01)	Acc@1  86.72 ( 81.77)	Acc@5  96.88 ( 97.45)
Epoch: [44][130/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.0168e-01 (5.9082e-01)	Acc@1  80.47 ( 81.73)	Acc@5  97.66 ( 97.45)
Epoch: [44][140/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.8186e-01 (5.8985e-01)	Acc@1  82.03 ( 81.74)	Acc@5  96.88 ( 97.44)
Epoch: [44][150/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.9874e-01 (5.8771e-01)	Acc@1  82.03 ( 81.73)	Acc@5  99.22 ( 97.50)
Epoch: [44][160/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.9959e-01 (5.8955e-01)	Acc@1  77.34 ( 81.65)	Acc@5  95.31 ( 97.52)
Epoch: [44][170/391]	Time  0.045 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.3766e-01 (5.8943e-01)	Acc@1  84.38 ( 81.67)	Acc@5  96.88 ( 97.50)
Epoch: [44][180/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.6000e-01 (5.9436e-01)	Acc@1  78.91 ( 81.57)	Acc@5  95.31 ( 97.43)
Epoch: [44][190/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.5325e-01 (5.9556e-01)	Acc@1  78.91 ( 81.52)	Acc@5  96.88 ( 97.44)
Epoch: [44][200/391]	Time  0.045 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.5802e-01 (5.9761e-01)	Acc@1  82.81 ( 81.43)	Acc@5  98.44 ( 97.42)
Epoch: [44][210/391]	Time  0.045 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.2042e-01 (6.0047e-01)	Acc@1  78.91 ( 81.36)	Acc@5  96.09 ( 97.38)
Epoch: [44][220/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.4547e-01 (6.0233e-01)	Acc@1  80.47 ( 81.31)	Acc@5  98.44 ( 97.38)
Epoch: [44][230/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 4.4759e-01 (6.0052e-01)	Acc@1  86.72 ( 81.36)	Acc@5  97.66 ( 97.43)
Epoch: [44][240/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.1673e-01 (5.9910e-01)	Acc@1  87.50 ( 81.40)	Acc@5  96.88 ( 97.45)
Epoch: [44][250/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.2704e-01 (6.0039e-01)	Acc@1  78.12 ( 81.35)	Acc@5  95.31 ( 97.44)
Epoch: [44][260/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.7556e-01 (6.0147e-01)	Acc@1  76.56 ( 81.36)	Acc@5  96.88 ( 97.43)
Epoch: [44][270/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.001)	Loss 5.8775e-01 (6.0197e-01)	Acc@1  84.38 ( 81.32)	Acc@5  98.44 ( 97.43)
Epoch: [44][280/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 6.5851e-01 (6.0398e-01)	Acc@1  79.69 ( 81.27)	Acc@5  98.44 ( 97.41)
Epoch: [44][290/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.001)	Loss 6.1209e-01 (6.0417e-01)	Acc@1  82.81 ( 81.25)	Acc@5  98.44 ( 97.41)
Epoch: [44][300/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.001)	Loss 6.2188e-01 (6.0560e-01)	Acc@1  80.47 ( 81.21)	Acc@5  97.66 ( 97.40)
Epoch: [44][310/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.001)	Loss 7.5945e-01 (6.0576e-01)	Acc@1  77.34 ( 81.22)	Acc@5  97.66 ( 97.41)
Epoch: [44][320/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 6.6802e-01 (6.0847e-01)	Acc@1  80.47 ( 81.16)	Acc@5  97.66 ( 97.39)
Epoch: [44][330/391]	Time  0.045 ( 0.042)	Data  0.001 ( 0.001)	Loss 7.3262e-01 (6.1016e-01)	Acc@1  71.88 ( 81.07)	Acc@5  96.88 ( 97.39)
Epoch: [44][340/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.001)	Loss 6.8505e-01 (6.1290e-01)	Acc@1  75.78 ( 80.95)	Acc@5  96.88 ( 97.37)
Epoch: [44][350/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 7.1537e-01 (6.1334e-01)	Acc@1  75.78 ( 80.94)	Acc@5  96.88 ( 97.35)
Epoch: [44][360/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 6.0315e-01 (6.1495e-01)	Acc@1  80.47 ( 80.89)	Acc@5  97.66 ( 97.34)
Epoch: [44][370/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.001)	Loss 4.9463e-01 (6.1586e-01)	Acc@1  82.03 ( 80.84)	Acc@5  96.88 ( 97.34)
Epoch: [44][380/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 5.6289e-01 (6.1581e-01)	Acc@1  83.59 ( 80.83)	Acc@5  99.22 ( 97.34)
Epoch: [44][390/391]	Time  0.026 ( 0.042)	Data  0.001 ( 0.001)	Loss 6.1825e-01 (6.1752e-01)	Acc@1  76.25 ( 80.77)	Acc@5  98.75 ( 97.33)
## e[44] optimizer.zero_grad (sum) time: 0.287738561630249
## e[44]       loss.backward (sum) time: 4.1343443393707275
## e[44]      optimizer.step (sum) time: 1.8897645473480225
## epoch[44] training(only) time: 16.437817335128784
# Switched to evaluate mode...
Test: [  0/100]	Time  0.151 ( 0.151)	Loss 1.3613e+00 (1.3613e+00)	Acc@1  63.00 ( 63.00)	Acc@5  89.00 ( 89.00)
Test: [ 10/100]	Time  0.018 ( 0.033)	Loss 1.5201e+00 (1.4643e+00)	Acc@1  59.00 ( 62.45)	Acc@5  87.00 ( 88.55)
Test: [ 20/100]	Time  0.022 ( 0.027)	Loss 1.1328e+00 (1.4574e+00)	Acc@1  72.00 ( 62.81)	Acc@5  93.00 ( 89.00)
Test: [ 30/100]	Time  0.022 ( 0.026)	Loss 1.6622e+00 (1.4610e+00)	Acc@1  61.00 ( 62.61)	Acc@5  88.00 ( 88.87)
Test: [ 40/100]	Time  0.024 ( 0.025)	Loss 1.3404e+00 (1.4612e+00)	Acc@1  65.00 ( 62.95)	Acc@5  90.00 ( 88.78)
Test: [ 50/100]	Time  0.021 ( 0.025)	Loss 1.3921e+00 (1.4634e+00)	Acc@1  67.00 ( 63.10)	Acc@5  90.00 ( 88.65)
Test: [ 60/100]	Time  0.022 ( 0.024)	Loss 1.6926e+00 (1.4510e+00)	Acc@1  58.00 ( 63.44)	Acc@5  87.00 ( 88.90)
Test: [ 70/100]	Time  0.021 ( 0.024)	Loss 1.7123e+00 (1.4527e+00)	Acc@1  57.00 ( 63.56)	Acc@5  85.00 ( 88.86)
Test: [ 80/100]	Time  0.031 ( 0.024)	Loss 1.5424e+00 (1.4561e+00)	Acc@1  57.00 ( 63.32)	Acc@5  86.00 ( 88.86)
Test: [ 90/100]	Time  0.022 ( 0.023)	Loss 1.7213e+00 (1.4470e+00)	Acc@1  59.00 ( 63.64)	Acc@5  85.00 ( 88.86)
 * Acc@1 63.940 Acc@5 88.980
### epoch[44] execution time: 18.84128212928772
EPOCH 45
i:   0, name:           module.stem.0.weight  changing lr from: 0.001501895814259612   to: 0.001135477166065490
i:   1, name:             module.stem.0.bias  changing lr from: 0.001668916604206632   to: 0.001230604220034714
i:   2, name:           module.stem.1.weight  changing lr from: 0.001857732284312052   to: 0.001349520013457000
i:   3, name:             module.stem.1.bias  changing lr from: 0.002067594511440428   to: 0.001491460130189769
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.002297766799711914   to: 0.001655670268040987
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.002547524884396939   to: 0.001841406745697160
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.002816157039088812   to: 0.002047936955776529
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.003102964349027409   to: 0.002274539767118033
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.003407260943320477   to: 0.002520505879290179
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.003728374188685634   to: 0.002785138132179398
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.004065644847215921   to: 0.003067751773395682
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.004418427200554508   to: 0.003367674686113752
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.004786089142750576   to: 0.003684247579851251
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.005168012243958541   to: 0.004016824146572056
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.005563591787035454   to: 0.004364771184391930
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.005972236778989342   to: 0.004727468691056552
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.006393369939130588   to: 0.005104309929257327
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.006826427665683737   to: 0.005494701465750229
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.007270859982523630   to: 0.005898063186144425
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.007726130467611835   to: 0.006313828287133993
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.008191716164623108   to: 0.006741443247854566
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.008667107479170655   to: 0.007180367781959678
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.009151808060959353   to: 0.007630074771926792
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.009645334673121581   to: 0.008090050187022378
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.010147217049917934   to: 0.008559792986277437
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.010656997743916152   to: 0.009038815007750074
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.011174231963695835   to: 0.009526640845280602
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.011698487403063972   to: 0.010022807713875696
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.012229344062705604   to: 0.010526865304792882
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.012766394065137597   to: 0.011038375631333596
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.013309241463778522   to: 0.011556912866293713
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.013857502046896446   to: 0.012082063171963059
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.014410803137146287   to: 0.012613424523510674
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.014968783387362416   to: 0.013150606526541136
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.015531092573227451   to: 0.013693230229557547
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.016097391383395859   to: 0.014240927932019865
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.016667351207610991   to: 0.014793342988642367
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.017240653923316841   to: 0.015350129610531782
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.017816991681228769   to: 0.015910952663727041
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.018396066690294928   to: 0.016475487465663331
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.018977591002446611   to: 0.017043419580047094
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.019561286297506537   to: 0.017614444610593940
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.020146883668594351   to: 0.018188267994048664
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.020734123408342887   to: 0.018764604792876539
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.021322754796211596   to: 0.019343179487984891
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.021912535887161150   to: 0.019923725771807028
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.022503233301929229   to: 0.020505986342054607
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.023094622019127410   to: 0.021089712696419707
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.023686485169357716   to: 0.021674664928484695
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.024278613831529919   to: 0.022260611525076621
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.024870806831542025   to: 0.022847329165281607
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.025462870543470312   to: 0.023434602521316079
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.026054618693399447   to: 0.024022224061433273
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.026645872166009291   to: 0.024609993855025793
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.027236458814020193   to: 0.025197719380070274
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.027826213270587232   to: 0.025785215333043489
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.028414976764721125   to: 0.026372303441426784
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.029002596939802519   to: 0.026958812278901297
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.029588927675246547   to: 0.027544577083324764
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.030173828911364012   to: 0.028129439577568749
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.030757166477457992   to: 0.028713247793284949
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.031338811923184690   to: 0.029295855897658235
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.031918642353201035   to: 0.029877124023195624
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.032496540265113748   to: 0.030456918100591208
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.033072393390738045   to: 0.031035109694699026
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.033646094540668359   to: 0.031611575843638370
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.034217541452157364   to: 0.032186198901048929
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.034786636640294744   to: 0.032758866381506782
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.035353287252472630   to: 0.033329470809106490
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.035917404926119521   to: 0.033897909569208462
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.036478905649681530   to: 0.034464084763346357
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.037037709626825045   to: 0.035027903067283893
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.037593741143832980   to: 0.035589275592206961
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.038146928440162202   to: 0.036148117749032004
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.038697203582128567   to: 0.036704349115809276
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.039244502339682352   to: 0.037257893308194796
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.039788764066235632   to: 0.037808677852963428
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.040329931581500174   to: 0.038356634064531395
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.040867951057294225   to: 0.038901696924455276
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.041402771906273284   to: 0.039443804963871537
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.041934346673539950   to: 0.039982900148838880
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.042462630931086397   to: 0.040518927768544405
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.042987583175021805   to: 0.041051836326332303
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.043509164725536759   to: 0.041581577433513206
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.044027339629555219   to: 0.042108105705910157
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.044542074566025283   to: 0.042631378663097554
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.045053338753798237   to: 0.043151356630287172
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.045561103862046086   to: 0.043668002642815298
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.046065343923167128   to: 0.044181282353184810
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.046566035248129092   to: 0.044691163940614502
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.047063156344199428   to: 0.045197618023048697
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.047556687835012428   to: 0.045700617571579366
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.048046612382922946   to: 0.046200137827232833
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.048532914613596718   to: 0.046696156220073254
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.049015581042787790   to: 0.047188652290575166
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.049494600005253395   to: 0.047677607613216981
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.049969961585757797   to: 0.048163005722248381
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.050441657552116465   to: 0.048644832039583891
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.050909681290232295   to: 0.049123073804775493
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.051374027741077188   to: 0.049597720007018037
i: 100, name:           module.conv10.weight  changing lr from: 0.051834693339571386   to: 0.050068761319140627
i: 101, name:             module.conv10.bias  changing lr from: 0.052291675955314913   to: 0.050536190033538549



# Switched to train mode...
Epoch: [45][  0/391]	Time  0.195 ( 0.195)	Data  0.147 ( 0.147)	Loss 6.6335e-01 (6.6335e-01)	Acc@1  80.47 ( 80.47)	Acc@5  97.66 ( 97.66)
Epoch: [45][ 10/391]	Time  0.042 ( 0.056)	Data  0.001 ( 0.014)	Loss 4.8510e-01 (5.7073e-01)	Acc@1  86.72 ( 82.53)	Acc@5  98.44 ( 97.51)
Epoch: [45][ 20/391]	Time  0.043 ( 0.049)	Data  0.001 ( 0.008)	Loss 6.0698e-01 (5.7200e-01)	Acc@1  82.81 ( 82.29)	Acc@5  96.88 ( 97.69)
Epoch: [45][ 30/391]	Time  0.041 ( 0.046)	Data  0.001 ( 0.006)	Loss 4.9563e-01 (5.7246e-01)	Acc@1  85.94 ( 82.13)	Acc@5  97.66 ( 97.78)
Epoch: [45][ 40/391]	Time  0.044 ( 0.045)	Data  0.001 ( 0.005)	Loss 5.9350e-01 (5.6529e-01)	Acc@1  83.59 ( 82.39)	Acc@5  98.44 ( 97.92)
Epoch: [45][ 50/391]	Time  0.042 ( 0.045)	Data  0.001 ( 0.004)	Loss 4.7861e-01 (5.6344e-01)	Acc@1  83.59 ( 82.46)	Acc@5 100.00 ( 97.86)
Epoch: [45][ 60/391]	Time  0.041 ( 0.044)	Data  0.001 ( 0.003)	Loss 5.7913e-01 (5.6530e-01)	Acc@1  84.38 ( 82.38)	Acc@5  98.44 ( 97.82)
Epoch: [45][ 70/391]	Time  0.040 ( 0.044)	Data  0.001 ( 0.003)	Loss 5.5115e-01 (5.6877e-01)	Acc@1  83.59 ( 82.24)	Acc@5  98.44 ( 97.84)
Epoch: [45][ 80/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.003)	Loss 6.1184e-01 (5.6944e-01)	Acc@1  81.25 ( 82.28)	Acc@5  97.66 ( 97.83)
Epoch: [45][ 90/391]	Time  0.039 ( 0.043)	Data  0.001 ( 0.003)	Loss 6.9026e-01 (5.7054e-01)	Acc@1  78.12 ( 82.27)	Acc@5  96.88 ( 97.81)
Epoch: [45][100/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.002)	Loss 5.1537e-01 (5.6759e-01)	Acc@1  82.81 ( 82.39)	Acc@5  97.66 ( 97.78)
Epoch: [45][110/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.002)	Loss 4.7369e-01 (5.6959e-01)	Acc@1  85.94 ( 82.41)	Acc@5 100.00 ( 97.75)
Epoch: [45][120/391]	Time  0.044 ( 0.043)	Data  0.001 ( 0.002)	Loss 4.8725e-01 (5.6793e-01)	Acc@1  86.72 ( 82.43)	Acc@5  98.44 ( 97.79)
Epoch: [45][130/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 5.0484e-01 (5.6719e-01)	Acc@1  83.59 ( 82.54)	Acc@5  99.22 ( 97.78)
Epoch: [45][140/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.002)	Loss 5.8577e-01 (5.6943e-01)	Acc@1  82.03 ( 82.52)	Acc@5  97.66 ( 97.77)
Epoch: [45][150/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 5.9879e-01 (5.6927e-01)	Acc@1  82.03 ( 82.48)	Acc@5  96.88 ( 97.74)
Epoch: [45][160/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.002)	Loss 4.8034e-01 (5.6770e-01)	Acc@1  85.94 ( 82.46)	Acc@5  98.44 ( 97.74)
Epoch: [45][170/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.002)	Loss 4.8684e-01 (5.6756e-01)	Acc@1  83.59 ( 82.52)	Acc@5  99.22 ( 97.72)
Epoch: [45][180/391]	Time  0.039 ( 0.043)	Data  0.001 ( 0.002)	Loss 5.6594e-01 (5.6619e-01)	Acc@1  82.81 ( 82.58)	Acc@5  98.44 ( 97.77)
Epoch: [45][190/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.8752e-01 (5.6920e-01)	Acc@1  81.25 ( 82.46)	Acc@5  98.44 ( 97.75)
Epoch: [45][200/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.002)	Loss 5.2249e-01 (5.7117e-01)	Acc@1  87.50 ( 82.40)	Acc@5  98.44 ( 97.75)
Epoch: [45][210/391]	Time  0.039 ( 0.043)	Data  0.001 ( 0.002)	Loss 5.3179e-01 (5.7172e-01)	Acc@1  82.81 ( 82.38)	Acc@5  97.66 ( 97.75)
Epoch: [45][220/391]	Time  0.044 ( 0.043)	Data  0.001 ( 0.002)	Loss 4.8615e-01 (5.6925e-01)	Acc@1  84.38 ( 82.47)	Acc@5  98.44 ( 97.76)
Epoch: [45][230/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.7538e-01 (5.6958e-01)	Acc@1  83.59 ( 82.46)	Acc@5  97.66 ( 97.76)
Epoch: [45][240/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.3740e-01 (5.7178e-01)	Acc@1  79.69 ( 82.35)	Acc@5  96.88 ( 97.73)
Epoch: [45][250/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 7.5934e-01 (5.7450e-01)	Acc@1  79.69 ( 82.34)	Acc@5  94.53 ( 97.68)
Epoch: [45][260/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.8239e-01 (5.7630e-01)	Acc@1  82.81 ( 82.24)	Acc@5  98.44 ( 97.69)
Epoch: [45][270/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 4.7846e-01 (5.7812e-01)	Acc@1  86.72 ( 82.19)	Acc@5 100.00 ( 97.67)
Epoch: [45][280/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.5812e-01 (5.7838e-01)	Acc@1  78.12 ( 82.15)	Acc@5  97.66 ( 97.69)
Epoch: [45][290/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.7016e-01 (5.7903e-01)	Acc@1  84.38 ( 82.16)	Acc@5  96.88 ( 97.67)
Epoch: [45][300/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.8232e-01 (5.7869e-01)	Acc@1  80.47 ( 82.20)	Acc@5  94.53 ( 97.66)
Epoch: [45][310/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.9375e-01 (5.8038e-01)	Acc@1  80.47 ( 82.18)	Acc@5  97.66 ( 97.63)
Epoch: [45][320/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.001)	Loss 5.2177e-01 (5.8190e-01)	Acc@1  85.16 ( 82.13)	Acc@5  98.44 ( 97.62)
Epoch: [45][330/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.001)	Loss 5.3202e-01 (5.8189e-01)	Acc@1  81.25 ( 82.12)	Acc@5  99.22 ( 97.63)
Epoch: [45][340/391]	Time  0.045 ( 0.042)	Data  0.001 ( 0.001)	Loss 5.0806e-01 (5.8206e-01)	Acc@1  80.47 ( 82.08)	Acc@5  98.44 ( 97.62)
Epoch: [45][350/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.001)	Loss 6.8307e-01 (5.8427e-01)	Acc@1  83.59 ( 81.99)	Acc@5  95.31 ( 97.59)
Epoch: [45][360/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.001)	Loss 5.9652e-01 (5.8515e-01)	Acc@1  82.81 ( 81.93)	Acc@5  98.44 ( 97.60)
Epoch: [45][370/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.001)	Loss 5.6233e-01 (5.8643e-01)	Acc@1  78.91 ( 81.91)	Acc@5  98.44 ( 97.58)
Epoch: [45][380/391]	Time  0.041 ( 0.042)	Data  0.002 ( 0.001)	Loss 7.1420e-01 (5.8681e-01)	Acc@1  75.78 ( 81.90)	Acc@5  95.31 ( 97.58)
Epoch: [45][390/391]	Time  0.026 ( 0.042)	Data  0.001 ( 0.001)	Loss 4.5407e-01 (5.8762e-01)	Acc@1  87.50 ( 81.88)	Acc@5  97.50 ( 97.57)
## e[45] optimizer.zero_grad (sum) time: 0.2866692543029785
## e[45]       loss.backward (sum) time: 4.176872491836548
## e[45]      optimizer.step (sum) time: 1.8314316272735596
## epoch[45] training(only) time: 16.5168514251709
# Switched to evaluate mode...
Test: [  0/100]	Time  0.153 ( 0.153)	Loss 1.3019e+00 (1.3019e+00)	Acc@1  67.00 ( 67.00)	Acc@5  89.00 ( 89.00)
Test: [ 10/100]	Time  0.022 ( 0.034)	Loss 1.3396e+00 (1.4476e+00)	Acc@1  65.00 ( 65.45)	Acc@5  93.00 ( 88.64)
Test: [ 20/100]	Time  0.018 ( 0.029)	Loss 1.2448e+00 (1.4314e+00)	Acc@1  68.00 ( 65.38)	Acc@5  90.00 ( 89.33)
Test: [ 30/100]	Time  0.024 ( 0.027)	Loss 1.5546e+00 (1.4568e+00)	Acc@1  60.00 ( 64.74)	Acc@5  87.00 ( 89.06)
Test: [ 40/100]	Time  0.019 ( 0.026)	Loss 1.2409e+00 (1.4507e+00)	Acc@1  70.00 ( 64.93)	Acc@5  93.00 ( 89.07)
Test: [ 50/100]	Time  0.021 ( 0.025)	Loss 1.5185e+00 (1.4541e+00)	Acc@1  66.00 ( 64.78)	Acc@5  89.00 ( 89.12)
Test: [ 60/100]	Time  0.024 ( 0.025)	Loss 1.4497e+00 (1.4313e+00)	Acc@1  63.00 ( 64.93)	Acc@5  90.00 ( 89.33)
Test: [ 70/100]	Time  0.019 ( 0.024)	Loss 1.4284e+00 (1.4269e+00)	Acc@1  66.00 ( 65.10)	Acc@5  88.00 ( 89.38)
Test: [ 80/100]	Time  0.020 ( 0.024)	Loss 1.5739e+00 (1.4308e+00)	Acc@1  60.00 ( 65.00)	Acc@5  86.00 ( 89.31)
Test: [ 90/100]	Time  0.017 ( 0.024)	Loss 1.7921e+00 (1.4230e+00)	Acc@1  63.00 ( 65.24)	Acc@5  83.00 ( 89.37)
 * Acc@1 65.210 Acc@5 89.400
### epoch[45] execution time: 18.919002532958984
EPOCH 46
i:   0, name:           module.stem.0.weight  changing lr from: 0.001135477166065490   to: 0.001000743693028921
i:   1, name:             module.stem.0.bias  changing lr from: 0.001230604220034714   to: 0.001020164657302085
i:   2, name:           module.stem.1.weight  changing lr from: 0.001349520013457000   to: 0.001065330806013408
i:   3, name:             module.stem.1.bias  changing lr from: 0.001491460130189769   to: 0.001135468291468144
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.001655670268040987   to: 0.001229811270168156
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.001841406745697160   to: 0.001347602566317717
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.002047936955776529   to: 0.001488094274099288
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.002274539767118033   to: 0.001650548302044229
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.002520505879290179   to: 0.001834236862699916
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.002785138132179398   to: 0.002038442910672577
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.003067751773395682   to: 0.002262460532003957
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.003367674686113752   to: 0.002505595287720723
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.003684247579851251   to: 0.002767164514277936
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.004016824146572056   to: 0.003046497583503026
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.004364771184391930   to: 0.003342936124533540
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.004727468691056552   to: 0.003655834210132285
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.005104309929257327   to: 0.003984558509655566
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.005494701465750229   to: 0.004328488410846192
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.005898063186144425   to: 0.004687016112520986
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.006313828287133993   to: 0.005059546690124072
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.006741443247854566   to: 0.005445498136021997
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.007180367781959678   to: 0.005844301376324045
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.007630074771926792   to: 0.006255400265922111
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.008090050187022378   to: 0.006678251563358450
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.008559792986277437   to: 0.007112324887046383
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.009038815007750074   to: 0.007557102654289410
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.009526640845280602   to: 0.008012080004467226
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.010022807713875696   to: 0.008476764707683498
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.010526865304792882   to: 0.008950677060098999
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.011038375631333596   to: 0.009433349767106247
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.011556912866293713   to: 0.009924327815436312
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.012082063171963059   to: 0.010423168335226680
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.012613424523510674   to: 0.010929440453018534
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.013150606526541136   to: 0.011442725136596027
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.013693230229557547   to: 0.011962615032524809
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.014240927932019865   to: 0.012488714297195676
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.014793342988642367   to: 0.013020638422129620
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.015350129610531782   to: 0.013558014054253397
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.015910952663727041   to: 0.014100478811809813
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.016475487465663331   to: 0.014647681096524527
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.017043419580047094   to: 0.015199279902610070
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.017614444610593940   to: 0.015754944623149990
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.018188267994048664   to: 0.016314354854368295
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.018764604792876539   to: 0.016877200198256233
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.019343179487984891   to: 0.017443180063993674
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.019923725771807028   to: 0.018012003468572842
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.020505986342054607   to: 0.018583388837001415
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.021089712696419707   to: 0.019157063802434936
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.021674664928484695   to: 0.019732765006561105
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.022260611525076621   to: 0.020310237900534746
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.022847329165281607   to: 0.020889236546737390
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.023434602521316079   to: 0.021469523421614175
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.024022224061433273   to: 0.022050869219819413
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.024609993855025793   to: 0.022633052659882094
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.025197719380070274   to: 0.023215860291584751
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.025785215333043489   to: 0.023799086305230283
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.026372303441426784   to: 0.024382532342957036
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.026958812278901297   to: 0.024966007312244139
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.027544577083324764   to: 0.025549327201737301
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.028129439577568749   to: 0.026132314899509512
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.028713247793284949   to: 0.026714800013860021
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.029295855897658235   to: 0.027296618696741437
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.029877124023195624   to: 0.027877613469895077
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.030456918100591208   to: 0.028457633053762879
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.031035109694699026   to: 0.029036532199235777
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.031611575843638370   to: 0.029614171522288114
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.032186198901048929   to: 0.030190417341540012
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.032758866381506782   to: 0.030765141518781288
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.033329470809106490   to: 0.031338221302483350
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.033897909569208462   to: 0.031909539174318664
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.034464084763346357   to: 0.032478982698701073
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.035027903067283893   to: 0.033046444375354173
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.035589275592206961   to: 0.033611821494910037
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.036148117749032004   to: 0.034175015997534974
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.036704349115809276   to: 0.034735934334575079
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.037257893308194796   to: 0.035294487333209341
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.037808677852963428   to: 0.035850590064094884
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.038356634064531395   to: 0.036404161711984996
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.038901696924455276   to: 0.036955125449297389
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.039443804963871537   to: 0.037503408312607379
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.039982900148838880   to: 0.038048941082037449
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.040518927768544405   to: 0.038591658163513336
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.041051836326332303   to: 0.039131497473852944
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.041581577433513206   to: 0.039668400328654312
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.042108105705910157   to: 0.040202311332945224
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.042631378663097554   to: 0.040733178274557316
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.043151356630287172   to: 0.041260952020184455
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.043668002642815298   to: 0.041785586414085342
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.044181282353184810   to: 0.042307038179388440
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.044691163940614502   to: 0.042825266821956566
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.045197618023048697   to: 0.043340234536768045
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.045700617571579366   to: 0.043851906116770298
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.046200137827232833   to: 0.044360248864161622
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.046696156220073254   to: 0.044865232504055941
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.047188652290575166   to: 0.045366829100485784
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.047677607613216981   to: 0.045865012974697923
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.048163005722248381   to: 0.046359760625696245
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.048644832039583891   to: 0.046851050652986524
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.049123073804775493   to: 0.047338863681477238
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.049597720007018037   to: 0.047823182288491806
i: 100, name:           module.conv10.weight  changing lr from: 0.050068761319140627   to: 0.048303990932846451
i: 101, name:             module.conv10.bias  changing lr from: 0.050536190033538549   to: 0.048781275885949139



# Switched to train mode...
Epoch: [46][  0/391]	Time  0.205 ( 0.205)	Data  0.155 ( 0.155)	Loss 6.4260e-01 (6.4260e-01)	Acc@1  82.03 ( 82.03)	Acc@5  96.88 ( 96.88)
Epoch: [46][ 10/391]	Time  0.041 ( 0.056)	Data  0.001 ( 0.015)	Loss 5.5988e-01 (5.7653e-01)	Acc@1  78.12 ( 82.32)	Acc@5  97.66 ( 97.80)
Epoch: [46][ 20/391]	Time  0.045 ( 0.051)	Data  0.001 ( 0.008)	Loss 6.2388e-01 (5.7726e-01)	Acc@1  82.03 ( 82.07)	Acc@5  93.75 ( 97.51)
Epoch: [46][ 30/391]	Time  0.042 ( 0.048)	Data  0.001 ( 0.006)	Loss 4.4504e-01 (5.6397e-01)	Acc@1  85.16 ( 82.23)	Acc@5  98.44 ( 97.71)
Epoch: [46][ 40/391]	Time  0.041 ( 0.046)	Data  0.001 ( 0.005)	Loss 5.4398e-01 (5.5996e-01)	Acc@1  82.03 ( 82.47)	Acc@5  96.88 ( 97.73)
Epoch: [46][ 50/391]	Time  0.040 ( 0.045)	Data  0.001 ( 0.004)	Loss 6.9110e-01 (5.6401e-01)	Acc@1  76.56 ( 82.02)	Acc@5  99.22 ( 97.81)
Epoch: [46][ 60/391]	Time  0.044 ( 0.045)	Data  0.001 ( 0.004)	Loss 6.2601e-01 (5.6855e-01)	Acc@1  78.91 ( 81.97)	Acc@5  98.44 ( 97.81)
Epoch: [46][ 70/391]	Time  0.041 ( 0.044)	Data  0.001 ( 0.003)	Loss 4.1367e-01 (5.7057e-01)	Acc@1  87.50 ( 82.02)	Acc@5 100.00 ( 97.74)
Epoch: [46][ 80/391]	Time  0.042 ( 0.044)	Data  0.001 ( 0.003)	Loss 4.7695e-01 (5.6566e-01)	Acc@1  84.38 ( 82.18)	Acc@5  97.66 ( 97.83)
Epoch: [46][ 90/391]	Time  0.039 ( 0.044)	Data  0.001 ( 0.003)	Loss 4.5893e-01 (5.6275e-01)	Acc@1  82.81 ( 82.34)	Acc@5  97.66 ( 97.81)
Epoch: [46][100/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.003)	Loss 4.5777e-01 (5.6152e-01)	Acc@1  85.94 ( 82.33)	Acc@5  98.44 ( 97.87)
Epoch: [46][110/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.002)	Loss 6.3580e-01 (5.6008e-01)	Acc@1  80.47 ( 82.42)	Acc@5  96.09 ( 97.86)
Epoch: [46][120/391]	Time  0.039 ( 0.043)	Data  0.001 ( 0.002)	Loss 6.6950e-01 (5.5986e-01)	Acc@1  75.78 ( 82.39)	Acc@5  96.88 ( 97.84)
Epoch: [46][130/391]	Time  0.044 ( 0.043)	Data  0.001 ( 0.002)	Loss 6.4715e-01 (5.6060e-01)	Acc@1  81.25 ( 82.38)	Acc@5  97.66 ( 97.85)
Epoch: [46][140/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.002)	Loss 4.9715e-01 (5.5759e-01)	Acc@1  84.38 ( 82.45)	Acc@5  98.44 ( 97.90)
Epoch: [46][150/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 5.7444e-01 (5.5538e-01)	Acc@1  78.12 ( 82.45)	Acc@5 100.00 ( 97.95)
Epoch: [46][160/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 8.8759e-01 (5.5812e-01)	Acc@1  75.00 ( 82.28)	Acc@5  96.88 ( 97.95)
Epoch: [46][170/391]	Time  0.042 ( 0.043)	Data  0.002 ( 0.002)	Loss 4.2077e-01 (5.5758e-01)	Acc@1  89.06 ( 82.33)	Acc@5 100.00 ( 97.98)
Epoch: [46][180/391]	Time  0.039 ( 0.043)	Data  0.001 ( 0.002)	Loss 7.4060e-01 (5.6189e-01)	Acc@1  78.91 ( 82.29)	Acc@5  97.66 ( 97.96)
Epoch: [46][190/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.002)	Loss 4.7814e-01 (5.6061e-01)	Acc@1  85.94 ( 82.37)	Acc@5  98.44 ( 97.96)
Epoch: [46][200/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 4.5753e-01 (5.6025e-01)	Acc@1  88.28 ( 82.41)	Acc@5  97.66 ( 97.96)
Epoch: [46][210/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.3356e-01 (5.6114e-01)	Acc@1  79.69 ( 82.39)	Acc@5  98.44 ( 97.94)
Epoch: [46][220/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.2246e-01 (5.6045e-01)	Acc@1  78.12 ( 82.41)	Acc@5  96.88 ( 97.93)
Epoch: [46][230/391]	Time  0.045 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.2924e-01 (5.6055e-01)	Acc@1  87.50 ( 82.43)	Acc@5  97.66 ( 97.93)
Epoch: [46][240/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 4.8868e-01 (5.5884e-01)	Acc@1  86.72 ( 82.48)	Acc@5  97.66 ( 97.93)
Epoch: [46][250/391]	Time  0.046 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.3104e-01 (5.5849e-01)	Acc@1  82.03 ( 82.49)	Acc@5  98.44 ( 97.93)
Epoch: [46][260/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.6210e-01 (5.5884e-01)	Acc@1  82.81 ( 82.47)	Acc@5  97.66 ( 97.93)
Epoch: [46][270/391]	Time  0.045 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.8638e-01 (5.5950e-01)	Acc@1  83.59 ( 82.46)	Acc@5  96.88 ( 97.89)
Epoch: [46][280/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.8244e-01 (5.6150e-01)	Acc@1  80.47 ( 82.40)	Acc@5 100.00 ( 97.88)
Epoch: [46][290/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.5016e-01 (5.6204e-01)	Acc@1  78.12 ( 82.43)	Acc@5  96.88 ( 97.86)
Epoch: [46][300/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.0298e-01 (5.6246e-01)	Acc@1  85.94 ( 82.41)	Acc@5  99.22 ( 97.85)
Epoch: [46][310/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.1744e-01 (5.6365e-01)	Acc@1  83.59 ( 82.38)	Acc@5  97.66 ( 97.83)
Epoch: [46][320/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.0331e-01 (5.6317e-01)	Acc@1  79.69 ( 82.39)	Acc@5  97.66 ( 97.85)
Epoch: [46][330/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.001)	Loss 6.5041e-01 (5.6547e-01)	Acc@1  78.12 ( 82.32)	Acc@5  96.88 ( 97.83)
Epoch: [46][340/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.001)	Loss 5.8880e-01 (5.6623e-01)	Acc@1  82.81 ( 82.29)	Acc@5  98.44 ( 97.83)
Epoch: [46][350/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.001)	Loss 5.5194e-01 (5.6626e-01)	Acc@1  85.16 ( 82.29)	Acc@5  98.44 ( 97.85)
Epoch: [46][360/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.001)	Loss 4.7459e-01 (5.6615e-01)	Acc@1  86.72 ( 82.28)	Acc@5  97.66 ( 97.84)
Epoch: [46][370/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.001)	Loss 7.3248e-01 (5.6750e-01)	Acc@1  81.25 ( 82.26)	Acc@5  96.88 ( 97.82)
Epoch: [46][380/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.001)	Loss 5.4469e-01 (5.6788e-01)	Acc@1  80.47 ( 82.25)	Acc@5 100.00 ( 97.83)
Epoch: [46][390/391]	Time  0.028 ( 0.042)	Data  0.001 ( 0.001)	Loss 7.0123e-01 (5.6895e-01)	Acc@1  82.50 ( 82.16)	Acc@5  95.00 ( 97.82)
## e[46] optimizer.zero_grad (sum) time: 0.2855873107910156
## e[46]       loss.backward (sum) time: 4.159972667694092
## e[46]      optimizer.step (sum) time: 1.839709997177124
## epoch[46] training(only) time: 16.490282773971558
# Switched to evaluate mode...
Test: [  0/100]	Time  0.150 ( 0.150)	Loss 1.3438e+00 (1.3438e+00)	Acc@1  67.00 ( 67.00)	Acc@5  90.00 ( 90.00)
Test: [ 10/100]	Time  0.022 ( 0.034)	Loss 1.2807e+00 (1.4146e+00)	Acc@1  62.00 ( 65.73)	Acc@5  88.00 ( 88.36)
Test: [ 20/100]	Time  0.022 ( 0.028)	Loss 1.1533e+00 (1.3724e+00)	Acc@1  72.00 ( 66.38)	Acc@5  94.00 ( 89.48)
Test: [ 30/100]	Time  0.024 ( 0.026)	Loss 1.5349e+00 (1.3984e+00)	Acc@1  63.00 ( 65.77)	Acc@5  89.00 ( 89.32)
Test: [ 40/100]	Time  0.019 ( 0.025)	Loss 1.3170e+00 (1.4061e+00)	Acc@1  67.00 ( 65.17)	Acc@5  95.00 ( 89.59)
Test: [ 50/100]	Time  0.024 ( 0.024)	Loss 1.4211e+00 (1.4133e+00)	Acc@1  69.00 ( 65.08)	Acc@5  91.00 ( 89.51)
Test: [ 60/100]	Time  0.021 ( 0.024)	Loss 1.5369e+00 (1.3959e+00)	Acc@1  59.00 ( 65.30)	Acc@5  87.00 ( 89.79)
Test: [ 70/100]	Time  0.022 ( 0.024)	Loss 1.5955e+00 (1.3998e+00)	Acc@1  67.00 ( 65.28)	Acc@5  87.00 ( 89.65)
Test: [ 80/100]	Time  0.019 ( 0.024)	Loss 1.5352e+00 (1.4111e+00)	Acc@1  67.00 ( 65.23)	Acc@5  85.00 ( 89.31)
Test: [ 90/100]	Time  0.024 ( 0.023)	Loss 1.7375e+00 (1.3975e+00)	Acc@1  62.00 ( 65.55)	Acc@5  86.00 ( 89.46)
 * Acc@1 65.780 Acc@5 89.620
### epoch[46] execution time: 18.890421628952026
EPOCH 47
REMOVING: module.stem.0.weight
REMOVING: module.stem.0.bias
REMOVING: module.stem.1.weight
i:   0, name:             module.stem.1.bias  changing lr from: 0.001135468291468144   to: 0.001001201933263656
i:   1, name:  module.fire2.squeeze.0.weight  changing lr from: 0.001229811270168156   to: 0.001022056012402144
i:   2, name:    module.fire2.squeeze.0.bias  changing lr from: 0.001347602566317717   to: 0.001068245066369416
i:   3, name:  module.fire2.squeeze.1.weight  changing lr from: 0.001488094274099288   to: 0.001139012112481057
i:   4, name:    module.fire2.squeeze.1.bias  changing lr from: 0.001650548302044229   to: 0.001233607979771744
i:   5, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.001834236862699916   to: 0.001351291946320476
i:   6, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.002038442910672577   to: 0.001491332318062732
i:   7, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.002262460532003957   to: 0.001653006952246948
i:   8, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.002505595287720723   to: 0.001835603728576573
i:   9, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.002767164514277936   to: 0.002038420970963161
i:  10, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.003046497583503026   to: 0.002260767822702092
i:  11, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.003342936124533540   to: 0.002501964577769371
i:  12, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.003655834210132285   to: 0.002761342970827579
i:  13, name:  module.fire3.squeeze.0.weight  changing lr from: 0.003984558509655566   to: 0.003038246428419821
i:  14, name:    module.fire3.squeeze.0.bias  changing lr from: 0.004328488410846192   to: 0.003332030283724584
i:  15, name:  module.fire3.squeeze.1.weight  changing lr from: 0.004687016112520986   to: 0.003642061957139780
i:  16, name:    module.fire3.squeeze.1.bias  changing lr from: 0.005059546690124072   to: 0.003967721104863219
i:  17, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.005445498136021997   to: 0.004308399737537749
i:  18, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.005844301376324045   to: 0.004663502310933481
i:  19, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.006255400265922111   to: 0.005032445790546002
i:  20, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.006678251563358450   to: 0.005414659691899714
i:  21, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.007112324887046383   to: 0.005809586098257535
i:  22, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.007557102654289410   to: 0.006216679657354168
i:  23, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.008012080004467226   to: 0.006635407558688299
i:  24, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.008476764707683498   to: 0.007065249492831021
i:  25, name:  module.fire4.squeeze.0.weight  changing lr from: 0.008950677060098999   to: 0.007505697594131405
i:  26, name:    module.fire4.squeeze.0.bias  changing lr from: 0.009433349767106247   to: 0.007956256368127822
i:  27, name:  module.fire4.squeeze.1.weight  changing lr from: 0.009924327815436312   to: 0.008416442604903540
i:  28, name:    module.fire4.squeeze.1.bias  changing lr from: 0.010423168335226680   to: 0.008885785279557915
i:  29, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.010929440453018534   to: 0.009363825440899785
i:  30, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.011442725136596027   to: 0.009850116089408407
i:  31, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.011962615032524809   to: 0.010344222045447497
i:  32, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.012488714297195676   to: 0.010845719808661846
i:  33, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.013020638422129620   to: 0.011354197409431686
i:  34, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.013558014054253397   to: 0.011869254253207930
i:  35, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.014100478811809813   to: 0.012390500958502720
i:  36, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.014647681096524527   to: 0.012917559189262035
i:  37, name:  module.fire5.squeeze.0.weight  changing lr from: 0.015199279902610070   to: 0.013450061482302555
i:  38, name:    module.fire5.squeeze.0.bias  changing lr from: 0.015754944623149990   to: 0.013987651070452262
i:  39, name:  module.fire5.squeeze.1.weight  changing lr from: 0.016314354854368295   to: 0.014529981701993121
i:  40, name:    module.fire5.squeeze.1.bias  changing lr from: 0.016877200198256233   to: 0.015076717456966437
i:  41, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.017443180063993674   to: 0.015627532560863383
i:  42, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.018012003468572842   to: 0.016182111196189630
i:  43, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.018583388837001415   to: 0.016740147312358677
i:  44, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.019157063802434936   to: 0.017301344434337975
i:  45, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.019732765006561105   to: 0.017865415470441317
i:  46, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.020310237900534746   to: 0.018432082519633370
i:  47, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.020889236546737390   to: 0.019001076678684982
i:  48, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.021469523421614175   to: 0.019572137849492743
i:  49, name:  module.fire6.squeeze.0.weight  changing lr from: 0.022050869219819413   to: 0.020145014546852791
i:  50, name:    module.fire6.squeeze.0.bias  changing lr from: 0.022633052659882094   to: 0.020719463706955456
i:  51, name:  module.fire6.squeeze.1.weight  changing lr from: 0.023215860291584751   to: 0.021295250496846663
i:  52, name:    module.fire6.squeeze.1.bias  changing lr from: 0.023799086305230283   to: 0.021872148125081217
i:  53, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.024382532342957036   to: 0.022449937653775277
i:  54, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.024966007312244139   to: 0.023028407812245733
i:  55, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.025549327201737301   to: 0.023607354812409099
i:  56, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.026132314899509512   to: 0.024186582166095101
i:  57, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.026714800013860021   to: 0.024765900504416946
i:  58, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.027296618696741437   to: 0.025345127399324281
i:  59, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.027877613469895077   to: 0.025924087187453610
i:  60, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.028457633053762879   to: 0.026502610796377203
i:  61, name:  module.fire7.squeeze.0.weight  changing lr from: 0.029036532199235777   to: 0.027080535573340815
i:  62, name:    module.fire7.squeeze.0.bias  changing lr from: 0.029614171522288114   to: 0.027657705116569453
i:  63, name:  module.fire7.squeeze.1.weight  changing lr from: 0.030190417341540012   to: 0.028233969109210111
i:  64, name:    module.fire7.squeeze.1.bias  changing lr from: 0.030765141518781288   to: 0.028809183155971214
i:  65, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.031338221302483350   to: 0.029383208622509739
i:  66, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.031909539174318664   to: 0.029955912477608423
i:  67, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.032478982698701073   to: 0.030527167138178157
i:  68, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.033046444375354173   to: 0.031096850317113147
i:  69, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.033611821494910037   to: 0.031664844874020305
i:  70, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.034175015997534974   to: 0.032231038668837600
i:  71, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.034735934334575079   to: 0.032795324418350959
i:  72, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.035294487333209341   to: 0.033357599555613432
i:  73, name:  module.fire8.squeeze.0.weight  changing lr from: 0.035850590064094884   to: 0.033917766092266058
i:  74, name:    module.fire8.squeeze.0.bias  changing lr from: 0.036404161711984996   to: 0.034475730483754831
i:  75, name:  module.fire8.squeeze.1.weight  changing lr from: 0.036955125449297389   to: 0.035031403497434499
i:  76, name:    module.fire8.squeeze.1.bias  changing lr from: 0.037503408312607379   to: 0.035584700083545841
i:  77, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.038048941082037449   to: 0.036135539249049185
i:  78, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.038591658163513336   to: 0.036683843934295128
i:  79, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.039131497473852944   to: 0.037229540892508343
i:  80, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.039668400328654312   to: 0.037772560572060042
i:  81, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.040202311332945224   to: 0.038312837001500066
i:  82, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.040733178274557316   to: 0.038850307677319486
i:  83, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.041260952020184455   to: 0.039384913454410579
i:  84, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.041785586414085342   to: 0.039916598439191202
i:  85, name:  module.fire9.squeeze.0.weight  changing lr from: 0.042307038179388440   to: 0.040445309885357501
i:  86, name:    module.fire9.squeeze.0.bias  changing lr from: 0.042825266821956566   to: 0.040970998092228351
i:  87, name:  module.fire9.squeeze.1.weight  changing lr from: 0.043340234536768045   to: 0.041493616305643632
i:  88, name:    module.fire9.squeeze.1.bias  changing lr from: 0.043851906116770298   to: 0.042013120621376951
i:  89, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.044360248864161622   to: 0.042529469891022936
i:  90, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.044865232504055941   to: 0.043042625630318236
i:  91, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.045366829100485784   to: 0.043552551929854841
i:  92, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.045865012974697923   to: 0.044059215368143501
i:  93, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.046359760625696245   to: 0.044562584926984998
i:  94, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.046851050652986524   to: 0.045062631909106449
i:  95, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.047338863681477238   to: 0.045559329858019387
i:  96, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.047823182288491806   to: 0.046052654480056826
i:  97, name:           module.conv10.weight  changing lr from: 0.048303990932846451   to: 0.046542583568545737
i:  98, name:             module.conv10.bias  changing lr from: 0.048781275885949139   to: 0.047029096930071894



# Switched to train mode...
Epoch: [47][  0/391]	Time  0.197 ( 0.197)	Data  0.149 ( 0.149)	Loss 7.0459e-01 (7.0459e-01)	Acc@1  78.12 ( 78.12)	Acc@5  97.66 ( 97.66)
Epoch: [47][ 10/391]	Time  0.040 ( 0.056)	Data  0.001 ( 0.014)	Loss 5.5679e-01 (5.4855e-01)	Acc@1  83.59 ( 82.46)	Acc@5  98.44 ( 97.87)
Epoch: [47][ 20/391]	Time  0.041 ( 0.049)	Data  0.001 ( 0.008)	Loss 6.1980e-01 (5.3745e-01)	Acc@1  80.47 ( 83.04)	Acc@5  98.44 ( 98.14)
Epoch: [47][ 30/391]	Time  0.040 ( 0.046)	Data  0.001 ( 0.006)	Loss 5.8032e-01 (5.2049e-01)	Acc@1  84.38 ( 83.47)	Acc@5  96.88 ( 98.24)
Epoch: [47][ 40/391]	Time  0.038 ( 0.044)	Data  0.001 ( 0.005)	Loss 4.7784e-01 (5.0326e-01)	Acc@1  88.28 ( 84.43)	Acc@5  98.44 ( 98.36)
Epoch: [47][ 50/391]	Time  0.038 ( 0.043)	Data  0.001 ( 0.004)	Loss 3.8554e-01 (4.9260e-01)	Acc@1  89.84 ( 84.73)	Acc@5  99.22 ( 98.38)
Epoch: [47][ 60/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.003)	Loss 5.0586e-01 (4.9248e-01)	Acc@1  86.72 ( 84.76)	Acc@5  98.44 ( 98.42)
Epoch: [47][ 70/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.003)	Loss 4.9411e-01 (4.9320e-01)	Acc@1  85.16 ( 84.64)	Acc@5  98.44 ( 98.40)
Epoch: [47][ 80/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.003)	Loss 5.9800e-01 (4.9759e-01)	Acc@1  80.47 ( 84.48)	Acc@5  98.44 ( 98.39)
Epoch: [47][ 90/391]	Time  0.046 ( 0.043)	Data  0.001 ( 0.003)	Loss 5.1554e-01 (5.0346e-01)	Acc@1  85.94 ( 84.34)	Acc@5  96.88 ( 98.33)
Epoch: [47][100/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.9452e-01 (5.0656e-01)	Acc@1  81.25 ( 84.16)	Acc@5  96.88 ( 98.33)
Epoch: [47][110/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.9590e-01 (5.0824e-01)	Acc@1  82.81 ( 84.13)	Acc@5  96.88 ( 98.29)
Epoch: [47][120/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 4.5643e-01 (5.0774e-01)	Acc@1  85.94 ( 84.17)	Acc@5  99.22 ( 98.28)
Epoch: [47][130/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.0096e-01 (5.1098e-01)	Acc@1  85.16 ( 84.12)	Acc@5  96.88 ( 98.23)
Epoch: [47][140/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.9132e-01 (5.1467e-01)	Acc@1  82.81 ( 84.10)	Acc@5  97.66 ( 98.19)
Epoch: [47][150/391]	Time  0.052 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.2539e-01 (5.1748e-01)	Acc@1  85.16 ( 83.98)	Acc@5  96.88 ( 98.18)
Epoch: [47][160/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.6896e-01 (5.1709e-01)	Acc@1  82.81 ( 83.93)	Acc@5  97.66 ( 98.19)
Epoch: [47][170/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 3.8016e-01 (5.2079e-01)	Acc@1  86.72 ( 83.90)	Acc@5 100.00 ( 98.11)
Epoch: [47][180/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.4891e-01 (5.2286e-01)	Acc@1  82.03 ( 83.84)	Acc@5  97.66 ( 98.11)
Epoch: [47][190/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.3476e-01 (5.2607e-01)	Acc@1  85.94 ( 83.76)	Acc@5  97.66 ( 98.09)
Epoch: [47][200/391]	Time  0.044 ( 0.042)	Data  0.002 ( 0.002)	Loss 5.5455e-01 (5.2965e-01)	Acc@1  79.69 ( 83.61)	Acc@5  99.22 ( 98.10)
Epoch: [47][210/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 4.6223e-01 (5.2900e-01)	Acc@1  86.72 ( 83.62)	Acc@5  97.66 ( 98.10)
Epoch: [47][220/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 7.9623e-01 (5.2912e-01)	Acc@1  73.44 ( 83.57)	Acc@5  94.53 ( 98.12)
Epoch: [47][230/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.3672e-01 (5.3270e-01)	Acc@1  82.81 ( 83.44)	Acc@5  96.88 ( 98.09)
Epoch: [47][240/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 4.4455e-01 (5.3461e-01)	Acc@1  85.94 ( 83.38)	Acc@5 100.00 ( 98.05)
Epoch: [47][250/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 4.9414e-01 (5.3596e-01)	Acc@1  82.03 ( 83.34)	Acc@5 100.00 ( 98.05)
Epoch: [47][260/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.5834e-01 (5.3670e-01)	Acc@1  82.03 ( 83.30)	Acc@5  96.88 ( 98.03)
Epoch: [47][270/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.002)	Loss 3.7439e-01 (5.3780e-01)	Acc@1  89.06 ( 83.27)	Acc@5 100.00 ( 98.03)
Epoch: [47][280/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 4.6759e-01 (5.3808e-01)	Acc@1  84.38 ( 83.26)	Acc@5  98.44 ( 98.03)
Epoch: [47][290/391]	Time  0.036 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.1646e-01 (5.3804e-01)	Acc@1  86.72 ( 83.21)	Acc@5  99.22 ( 98.04)
Epoch: [47][300/391]	Time  0.043 ( 0.041)	Data  0.001 ( 0.002)	Loss 6.1836e-01 (5.3919e-01)	Acc@1  77.34 ( 83.16)	Acc@5  96.88 ( 98.01)
Epoch: [47][310/391]	Time  0.040 ( 0.041)	Data  0.002 ( 0.002)	Loss 6.4240e-01 (5.4004e-01)	Acc@1  78.12 ( 83.13)	Acc@5  97.66 ( 98.00)
Epoch: [47][320/391]	Time  0.045 ( 0.041)	Data  0.002 ( 0.002)	Loss 7.0081e-01 (5.4104e-01)	Acc@1  79.69 ( 83.08)	Acc@5  95.31 ( 97.98)
Epoch: [47][330/391]	Time  0.037 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.8716e-01 (5.4140e-01)	Acc@1  83.59 ( 83.07)	Acc@5  98.44 ( 97.98)
Epoch: [47][340/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.001)	Loss 4.5037e-01 (5.4282e-01)	Acc@1  85.94 ( 83.01)	Acc@5  98.44 ( 97.96)
Epoch: [47][350/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.001)	Loss 7.2625e-01 (5.4389e-01)	Acc@1  75.78 ( 82.95)	Acc@5  97.66 ( 97.98)
Epoch: [47][360/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.001)	Loss 5.9174e-01 (5.4497e-01)	Acc@1  83.59 ( 82.90)	Acc@5  97.66 ( 97.96)
Epoch: [47][370/391]	Time  0.037 ( 0.041)	Data  0.001 ( 0.001)	Loss 5.6081e-01 (5.4551e-01)	Acc@1  86.72 ( 82.91)	Acc@5  98.44 ( 97.96)
Epoch: [47][380/391]	Time  0.052 ( 0.041)	Data  0.001 ( 0.001)	Loss 5.1207e-01 (5.4609e-01)	Acc@1  83.59 ( 82.88)	Acc@5  98.44 ( 97.96)
Epoch: [47][390/391]	Time  0.029 ( 0.041)	Data  0.001 ( 0.001)	Loss 6.5782e-01 (5.4804e-01)	Acc@1  76.25 ( 82.81)	Acc@5 100.00 ( 97.94)
## e[47] optimizer.zero_grad (sum) time: 0.27779436111450195
## e[47]       loss.backward (sum) time: 4.011662006378174
## e[47]      optimizer.step (sum) time: 1.8768177032470703
## epoch[47] training(only) time: 16.159688234329224
# Switched to evaluate mode...
Test: [  0/100]	Time  0.154 ( 0.154)	Loss 1.4030e+00 (1.4030e+00)	Acc@1  67.00 ( 67.00)	Acc@5  86.00 ( 86.00)
Test: [ 10/100]	Time  0.021 ( 0.034)	Loss 1.4203e+00 (1.4970e+00)	Acc@1  59.00 ( 65.09)	Acc@5  92.00 ( 87.82)
Test: [ 20/100]	Time  0.019 ( 0.028)	Loss 1.3343e+00 (1.4331e+00)	Acc@1  71.00 ( 65.57)	Acc@5  92.00 ( 88.90)
Test: [ 30/100]	Time  0.019 ( 0.026)	Loss 1.5683e+00 (1.4426e+00)	Acc@1  55.00 ( 64.97)	Acc@5  91.00 ( 88.77)
Test: [ 40/100]	Time  0.024 ( 0.025)	Loss 1.3090e+00 (1.4251e+00)	Acc@1  64.00 ( 65.20)	Acc@5  91.00 ( 89.05)
Test: [ 50/100]	Time  0.024 ( 0.025)	Loss 1.4408e+00 (1.4215e+00)	Acc@1  66.00 ( 65.20)	Acc@5  90.00 ( 89.10)
Test: [ 60/100]	Time  0.024 ( 0.024)	Loss 1.4377e+00 (1.4039e+00)	Acc@1  60.00 ( 65.10)	Acc@5  88.00 ( 89.41)
Test: [ 70/100]	Time  0.021 ( 0.024)	Loss 1.3952e+00 (1.3906e+00)	Acc@1  65.00 ( 65.51)	Acc@5  90.00 ( 89.39)
Test: [ 80/100]	Time  0.019 ( 0.024)	Loss 1.4183e+00 (1.4029e+00)	Acc@1  66.00 ( 65.36)	Acc@5  88.00 ( 89.14)
Test: [ 90/100]	Time  0.023 ( 0.024)	Loss 1.6667e+00 (1.3962e+00)	Acc@1  61.00 ( 65.53)	Acc@5  86.00 ( 89.31)
 * Acc@1 65.760 Acc@5 89.330
### epoch[47] execution time: 18.557814359664917
EPOCH 48
REMOVING: module.stem.1.bias
REMOVING: module.fire2.squeeze.0.weight
REMOVING: module.fire2.squeeze.0.bias
i:   0, name:  module.fire2.squeeze.1.weight  changing lr from: 0.001139012112481057   to: 0.001002176431456941
i:   1, name:    module.fire2.squeeze.1.bias  changing lr from: 0.001233607979771744   to: 0.001025468120044503
i:   2, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.001351291946320476   to: 0.001073668339882954
i:   3, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.001491332318062732   to: 0.001146036570688618
i:   4, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.001653006952246948   to: 0.001241839946507955
i:   5, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.001835603728576573   to: 0.001360353866001034
i:   6, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.002038420970963161   to: 0.001500862546882830
i:   7, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.002260767822702092   to: 0.001662659527519843
i:   8, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.002501964577769371   to: 0.001845048118569031
i:   9, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.002761342970827579   to: 0.002047341807437380
i:  10, name:  module.fire3.squeeze.0.weight  changing lr from: 0.003038246428419821   to: 0.002268864618232113
i:  11, name:    module.fire3.squeeze.0.bias  changing lr from: 0.003332030283724584   to: 0.002508951429765465
i:  12, name:  module.fire3.squeeze.1.weight  changing lr from: 0.003642061957139780   to: 0.002766948254072892
i:  13, name:    module.fire3.squeeze.1.bias  changing lr from: 0.003967721104863219   to: 0.003042212477801209
i:  14, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.004308399737537749   to: 0.003334113068722127
i:  15, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.004663502310933481   to: 0.003642030749528923
i:  16, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.005032445790546002   to: 0.003965358140977437
i:  17, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.005414659691899714   to: 0.004303499876339916
i:  18, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.005809586098257535   to: 0.004655872689048850
i:  19, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.006216679657354168   to: 0.005021905475320331
i:  20, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.006635407558688299   to: 0.005401039333460794
i:  21, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.007065249492831021   to: 0.005792727581478695
i:  22, name:  module.fire4.squeeze.0.weight  changing lr from: 0.007505697594131405   to: 0.006196435754542345
i:  23, name:    module.fire4.squeeze.0.bias  changing lr from: 0.007956256368127822   to: 0.006611641583748290
i:  24, name:  module.fire4.squeeze.1.weight  changing lr from: 0.008416442604903540   to: 0.007037834957590294
i:  25, name:    module.fire4.squeeze.1.bias  changing lr from: 0.008885785279557915   to: 0.007474517867447122
i:  26, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.009363825440899785   to: 0.007921204338338372
i:  27, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.009850116089408407   to: 0.008377420346131492
i:  28, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.010344222045447497   to: 0.008842703722319094
i:  29, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.010845719808661846   to: 0.009316604047424935
i:  30, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.011354197409431686   to: 0.009798682534038001
i:  31, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.011869254253207930   to: 0.010288511900418257
i:  32, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.012390500958502720   to: 0.010785676235563497
i:  33, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.012917559189262035   to: 0.011289770856575974
i:  34, name:  module.fire5.squeeze.0.weight  changing lr from: 0.013450061482302555   to: 0.011800402159117689
i:  35, name:    module.fire5.squeeze.0.bias  changing lr from: 0.013987651070452262   to: 0.012317187461696667
i:  36, name:  module.fire5.squeeze.1.weight  changing lr from: 0.014529981701993121   to: 0.012839754844481816
i:  37, name:    module.fire5.squeeze.1.bias  changing lr from: 0.015076717456966437   to: 0.013367742983301185
i:  38, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.015627532560863383   to: 0.013900800979437623
i:  39, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.016182111196189630   to: 0.014438588185797498
i:  40, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.016740147312358677   to: 0.014980774029990714
i:  41, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.017301344434337975   to: 0.015527037834826136
i:  42, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.017865415470441317   to: 0.016077068636691783
i:  43, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.018432082519633370   to: 0.016630565002259234
i:  44, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.019001076678684982   to: 0.017187234843920259
i:  45, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.019572137849492743   to: 0.017746795234335932
i:  46, name:  module.fire6.squeeze.0.weight  changing lr from: 0.020145014546852791   to: 0.018308972220451480
i:  47, name:    module.fire6.squeeze.0.bias  changing lr from: 0.020719463706955456   to: 0.018873500637304131
i:  48, name:  module.fire6.squeeze.1.weight  changing lr from: 0.021295250496846663   to: 0.019440123921927798
i:  49, name:    module.fire6.squeeze.1.bias  changing lr from: 0.021872148125081217   to: 0.020008593927634318
i:  50, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.022449937653775277   to: 0.020578670738930990
i:  51, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.023028407812245733   to: 0.021150122487312007
i:  52, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.023607354812409099   to: 0.021722725168143511
i:  53, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.024186582166095101   to: 0.022296262458842600
i:  54, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.024765900504416946   to: 0.022870525538534598
i:  55, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.025345127399324281   to: 0.023445312909355649
i:  56, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.025924087187453610   to: 0.024020430219553270
i:  57, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.026502610796377203   to: 0.024595690088522693
i:  58, name:  module.fire7.squeeze.0.weight  changing lr from: 0.027080535573340815   to: 0.025170911933903840
i:  59, name:    module.fire7.squeeze.0.bias  changing lr from: 0.027657705116569453   to: 0.025745921800850453
i:  60, name:  module.fire7.squeeze.1.weight  changing lr from: 0.028233969109210111   to: 0.026320552193571791
i:  61, name:    module.fire7.squeeze.1.bias  changing lr from: 0.028809183155971214   to: 0.026894641909235451
i:  62, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.029383208622509739   to: 0.027468035874310209
i:  63, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.029955912477608423   to: 0.028040584983417150
i:  64, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.030527167138178157   to: 0.028612145940749147
i:  65, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.031096850317113147   to: 0.029182581104109262
i:  66, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.031664844874020305   to: 0.029751758331611724
i:  67, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.032231038668837600   to: 0.030319550831080580
i:  68, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.032795324418350959   to: 0.030885837012175257
i:  69, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.033357599555613432   to: 0.031450500341265106
i:  70, name:  module.fire8.squeeze.0.weight  changing lr from: 0.033917766092266058   to: 0.032013429199069389
i:  71, name:    module.fire8.squeeze.0.bias  changing lr from: 0.034475730483754831   to: 0.032574516741073360
i:  72, name:  module.fire8.squeeze.1.weight  changing lr from: 0.035031403497434499   to: 0.033133660760726373
i:  73, name:    module.fire8.squeeze.1.bias  changing lr from: 0.035584700083545841   to: 0.033690763555422769
i:  74, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.036135539249049185   to: 0.034245731795261893
i:  75, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.036683843934295128   to: 0.034798476394580218
i:  76, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.037229540892508343   to: 0.035348912386243735
i:  77, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.037772560572060042   to: 0.035896958798686429
i:  78, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.038312837001500066   to: 0.036442538535676576
i:  79, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.038850307677319486   to: 0.036985578258790723
i:  80, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.039384913454410579   to: 0.037526008272571527
i:  81, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.039916598439191202   to: 0.038063762412344070
i:  82, name:  module.fire9.squeeze.0.weight  changing lr from: 0.040445309885357501   to: 0.038598777934662987
i:  83, name:    module.fire9.squeeze.0.bias  changing lr from: 0.040970998092228351   to: 0.039130995410360137
i:  84, name:  module.fire9.squeeze.1.weight  changing lr from: 0.041493616305643632   to: 0.039660358620161859
i:  85, name:    module.fire9.squeeze.1.bias  changing lr from: 0.042013120621376951   to: 0.040186814452842418
i:  86, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.042529469891022936   to: 0.040710312805879334
i:  87, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.043042625630318236   to: 0.041230806488574696
i:  88, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.043552551929854841   to: 0.041748251127606072
i:  89, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.044059215368143501   to: 0.042262605074968866
i:  90, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.044562584926984998   to: 0.042773829318272012
i:  91, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.045062631909106449   to: 0.043281887393347679
i:  92, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.045559329858019387   to: 0.043786745299134969
i:  93, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.046052654480056826   to: 0.044288371414797856
i:  94, name:           module.conv10.weight  changing lr from: 0.046542583568545737   to: 0.044786736419036501
i:  95, name:             module.conv10.bias  changing lr from: 0.047029096930071894   to: 0.045281813211551100



# Switched to train mode...
Epoch: [48][  0/391]	Time  0.190 ( 0.190)	Data  0.146 ( 0.146)	Loss 5.1967e-01 (5.1967e-01)	Acc@1  82.03 ( 82.03)	Acc@5  99.22 ( 99.22)
Epoch: [48][ 10/391]	Time  0.038 ( 0.054)	Data  0.001 ( 0.014)	Loss 5.5821e-01 (5.1689e-01)	Acc@1  83.59 ( 84.59)	Acc@5  96.88 ( 97.94)
Epoch: [48][ 20/391]	Time  0.037 ( 0.047)	Data  0.001 ( 0.008)	Loss 5.5180e-01 (4.8262e-01)	Acc@1  83.59 ( 85.57)	Acc@5  96.88 ( 98.29)
Epoch: [48][ 30/391]	Time  0.039 ( 0.045)	Data  0.001 ( 0.006)	Loss 4.1068e-01 (4.8363e-01)	Acc@1  87.50 ( 85.41)	Acc@5  99.22 ( 98.29)
Epoch: [48][ 40/391]	Time  0.039 ( 0.044)	Data  0.001 ( 0.005)	Loss 5.5263e-01 (4.8854e-01)	Acc@1  82.03 ( 85.12)	Acc@5  99.22 ( 98.30)
Epoch: [48][ 50/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.004)	Loss 5.1469e-01 (4.9509e-01)	Acc@1  86.72 ( 84.83)	Acc@5  97.66 ( 98.19)
Epoch: [48][ 60/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.003)	Loss 6.1421e-01 (5.0621e-01)	Acc@1  82.81 ( 84.25)	Acc@5  96.09 ( 98.16)
Epoch: [48][ 70/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.003)	Loss 5.6181e-01 (5.0963e-01)	Acc@1  83.59 ( 84.04)	Acc@5  96.88 ( 98.20)
Epoch: [48][ 80/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.003)	Loss 3.5820e-01 (5.0826e-01)	Acc@1  89.06 ( 83.98)	Acc@5  99.22 ( 98.18)
Epoch: [48][ 90/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.003)	Loss 5.0280e-01 (5.0975e-01)	Acc@1  83.59 ( 83.93)	Acc@5  97.66 ( 98.19)
Epoch: [48][100/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.003)	Loss 5.1034e-01 (5.0763e-01)	Acc@1  85.16 ( 83.97)	Acc@5  99.22 ( 98.21)
Epoch: [48][110/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.2189e-01 (5.0815e-01)	Acc@1  87.50 ( 83.99)	Acc@5  96.88 ( 98.21)
Epoch: [48][120/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.3437e-01 (5.1029e-01)	Acc@1  81.25 ( 83.86)	Acc@5  98.44 ( 98.22)
Epoch: [48][130/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.1570e-01 (5.0982e-01)	Acc@1  84.38 ( 83.81)	Acc@5  97.66 ( 98.23)
Epoch: [48][140/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 4.5848e-01 (5.0987e-01)	Acc@1  85.16 ( 83.86)	Acc@5  99.22 ( 98.21)
Epoch: [48][150/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.8779e-01 (5.1002e-01)	Acc@1  89.06 ( 83.88)	Acc@5  97.66 ( 98.17)
Epoch: [48][160/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.0414e-01 (5.0643e-01)	Acc@1  82.81 ( 84.08)	Acc@5  99.22 ( 98.20)
Epoch: [48][170/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.2894e-01 (5.0593e-01)	Acc@1  89.06 ( 84.06)	Acc@5  99.22 ( 98.21)
Epoch: [48][180/391]	Time  0.051 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.5183e-01 (5.0729e-01)	Acc@1  84.38 ( 83.99)	Acc@5  98.44 ( 98.21)
Epoch: [48][190/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.5820e-01 (5.0925e-01)	Acc@1  78.12 ( 83.95)	Acc@5  99.22 ( 98.20)
Epoch: [48][200/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.9031e-01 (5.0964e-01)	Acc@1  85.94 ( 83.93)	Acc@5 100.00 ( 98.18)
Epoch: [48][210/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.8952e-01 (5.1215e-01)	Acc@1  82.03 ( 83.80)	Acc@5  97.66 ( 98.18)
Epoch: [48][220/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.6989e-01 (5.1483e-01)	Acc@1  81.25 ( 83.73)	Acc@5  98.44 ( 98.17)
Epoch: [48][230/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 7.2618e-01 (5.1488e-01)	Acc@1  75.78 ( 83.71)	Acc@5  96.09 ( 98.16)
Epoch: [48][240/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.7353e-01 (5.1538e-01)	Acc@1  82.81 ( 83.68)	Acc@5  98.44 ( 98.16)
Epoch: [48][250/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.9680e-01 (5.1568e-01)	Acc@1  86.72 ( 83.73)	Acc@5  96.88 ( 98.13)
Epoch: [48][260/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.8904e-01 (5.1488e-01)	Acc@1  83.59 ( 83.75)	Acc@5  97.66 ( 98.14)
Epoch: [48][270/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.5624e-01 (5.1530e-01)	Acc@1  80.47 ( 83.74)	Acc@5  96.88 ( 98.14)
Epoch: [48][280/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.1301e-01 (5.1499e-01)	Acc@1  83.59 ( 83.73)	Acc@5  98.44 ( 98.14)
Epoch: [48][290/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.9947e-01 (5.1616e-01)	Acc@1  86.72 ( 83.72)	Acc@5  98.44 ( 98.13)
Epoch: [48][300/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.8151e-01 (5.1748e-01)	Acc@1  82.03 ( 83.68)	Acc@5  97.66 ( 98.13)
Epoch: [48][310/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.0870e-01 (5.1741e-01)	Acc@1  85.16 ( 83.69)	Acc@5  98.44 ( 98.12)
Epoch: [48][320/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.4796e-01 (5.1672e-01)	Acc@1  82.81 ( 83.70)	Acc@5  96.09 ( 98.11)
Epoch: [48][330/391]	Time  0.043 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.8010e-01 (5.1922e-01)	Acc@1  84.38 ( 83.61)	Acc@5  98.44 ( 98.09)
Epoch: [48][340/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.001)	Loss 6.3325e-01 (5.2073e-01)	Acc@1  78.91 ( 83.54)	Acc@5  99.22 ( 98.10)
Epoch: [48][350/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.001)	Loss 6.2934e-01 (5.2088e-01)	Acc@1  78.91 ( 83.54)	Acc@5  96.88 ( 98.11)
Epoch: [48][360/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.001)	Loss 5.6615e-01 (5.2189e-01)	Acc@1  81.25 ( 83.51)	Acc@5  97.66 ( 98.11)
Epoch: [48][370/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.001)	Loss 4.7017e-01 (5.2246e-01)	Acc@1  83.59 ( 83.49)	Acc@5  98.44 ( 98.10)
Epoch: [48][380/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.001)	Loss 3.7811e-01 (5.2201e-01)	Acc@1  87.50 ( 83.54)	Acc@5  98.44 ( 98.08)
Epoch: [48][390/391]	Time  0.028 ( 0.041)	Data  0.001 ( 0.001)	Loss 6.5386e-01 (5.2238e-01)	Acc@1  78.75 ( 83.54)	Acc@5  97.50 ( 98.07)
## e[48] optimizer.zero_grad (sum) time: 0.26840662956237793
## e[48]       loss.backward (sum) time: 3.9348390102386475
## e[48]      optimizer.step (sum) time: 1.7660088539123535
## epoch[48] training(only) time: 16.108102083206177
# Switched to evaluate mode...
Test: [  0/100]	Time  0.157 ( 0.157)	Loss 1.1351e+00 (1.1351e+00)	Acc@1  71.00 ( 71.00)	Acc@5  90.00 ( 90.00)
Test: [ 10/100]	Time  0.022 ( 0.034)	Loss 1.4014e+00 (1.4101e+00)	Acc@1  65.00 ( 66.09)	Acc@5  90.00 ( 89.73)
Test: [ 20/100]	Time  0.024 ( 0.029)	Loss 1.2274e+00 (1.3688e+00)	Acc@1  70.00 ( 66.48)	Acc@5  91.00 ( 90.14)
Test: [ 30/100]	Time  0.024 ( 0.027)	Loss 1.5978e+00 (1.4005e+00)	Acc@1  64.00 ( 65.71)	Acc@5  86.00 ( 89.55)
Test: [ 40/100]	Time  0.024 ( 0.026)	Loss 1.5062e+00 (1.4039e+00)	Acc@1  62.00 ( 65.71)	Acc@5  89.00 ( 89.49)
Test: [ 50/100]	Time  0.022 ( 0.025)	Loss 1.4111e+00 (1.4120e+00)	Acc@1  67.00 ( 65.37)	Acc@5  90.00 ( 89.37)
Test: [ 60/100]	Time  0.024 ( 0.025)	Loss 1.8137e+00 (1.4005e+00)	Acc@1  58.00 ( 65.66)	Acc@5  86.00 ( 89.51)
Test: [ 70/100]	Time  0.018 ( 0.024)	Loss 1.5251e+00 (1.4008e+00)	Acc@1  66.00 ( 65.76)	Acc@5  86.00 ( 89.48)
Test: [ 80/100]	Time  0.024 ( 0.024)	Loss 1.4399e+00 (1.4108e+00)	Acc@1  66.00 ( 65.75)	Acc@5  88.00 ( 89.37)
Test: [ 90/100]	Time  0.022 ( 0.024)	Loss 1.6929e+00 (1.4010e+00)	Acc@1  62.00 ( 65.87)	Acc@5  85.00 ( 89.37)
 * Acc@1 66.080 Acc@5 89.480
### epoch[48] execution time: 18.55903720855713
EPOCH 49
REMOVING: module.fire2.squeeze.1.weight
REMOVING: module.fire2.squeeze.1.bias
REMOVING: module.fire2.expand_1x1.0.weight
i:   0, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.001146036570688618   to: 0.001003963216179354
i:   1, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.001241839946507955   to: 0.001030611670103475
i:   2, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.001360353866001034   to: 0.001081728179421303
i:   3, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.001500862546882830   to: 0.001156588299572280
i:   4, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.001662659527519843   to: 0.001254475113278130
i:   5, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.001845048118569031   to: 0.001374679813205553
i:   6, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.002047341807437380   to: 0.001516502231403337
i:   7, name:  module.fire3.squeeze.0.weight  changing lr from: 0.002268864618232113   to: 0.001679251318357660
i:   8, name:    module.fire3.squeeze.0.bias  changing lr from: 0.002508951429765465   to: 0.001862245574405501
i:   9, name:  module.fire3.squeeze.1.weight  changing lr from: 0.002766948254072892   to: 0.002064813436142726
i:  10, name:    module.fire3.squeeze.1.bias  changing lr from: 0.003042212477801209   to: 0.002286293620361501
i:  11, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.003334113068722127   to: 0.002526035427951078
i:  12, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.003642030749528923   to: 0.002783399010096986
i:  13, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.003965358140977437   to: 0.003057755599016631
i:  14, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.004303499876339916   to: 0.003348487705374308
i:  15, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.004655872689048850   to: 0.003654989284425691
i:  16, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.005021905475320331   to: 0.003976665872851065
i:  17, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.005401039333460794   to: 0.004312934698148817
i:  18, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.005792727581478695   to: 0.004663224762374429
i:  19, name:  module.fire4.squeeze.0.weight  changing lr from: 0.006196435754542345   to: 0.005026976901927277
i:  20, name:    module.fire4.squeeze.0.bias  changing lr from: 0.006611641583748290   to: 0.005403643825006576
i:  21, name:  module.fire4.squeeze.1.weight  changing lr from: 0.007037834957590294   to: 0.005792690128279914
i:  22, name:    module.fire4.squeeze.1.bias  changing lr from: 0.007474517867447122   to: 0.006193592294232163
i:  23, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.007921204338338372   to: 0.006605838670589464
i:  24, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.008377420346131492   to: 0.007028929433142694
i:  25, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.008842703722319094   to: 0.007462376533227188
i:  26, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.009316604047424935   to: 0.007905703631049692
i:  27, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.009798682534038001   to: 0.008358446015991349
i:  28, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.010288511900418257   to: 0.008820150514954567
i:  29, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.010785676235563497   to: 0.009290375389764231
i:  30, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.011289770856575974   to: 0.009768690224577770
i:  31, name:  module.fire5.squeeze.0.weight  changing lr from: 0.011800402159117689   to: 0.010254675804205683
i:  32, name:    module.fire5.squeeze.0.bias  changing lr from: 0.012317187461696667   to: 0.010747923984192866
i:  33, name:  module.fire5.squeeze.1.weight  changing lr from: 0.012839754844481816   to: 0.011248037553462393
i:  34, name:    module.fire5.squeeze.1.bias  changing lr from: 0.013367742983301185   to: 0.011754630090277229
i:  35, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.013900800979437623   to: 0.012267325812229730
i:  36, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.014438588185797498   to: 0.012785759420927717
i:  37, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.014980774029990714   to: 0.013309575942003927
i:  38, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.015527037834826136   to: 0.013838430561038294
i:  39, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.016077068636691783   to: 0.014371988455944361
i:  40, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.016630565002259234   to: 0.014909924626337313
i:  41, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.017187234843920259   to: 0.015451923720366800
i:  42, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.017746795234335932   to: 0.015997679859466624
i:  43, name:  module.fire6.squeeze.0.weight  changing lr from: 0.018308972220451480   to: 0.016546896461442872
i:  44, name:    module.fire6.squeeze.0.bias  changing lr from: 0.018873500637304131   to: 0.017099286062293727
i:  45, name:  module.fire6.squeeze.1.weight  changing lr from: 0.019440123921927798   to: 0.017654570137126825
i:  46, name:    module.fire6.squeeze.1.bias  changing lr from: 0.020008593927634318   to: 0.018212478920514318
i:  47, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.020578670738930990   to: 0.018772751226601738
i:  48, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.021150122487312007   to: 0.019335134269263050
i:  49, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.021722725168143511   to: 0.019899383482573203
i:  50, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.022296262458842600   to: 0.020465262341847670
i:  51, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.022870525538534598   to: 0.021032542185480681
i:  52, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.023445312909355649   to: 0.021601002037793235
i:  53, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.024020430219553270   to: 0.022170428433086295
i:  54, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.024595690088522693   to: 0.022740615241077490
i:  55, name:  module.fire7.squeeze.0.weight  changing lr from: 0.025170911933903840   to: 0.023311363493883776
i:  56, name:    module.fire7.squeeze.0.bias  changing lr from: 0.025745921800850453   to: 0.023882481214698784
i:  57, name:  module.fire7.squeeze.1.weight  changing lr from: 0.026320552193571791   to: 0.024453783248298874
i:  58, name:    module.fire7.squeeze.1.bias  changing lr from: 0.026894641909235451   to: 0.025025091093499843
i:  59, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.027468035874310209   to: 0.025596232737673558
i:  60, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.028040584983417150   to: 0.026167042493422478
i:  61, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.028612145940749147   to: 0.026737360837499582
i:  62, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.029182581104109262   to: 0.027307034252050767
i:  63, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.029751758331611724   to: 0.027875915068247784
i:  64, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.030319550831080580   to: 0.028443861312370658
i:  65, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.030885837012175257   to: 0.029010736554390706
i:  66, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.031450500341265106   to: 0.029576409759096867
i:  67, name:  module.fire8.squeeze.0.weight  changing lr from: 0.032013429199069389   to: 0.030140755139801956
i:  68, name:    module.fire8.squeeze.0.bias  changing lr from: 0.032574516741073360   to: 0.030703652014657603
i:  69, name:  module.fire8.squeeze.1.weight  changing lr from: 0.033133660760726373   to: 0.031264984665601306
i:  70, name:    module.fire8.squeeze.1.bias  changing lr from: 0.033690763555422769   to: 0.031824642199952957
i:  71, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.034245731795261893   to: 0.032382518414672400
i:  72, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.034798476394580218   to: 0.032938511663285507
i:  73, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.035348912386243735   to: 0.033492524725480602
i:  74, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.035896958798686429   to: 0.034044464679373741
i:  75, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.036442538535676576   to: 0.034594242776436517
i:  76, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.036985578258790723   to: 0.035141774319077348
i:  77, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.037526008272571527   to: 0.035686978540863133
i:  78, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.038063762412344070   to: 0.036229778489365309
i:  79, name:  module.fire9.squeeze.0.weight  changing lr from: 0.038598777934662987   to: 0.036770100911611939
i:  80, name:    module.fire9.squeeze.0.bias  changing lr from: 0.039130995410360137   to: 0.037307876142124025
i:  81, name:  module.fire9.squeeze.1.weight  changing lr from: 0.039660358620161859   to: 0.037843037993513087
i:  82, name:    module.fire9.squeeze.1.bias  changing lr from: 0.040186814452842418   to: 0.038375523649613552
i:  83, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.040710312805879334   to: 0.038905273561123062
i:  84, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.041230806488574696   to: 0.039432231343720620
i:  85, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.041748251127606072   to: 0.039956343678632246
i:  86, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.042262605074968866   to: 0.040477560215611393
i:  87, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.042773829318272012   to: 0.040995833478300908
i:  88, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.043281887393347679   to: 0.041511118771941857
i:  89, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.043786745299134969   to: 0.042023374093393379
i:  90, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.044288371414797856   to: 0.042532560043427731
i:  91, name:           module.conv10.weight  changing lr from: 0.044786736419036501   to: 0.043038639741262923
i:  92, name:             module.conv10.bias  changing lr from: 0.045281813211551100   to: 0.043541578741295751



# Switched to train mode...
Epoch: [49][  0/391]	Time  0.204 ( 0.204)	Data  0.145 ( 0.145)	Loss 6.3575e-01 (6.3575e-01)	Acc@1  82.81 ( 82.81)	Acc@5  97.66 ( 97.66)
Epoch: [49][ 10/391]	Time  0.041 ( 0.055)	Data  0.001 ( 0.014)	Loss 6.0662e-01 (5.0122e-01)	Acc@1  82.81 ( 84.73)	Acc@5  96.88 ( 98.51)
Epoch: [49][ 20/391]	Time  0.039 ( 0.048)	Data  0.001 ( 0.008)	Loss 6.3290e-01 (4.9766e-01)	Acc@1  81.25 ( 85.34)	Acc@5  94.53 ( 98.25)
Epoch: [49][ 30/391]	Time  0.043 ( 0.046)	Data  0.001 ( 0.006)	Loss 4.3365e-01 (4.9798e-01)	Acc@1  86.72 ( 85.06)	Acc@5  99.22 ( 98.26)
Epoch: [49][ 40/391]	Time  0.040 ( 0.044)	Data  0.001 ( 0.005)	Loss 4.2062e-01 (5.0676e-01)	Acc@1  87.50 ( 84.34)	Acc@5  98.44 ( 98.13)
Epoch: [49][ 50/391]	Time  0.039 ( 0.043)	Data  0.001 ( 0.004)	Loss 4.4575e-01 (4.9044e-01)	Acc@1  85.94 ( 84.70)	Acc@5  98.44 ( 98.36)
Epoch: [49][ 60/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.003)	Loss 4.6624e-01 (4.8140e-01)	Acc@1  87.50 ( 84.90)	Acc@5  98.44 ( 98.44)
Epoch: [49][ 70/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.003)	Loss 5.7051e-01 (4.7672e-01)	Acc@1  81.25 ( 85.07)	Acc@5  97.66 ( 98.46)
Epoch: [49][ 80/391]	Time  0.044 ( 0.043)	Data  0.001 ( 0.003)	Loss 4.7991e-01 (4.8048e-01)	Acc@1  85.94 ( 84.99)	Acc@5  96.88 ( 98.43)
Epoch: [49][ 90/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.003)	Loss 5.2291e-01 (4.8458e-01)	Acc@1  83.59 ( 84.93)	Acc@5  96.88 ( 98.39)
Epoch: [49][100/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.0357e-01 (4.8512e-01)	Acc@1  82.03 ( 84.93)	Acc@5  96.88 ( 98.39)
Epoch: [49][110/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 4.2152e-01 (4.8726e-01)	Acc@1  87.50 ( 84.94)	Acc@5  98.44 ( 98.40)
Epoch: [49][120/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 4.8612e-01 (4.8886e-01)	Acc@1  85.94 ( 84.82)	Acc@5  96.88 ( 98.39)
Epoch: [49][130/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 4.9803e-01 (4.8674e-01)	Acc@1  85.16 ( 84.90)	Acc@5  97.66 ( 98.40)
Epoch: [49][140/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 4.2274e-01 (4.8548e-01)	Acc@1  88.28 ( 84.98)	Acc@5  98.44 ( 98.44)
Epoch: [49][150/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.0186e-01 (4.8575e-01)	Acc@1  83.59 ( 84.88)	Acc@5  98.44 ( 98.46)
Epoch: [49][160/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.8371e-01 (4.8642e-01)	Acc@1  88.28 ( 84.89)	Acc@5  97.66 ( 98.43)
Epoch: [49][170/391]	Time  0.043 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.8777e-01 (4.8695e-01)	Acc@1  85.94 ( 84.89)	Acc@5  98.44 ( 98.39)
Epoch: [49][180/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.7420e-01 (4.8871e-01)	Acc@1  80.47 ( 84.84)	Acc@5  98.44 ( 98.38)
Epoch: [49][190/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.8670e-01 (4.8961e-01)	Acc@1  84.38 ( 84.78)	Acc@5 100.00 ( 98.39)
Epoch: [49][200/391]	Time  0.040 ( 0.041)	Data  0.002 ( 0.002)	Loss 5.4229e-01 (4.9007e-01)	Acc@1  83.59 ( 84.74)	Acc@5  97.66 ( 98.37)
Epoch: [49][210/391]	Time  0.044 ( 0.041)	Data  0.001 ( 0.002)	Loss 7.2506e-01 (4.9266e-01)	Acc@1  74.22 ( 84.61)	Acc@5  97.66 ( 98.33)
Epoch: [49][220/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.6727e-01 (4.9559e-01)	Acc@1  78.91 ( 84.54)	Acc@5  96.09 ( 98.30)
Epoch: [49][230/391]	Time  0.043 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.4481e-01 (4.9618e-01)	Acc@1  82.03 ( 84.51)	Acc@5  98.44 ( 98.32)
Epoch: [49][240/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.3522e-01 (4.9758e-01)	Acc@1  87.50 ( 84.49)	Acc@5  98.44 ( 98.29)
Epoch: [49][250/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.5917e-01 (4.9977e-01)	Acc@1  84.38 ( 84.45)	Acc@5  97.66 ( 98.25)
Epoch: [49][260/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 7.3738e-01 (5.0209e-01)	Acc@1  78.12 ( 84.35)	Acc@5  96.09 ( 98.23)
Epoch: [49][270/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.3546e-01 (5.0156e-01)	Acc@1  82.81 ( 84.34)	Acc@5  99.22 ( 98.24)
Epoch: [49][280/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.8111e-01 (5.0171e-01)	Acc@1  80.47 ( 84.33)	Acc@5  98.44 ( 98.23)
Epoch: [49][290/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 8.4173e-01 (5.0225e-01)	Acc@1  75.00 ( 84.27)	Acc@5  96.09 ( 98.24)
Epoch: [49][300/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.001)	Loss 4.4733e-01 (5.0126e-01)	Acc@1  87.50 ( 84.32)	Acc@5  97.66 ( 98.25)
Epoch: [49][310/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.001)	Loss 4.9581e-01 (5.0214e-01)	Acc@1  85.94 ( 84.28)	Acc@5  98.44 ( 98.25)
Epoch: [49][320/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.001)	Loss 5.0863e-01 (5.0298e-01)	Acc@1  83.59 ( 84.25)	Acc@5  99.22 ( 98.24)
Epoch: [49][330/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.001)	Loss 7.3541e-01 (5.0474e-01)	Acc@1  79.69 ( 84.20)	Acc@5  96.09 ( 98.23)
Epoch: [49][340/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.001)	Loss 5.9934e-01 (5.0527e-01)	Acc@1  82.81 ( 84.18)	Acc@5  98.44 ( 98.23)
Epoch: [49][350/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.001)	Loss 3.6406e-01 (5.0555e-01)	Acc@1  87.50 ( 84.16)	Acc@5  99.22 ( 98.23)
Epoch: [49][360/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.001)	Loss 5.2077e-01 (5.0657e-01)	Acc@1  81.25 ( 84.13)	Acc@5  98.44 ( 98.23)
Epoch: [49][370/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.001)	Loss 5.5421e-01 (5.0757e-01)	Acc@1  82.03 ( 84.07)	Acc@5  97.66 ( 98.23)
Epoch: [49][380/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.001)	Loss 5.1214e-01 (5.0794e-01)	Acc@1  83.59 ( 84.08)	Acc@5  99.22 ( 98.23)
Epoch: [49][390/391]	Time  0.028 ( 0.041)	Data  0.001 ( 0.001)	Loss 6.5548e-01 (5.0943e-01)	Acc@1  78.75 ( 84.04)	Acc@5  97.50 ( 98.21)
## e[49] optimizer.zero_grad (sum) time: 0.26398777961730957
## e[49]       loss.backward (sum) time: 3.8546366691589355
## e[49]      optimizer.step (sum) time: 1.7630577087402344
## epoch[49] training(only) time: 16.03654146194458
# Switched to evaluate mode...
Test: [  0/100]	Time  0.163 ( 0.163)	Loss 1.3481e+00 (1.3481e+00)	Acc@1  68.00 ( 68.00)	Acc@5  90.00 ( 90.00)
Test: [ 10/100]	Time  0.023 ( 0.035)	Loss 1.3002e+00 (1.4511e+00)	Acc@1  64.00 ( 66.18)	Acc@5  91.00 ( 89.45)
Test: [ 20/100]	Time  0.025 ( 0.030)	Loss 1.2570e+00 (1.4197e+00)	Acc@1  66.00 ( 66.19)	Acc@5  93.00 ( 90.33)
Test: [ 30/100]	Time  0.024 ( 0.028)	Loss 1.5506e+00 (1.4554e+00)	Acc@1  64.00 ( 65.65)	Acc@5  91.00 ( 89.87)
Test: [ 40/100]	Time  0.019 ( 0.026)	Loss 1.4370e+00 (1.4571e+00)	Acc@1  64.00 ( 65.59)	Acc@5  90.00 ( 89.76)
Test: [ 50/100]	Time  0.022 ( 0.025)	Loss 1.4686e+00 (1.4640e+00)	Acc@1  65.00 ( 65.10)	Acc@5  92.00 ( 89.67)
Test: [ 60/100]	Time  0.022 ( 0.024)	Loss 1.6716e+00 (1.4406e+00)	Acc@1  59.00 ( 65.44)	Acc@5  84.00 ( 89.90)
Test: [ 70/100]	Time  0.021 ( 0.024)	Loss 1.5529e+00 (1.4384e+00)	Acc@1  64.00 ( 65.66)	Acc@5  88.00 ( 89.75)
Test: [ 80/100]	Time  0.022 ( 0.024)	Loss 1.5351e+00 (1.4456e+00)	Acc@1  67.00 ( 65.69)	Acc@5  88.00 ( 89.57)
Test: [ 90/100]	Time  0.024 ( 0.024)	Loss 1.9495e+00 (1.4396e+00)	Acc@1  58.00 ( 65.78)	Acc@5  87.00 ( 89.74)
 * Acc@1 65.840 Acc@5 89.980
### epoch[49] execution time: 18.488255739212036
EPOCH 50
REMOVING: module.fire2.expand_1x1.0.bias
REMOVING: module.fire2.expand_1x1.1.weight
REMOVING: module.fire2.expand_1x1.1.bias
i:   0, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.001156588299572280   to: 0.001006942550728784
i:   1, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.001254475113278130   to: 0.001037785884132180
i:   2, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.001374679813205553   to: 0.001092644758309696
i:   3, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.001516502231403337   to: 0.001170810435569058
i:   4, name:  module.fire3.squeeze.0.weight  changing lr from: 0.001679251318357660   to: 0.001271581604418009
i:   5, name:    module.fire3.squeeze.0.bias  changing lr from: 0.001862245574405501   to: 0.001394264934276112
i:   6, name:  module.fire3.squeeze.1.weight  changing lr from: 0.002064813436142726   to: 0.001538175579515393
i:   7, name:    module.fire3.squeeze.1.bias  changing lr from: 0.002286293620361501   to: 0.001702637635527148
i:   8, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.002526035427951078   to: 0.001886984549413644
i:   9, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.002783399010096986   to: 0.002090559487805848
i:  10, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.003057755599016631   to: 0.002312715664211745
i:  11, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.003348487705374308   to: 0.002552816628204862
i:  12, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.003654989284425691   to: 0.002810236518668878
i:  13, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.003976665872851065   to: 0.003084360283222492
i:  14, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.004312934698148817   to: 0.003374583865858948
i:  15, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.004663224762374429   to: 0.003680314364746856
i:  16, name:  module.fire4.squeeze.0.weight  changing lr from: 0.005026976901927277   to: 0.004000970162053129
i:  17, name:    module.fire4.squeeze.0.bias  changing lr from: 0.005403643825006576   to: 0.004335981027565632
i:  18, name:  module.fire4.squeeze.1.weight  changing lr from: 0.005792690128279914   to: 0.004684788197811934
i:  19, name:    module.fire4.squeeze.1.bias  changing lr from: 0.006193592294232163   to: 0.005046844432292212
i:  20, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.006605838670589464   to: 0.005421614048367462
i:  21, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.007028929433142694   to: 0.005808572936270766
i:  22, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.007462376533227188   to: 0.006207208555637777
i:  23, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.007905703631049692   to: 0.006617019914883398
i:  24, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.008358446015991349   to: 0.007037517534685549
i:  25, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.008820150514954567   to: 0.007468223396771872
i:  26, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.009290375389764231   to: 0.007908670879144541
i:  27, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.009768690224577770   to: 0.008358404678817738
i:  28, name:  module.fire5.squeeze.0.weight  changing lr from: 0.010254675804205683   to: 0.008816980723086298
i:  29, name:    module.fire5.squeeze.0.bias  changing lr from: 0.010747923984192866   to: 0.009283966070288464
i:  30, name:  module.fire5.squeeze.1.weight  changing lr from: 0.011248037553462393   to: 0.009758938800973099
i:  31, name:    module.fire5.squeeze.1.bias  changing lr from: 0.011754630090277229   to: 0.010241487900331987
i:  32, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.012267325812229730   to: 0.010731213132708379
i:  33, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.012785759420927717   to: 0.011227724908947866
i:  34, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.013309575942003927   to: 0.011730644147312508
i:  35, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.013838430561038294   to: 0.012239602128637728
i:  36, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.014371988455944361   to: 0.012754240346370110
i:  37, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.014909924626337313   to: 0.013274210352087083
i:  38, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.015451923720366800   to: 0.013799173597061183
i:  39, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.015997679859466624   to: 0.014328801270398060
i:  40, name:  module.fire6.squeeze.0.weight  changing lr from: 0.016546896461442872   to: 0.014862774134243056
i:  41, name:    module.fire6.squeeze.0.bias  changing lr from: 0.017099286062293727   to: 0.015400782356520031
i:  42, name:  module.fire6.squeeze.1.weight  changing lr from: 0.017654570137126825   to: 0.015942525341635615
i:  43, name:    module.fire6.squeeze.1.bias  changing lr from: 0.018212478920514318   to: 0.016487711559553486
i:  44, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.018772751226601738   to: 0.017036058373616474
i:  45, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.019335134269263050   to: 0.017587291867467415
i:  46, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.019899383482573203   to: 0.018141146671396553
i:  47, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.020465262341847670   to: 0.018697365788418515
i:  48, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.021032542185480681   to: 0.019255700420361472
i:  49, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.021601002037793235   to: 0.019815909794228665
i:  50, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.022170428433086295   to: 0.020377760989073901
i:  51, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.022740615241077490   to: 0.020941028763613374
i:  52, name:  module.fire7.squeeze.0.weight  changing lr from: 0.023311363493883776   to: 0.021505495384778934
i:  53, name:    module.fire7.squeeze.0.bias  changing lr from: 0.023882481214698784   to: 0.022070950457400748
i:  54, name:  module.fire7.squeeze.1.weight  changing lr from: 0.024453783248298874   to: 0.022637190755192105
i:  55, name:    module.fire7.squeeze.1.bias  changing lr from: 0.025025091093499843   to: 0.023204020053193886
i:  56, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.025596232737673558   to: 0.023771248961822727
i:  57, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.026167042493422478   to: 0.024338694762652990
i:  58, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.026737360837499582   to: 0.024906181246051234
i:  59, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.027307034252050767   to: 0.025473538550769389
i:  60, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.027875915068247784   to: 0.026040603005592355
i:  61, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.028443861312370658   to: 0.026607216973125403
i:  62, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.029010736554390706   to: 0.027173228695797108
i:  63, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.029576409759096867   to: 0.027738492144144290
i:  64, name:  module.fire8.squeeze.0.weight  changing lr from: 0.030140755139801956   to: 0.028302866867437406
i:  65, name:    module.fire8.squeeze.0.bias  changing lr from: 0.030703652014657603   to: 0.028866217846696421
i:  66, name:  module.fire8.squeeze.1.weight  changing lr from: 0.031264984665601306   to: 0.029428415350140416
i:  67, name:    module.fire8.squeeze.1.bias  changing lr from: 0.031824642199952957   to: 0.029989334791106617
i:  68, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.032382518414672400   to: 0.030548856588468249
i:  69, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.032938511663285507   to: 0.031106866029575398
i:  70, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.033492524725480602   to: 0.031663253135735918
i:  71, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.034044464679373741   to: 0.032217912530250005
i:  72, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.034594242776436517   to: 0.032770743309005528
i:  73, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.035141774319077348   to: 0.033321648913638383
i:  74, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.035686978540863133   to: 0.033870537007256500
i:  75, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.036229778489365309   to: 0.034417319352723408
i:  76, name:  module.fire9.squeeze.0.weight  changing lr from: 0.036770100911611939   to: 0.034961911693493164
i:  77, name:    module.fire9.squeeze.0.bias  changing lr from: 0.037307876142124025   to: 0.035504233636985343
i:  78, name:  module.fire9.squeeze.1.weight  changing lr from: 0.037843037993513087   to: 0.036044208540485866
i:  79, name:    module.fire9.squeeze.1.bias  changing lr from: 0.038375523649613552   to: 0.036581763399556724
i:  80, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.038905273561123062   to: 0.037116828738934828
i:  81, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.039432231343720620   to: 0.037649338505898577
i:  82, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.039956343678632246   to: 0.038179229966077935
i:  83, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.040477560215611393   to: 0.038706443601682398
i:  84, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.040995833478300908   to: 0.039230923012119542
i:  85, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.041511118771941857   to: 0.039752614816974945
i:  86, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.042023374093393379   to: 0.040271468561323180
i:  87, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.042532560043427731   to: 0.040787436623338502
i:  88, name:           module.conv10.weight  changing lr from: 0.043038639741262923   to: 0.041300474124172454
i:  89, name:             module.conv10.bias  changing lr from: 0.043541578741295751   to: 0.041810538840064818



# Switched to train mode...
Epoch: [50][  0/391]	Time  0.193 ( 0.193)	Data  0.148 ( 0.148)	Loss 4.3406e-01 (4.3406e-01)	Acc@1  85.94 ( 85.94)	Acc@5  97.66 ( 97.66)
Epoch: [50][ 10/391]	Time  0.044 ( 0.056)	Data  0.001 ( 0.014)	Loss 4.1405e-01 (4.5992e-01)	Acc@1  88.28 ( 85.87)	Acc@5  96.88 ( 98.44)
Epoch: [50][ 20/391]	Time  0.046 ( 0.049)	Data  0.001 ( 0.008)	Loss 4.0489e-01 (4.5269e-01)	Acc@1  89.06 ( 86.31)	Acc@5  99.22 ( 98.55)
Epoch: [50][ 30/391]	Time  0.043 ( 0.046)	Data  0.001 ( 0.006)	Loss 4.3531e-01 (4.5739e-01)	Acc@1  83.59 ( 85.81)	Acc@5  98.44 ( 98.59)
Epoch: [50][ 40/391]	Time  0.039 ( 0.045)	Data  0.001 ( 0.004)	Loss 3.8730e-01 (4.5486e-01)	Acc@1  89.84 ( 85.86)	Acc@5  99.22 ( 98.63)
Epoch: [50][ 50/391]	Time  0.041 ( 0.044)	Data  0.001 ( 0.004)	Loss 4.0358e-01 (4.5827e-01)	Acc@1  85.16 ( 85.72)	Acc@5  99.22 ( 98.59)
Epoch: [50][ 60/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.003)	Loss 5.1375e-01 (4.5971e-01)	Acc@1  84.38 ( 85.69)	Acc@5  97.66 ( 98.60)
Epoch: [50][ 70/391]	Time  0.039 ( 0.043)	Data  0.001 ( 0.003)	Loss 5.1181e-01 (4.6949e-01)	Acc@1  85.16 ( 85.32)	Acc@5  98.44 ( 98.50)
Epoch: [50][ 80/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.003)	Loss 5.3241e-01 (4.7035e-01)	Acc@1  83.59 ( 85.35)	Acc@5  97.66 ( 98.51)
Epoch: [50][ 90/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.003)	Loss 4.6558e-01 (4.6888e-01)	Acc@1  84.38 ( 85.29)	Acc@5 100.00 ( 98.52)
Epoch: [50][100/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 3.7205e-01 (4.7289e-01)	Acc@1  89.84 ( 85.17)	Acc@5  96.88 ( 98.47)
Epoch: [50][110/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 4.7930e-01 (4.6907e-01)	Acc@1  84.38 ( 85.26)	Acc@5  98.44 ( 98.49)
Epoch: [50][120/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 4.5164e-01 (4.7043e-01)	Acc@1  81.25 ( 85.21)	Acc@5  99.22 ( 98.51)
Epoch: [50][130/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.002)	Loss 3.7492e-01 (4.6875e-01)	Acc@1  87.50 ( 85.27)	Acc@5 100.00 ( 98.50)
Epoch: [50][140/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 4.4998e-01 (4.7199e-01)	Acc@1  86.72 ( 85.23)	Acc@5  97.66 ( 98.45)
Epoch: [50][150/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 4.9670e-01 (4.7427e-01)	Acc@1  85.16 ( 85.14)	Acc@5  97.66 ( 98.45)
Epoch: [50][160/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.9612e-01 (4.7359e-01)	Acc@1  88.28 ( 85.12)	Acc@5  99.22 ( 98.48)
Epoch: [50][170/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.4074e-01 (4.7448e-01)	Acc@1  88.28 ( 85.04)	Acc@5  98.44 ( 98.49)
Epoch: [50][180/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.3246e-01 (4.7643e-01)	Acc@1  86.72 ( 85.00)	Acc@5  99.22 ( 98.46)
Epoch: [50][190/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.1626e-01 (4.7830e-01)	Acc@1  80.47 ( 84.89)	Acc@5 100.00 ( 98.47)
Epoch: [50][200/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.5669e-01 (4.7850e-01)	Acc@1  81.25 ( 84.88)	Acc@5  97.66 ( 98.47)
Epoch: [50][210/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.4632e-01 (4.7861e-01)	Acc@1  84.38 ( 84.89)	Acc@5  98.44 ( 98.46)
Epoch: [50][220/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.3538e-01 (4.7831e-01)	Acc@1  86.72 ( 84.91)	Acc@5  98.44 ( 98.45)
Epoch: [50][230/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.6967e-01 (4.7771e-01)	Acc@1  85.94 ( 84.94)	Acc@5  96.88 ( 98.45)
Epoch: [50][240/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.9844e-01 (4.7945e-01)	Acc@1  83.59 ( 84.95)	Acc@5  95.31 ( 98.42)
Epoch: [50][250/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.7046e-01 (4.8140e-01)	Acc@1  82.03 ( 84.90)	Acc@5  98.44 ( 98.39)
Epoch: [50][260/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.001)	Loss 5.7182e-01 (4.8274e-01)	Acc@1  80.47 ( 84.85)	Acc@5  96.88 ( 98.39)
Epoch: [50][270/391]	Time  0.043 ( 0.041)	Data  0.001 ( 0.001)	Loss 4.3319e-01 (4.8339e-01)	Acc@1  86.72 ( 84.81)	Acc@5  98.44 ( 98.39)
Epoch: [50][280/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.001)	Loss 4.9652e-01 (4.8412e-01)	Acc@1  83.59 ( 84.81)	Acc@5  97.66 ( 98.38)
Epoch: [50][290/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.001)	Loss 3.2916e-01 (4.8379e-01)	Acc@1  89.84 ( 84.83)	Acc@5  99.22 ( 98.38)
Epoch: [50][300/391]	Time  0.037 ( 0.041)	Data  0.001 ( 0.001)	Loss 3.7453e-01 (4.8567e-01)	Acc@1  90.62 ( 84.80)	Acc@5  99.22 ( 98.35)
Epoch: [50][310/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.001)	Loss 6.1105e-01 (4.8694e-01)	Acc@1  82.03 ( 84.77)	Acc@5  96.88 ( 98.35)
Epoch: [50][320/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.001)	Loss 4.5400e-01 (4.8843e-01)	Acc@1  81.25 ( 84.72)	Acc@5  98.44 ( 98.34)
Epoch: [50][330/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.001)	Loss 6.6392e-01 (4.8988e-01)	Acc@1  77.34 ( 84.71)	Acc@5  97.66 ( 98.31)
Epoch: [50][340/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.001)	Loss 4.7820e-01 (4.9051e-01)	Acc@1  84.38 ( 84.68)	Acc@5  98.44 ( 98.31)
Epoch: [50][350/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.001)	Loss 4.8943e-01 (4.9019e-01)	Acc@1  84.38 ( 84.69)	Acc@5  97.66 ( 98.31)
Epoch: [50][360/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.001)	Loss 5.6545e-01 (4.9161e-01)	Acc@1  81.25 ( 84.64)	Acc@5  97.66 ( 98.29)
Epoch: [50][370/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.001)	Loss 4.2521e-01 (4.9138e-01)	Acc@1  87.50 ( 84.64)	Acc@5  97.66 ( 98.31)
Epoch: [50][380/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.001)	Loss 5.6363e-01 (4.9233e-01)	Acc@1  82.81 ( 84.64)	Acc@5  96.88 ( 98.29)
Epoch: [50][390/391]	Time  0.031 ( 0.041)	Data  0.001 ( 0.001)	Loss 6.0136e-01 (4.9354e-01)	Acc@1  82.50 ( 84.61)	Acc@5  96.25 ( 98.28)
## e[50] optimizer.zero_grad (sum) time: 0.2537102699279785
## e[50]       loss.backward (sum) time: 3.887817621231079
## e[50]      optimizer.step (sum) time: 1.708728551864624
## epoch[50] training(only) time: 15.979751348495483
# Switched to evaluate mode...
Test: [  0/100]	Time  0.158 ( 0.158)	Loss 1.2137e+00 (1.2137e+00)	Acc@1  66.00 ( 66.00)	Acc@5  90.00 ( 90.00)
Test: [ 10/100]	Time  0.019 ( 0.032)	Loss 1.5146e+00 (1.4505e+00)	Acc@1  67.00 ( 66.64)	Acc@5  91.00 ( 88.91)
Test: [ 20/100]	Time  0.025 ( 0.027)	Loss 1.1983e+00 (1.4102e+00)	Acc@1  70.00 ( 67.33)	Acc@5  93.00 ( 89.67)
Test: [ 30/100]	Time  0.021 ( 0.026)	Loss 1.7193e+00 (1.4515e+00)	Acc@1  60.00 ( 66.32)	Acc@5  88.00 ( 89.39)
Test: [ 40/100]	Time  0.024 ( 0.025)	Loss 1.5700e+00 (1.4456e+00)	Acc@1  65.00 ( 66.07)	Acc@5  87.00 ( 89.66)
Test: [ 50/100]	Time  0.021 ( 0.025)	Loss 1.4200e+00 (1.4412e+00)	Acc@1  67.00 ( 66.02)	Acc@5  93.00 ( 89.55)
Test: [ 60/100]	Time  0.021 ( 0.025)	Loss 1.5779e+00 (1.4227e+00)	Acc@1  63.00 ( 66.21)	Acc@5  88.00 ( 89.92)
Test: [ 70/100]	Time  0.022 ( 0.024)	Loss 1.5731e+00 (1.4307e+00)	Acc@1  64.00 ( 66.28)	Acc@5  88.00 ( 89.79)
Test: [ 80/100]	Time  0.029 ( 0.024)	Loss 1.5449e+00 (1.4339e+00)	Acc@1  66.00 ( 66.23)	Acc@5  89.00 ( 89.70)
Test: [ 90/100]	Time  0.023 ( 0.024)	Loss 1.7979e+00 (1.4273e+00)	Acc@1  63.00 ( 66.27)	Acc@5  84.00 ( 89.73)
 * Acc@1 66.510 Acc@5 89.910
### epoch[50] execution time: 18.4376962184906
EPOCH 51
REMOVING: module.fire2.expand_3x3.0.weight
REMOVING: module.fire2.expand_3x3.0.bias
REMOVING: module.fire2.expand_3x3.1.weight
i:   0, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.001170810435569058   to: 0.001011559862627930
i:   1, name:  module.fire3.squeeze.0.weight  changing lr from: 0.001271581604418009   to: 0.001047359364565991
i:   2, name:    module.fire3.squeeze.0.bias  changing lr from: 0.001394264934276112   to: 0.001106711661655290
i:   3, name:  module.fire3.squeeze.1.weight  changing lr from: 0.001538175579515393   to: 0.001188923373088107
i:   4, name:    module.fire3.squeeze.1.bias  changing lr from: 0.001702637635527148   to: 0.001293308465133696
i:   5, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.001886984549413644   to: 0.001419188777786306
i:   6, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.002090559487805848   to: 0.001565894503229025
i:   7, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.002312715664211745   to: 0.001732764618670573
i:   8, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.002552816628204862   to: 0.001919147276018989
i:   9, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.002810236518668878   to: 0.002124400150763566
i:  10, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.003084360283222492   to: 0.002347890752345121
i:  11, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.003374583865858948   to: 0.002588996698204804
i:  12, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.003680314364746856   to: 0.002847105953613054
i:  13, name:  module.fire4.squeeze.0.weight  changing lr from: 0.004000970162053129   to: 0.003121617039293655
i:  14, name:    module.fire4.squeeze.0.bias  changing lr from: 0.004335981027565632   to: 0.003411939208772712
i:  15, name:  module.fire4.squeeze.1.weight  changing lr from: 0.004684788197811934   to: 0.003717492597299659
i:  16, name:    module.fire4.squeeze.1.bias  changing lr from: 0.005046844432292212   to: 0.004037708344106349
i:  17, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.005421614048367462   to: 0.004372028689691309
i:  18, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.005808572936270766   to: 0.004719907049739935
i:  19, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.006207208555637777   to: 0.005080808067216702
i:  20, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.006617019914883398   to: 0.005454207644093616
i:  21, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.007037517534685549   to: 0.005839592954109029
i:  22, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.007468223396771872   to: 0.006236462437883682
i:  23, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.007908670879144541   to: 0.006644325781655269
i:  24, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.008358404678817738   to: 0.007062703880830145
i:  25, name:  module.fire5.squeeze.0.weight  changing lr from: 0.008816980723086298   to: 0.007491128789489964
i:  26, name:    module.fire5.squeeze.0.bias  changing lr from: 0.009283966070288464   to: 0.007929143656932569
i:  27, name:  module.fire5.squeeze.1.weight  changing lr from: 0.009758938800973099   to: 0.008376302652270174
i:  28, name:    module.fire5.squeeze.1.bias  changing lr from: 0.010241487900331987   to: 0.008832170878054161
i:  29, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.010731213132708379   to: 0.009296324273843276
i:  30, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.011227724908947866   to: 0.009768349510582728
i:  31, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.011730644147312508   to: 0.010247843876613798
i:  32, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.012239602128637728   to: 0.010734415156087695
i:  33, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.012754240346370110   to: 0.011227681500513502
i:  34, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.013274210352087083   to: 0.011727271294128667
i:  35, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.013799173597061183   to: 0.012232823013739496
i:  36, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.014328801270398060   to: 0.012743985083642016
i:  37, name:  module.fire6.squeeze.0.weight  changing lr from: 0.014862774134243056   to: 0.013260415726195941
i:  38, name:    module.fire6.squeeze.0.bias  changing lr from: 0.015400782356520031   to: 0.013781782808590558
i:  39, name:  module.fire6.squeeze.1.weight  changing lr from: 0.015942525341635615   to: 0.014307763686307439
i:  40, name:    module.fire6.squeeze.1.bias  changing lr from: 0.016487711559553486   to: 0.014838045043753339
i:  41, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.017036058373616474   to: 0.015372322732507465
i:  42, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.017587291867467415   to: 0.015910301607596867
i:  43, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.018141146671396553   to: 0.016451695362188341
i:  44, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.018697365788418515   to: 0.016996226361057822
i:  45, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.019255700420361472   to: 0.017543625473174812
i:  46, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.019815909794228665   to: 0.018093631903715265
i:  47, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.020377760989073901   to: 0.018645993025794477
i:  48, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.020941028763613374   to: 0.019200464212190679
i:  49, name:  module.fire7.squeeze.0.weight  changing lr from: 0.021505495384778934   to: 0.019756808667310208
i:  50, name:    module.fire7.squeeze.0.bias  changing lr from: 0.022070950457400748   to: 0.020314797259625962
i:  51, name:  module.fire7.squeeze.1.weight  changing lr from: 0.022637190755192105   to: 0.020874208354803320
i:  52, name:    module.fire7.squeeze.1.bias  changing lr from: 0.023204020053193886   to: 0.021434827649710886
i:  53, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.023771248961822727   to: 0.021996448007497574
i:  54, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.024338694762652990   to: 0.022558869293902148
i:  55, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.024906181246051234   to: 0.023121898214947964
i:  56, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.025473538550769389   to: 0.023685348156161214
i:  57, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.026040603005592355   to: 0.024249039023439580
i:  58, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.026607216973125403   to: 0.024812797085685352
i:  59, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.027173228695797108   to: 0.025376454819306678
i:  60, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.027738492144144290   to: 0.025939850754679444
i:  61, name:  module.fire8.squeeze.0.weight  changing lr from: 0.028302866867437406   to: 0.026502829324653310
i:  62, name:    module.fire8.squeeze.0.bias  changing lr from: 0.028866217846696421   to: 0.027065240715175101
i:  63, name:  module.fire8.squeeze.1.weight  changing lr from: 0.029428415350140416   to: 0.027626940718095051
i:  64, name:    module.fire8.squeeze.1.bias  changing lr from: 0.029989334791106617   to: 0.028187790586213068
i:  65, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.030548856588468249   to: 0.028747656890613694
i:  66, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.031106866029575398   to: 0.029306411380332908
i:  67, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.031663253135735918   to: 0.029863930844391842
i:  68, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.032217912530250005   to: 0.030420096976227107
i:  69, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.032770743309005528   to: 0.030974796240541159
i:  70, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.033321648913638383   to: 0.031527919742591365
i:  71, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.033870537007256500   to: 0.032079363099930550
i:  72, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.034417319352723408   to: 0.032629026316608058
i:  73, name:  module.fire9.squeeze.0.weight  changing lr from: 0.034961911693493164   to: 0.033176813659835373
i:  74, name:    module.fire9.squeeze.0.bias  changing lr from: 0.035504233636985343   to: 0.033722633539116580
i:  75, name:  module.fire9.squeeze.1.weight  changing lr from: 0.036044208540485866   to: 0.034266398387840458
i:  76, name:    module.fire9.squeeze.1.bias  changing lr from: 0.036581763399556724   to: 0.034808024547327114
i:  77, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.037116828738934828   to: 0.035347432153319404
i:  78, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.037649338505898577   to: 0.035884545024906074
i:  79, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.038179229966077935   to: 0.036419290555861371
i:  80, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.038706443601682398   to: 0.036951599608382624
i:  81, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.039230923012119542   to: 0.037481406409206351
i:  82, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.039752614816974945   to: 0.038008648448080058
i:  83, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.040271468561323180   to: 0.038533266378565835
i:  84, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.040787436623338502   to: 0.039055203921150181
i:  85, name:           module.conv10.weight  changing lr from: 0.041300474124172454   to: 0.039574407768632781
i:  86, name:             module.conv10.bias  changing lr from: 0.041810538840064818   to: 0.040090827493765489



# Switched to train mode...
Epoch: [51][  0/391]	Time  0.193 ( 0.193)	Data  0.148 ( 0.148)	Loss 3.9469e-01 (3.9469e-01)	Acc@1  90.62 ( 90.62)	Acc@5  98.44 ( 98.44)
Epoch: [51][ 10/391]	Time  0.042 ( 0.055)	Data  0.001 ( 0.014)	Loss 4.5120e-01 (4.5013e-01)	Acc@1  85.94 ( 86.86)	Acc@5  98.44 ( 98.30)
Epoch: [51][ 20/391]	Time  0.039 ( 0.048)	Data  0.001 ( 0.008)	Loss 3.0598e-01 (4.4910e-01)	Acc@1  92.19 ( 86.64)	Acc@5  97.66 ( 98.47)
Epoch: [51][ 30/391]	Time  0.040 ( 0.045)	Data  0.001 ( 0.006)	Loss 2.7057e-01 (4.3687e-01)	Acc@1  91.41 ( 86.87)	Acc@5  98.44 ( 98.54)
Epoch: [51][ 40/391]	Time  0.039 ( 0.044)	Data  0.001 ( 0.005)	Loss 4.5882e-01 (4.3498e-01)	Acc@1  85.94 ( 86.87)	Acc@5  99.22 ( 98.69)
Epoch: [51][ 50/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.004)	Loss 4.2951e-01 (4.3656e-01)	Acc@1  87.50 ( 86.80)	Acc@5 100.00 ( 98.67)
Epoch: [51][ 60/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.003)	Loss 5.3819e-01 (4.4235e-01)	Acc@1  82.81 ( 86.44)	Acc@5  97.66 ( 98.69)
Epoch: [51][ 70/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.003)	Loss 4.2027e-01 (4.3957e-01)	Acc@1  84.38 ( 86.47)	Acc@5  99.22 ( 98.71)
Epoch: [51][ 80/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.003)	Loss 3.8045e-01 (4.4199e-01)	Acc@1  87.50 ( 86.50)	Acc@5  99.22 ( 98.70)
Epoch: [51][ 90/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.003)	Loss 4.2005e-01 (4.4272e-01)	Acc@1  89.06 ( 86.48)	Acc@5 100.00 ( 98.72)
Epoch: [51][100/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 3.8101e-01 (4.4523e-01)	Acc@1  89.84 ( 86.46)	Acc@5  98.44 ( 98.70)
Epoch: [51][110/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 4.8271e-01 (4.4490e-01)	Acc@1  89.06 ( 86.46)	Acc@5  97.66 ( 98.69)
Epoch: [51][120/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.9372e-01 (4.4312e-01)	Acc@1  90.62 ( 86.53)	Acc@5  99.22 ( 98.70)
Epoch: [51][130/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.8444e-01 (4.4275e-01)	Acc@1  85.94 ( 86.55)	Acc@5  99.22 ( 98.71)
Epoch: [51][140/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.0839e-01 (4.4746e-01)	Acc@1  80.47 ( 86.34)	Acc@5  97.66 ( 98.65)
Epoch: [51][150/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.3012e-01 (4.4747e-01)	Acc@1  85.94 ( 86.27)	Acc@5  99.22 ( 98.67)
Epoch: [51][160/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.7351e-01 (4.4903e-01)	Acc@1  83.59 ( 86.19)	Acc@5  99.22 ( 98.66)
Epoch: [51][170/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.3769e-01 (4.5137e-01)	Acc@1  82.81 ( 86.11)	Acc@5  97.66 ( 98.65)
Epoch: [51][180/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.5308e-01 (4.5110e-01)	Acc@1  87.50 ( 86.10)	Acc@5  97.66 ( 98.64)
Epoch: [51][190/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.4725e-01 (4.5135e-01)	Acc@1  88.28 ( 86.12)	Acc@5  97.66 ( 98.63)
Epoch: [51][200/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.8816e-01 (4.4969e-01)	Acc@1  87.50 ( 86.13)	Acc@5 100.00 ( 98.64)
Epoch: [51][210/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.7306e-01 (4.5161e-01)	Acc@1  89.06 ( 86.04)	Acc@5 100.00 ( 98.64)
Epoch: [51][220/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.9244e-01 (4.5174e-01)	Acc@1  85.16 ( 86.02)	Acc@5  98.44 ( 98.64)
Epoch: [51][230/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.2054e-01 (4.5368e-01)	Acc@1  83.59 ( 85.99)	Acc@5  98.44 ( 98.62)
Epoch: [51][240/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.3762e-01 (4.5400e-01)	Acc@1  87.50 ( 85.98)	Acc@5  97.66 ( 98.62)
Epoch: [51][250/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.3031e-01 (4.5573e-01)	Acc@1  84.38 ( 85.92)	Acc@5  97.66 ( 98.61)
Epoch: [51][260/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.3829e-01 (4.5741e-01)	Acc@1  84.38 ( 85.84)	Acc@5  98.44 ( 98.60)
Epoch: [51][270/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.4167e-01 (4.5573e-01)	Acc@1  86.72 ( 85.90)	Acc@5  99.22 ( 98.61)
Epoch: [51][280/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.8867e-01 (4.5615e-01)	Acc@1  85.94 ( 85.89)	Acc@5  97.66 ( 98.62)
Epoch: [51][290/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.5935e-01 (4.5682e-01)	Acc@1  85.16 ( 85.84)	Acc@5  99.22 ( 98.62)
Epoch: [51][300/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.001)	Loss 4.9528e-01 (4.5742e-01)	Acc@1  85.16 ( 85.79)	Acc@5  97.66 ( 98.63)
Epoch: [51][310/391]	Time  0.043 ( 0.041)	Data  0.001 ( 0.001)	Loss 6.2431e-01 (4.5850e-01)	Acc@1  82.81 ( 85.73)	Acc@5  95.31 ( 98.59)
Epoch: [51][320/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.001)	Loss 5.1546e-01 (4.5844e-01)	Acc@1  85.16 ( 85.75)	Acc@5  98.44 ( 98.59)
Epoch: [51][330/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.001)	Loss 4.9604e-01 (4.5974e-01)	Acc@1  82.81 ( 85.71)	Acc@5  99.22 ( 98.58)
Epoch: [51][340/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.001)	Loss 5.5059e-01 (4.6103e-01)	Acc@1  85.16 ( 85.64)	Acc@5  97.66 ( 98.57)
Epoch: [51][350/391]	Time  0.037 ( 0.041)	Data  0.001 ( 0.001)	Loss 4.9656e-01 (4.6202e-01)	Acc@1  82.03 ( 85.59)	Acc@5  99.22 ( 98.58)
Epoch: [51][360/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.001)	Loss 4.3529e-01 (4.6406e-01)	Acc@1  85.94 ( 85.53)	Acc@5  99.22 ( 98.55)
Epoch: [51][370/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.001)	Loss 4.7797e-01 (4.6492e-01)	Acc@1  86.72 ( 85.48)	Acc@5  97.66 ( 98.54)
Epoch: [51][380/391]	Time  0.038 ( 0.040)	Data  0.001 ( 0.001)	Loss 3.8324e-01 (4.6470e-01)	Acc@1  88.28 ( 85.48)	Acc@5  99.22 ( 98.55)
Epoch: [51][390/391]	Time  0.026 ( 0.040)	Data  0.001 ( 0.001)	Loss 7.4213e-01 (4.6718e-01)	Acc@1  80.00 ( 85.39)	Acc@5  93.75 ( 98.52)
## e[51] optimizer.zero_grad (sum) time: 0.2470712661743164
## e[51]       loss.backward (sum) time: 3.7977538108825684
## e[51]      optimizer.step (sum) time: 1.6720829010009766
## epoch[51] training(only) time: 15.887857437133789
# Switched to evaluate mode...
Test: [  0/100]	Time  0.155 ( 0.155)	Loss 1.3287e+00 (1.3287e+00)	Acc@1  68.00 ( 68.00)	Acc@5  90.00 ( 90.00)
Test: [ 10/100]	Time  0.020 ( 0.033)	Loss 1.4415e+00 (1.4269e+00)	Acc@1  65.00 ( 66.09)	Acc@5  91.00 ( 89.18)
Test: [ 20/100]	Time  0.025 ( 0.028)	Loss 1.3312e+00 (1.3912e+00)	Acc@1  69.00 ( 67.29)	Acc@5  91.00 ( 89.67)
Test: [ 30/100]	Time  0.024 ( 0.027)	Loss 1.8122e+00 (1.4197e+00)	Acc@1  54.00 ( 66.58)	Acc@5  89.00 ( 89.68)
Test: [ 40/100]	Time  0.024 ( 0.026)	Loss 1.3820e+00 (1.4186e+00)	Acc@1  64.00 ( 66.39)	Acc@5  91.00 ( 89.88)
Test: [ 50/100]	Time  0.024 ( 0.025)	Loss 1.5669e+00 (1.4155e+00)	Acc@1  62.00 ( 66.35)	Acc@5  89.00 ( 89.80)
Test: [ 60/100]	Time  0.024 ( 0.025)	Loss 1.6477e+00 (1.3986e+00)	Acc@1  60.00 ( 66.51)	Acc@5  90.00 ( 90.10)
Test: [ 70/100]	Time  0.023 ( 0.025)	Loss 1.5002e+00 (1.4054e+00)	Acc@1  68.00 ( 66.62)	Acc@5  87.00 ( 89.96)
Test: [ 80/100]	Time  0.021 ( 0.024)	Loss 1.7448e+00 (1.4144e+00)	Acc@1  65.00 ( 66.47)	Acc@5  88.00 ( 89.91)
Test: [ 90/100]	Time  0.023 ( 0.024)	Loss 1.7939e+00 (1.4082e+00)	Acc@1  63.00 ( 66.63)	Acc@5  85.00 ( 89.96)
 * Acc@1 66.880 Acc@5 90.060
### epoch[51] execution time: 18.32577919960022
EPOCH 52
REMOVING: module.fire2.expand_3x3.1.bias
REMOVING: module.fire3.squeeze.0.weight
i:   0, name:    module.fire3.squeeze.0.bias  changing lr from: 0.001106711661655290   to: 0.001000631653351713
i:   1, name:  module.fire3.squeeze.1.weight  changing lr from: 0.001188923373088107   to: 0.001018309345057027
i:   2, name:    module.fire3.squeeze.1.bias  changing lr from: 0.001293308465133696   to: 0.001059753591295991
i:   3, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.001419188777786306   to: 0.001124279298084823
i:   4, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.001565894503229025   to: 0.001211208110764027
i:   5, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.001732764618670573   to: 0.001319868960940767
i:   6, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.001919147276018989   to: 0.001449598565149456
i:   7, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.002124400150763566   to: 0.001599741877743076
i:   8, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.002347890752345121   to: 0.001769652500438500
i:   9, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.002588996698204804   to: 0.001958693050850917
i:  10, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.002847105953613054   to: 0.002166235492264739
i:  11, name:  module.fire4.squeeze.0.weight  changing lr from: 0.003121617039293655   to: 0.002391661426801899
i:  12, name:    module.fire4.squeeze.0.bias  changing lr from: 0.003411939208772712   to: 0.002634362354063446
i:  13, name:  module.fire4.squeeze.1.weight  changing lr from: 0.003717492597299659   to: 0.002893739897236396
i:  14, name:    module.fire4.squeeze.1.bias  changing lr from: 0.004037708344106349   to: 0.003169205998576124
i:  15, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.004372028689691309   to: 0.003460183086093754
i:  16, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.004719907049739935   to: 0.003766104213200105
i:  17, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.005080808067216702   to: 0.004086413172980746
i:  18, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.005454207644093616   to: 0.004420564588702624
i:  19, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.005839592954109029   to: 0.004768023982080077
i:  20, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.006236462437883682   to: 0.005128267820757758
i:  21, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.006644325781655269   to: 0.005500783546400028
i:  22, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.007062703880830145   to: 0.005885069584709973
i:  23, name:  module.fire5.squeeze.0.weight  changing lr from: 0.007491128789489964   to: 0.006280635338637907
i:  24, name:    module.fire5.squeeze.0.bias  changing lr from: 0.007929143656932569   to: 0.006687001165977063
i:  25, name:  module.fire5.squeeze.1.weight  changing lr from: 0.008376302652270174   to: 0.007103698342484787
i:  26, name:    module.fire5.squeeze.1.bias  changing lr from: 0.008832170878054161   to: 0.007530269011610562
i:  27, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.009296324273843276   to: 0.007966266121855975
i:  28, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.009768349510582728   to: 0.008411253352739890
i:  29, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.010247843876613798   to: 0.008864805030289451
i:  30, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.010734415156087695   to: 0.009326506032930008
i:  31, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.011227681500513502   to: 0.009795951688598342
i:  32, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.011727271294128667   to: 0.010272747663859650
i:  33, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.012232823013739496   to: 0.010756509845764678
i:  34, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.012743985083642016   to: 0.011246864217142171
i:  35, name:  module.fire6.squeeze.0.weight  changing lr from: 0.013260415726195941   to: 0.011743446725982216
i:  36, name:    module.fire6.squeeze.0.bias  changing lr from: 0.013781782808590558   to: 0.012245903149527761
i:  37, name:  module.fire6.squeeze.1.weight  changing lr from: 0.014307763686307439   to: 0.012753888953655795
i:  38, name:    module.fire6.squeeze.1.bias  changing lr from: 0.014838045043753339   to: 0.013267069148094536
i:  39, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.015372322732507465   to: 0.013785118137990621
i:  40, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.015910301607596867   to: 0.014307719572307948
i:  41, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.016451695362188341   to: 0.014834566189510741
i:  42, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.016996226361057822   to: 0.015365359660953655
i:  43, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.017543625473174812   to: 0.015899810432376243
i:  44, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.018093631903715265   to: 0.016437637563871187
i:  45, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.018645993025794477   to: 0.016978568568672636
i:  46, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.019200464212190679   to: 0.017522339251087204
i:  47, name:  module.fire7.squeeze.0.weight  changing lr from: 0.019756808667310208   to: 0.018068693543867625
i:  48, name:    module.fire7.squeeze.0.bias  changing lr from: 0.020314797259625962   to: 0.018617383345308613
i:  49, name:  module.fire7.squeeze.1.weight  changing lr from: 0.020874208354803320   to: 0.019168168356324077
i:  50, name:    module.fire7.squeeze.1.bias  changing lr from: 0.021434827649710886   to: 0.019720815917745993
i:  51, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.021996448007497574   to: 0.020275100848067714
i:  52, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.022558869293902148   to: 0.020830805281837006
i:  53, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.023121898214947964   to: 0.021387718508888667
i:  54, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.023685348156161214   to: 0.021945636814590504
i:  55, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.024249039023439580   to: 0.022504363321263595
i:  56, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.024812797085685352   to: 0.023063707830922597
i:  57, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.025376454819306678   to: 0.023623486669470607
i:  58, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.025939850754679444   to: 0.024183522532469817
i:  59, name:  module.fire8.squeeze.0.weight  changing lr from: 0.026502829324653310   to: 0.024743644332598992
i:  60, name:    module.fire8.squeeze.0.bias  changing lr from: 0.027065240715175101   to: 0.025303687048897124
i:  61, name:  module.fire8.squeeze.1.weight  changing lr from: 0.027626940718095051   to: 0.025863491577883681
i:  62, name:    module.fire8.squeeze.1.bias  changing lr from: 0.028187790586213068   to: 0.026422904586635421
i:  63, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.028747656890613694   to: 0.026981778367891465
i:  64, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.029306411380332908   to: 0.027539970697250199
i:  65, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.029863930844391842   to: 0.028097344692513196
i:  66, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.030420096976227107   to: 0.028653768675224435
i:  67, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.030974796240541159   to: 0.029209116034446477
i:  68, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.031527919742591365   to: 0.029763265092808334
i:  69, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.032079363099930550   to: 0.030316098974854357
i:  70, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.032629026316608058   to: 0.030867505477717400
i:  71, name:  module.fire9.squeeze.0.weight  changing lr from: 0.033176813659835373   to: 0.031417376944134996
i:  72, name:    module.fire9.squeeze.0.bias  changing lr from: 0.033722633539116580   to: 0.031965610137821607
i:  73, name:  module.fire9.squeeze.1.weight  changing lr from: 0.034266398387840458   to: 0.032512106121206419
i:  74, name:    module.fire9.squeeze.1.bias  changing lr from: 0.034808024547327114   to: 0.033056770135541223
i:  75, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.035347432153319404   to: 0.033599511483379731
i:  76, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.035884545024906074   to: 0.034140243413425482
i:  77, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.036419290555861371   to: 0.034678883007742745
i:  78, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.036951599608382624   to: 0.035215351071321267
i:  79, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.037481406409206351   to: 0.035749572023983510
i:  80, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.038008648448080058   to: 0.036281473794619865
i:  81, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.038533266378565835   to: 0.036810987717735159
i:  82, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.039055203921150181   to: 0.037338048432287961
i:  83, name:           module.conv10.weight  changing lr from: 0.039574407768632781   to: 0.037862593782801622
i:  84, name:             module.conv10.bias  changing lr from: 0.040090827493765489   to: 0.038384564722724716



# Switched to train mode...
Epoch: [52][  0/391]	Time  0.193 ( 0.193)	Data  0.149 ( 0.149)	Loss 4.4751e-01 (4.4751e-01)	Acc@1  86.72 ( 86.72)	Acc@5  98.44 ( 98.44)
Epoch: [52][ 10/391]	Time  0.045 ( 0.054)	Data  0.001 ( 0.014)	Loss 3.6792e-01 (3.9262e-01)	Acc@1  89.06 ( 88.35)	Acc@5  99.22 ( 99.22)
Epoch: [52][ 20/391]	Time  0.038 ( 0.048)	Data  0.001 ( 0.008)	Loss 3.7833e-01 (4.2526e-01)	Acc@1  87.50 ( 86.72)	Acc@5 100.00 ( 98.85)
Epoch: [52][ 30/391]	Time  0.039 ( 0.045)	Data  0.001 ( 0.006)	Loss 2.7338e-01 (4.1217e-01)	Acc@1  92.97 ( 87.27)	Acc@5 100.00 ( 98.84)
Epoch: [52][ 40/391]	Time  0.041 ( 0.044)	Data  0.001 ( 0.005)	Loss 4.4245e-01 (4.1776e-01)	Acc@1  85.16 ( 87.20)	Acc@5 100.00 ( 98.88)
Epoch: [52][ 50/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.004)	Loss 3.5335e-01 (4.1748e-01)	Acc@1  89.84 ( 87.29)	Acc@5  97.66 ( 98.93)
Epoch: [52][ 60/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.003)	Loss 3.6878e-01 (4.1194e-01)	Acc@1  90.62 ( 87.47)	Acc@5  97.66 ( 98.89)
Epoch: [52][ 70/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.003)	Loss 4.7648e-01 (4.1195e-01)	Acc@1  86.72 ( 87.39)	Acc@5  98.44 ( 98.95)
Epoch: [52][ 80/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.003)	Loss 4.4116e-01 (4.1058e-01)	Acc@1  86.72 ( 87.50)	Acc@5  97.66 ( 98.88)
Epoch: [52][ 90/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.003)	Loss 3.6166e-01 (4.1507e-01)	Acc@1  88.28 ( 87.22)	Acc@5 100.00 ( 98.85)
Epoch: [52][100/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.2299e-01 (4.1918e-01)	Acc@1  83.59 ( 87.05)	Acc@5  96.09 ( 98.84)
Epoch: [52][110/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.6781e-01 (4.2423e-01)	Acc@1  83.59 ( 86.95)	Acc@5  96.09 ( 98.81)
Epoch: [52][120/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.7091e-01 (4.2547e-01)	Acc@1  84.38 ( 86.82)	Acc@5  97.66 ( 98.80)
Epoch: [52][130/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.3697e-01 (4.2668e-01)	Acc@1  85.16 ( 86.82)	Acc@5  99.22 ( 98.79)
Epoch: [52][140/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.2140e-01 (4.2575e-01)	Acc@1  88.28 ( 86.87)	Acc@5  99.22 ( 98.79)
Epoch: [52][150/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.0579e-01 (4.2790e-01)	Acc@1  90.62 ( 86.80)	Acc@5 100.00 ( 98.76)
Epoch: [52][160/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.3514e-01 (4.2816e-01)	Acc@1  88.28 ( 86.71)	Acc@5 100.00 ( 98.77)
Epoch: [52][170/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.9762e-01 (4.2999e-01)	Acc@1  84.38 ( 86.64)	Acc@5  99.22 ( 98.76)
Epoch: [52][180/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.8990e-01 (4.2872e-01)	Acc@1  89.06 ( 86.71)	Acc@5  96.09 ( 98.74)
Epoch: [52][190/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.7273e-01 (4.2976e-01)	Acc@1  91.41 ( 86.64)	Acc@5 100.00 ( 98.76)
Epoch: [52][200/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.9906e-01 (4.3124e-01)	Acc@1  85.16 ( 86.56)	Acc@5  96.88 ( 98.76)
Epoch: [52][210/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.2623e-01 (4.3394e-01)	Acc@1  87.50 ( 86.50)	Acc@5  98.44 ( 98.74)
Epoch: [52][220/391]	Time  0.037 ( 0.040)	Data  0.001 ( 0.002)	Loss 5.1518e-01 (4.3726e-01)	Acc@1  82.03 ( 86.39)	Acc@5  98.44 ( 98.73)
Epoch: [52][230/391]	Time  0.038 ( 0.040)	Data  0.001 ( 0.002)	Loss 3.7348e-01 (4.3590e-01)	Acc@1  90.62 ( 86.43)	Acc@5  98.44 ( 98.75)
Epoch: [52][240/391]	Time  0.040 ( 0.040)	Data  0.001 ( 0.002)	Loss 5.1704e-01 (4.3667e-01)	Acc@1  82.03 ( 86.40)	Acc@5  97.66 ( 98.73)
Epoch: [52][250/391]	Time  0.043 ( 0.040)	Data  0.001 ( 0.002)	Loss 4.6672e-01 (4.3568e-01)	Acc@1  85.16 ( 86.44)	Acc@5  97.66 ( 98.74)
Epoch: [52][260/391]	Time  0.038 ( 0.040)	Data  0.001 ( 0.002)	Loss 5.4140e-01 (4.3697e-01)	Acc@1  80.47 ( 86.37)	Acc@5  99.22 ( 98.74)
Epoch: [52][270/391]	Time  0.041 ( 0.040)	Data  0.001 ( 0.002)	Loss 6.4119e-01 (4.3899e-01)	Acc@1  78.12 ( 86.33)	Acc@5  97.66 ( 98.71)
Epoch: [52][280/391]	Time  0.040 ( 0.040)	Data  0.001 ( 0.002)	Loss 5.2480e-01 (4.4007e-01)	Acc@1  83.59 ( 86.29)	Acc@5  97.66 ( 98.72)
Epoch: [52][290/391]	Time  0.039 ( 0.040)	Data  0.001 ( 0.001)	Loss 3.3742e-01 (4.4096e-01)	Acc@1  90.62 ( 86.26)	Acc@5  97.66 ( 98.71)
Epoch: [52][300/391]	Time  0.039 ( 0.040)	Data  0.001 ( 0.001)	Loss 4.5976e-01 (4.4117e-01)	Acc@1  81.25 ( 86.19)	Acc@5  98.44 ( 98.72)
Epoch: [52][310/391]	Time  0.038 ( 0.040)	Data  0.001 ( 0.001)	Loss 5.5681e-01 (4.4207e-01)	Acc@1  83.59 ( 86.13)	Acc@5  97.66 ( 98.71)
Epoch: [52][320/391]	Time  0.042 ( 0.040)	Data  0.001 ( 0.001)	Loss 4.0887e-01 (4.4291e-01)	Acc@1  87.50 ( 86.12)	Acc@5  99.22 ( 98.71)
Epoch: [52][330/391]	Time  0.042 ( 0.040)	Data  0.001 ( 0.001)	Loss 3.5577e-01 (4.4246e-01)	Acc@1  89.84 ( 86.14)	Acc@5  99.22 ( 98.71)
Epoch: [52][340/391]	Time  0.041 ( 0.040)	Data  0.001 ( 0.001)	Loss 5.1345e-01 (4.4308e-01)	Acc@1  83.59 ( 86.10)	Acc@5  98.44 ( 98.72)
Epoch: [52][350/391]	Time  0.038 ( 0.040)	Data  0.001 ( 0.001)	Loss 6.3233e-01 (4.4319e-01)	Acc@1  74.22 ( 86.08)	Acc@5  98.44 ( 98.71)
Epoch: [52][360/391]	Time  0.039 ( 0.040)	Data  0.001 ( 0.001)	Loss 4.2530e-01 (4.4396e-01)	Acc@1  83.59 ( 86.05)	Acc@5 100.00 ( 98.70)
Epoch: [52][370/391]	Time  0.039 ( 0.040)	Data  0.001 ( 0.001)	Loss 5.2056e-01 (4.4530e-01)	Acc@1  82.03 ( 86.00)	Acc@5  97.66 ( 98.69)
Epoch: [52][380/391]	Time  0.040 ( 0.040)	Data  0.001 ( 0.001)	Loss 6.0956e-01 (4.4772e-01)	Acc@1  78.91 ( 85.91)	Acc@5  97.66 ( 98.68)
Epoch: [52][390/391]	Time  0.026 ( 0.040)	Data  0.001 ( 0.001)	Loss 7.5688e-01 (4.4938e-01)	Acc@1  75.00 ( 85.88)	Acc@5  95.00 ( 98.67)
## e[52] optimizer.zero_grad (sum) time: 0.23844051361083984
## e[52]       loss.backward (sum) time: 3.747128486633301
## e[52]      optimizer.step (sum) time: 1.6290030479431152
## epoch[52] training(only) time: 15.77255129814148
# Switched to evaluate mode...
Test: [  0/100]	Time  0.159 ( 0.159)	Loss 1.4096e+00 (1.4096e+00)	Acc@1  64.00 ( 64.00)	Acc@5  91.00 ( 91.00)
Test: [ 10/100]	Time  0.018 ( 0.033)	Loss 1.5564e+00 (1.5137e+00)	Acc@1  61.00 ( 63.91)	Acc@5  91.00 ( 89.00)
Test: [ 20/100]	Time  0.024 ( 0.028)	Loss 1.3861e+00 (1.4680e+00)	Acc@1  69.00 ( 65.29)	Acc@5  93.00 ( 89.48)
Test: [ 30/100]	Time  0.023 ( 0.026)	Loss 1.8017e+00 (1.4810e+00)	Acc@1  60.00 ( 65.10)	Acc@5  87.00 ( 89.19)
Test: [ 40/100]	Time  0.024 ( 0.025)	Loss 1.5024e+00 (1.4688e+00)	Acc@1  66.00 ( 65.68)	Acc@5  89.00 ( 89.24)
Test: [ 50/100]	Time  0.020 ( 0.024)	Loss 1.4635e+00 (1.4647e+00)	Acc@1  68.00 ( 65.78)	Acc@5  91.00 ( 89.35)
Test: [ 60/100]	Time  0.024 ( 0.024)	Loss 1.7580e+00 (1.4392e+00)	Acc@1  59.00 ( 66.13)	Acc@5  84.00 ( 89.66)
Test: [ 70/100]	Time  0.023 ( 0.024)	Loss 1.6387e+00 (1.4390e+00)	Acc@1  67.00 ( 66.15)	Acc@5  87.00 ( 89.66)
Test: [ 80/100]	Time  0.024 ( 0.024)	Loss 1.6429e+00 (1.4455e+00)	Acc@1  65.00 ( 65.90)	Acc@5  87.00 ( 89.53)
Test: [ 90/100]	Time  0.024 ( 0.024)	Loss 1.8120e+00 (1.4380e+00)	Acc@1  58.00 ( 66.10)	Acc@5  84.00 ( 89.62)
 * Acc@1 66.150 Acc@5 89.780
### epoch[52] execution time: 18.214826107025146
EPOCH 53
REMOVING: module.fire3.squeeze.0.bias
REMOVING: module.fire3.squeeze.1.weight
REMOVING: module.fire3.squeeze.1.bias
i:   0, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.001124279298084823   to: 0.001003284447787805
i:   1, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.001211208110764027   to: 0.001027719895412492
i:   2, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.001319868960940767   to: 0.001075428738004757
i:   3, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.001449598565149456   to: 0.001145740611665579
i:   4, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.001599741877743076   to: 0.001237991876243032
i:   5, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.001769652500438500   to: 0.001351526132055319
i:   6, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.001958693050850917   to: 0.001485694690803640
i:   7, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.002166235492264739   to: 0.001639857003055194
i:   8, name:  module.fire4.squeeze.0.weight  changing lr from: 0.002391661426801899   to: 0.001813381044591977
i:   9, name:    module.fire4.squeeze.0.bias  changing lr from: 0.002634362354063446   to: 0.002005643663837352
i:  10, name:  module.fire4.squeeze.1.weight  changing lr from: 0.002893739897236396   to: 0.002216030892489334
i:  11, name:    module.fire4.squeeze.1.bias  changing lr from: 0.003169205998576124   to: 0.002443938221407676
i:  12, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.003460183086093754   to: 0.002688770843721077
i:  13, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.003766104213200105   to: 0.002949943867041887
i:  14, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.004086413172980746   to: 0.003226882496597782
i:  15, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.004420564588702624   to: 0.003519022191014148
i:  16, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.004768023982080077   to: 0.003825808792406642
i:  17, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.005128267820757758   to: 0.004146698632371098
i:  18, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.005500783546400028   to: 0.004481158615387414
i:  19, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.005885069584709973   to: 0.004828666281085991
i:  20, name:  module.fire5.squeeze.0.weight  changing lr from: 0.006280635338637907   to: 0.005188709846758266
i:  21, name:    module.fire5.squeeze.0.bias  changing lr from: 0.006687001165977063   to: 0.005560788231429164
i:  22, name:  module.fire5.squeeze.1.weight  changing lr from: 0.007103698342484787   to: 0.005944411062746185
i:  23, name:    module.fire5.squeeze.1.bias  changing lr from: 0.007530269011610562   to: 0.006339098667880311
i:  24, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.007966266121855975   to: 0.006744382049574759
i:  25, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.008411253352739890   to: 0.007159802848422275
i:  26, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.008864805030289451   to: 0.007584913292396472
i:  27, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.009326506032930008   to: 0.008019276134611574
i:  28, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.009795951688598342   to: 0.008462464580233369
i:  29, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.010272747663859650   to: 0.008914062203417034
i:  30, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.010756509845764678   to: 0.009373662855100332
i:  31, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.011246864217142171   to: 0.009840870562436072
i:  32, name:  module.fire6.squeeze.0.weight  changing lr from: 0.011743446725982216   to: 0.010315299420605665
i:  33, name:    module.fire6.squeeze.0.bias  changing lr from: 0.012245903149527761   to: 0.010796573477713761
i:  34, name:  module.fire6.squeeze.1.weight  changing lr from: 0.012753888953655795   to: 0.011284326613425173
i:  35, name:    module.fire6.squeeze.1.bias  changing lr from: 0.013267069148094536   to: 0.011778202411967632
i:  36, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.013785118137990621   to: 0.012277854030088187
i:  37, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.014307719572307948   to: 0.012782944060516221
i:  38, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.014834566189510741   to: 0.013293144391454004
i:  39, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.015365359660953655   to: 0.013808136062583454
i:  40, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.015899810432376243   to: 0.014327609118049162
i:  41, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.016437637563871187   to: 0.014851262456848046
i:  42, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.016978568568672636   to: 0.015378803681029739
i:  43, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.017522339251087204   to: 0.015909948942085510
i:  44, name:  module.fire7.squeeze.0.weight  changing lr from: 0.018068693543867625   to: 0.016444422785879632
i:  45, name:    module.fire7.squeeze.0.bias  changing lr from: 0.018617383345308613   to: 0.016981957996452881
i:  46, name:  module.fire7.squeeze.1.weight  changing lr from: 0.019168168356324077   to: 0.017522295439006363
i:  47, name:    module.fire7.squeeze.1.bias  changing lr from: 0.019720815917745993   to: 0.018065183902352584
i:  48, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.020275100848067714   to: 0.018610379941100676
i:  49, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.020830805281837006   to: 0.019157647717823630
i:  50, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.021387718508888667   to: 0.019706758845437846
i:  51, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.021945636814590504   to: 0.020257492230007543
i:  52, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.022504363321263595   to: 0.020809633914171368
i:  53, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.023063707830922597   to: 0.021362976921372425
i:  54, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.023623486669470607   to: 0.021917321101059230
i:  55, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.024183522532469817   to: 0.022472472975010895
i:  56, name:  module.fire8.squeeze.0.weight  changing lr from: 0.024743644332598992   to: 0.023028245584927654
i:  57, name:    module.fire8.squeeze.0.bias  changing lr from: 0.025303687048897124   to: 0.023584458341414712
i:  58, name:  module.fire8.squeeze.1.weight  changing lr from: 0.025863491577883681   to: 0.024140936874477228
i:  59, name:    module.fire8.squeeze.1.bias  changing lr from: 0.026422904586635421   to: 0.024697512885632263
i:  60, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.026981778367891465   to: 0.025254024001734030
i:  61, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.027539970697250199   to: 0.025810313630599185
i:  62, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.028097344692513196   to: 0.026366230818509664
i:  63, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.028653768675224435   to: 0.026921630109662212
i:  64, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.029209116034446477   to: 0.027476371407625891
i:  65, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.029763265092808334   to: 0.028030319838861575
i:  66, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.030316098974854357   to: 0.028583345618349906
i:  67, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.030867505477717400   to: 0.029135323917368280
i:  68, name:  module.fire9.squeeze.0.weight  changing lr from: 0.031417376944134996   to: 0.029686134733451122
i:  69, name:    module.fire9.squeeze.0.bias  changing lr from: 0.031965610137821607   to: 0.030235662762561621
i:  70, name:  module.fire9.squeeze.1.weight  changing lr from: 0.032512106121206419   to: 0.030783797273498555
i:  71, name:    module.fire9.squeeze.1.bias  changing lr from: 0.033056770135541223   to: 0.031330431984555943
i:  72, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.033599511483379731   to: 0.031875464942449500
i:  73, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.034140243413425482   to: 0.032418798403518870
i:  74, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.034678883007742745   to: 0.032960338717211081
i:  75, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.035215351071321267   to: 0.033499996211846704
i:  76, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.035749572023983510   to: 0.034037685082666892
i:  77, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.036281473794619865   to: 0.034573323282156183
i:  78, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.036810987717735159   to: 0.035106832412633071
i:  79, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.037338048432287961   to: 0.035638137621097722
i:  80, name:           module.conv10.weight  changing lr from: 0.037862593782801622   to: 0.036167167496323559
i:  81, name:             module.conv10.bias  changing lr from: 0.038384564722724716   to: 0.036693853968177349



# Switched to train mode...
Epoch: [53][  0/391]	Time  0.202 ( 0.202)	Data  0.156 ( 0.156)	Loss 4.4811e-01 (4.4811e-01)	Acc@1  84.38 ( 84.38)	Acc@5  98.44 ( 98.44)
Epoch: [53][ 10/391]	Time  0.038 ( 0.055)	Data  0.001 ( 0.015)	Loss 4.9830e-01 (4.4082e-01)	Acc@1  86.72 ( 86.86)	Acc@5  98.44 ( 98.72)
Epoch: [53][ 20/391]	Time  0.040 ( 0.048)	Data  0.001 ( 0.008)	Loss 3.8064e-01 (4.2750e-01)	Acc@1  89.84 ( 87.20)	Acc@5  98.44 ( 98.62)
Epoch: [53][ 30/391]	Time  0.037 ( 0.045)	Data  0.001 ( 0.006)	Loss 4.9322e-01 (4.2022e-01)	Acc@1  85.16 ( 87.73)	Acc@5  96.88 ( 98.59)
Epoch: [53][ 40/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.005)	Loss 4.4377e-01 (4.2711e-01)	Acc@1  88.28 ( 87.16)	Acc@5  98.44 ( 98.70)
Epoch: [53][ 50/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.004)	Loss 3.4297e-01 (4.2869e-01)	Acc@1  89.06 ( 86.89)	Acc@5  99.22 ( 98.68)
Epoch: [53][ 60/391]	Time  0.037 ( 0.042)	Data  0.001 ( 0.004)	Loss 3.2065e-01 (4.2252e-01)	Acc@1  87.50 ( 87.08)	Acc@5 100.00 ( 98.69)
Epoch: [53][ 70/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.003)	Loss 3.7100e-01 (4.2027e-01)	Acc@1  85.16 ( 86.95)	Acc@5  99.22 ( 98.76)
Epoch: [53][ 80/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.003)	Loss 4.4142e-01 (4.2061e-01)	Acc@1  82.81 ( 86.86)	Acc@5  97.66 ( 98.80)
Epoch: [53][ 90/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.003)	Loss 3.2114e-01 (4.1616e-01)	Acc@1  88.28 ( 87.01)	Acc@5 100.00 ( 98.79)
Epoch: [53][100/391]	Time  0.037 ( 0.041)	Data  0.001 ( 0.003)	Loss 2.8624e-01 (4.1599e-01)	Acc@1  91.41 ( 87.04)	Acc@5  99.22 ( 98.80)
Epoch: [53][110/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.5062e-01 (4.1788e-01)	Acc@1  87.50 ( 86.97)	Acc@5  99.22 ( 98.73)
Epoch: [53][120/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.3532e-01 (4.1762e-01)	Acc@1  86.72 ( 86.98)	Acc@5 100.00 ( 98.73)
Epoch: [53][130/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.0600e-01 (4.1611e-01)	Acc@1  80.47 ( 87.05)	Acc@5  98.44 ( 98.75)
Epoch: [53][140/391]	Time  0.038 ( 0.040)	Data  0.001 ( 0.002)	Loss 4.8052e-01 (4.1715e-01)	Acc@1  85.94 ( 87.02)	Acc@5  96.09 ( 98.74)
Epoch: [53][150/391]	Time  0.046 ( 0.040)	Data  0.001 ( 0.002)	Loss 4.4838e-01 (4.1579e-01)	Acc@1  86.72 ( 87.12)	Acc@5  99.22 ( 98.76)
Epoch: [53][160/391]	Time  0.041 ( 0.040)	Data  0.001 ( 0.002)	Loss 3.2755e-01 (4.1929e-01)	Acc@1  88.28 ( 87.01)	Acc@5 100.00 ( 98.72)
Epoch: [53][170/391]	Time  0.038 ( 0.040)	Data  0.001 ( 0.002)	Loss 3.2263e-01 (4.1980e-01)	Acc@1  92.97 ( 86.99)	Acc@5  98.44 ( 98.72)
Epoch: [53][180/391]	Time  0.039 ( 0.040)	Data  0.001 ( 0.002)	Loss 4.4266e-01 (4.1902e-01)	Acc@1  86.72 ( 87.03)	Acc@5  99.22 ( 98.73)
Epoch: [53][190/391]	Time  0.040 ( 0.040)	Data  0.001 ( 0.002)	Loss 4.9802e-01 (4.1925e-01)	Acc@1  80.47 ( 86.99)	Acc@5  99.22 ( 98.75)
Epoch: [53][200/391]	Time  0.041 ( 0.040)	Data  0.001 ( 0.002)	Loss 4.5500e-01 (4.2197e-01)	Acc@1  85.16 ( 86.93)	Acc@5  99.22 ( 98.74)
Epoch: [53][210/391]	Time  0.037 ( 0.040)	Data  0.001 ( 0.002)	Loss 3.0996e-01 (4.2209e-01)	Acc@1  89.06 ( 86.87)	Acc@5 100.00 ( 98.76)
Epoch: [53][220/391]	Time  0.038 ( 0.040)	Data  0.001 ( 0.002)	Loss 5.2369e-01 (4.2421e-01)	Acc@1  82.03 ( 86.79)	Acc@5  98.44 ( 98.75)
Epoch: [53][230/391]	Time  0.037 ( 0.040)	Data  0.001 ( 0.002)	Loss 4.1277e-01 (4.2376e-01)	Acc@1  88.28 ( 86.81)	Acc@5  98.44 ( 98.75)
Epoch: [53][240/391]	Time  0.038 ( 0.040)	Data  0.001 ( 0.002)	Loss 3.7278e-01 (4.2340e-01)	Acc@1  89.84 ( 86.82)	Acc@5  99.22 ( 98.76)
Epoch: [53][250/391]	Time  0.038 ( 0.040)	Data  0.002 ( 0.002)	Loss 3.7380e-01 (4.2348e-01)	Acc@1  87.50 ( 86.83)	Acc@5  99.22 ( 98.76)
Epoch: [53][260/391]	Time  0.038 ( 0.040)	Data  0.001 ( 0.002)	Loss 3.3263e-01 (4.2280e-01)	Acc@1  90.62 ( 86.85)	Acc@5 100.00 ( 98.77)
Epoch: [53][270/391]	Time  0.040 ( 0.040)	Data  0.001 ( 0.002)	Loss 5.5647e-01 (4.2422e-01)	Acc@1  83.59 ( 86.78)	Acc@5  96.88 ( 98.77)
Epoch: [53][280/391]	Time  0.037 ( 0.040)	Data  0.001 ( 0.002)	Loss 4.3828e-01 (4.2485e-01)	Acc@1  83.59 ( 86.72)	Acc@5  98.44 ( 98.77)
Epoch: [53][290/391]	Time  0.037 ( 0.040)	Data  0.001 ( 0.002)	Loss 4.4106e-01 (4.2594e-01)	Acc@1  86.72 ( 86.68)	Acc@5  98.44 ( 98.75)
Epoch: [53][300/391]	Time  0.038 ( 0.040)	Data  0.001 ( 0.002)	Loss 3.4204e-01 (4.2692e-01)	Acc@1  90.62 ( 86.67)	Acc@5  99.22 ( 98.73)
Epoch: [53][310/391]	Time  0.041 ( 0.040)	Data  0.001 ( 0.002)	Loss 4.7985e-01 (4.2735e-01)	Acc@1  82.81 ( 86.64)	Acc@5  97.66 ( 98.74)
Epoch: [53][320/391]	Time  0.038 ( 0.040)	Data  0.001 ( 0.001)	Loss 4.7551e-01 (4.2825e-01)	Acc@1  83.59 ( 86.58)	Acc@5  98.44 ( 98.73)
Epoch: [53][330/391]	Time  0.037 ( 0.040)	Data  0.001 ( 0.001)	Loss 4.2810e-01 (4.2897e-01)	Acc@1  88.28 ( 86.59)	Acc@5  98.44 ( 98.70)
Epoch: [53][340/391]	Time  0.038 ( 0.040)	Data  0.001 ( 0.001)	Loss 4.0037e-01 (4.3054e-01)	Acc@1  85.16 ( 86.54)	Acc@5  99.22 ( 98.69)
Epoch: [53][350/391]	Time  0.038 ( 0.040)	Data  0.001 ( 0.001)	Loss 4.0995e-01 (4.3146e-01)	Acc@1  89.06 ( 86.51)	Acc@5  97.66 ( 98.68)
Epoch: [53][360/391]	Time  0.040 ( 0.040)	Data  0.001 ( 0.001)	Loss 5.2018e-01 (4.3251e-01)	Acc@1  82.03 ( 86.50)	Acc@5  98.44 ( 98.67)
Epoch: [53][370/391]	Time  0.037 ( 0.040)	Data  0.001 ( 0.001)	Loss 4.9073e-01 (4.3255e-01)	Acc@1  85.94 ( 86.50)	Acc@5  99.22 ( 98.68)
Epoch: [53][380/391]	Time  0.044 ( 0.040)	Data  0.001 ( 0.001)	Loss 4.0281e-01 (4.3295e-01)	Acc@1  85.94 ( 86.49)	Acc@5  99.22 ( 98.68)
Epoch: [53][390/391]	Time  0.031 ( 0.040)	Data  0.001 ( 0.001)	Loss 5.6446e-01 (4.3341e-01)	Acc@1  78.75 ( 86.47)	Acc@5  97.50 ( 98.68)
## e[53] optimizer.zero_grad (sum) time: 0.23230910301208496
## e[53]       loss.backward (sum) time: 3.686126708984375
## e[53]      optimizer.step (sum) time: 1.583254098892212
## epoch[53] training(only) time: 15.557305097579956
# Switched to evaluate mode...
Test: [  0/100]	Time  0.154 ( 0.154)	Loss 1.1608e+00 (1.1608e+00)	Acc@1  69.00 ( 69.00)	Acc@5  87.00 ( 87.00)
Test: [ 10/100]	Time  0.024 ( 0.034)	Loss 1.5871e+00 (1.4427e+00)	Acc@1  63.00 ( 66.82)	Acc@5  88.00 ( 88.55)
Test: [ 20/100]	Time  0.024 ( 0.028)	Loss 1.2447e+00 (1.3949e+00)	Acc@1  70.00 ( 67.52)	Acc@5  95.00 ( 89.57)
Test: [ 30/100]	Time  0.023 ( 0.026)	Loss 1.5936e+00 (1.4061e+00)	Acc@1  61.00 ( 66.97)	Acc@5  90.00 ( 89.81)
Test: [ 40/100]	Time  0.021 ( 0.026)	Loss 1.3757e+00 (1.3975e+00)	Acc@1  68.00 ( 67.10)	Acc@5  94.00 ( 90.12)
Test: [ 50/100]	Time  0.024 ( 0.025)	Loss 1.4182e+00 (1.4012e+00)	Acc@1  67.00 ( 66.90)	Acc@5  90.00 ( 90.00)
Test: [ 60/100]	Time  0.023 ( 0.025)	Loss 1.5099e+00 (1.3736e+00)	Acc@1  63.00 ( 67.31)	Acc@5  86.00 ( 90.31)
Test: [ 70/100]	Time  0.022 ( 0.024)	Loss 1.6204e+00 (1.3770e+00)	Acc@1  63.00 ( 67.32)	Acc@5  88.00 ( 90.27)
Test: [ 80/100]	Time  0.024 ( 0.024)	Loss 1.6445e+00 (1.3869e+00)	Acc@1  67.00 ( 67.25)	Acc@5  87.00 ( 90.20)
Test: [ 90/100]	Time  0.024 ( 0.024)	Loss 1.9667e+00 (1.3816e+00)	Acc@1  57.00 ( 67.24)	Acc@5  87.00 ( 90.32)
 * Acc@1 67.460 Acc@5 90.430
### epoch[53] execution time: 18.003246545791626
EPOCH 54
REMOVING: module.fire3.expand_1x1.0.weight
REMOVING: module.fire3.expand_1x1.0.bias
REMOVING: module.fire3.expand_1x1.1.weight
i:   0, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.001145740611665579   to: 0.001008589481088367
i:   1, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.001237991876243032   to: 0.001040343096861406
i:   2, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.001351526132055319   to: 0.001094871519790279
i:   3, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.001485694690803640   to: 0.001171518811375115
i:   4, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.001639857003055194   to: 0.001269635752869113
i:   5, name:  module.fire4.squeeze.0.weight  changing lr from: 0.001813381044591977   to: 0.001388580332245936
i:   6, name:    module.fire4.squeeze.0.bias  changing lr from: 0.002005643663837352   to: 0.001527718187744525
i:   7, name:  module.fire4.squeeze.1.weight  changing lr from: 0.002216030892489334   to: 0.001686423010245507
i:   8, name:    module.fire4.squeeze.1.bias  changing lr from: 0.002443938221407676   to: 0.001864076906653316
i:   9, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.002688770843721077   to: 0.002060070726378409
i:  10, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.002949943867041887   to: 0.002273804352935482
i:  11, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.003226882496597782   to: 0.002504686962595886
i:  12, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.003519022191014148   to: 0.002752137251956093
i:  13, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.003825808792406642   to: 0.003015583636209173
i:  14, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.004146698632371098   to: 0.003294464419832793
i:  15, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.004481158615387414   to: 0.003588227941335242
i:  16, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.004828666281085991   to: 0.003896332693631160
i:  17, name:  module.fire5.squeeze.0.weight  changing lr from: 0.005188709846758266   to: 0.004218247421549947
i:  18, name:    module.fire5.squeeze.0.bias  changing lr from: 0.005560788231429164   to: 0.004553451197913643
i:  19, name:  module.fire5.squeeze.1.weight  changing lr from: 0.005944411062746185   to: 0.004901433479555855
i:  20, name:    module.fire5.squeeze.1.bias  changing lr from: 0.006339098667880311   to: 0.005261694144591349
i:  21, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.006744382049574759   to: 0.005633743512184075
i:  22, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.007159802848422275   to: 0.006017102346003378
i:  23, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.007584913292396472   to: 0.006411301842500394
i:  24, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.008019276134611574   to: 0.006815883605082395
i:  25, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.008462464580233369   to: 0.007230399605208665
i:  26, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.008914062203417034   to: 0.007654412131381244
i:  27, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.009373662855100332   to: 0.008087493726953865
i:  28, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.009840870562436072   to: 0.008529227117635157
i:  29, name:  module.fire6.squeeze.0.weight  changing lr from: 0.010315299420605665   to: 0.008979205129516447
i:  30, name:    module.fire6.squeeze.0.bias  changing lr from: 0.010796573477713761   to: 0.009437030598410695
i:  31, name:  module.fire6.squeeze.1.weight  changing lr from: 0.011284326613425173   to: 0.009902316271246752
i:  32, name:    module.fire6.squeeze.1.bias  changing lr from: 0.011778202411967632   to: 0.010374684700222712
i:  33, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.012277854030088187   to: 0.010853768130383912
i:  34, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.012782944060516221   to: 0.011339208381252956
i:  35, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.013293144391454004   to: 0.011830656723104949
i:  36, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.013808136062583454   to: 0.012327773748445636
i:  37, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.014327609118049162   to: 0.012830229239219299
i:  38, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.014851262456848046   to: 0.013337702030240661
i:  39, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.015378803681029739   to: 0.013849879869316573
i:  40, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.015909948942085510   to: 0.014366459274494377
i:  41, name:  module.fire7.squeeze.0.weight  changing lr from: 0.016444422785879632   to: 0.014887145388847178
i:  42, name:    module.fire7.squeeze.0.bias  changing lr from: 0.016981957996452881   to: 0.015411651833180523
i:  43, name:  module.fire7.squeeze.1.weight  changing lr from: 0.017522295439006363   to: 0.015939700557020375
i:  44, name:    module.fire7.squeeze.1.bias  changing lr from: 0.018065183902352584   to: 0.016471021688219307
i:  45, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.018610379941100676   to: 0.017005353381495402
i:  46, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.019157647717823630   to: 0.017542441666197606
i:  47, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.019706758845437846   to: 0.018082040293571161
i:  48, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.020257492230007543   to: 0.018623910583777475
i:  49, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.020809633914171368   to: 0.019167821272905800
i:  50, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.021362976921372425   to: 0.019713548360195315
i:  51, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.021917321101059230   to: 0.020260874955672276
i:  52, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.022472472975010895   to: 0.020809591128389218
i:  53, name:  module.fire8.squeeze.0.weight  changing lr from: 0.023028245584927654   to: 0.021359493755440724
i:  54, name:    module.fire8.squeeze.0.bias  changing lr from: 0.023584458341414712   to: 0.021910386371915086
i:  55, name:  module.fire8.squeeze.1.weight  changing lr from: 0.024140936874477228   to: 0.022462079021929284
i:  56, name:    module.fire8.squeeze.1.bias  changing lr from: 0.024697512885632263   to: 0.023014388110881967
i:  57, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.025254024001734030   to: 0.023567136259047092
i:  58, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.025810313630599185   to: 0.024120152156621479
i:  59, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.026366230818509664   to: 0.024673270420327388
i:  60, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.026921630109662212   to: 0.025226331451663003
i:  61, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.027476371407625891   to: 0.025779181296883804
i:  62, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.028030319838861575   to: 0.026331671508789622
i:  63, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.028583345618349906   to: 0.026883659010383816
i:  64, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.029135323917368280   to: 0.027435005960463738
i:  65, name:  module.fire9.squeeze.0.weight  changing lr from: 0.029686134733451122   to: 0.027985579621194429
i:  66, name:    module.fire9.squeeze.0.bias  changing lr from: 0.030235662762561621   to: 0.028535252227710497
i:  67, name:  module.fire9.squeeze.1.weight  changing lr from: 0.030783797273498555   to: 0.029083900859785752
i:  68, name:    module.fire9.squeeze.1.bias  changing lr from: 0.031330431984555943   to: 0.029631407315603178
i:  69, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.031875464942449500   to: 0.030177657987653497
i:  70, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.032418798403518870   to: 0.030722543740784536
i:  71, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.032960338717211081   to: 0.031265959792419626
i:  72, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.033499996211846704   to: 0.031807805594958050
i:  73, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.034037685082666892   to: 0.032347984720367269
i:  74, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.034573323282156183   to: 0.032886404746972263
i:  75, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.035106832412633071   to: 0.033422977148443604
i:  76, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.035638137621097722   to: 0.033957617184983295
i:  77, name:           module.conv10.weight  changing lr from: 0.036167167496323559   to: 0.034490243796703700
i:  78, name:             module.conv10.bias  changing lr from: 0.036693853968177349   to: 0.035020779499192356



# Switched to train mode...
Epoch: [54][  0/391]	Time  0.199 ( 0.199)	Data  0.155 ( 0.155)	Loss 4.3252e-01 (4.3252e-01)	Acc@1  81.25 ( 81.25)	Acc@5  98.44 ( 98.44)
Epoch: [54][ 10/391]	Time  0.041 ( 0.054)	Data  0.001 ( 0.015)	Loss 4.0223e-01 (4.1968e-01)	Acc@1  89.06 ( 86.58)	Acc@5  99.22 ( 99.01)
Epoch: [54][ 20/391]	Time  0.039 ( 0.047)	Data  0.001 ( 0.008)	Loss 4.5043e-01 (4.1288e-01)	Acc@1  84.38 ( 87.13)	Acc@5  98.44 ( 98.77)
Epoch: [54][ 30/391]	Time  0.038 ( 0.045)	Data  0.001 ( 0.006)	Loss 3.3297e-01 (4.1255e-01)	Acc@1  86.72 ( 87.12)	Acc@5  99.22 ( 98.71)
Epoch: [54][ 40/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.005)	Loss 3.4003e-01 (4.0905e-01)	Acc@1  89.06 ( 87.27)	Acc@5  98.44 ( 98.74)
Epoch: [54][ 50/391]	Time  0.037 ( 0.043)	Data  0.001 ( 0.004)	Loss 3.9531e-01 (4.0185e-01)	Acc@1  89.84 ( 87.58)	Acc@5  98.44 ( 98.85)
Epoch: [54][ 60/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.003)	Loss 5.3016e-01 (3.9954e-01)	Acc@1  80.47 ( 87.37)	Acc@5  99.22 ( 98.90)
Epoch: [54][ 70/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.003)	Loss 4.3960e-01 (3.9989e-01)	Acc@1  83.59 ( 87.48)	Acc@5  98.44 ( 98.89)
Epoch: [54][ 80/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.003)	Loss 4.2830e-01 (3.9768e-01)	Acc@1  86.72 ( 87.54)	Acc@5  97.66 ( 98.91)
Epoch: [54][ 90/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.003)	Loss 4.1377e-01 (3.9818e-01)	Acc@1  85.94 ( 87.47)	Acc@5  99.22 ( 98.84)
Epoch: [54][100/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.5644e-01 (3.9951e-01)	Acc@1  85.94 ( 87.41)	Acc@5  98.44 ( 98.85)
Epoch: [54][110/391]	Time  0.041 ( 0.040)	Data  0.001 ( 0.002)	Loss 5.4473e-01 (4.0060e-01)	Acc@1  82.03 ( 87.36)	Acc@5  98.44 ( 98.87)
Epoch: [54][120/391]	Time  0.039 ( 0.040)	Data  0.001 ( 0.002)	Loss 4.3195e-01 (4.0111e-01)	Acc@1  85.94 ( 87.44)	Acc@5  99.22 ( 98.86)
Epoch: [54][130/391]	Time  0.040 ( 0.040)	Data  0.001 ( 0.002)	Loss 3.5004e-01 (4.0035e-01)	Acc@1  86.72 ( 87.48)	Acc@5  99.22 ( 98.91)
Epoch: [54][140/391]	Time  0.038 ( 0.040)	Data  0.001 ( 0.002)	Loss 3.2996e-01 (3.9846e-01)	Acc@1  89.84 ( 87.59)	Acc@5 100.00 ( 98.92)
Epoch: [54][150/391]	Time  0.042 ( 0.040)	Data  0.001 ( 0.002)	Loss 4.5397e-01 (4.0178e-01)	Acc@1  85.16 ( 87.49)	Acc@5  99.22 ( 98.89)
Epoch: [54][160/391]	Time  0.039 ( 0.040)	Data  0.001 ( 0.002)	Loss 4.8754e-01 (4.0253e-01)	Acc@1  85.94 ( 87.53)	Acc@5  98.44 ( 98.90)
Epoch: [54][170/391]	Time  0.038 ( 0.040)	Data  0.001 ( 0.002)	Loss 3.7077e-01 (4.0070e-01)	Acc@1  87.50 ( 87.62)	Acc@5 100.00 ( 98.91)
Epoch: [54][180/391]	Time  0.049 ( 0.040)	Data  0.001 ( 0.002)	Loss 4.1996e-01 (4.0197e-01)	Acc@1  89.06 ( 87.60)	Acc@5  99.22 ( 98.90)
Epoch: [54][190/391]	Time  0.038 ( 0.040)	Data  0.001 ( 0.002)	Loss 3.6839e-01 (4.0100e-01)	Acc@1  89.84 ( 87.57)	Acc@5  98.44 ( 98.93)
Epoch: [54][200/391]	Time  0.043 ( 0.040)	Data  0.001 ( 0.002)	Loss 5.3504e-01 (4.0090e-01)	Acc@1  86.72 ( 87.57)	Acc@5  98.44 ( 98.95)
Epoch: [54][210/391]	Time  0.038 ( 0.040)	Data  0.001 ( 0.002)	Loss 3.2463e-01 (4.0157e-01)	Acc@1  88.28 ( 87.52)	Acc@5  99.22 ( 98.95)
Epoch: [54][220/391]	Time  0.038 ( 0.040)	Data  0.001 ( 0.002)	Loss 2.9070e-01 (4.0199e-01)	Acc@1  90.62 ( 87.50)	Acc@5 100.00 ( 98.97)
Epoch: [54][230/391]	Time  0.039 ( 0.040)	Data  0.001 ( 0.002)	Loss 4.4392e-01 (4.0227e-01)	Acc@1  87.50 ( 87.52)	Acc@5  96.88 ( 98.96)
Epoch: [54][240/391]	Time  0.039 ( 0.040)	Data  0.001 ( 0.002)	Loss 5.0485e-01 (4.0280e-01)	Acc@1  85.16 ( 87.51)	Acc@5  99.22 ( 98.96)
Epoch: [54][250/391]	Time  0.037 ( 0.040)	Data  0.001 ( 0.002)	Loss 3.9804e-01 (4.0388e-01)	Acc@1  86.72 ( 87.49)	Acc@5  99.22 ( 98.95)
Epoch: [54][260/391]	Time  0.039 ( 0.040)	Data  0.001 ( 0.002)	Loss 3.5006e-01 (4.0448e-01)	Acc@1  88.28 ( 87.45)	Acc@5  99.22 ( 98.96)
Epoch: [54][270/391]	Time  0.039 ( 0.040)	Data  0.001 ( 0.002)	Loss 5.1766e-01 (4.0531e-01)	Acc@1  82.81 ( 87.46)	Acc@5  97.66 ( 98.94)
Epoch: [54][280/391]	Time  0.038 ( 0.040)	Data  0.001 ( 0.002)	Loss 4.5220e-01 (4.0841e-01)	Acc@1  85.94 ( 87.34)	Acc@5 100.00 ( 98.92)
Epoch: [54][290/391]	Time  0.041 ( 0.040)	Data  0.001 ( 0.001)	Loss 4.5595e-01 (4.0980e-01)	Acc@1  84.38 ( 87.32)	Acc@5  97.66 ( 98.89)
Epoch: [54][300/391]	Time  0.038 ( 0.040)	Data  0.001 ( 0.001)	Loss 5.9138e-01 (4.1110e-01)	Acc@1  79.69 ( 87.30)	Acc@5  96.88 ( 98.89)
Epoch: [54][310/391]	Time  0.037 ( 0.040)	Data  0.001 ( 0.001)	Loss 4.0864e-01 (4.1140e-01)	Acc@1  89.06 ( 87.29)	Acc@5  99.22 ( 98.89)
Epoch: [54][320/391]	Time  0.037 ( 0.040)	Data  0.001 ( 0.001)	Loss 3.3390e-01 (4.1094e-01)	Acc@1  86.72 ( 87.29)	Acc@5 100.00 ( 98.90)
Epoch: [54][330/391]	Time  0.041 ( 0.040)	Data  0.001 ( 0.001)	Loss 4.1103e-01 (4.1142e-01)	Acc@1  86.72 ( 87.25)	Acc@5  99.22 ( 98.89)
Epoch: [54][340/391]	Time  0.039 ( 0.040)	Data  0.001 ( 0.001)	Loss 4.3849e-01 (4.1156e-01)	Acc@1  83.59 ( 87.23)	Acc@5  97.66 ( 98.89)
Epoch: [54][350/391]	Time  0.043 ( 0.040)	Data  0.001 ( 0.001)	Loss 3.7072e-01 (4.1204e-01)	Acc@1  88.28 ( 87.21)	Acc@5  99.22 ( 98.88)
Epoch: [54][360/391]	Time  0.038 ( 0.040)	Data  0.001 ( 0.001)	Loss 4.0799e-01 (4.1193e-01)	Acc@1  87.50 ( 87.20)	Acc@5  99.22 ( 98.88)
Epoch: [54][370/391]	Time  0.037 ( 0.040)	Data  0.001 ( 0.001)	Loss 4.2615e-01 (4.1215e-01)	Acc@1  84.38 ( 87.18)	Acc@5  98.44 ( 98.88)
Epoch: [54][380/391]	Time  0.040 ( 0.039)	Data  0.001 ( 0.001)	Loss 3.7399e-01 (4.1185e-01)	Acc@1  89.84 ( 87.18)	Acc@5 100.00 ( 98.88)
Epoch: [54][390/391]	Time  0.026 ( 0.039)	Data  0.001 ( 0.001)	Loss 4.2091e-01 (4.1249e-01)	Acc@1  86.25 ( 87.16)	Acc@5  98.75 ( 98.88)
## e[54] optimizer.zero_grad (sum) time: 0.22358393669128418
## e[54]       loss.backward (sum) time: 3.6234583854675293
## e[54]      optimizer.step (sum) time: 1.5017023086547852
## epoch[54] training(only) time: 15.513853073120117
# Switched to evaluate mode...
Test: [  0/100]	Time  0.158 ( 0.158)	Loss 1.2922e+00 (1.2922e+00)	Acc@1  68.00 ( 68.00)	Acc@5  89.00 ( 89.00)
Test: [ 10/100]	Time  0.020 ( 0.034)	Loss 1.4041e+00 (1.4490e+00)	Acc@1  68.00 ( 67.09)	Acc@5  89.00 ( 88.82)
Test: [ 20/100]	Time  0.023 ( 0.028)	Loss 1.1523e+00 (1.4042e+00)	Acc@1  71.00 ( 68.29)	Acc@5  91.00 ( 89.48)
Test: [ 30/100]	Time  0.021 ( 0.026)	Loss 1.6329e+00 (1.4421e+00)	Acc@1  60.00 ( 67.13)	Acc@5  88.00 ( 89.29)
Test: [ 40/100]	Time  0.024 ( 0.025)	Loss 1.5169e+00 (1.4241e+00)	Acc@1  63.00 ( 67.15)	Acc@5  87.00 ( 89.46)
Test: [ 50/100]	Time  0.024 ( 0.025)	Loss 1.5956e+00 (1.4348e+00)	Acc@1  68.00 ( 66.94)	Acc@5  88.00 ( 89.43)
Test: [ 60/100]	Time  0.024 ( 0.025)	Loss 1.5612e+00 (1.4142e+00)	Acc@1  60.00 ( 66.85)	Acc@5  86.00 ( 89.77)
Test: [ 70/100]	Time  0.021 ( 0.025)	Loss 1.5759e+00 (1.4168e+00)	Acc@1  68.00 ( 66.77)	Acc@5  87.00 ( 89.70)
Test: [ 80/100]	Time  0.023 ( 0.024)	Loss 1.5740e+00 (1.4266e+00)	Acc@1  67.00 ( 66.85)	Acc@5  90.00 ( 89.59)
Test: [ 90/100]	Time  0.021 ( 0.024)	Loss 1.9749e+00 (1.4208e+00)	Acc@1  63.00 ( 66.91)	Acc@5  83.00 ( 89.69)
 * Acc@1 67.130 Acc@5 89.850
### epoch[54] execution time: 17.946696043014526
EPOCH 55
REMOVING: module.fire3.expand_1x1.1.bias
REMOVING: module.fire3.expand_3x3.0.weight
i:   0, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.001094871519790279   to: 0.001000523381565803
i:   1, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.001171518811375115   to: 0.001017173165621964
i:   2, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.001269635752869113   to: 0.001056742984833974
i:   3, name:  module.fire4.squeeze.0.weight  changing lr from: 0.001388580332245936   to: 0.001118584818423256
i:   4, name:    module.fire4.squeeze.0.bias  changing lr from: 0.001527718187744525   to: 0.001202056869053641
i:   5, name:  module.fire4.squeeze.1.weight  changing lr from: 0.001686423010245507   to: 0.001306524063958424
i:   6, name:    module.fire4.squeeze.1.bias  changing lr from: 0.001864076906653316   to: 0.001431358512736174
i:   7, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.002060070726378409   to: 0.001575939924025915
i:   8, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.002273804352935482   to: 0.001739655983196153
i:   9, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.002504686962595886   to: 0.001921902693105492
i:  10, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.002752137251956093   to: 0.002122084679917457
i:  11, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.003015583636209173   to: 0.002339615465877331
i:  12, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.003294464419832793   to: 0.002573917710885370
i:  13, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.003588227941335242   to: 0.002824423424628363
i:  14, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.003896332693631160   to: 0.003090574150960734
i:  15, name:  module.fire5.squeeze.0.weight  changing lr from: 0.004218247421549947   to: 0.003371821126156576
i:  16, name:    module.fire5.squeeze.0.bias  changing lr from: 0.004553451197913643   to: 0.003667625412586428
i:  17, name:  module.fire5.squeeze.1.weight  changing lr from: 0.004901433479555855   to: 0.003977458009305822
i:  18, name:    module.fire5.squeeze.1.bias  changing lr from: 0.005261694144591349   to: 0.004300799940978644
i:  19, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.005633743512184075   to: 0.004637142326494619
i:  20, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.006017102346003378   to: 0.004985986428580013
i:  21, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.006411301842500394   to: 0.005346843685640467
i:  22, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.006815883605082395   to: 0.005719235727018267
i:  23, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.007230399605208665   to: 0.006102694372789741
i:  24, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.007654412131381244   to: 0.006496761619175572
i:  25, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.008087493726953865   to: 0.006900989610583990
i:  26, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.008529227117635157   to: 0.007314940599257202
i:  27, name:  module.fire6.squeeze.0.weight  changing lr from: 0.008979205129516447   to: 0.007738186893442750
i:  28, name:    module.fire6.squeeze.0.bias  changing lr from: 0.009437030598410695   to: 0.008170310794964830
i:  29, name:  module.fire6.squeeze.1.weight  changing lr from: 0.009902316271246752   to: 0.008610904527026009
i:  30, name:    module.fire6.squeeze.1.bias  changing lr from: 0.010374684700222712   to: 0.009059570153025876
i:  31, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.010853768130383912   to: 0.009515919487143077
i:  32, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.011339208381252956   to: 0.009979573997385610
i:  33, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.011830656723104949   to: 0.010450164701777731
i:  34, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.012327773748445636   to: 0.010927332058313682
i:  35, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.012830229239219299   to: 0.011410725849274883
i:  36, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.013337702030240661   to: 0.011900005060472278
i:  37, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.013849879869316573   to: 0.012394837755944209
i:  38, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.014366459274494377   to: 0.012894900948609223
i:  39, name:  module.fire7.squeeze.0.weight  changing lr from: 0.014887145388847178   to: 0.013399880467343868
i:  40, name:    module.fire7.squeeze.0.bias  changing lr from: 0.015411651833180523   to: 0.013909470820927687
i:  41, name:  module.fire7.squeeze.1.weight  changing lr from: 0.015939700557020375   to: 0.014423375059270445
i:  42, name:    module.fire7.squeeze.1.bias  changing lr from: 0.016471021688219307   to: 0.014941304632311476
i:  43, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.017005353381495402   to: 0.015462979246956981
i:  44, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.017542441666197606   to: 0.015988126722397099
i:  45, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.018082040293571161   to: 0.016516482844123586
i:  46, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.018623910583777475   to: 0.017047791216947078
i:  47, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.019167821272905800   to: 0.017581803117293821
i:  48, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.019713548360195315   to: 0.018118277345041751
i:  49, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.020260874955672276   to: 0.018656980075139242
i:  50, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.020809591128389218   to: 0.019197684709231427
i:  51, name:  module.fire8.squeeze.0.weight  changing lr from: 0.021359493755440724   to: 0.019740171727503530
i:  52, name:    module.fire8.squeeze.0.bias  changing lr from: 0.021910386371915086   to: 0.020284228540935197
i:  53, name:  module.fire8.squeeze.1.weight  changing lr from: 0.022462079021929284   to: 0.020829649344145426
i:  54, name:    module.fire8.squeeze.1.bias  changing lr from: 0.023014388110881967   to: 0.021376234968993435
i:  55, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.023567136259047092   to: 0.021923792739088201
i:  56, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.024120152156621479   to: 0.022472136325347471
i:  57, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.024673270420327388   to: 0.023021085602734109
i:  58, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.025226331451663003   to: 0.023570466508288410
i:  59, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.025779181296883804   to: 0.024120110900562972
i:  60, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.026331671508789622   to: 0.024669856420558491
i:  61, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.026883659010383816   to: 0.025219546354248001
i:  62, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.027435005960463738   to: 0.025769029496770086
i:  63, name:  module.fire9.squeeze.0.weight  changing lr from: 0.027985579621194429   to: 0.026318160018362097
i:  64, name:    module.fire9.squeeze.0.bias  changing lr from: 0.028535252227710497   to: 0.026866797332097372
i:  65, name:  module.fire9.squeeze.1.weight  changing lr from: 0.029083900859785752   to: 0.027414805963483224
i:  66, name:    module.fire9.squeeze.1.bias  changing lr from: 0.029631407315603178   to: 0.027962055421969424
i:  67, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.030177657987653497   to: 0.028508420074410862
i:  68, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.030722543740784536   to: 0.029053779020521798
i:  69, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.031265959792419626   to: 0.029598015970353914
i:  70, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.031807805594958050   to: 0.030141019123824764
i:  71, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.032347984720367269   to: 0.030682681052318667
i:  72, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.032886404746972263   to: 0.031222898582377534
i:  73, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.033422977148443604   to: 0.031761572681494335
i:  74, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.033957617184983295   to: 0.032298608346018845
i:  75, name:           module.conv10.weight  changing lr from: 0.034490243796703700   to: 0.032833914491181067
i:  76, name:             module.conv10.bias  changing lr from: 0.035020779499192356   to: 0.033367403843234243



# Switched to train mode...
Epoch: [55][  0/391]	Time  0.196 ( 0.196)	Data  0.152 ( 0.152)	Loss 3.8216e-01 (3.8216e-01)	Acc@1  87.50 ( 87.50)	Acc@5  99.22 ( 99.22)
Epoch: [55][ 10/391]	Time  0.040 ( 0.054)	Data  0.001 ( 0.015)	Loss 3.9961e-01 (3.5196e-01)	Acc@1  88.28 ( 89.06)	Acc@5  99.22 ( 99.43)
Epoch: [55][ 20/391]	Time  0.040 ( 0.047)	Data  0.001 ( 0.008)	Loss 3.7075e-01 (3.6239e-01)	Acc@1  84.38 ( 89.14)	Acc@5 100.00 ( 99.26)
Epoch: [55][ 30/391]	Time  0.041 ( 0.044)	Data  0.001 ( 0.006)	Loss 3.9279e-01 (3.7962e-01)	Acc@1  87.50 ( 88.56)	Acc@5  99.22 ( 98.97)
Epoch: [55][ 40/391]	Time  0.037 ( 0.043)	Data  0.001 ( 0.005)	Loss 5.6433e-01 (3.9433e-01)	Acc@1  83.59 ( 88.07)	Acc@5  97.66 ( 98.93)
Epoch: [55][ 50/391]	Time  0.037 ( 0.042)	Data  0.001 ( 0.004)	Loss 2.7267e-01 (3.9611e-01)	Acc@1  93.75 ( 88.11)	Acc@5  99.22 ( 98.85)
Epoch: [55][ 60/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.003)	Loss 4.8108e-01 (3.9863e-01)	Acc@1  83.59 ( 87.90)	Acc@5  99.22 ( 98.82)
Epoch: [55][ 70/391]	Time  0.037 ( 0.041)	Data  0.001 ( 0.003)	Loss 4.3786e-01 (3.9925e-01)	Acc@1  86.72 ( 87.75)	Acc@5  97.66 ( 98.80)
Epoch: [55][ 80/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.003)	Loss 3.7776e-01 (3.9506e-01)	Acc@1  86.72 ( 87.95)	Acc@5  99.22 ( 98.85)
Epoch: [55][ 90/391]	Time  0.038 ( 0.040)	Data  0.001 ( 0.003)	Loss 4.0901e-01 (3.9471e-01)	Acc@1  86.72 ( 87.92)	Acc@5  99.22 ( 98.88)
Epoch: [55][100/391]	Time  0.040 ( 0.040)	Data  0.001 ( 0.003)	Loss 4.9225e-01 (3.9815e-01)	Acc@1  84.38 ( 87.79)	Acc@5  99.22 ( 98.87)
Epoch: [55][110/391]	Time  0.039 ( 0.040)	Data  0.001 ( 0.002)	Loss 3.7072e-01 (3.9665e-01)	Acc@1  89.06 ( 87.76)	Acc@5  99.22 ( 98.89)
Epoch: [55][120/391]	Time  0.039 ( 0.040)	Data  0.002 ( 0.002)	Loss 3.3309e-01 (3.9826e-01)	Acc@1  89.84 ( 87.71)	Acc@5  99.22 ( 98.88)
Epoch: [55][130/391]	Time  0.037 ( 0.040)	Data  0.001 ( 0.002)	Loss 3.3264e-01 (3.9673e-01)	Acc@1  89.06 ( 87.74)	Acc@5  99.22 ( 98.89)
Epoch: [55][140/391]	Time  0.037 ( 0.040)	Data  0.002 ( 0.002)	Loss 3.0649e-01 (3.9593e-01)	Acc@1  90.62 ( 87.77)	Acc@5 100.00 ( 98.88)
Epoch: [55][150/391]	Time  0.039 ( 0.040)	Data  0.001 ( 0.002)	Loss 2.7744e-01 (3.9323e-01)	Acc@1  90.62 ( 87.85)	Acc@5  99.22 ( 98.89)
Epoch: [55][160/391]	Time  0.038 ( 0.040)	Data  0.001 ( 0.002)	Loss 4.7182e-01 (3.9625e-01)	Acc@1  85.16 ( 87.74)	Acc@5  98.44 ( 98.86)
Epoch: [55][170/391]	Time  0.039 ( 0.040)	Data  0.001 ( 0.002)	Loss 4.6510e-01 (3.9407e-01)	Acc@1  85.16 ( 87.83)	Acc@5  97.66 ( 98.88)
Epoch: [55][180/391]	Time  0.037 ( 0.039)	Data  0.001 ( 0.002)	Loss 5.0505e-01 (3.9653e-01)	Acc@1  84.38 ( 87.73)	Acc@5  97.66 ( 98.85)
Epoch: [55][190/391]	Time  0.037 ( 0.039)	Data  0.001 ( 0.002)	Loss 4.2373e-01 (3.9878e-01)	Acc@1  88.28 ( 87.70)	Acc@5  97.66 ( 98.82)
Epoch: [55][200/391]	Time  0.038 ( 0.039)	Data  0.001 ( 0.002)	Loss 4.8333e-01 (3.9792e-01)	Acc@1  85.16 ( 87.72)	Acc@5  99.22 ( 98.82)
Epoch: [55][210/391]	Time  0.038 ( 0.039)	Data  0.002 ( 0.002)	Loss 4.0394e-01 (3.9536e-01)	Acc@1  87.50 ( 87.78)	Acc@5  98.44 ( 98.84)
Epoch: [55][220/391]	Time  0.039 ( 0.039)	Data  0.001 ( 0.002)	Loss 4.0637e-01 (3.9552e-01)	Acc@1  86.72 ( 87.76)	Acc@5  98.44 ( 98.85)
Epoch: [55][230/391]	Time  0.037 ( 0.039)	Data  0.001 ( 0.002)	Loss 5.1570e-01 (3.9590e-01)	Acc@1  88.28 ( 87.79)	Acc@5  97.66 ( 98.83)
Epoch: [55][240/391]	Time  0.040 ( 0.039)	Data  0.001 ( 0.002)	Loss 3.5896e-01 (3.9541e-01)	Acc@1  89.06 ( 87.82)	Acc@5  99.22 ( 98.85)
Epoch: [55][250/391]	Time  0.040 ( 0.039)	Data  0.001 ( 0.002)	Loss 3.8746e-01 (3.9538e-01)	Acc@1  88.28 ( 87.79)	Acc@5  99.22 ( 98.87)
Epoch: [55][260/391]	Time  0.035 ( 0.039)	Data  0.002 ( 0.002)	Loss 4.2243e-01 (3.9410e-01)	Acc@1  85.16 ( 87.80)	Acc@5  99.22 ( 98.88)
Epoch: [55][270/391]	Time  0.043 ( 0.039)	Data  0.001 ( 0.002)	Loss 4.6850e-01 (3.9430e-01)	Acc@1  86.72 ( 87.79)	Acc@5  98.44 ( 98.89)
Epoch: [55][280/391]	Time  0.035 ( 0.039)	Data  0.001 ( 0.002)	Loss 2.7432e-01 (3.9179e-01)	Acc@1  90.62 ( 87.90)	Acc@5 100.00 ( 98.92)
Epoch: [55][290/391]	Time  0.037 ( 0.039)	Data  0.001 ( 0.002)	Loss 3.7002e-01 (3.9169e-01)	Acc@1  90.62 ( 87.89)	Acc@5  97.66 ( 98.91)
Epoch: [55][300/391]	Time  0.039 ( 0.039)	Data  0.001 ( 0.002)	Loss 4.5955e-01 (3.9350e-01)	Acc@1  85.94 ( 87.82)	Acc@5  98.44 ( 98.90)
Epoch: [55][310/391]	Time  0.039 ( 0.039)	Data  0.001 ( 0.002)	Loss 3.8546e-01 (3.9364e-01)	Acc@1  88.28 ( 87.79)	Acc@5  99.22 ( 98.91)
Epoch: [55][320/391]	Time  0.037 ( 0.039)	Data  0.001 ( 0.002)	Loss 4.1730e-01 (3.9421e-01)	Acc@1  86.72 ( 87.77)	Acc@5  99.22 ( 98.90)
Epoch: [55][330/391]	Time  0.038 ( 0.039)	Data  0.001 ( 0.002)	Loss 4.4204e-01 (3.9503e-01)	Acc@1  84.38 ( 87.75)	Acc@5  97.66 ( 98.89)
Epoch: [55][340/391]	Time  0.038 ( 0.039)	Data  0.001 ( 0.001)	Loss 5.6947e-01 (3.9528e-01)	Acc@1  85.16 ( 87.77)	Acc@5  96.09 ( 98.88)
Epoch: [55][350/391]	Time  0.042 ( 0.039)	Data  0.001 ( 0.001)	Loss 4.0657e-01 (3.9640e-01)	Acc@1  88.28 ( 87.75)	Acc@5  97.66 ( 98.87)
Epoch: [55][360/391]	Time  0.039 ( 0.039)	Data  0.001 ( 0.001)	Loss 3.2076e-01 (3.9666e-01)	Acc@1  88.28 ( 87.72)	Acc@5  98.44 ( 98.86)
Epoch: [55][370/391]	Time  0.039 ( 0.039)	Data  0.001 ( 0.001)	Loss 5.4780e-01 (3.9791e-01)	Acc@1  81.25 ( 87.65)	Acc@5  98.44 ( 98.86)
Epoch: [55][380/391]	Time  0.044 ( 0.039)	Data  0.001 ( 0.001)	Loss 3.8387e-01 (3.9811e-01)	Acc@1  88.28 ( 87.65)	Acc@5  99.22 ( 98.86)
Epoch: [55][390/391]	Time  0.026 ( 0.039)	Data  0.001 ( 0.001)	Loss 5.1223e-01 (3.9910e-01)	Acc@1  83.75 ( 87.62)	Acc@5  97.50 ( 98.84)
## e[55] optimizer.zero_grad (sum) time: 0.2180781364440918
## e[55]       loss.backward (sum) time: 3.582268476486206
## e[55]      optimizer.step (sum) time: 1.5123264789581299
## epoch[55] training(only) time: 15.275137424468994
# Switched to evaluate mode...
Test: [  0/100]	Time  0.152 ( 0.152)	Loss 1.2969e+00 (1.2969e+00)	Acc@1  66.00 ( 66.00)	Acc@5  89.00 ( 89.00)
Test: [ 10/100]	Time  0.019 ( 0.033)	Loss 1.4611e+00 (1.4584e+00)	Acc@1  68.00 ( 66.73)	Acc@5  89.00 ( 88.82)
Test: [ 20/100]	Time  0.024 ( 0.028)	Loss 1.1988e+00 (1.4022e+00)	Acc@1  75.00 ( 67.90)	Acc@5  94.00 ( 90.05)
Test: [ 30/100]	Time  0.022 ( 0.026)	Loss 1.7471e+00 (1.4172e+00)	Acc@1  62.00 ( 67.52)	Acc@5  90.00 ( 89.97)
Test: [ 40/100]	Time  0.017 ( 0.024)	Loss 1.4570e+00 (1.4120e+00)	Acc@1  66.00 ( 67.46)	Acc@5  91.00 ( 90.20)
Test: [ 50/100]	Time  0.022 ( 0.024)	Loss 1.6718e+00 (1.4178e+00)	Acc@1  65.00 ( 67.12)	Acc@5  88.00 ( 90.00)
Test: [ 60/100]	Time  0.022 ( 0.024)	Loss 1.5176e+00 (1.4031e+00)	Acc@1  66.00 ( 67.39)	Acc@5  87.00 ( 90.34)
Test: [ 70/100]	Time  0.024 ( 0.023)	Loss 1.4923e+00 (1.4048e+00)	Acc@1  72.00 ( 67.54)	Acc@5  89.00 ( 90.27)
Test: [ 80/100]	Time  0.023 ( 0.023)	Loss 1.5818e+00 (1.4122e+00)	Acc@1  68.00 ( 67.56)	Acc@5  89.00 ( 90.17)
Test: [ 90/100]	Time  0.021 ( 0.023)	Loss 1.5861e+00 (1.3974e+00)	Acc@1  64.00 ( 67.77)	Acc@5  92.00 ( 90.42)
 * Acc@1 67.990 Acc@5 90.530
### epoch[55] execution time: 17.638314962387085
EPOCH 56
REMOVING: module.fire3.expand_3x3.0.bias
REMOVING: module.fire3.expand_3x3.1.weight
REMOVING: module.fire3.expand_3x3.1.bias
i:   0, name:  module.fire4.squeeze.0.weight  changing lr from: 0.001118584818423256   to: 0.001004236984742045
i:   1, name:    module.fire4.squeeze.0.bias  changing lr from: 0.001202056869053641   to: 0.001029662017431292
i:   2, name:  module.fire4.squeeze.1.weight  changing lr from: 0.001306524063958424   to: 0.001077487372257396
i:   3, name:    module.fire4.squeeze.1.bias  changing lr from: 0.001431358512736174   to: 0.001147078862434624
i:   4, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.001575939924025915   to: 0.001237808566610675
i:   5, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.001739655983196153   to: 0.001349055299172429
i:   6, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.001921902693105492   to: 0.001480205039554582
i:   7, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.002122084679917457   to: 0.001630651322643810
i:   8, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.002339615465877331   to: 0.001799795592298447
i:   9, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.002573917710885370   to: 0.001987047519930779
i:  10, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.002824423424628363   to: 0.002191825290027904
i:  11, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.003090574150960734   to: 0.002413555854415849
i:  12, name:  module.fire5.squeeze.0.weight  changing lr from: 0.003371821126156576   to: 0.002651675157002353
i:  13, name:    module.fire5.squeeze.0.bias  changing lr from: 0.003667625412586428   to: 0.002905628330664955
i:  14, name:  module.fire5.squeeze.1.weight  changing lr from: 0.003977458009305822   to: 0.003174869867883811
i:  15, name:    module.fire5.squeeze.1.bias  changing lr from: 0.004300799940978644   to: 0.003458863766653319
i:  16, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.004637142326494619   to: 0.003757083653141585
i:  17, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.004985986428580013   to: 0.004069012882504996
i:  18, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.005346843685640467   to: 0.004394144619203093
i:  19, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.005719235727018267   to: 0.004731981898100434
i:  20, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.006102694372789741   to: 0.005082037667583494
i:  21, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.006496761619175572   to: 0.005443834815865472
i:  22, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.006900989610583990   to: 0.005816906181596775
i:  23, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.007314940599257202   to: 0.006200794549846982
i:  24, name:  module.fire6.squeeze.0.weight  changing lr from: 0.007738186893442750   to: 0.006595052634472981
i:  25, name:    module.fire6.squeeze.0.bias  changing lr from: 0.008170310794964830   to: 0.006999243047838821
i:  26, name:  module.fire6.squeeze.1.weight  changing lr from: 0.008610904527026009   to: 0.007412938258805645
i:  27, name:    module.fire6.squeeze.1.bias  changing lr from: 0.009059570153025876   to: 0.007835720539863904
i:  28, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.009515919487143077   to: 0.008267181904236798
i:  29, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.009979573997385610   to: 0.008706924033740564
i:  30, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.010450164701777731   to: 0.009154558198147460
i:  31, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.010927332058313682   to: 0.009609705166757011
i:  32, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.011410725849274883   to: 0.010071995112844827
i:  33, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.011900005060472278   to: 0.010541067511620893
i:  34, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.012394837755944209   to: 0.011016571032295509
i:  35, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.012894900948609223   to: 0.011498163424817527
i:  36, name:  module.fire7.squeeze.0.weight  changing lr from: 0.013399880467343868   to: 0.011985511401818111
i:  37, name:    module.fire7.squeeze.0.bias  changing lr from: 0.013909470820927687   to: 0.012478290516262508
i:  38, name:  module.fire7.squeeze.1.weight  changing lr from: 0.014423375059270445   to: 0.012976185035283305
i:  39, name:    module.fire7.squeeze.1.bias  changing lr from: 0.014941304632311476   to: 0.013478887810641483
i:  40, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.015462979246956981   to: 0.013986100146234248
i:  41, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.015988126722397099   to: 0.014497531663043944
i:  42, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.016516482844123586   to: 0.015012900161898074
i:  43, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.017047791216947078   to: 0.015531931484387106
i:  44, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.017581803117293821   to: 0.016054359372265802
i:  45, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.018118277345041751   to: 0.016579925325641415
i:  46, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.018656980075139242   to: 0.017108378460234209
i:  47, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.019197684709231427   to: 0.017639475363974911
i:  48, name:  module.fire8.squeeze.0.weight  changing lr from: 0.019740171727503530   to: 0.018172979953187490
i:  49, name:    module.fire8.squeeze.0.bias  changing lr from: 0.020284228540935197   to: 0.018708663328587113
i:  50, name:  module.fire8.squeeze.1.weight  changing lr from: 0.020829649344145426   to: 0.019246303631308432
i:  51, name:    module.fire8.squeeze.1.bias  changing lr from: 0.021376234968993435   to: 0.019785685899162936
i:  52, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.021923792739088201   to: 0.020326601923309685
i:  53, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.022472136325347471   to: 0.020868850105510900
i:  54, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.023021085602734109   to: 0.021412235316129419
i:  55, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.023570466508288410   to: 0.021956568753013925
i:  56, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.024120110900562972   to: 0.022501667801405167
i:  57, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.024669856420558491   to: 0.023047355894986576
i:  58, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.025219546354248001   to: 0.023593462378190655
i:  59, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.025769029496770086   to: 0.024139822369864186
i:  60, name:  module.fire9.squeeze.0.weight  changing lr from: 0.026318160018362097   to: 0.024686276628385052
i:  61, name:    module.fire9.squeeze.0.bias  changing lr from: 0.026866797332097372   to: 0.025232671418315252
i:  62, name:  module.fire9.squeeze.1.weight  changing lr from: 0.027414805963483224   to: 0.025778858378665906
i:  63, name:    module.fire9.squeeze.1.bias  changing lr from: 0.027962055421969424   to: 0.026324694392842924
i:  64, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.028508420074410862   to: 0.026870041460334289
i:  65, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.029053779020521798   to: 0.027414766570192879
i:  66, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.029598015970353914   to: 0.027958741576363133
i:  67, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.030141019123824764   to: 0.028501843074892497
i:  68, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.030682681052318667   to: 0.029043952283064434
i:  69, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.031222898582377534   to: 0.029584954920483231
i:  70, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.031761572681494335   to: 0.030124741092136222
i:  71, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.032298608346018845   to: 0.030663205173455128
i:  72, name:           module.conv10.weight  changing lr from: 0.032833914491181067   to: 0.031200245697392600
i:  73, name:             module.conv10.bias  changing lr from: 0.033367403843234243   to: 0.031735765243527003



# Switched to train mode...
Epoch: [56][  0/391]	Time  0.193 ( 0.193)	Data  0.151 ( 0.151)	Loss 4.7704e-01 (4.7704e-01)	Acc@1  83.59 ( 83.59)	Acc@5  99.22 ( 99.22)
Epoch: [56][ 10/391]	Time  0.038 ( 0.052)	Data  0.001 ( 0.015)	Loss 2.9463e-01 (3.7445e-01)	Acc@1  92.19 ( 88.99)	Acc@5  99.22 ( 98.72)
Epoch: [56][ 20/391]	Time  0.036 ( 0.046)	Data  0.001 ( 0.008)	Loss 4.3692e-01 (3.4604e-01)	Acc@1  85.94 ( 89.62)	Acc@5 100.00 ( 99.18)
Epoch: [56][ 30/391]	Time  0.038 ( 0.043)	Data  0.001 ( 0.006)	Loss 4.1674e-01 (3.5437e-01)	Acc@1  87.50 ( 89.26)	Acc@5  99.22 ( 99.14)
Epoch: [56][ 40/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.005)	Loss 3.1405e-01 (3.6342e-01)	Acc@1  89.84 ( 88.99)	Acc@5  99.22 ( 99.05)
Epoch: [56][ 50/391]	Time  0.036 ( 0.041)	Data  0.001 ( 0.004)	Loss 4.1647e-01 (3.6732e-01)	Acc@1  89.84 ( 88.83)	Acc@5  98.44 ( 98.96)
Epoch: [56][ 60/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.003)	Loss 3.7839e-01 (3.6441e-01)	Acc@1  90.62 ( 89.11)	Acc@5  98.44 ( 98.98)
Epoch: [56][ 70/391]	Time  0.037 ( 0.040)	Data  0.002 ( 0.003)	Loss 3.6066e-01 (3.6568e-01)	Acc@1  87.50 ( 89.04)	Acc@5 100.00 ( 99.01)
Epoch: [56][ 80/391]	Time  0.037 ( 0.040)	Data  0.001 ( 0.003)	Loss 3.9955e-01 (3.7108e-01)	Acc@1  87.50 ( 88.86)	Acc@5  99.22 ( 98.97)
Epoch: [56][ 90/391]	Time  0.037 ( 0.040)	Data  0.001 ( 0.003)	Loss 3.8692e-01 (3.7288e-01)	Acc@1  88.28 ( 88.68)	Acc@5 100.00 ( 98.95)
Epoch: [56][100/391]	Time  0.037 ( 0.040)	Data  0.001 ( 0.002)	Loss 3.5996e-01 (3.7278e-01)	Acc@1  89.84 ( 88.67)	Acc@5  97.66 ( 98.96)
Epoch: [56][110/391]	Time  0.038 ( 0.039)	Data  0.001 ( 0.002)	Loss 3.1979e-01 (3.6988e-01)	Acc@1  89.06 ( 88.65)	Acc@5  99.22 ( 98.98)
Epoch: [56][120/391]	Time  0.038 ( 0.040)	Data  0.001 ( 0.002)	Loss 3.7537e-01 (3.6958e-01)	Acc@1  85.94 ( 88.52)	Acc@5 100.00 ( 99.00)
Epoch: [56][130/391]	Time  0.037 ( 0.039)	Data  0.001 ( 0.002)	Loss 3.7808e-01 (3.7045e-01)	Acc@1  87.50 ( 88.44)	Acc@5  98.44 ( 98.98)
Epoch: [56][140/391]	Time  0.037 ( 0.039)	Data  0.001 ( 0.002)	Loss 3.2799e-01 (3.7014e-01)	Acc@1  89.06 ( 88.47)	Acc@5  99.22 ( 98.98)
Epoch: [56][150/391]	Time  0.040 ( 0.039)	Data  0.001 ( 0.002)	Loss 3.7299e-01 (3.6945e-01)	Acc@1  90.62 ( 88.49)	Acc@5  99.22 ( 98.99)
Epoch: [56][160/391]	Time  0.038 ( 0.039)	Data  0.001 ( 0.002)	Loss 4.1114e-01 (3.7007e-01)	Acc@1  86.72 ( 88.43)	Acc@5  99.22 ( 98.99)
Epoch: [56][170/391]	Time  0.037 ( 0.039)	Data  0.001 ( 0.002)	Loss 3.6590e-01 (3.6916e-01)	Acc@1  89.84 ( 88.47)	Acc@5  99.22 ( 99.00)
Epoch: [56][180/391]	Time  0.038 ( 0.039)	Data  0.001 ( 0.002)	Loss 3.4734e-01 (3.7031e-01)	Acc@1  89.06 ( 88.48)	Acc@5 100.00 ( 98.99)
Epoch: [56][190/391]	Time  0.037 ( 0.039)	Data  0.001 ( 0.002)	Loss 2.5968e-01 (3.7033e-01)	Acc@1  91.41 ( 88.51)	Acc@5 100.00 ( 98.98)
Epoch: [56][200/391]	Time  0.038 ( 0.039)	Data  0.001 ( 0.002)	Loss 2.2359e-01 (3.7016e-01)	Acc@1  92.97 ( 88.49)	Acc@5 100.00 ( 99.00)
Epoch: [56][210/391]	Time  0.038 ( 0.039)	Data  0.001 ( 0.002)	Loss 4.0140e-01 (3.6950e-01)	Acc@1  89.06 ( 88.47)	Acc@5  98.44 ( 99.01)
Epoch: [56][220/391]	Time  0.039 ( 0.039)	Data  0.001 ( 0.002)	Loss 3.9770e-01 (3.7175e-01)	Acc@1  87.50 ( 88.43)	Acc@5  99.22 ( 98.99)
Epoch: [56][230/391]	Time  0.037 ( 0.039)	Data  0.001 ( 0.002)	Loss 5.1714e-01 (3.7300e-01)	Acc@1  82.81 ( 88.41)	Acc@5  98.44 ( 99.00)
Epoch: [56][240/391]	Time  0.038 ( 0.039)	Data  0.001 ( 0.002)	Loss 3.5543e-01 (3.7292e-01)	Acc@1  90.62 ( 88.41)	Acc@5  99.22 ( 99.00)
Epoch: [56][250/391]	Time  0.038 ( 0.039)	Data  0.001 ( 0.002)	Loss 4.5367e-01 (3.7347e-01)	Acc@1  85.16 ( 88.40)	Acc@5  99.22 ( 98.99)
Epoch: [56][260/391]	Time  0.040 ( 0.039)	Data  0.001 ( 0.002)	Loss 4.2992e-01 (3.7421e-01)	Acc@1  84.38 ( 88.35)	Acc@5 100.00 ( 98.99)
Epoch: [56][270/391]	Time  0.038 ( 0.039)	Data  0.001 ( 0.002)	Loss 4.5247e-01 (3.7631e-01)	Acc@1  85.94 ( 88.24)	Acc@5  99.22 ( 98.98)
Epoch: [56][280/391]	Time  0.037 ( 0.039)	Data  0.001 ( 0.002)	Loss 2.7237e-01 (3.7632e-01)	Acc@1  90.62 ( 88.23)	Acc@5 100.00 ( 98.99)
Epoch: [56][290/391]	Time  0.036 ( 0.039)	Data  0.001 ( 0.002)	Loss 3.5669e-01 (3.7653e-01)	Acc@1  89.84 ( 88.22)	Acc@5  99.22 ( 98.99)
Epoch: [56][300/391]	Time  0.039 ( 0.039)	Data  0.001 ( 0.001)	Loss 3.4682e-01 (3.7646e-01)	Acc@1  92.19 ( 88.20)	Acc@5 100.00 ( 98.99)
Epoch: [56][310/391]	Time  0.037 ( 0.039)	Data  0.001 ( 0.001)	Loss 4.5314e-01 (3.7611e-01)	Acc@1  85.16 ( 88.22)	Acc@5  99.22 ( 98.99)
Epoch: [56][320/391]	Time  0.038 ( 0.039)	Data  0.001 ( 0.001)	Loss 3.3432e-01 (3.7630e-01)	Acc@1  89.84 ( 88.21)	Acc@5 100.00 ( 98.99)
Epoch: [56][330/391]	Time  0.038 ( 0.039)	Data  0.001 ( 0.001)	Loss 3.9751e-01 (3.7644e-01)	Acc@1  86.72 ( 88.18)	Acc@5 100.00 ( 98.99)
Epoch: [56][340/391]	Time  0.036 ( 0.039)	Data  0.001 ( 0.001)	Loss 3.5328e-01 (3.7686e-01)	Acc@1  87.50 ( 88.15)	Acc@5  98.44 ( 98.99)
Epoch: [56][350/391]	Time  0.037 ( 0.039)	Data  0.001 ( 0.001)	Loss 4.7238e-01 (3.7812e-01)	Acc@1  86.72 ( 88.15)	Acc@5  99.22 ( 98.98)
Epoch: [56][360/391]	Time  0.039 ( 0.039)	Data  0.001 ( 0.001)	Loss 4.0569e-01 (3.7879e-01)	Acc@1  84.38 ( 88.14)	Acc@5  99.22 ( 98.98)
Epoch: [56][370/391]	Time  0.037 ( 0.039)	Data  0.001 ( 0.001)	Loss 4.3106e-01 (3.7914e-01)	Acc@1  85.94 ( 88.15)	Acc@5  99.22 ( 98.99)
Epoch: [56][380/391]	Time  0.040 ( 0.039)	Data  0.001 ( 0.001)	Loss 3.6588e-01 (3.7990e-01)	Acc@1  87.50 ( 88.13)	Acc@5  99.22 ( 98.99)
Epoch: [56][390/391]	Time  0.026 ( 0.038)	Data  0.001 ( 0.001)	Loss 3.3237e-01 (3.8084e-01)	Acc@1  91.25 ( 88.10)	Acc@5  98.75 ( 98.97)
## e[56] optimizer.zero_grad (sum) time: 0.21038126945495605
## e[56]       loss.backward (sum) time: 3.540215015411377
## e[56]      optimizer.step (sum) time: 1.4677391052246094
## epoch[56] training(only) time: 15.134541511535645
# Switched to evaluate mode...
Test: [  0/100]	Time  0.149 ( 0.149)	Loss 1.2880e+00 (1.2880e+00)	Acc@1  68.00 ( 68.00)	Acc@5  90.00 ( 90.00)
Test: [ 10/100]	Time  0.020 ( 0.034)	Loss 1.6087e+00 (1.4468e+00)	Acc@1  59.00 ( 66.27)	Acc@5  89.00 ( 89.36)
Test: [ 20/100]	Time  0.021 ( 0.028)	Loss 1.2140e+00 (1.4040e+00)	Acc@1  76.00 ( 67.19)	Acc@5  93.00 ( 89.71)
Test: [ 30/100]	Time  0.021 ( 0.026)	Loss 1.6255e+00 (1.4387e+00)	Acc@1  60.00 ( 66.35)	Acc@5  90.00 ( 89.71)
Test: [ 40/100]	Time  0.024 ( 0.026)	Loss 1.4758e+00 (1.4409e+00)	Acc@1  67.00 ( 66.27)	Acc@5  92.00 ( 89.83)
Test: [ 50/100]	Time  0.021 ( 0.025)	Loss 1.3620e+00 (1.4402e+00)	Acc@1  70.00 ( 66.35)	Acc@5  91.00 ( 89.67)
Test: [ 60/100]	Time  0.024 ( 0.025)	Loss 1.4775e+00 (1.4181e+00)	Acc@1  62.00 ( 66.56)	Acc@5  89.00 ( 90.07)
Test: [ 70/100]	Time  0.021 ( 0.025)	Loss 1.7007e+00 (1.4211e+00)	Acc@1  63.00 ( 66.44)	Acc@5  87.00 ( 90.06)
Test: [ 80/100]	Time  0.029 ( 0.024)	Loss 1.6758e+00 (1.4254e+00)	Acc@1  68.00 ( 66.43)	Acc@5  86.00 ( 89.98)
Test: [ 90/100]	Time  0.022 ( 0.024)	Loss 1.4969e+00 (1.4110e+00)	Acc@1  63.00 ( 66.74)	Acc@5  90.00 ( 90.18)
 * Acc@1 67.080 Acc@5 90.280
### epoch[56] execution time: 17.588428020477295
EPOCH 57
REMOVING: module.fire4.squeeze.0.weight
REMOVING: module.fire4.squeeze.0.bias
i:   0, name:  module.fire4.squeeze.1.weight  changing lr from: 0.001077487372257396   to: 0.001000008257637818
i:   1, name:    module.fire4.squeeze.1.bias  changing lr from: 0.001147078862434624   to: 0.001012089262398601
i:   2, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.001237808566610675   to: 0.001046675499440468
i:   3, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.001349055299172429   to: 0.001103140535388452
i:   4, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.001480205039554582   to: 0.001180863766474121
i:   5, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.001630651322643810   to: 0.001279230899684119
i:   6, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.001799795592298447   to: 0.001397634393104013
i:   7, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.001987047519930779   to: 0.001535473857507407
i:   8, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.002191825290027904   to: 0.001692156421170526
i:   9, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.002413555854415849   to: 0.001867097059823185
i:  10, name:  module.fire5.squeeze.0.weight  changing lr from: 0.002651675157002353   to: 0.002059718893578049
i:  11, name:    module.fire5.squeeze.0.bias  changing lr from: 0.002905628330664955   to: 0.002269453452612185
i:  12, name:  module.fire5.squeeze.1.weight  changing lr from: 0.003174869867883811   to: 0.002495740913307520
i:  13, name:    module.fire5.squeeze.1.bias  changing lr from: 0.003458863766653319   to: 0.002738030306491256
i:  14, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.003757083653141585   to: 0.002995779699351652
i:  15, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.004069012882504996   to: 0.003268456352541687
i:  16, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.004394144619203093   to: 0.003555536853920365
i:  17, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.004731981898100434   to: 0.003856507230321010
i:  18, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.005082037667583494   to: 0.004170863038676109
i:  19, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.005443834815865472   to: 0.004498109437771135
i:  20, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.005816906181596775   to: 0.004837761241843008
i:  21, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.006200794549846982   to: 0.005189342957184677
i:  22, name:  module.fire6.squeeze.0.weight  changing lr from: 0.006595052634472981   to: 0.005552388802864227
i:  23, name:    module.fire6.squeeze.0.bias  changing lr from: 0.006999243047838821   to: 0.005926442716615714
i:  24, name:  module.fire6.squeeze.1.weight  changing lr from: 0.007412938258805645   to: 0.006311058346909182
i:  25, name:    module.fire6.squeeze.1.bias  changing lr from: 0.007835720539863904   to: 0.006705799032159254
i:  26, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.008267181904236798   to: 0.007110237767985711
i:  27, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.008706924033740564   to: 0.007523957163394140
i:  28, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.009154558198147460   to: 0.007946549386702195
i:  29, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.009609705166757011   to: 0.008377616101994756
i:  30, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.010071995112844827   to: 0.008816768396852182
i:  31, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.010541067511620893   to: 0.009263626702056382
i:  32, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.011016571032295509   to: 0.009717820703943274
i:  33, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.011498163424817527   to: 0.010178989250034159
i:  34, name:  module.fire7.squeeze.0.weight  changing lr from: 0.011985511401818111   to: 0.010646780248544790
i:  35, name:    module.fire7.squeeze.0.bias  changing lr from: 0.012478290516262508   to: 0.011120850562338230
i:  36, name:  module.fire7.squeeze.1.weight  changing lr from: 0.012976185035283305   to: 0.011600865897855937
i:  37, name:    module.fire7.squeeze.1.bias  changing lr from: 0.013478887810641483   to: 0.012086500689532126
i:  38, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.013986100146234248   to: 0.012577437980167288
i:  39, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.014497531663043944   to: 0.013073369297709508
i:  40, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.015012900161898074   to: 0.013573994528866252
i:  41, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.015531931484387106   to: 0.014079021789943517
i:  42, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.016054359372265802   to: 0.014588167295286537
i:  43, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.016579925325641415   to: 0.015101155223672058
i:  44, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.017108378460234209   to: 0.015617717582981812
i:  45, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.017639475363974911   to: 0.016137594073464968
i:  46, name:  module.fire8.squeeze.0.weight  changing lr from: 0.018172979953187490   to: 0.016660531949878443
i:  47, name:    module.fire8.squeeze.0.bias  changing lr from: 0.018708663328587113   to: 0.017186285882774665
i:  48, name:  module.fire8.squeeze.1.weight  changing lr from: 0.019246303631308432   to: 0.017714617819188944
i:  49, name:    module.fire8.squeeze.1.bias  changing lr from: 0.019785685899162936   to: 0.018245296842961455
i:  50, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.020326601923309685   to: 0.018778099034912350
i:  51, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.020868850105510900   to: 0.019312807333074205
i:  52, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.021412235316129419   to: 0.019849211393170293
i:  53, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.021956568753013925   to: 0.020387107449514438
i:  54, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.022501667801405167   to: 0.020926298176494190
i:  55, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.023047355894986576   to: 0.021466592550787846
i:  56, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.023593462378190655   to: 0.022007805714452919
i:  57, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.024139822369864186   to: 0.022549758839013542
i:  58, name:  module.fire9.squeeze.0.weight  changing lr from: 0.024686276628385052   to: 0.023092278990663302
i:  59, name:    module.fire9.squeeze.0.bias  changing lr from: 0.025232671418315252   to: 0.023635198996690268
i:  60, name:  module.fire9.squeeze.1.weight  changing lr from: 0.025778858378665906   to: 0.024178357313221724
i:  61, name:    module.fire9.squeeze.1.bias  changing lr from: 0.026324694392842924   to: 0.024721597894377126
i:  62, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.026870041460334289   to: 0.025264770062909558
i:  63, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.027414766570192879   to: 0.025807728382408381
i:  64, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.027958741576363133   to: 0.026350332531127719
i:  65, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.028501843074892497   to: 0.026892447177499491
i:  66, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.029043952283064434   to: 0.027433941857382238
i:  67, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.029584954920483231   to: 0.027974690853091413
i:  68, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.030124741092136222   to: 0.028514573074250683
i:  69, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.030663205173455128   to: 0.029053471940499006
i:  70, name:           module.conv10.weight  changing lr from: 0.031200245697392600   to: 0.029591275266082375
i:  71, name:             module.conv10.bias  changing lr from: 0.031735765243527003   to: 0.030127875146354961



# Switched to train mode...
Epoch: [57][  0/391]	Time  0.187 ( 0.187)	Data  0.143 ( 0.143)	Loss 3.2256e-01 (3.2256e-01)	Acc@1  89.06 ( 89.06)	Acc@5  99.22 ( 99.22)
Epoch: [57][ 10/391]	Time  0.038 ( 0.053)	Data  0.001 ( 0.014)	Loss 3.4273e-01 (3.2714e-01)	Acc@1  89.06 ( 89.42)	Acc@5  98.44 ( 99.29)
Epoch: [57][ 20/391]	Time  0.036 ( 0.046)	Data  0.001 ( 0.008)	Loss 4.1156e-01 (3.3109e-01)	Acc@1  86.72 ( 89.21)	Acc@5 100.00 ( 99.18)
Epoch: [57][ 30/391]	Time  0.039 ( 0.043)	Data  0.001 ( 0.006)	Loss 3.6704e-01 (3.2860e-01)	Acc@1  86.72 ( 89.26)	Acc@5  98.44 ( 99.19)
Epoch: [57][ 40/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.004)	Loss 3.3594e-01 (3.3397e-01)	Acc@1  89.84 ( 89.16)	Acc@5  99.22 ( 99.07)
Epoch: [57][ 50/391]	Time  0.037 ( 0.041)	Data  0.001 ( 0.004)	Loss 3.5865e-01 (3.3285e-01)	Acc@1  89.84 ( 89.20)	Acc@5  98.44 ( 99.10)
Epoch: [57][ 60/391]	Time  0.037 ( 0.041)	Data  0.001 ( 0.003)	Loss 2.7798e-01 (3.3510e-01)	Acc@1  90.62 ( 89.24)	Acc@5  99.22 ( 99.10)
Epoch: [57][ 70/391]	Time  0.036 ( 0.040)	Data  0.001 ( 0.003)	Loss 4.1960e-01 (3.3961e-01)	Acc@1  86.72 ( 89.19)	Acc@5  98.44 ( 99.12)
Epoch: [57][ 80/391]	Time  0.040 ( 0.040)	Data  0.001 ( 0.003)	Loss 2.5693e-01 (3.3776e-01)	Acc@1  92.97 ( 89.39)	Acc@5 100.00 ( 99.16)
Epoch: [57][ 90/391]	Time  0.039 ( 0.040)	Data  0.001 ( 0.003)	Loss 3.2289e-01 (3.4162e-01)	Acc@1  93.75 ( 89.29)	Acc@5  98.44 ( 99.12)
Epoch: [57][100/391]	Time  0.037 ( 0.039)	Data  0.001 ( 0.002)	Loss 2.7538e-01 (3.4334e-01)	Acc@1  93.75 ( 89.33)	Acc@5  99.22 ( 99.09)
Epoch: [57][110/391]	Time  0.037 ( 0.039)	Data  0.001 ( 0.002)	Loss 3.2970e-01 (3.4722e-01)	Acc@1  90.62 ( 89.28)	Acc@5 100.00 ( 99.06)
Epoch: [57][120/391]	Time  0.037 ( 0.039)	Data  0.001 ( 0.002)	Loss 3.4984e-01 (3.4994e-01)	Acc@1  89.84 ( 89.19)	Acc@5  99.22 ( 99.07)
Epoch: [57][130/391]	Time  0.040 ( 0.039)	Data  0.001 ( 0.002)	Loss 3.8690e-01 (3.4975e-01)	Acc@1  87.50 ( 89.10)	Acc@5 100.00 ( 99.11)
Epoch: [57][140/391]	Time  0.037 ( 0.039)	Data  0.001 ( 0.002)	Loss 4.1853e-01 (3.5381e-01)	Acc@1  84.38 ( 88.92)	Acc@5  99.22 ( 99.11)
Epoch: [57][150/391]	Time  0.040 ( 0.039)	Data  0.001 ( 0.002)	Loss 3.0438e-01 (3.5549e-01)	Acc@1  89.06 ( 88.82)	Acc@5 100.00 ( 99.08)
Epoch: [57][160/391]	Time  0.037 ( 0.039)	Data  0.002 ( 0.002)	Loss 3.6468e-01 (3.5592e-01)	Acc@1  85.16 ( 88.80)	Acc@5 100.00 ( 99.09)
Epoch: [57][170/391]	Time  0.038 ( 0.039)	Data  0.001 ( 0.002)	Loss 3.5553e-01 (3.5557e-01)	Acc@1  89.84 ( 88.86)	Acc@5  98.44 ( 99.06)
Epoch: [57][180/391]	Time  0.037 ( 0.039)	Data  0.002 ( 0.002)	Loss 3.9769e-01 (3.5668e-01)	Acc@1  88.28 ( 88.83)	Acc@5  98.44 ( 99.08)
Epoch: [57][190/391]	Time  0.038 ( 0.039)	Data  0.001 ( 0.002)	Loss 4.5569e-01 (3.5718e-01)	Acc@1  85.16 ( 88.77)	Acc@5  97.66 ( 99.08)
Epoch: [57][200/391]	Time  0.036 ( 0.039)	Data  0.001 ( 0.002)	Loss 3.6726e-01 (3.5807e-01)	Acc@1  88.28 ( 88.76)	Acc@5 100.00 ( 99.10)
Epoch: [57][210/391]	Time  0.036 ( 0.039)	Data  0.001 ( 0.002)	Loss 3.6498e-01 (3.5822e-01)	Acc@1  88.28 ( 88.73)	Acc@5 100.00 ( 99.12)
Epoch: [57][220/391]	Time  0.039 ( 0.039)	Data  0.001 ( 0.002)	Loss 2.3932e-01 (3.5857e-01)	Acc@1  92.19 ( 88.71)	Acc@5 100.00 ( 99.11)
Epoch: [57][230/391]	Time  0.038 ( 0.039)	Data  0.001 ( 0.002)	Loss 3.1588e-01 (3.5732e-01)	Acc@1  91.41 ( 88.76)	Acc@5  99.22 ( 99.12)
Epoch: [57][240/391]	Time  0.037 ( 0.039)	Data  0.001 ( 0.002)	Loss 4.3514e-01 (3.5739e-01)	Acc@1  88.28 ( 88.80)	Acc@5  98.44 ( 99.12)
Epoch: [57][250/391]	Time  0.036 ( 0.039)	Data  0.001 ( 0.002)	Loss 2.6613e-01 (3.5730e-01)	Acc@1  91.41 ( 88.79)	Acc@5 100.00 ( 99.10)
Epoch: [57][260/391]	Time  0.038 ( 0.039)	Data  0.001 ( 0.002)	Loss 3.0853e-01 (3.5781e-01)	Acc@1  89.84 ( 88.77)	Acc@5 100.00 ( 99.10)
Epoch: [57][270/391]	Time  0.037 ( 0.039)	Data  0.001 ( 0.002)	Loss 2.7988e-01 (3.5885e-01)	Acc@1  91.41 ( 88.73)	Acc@5  99.22 ( 99.10)
Epoch: [57][280/391]	Time  0.039 ( 0.039)	Data  0.001 ( 0.002)	Loss 4.2149e-01 (3.6026e-01)	Acc@1  86.72 ( 88.70)	Acc@5  99.22 ( 99.10)
Epoch: [57][290/391]	Time  0.038 ( 0.039)	Data  0.001 ( 0.002)	Loss 4.2372e-01 (3.6142e-01)	Acc@1  85.16 ( 88.64)	Acc@5  99.22 ( 99.09)
Epoch: [57][300/391]	Time  0.037 ( 0.039)	Data  0.001 ( 0.001)	Loss 3.8872e-01 (3.6153e-01)	Acc@1  86.72 ( 88.62)	Acc@5 100.00 ( 99.09)
Epoch: [57][310/391]	Time  0.037 ( 0.038)	Data  0.001 ( 0.001)	Loss 3.8176e-01 (3.6195e-01)	Acc@1  88.28 ( 88.60)	Acc@5  98.44 ( 99.08)
Epoch: [57][320/391]	Time  0.038 ( 0.038)	Data  0.001 ( 0.001)	Loss 3.2636e-01 (3.6143e-01)	Acc@1  88.28 ( 88.64)	Acc@5 100.00 ( 99.10)
Epoch: [57][330/391]	Time  0.037 ( 0.038)	Data  0.001 ( 0.001)	Loss 3.7562e-01 (3.6129e-01)	Acc@1  89.06 ( 88.66)	Acc@5  98.44 ( 99.09)
Epoch: [57][340/391]	Time  0.038 ( 0.038)	Data  0.001 ( 0.001)	Loss 3.9653e-01 (3.6112e-01)	Acc@1  86.72 ( 88.67)	Acc@5  99.22 ( 99.09)
Epoch: [57][350/391]	Time  0.037 ( 0.038)	Data  0.001 ( 0.001)	Loss 2.2192e-01 (3.6126e-01)	Acc@1  94.53 ( 88.65)	Acc@5 100.00 ( 99.08)
Epoch: [57][360/391]	Time  0.039 ( 0.038)	Data  0.001 ( 0.001)	Loss 4.9177e-01 (3.6206e-01)	Acc@1  83.59 ( 88.62)	Acc@5 100.00 ( 99.08)
Epoch: [57][370/391]	Time  0.039 ( 0.038)	Data  0.001 ( 0.001)	Loss 3.9321e-01 (3.6268e-01)	Acc@1  85.16 ( 88.60)	Acc@5  99.22 ( 99.08)
Epoch: [57][380/391]	Time  0.039 ( 0.038)	Data  0.001 ( 0.001)	Loss 3.9560e-01 (3.6309e-01)	Acc@1  89.06 ( 88.58)	Acc@5 100.00 ( 99.08)
Epoch: [57][390/391]	Time  0.026 ( 0.038)	Data  0.001 ( 0.001)	Loss 3.0600e-01 (3.6396e-01)	Acc@1  88.75 ( 88.56)	Acc@5 100.00 ( 99.08)
## e[57] optimizer.zero_grad (sum) time: 0.20367741584777832
## e[57]       loss.backward (sum) time: 3.4875314235687256
## e[57]      optimizer.step (sum) time: 1.4307425022125244
## epoch[57] training(only) time: 15.09067153930664
# Switched to evaluate mode...
Test: [  0/100]	Time  0.150 ( 0.150)	Loss 1.2939e+00 (1.2939e+00)	Acc@1  70.00 ( 70.00)	Acc@5  91.00 ( 91.00)
Test: [ 10/100]	Time  0.025 ( 0.033)	Loss 1.4566e+00 (1.4337e+00)	Acc@1  66.00 ( 67.64)	Acc@5  89.00 ( 89.45)
Test: [ 20/100]	Time  0.024 ( 0.029)	Loss 1.3542e+00 (1.4056e+00)	Acc@1  74.00 ( 68.71)	Acc@5  93.00 ( 90.43)
Test: [ 30/100]	Time  0.016 ( 0.026)	Loss 1.7023e+00 (1.4179e+00)	Acc@1  63.00 ( 68.16)	Acc@5  89.00 ( 90.29)
Test: [ 40/100]	Time  0.018 ( 0.025)	Loss 1.3975e+00 (1.4134e+00)	Acc@1  69.00 ( 67.80)	Acc@5  88.00 ( 90.34)
Test: [ 50/100]	Time  0.017 ( 0.024)	Loss 1.5446e+00 (1.4204e+00)	Acc@1  71.00 ( 67.49)	Acc@5  91.00 ( 90.27)
Test: [ 60/100]	Time  0.018 ( 0.023)	Loss 1.6094e+00 (1.4034e+00)	Acc@1  63.00 ( 67.49)	Acc@5  89.00 ( 90.44)
Test: [ 70/100]	Time  0.018 ( 0.022)	Loss 1.4963e+00 (1.4025e+00)	Acc@1  70.00 ( 67.65)	Acc@5  90.00 ( 90.48)
Test: [ 80/100]	Time  0.019 ( 0.022)	Loss 1.4544e+00 (1.4081e+00)	Acc@1  65.00 ( 67.64)	Acc@5  89.00 ( 90.35)
Test: [ 90/100]	Time  0.019 ( 0.022)	Loss 1.5652e+00 (1.3975e+00)	Acc@1  64.00 ( 67.62)	Acc@5  89.00 ( 90.45)
 * Acc@1 67.910 Acc@5 90.500
### epoch[57] execution time: 17.30498957633972
EPOCH 58
REMOVING: module.fire4.squeeze.1.weight
REMOVING: module.fire4.squeeze.1.bias
REMOVING: module.fire4.expand_1x1.0.weight
i:   0, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.001103140535388452   to: 0.001002628302658225
i:   1, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.001180863766474121   to: 0.001024739401259166
i:   2, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.001279230899684119   to: 0.001068820049760870
i:   3, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.001397634393104013   to: 0.001134257086740519
i:   4, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.001535473857507407   to: 0.001220443258374126
i:   5, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.001692156421170526   to: 0.001326777668287692
i:   6, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.001867097059823185   to: 0.001452666188865247
i:   7, name:  module.fire5.squeeze.0.weight  changing lr from: 0.002059718893578049   to: 0.001597521835953419
i:   8, name:    module.fire5.squeeze.0.bias  changing lr from: 0.002269453452612185   to: 0.001760765108835687
i:   9, name:  module.fire5.squeeze.1.weight  changing lr from: 0.002495740913307520   to: 0.001941824297283239
i:  10, name:    module.fire5.squeeze.1.bias  changing lr from: 0.002738030306491256   to: 0.002140135757424254
i:  11, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.002995779699351652   to: 0.002355144158108357
i:  12, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.003268456352541687   to: 0.002586302699379827
i:  13, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.003555536853920365   to: 0.002833073304609928
i:  14, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.003856507230321010   to: 0.003094926787777779
i:  15, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.004170863038676109   to: 0.003371342997328452
i:  16, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.004498109437771135   to: 0.003661810937978526
i:  17, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.004837761241843008   to: 0.003965828871781435
i:  18, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.005189342957184677   to: 0.004282904399709141
i:  19, name:  module.fire6.squeeze.0.weight  changing lr from: 0.005552388802864227   to: 0.004612554524951961
i:  20, name:    module.fire6.squeeze.0.bias  changing lr from: 0.005926442716615714   to: 0.004954305699085253
i:  21, name:  module.fire6.squeeze.1.weight  changing lr from: 0.006311058346909182   to: 0.005307693852200339
i:  22, name:    module.fire6.squeeze.1.bias  changing lr from: 0.006705799032159254   to: 0.005672264408046539
i:  23, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.007110237767985711   to: 0.006047572285183700
i:  24, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.007523957163394140   to: 0.006433181885096495
i:  25, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.007946549386702195   to: 0.006828667068177812
i:  26, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.008377616101994756   to: 0.007233611118443350
i:  27, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.008816768396852182   to: 0.007647606697798809
i:  28, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.009263626702056382   to: 0.008070255790639018
i:  29, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.009717820703943274   to: 0.008501169639520023
i:  30, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.010178989250034159   to: 0.008939968672606852
i:  31, name:  module.fire7.squeeze.0.weight  changing lr from: 0.010646780248544790   to: 0.009386282423563892
i:  32, name:    module.fire7.squeeze.0.bias  changing lr from: 0.011120850562338230   to: 0.009839749444519420
i:  33, name:  module.fire7.squeeze.1.weight  changing lr from: 0.011600865897855937   to: 0.010300017212702631
i:  34, name:    module.fire7.squeeze.1.bias  changing lr from: 0.012086500689532126   to: 0.010766742031319221
i:  35, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.012577437980167288   to: 0.011239588925201011
i:  36, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.013073369297709508   to: 0.011718231531734995
i:  37, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.013573994528866252   to: 0.012202351987549809
i:  38, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.014079021789943517   to: 0.012691640811409388
i:  39, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.014588167295286537   to: 0.013185796783738973
i:  40, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.015101155223672058   to: 0.013684526823182587
i:  41, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.015617717582981812   to: 0.014187545860568772
i:  42, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.016137594073464968   to: 0.014694576710637529
i:  43, name:  module.fire8.squeeze.0.weight  changing lr from: 0.016660531949878443   to: 0.015205349941860964
i:  44, name:    module.fire8.squeeze.0.bias  changing lr from: 0.017186285882774665   to: 0.015719603744668749
i:  45, name:  module.fire8.squeeze.1.weight  changing lr from: 0.017714617819188944   to: 0.016237083798370827
i:  46, name:    module.fire8.squeeze.1.bias  changing lr from: 0.018245296842961455   to: 0.016757543137050357
i:  47, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.018778099034912350   to: 0.017280742014682254
i:  48, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.019312807333074205   to: 0.017806447769716821
i:  49, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.019849211393170293   to: 0.018334434689350337
i:  50, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.020387107449514438   to: 0.018864483873690597
i:  51, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.020926298176494190   to: 0.019396383100009903
i:  52, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.021466592550787846   to: 0.019929926687265516
i:  53, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.022007805714452919   to: 0.020464915361052743
i:  54, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.022549758839013542   to: 0.021001156119145444
i:  55, name:  module.fire9.squeeze.0.weight  changing lr from: 0.023092278990663302   to: 0.021538462097765707
i:  56, name:    module.fire9.squeeze.0.bias  changing lr from: 0.023635198996690268   to: 0.022076652438713720
i:  57, name:  module.fire9.squeeze.1.weight  changing lr from: 0.024178357313221724   to: 0.022615552157478611
i:  58, name:    module.fire9.squeeze.1.bias  changing lr from: 0.024721597894377126   to: 0.023154992012440902
i:  59, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.025264770062909558   to: 0.023694808375267884
i:  60, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.025807728382408381   to: 0.024234843102594335
i:  61, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.026350332531127719   to: 0.024774943409072776
i:  62, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.026892447177499491   to: 0.025314961741869386
i:  63, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.027433941857382238   to: 0.025854755656674541
i:  64, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.027974690853091413   to: 0.026394187695289745
i:  65, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.028514573074250683   to: 0.026933125264845981
i:  66, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.029053471940499006   to: 0.027471440518702806
i:  67, name:           module.conv10.weight  changing lr from: 0.029591275266082375   to: 0.028009010239071288
i:  68, name:             module.conv10.bias  changing lr from: 0.030127875146354961   to: 0.028545715721398458



# Switched to train mode...
Epoch: [58][  0/391]	Time  0.195 ( 0.195)	Data  0.151 ( 0.151)	Loss 2.5044e-01 (2.5044e-01)	Acc@1  92.19 ( 92.19)	Acc@5 100.00 (100.00)
Epoch: [58][ 10/391]	Time  0.040 ( 0.052)	Data  0.001 ( 0.015)	Loss 2.8557e-01 (2.9439e-01)	Acc@1  90.62 ( 91.41)	Acc@5 100.00 ( 99.57)
Epoch: [58][ 20/391]	Time  0.037 ( 0.046)	Data  0.001 ( 0.008)	Loss 3.5589e-01 (3.0035e-01)	Acc@1  92.19 ( 91.22)	Acc@5  99.22 ( 99.37)
Epoch: [58][ 30/391]	Time  0.036 ( 0.043)	Data  0.001 ( 0.006)	Loss 2.4930e-01 (3.1019e-01)	Acc@1  94.53 ( 91.08)	Acc@5  99.22 ( 99.27)
Epoch: [58][ 40/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.005)	Loss 2.9069e-01 (3.1541e-01)	Acc@1  90.62 ( 90.57)	Acc@5 100.00 ( 99.26)
Epoch: [58][ 50/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.004)	Loss 2.9364e-01 (3.1393e-01)	Acc@1  91.41 ( 90.66)	Acc@5 100.00 ( 99.23)
Epoch: [58][ 60/391]	Time  0.037 ( 0.041)	Data  0.001 ( 0.003)	Loss 2.9460e-01 (3.1945e-01)	Acc@1  93.75 ( 90.37)	Acc@5  99.22 ( 99.26)
Epoch: [58][ 70/391]	Time  0.037 ( 0.040)	Data  0.001 ( 0.003)	Loss 3.7441e-01 (3.2574e-01)	Acc@1  89.06 ( 90.12)	Acc@5  99.22 ( 99.24)
Epoch: [58][ 80/391]	Time  0.036 ( 0.040)	Data  0.001 ( 0.003)	Loss 2.7638e-01 (3.2537e-01)	Acc@1  91.41 ( 90.09)	Acc@5  98.44 ( 99.21)
Epoch: [58][ 90/391]	Time  0.034 ( 0.040)	Data  0.001 ( 0.003)	Loss 3.8363e-01 (3.2730e-01)	Acc@1  85.94 ( 90.02)	Acc@5  99.22 ( 99.22)
Epoch: [58][100/391]	Time  0.035 ( 0.039)	Data  0.001 ( 0.002)	Loss 4.0249e-01 (3.2902e-01)	Acc@1  87.50 ( 90.01)	Acc@5  99.22 ( 99.23)
Epoch: [58][110/391]	Time  0.038 ( 0.039)	Data  0.001 ( 0.002)	Loss 3.0990e-01 (3.2894e-01)	Acc@1  92.97 ( 90.03)	Acc@5  99.22 ( 99.22)
Epoch: [58][120/391]	Time  0.037 ( 0.039)	Data  0.001 ( 0.002)	Loss 3.9804e-01 (3.2711e-01)	Acc@1  86.72 ( 90.06)	Acc@5  99.22 ( 99.23)
Epoch: [58][130/391]	Time  0.039 ( 0.039)	Data  0.001 ( 0.002)	Loss 3.9176e-01 (3.2861e-01)	Acc@1  87.50 ( 89.99)	Acc@5  98.44 ( 99.24)
Epoch: [58][140/391]	Time  0.036 ( 0.039)	Data  0.001 ( 0.002)	Loss 3.6646e-01 (3.2838e-01)	Acc@1  90.62 ( 90.04)	Acc@5  99.22 ( 99.21)
Epoch: [58][150/391]	Time  0.036 ( 0.039)	Data  0.001 ( 0.002)	Loss 4.3689e-01 (3.2805e-01)	Acc@1  87.50 ( 90.03)	Acc@5  99.22 ( 99.24)
Epoch: [58][160/391]	Time  0.039 ( 0.039)	Data  0.001 ( 0.002)	Loss 3.1504e-01 (3.2990e-01)	Acc@1  89.06 ( 90.00)	Acc@5 100.00 ( 99.25)
Epoch: [58][170/391]	Time  0.036 ( 0.039)	Data  0.001 ( 0.002)	Loss 4.1882e-01 (3.3055e-01)	Acc@1  87.50 ( 89.98)	Acc@5  99.22 ( 99.26)
Epoch: [58][180/391]	Time  0.036 ( 0.039)	Data  0.001 ( 0.002)	Loss 3.5777e-01 (3.3222e-01)	Acc@1  89.84 ( 89.91)	Acc@5  98.44 ( 99.26)
Epoch: [58][190/391]	Time  0.038 ( 0.039)	Data  0.001 ( 0.002)	Loss 4.4877e-01 (3.3314e-01)	Acc@1  88.28 ( 89.87)	Acc@5  96.88 ( 99.25)
Epoch: [58][200/391]	Time  0.036 ( 0.038)	Data  0.001 ( 0.002)	Loss 4.7857e-01 (3.3577e-01)	Acc@1  84.38 ( 89.80)	Acc@5  99.22 ( 99.24)
Epoch: [58][210/391]	Time  0.037 ( 0.038)	Data  0.001 ( 0.002)	Loss 3.1926e-01 (3.3589e-01)	Acc@1  90.62 ( 89.81)	Acc@5  98.44 ( 99.23)
Epoch: [58][220/391]	Time  0.037 ( 0.038)	Data  0.001 ( 0.002)	Loss 3.7969e-01 (3.3788e-01)	Acc@1  91.41 ( 89.73)	Acc@5  98.44 ( 99.23)
Epoch: [58][230/391]	Time  0.041 ( 0.038)	Data  0.001 ( 0.002)	Loss 2.5552e-01 (3.3850e-01)	Acc@1  91.41 ( 89.70)	Acc@5  99.22 ( 99.23)
Epoch: [58][240/391]	Time  0.037 ( 0.038)	Data  0.001 ( 0.002)	Loss 3.5887e-01 (3.3990e-01)	Acc@1  89.06 ( 89.66)	Acc@5  99.22 ( 99.22)
Epoch: [58][250/391]	Time  0.037 ( 0.038)	Data  0.001 ( 0.002)	Loss 5.0432e-01 (3.4094e-01)	Acc@1  81.25 ( 89.63)	Acc@5  98.44 ( 99.20)
Epoch: [58][260/391]	Time  0.037 ( 0.038)	Data  0.001 ( 0.002)	Loss 3.8368e-01 (3.4278e-01)	Acc@1  88.28 ( 89.54)	Acc@5  99.22 ( 99.18)
Epoch: [58][270/391]	Time  0.036 ( 0.038)	Data  0.001 ( 0.002)	Loss 4.5572e-01 (3.4356e-01)	Acc@1  83.59 ( 89.52)	Acc@5  98.44 ( 99.18)
Epoch: [58][280/391]	Time  0.038 ( 0.038)	Data  0.001 ( 0.002)	Loss 3.5481e-01 (3.4494e-01)	Acc@1  89.06 ( 89.45)	Acc@5  98.44 ( 99.17)
Epoch: [58][290/391]	Time  0.037 ( 0.038)	Data  0.001 ( 0.002)	Loss 2.4159e-01 (3.4535e-01)	Acc@1  90.62 ( 89.45)	Acc@5 100.00 ( 99.17)
Epoch: [58][300/391]	Time  0.037 ( 0.038)	Data  0.001 ( 0.002)	Loss 2.6070e-01 (3.4592e-01)	Acc@1  91.41 ( 89.43)	Acc@5 100.00 ( 99.15)
Epoch: [58][310/391]	Time  0.036 ( 0.038)	Data  0.001 ( 0.001)	Loss 3.5431e-01 (3.4615e-01)	Acc@1  86.72 ( 89.40)	Acc@5  99.22 ( 99.15)
Epoch: [58][320/391]	Time  0.039 ( 0.038)	Data  0.001 ( 0.001)	Loss 2.7518e-01 (3.4746e-01)	Acc@1  92.19 ( 89.34)	Acc@5  97.66 ( 99.15)
Epoch: [58][330/391]	Time  0.036 ( 0.038)	Data  0.001 ( 0.001)	Loss 4.8276e-01 (3.4964e-01)	Acc@1  84.38 ( 89.27)	Acc@5  96.88 ( 99.12)
Epoch: [58][340/391]	Time  0.040 ( 0.038)	Data  0.001 ( 0.001)	Loss 4.9152e-01 (3.4958e-01)	Acc@1  84.38 ( 89.27)	Acc@5  98.44 ( 99.13)
Epoch: [58][350/391]	Time  0.036 ( 0.038)	Data  0.001 ( 0.001)	Loss 3.1124e-01 (3.5001e-01)	Acc@1  91.41 ( 89.26)	Acc@5  99.22 ( 99.12)
Epoch: [58][360/391]	Time  0.036 ( 0.038)	Data  0.001 ( 0.001)	Loss 4.1571e-01 (3.5042e-01)	Acc@1  86.72 ( 89.24)	Acc@5 100.00 ( 99.13)
Epoch: [58][370/391]	Time  0.036 ( 0.038)	Data  0.001 ( 0.001)	Loss 4.0369e-01 (3.5115e-01)	Acc@1  84.38 ( 89.22)	Acc@5 100.00 ( 99.14)
Epoch: [58][380/391]	Time  0.039 ( 0.038)	Data  0.001 ( 0.001)	Loss 4.2243e-01 (3.5168e-01)	Acc@1  86.72 ( 89.17)	Acc@5  99.22 ( 99.14)
Epoch: [58][390/391]	Time  0.023 ( 0.038)	Data  0.001 ( 0.001)	Loss 4.5928e-01 (3.5224e-01)	Acc@1  85.00 ( 89.15)	Acc@5  98.75 ( 99.15)
## e[58] optimizer.zero_grad (sum) time: 0.19546747207641602
## e[58]       loss.backward (sum) time: 3.377531051635742
## e[58]      optimizer.step (sum) time: 1.3313298225402832
## epoch[58] training(only) time: 14.93217945098877
# Switched to evaluate mode...
Test: [  0/100]	Time  0.153 ( 0.153)	Loss 1.1411e+00 (1.1411e+00)	Acc@1  71.00 ( 71.00)	Acc@5  87.00 ( 87.00)
Test: [ 10/100]	Time  0.025 ( 0.035)	Loss 1.3523e+00 (1.4099e+00)	Acc@1  66.00 ( 68.36)	Acc@5  92.00 ( 88.91)
Test: [ 20/100]	Time  0.023 ( 0.028)	Loss 1.2137e+00 (1.3876e+00)	Acc@1  71.00 ( 68.14)	Acc@5  94.00 ( 89.76)
Test: [ 30/100]	Time  0.025 ( 0.027)	Loss 1.6759e+00 (1.4149e+00)	Acc@1  57.00 ( 67.06)	Acc@5  89.00 ( 89.58)
Test: [ 40/100]	Time  0.022 ( 0.026)	Loss 1.3471e+00 (1.4111e+00)	Acc@1  69.00 ( 67.34)	Acc@5  92.00 ( 89.80)
Test: [ 50/100]	Time  0.025 ( 0.025)	Loss 1.4924e+00 (1.4220e+00)	Acc@1  70.00 ( 67.33)	Acc@5  91.00 ( 89.80)
Test: [ 60/100]	Time  0.023 ( 0.025)	Loss 1.6502e+00 (1.4003e+00)	Acc@1  61.00 ( 67.43)	Acc@5  84.00 ( 90.13)
Test: [ 70/100]	Time  0.024 ( 0.024)	Loss 1.6485e+00 (1.4039e+00)	Acc@1  68.00 ( 67.35)	Acc@5  86.00 ( 90.14)
Test: [ 80/100]	Time  0.024 ( 0.024)	Loss 1.4193e+00 (1.4058e+00)	Acc@1  69.00 ( 67.41)	Acc@5  90.00 ( 90.06)
Test: [ 90/100]	Time  0.022 ( 0.024)	Loss 1.6145e+00 (1.3939e+00)	Acc@1  66.00 ( 67.62)	Acc@5  90.00 ( 90.08)
 * Acc@1 67.800 Acc@5 90.280
### epoch[58] execution time: 17.36382508277893
EPOCH 59
REMOVING: module.fire4.expand_1x1.0.bias
REMOVING: module.fire4.expand_1x1.1.weight
REMOVING: module.fire4.expand_1x1.1.bias
i:   0, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.001134257086740519   to: 0.001010400584188175
i:   1, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.001220443258374126   to: 0.001042825340545921
i:   2, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.001326777668287692   to: 0.001096684141924475
i:   3, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.001452666188865247   to: 0.001171376883197799
i:   4, name:  module.fire5.squeeze.0.weight  changing lr from: 0.001597521835953419   to: 0.001266309443438539
i:   5, name:    module.fire5.squeeze.0.bias  changing lr from: 0.001760765108835687   to: 0.001380894105545732
i:   6, name:  module.fire5.squeeze.1.weight  changing lr from: 0.001941824297283239   to: 0.001514549939495595
i:   7, name:    module.fire5.squeeze.1.bias  changing lr from: 0.002140135757424254   to: 0.001666703151050046
i:   8, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.002355144158108357   to: 0.001836787397693883
i:   9, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.002586302699379827   to: 0.002024244073509073
i:  10, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.002833073304609928   to: 0.002228522564632079
i:  11, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.003094926787777779   to: 0.002449080476879089
i:  12, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.003371342997328452   to: 0.002685383837063242
i:  13, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.003661810937978526   to: 0.002936907269468819
i:  14, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.003965828871781435   to: 0.003203134148888969
i:  15, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.004282904399709141   to: 0.003483556731576519
i:  16, name:  module.fire6.squeeze.0.weight  changing lr from: 0.004612554524951961   to: 0.003777676265401785
i:  17, name:    module.fire6.squeeze.0.bias  changing lr from: 0.004954305699085253   to: 0.004085003080456744
i:  18, name:  module.fire6.squeeze.1.weight  changing lr from: 0.005307693852200339   to: 0.004405056661292033
i:  19, name:    module.fire6.squeeze.1.bias  changing lr from: 0.005672264408046539   to: 0.004737365701921402
i:  20, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.006047572285183700   to: 0.005081468144678707
i:  21, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.006433181885096495   to: 0.005436911203962957
i:  22, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.006828667068177812   to: 0.005803251375860563
i:  23, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.007233611118443350   to: 0.006180054434587578
i:  24, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.007647606697798809   to: 0.006566895416651180
i:  25, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.008070255790639018   to: 0.006963358593585905
i:  26, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.008501169639520023   to: 0.007369037434079867
i:  27, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.008939968672606852   to: 0.007783534556265703
i:  28, name:  module.fire7.squeeze.0.weight  changing lr from: 0.009386282423563892   to: 0.008206461670912740
i:  29, name:    module.fire7.squeeze.0.bias  changing lr from: 0.009839749444519420   to: 0.008637439516220018
i:  30, name:  module.fire7.squeeze.1.weight  changing lr from: 0.010300017212702631   to: 0.009076097784874105
i:  31, name:    module.fire7.squeeze.1.bias  changing lr from: 0.010766742031319221   to: 0.009522075044001037
i:  32, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.011239588925201011   to: 0.009975018648609713
i:  33, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.011718231531734995   to: 0.010434584649091395
i:  34, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.012202351987549809   to: 0.010900437693310540
i:  35, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.012691640811409388   to: 0.011372250923792342
i:  36, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.013185796783738973   to: 0.011849705870485373
i:  37, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.013684526823182587   to: 0.012332492339549896
i:  38, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.014187545860568772   to: 0.012820308298598353
i:  39, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.014694576710637529   to: 0.013312859758788431
i:  40, name:  module.fire8.squeeze.0.weight  changing lr from: 0.015205349941860964   to: 0.013809860654147167
i:  41, name:    module.fire8.squeeze.0.bias  changing lr from: 0.015719603744668749   to: 0.014311032718481421
i:  42, name:  module.fire8.squeeze.1.weight  changing lr from: 0.016237083798370827   to: 0.014816105360209171
i:  43, name:    module.fire8.squeeze.1.bias  changing lr from: 0.016757543137050357   to: 0.015324815535425522
i:  44, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.017280742014682254   to: 0.015836907619497891
i:  45, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.017806447769716821   to: 0.016352133277466846
i:  46, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.018334434689350337   to: 0.016870251333510795
i:  47, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.018864483873690597   to: 0.017391027639716544
i:  48, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.019396383100009903   to: 0.017914234944381303
i:  49, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.019929926687265516   to: 0.018439652760057341
i:  50, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.020464915361052743   to: 0.018967067231535018
i:  51, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.021001156119145444   to: 0.019496271003947237
i:  52, name:  module.fire9.squeeze.0.weight  changing lr from: 0.021538462097765707   to: 0.020027063091164976
i:  53, name:    module.fire9.squeeze.0.bias  changing lr from: 0.022076652438713720   to: 0.020559248744640796
i:  54, name:  module.fire9.squeeze.1.weight  changing lr from: 0.022615552157478611   to: 0.021092639322846569
i:  55, name:    module.fire9.squeeze.1.bias  changing lr from: 0.023154992012440902   to: 0.021627052161439689
i:  56, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.023694808375267884   to: 0.022162310444281866
i:  57, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.024234843102594335   to: 0.022698243075424802
i:  58, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.024774943409072776   to: 0.023234684552167702
i:  59, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.025314961741869386   to: 0.023771474839282006
i:  60, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.025854755656674541   to: 0.024308459244491806
i:  61, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.026394187695289745   to: 0.024845488295288744
i:  62, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.026933125264845981   to: 0.025382417617153992
i:  63, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.027471440518702806   to: 0.025919107813252525
i:  64, name:           module.conv10.weight  changing lr from: 0.028009010239071288   to: 0.026455424345658042
i:  65, name:             module.conv10.bias  changing lr from: 0.028545715721398458   to: 0.026991237418160913



# Switched to train mode...
Epoch: [59][  0/391]	Time  0.197 ( 0.197)	Data  0.155 ( 0.155)	Loss 3.5916e-01 (3.5916e-01)	Acc@1  89.84 ( 89.84)	Acc@5  99.22 ( 99.22)
Epoch: [59][ 10/391]	Time  0.038 ( 0.053)	Data  0.001 ( 0.015)	Loss 4.4084e-01 (3.6362e-01)	Acc@1  87.50 ( 88.64)	Acc@5  98.44 ( 99.08)
Epoch: [59][ 20/391]	Time  0.038 ( 0.045)	Data  0.001 ( 0.008)	Loss 2.2033e-01 (3.4229e-01)	Acc@1  92.97 ( 89.25)	Acc@5 100.00 ( 99.33)
Epoch: [59][ 30/391]	Time  0.036 ( 0.043)	Data  0.001 ( 0.006)	Loss 3.0647e-01 (3.3630e-01)	Acc@1  90.62 ( 89.59)	Acc@5  99.22 ( 99.27)
Epoch: [59][ 40/391]	Time  0.037 ( 0.041)	Data  0.001 ( 0.005)	Loss 3.6667e-01 (3.3775e-01)	Acc@1  85.16 ( 89.42)	Acc@5 100.00 ( 99.31)
Epoch: [59][ 50/391]	Time  0.036 ( 0.040)	Data  0.001 ( 0.004)	Loss 2.9557e-01 (3.3472e-01)	Acc@1  89.84 ( 89.58)	Acc@5 100.00 ( 99.34)
Epoch: [59][ 60/391]	Time  0.036 ( 0.040)	Data  0.001 ( 0.003)	Loss 2.3509e-01 (3.3128e-01)	Acc@1  94.53 ( 89.91)	Acc@5 100.00 ( 99.35)
Epoch: [59][ 70/391]	Time  0.037 ( 0.039)	Data  0.001 ( 0.003)	Loss 3.6330e-01 (3.3196e-01)	Acc@1  87.50 ( 89.88)	Acc@5  99.22 ( 99.33)
Epoch: [59][ 80/391]	Time  0.036 ( 0.039)	Data  0.001 ( 0.003)	Loss 2.5272e-01 (3.2959e-01)	Acc@1  92.97 ( 89.92)	Acc@5  99.22 ( 99.32)
Epoch: [59][ 90/391]	Time  0.038 ( 0.039)	Data  0.001 ( 0.003)	Loss 2.5874e-01 (3.2814e-01)	Acc@1  90.62 ( 89.98)	Acc@5  99.22 ( 99.35)
Epoch: [59][100/391]	Time  0.036 ( 0.039)	Data  0.001 ( 0.002)	Loss 4.1294e-01 (3.3034e-01)	Acc@1  89.06 ( 89.91)	Acc@5  96.88 ( 99.29)
Epoch: [59][110/391]	Time  0.038 ( 0.039)	Data  0.001 ( 0.002)	Loss 3.9883e-01 (3.2919e-01)	Acc@1  87.50 ( 89.89)	Acc@5  99.22 ( 99.30)
Epoch: [59][120/391]	Time  0.036 ( 0.039)	Data  0.001 ( 0.002)	Loss 3.3548e-01 (3.2659e-01)	Acc@1  89.84 ( 90.02)	Acc@5  99.22 ( 99.31)
Epoch: [59][130/391]	Time  0.036 ( 0.038)	Data  0.001 ( 0.002)	Loss 3.0348e-01 (3.2499e-01)	Acc@1  89.06 ( 90.03)	Acc@5 100.00 ( 99.30)
Epoch: [59][140/391]	Time  0.036 ( 0.038)	Data  0.001 ( 0.002)	Loss 3.1357e-01 (3.2515e-01)	Acc@1  89.84 ( 90.05)	Acc@5  99.22 ( 99.28)
Epoch: [59][150/391]	Time  0.049 ( 0.038)	Data  0.001 ( 0.002)	Loss 3.7265e-01 (3.2748e-01)	Acc@1  85.16 ( 89.94)	Acc@5  99.22 ( 99.29)
Epoch: [59][160/391]	Time  0.039 ( 0.038)	Data  0.001 ( 0.002)	Loss 3.1564e-01 (3.2781e-01)	Acc@1  89.06 ( 89.90)	Acc@5 100.00 ( 99.29)
Epoch: [59][170/391]	Time  0.036 ( 0.038)	Data  0.001 ( 0.002)	Loss 3.8803e-01 (3.3067e-01)	Acc@1  85.16 ( 89.80)	Acc@5 100.00 ( 99.26)
Epoch: [59][180/391]	Time  0.037 ( 0.038)	Data  0.001 ( 0.002)	Loss 3.0863e-01 (3.2934e-01)	Acc@1  91.41 ( 89.92)	Acc@5  99.22 ( 99.25)
Epoch: [59][190/391]	Time  0.039 ( 0.038)	Data  0.001 ( 0.002)	Loss 3.6513e-01 (3.2932e-01)	Acc@1  89.06 ( 89.91)	Acc@5  97.66 ( 99.25)
Epoch: [59][200/391]	Time  0.037 ( 0.038)	Data  0.001 ( 0.002)	Loss 3.6666e-01 (3.3131e-01)	Acc@1  88.28 ( 89.86)	Acc@5  96.88 ( 99.23)
Epoch: [59][210/391]	Time  0.036 ( 0.038)	Data  0.001 ( 0.002)	Loss 2.8933e-01 (3.3093e-01)	Acc@1  89.84 ( 89.87)	Acc@5 100.00 ( 99.23)
Epoch: [59][220/391]	Time  0.038 ( 0.038)	Data  0.001 ( 0.002)	Loss 3.4062e-01 (3.3203e-01)	Acc@1  90.62 ( 89.81)	Acc@5  98.44 ( 99.23)
Epoch: [59][230/391]	Time  0.037 ( 0.038)	Data  0.001 ( 0.002)	Loss 3.7805e-01 (3.3339e-01)	Acc@1  90.62 ( 89.79)	Acc@5  98.44 ( 99.20)
Epoch: [59][240/391]	Time  0.038 ( 0.038)	Data  0.001 ( 0.002)	Loss 2.5574e-01 (3.3362e-01)	Acc@1  91.41 ( 89.79)	Acc@5 100.00 ( 99.18)
Epoch: [59][250/391]	Time  0.036 ( 0.038)	Data  0.001 ( 0.002)	Loss 2.4375e-01 (3.3272e-01)	Acc@1  92.97 ( 89.81)	Acc@5 100.00 ( 99.18)
Epoch: [59][260/391]	Time  0.037 ( 0.038)	Data  0.001 ( 0.002)	Loss 4.1328e-01 (3.3443e-01)	Acc@1  85.16 ( 89.75)	Acc@5 100.00 ( 99.19)
Epoch: [59][270/391]	Time  0.034 ( 0.038)	Data  0.001 ( 0.002)	Loss 3.3031e-01 (3.3649e-01)	Acc@1  88.28 ( 89.67)	Acc@5  99.22 ( 99.18)
Epoch: [59][280/391]	Time  0.037 ( 0.038)	Data  0.001 ( 0.002)	Loss 4.2613e-01 (3.3550e-01)	Acc@1  83.59 ( 89.70)	Acc@5  99.22 ( 99.19)
Epoch: [59][290/391]	Time  0.036 ( 0.038)	Data  0.001 ( 0.001)	Loss 3.7470e-01 (3.3625e-01)	Acc@1  90.62 ( 89.68)	Acc@5  99.22 ( 99.19)
Epoch: [59][300/391]	Time  0.035 ( 0.038)	Data  0.001 ( 0.001)	Loss 2.2767e-01 (3.3520e-01)	Acc@1  92.97 ( 89.70)	Acc@5  99.22 ( 99.19)
Epoch: [59][310/391]	Time  0.036 ( 0.038)	Data  0.001 ( 0.001)	Loss 4.4204e-01 (3.3534e-01)	Acc@1  86.72 ( 89.68)	Acc@5  98.44 ( 99.19)
Epoch: [59][320/391]	Time  0.037 ( 0.038)	Data  0.001 ( 0.001)	Loss 4.0810e-01 (3.3457e-01)	Acc@1  87.50 ( 89.71)	Acc@5  98.44 ( 99.19)
Epoch: [59][330/391]	Time  0.038 ( 0.038)	Data  0.001 ( 0.001)	Loss 3.6597e-01 (3.3504e-01)	Acc@1  89.06 ( 89.68)	Acc@5  99.22 ( 99.19)
Epoch: [59][340/391]	Time  0.036 ( 0.038)	Data  0.001 ( 0.001)	Loss 4.7241e-01 (3.3638e-01)	Acc@1  82.81 ( 89.62)	Acc@5 100.00 ( 99.19)
Epoch: [59][350/391]	Time  0.037 ( 0.038)	Data  0.001 ( 0.001)	Loss 2.7128e-01 (3.3730e-01)	Acc@1  92.19 ( 89.58)	Acc@5 100.00 ( 99.19)
Epoch: [59][360/391]	Time  0.035 ( 0.038)	Data  0.001 ( 0.001)	Loss 2.5819e-01 (3.3715e-01)	Acc@1  92.97 ( 89.58)	Acc@5  99.22 ( 99.18)
Epoch: [59][370/391]	Time  0.036 ( 0.038)	Data  0.001 ( 0.001)	Loss 4.0964e-01 (3.3840e-01)	Acc@1  86.72 ( 89.53)	Acc@5  97.66 ( 99.16)
Epoch: [59][380/391]	Time  0.048 ( 0.038)	Data  0.001 ( 0.001)	Loss 3.5184e-01 (3.3927e-01)	Acc@1  90.62 ( 89.50)	Acc@5  99.22 ( 99.17)
Epoch: [59][390/391]	Time  0.023 ( 0.038)	Data  0.001 ( 0.001)	Loss 3.6583e-01 (3.4040e-01)	Acc@1  87.50 ( 89.49)	Acc@5 100.00 ( 99.15)
## e[59] optimizer.zero_grad (sum) time: 0.19089221954345703
## e[59]       loss.backward (sum) time: 3.4219532012939453
## e[59]      optimizer.step (sum) time: 1.2371759414672852
## epoch[59] training(only) time: 14.756007671356201
# Switched to evaluate mode...
Test: [  0/100]	Time  0.160 ( 0.160)	Loss 1.1286e+00 (1.1286e+00)	Acc@1  72.00 ( 72.00)	Acc@5  87.00 ( 87.00)
Test: [ 10/100]	Time  0.022 ( 0.034)	Loss 1.2837e+00 (1.4386e+00)	Acc@1  65.00 ( 67.45)	Acc@5  91.00 ( 89.18)
Test: [ 20/100]	Time  0.023 ( 0.029)	Loss 1.1775e+00 (1.4059e+00)	Acc@1  71.00 ( 67.14)	Acc@5  94.00 ( 90.00)
Test: [ 30/100]	Time  0.018 ( 0.027)	Loss 1.6629e+00 (1.4394e+00)	Acc@1  58.00 ( 66.39)	Acc@5  90.00 ( 89.81)
Test: [ 40/100]	Time  0.023 ( 0.026)	Loss 1.4231e+00 (1.4255e+00)	Acc@1  66.00 ( 66.61)	Acc@5  89.00 ( 89.90)
Test: [ 50/100]	Time  0.024 ( 0.025)	Loss 1.3805e+00 (1.4268e+00)	Acc@1  68.00 ( 66.51)	Acc@5  92.00 ( 89.88)
Test: [ 60/100]	Time  0.024 ( 0.025)	Loss 1.6517e+00 (1.4060e+00)	Acc@1  58.00 ( 66.66)	Acc@5  86.00 ( 90.18)
Test: [ 70/100]	Time  0.017 ( 0.024)	Loss 1.4849e+00 (1.4043e+00)	Acc@1  67.00 ( 66.77)	Acc@5  89.00 ( 90.21)
Test: [ 80/100]	Time  0.020 ( 0.024)	Loss 1.5763e+00 (1.4104e+00)	Acc@1  72.00 ( 66.75)	Acc@5  88.00 ( 90.06)
Test: [ 90/100]	Time  0.018 ( 0.023)	Loss 1.6787e+00 (1.3953e+00)	Acc@1  62.00 ( 67.14)	Acc@5  88.00 ( 90.16)
 * Acc@1 67.380 Acc@5 90.300
### epoch[59] execution time: 17.11316728591919
EPOCH 60
REMOVING: module.fire4.expand_3x3.0.weight
REMOVING: module.fire4.expand_3x3.0.bias
i:   0, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.001096684141924475   to: 0.001002502502751811
i:   1, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.001171376883197799   to: 0.001023985011917632
i:   2, name:  module.fire5.squeeze.0.weight  changing lr from: 0.001266309443438539   to: 0.001066959885427470
i:   3, name:    module.fire5.squeeze.0.bias  changing lr from: 0.001380894105545732   to: 0.001130834243163464
i:   4, name:  module.fire5.squeeze.1.weight  changing lr from: 0.001514549939495595   to: 0.001215020836311269
i:   5, name:    module.fire5.squeeze.1.bias  changing lr from: 0.001666703151050046   to: 0.001318938473976182
i:   6, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.001836787397693883   to: 0.001442012413699461
i:   7, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.002024244073509073   to: 0.001583674717670152
i:   8, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.002228522564632079   to: 0.001743364576366889
i:   9, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.002449080476879089   to: 0.001920528601303755
i:  10, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.002685383837063242   to: 0.002114621088494339
i:  11, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.002936907269468819   to: 0.002325104254189341
i:  12, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.003203134148888969   to: 0.002551448444384401
i:  13, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.003483556731576519   to: 0.002793132319537649
i:  14, name:  module.fire6.squeeze.0.weight  changing lr from: 0.003777676265401785   to: 0.003049643015880348
i:  15, name:    module.fire6.squeeze.0.bias  changing lr from: 0.004085003080456744   to: 0.003320476284648487
i:  16, name:  module.fire6.squeeze.1.weight  changing lr from: 0.004405056661292033   to: 0.003605136610509357
i:  17, name:    module.fire6.squeeze.1.bias  changing lr from: 0.004737365701921402   to: 0.003903137310404347
i:  18, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.005081468144678707   to: 0.004214000613977941
i:  19, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.005436911203962957   to: 0.004537257726712356
i:  20, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.005803251375860563   to: 0.004872448876838952
i:  21, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.006180054434587578   to: 0.005219123347049864
i:  22, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.006566895416651180   to: 0.005576839491987572
i:  23, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.006963358593585905   to: 0.005945164742445291
i:  24, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.007369037434079867   to: 0.006323675597168143
i:  25, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.007783534556265703   to: 0.006711957603103269
i:  26, name:  module.fire7.squeeze.0.weight  changing lr from: 0.008206461670912740   to: 0.007109605324906564
i:  27, name:    module.fire7.squeeze.0.bias  changing lr from: 0.008637439516220018   to: 0.007516222304475056
i:  28, name:  module.fire7.squeeze.1.weight  changing lr from: 0.009076097784874105   to: 0.007931421011235913
i:  29, name:    module.fire7.squeeze.1.bias  changing lr from: 0.009522075044001037   to: 0.008354822783887265
i:  30, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.009975018648609713   to: 0.008786057764251037
i:  31, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.010434584649091395   to: 0.009224764823864102
i:  32, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.010900437693310540   to: 0.009670591483902317
i:  33, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.011372250923792342   to: 0.010123193829000360
i:  34, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.011849705870485373   to: 0.010582236415501118
i:  35, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.012332492339549896   to: 0.011047392174639115
i:  36, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.012820308298598353   to: 0.011518342311135930
i:  37, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.013312859758788431   to: 0.011994776197658107
i:  38, name:  module.fire8.squeeze.0.weight  changing lr from: 0.013809860654147167   to: 0.012476391265564150
i:  39, name:    module.fire8.squeeze.0.bias  changing lr from: 0.014311032718481421   to: 0.012962892892341975
i:  40, name:  module.fire8.squeeze.1.weight  changing lr from: 0.014816105360209171   to: 0.013453994286116266
i:  41, name:    module.fire8.squeeze.1.bias  changing lr from: 0.015324815535425522   to: 0.013949416367582061
i:  42, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.015836907619497891   to: 0.014448887649700599
i:  43, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.016352133277466846   to: 0.014952144115473253
i:  44, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.016870251333510795   to: 0.015458929094089885
i:  45, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.017391027639716544   to: 0.015968993135730060
i:  46, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.017914234944381303   to: 0.016482093885277820
i:  47, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.018439652760057341   to: 0.016997995955194436
i:  48, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.018967067231535018   to: 0.017516470797777395
i:  49, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.019496271003947237   to: 0.018037296577019135
i:  50, name:  module.fire9.squeeze.0.weight  changing lr from: 0.020027063091164976   to: 0.018560258040264638
i:  51, name:    module.fire9.squeeze.0.bias  changing lr from: 0.020559248744640796   to: 0.019085146389853303
i:  52, name:  module.fire9.squeeze.1.weight  changing lr from: 0.021092639322846569   to: 0.019611759154917658
i:  53, name:    module.fire9.squeeze.1.bias  changing lr from: 0.021627052161439689   to: 0.020139900063499451
i:  54, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.022162310444281866   to: 0.020669378915131577
i:  55, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.022698243075424802   to: 0.021200011454023560
i:  56, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.023234684552167702   to: 0.021731619242977913
i:  57, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.023771474839282006   to: 0.022264029538154526
i:  58, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.024308459244491806   to: 0.022797075164791038
i:  59, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.024845488295288744   to: 0.023330594393978450
i:  60, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.025382417617153992   to: 0.023864430820582167
i:  61, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.025919107813252525   to: 0.024398433242391760
i:  62, name:           module.conv10.weight  changing lr from: 0.026455424345658042   to: 0.024932455540574328
i:  63, name:             module.conv10.bias  changing lr from: 0.026991237418160913   to: 0.025466356561499877



# Switched to train mode...
Epoch: [60][  0/391]	Time  0.186 ( 0.186)	Data  0.144 ( 0.144)	Loss 2.3235e-01 (2.3235e-01)	Acc@1  93.75 ( 93.75)	Acc@5  99.22 ( 99.22)
Epoch: [60][ 10/391]	Time  0.037 ( 0.052)	Data  0.001 ( 0.014)	Loss 2.6063e-01 (2.7788e-01)	Acc@1  91.41 ( 91.97)	Acc@5  98.44 ( 99.57)
Epoch: [60][ 20/391]	Time  0.038 ( 0.045)	Data  0.001 ( 0.008)	Loss 2.6048e-01 (2.9689e-01)	Acc@1  92.19 ( 90.74)	Acc@5 100.00 ( 99.44)
Epoch: [60][ 30/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.006)	Loss 2.3415e-01 (2.9590e-01)	Acc@1  92.19 ( 90.88)	Acc@5 100.00 ( 99.45)
Epoch: [60][ 40/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.004)	Loss 2.7856e-01 (2.9206e-01)	Acc@1  92.19 ( 90.91)	Acc@5  99.22 ( 99.47)
Epoch: [60][ 50/391]	Time  0.036 ( 0.040)	Data  0.001 ( 0.004)	Loss 3.7638e-01 (2.9606e-01)	Acc@1  89.06 ( 90.78)	Acc@5  99.22 ( 99.40)
Epoch: [60][ 60/391]	Time  0.036 ( 0.040)	Data  0.001 ( 0.003)	Loss 3.1388e-01 (3.0183e-01)	Acc@1  93.75 ( 90.66)	Acc@5 100.00 ( 99.36)
Epoch: [60][ 70/391]	Time  0.035 ( 0.039)	Data  0.001 ( 0.003)	Loss 2.6846e-01 (2.9798e-01)	Acc@1  92.19 ( 90.78)	Acc@5 100.00 ( 99.42)
Epoch: [60][ 80/391]	Time  0.036 ( 0.039)	Data  0.001 ( 0.003)	Loss 2.6854e-01 (3.0076e-01)	Acc@1  92.97 ( 90.77)	Acc@5  99.22 ( 99.39)
Epoch: [60][ 90/391]	Time  0.037 ( 0.039)	Data  0.001 ( 0.002)	Loss 3.2017e-01 (3.0088e-01)	Acc@1  90.62 ( 90.86)	Acc@5  99.22 ( 99.40)
Epoch: [60][100/391]	Time  0.040 ( 0.038)	Data  0.001 ( 0.002)	Loss 3.0677e-01 (3.0252e-01)	Acc@1  91.41 ( 90.77)	Acc@5 100.00 ( 99.40)
Epoch: [60][110/391]	Time  0.035 ( 0.038)	Data  0.001 ( 0.002)	Loss 2.2303e-01 (3.0146e-01)	Acc@1  93.75 ( 90.82)	Acc@5 100.00 ( 99.41)
Epoch: [60][120/391]	Time  0.036 ( 0.038)	Data  0.001 ( 0.002)	Loss 2.9703e-01 (3.0151e-01)	Acc@1  91.41 ( 90.81)	Acc@5  99.22 ( 99.41)
Epoch: [60][130/391]	Time  0.037 ( 0.038)	Data  0.001 ( 0.002)	Loss 3.9364e-01 (3.0443e-01)	Acc@1  84.38 ( 90.70)	Acc@5  99.22 ( 99.40)
Epoch: [60][140/391]	Time  0.041 ( 0.038)	Data  0.001 ( 0.002)	Loss 2.6609e-01 (3.0634e-01)	Acc@1  93.75 ( 90.64)	Acc@5  98.44 ( 99.38)
Epoch: [60][150/391]	Time  0.037 ( 0.038)	Data  0.001 ( 0.002)	Loss 3.3908e-01 (3.0623e-01)	Acc@1  89.84 ( 90.60)	Acc@5  99.22 ( 99.38)
Epoch: [60][160/391]	Time  0.037 ( 0.038)	Data  0.001 ( 0.002)	Loss 4.6902e-01 (3.0826e-01)	Acc@1  85.94 ( 90.60)	Acc@5  99.22 ( 99.36)
Epoch: [60][170/391]	Time  0.036 ( 0.038)	Data  0.001 ( 0.002)	Loss 3.4869e-01 (3.0818e-01)	Acc@1  89.84 ( 90.62)	Acc@5 100.00 ( 99.39)
Epoch: [60][180/391]	Time  0.045 ( 0.038)	Data  0.001 ( 0.002)	Loss 2.5080e-01 (3.0898e-01)	Acc@1  93.75 ( 90.57)	Acc@5  99.22 ( 99.37)
Epoch: [60][190/391]	Time  0.036 ( 0.038)	Data  0.001 ( 0.002)	Loss 4.1720e-01 (3.0911e-01)	Acc@1  89.06 ( 90.56)	Acc@5  96.88 ( 99.37)
Epoch: [60][200/391]	Time  0.039 ( 0.038)	Data  0.001 ( 0.002)	Loss 3.6501e-01 (3.0986e-01)	Acc@1  88.28 ( 90.52)	Acc@5  99.22 ( 99.36)
Epoch: [60][210/391]	Time  0.037 ( 0.038)	Data  0.001 ( 0.002)	Loss 2.4458e-01 (3.1026e-01)	Acc@1  92.97 ( 90.52)	Acc@5 100.00 ( 99.36)
Epoch: [60][220/391]	Time  0.036 ( 0.038)	Data  0.001 ( 0.002)	Loss 3.2840e-01 (3.0984e-01)	Acc@1  85.16 ( 90.54)	Acc@5 100.00 ( 99.36)
Epoch: [60][230/391]	Time  0.037 ( 0.038)	Data  0.001 ( 0.002)	Loss 2.8325e-01 (3.1045e-01)	Acc@1  91.41 ( 90.51)	Acc@5 100.00 ( 99.37)
Epoch: [60][240/391]	Time  0.037 ( 0.038)	Data  0.001 ( 0.001)	Loss 2.5962e-01 (3.1240e-01)	Acc@1  91.41 ( 90.42)	Acc@5 100.00 ( 99.37)
Epoch: [60][250/391]	Time  0.037 ( 0.038)	Data  0.001 ( 0.001)	Loss 3.9505e-01 (3.1296e-01)	Acc@1  85.94 ( 90.38)	Acc@5  99.22 ( 99.36)
Epoch: [60][260/391]	Time  0.037 ( 0.037)	Data  0.001 ( 0.001)	Loss 2.8574e-01 (3.1333e-01)	Acc@1  91.41 ( 90.35)	Acc@5  99.22 ( 99.36)
Epoch: [60][270/391]	Time  0.039 ( 0.037)	Data  0.001 ( 0.001)	Loss 4.1758e-01 (3.1455e-01)	Acc@1  88.28 ( 90.31)	Acc@5  97.66 ( 99.34)
Epoch: [60][280/391]	Time  0.040 ( 0.037)	Data  0.001 ( 0.001)	Loss 4.2036e-01 (3.1411e-01)	Acc@1  85.16 ( 90.30)	Acc@5 100.00 ( 99.35)
Epoch: [60][290/391]	Time  0.035 ( 0.037)	Data  0.001 ( 0.001)	Loss 3.0627e-01 (3.1472e-01)	Acc@1  87.50 ( 90.25)	Acc@5  99.22 ( 99.36)
Epoch: [60][300/391]	Time  0.041 ( 0.037)	Data  0.001 ( 0.001)	Loss 3.1069e-01 (3.1510e-01)	Acc@1  89.06 ( 90.24)	Acc@5 100.00 ( 99.35)
Epoch: [60][310/391]	Time  0.036 ( 0.037)	Data  0.001 ( 0.001)	Loss 4.5835e-01 (3.1722e-01)	Acc@1  85.94 ( 90.17)	Acc@5  96.09 ( 99.34)
Epoch: [60][320/391]	Time  0.036 ( 0.037)	Data  0.001 ( 0.001)	Loss 3.7673e-01 (3.1851e-01)	Acc@1  91.41 ( 90.14)	Acc@5 100.00 ( 99.33)
Epoch: [60][330/391]	Time  0.040 ( 0.037)	Data  0.001 ( 0.001)	Loss 3.5645e-01 (3.1875e-01)	Acc@1  89.84 ( 90.11)	Acc@5 100.00 ( 99.33)
Epoch: [60][340/391]	Time  0.040 ( 0.037)	Data  0.001 ( 0.001)	Loss 3.6825e-01 (3.1982e-01)	Acc@1  89.84 ( 90.08)	Acc@5  98.44 ( 99.31)
Epoch: [60][350/391]	Time  0.036 ( 0.037)	Data  0.001 ( 0.001)	Loss 3.4959e-01 (3.2047e-01)	Acc@1  89.84 ( 90.07)	Acc@5 100.00 ( 99.31)
Epoch: [60][360/391]	Time  0.036 ( 0.037)	Data  0.001 ( 0.001)	Loss 3.3456e-01 (3.2165e-01)	Acc@1  87.50 ( 90.02)	Acc@5  99.22 ( 99.32)
Epoch: [60][370/391]	Time  0.035 ( 0.037)	Data  0.001 ( 0.001)	Loss 3.3557e-01 (3.2131e-01)	Acc@1  88.28 ( 90.02)	Acc@5  99.22 ( 99.32)
Epoch: [60][380/391]	Time  0.037 ( 0.037)	Data  0.001 ( 0.001)	Loss 3.1402e-01 (3.2121e-01)	Acc@1  92.19 ( 90.03)	Acc@5  98.44 ( 99.32)
Epoch: [60][390/391]	Time  0.025 ( 0.037)	Data  0.001 ( 0.001)	Loss 6.4109e-01 (3.2187e-01)	Acc@1  78.75 ( 89.99)	Acc@5  98.75 ( 99.32)
## e[60] optimizer.zero_grad (sum) time: 0.1832413673400879
## e[60]       loss.backward (sum) time: 3.406527042388916
## e[60]      optimizer.step (sum) time: 1.1911492347717285
## epoch[60] training(only) time: 14.664207696914673
# Switched to evaluate mode...
Test: [  0/100]	Time  0.161 ( 0.161)	Loss 1.3324e+00 (1.3324e+00)	Acc@1  71.00 ( 71.00)	Acc@5  89.00 ( 89.00)
Test: [ 10/100]	Time  0.019 ( 0.034)	Loss 1.2395e+00 (1.4887e+00)	Acc@1  69.00 ( 66.55)	Acc@5  93.00 ( 88.18)
Test: [ 20/100]	Time  0.019 ( 0.027)	Loss 1.2408e+00 (1.4360e+00)	Acc@1  73.00 ( 67.86)	Acc@5  91.00 ( 89.33)
Test: [ 30/100]	Time  0.018 ( 0.025)	Loss 1.7981e+00 (1.4589e+00)	Acc@1  55.00 ( 66.81)	Acc@5  89.00 ( 89.19)
Test: [ 40/100]	Time  0.018 ( 0.024)	Loss 1.4627e+00 (1.4544e+00)	Acc@1  72.00 ( 66.90)	Acc@5  88.00 ( 89.29)
Test: [ 50/100]	Time  0.016 ( 0.023)	Loss 1.4875e+00 (1.4587e+00)	Acc@1  66.00 ( 66.86)	Acc@5  92.00 ( 89.49)
Test: [ 60/100]	Time  0.024 ( 0.023)	Loss 1.5950e+00 (1.4359e+00)	Acc@1  63.00 ( 67.25)	Acc@5  87.00 ( 89.87)
Test: [ 70/100]	Time  0.018 ( 0.023)	Loss 1.6009e+00 (1.4315e+00)	Acc@1  66.00 ( 67.39)	Acc@5  88.00 ( 89.93)
Test: [ 80/100]	Time  0.020 ( 0.022)	Loss 1.6114e+00 (1.4377e+00)	Acc@1  69.00 ( 67.32)	Acc@5  88.00 ( 89.86)
Test: [ 90/100]	Time  0.017 ( 0.022)	Loss 1.8615e+00 (1.4288e+00)	Acc@1  62.00 ( 67.54)	Acc@5  88.00 ( 89.99)
 * Acc@1 67.800 Acc@5 90.150
### epoch[60] execution time: 16.960456609725952
EPOCH 61
REMOVING: module.fire4.expand_3x3.1.weight
REMOVING: module.fire4.expand_3x3.1.bias
i:   0, name:  module.fire5.squeeze.0.weight  changing lr from: 0.001066959885427470   to: 0.001000001713038822
i:   1, name:    module.fire5.squeeze.0.bias  changing lr from: 0.001130834243163464   to: 0.001011239716387590
i:   2, name:  module.fire5.squeeze.1.weight  changing lr from: 0.001215020836311269   to: 0.001044010213425905
i:   3, name:    module.fire5.squeeze.1.bias  changing lr from: 0.001318938473976182   to: 0.001097727595780478
i:   4, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.001442012413699461   to: 0.001171811553679801
i:   5, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.001583674717670152   to: 0.001265687508296036
i:   6, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.001743364576366889   to: 0.001378787008309989
i:   7, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.001920528601303755   to: 0.001510548092454805
i:   8, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.002114621088494339   to: 0.001660415619735516
i:   9, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.002325104254189341   to: 0.001827841568963744
i:  10, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.002551448444384401   to: 0.002012285309189248
i:  11, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.002793132319537649   to: 0.002213213842553168
i:  12, name:  module.fire6.squeeze.0.weight  changing lr from: 0.003049643015880348   to: 0.002430102021031587
i:  13, name:    module.fire6.squeeze.0.bias  changing lr from: 0.003320476284648487   to: 0.002662432738482561
i:  14, name:  module.fire6.squeeze.1.weight  changing lr from: 0.003605136610509357   to: 0.002909697099355729
i:  15, name:    module.fire6.squeeze.1.bias  changing lr from: 0.003903137310404347   to: 0.003171394565369639
i:  16, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.004214000613977941   to: 0.003447033081410366
i:  17, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.004537257726712356   to: 0.003736129181853253
i:  18, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.004872448876838952   to: 0.004038208078460120
i:  19, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.005219123347049864   to: 0.004352803730955240
i:  20, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.005576839491987572   to: 0.004679458901336708
i:  21, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.005945164742445291   to: 0.005017725192932664
i:  22, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.006323675597168143   to: 0.005367163075168312
i:  23, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.006711957603103269   to: 0.005727341894965165
i:  24, name:  module.fire7.squeeze.0.weight  changing lr from: 0.007109605324906564   to: 0.006097839875652866
i:  25, name:    module.fire7.squeeze.0.bias  changing lr from: 0.007516222304475056   to: 0.006478244104232444
i:  26, name:  module.fire7.squeeze.1.weight  changing lr from: 0.007931421011235913   to: 0.006868150507790854
i:  27, name:    module.fire7.squeeze.1.bias  changing lr from: 0.008354822783887265   to: 0.007267163819828481
i:  28, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.008786057764251037   to: 0.007674897537224772
i:  29, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.009224764823864102   to: 0.008090973868531248
i:  30, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.009670591483902317   to: 0.008515023674247562
i:  31, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.010123193829000360   to: 0.008946686399702780
i:  32, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.010582236415501118   to: 0.009385610001133093
i:  33, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.011047392174639115   to: 0.009831450865515939
i:  34, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.011518342311135930   to: 0.010283873724692170
i:  35, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.011994776197658107   to: 0.010742551564278807
i:  36, name:  module.fire8.squeeze.0.weight  changing lr from: 0.012476391265564150   to: 0.011207165527848995
i:  37, name:    module.fire8.squeeze.0.bias  changing lr from: 0.012962892892341975   to: 0.011677404816829006
i:  38, name:  module.fire8.squeeze.1.weight  changing lr from: 0.013453994286116266   to: 0.012152966586538149
i:  39, name:    module.fire8.squeeze.1.bias  changing lr from: 0.013949416367582061   to: 0.012633555838773299
i:  40, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.014448887649700599   to: 0.013118885311316809
i:  41, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.014952144115473253   to: 0.013608675364725892
i:  42, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.015458929094089885   to: 0.014102653866739250
i:  43, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.015968993135730060   to: 0.014600556074618548
i:  44, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.016482093885277820   to: 0.015102124515721838
i:  45, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.016997995955194436   to: 0.015607108866589409
i:  46, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.017516470797777395   to: 0.016115265830804075
i:  47, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.018037296577019135   to: 0.016626359015872227
i:  48, name:  module.fire9.squeeze.0.weight  changing lr from: 0.018560258040264638   to: 0.017140158809356210
i:  49, name:    module.fire9.squeeze.0.bias  changing lr from: 0.019085146389853303   to: 0.017656442254473260
i:  50, name:  module.fire9.squeeze.1.weight  changing lr from: 0.019611759154917658   to: 0.018174992925362666
i:  51, name:    module.fire9.squeeze.1.bias  changing lr from: 0.020139900063499451   to: 0.018695600802208952
i:  52, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.020669378915131577   to: 0.019218062146395876
i:  53, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.021200011454023560   to: 0.019742179375854495
i:  54, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.021731619242977913   to: 0.020267760940756271
i:  55, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.022264029538154526   to: 0.020794621199691561
i:  56, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.022797075164791038   to: 0.021322580296463608
i:  57, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.023330594393978450   to: 0.021851464037617764
i:  58, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.023864430820582167   to: 0.022381103770816702
i:  59, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.024398433242391760   to: 0.022911336264163397
i:  60, name:           module.conv10.weight  changing lr from: 0.024932455540574328   to: 0.023442003586565448
i:  61, name:             module.conv10.bias  changing lr from: 0.025466356561499877   to: 0.023972952989226082



# Switched to train mode...
Epoch: [61][  0/391]	Time  0.200 ( 0.200)	Data  0.157 ( 0.157)	Loss 3.1972e-01 (3.1972e-01)	Acc@1  89.84 ( 89.84)	Acc@5 100.00 (100.00)
Epoch: [61][ 10/391]	Time  0.037 ( 0.052)	Data  0.001 ( 0.015)	Loss 2.4238e-01 (3.1681e-01)	Acc@1  92.19 ( 89.42)	Acc@5 100.00 ( 99.72)
Epoch: [61][ 20/391]	Time  0.034 ( 0.044)	Data  0.001 ( 0.008)	Loss 2.7919e-01 (3.1531e-01)	Acc@1  94.53 ( 90.10)	Acc@5 100.00 ( 99.63)
Epoch: [61][ 30/391]	Time  0.036 ( 0.042)	Data  0.001 ( 0.006)	Loss 3.3715e-01 (3.2654e-01)	Acc@1  89.84 ( 89.69)	Acc@5  99.22 ( 99.55)
Epoch: [61][ 40/391]	Time  0.035 ( 0.040)	Data  0.001 ( 0.005)	Loss 3.6185e-01 (3.2486e-01)	Acc@1  88.28 ( 89.98)	Acc@5 100.00 ( 99.50)
Epoch: [61][ 50/391]	Time  0.035 ( 0.040)	Data  0.001 ( 0.004)	Loss 3.9343e-01 (3.1699e-01)	Acc@1  88.28 ( 90.20)	Acc@5  98.44 ( 99.51)
Epoch: [61][ 60/391]	Time  0.038 ( 0.039)	Data  0.001 ( 0.004)	Loss 2.2161e-01 (3.1653e-01)	Acc@1  94.53 ( 90.10)	Acc@5 100.00 ( 99.53)
Epoch: [61][ 70/391]	Time  0.037 ( 0.039)	Data  0.001 ( 0.003)	Loss 2.1455e-01 (3.1189e-01)	Acc@1  95.31 ( 90.29)	Acc@5 100.00 ( 99.53)
Epoch: [61][ 80/391]	Time  0.038 ( 0.039)	Data  0.001 ( 0.003)	Loss 3.2414e-01 (3.1079e-01)	Acc@1  89.84 ( 90.30)	Acc@5  99.22 ( 99.52)
Epoch: [61][ 90/391]	Time  0.034 ( 0.038)	Data  0.001 ( 0.003)	Loss 4.0389e-01 (3.0847e-01)	Acc@1  89.06 ( 90.36)	Acc@5  98.44 ( 99.53)
Epoch: [61][100/391]	Time  0.035 ( 0.038)	Data  0.001 ( 0.003)	Loss 3.3799e-01 (3.0840e-01)	Acc@1  90.62 ( 90.32)	Acc@5 100.00 ( 99.53)
Epoch: [61][110/391]	Time  0.035 ( 0.038)	Data  0.001 ( 0.002)	Loss 3.6687e-01 (3.0851e-01)	Acc@1  87.50 ( 90.29)	Acc@5  99.22 ( 99.51)
Epoch: [61][120/391]	Time  0.040 ( 0.038)	Data  0.001 ( 0.002)	Loss 3.9573e-01 (3.0888e-01)	Acc@1  89.84 ( 90.31)	Acc@5  98.44 ( 99.50)
Epoch: [61][130/391]	Time  0.035 ( 0.038)	Data  0.001 ( 0.002)	Loss 3.8056e-01 (3.0924e-01)	Acc@1  87.50 ( 90.30)	Acc@5  98.44 ( 99.50)
Epoch: [61][140/391]	Time  0.036 ( 0.038)	Data  0.001 ( 0.002)	Loss 2.4602e-01 (3.0742e-01)	Acc@1  92.19 ( 90.43)	Acc@5 100.00 ( 99.51)
Epoch: [61][150/391]	Time  0.035 ( 0.038)	Data  0.001 ( 0.002)	Loss 3.3120e-01 (3.0896e-01)	Acc@1  89.84 ( 90.39)	Acc@5 100.00 ( 99.49)
Epoch: [61][160/391]	Time  0.035 ( 0.038)	Data  0.001 ( 0.002)	Loss 2.9678e-01 (3.0856e-01)	Acc@1  90.62 ( 90.44)	Acc@5  98.44 ( 99.47)
Epoch: [61][170/391]	Time  0.036 ( 0.038)	Data  0.001 ( 0.002)	Loss 2.9061e-01 (3.1035e-01)	Acc@1  92.19 ( 90.39)	Acc@5  99.22 ( 99.46)
Epoch: [61][180/391]	Time  0.037 ( 0.038)	Data  0.001 ( 0.002)	Loss 3.2835e-01 (3.1008e-01)	Acc@1  91.41 ( 90.38)	Acc@5 100.00 ( 99.46)
Epoch: [61][190/391]	Time  0.039 ( 0.037)	Data  0.001 ( 0.002)	Loss 3.9237e-01 (3.0954e-01)	Acc@1  89.84 ( 90.41)	Acc@5  96.88 ( 99.44)
Epoch: [61][200/391]	Time  0.041 ( 0.037)	Data  0.001 ( 0.002)	Loss 3.1051e-01 (3.0867e-01)	Acc@1  91.41 ( 90.40)	Acc@5 100.00 ( 99.44)
Epoch: [61][210/391]	Time  0.035 ( 0.037)	Data  0.001 ( 0.002)	Loss 3.1512e-01 (3.0708e-01)	Acc@1  91.41 ( 90.45)	Acc@5 100.00 ( 99.45)
Epoch: [61][220/391]	Time  0.035 ( 0.037)	Data  0.001 ( 0.002)	Loss 4.4399e-01 (3.0877e-01)	Acc@1  86.72 ( 90.39)	Acc@5  99.22 ( 99.44)
Epoch: [61][230/391]	Time  0.035 ( 0.037)	Data  0.001 ( 0.002)	Loss 3.5317e-01 (3.0871e-01)	Acc@1  90.62 ( 90.38)	Acc@5  98.44 ( 99.44)
Epoch: [61][240/391]	Time  0.035 ( 0.037)	Data  0.001 ( 0.002)	Loss 3.3309e-01 (3.0827e-01)	Acc@1  92.19 ( 90.43)	Acc@5  97.66 ( 99.42)
Epoch: [61][250/391]	Time  0.035 ( 0.037)	Data  0.001 ( 0.002)	Loss 3.6328e-01 (3.0752e-01)	Acc@1  85.94 ( 90.46)	Acc@5  98.44 ( 99.42)
Epoch: [61][260/391]	Time  0.037 ( 0.037)	Data  0.001 ( 0.002)	Loss 2.7259e-01 (3.0704e-01)	Acc@1  90.62 ( 90.46)	Acc@5  99.22 ( 99.42)
Epoch: [61][270/391]	Time  0.036 ( 0.037)	Data  0.001 ( 0.002)	Loss 3.5534e-01 (3.0747e-01)	Acc@1  89.84 ( 90.43)	Acc@5  98.44 ( 99.41)
Epoch: [61][280/391]	Time  0.037 ( 0.037)	Data  0.001 ( 0.002)	Loss 2.5636e-01 (3.0847e-01)	Acc@1  92.19 ( 90.42)	Acc@5 100.00 ( 99.41)
Epoch: [61][290/391]	Time  0.035 ( 0.037)	Data  0.001 ( 0.002)	Loss 2.4227e-01 (3.0969e-01)	Acc@1  92.97 ( 90.42)	Acc@5 100.00 ( 99.40)
Epoch: [61][300/391]	Time  0.038 ( 0.037)	Data  0.001 ( 0.001)	Loss 3.5756e-01 (3.1076e-01)	Acc@1  90.62 ( 90.36)	Acc@5  99.22 ( 99.40)
Epoch: [61][310/391]	Time  0.038 ( 0.037)	Data  0.001 ( 0.001)	Loss 3.8350e-01 (3.1235e-01)	Acc@1  87.50 ( 90.31)	Acc@5  99.22 ( 99.38)
Epoch: [61][320/391]	Time  0.036 ( 0.037)	Data  0.001 ( 0.001)	Loss 3.1989e-01 (3.1325e-01)	Acc@1  89.84 ( 90.26)	Acc@5 100.00 ( 99.37)
Epoch: [61][330/391]	Time  0.038 ( 0.037)	Data  0.001 ( 0.001)	Loss 3.4298e-01 (3.1405e-01)	Acc@1  91.41 ( 90.24)	Acc@5  97.66 ( 99.37)
Epoch: [61][340/391]	Time  0.035 ( 0.037)	Data  0.001 ( 0.001)	Loss 2.8465e-01 (3.1390e-01)	Acc@1  91.41 ( 90.23)	Acc@5 100.00 ( 99.38)
Epoch: [61][350/391]	Time  0.038 ( 0.037)	Data  0.001 ( 0.001)	Loss 2.5586e-01 (3.1384e-01)	Acc@1  92.19 ( 90.23)	Acc@5 100.00 ( 99.38)
Epoch: [61][360/391]	Time  0.035 ( 0.037)	Data  0.001 ( 0.001)	Loss 3.5134e-01 (3.1490e-01)	Acc@1  85.94 ( 90.19)	Acc@5  99.22 ( 99.38)
Epoch: [61][370/391]	Time  0.037 ( 0.037)	Data  0.001 ( 0.001)	Loss 3.2827e-01 (3.1609e-01)	Acc@1  89.06 ( 90.15)	Acc@5  99.22 ( 99.37)
Epoch: [61][380/391]	Time  0.038 ( 0.037)	Data  0.001 ( 0.001)	Loss 4.1598e-01 (3.1693e-01)	Acc@1  87.50 ( 90.14)	Acc@5  98.44 ( 99.37)
Epoch: [61][390/391]	Time  0.025 ( 0.037)	Data  0.001 ( 0.001)	Loss 4.3128e-01 (3.1729e-01)	Acc@1  85.00 ( 90.09)	Acc@5  98.75 ( 99.38)
## e[61] optimizer.zero_grad (sum) time: 0.18015623092651367
## e[61]       loss.backward (sum) time: 3.35725998878479
## e[61]      optimizer.step (sum) time: 1.1596291065216064
## epoch[61] training(only) time: 14.566375494003296
# Switched to evaluate mode...
Test: [  0/100]	Time  0.155 ( 0.155)	Loss 1.2210e+00 (1.2210e+00)	Acc@1  71.00 ( 71.00)	Acc@5  89.00 ( 89.00)
Test: [ 10/100]	Time  0.024 ( 0.035)	Loss 1.5411e+00 (1.4666e+00)	Acc@1  67.00 ( 67.64)	Acc@5  90.00 ( 89.36)
Test: [ 20/100]	Time  0.022 ( 0.029)	Loss 1.2761e+00 (1.4228e+00)	Acc@1  70.00 ( 68.24)	Acc@5  95.00 ( 90.33)
Test: [ 30/100]	Time  0.018 ( 0.027)	Loss 1.8199e+00 (1.4514e+00)	Acc@1  59.00 ( 67.42)	Acc@5  89.00 ( 90.26)
Test: [ 40/100]	Time  0.023 ( 0.025)	Loss 1.3442e+00 (1.4428e+00)	Acc@1  67.00 ( 67.34)	Acc@5  93.00 ( 90.29)
Test: [ 50/100]	Time  0.023 ( 0.024)	Loss 1.4494e+00 (1.4456e+00)	Acc@1  68.00 ( 67.06)	Acc@5  93.00 ( 90.24)
Test: [ 60/100]	Time  0.018 ( 0.023)	Loss 1.6406e+00 (1.4234e+00)	Acc@1  63.00 ( 67.18)	Acc@5  88.00 ( 90.62)
Test: [ 70/100]	Time  0.021 ( 0.023)	Loss 1.5884e+00 (1.4211e+00)	Acc@1  67.00 ( 67.18)	Acc@5  87.00 ( 90.56)
Test: [ 80/100]	Time  0.018 ( 0.023)	Loss 1.6053e+00 (1.4266e+00)	Acc@1  68.00 ( 67.16)	Acc@5  89.00 ( 90.48)
Test: [ 90/100]	Time  0.017 ( 0.023)	Loss 1.6687e+00 (1.4188e+00)	Acc@1  64.00 ( 67.26)	Acc@5  87.00 ( 90.54)
 * Acc@1 67.630 Acc@5 90.610
### epoch[61] execution time: 16.88361692428589
EPOCH 62
REMOVING: module.fire5.squeeze.0.weight
REMOVING: module.fire5.squeeze.0.bias
REMOVING: module.fire5.squeeze.1.weight
i:   0, name:    module.fire5.squeeze.1.bias  changing lr from: 0.001097727595780478   to: 0.001003634012413478
i:   1, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.001171811553679801   to: 0.001026864022684869
i:   2, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.001265687508296036   to: 0.001071071244522458
i:   3, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.001378787008309989   to: 0.001135682347655763
i:   4, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.001510548092454805   to: 0.001220129424513810
i:   5, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.001660415619735516   to: 0.001323850391686181
i:   6, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.001827841568963744   to: 0.001446289357686863
i:   7, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.002012285309189248   to: 0.001586896958680466
i:   8, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.002213213842553168   to: 0.001745130663774835
i:   9, name:  module.fire6.squeeze.0.weight  changing lr from: 0.002430102021031587   to: 0.001920455051428676
i:  10, name:    module.fire6.squeeze.0.bias  changing lr from: 0.002662432738482561   to: 0.002112342058468163
i:  11, name:  module.fire6.squeeze.1.weight  changing lr from: 0.002909697099355729   to: 0.002320271203152162
i:  12, name:    module.fire6.squeeze.1.bias  changing lr from: 0.003171394565369639   to: 0.002543729783672398
i:  13, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.003447033081410366   to: 0.002782213053422427
i:  14, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.003736129181853253   to: 0.003035224374317496
i:  15, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.004038208078460120   to: 0.003302275349396915
i:  16, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.004352803730955240   to: 0.003582885935890944
i:  17, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.004679458901336708   to: 0.003876584539886074
i:  18, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.005017725192932664   to: 0.004182908093674880
i:  19, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.005367163075168312   to: 0.004501402116831159
i:  20, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.005727341894965165   to: 0.004831620762005927
i:  21, name:  module.fire7.squeeze.0.weight  changing lr from: 0.006097839875652866   to: 0.005173126846396491
i:  22, name:    module.fire7.squeeze.0.bias  changing lr from: 0.006478244104232444   to: 0.005525491869798576
i:  23, name:  module.fire7.squeeze.1.weight  changing lr from: 0.006868150507790854   to: 0.005888296020110411
i:  24, name:    module.fire7.squeeze.1.bias  changing lr from: 0.007267163819828481   to: 0.006261128167117968
i:  25, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.007674897537224772   to: 0.006643585845352473
i:  26, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.008090973868531248   to: 0.007035275226773479
i:  27, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.008515023674247562   to: 0.007435811083995768
i:  28, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.008946686399702780   to: 0.007844816744742810
i:  29, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.009385610001133093   to: 0.008261924038176893
i:  30, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.009831450865515939   to: 0.008686773233723221
i:  31, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.010283873724692170   to: 0.009119012972974821
i:  32, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.010742551564278807   to: 0.009558300195234664
i:  33, name:  module.fire8.squeeze.0.weight  changing lr from: 0.011207165527848995   to: 0.010004300057223459
i:  34, name:    module.fire8.squeeze.0.bias  changing lr from: 0.011677404816829006   to: 0.010456685847453091
i:  35, name:  module.fire8.squeeze.1.weight  changing lr from: 0.012152966586538149   to: 0.010915138895740372
i:  36, name:    module.fire8.squeeze.1.bias  changing lr from: 0.012633555838773299   to: 0.011379348478309258
i:  37, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.013118885311316809   to: 0.011849011718906000
i:  38, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.013608675364725892   to: 0.012323833486328352
i:  39, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.014102653866739250   to: 0.012803526288747220
i:  40, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.014600556074618548   to: 0.013287810165178205
i:  41, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.015102124515721838   to: 0.013776412574439661
i:  42, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.015607108866589409   to: 0.014269068281914644
i:  43, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.016115265830804075   to: 0.014765519244415205
i:  44, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.016626359015872227   to: 0.015265514493429687
i:  45, name:  module.fire9.squeeze.0.weight  changing lr from: 0.017140158809356210   to: 0.015768810017016882
i:  46, name:    module.fire9.squeeze.0.bias  changing lr from: 0.017656442254473260   to: 0.016275168640594185
i:  47, name:  module.fire9.squeeze.1.weight  changing lr from: 0.018174992925362666   to: 0.016784359906851960
i:  48, name:    module.fire9.squeeze.1.bias  changing lr from: 0.018695600802208952   to: 0.017296159955011065
i:  49, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.019218062146395876   to: 0.017810351399626861
i:  50, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.019742179375854495   to: 0.018326723209129241
i:  51, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.020267760940756271   to: 0.018845070584275998
i:  52, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.020794621199691561   to: 0.019365194836684110
i:  53, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.021322580296463608   to: 0.019886903267592765
i:  54, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.021851464037617764   to: 0.020410009047000400
i:  55, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.022381103770816702   to: 0.020934331093307935
i:  56, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.022911336264163397   to: 0.021459693953590715
i:  57, name:           module.conv10.weight  changing lr from: 0.023442003586565448   to: 0.021985927684612112
i:  58, name:             module.conv10.bias  changing lr from: 0.023972952989226082   to: 0.022512867734682970



# Switched to train mode...
Epoch: [62][  0/391]	Time  0.181 ( 0.181)	Data  0.137 ( 0.137)	Loss 2.4547e-01 (2.4547e-01)	Acc@1  91.41 ( 91.41)	Acc@5  99.22 ( 99.22)
Epoch: [62][ 10/391]	Time  0.037 ( 0.049)	Data  0.001 ( 0.013)	Loss 3.0208e-01 (2.6415e-01)	Acc@1  89.06 ( 91.90)	Acc@5 100.00 ( 99.57)
Epoch: [62][ 20/391]	Time  0.034 ( 0.044)	Data  0.001 ( 0.007)	Loss 2.2738e-01 (2.7203e-01)	Acc@1  95.31 ( 91.85)	Acc@5 100.00 ( 99.48)
Epoch: [62][ 30/391]	Time  0.035 ( 0.042)	Data  0.001 ( 0.005)	Loss 3.0964e-01 (2.7983e-01)	Acc@1  92.19 ( 91.58)	Acc@5 100.00 ( 99.47)
Epoch: [62][ 40/391]	Time  0.037 ( 0.040)	Data  0.001 ( 0.004)	Loss 2.4252e-01 (2.8173e-01)	Acc@1  92.19 ( 91.37)	Acc@5 100.00 ( 99.50)
Epoch: [62][ 50/391]	Time  0.036 ( 0.040)	Data  0.001 ( 0.004)	Loss 3.3139e-01 (2.8462e-01)	Acc@1  89.06 ( 91.34)	Acc@5  99.22 ( 99.48)
Epoch: [62][ 60/391]	Time  0.038 ( 0.039)	Data  0.001 ( 0.003)	Loss 2.9085e-01 (2.8557e-01)	Acc@1  90.62 ( 91.30)	Acc@5  98.44 ( 99.46)
Epoch: [62][ 70/391]	Time  0.035 ( 0.039)	Data  0.001 ( 0.003)	Loss 2.8494e-01 (2.8605e-01)	Acc@1  91.41 ( 91.26)	Acc@5 100.00 ( 99.50)
Epoch: [62][ 80/391]	Time  0.034 ( 0.038)	Data  0.001 ( 0.003)	Loss 4.0027e-01 (2.8766e-01)	Acc@1  89.06 ( 91.08)	Acc@5  99.22 ( 99.52)
Epoch: [62][ 90/391]	Time  0.036 ( 0.038)	Data  0.001 ( 0.002)	Loss 4.2388e-01 (2.9111e-01)	Acc@1  89.06 ( 91.10)	Acc@5  99.22 ( 99.49)
Epoch: [62][100/391]	Time  0.035 ( 0.038)	Data  0.001 ( 0.002)	Loss 3.9582e-01 (2.9178e-01)	Acc@1  87.50 ( 90.97)	Acc@5  99.22 ( 99.50)
Epoch: [62][110/391]	Time  0.036 ( 0.038)	Data  0.001 ( 0.002)	Loss 2.5918e-01 (2.9235e-01)	Acc@1  89.06 ( 90.91)	Acc@5  99.22 ( 99.50)
Epoch: [62][120/391]	Time  0.037 ( 0.038)	Data  0.001 ( 0.002)	Loss 3.4712e-01 (2.9178e-01)	Acc@1  91.41 ( 90.91)	Acc@5  98.44 ( 99.49)
Epoch: [62][130/391]	Time  0.035 ( 0.038)	Data  0.001 ( 0.002)	Loss 3.7265e-01 (2.9123e-01)	Acc@1  90.62 ( 90.98)	Acc@5  98.44 ( 99.48)
Epoch: [62][140/391]	Time  0.036 ( 0.037)	Data  0.001 ( 0.002)	Loss 4.2957e-01 (2.9424e-01)	Acc@1  84.38 ( 90.87)	Acc@5 100.00 ( 99.47)
Epoch: [62][150/391]	Time  0.039 ( 0.037)	Data  0.001 ( 0.002)	Loss 2.5197e-01 (2.9317e-01)	Acc@1  90.62 ( 90.93)	Acc@5 100.00 ( 99.48)
Epoch: [62][160/391]	Time  0.041 ( 0.037)	Data  0.001 ( 0.002)	Loss 3.6976e-01 (2.9335e-01)	Acc@1  86.72 ( 90.92)	Acc@5  98.44 ( 99.49)
Epoch: [62][170/391]	Time  0.035 ( 0.037)	Data  0.001 ( 0.002)	Loss 2.7820e-01 (2.9392e-01)	Acc@1  89.06 ( 90.85)	Acc@5  99.22 ( 99.50)
Epoch: [62][180/391]	Time  0.040 ( 0.037)	Data  0.001 ( 0.002)	Loss 2.6958e-01 (2.9393e-01)	Acc@1  89.06 ( 90.85)	Acc@5 100.00 ( 99.49)
Epoch: [62][190/391]	Time  0.033 ( 0.037)	Data  0.001 ( 0.002)	Loss 2.4237e-01 (2.9439e-01)	Acc@1  94.53 ( 90.86)	Acc@5  99.22 ( 99.48)
Epoch: [62][200/391]	Time  0.035 ( 0.037)	Data  0.001 ( 0.002)	Loss 3.2573e-01 (2.9413e-01)	Acc@1  92.19 ( 90.91)	Acc@5  99.22 ( 99.48)
Epoch: [62][210/391]	Time  0.035 ( 0.037)	Data  0.001 ( 0.002)	Loss 3.0058e-01 (2.9507e-01)	Acc@1  90.62 ( 90.83)	Acc@5 100.00 ( 99.48)
Epoch: [62][220/391]	Time  0.035 ( 0.037)	Data  0.001 ( 0.002)	Loss 2.5909e-01 (2.9550e-01)	Acc@1  92.97 ( 90.78)	Acc@5 100.00 ( 99.48)
Epoch: [62][230/391]	Time  0.036 ( 0.037)	Data  0.001 ( 0.002)	Loss 3.6490e-01 (2.9642e-01)	Acc@1  85.94 ( 90.71)	Acc@5  99.22 ( 99.47)
Epoch: [62][240/391]	Time  0.036 ( 0.037)	Data  0.001 ( 0.002)	Loss 2.2681e-01 (2.9657e-01)	Acc@1  92.19 ( 90.72)	Acc@5 100.00 ( 99.47)
Epoch: [62][250/391]	Time  0.035 ( 0.037)	Data  0.001 ( 0.002)	Loss 3.3473e-01 (2.9717e-01)	Acc@1  88.28 ( 90.72)	Acc@5 100.00 ( 99.46)
Epoch: [62][260/391]	Time  0.036 ( 0.037)	Data  0.001 ( 0.002)	Loss 4.0793e-01 (2.9716e-01)	Acc@1  86.72 ( 90.69)	Acc@5 100.00 ( 99.46)
Epoch: [62][270/391]	Time  0.041 ( 0.037)	Data  0.001 ( 0.001)	Loss 1.9917e-01 (2.9726e-01)	Acc@1  94.53 ( 90.65)	Acc@5 100.00 ( 99.47)
Epoch: [62][280/391]	Time  0.035 ( 0.037)	Data  0.001 ( 0.001)	Loss 2.6949e-01 (2.9742e-01)	Acc@1  92.19 ( 90.65)	Acc@5 100.00 ( 99.47)
Epoch: [62][290/391]	Time  0.038 ( 0.037)	Data  0.001 ( 0.001)	Loss 2.1368e-01 (2.9680e-01)	Acc@1  92.19 ( 90.66)	Acc@5 100.00 ( 99.47)
Epoch: [62][300/391]	Time  0.036 ( 0.037)	Data  0.001 ( 0.001)	Loss 3.0199e-01 (2.9826e-01)	Acc@1  89.84 ( 90.62)	Acc@5 100.00 ( 99.47)
Epoch: [62][310/391]	Time  0.037 ( 0.037)	Data  0.001 ( 0.001)	Loss 2.3839e-01 (2.9883e-01)	Acc@1  93.75 ( 90.66)	Acc@5  99.22 ( 99.45)
Epoch: [62][320/391]	Time  0.034 ( 0.037)	Data  0.001 ( 0.001)	Loss 4.2317e-01 (2.9931e-01)	Acc@1  88.28 ( 90.65)	Acc@5  98.44 ( 99.45)
Epoch: [62][330/391]	Time  0.037 ( 0.037)	Data  0.001 ( 0.001)	Loss 4.1616e-01 (2.9974e-01)	Acc@1  85.16 ( 90.66)	Acc@5  97.66 ( 99.45)
Epoch: [62][340/391]	Time  0.040 ( 0.037)	Data  0.001 ( 0.001)	Loss 3.3626e-01 (3.0046e-01)	Acc@1  91.41 ( 90.63)	Acc@5 100.00 ( 99.45)
Epoch: [62][350/391]	Time  0.036 ( 0.037)	Data  0.001 ( 0.001)	Loss 3.9373e-01 (3.0112e-01)	Acc@1  85.94 ( 90.60)	Acc@5 100.00 ( 99.45)
Epoch: [62][360/391]	Time  0.037 ( 0.037)	Data  0.001 ( 0.001)	Loss 3.3806e-01 (3.0207e-01)	Acc@1  89.06 ( 90.54)	Acc@5  98.44 ( 99.44)
Epoch: [62][370/391]	Time  0.035 ( 0.037)	Data  0.001 ( 0.001)	Loss 2.9946e-01 (3.0249e-01)	Acc@1  91.41 ( 90.52)	Acc@5 100.00 ( 99.45)
Epoch: [62][380/391]	Time  0.036 ( 0.037)	Data  0.001 ( 0.001)	Loss 3.9499e-01 (3.0261e-01)	Acc@1  89.84 ( 90.51)	Acc@5  98.44 ( 99.44)
Epoch: [62][390/391]	Time  0.028 ( 0.037)	Data  0.001 ( 0.001)	Loss 3.6224e-01 (3.0245e-01)	Acc@1  90.00 ( 90.53)	Acc@5  98.75 ( 99.44)
## e[62] optimizer.zero_grad (sum) time: 0.17078208923339844
## e[62]       loss.backward (sum) time: 3.3260905742645264
## e[62]      optimizer.step (sum) time: 1.135939598083496
## epoch[62] training(only) time: 14.413795709609985
# Switched to evaluate mode...
Test: [  0/100]	Time  0.150 ( 0.150)	Loss 1.3257e+00 (1.3257e+00)	Acc@1  68.00 ( 68.00)	Acc@5  89.00 ( 89.00)
Test: [ 10/100]	Time  0.023 ( 0.034)	Loss 1.3552e+00 (1.4482e+00)	Acc@1  65.00 ( 68.27)	Acc@5  92.00 ( 89.55)
Test: [ 20/100]	Time  0.025 ( 0.029)	Loss 1.2526e+00 (1.3844e+00)	Acc@1  70.00 ( 68.86)	Acc@5  95.00 ( 90.57)
Test: [ 30/100]	Time  0.024 ( 0.027)	Loss 1.6590e+00 (1.4088e+00)	Acc@1  60.00 ( 67.84)	Acc@5  89.00 ( 90.29)
Test: [ 40/100]	Time  0.016 ( 0.026)	Loss 1.3218e+00 (1.3985e+00)	Acc@1  71.00 ( 67.95)	Acc@5  92.00 ( 90.41)
Test: [ 50/100]	Time  0.020 ( 0.025)	Loss 1.3789e+00 (1.4104e+00)	Acc@1  71.00 ( 67.65)	Acc@5  90.00 ( 90.22)
Test: [ 60/100]	Time  0.016 ( 0.024)	Loss 1.6112e+00 (1.3965e+00)	Acc@1  63.00 ( 67.77)	Acc@5  84.00 ( 90.38)
Test: [ 70/100]	Time  0.017 ( 0.023)	Loss 1.7353e+00 (1.3976e+00)	Acc@1  66.00 ( 67.80)	Acc@5  89.00 ( 90.39)
Test: [ 80/100]	Time  0.030 ( 0.023)	Loss 1.4707e+00 (1.4035e+00)	Acc@1  71.00 ( 67.85)	Acc@5  90.00 ( 90.38)
Test: [ 90/100]	Time  0.017 ( 0.023)	Loss 1.8492e+00 (1.3919e+00)	Acc@1  63.00 ( 68.09)	Acc@5  87.00 ( 90.47)
 * Acc@1 68.260 Acc@5 90.590
### epoch[62] execution time: 16.73792314529419
EPOCH 63
REMOVING: module.fire5.squeeze.1.bias
REMOVING: module.fire5.expand_1x1.0.weight
i:   0, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.001071071244522458   to: 0.001000308691492590
i:   1, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.001135682347655763   to: 0.001014645715485556
i:   2, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.001220129424513810   to: 0.001049974221548821
i:   3, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.001323850391686181   to: 0.001105727875930539
i:   4, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.001446289357686863   to: 0.001181345477776634
i:   5, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.001586896958680466   to: 0.001276271364399350
i:   6, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.001745130663774835   to: 0.001389955783209533
i:   7, name:  module.fire6.squeeze.0.weight  changing lr from: 0.001920455051428676   to: 0.001521855231934426
i:   8, name:    module.fire6.squeeze.0.bias  changing lr from: 0.002112342058468163   to: 0.001671432768689445
i:   9, name:  module.fire6.squeeze.1.weight  changing lr from: 0.002320271203152162   to: 0.001838158293419156
i:  10, name:    module.fire6.squeeze.1.bias  changing lr from: 0.002543729783672398   to: 0.002021508802169957
i:  11, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.002782213053422427   to: 0.002220968615604867
i:  12, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.003035224374317496   to: 0.002436029583119097
i:  13, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.003302275349396915   to: 0.002666191263864675
i:  14, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.003582885935890944   to: 0.002910961085942103
i:  15, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.003876584539886074   to: 0.003169854484968592
i:  16, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.004182908093674880   to: 0.003442395023183891
i:  17, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.004501402116831159   to: 0.003728114490208417
i:  18, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.004831620762005927   to: 0.004026552986522097
i:  19, name:  module.fire7.squeeze.0.weight  changing lr from: 0.005173126846396491   to: 0.004337258990688186
i:  20, name:    module.fire7.squeeze.0.bias  changing lr from: 0.005525491869798576   to: 0.004659789411302255
i:  21, name:  module.fire7.squeeze.1.weight  changing lr from: 0.005888296020110411   to: 0.004993709624604952
i:  22, name:    module.fire7.squeeze.1.bias  changing lr from: 0.006261128167117968   to: 0.005338593498655108
i:  23, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.006643585845352473   to: 0.005694023404921028
i:  24, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.007035275226773479   to: 0.006059590218108024
i:  25, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.007435811083995768   to: 0.006434893305003564
i:  26, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.007844816744742810   to: 0.006819540503084775
i:  27, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.008261924038176893   to: 0.007213148089598242
i:  28, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.008686773233723221   to: 0.007615340741787912
i:  29, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.009119012972974821   to: 0.008025751488914795
i:  30, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.009558300195234664   to: 0.008444021656679894
i:  31, name:  module.fire8.squeeze.0.weight  changing lr from: 0.010004300057223459   to: 0.008869800804632243
i:  32, name:    module.fire8.squeeze.0.bias  changing lr from: 0.010456685847453091   to: 0.009302746657114187
i:  33, name:  module.fire8.squeeze.1.weight  changing lr from: 0.010915138895740372   to: 0.009742525028268133
i:  34, name:    module.fire8.squeeze.1.bias  changing lr from: 0.011379348478309258   to: 0.010188809741602217
i:  35, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.011849011718906000   to: 0.010641282544585594
i:  36, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.012323833486328352   to: 0.011099633018720474
i:  37, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.012803526288747220   to: 0.011563558485512444
i:  38, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.013287810165178205   to: 0.012032763908739374
i:  39, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.013776412574439661   to: 0.012506961793395766
i:  40, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.014269068281914644   to: 0.012985872081669625
i:  41, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.014765519244415205   to: 0.013469222046287567
i:  42, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.015265514493429687   to: 0.013956746181545861
i:  43, name:  module.fire9.squeeze.0.weight  changing lr from: 0.015768810017016882   to: 0.014448186092325628
i:  44, name:    module.fire9.squeeze.0.bias  changing lr from: 0.016275168640594185   to: 0.014943290381373413
i:  45, name:  module.fire9.squeeze.1.weight  changing lr from: 0.016784359906851960   to: 0.015441814535111353
i:  46, name:    module.fire9.squeeze.1.bias  changing lr from: 0.017296159955011065   to: 0.015943520808225302
i:  47, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.017810351399626861   to: 0.016448178107263522
i:  48, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.018326723209129241   to: 0.016955561873464520
i:  49, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.018845070584275998   to: 0.017465453965018418
i:  50, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.019365194836684110   to: 0.017977642538952950
i:  51, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.019886903267592765   to: 0.018491921932822713
i:  52, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.020410009047000400   to: 0.019008092546368444
i:  53, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.020934331093307935   to: 0.019525960723301160
i:  54, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.021459693953590715   to: 0.020045338633355891
i:  55, name:           module.conv10.weight  changing lr from: 0.021985927684612112   to: 0.020566044154749004
i:  56, name:             module.conv10.bias  changing lr from: 0.022512867734682970   to: 0.021087900757163339



# Switched to train mode...
Epoch: [63][  0/391]	Time  0.192 ( 0.192)	Data  0.151 ( 0.151)	Loss 2.4860e-01 (2.4860e-01)	Acc@1  92.97 ( 92.97)	Acc@5 100.00 (100.00)
Epoch: [63][ 10/391]	Time  0.036 ( 0.051)	Data  0.001 ( 0.014)	Loss 2.9615e-01 (2.6395e-01)	Acc@1  92.19 ( 92.19)	Acc@5  99.22 ( 99.72)
Epoch: [63][ 20/391]	Time  0.037 ( 0.044)	Data  0.001 ( 0.008)	Loss 2.3087e-01 (2.5942e-01)	Acc@1  94.53 ( 92.34)	Acc@5 100.00 ( 99.70)
Epoch: [63][ 30/391]	Time  0.034 ( 0.041)	Data  0.001 ( 0.006)	Loss 3.9861e-01 (2.6126e-01)	Acc@1  88.28 ( 92.41)	Acc@5 100.00 ( 99.65)
Epoch: [63][ 40/391]	Time  0.038 ( 0.040)	Data  0.001 ( 0.005)	Loss 2.2938e-01 (2.6763e-01)	Acc@1  93.75 ( 92.19)	Acc@5 100.00 ( 99.62)
Epoch: [63][ 50/391]	Time  0.034 ( 0.039)	Data  0.001 ( 0.004)	Loss 2.6982e-01 (2.6261e-01)	Acc@1  91.41 ( 92.14)	Acc@5  99.22 ( 99.65)
Epoch: [63][ 60/391]	Time  0.035 ( 0.039)	Data  0.001 ( 0.003)	Loss 2.6706e-01 (2.6883e-01)	Acc@1  95.31 ( 91.96)	Acc@5  99.22 ( 99.64)
Epoch: [63][ 70/391]	Time  0.037 ( 0.038)	Data  0.001 ( 0.003)	Loss 3.0453e-01 (2.7206e-01)	Acc@1  89.06 ( 91.76)	Acc@5  99.22 ( 99.61)
Epoch: [63][ 80/391]	Time  0.035 ( 0.038)	Data  0.001 ( 0.003)	Loss 2.7743e-01 (2.6870e-01)	Acc@1  92.19 ( 91.83)	Acc@5 100.00 ( 99.64)
Epoch: [63][ 90/391]	Time  0.039 ( 0.038)	Data  0.001 ( 0.003)	Loss 3.3235e-01 (2.7479e-01)	Acc@1  85.16 ( 91.53)	Acc@5  99.22 ( 99.64)
Epoch: [63][100/391]	Time  0.034 ( 0.037)	Data  0.001 ( 0.002)	Loss 2.6029e-01 (2.7430e-01)	Acc@1  90.62 ( 91.52)	Acc@5 100.00 ( 99.66)
Epoch: [63][110/391]	Time  0.037 ( 0.037)	Data  0.001 ( 0.002)	Loss 2.2274e-01 (2.7431e-01)	Acc@1  93.75 ( 91.59)	Acc@5 100.00 ( 99.67)
Epoch: [63][120/391]	Time  0.038 ( 0.037)	Data  0.001 ( 0.002)	Loss 2.5881e-01 (2.7565e-01)	Acc@1  92.19 ( 91.61)	Acc@5 100.00 ( 99.65)
Epoch: [63][130/391]	Time  0.036 ( 0.037)	Data  0.001 ( 0.002)	Loss 3.7558e-01 (2.7668e-01)	Acc@1  85.94 ( 91.58)	Acc@5 100.00 ( 99.64)
Epoch: [63][140/391]	Time  0.037 ( 0.037)	Data  0.001 ( 0.002)	Loss 3.4582e-01 (2.7699e-01)	Acc@1  89.84 ( 91.58)	Acc@5  99.22 ( 99.62)
Epoch: [63][150/391]	Time  0.035 ( 0.037)	Data  0.001 ( 0.002)	Loss 3.3030e-01 (2.7594e-01)	Acc@1  89.06 ( 91.62)	Acc@5  99.22 ( 99.62)
Epoch: [63][160/391]	Time  0.035 ( 0.037)	Data  0.001 ( 0.002)	Loss 2.5183e-01 (2.7742e-01)	Acc@1  92.97 ( 91.60)	Acc@5  99.22 ( 99.63)
Epoch: [63][170/391]	Time  0.037 ( 0.037)	Data  0.001 ( 0.002)	Loss 2.8363e-01 (2.7723e-01)	Acc@1  90.62 ( 91.60)	Acc@5 100.00 ( 99.63)
Epoch: [63][180/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.002)	Loss 2.4767e-01 (2.7691e-01)	Acc@1  91.41 ( 91.62)	Acc@5 100.00 ( 99.63)
Epoch: [63][190/391]	Time  0.036 ( 0.036)	Data  0.001 ( 0.002)	Loss 2.2921e-01 (2.7666e-01)	Acc@1  93.75 ( 91.60)	Acc@5 100.00 ( 99.63)
Epoch: [63][200/391]	Time  0.037 ( 0.036)	Data  0.001 ( 0.002)	Loss 2.9900e-01 (2.7722e-01)	Acc@1  91.41 ( 91.62)	Acc@5 100.00 ( 99.62)
Epoch: [63][210/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.002)	Loss 3.6917e-01 (2.7860e-01)	Acc@1  89.84 ( 91.58)	Acc@5  99.22 ( 99.61)
Epoch: [63][220/391]	Time  0.039 ( 0.036)	Data  0.001 ( 0.002)	Loss 2.7080e-01 (2.7807e-01)	Acc@1  91.41 ( 91.59)	Acc@5 100.00 ( 99.61)
Epoch: [63][230/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.002)	Loss 3.2371e-01 (2.7926e-01)	Acc@1  89.06 ( 91.54)	Acc@5 100.00 ( 99.58)
Epoch: [63][240/391]	Time  0.035 ( 0.036)	Data  0.001 ( 0.002)	Loss 2.5824e-01 (2.7895e-01)	Acc@1  92.19 ( 91.55)	Acc@5 100.00 ( 99.58)
Epoch: [63][250/391]	Time  0.035 ( 0.036)	Data  0.001 ( 0.002)	Loss 3.0308e-01 (2.7977e-01)	Acc@1  89.84 ( 91.49)	Acc@5  99.22 ( 99.57)
Epoch: [63][260/391]	Time  0.037 ( 0.036)	Data  0.001 ( 0.002)	Loss 2.9820e-01 (2.8042e-01)	Acc@1  89.06 ( 91.43)	Acc@5  98.44 ( 99.55)
Epoch: [63][270/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.001)	Loss 2.5048e-01 (2.8083e-01)	Acc@1  91.41 ( 91.41)	Acc@5  99.22 ( 99.54)
Epoch: [63][280/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.001)	Loss 2.6797e-01 (2.8116e-01)	Acc@1  94.53 ( 91.40)	Acc@5 100.00 ( 99.54)
Epoch: [63][290/391]	Time  0.037 ( 0.036)	Data  0.001 ( 0.001)	Loss 2.5644e-01 (2.8114e-01)	Acc@1  92.97 ( 91.41)	Acc@5  98.44 ( 99.54)
Epoch: [63][300/391]	Time  0.038 ( 0.036)	Data  0.001 ( 0.001)	Loss 2.5259e-01 (2.8166e-01)	Acc@1  92.97 ( 91.38)	Acc@5  98.44 ( 99.54)
Epoch: [63][310/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.001)	Loss 2.8043e-01 (2.8234e-01)	Acc@1  87.50 ( 91.35)	Acc@5 100.00 ( 99.53)
Epoch: [63][320/391]	Time  0.037 ( 0.036)	Data  0.001 ( 0.001)	Loss 2.1034e-01 (2.8259e-01)	Acc@1  95.31 ( 91.33)	Acc@5 100.00 ( 99.54)
Epoch: [63][330/391]	Time  0.036 ( 0.036)	Data  0.001 ( 0.001)	Loss 2.5257e-01 (2.8336e-01)	Acc@1  91.41 ( 91.29)	Acc@5 100.00 ( 99.54)
Epoch: [63][340/391]	Time  0.037 ( 0.036)	Data  0.001 ( 0.001)	Loss 3.7383e-01 (2.8379e-01)	Acc@1  90.62 ( 91.26)	Acc@5 100.00 ( 99.54)
Epoch: [63][350/391]	Time  0.036 ( 0.036)	Data  0.001 ( 0.001)	Loss 2.7454e-01 (2.8373e-01)	Acc@1  91.41 ( 91.26)	Acc@5  99.22 ( 99.54)
Epoch: [63][360/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.001)	Loss 2.2647e-01 (2.8390e-01)	Acc@1  92.19 ( 91.25)	Acc@5 100.00 ( 99.54)
Epoch: [63][370/391]	Time  0.035 ( 0.036)	Data  0.001 ( 0.001)	Loss 3.3524e-01 (2.8505e-01)	Acc@1  87.50 ( 91.20)	Acc@5 100.00 ( 99.54)
Epoch: [63][380/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.001)	Loss 2.2785e-01 (2.8525e-01)	Acc@1  93.75 ( 91.21)	Acc@5  99.22 ( 99.54)
Epoch: [63][390/391]	Time  0.025 ( 0.036)	Data  0.001 ( 0.001)	Loss 2.2489e-01 (2.8474e-01)	Acc@1  93.75 ( 91.23)	Acc@5 100.00 ( 99.54)
## e[63] optimizer.zero_grad (sum) time: 0.1642465591430664
## e[63]       loss.backward (sum) time: 3.25431752204895
## e[63]      optimizer.step (sum) time: 1.111210584640503
## epoch[63] training(only) time: 14.112643480300903
# Switched to evaluate mode...
Test: [  0/100]	Time  0.155 ( 0.155)	Loss 1.2238e+00 (1.2238e+00)	Acc@1  71.00 ( 71.00)	Acc@5  92.00 ( 92.00)
Test: [ 10/100]	Time  0.024 ( 0.035)	Loss 1.3950e+00 (1.4614e+00)	Acc@1  68.00 ( 67.55)	Acc@5  93.00 ( 90.27)
Test: [ 20/100]	Time  0.024 ( 0.029)	Loss 1.2471e+00 (1.4195e+00)	Acc@1  75.00 ( 67.90)	Acc@5  93.00 ( 90.81)
Test: [ 30/100]	Time  0.023 ( 0.027)	Loss 1.8485e+00 (1.4472e+00)	Acc@1  62.00 ( 67.26)	Acc@5  90.00 ( 90.58)
Test: [ 40/100]	Time  0.022 ( 0.025)	Loss 1.3707e+00 (1.4321e+00)	Acc@1  69.00 ( 67.32)	Acc@5  92.00 ( 90.54)
Test: [ 50/100]	Time  0.022 ( 0.025)	Loss 1.4010e+00 (1.4368e+00)	Acc@1  70.00 ( 67.39)	Acc@5  90.00 ( 90.43)
Test: [ 60/100]	Time  0.017 ( 0.025)	Loss 1.4935e+00 (1.4085e+00)	Acc@1  63.00 ( 67.61)	Acc@5  86.00 ( 90.77)
Test: [ 70/100]	Time  0.018 ( 0.024)	Loss 1.6286e+00 (1.4149e+00)	Acc@1  65.00 ( 67.38)	Acc@5  88.00 ( 90.73)
Test: [ 80/100]	Time  0.019 ( 0.023)	Loss 1.5066e+00 (1.4201e+00)	Acc@1  73.00 ( 67.41)	Acc@5  87.00 ( 90.62)
Test: [ 90/100]	Time  0.024 ( 0.023)	Loss 1.8102e+00 (1.4108e+00)	Acc@1  63.00 ( 67.60)	Acc@5  87.00 ( 90.70)
 * Acc@1 67.740 Acc@5 90.880
### epoch[63] execution time: 16.48280096054077
EPOCH 64
REMOVING: module.fire5.expand_1x1.0.bias
REMOVING: module.fire5.expand_1x1.1.weight
REMOVING: module.fire5.expand_1x1.1.bias
i:   0, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.001105727875930539   to: 0.001006568141406754
i:   1, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.001181345477776634   to: 0.001033633387362458
i:   2, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.001276271364399350   to: 0.001081129959471121
i:   3, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.001389955783209533   to: 0.001148503378051790
i:   4, name:  module.fire6.squeeze.0.weight  changing lr from: 0.001521855231934426   to: 0.001235204432646363
i:   5, name:    module.fire6.squeeze.0.bias  changing lr from: 0.001671432768689445   to: 0.001340689557128065
i:   6, name:  module.fire6.squeeze.1.weight  changing lr from: 0.001838158293419156   to: 0.001464421173451601
i:   7, name:    module.fire6.squeeze.1.bias  changing lr from: 0.002021508802169957   to: 0.001605868005577559
i:   8, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.002220968615604867   to: 0.001764505365052820
i:   9, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.002436029583119097   to: 0.001939815409677686
i:  10, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.002666191263864675   to: 0.002131287376640438
i:  11, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.002910961085942103   to: 0.002338417791450009
i:  12, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.003169854484968592   to: 0.002560710653948983
i:  13, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.003442395023183891   to: 0.002797677602640335
i:  14, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.003728114490208417   to: 0.003048838058514524
i:  15, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.004026552986522097   to: 0.003313719349516785
i:  16, name:  module.fire7.squeeze.0.weight  changing lr from: 0.004337258990688186   to: 0.003591856816749288
i:  17, name:    module.fire7.squeeze.0.bias  changing lr from: 0.004659789411302255   to: 0.003882793903458298
i:  18, name:  module.fire7.squeeze.1.weight  changing lr from: 0.004993709624604952   to: 0.004186082227813175
i:  19, name:    module.fire7.squeeze.1.bias  changing lr from: 0.005338593498655108   to: 0.004501281640441840
i:  20, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.005694023404921028   to: 0.004827960267646347
i:  21, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.006059590218108024   to: 0.005165694541181936
i:  22, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.006434893305003564   to: 0.005514069215444594
i:  23, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.006819540503084775   to: 0.005872677372873908
i:  24, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.007213148089598242   to: 0.006241120418342272
i:  25, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.007615340741787912   to: 0.006619008063265258
i:  26, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.008025751488914795   to: 0.007005958300134767
i:  27, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.008444021656679894   to: 0.007401597368142742
i:  28, name:  module.fire8.squeeze.0.weight  changing lr from: 0.008869800804632243   to: 0.007805559710531856
i:  29, name:    module.fire8.squeeze.0.bias  changing lr from: 0.009302746657114187   to: 0.008217487924278382
i:  30, name:  module.fire8.squeeze.1.weight  changing lr from: 0.009742525028268133   to: 0.008637032702683418
i:  31, name:    module.fire8.squeeze.1.bias  changing lr from: 0.010188809741602217   to: 0.009063852771419488
i:  32, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.010641282544585594   to: 0.009497614818551901
i:  33, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.011099633018720474   to: 0.009937993419028884
i:  34, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.011563558485512444   to: 0.010384670954107535
i:  35, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.012032763908739374   to: 0.010837337526159424
i:  36, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.012506961793395766   to: 0.011295690869275472
i:  37, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.012985872081669625   to: 0.011759436256067884
i:  38, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.013469222046287567   to: 0.012228286401044508
i:  39, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.013956746181545861   to: 0.012701961360911042
i:  40, name:  module.fire9.squeeze.0.weight  changing lr from: 0.014448186092325628   to: 0.013180188432136409
i:  41, name:    module.fire9.squeeze.0.bias  changing lr from: 0.014943290381373413   to: 0.013662702046097548
i:  42, name:  module.fire9.squeeze.1.weight  changing lr from: 0.015441814535111353   to: 0.014149243662101962
i:  43, name:    module.fire9.squeeze.1.bias  changing lr from: 0.015943520808225302   to: 0.014639561658568917
i:  44, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.016448178107263522   to: 0.015133411222633529
i:  45, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.016955561873464520   to: 0.015630554238422460
i:  46, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.017465453965018418   to: 0.016130759174234476
i:  47, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.017977642538952950   to: 0.016633800968844831
i:  48, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.018491921932822713   to: 0.017139460917139034
i:  49, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.019008092546368444   to: 0.017647526555267991
i:  50, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.019525960723301160   to: 0.018157791545504214
i:  51, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.020045338633355891   to: 0.018670055560967021
i:  52, name:           module.conv10.weight  changing lr from: 0.020566044154749004   to: 0.019184124170373629
i:  53, name:             module.conv10.bias  changing lr from: 0.021087900757163339   to: 0.019699808722961315



# Switched to train mode...
Epoch: [64][  0/391]	Time  0.186 ( 0.186)	Data  0.145 ( 0.145)	Loss 1.8307e-01 (1.8307e-01)	Acc@1  95.31 ( 95.31)	Acc@5 100.00 (100.00)
Epoch: [64][ 10/391]	Time  0.034 ( 0.050)	Data  0.001 ( 0.014)	Loss 3.5461e-01 (2.4161e-01)	Acc@1  88.28 ( 92.83)	Acc@5  99.22 ( 99.50)
Epoch: [64][ 20/391]	Time  0.034 ( 0.043)	Data  0.001 ( 0.008)	Loss 2.9492e-01 (2.5449e-01)	Acc@1  86.72 ( 92.56)	Acc@5 100.00 ( 99.59)
Epoch: [64][ 30/391]	Time  0.035 ( 0.041)	Data  0.001 ( 0.006)	Loss 2.1071e-01 (2.5256e-01)	Acc@1  96.09 ( 92.52)	Acc@5 100.00 ( 99.67)
Epoch: [64][ 40/391]	Time  0.034 ( 0.039)	Data  0.001 ( 0.005)	Loss 3.3482e-01 (2.5838e-01)	Acc@1  89.84 ( 92.02)	Acc@5 100.00 ( 99.66)
Epoch: [64][ 50/391]	Time  0.036 ( 0.038)	Data  0.001 ( 0.004)	Loss 3.5797e-01 (2.6897e-01)	Acc@1  91.41 ( 91.80)	Acc@5  99.22 ( 99.53)
Epoch: [64][ 60/391]	Time  0.034 ( 0.038)	Data  0.001 ( 0.003)	Loss 2.6311e-01 (2.6862e-01)	Acc@1  89.06 ( 91.89)	Acc@5 100.00 ( 99.54)
Epoch: [64][ 70/391]	Time  0.034 ( 0.037)	Data  0.001 ( 0.003)	Loss 3.8039e-01 (2.7321e-01)	Acc@1  89.84 ( 91.67)	Acc@5  99.22 ( 99.50)
Epoch: [64][ 80/391]	Time  0.034 ( 0.037)	Data  0.001 ( 0.003)	Loss 3.1166e-01 (2.7340e-01)	Acc@1  87.50 ( 91.61)	Acc@5 100.00 ( 99.49)
Epoch: [64][ 90/391]	Time  0.038 ( 0.037)	Data  0.001 ( 0.003)	Loss 2.1484e-01 (2.7182e-01)	Acc@1  92.19 ( 91.68)	Acc@5 100.00 ( 99.49)
Epoch: [64][100/391]	Time  0.035 ( 0.037)	Data  0.001 ( 0.002)	Loss 2.9499e-01 (2.7123e-01)	Acc@1  92.97 ( 91.72)	Acc@5  98.44 ( 99.48)
Epoch: [64][110/391]	Time  0.038 ( 0.036)	Data  0.001 ( 0.002)	Loss 2.9536e-01 (2.7310e-01)	Acc@1  89.06 ( 91.62)	Acc@5  99.22 ( 99.49)
Epoch: [64][120/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.002)	Loss 2.8435e-01 (2.7421e-01)	Acc@1  89.84 ( 91.55)	Acc@5  99.22 ( 99.48)
Epoch: [64][130/391]	Time  0.035 ( 0.036)	Data  0.001 ( 0.002)	Loss 2.3900e-01 (2.7459e-01)	Acc@1  93.75 ( 91.58)	Acc@5 100.00 ( 99.47)
Epoch: [64][140/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.002)	Loss 3.4561e-01 (2.7392e-01)	Acc@1  89.84 ( 91.64)	Acc@5 100.00 ( 99.47)
Epoch: [64][150/391]	Time  0.033 ( 0.036)	Data  0.001 ( 0.002)	Loss 2.6183e-01 (2.7229e-01)	Acc@1  92.97 ( 91.68)	Acc@5 100.00 ( 99.49)
Epoch: [64][160/391]	Time  0.037 ( 0.036)	Data  0.001 ( 0.002)	Loss 2.9101e-01 (2.7328e-01)	Acc@1  90.62 ( 91.65)	Acc@5 100.00 ( 99.48)
Epoch: [64][170/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.002)	Loss 2.4003e-01 (2.7418e-01)	Acc@1  92.19 ( 91.58)	Acc@5 100.00 ( 99.48)
Epoch: [64][180/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.002)	Loss 1.8110e-01 (2.7286e-01)	Acc@1  95.31 ( 91.65)	Acc@5 100.00 ( 99.48)
Epoch: [64][190/391]	Time  0.038 ( 0.036)	Data  0.001 ( 0.002)	Loss 3.6123e-01 (2.7380e-01)	Acc@1  86.72 ( 91.59)	Acc@5  98.44 ( 99.48)
Epoch: [64][200/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.002)	Loss 2.1030e-01 (2.7425e-01)	Acc@1  92.97 ( 91.55)	Acc@5 100.00 ( 99.49)
Epoch: [64][210/391]	Time  0.035 ( 0.036)	Data  0.001 ( 0.002)	Loss 1.9938e-01 (2.7515e-01)	Acc@1  94.53 ( 91.53)	Acc@5  99.22 ( 99.47)
Epoch: [64][220/391]	Time  0.037 ( 0.036)	Data  0.001 ( 0.002)	Loss 2.8678e-01 (2.7627e-01)	Acc@1  92.19 ( 91.45)	Acc@5 100.00 ( 99.47)
Epoch: [64][230/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.002)	Loss 2.9063e-01 (2.7672e-01)	Acc@1  89.84 ( 91.42)	Acc@5 100.00 ( 99.46)
Epoch: [64][240/391]	Time  0.036 ( 0.036)	Data  0.001 ( 0.002)	Loss 2.9588e-01 (2.7736e-01)	Acc@1  92.19 ( 91.45)	Acc@5  99.22 ( 99.46)
Epoch: [64][250/391]	Time  0.035 ( 0.036)	Data  0.001 ( 0.002)	Loss 1.8191e-01 (2.7671e-01)	Acc@1  95.31 ( 91.47)	Acc@5 100.00 ( 99.46)
Epoch: [64][260/391]	Time  0.037 ( 0.036)	Data  0.001 ( 0.002)	Loss 3.2132e-01 (2.7650e-01)	Acc@1  89.06 ( 91.48)	Acc@5  99.22 ( 99.47)
Epoch: [64][270/391]	Time  0.035 ( 0.036)	Data  0.001 ( 0.002)	Loss 2.5006e-01 (2.7754e-01)	Acc@1  91.41 ( 91.46)	Acc@5 100.00 ( 99.45)
Epoch: [64][280/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.001)	Loss 2.7102e-01 (2.7748e-01)	Acc@1  90.62 ( 91.45)	Acc@5 100.00 ( 99.46)
Epoch: [64][290/391]	Time  0.037 ( 0.036)	Data  0.001 ( 0.001)	Loss 2.8557e-01 (2.7738e-01)	Acc@1  95.31 ( 91.46)	Acc@5  99.22 ( 99.45)
Epoch: [64][300/391]	Time  0.036 ( 0.036)	Data  0.001 ( 0.001)	Loss 1.9098e-01 (2.7725e-01)	Acc@1  96.88 ( 91.44)	Acc@5 100.00 ( 99.46)
Epoch: [64][310/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.001)	Loss 2.7676e-01 (2.7762e-01)	Acc@1  89.06 ( 91.40)	Acc@5  99.22 ( 99.46)
Epoch: [64][320/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.001)	Loss 2.6017e-01 (2.7729e-01)	Acc@1  94.53 ( 91.44)	Acc@5  99.22 ( 99.46)
Epoch: [64][330/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.001)	Loss 2.1706e-01 (2.7671e-01)	Acc@1  94.53 ( 91.48)	Acc@5 100.00 ( 99.46)
Epoch: [64][340/391]	Time  0.037 ( 0.036)	Data  0.001 ( 0.001)	Loss 2.4595e-01 (2.7668e-01)	Acc@1  95.31 ( 91.47)	Acc@5  98.44 ( 99.46)
Epoch: [64][350/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.001)	Loss 3.9051e-01 (2.7829e-01)	Acc@1  89.84 ( 91.42)	Acc@5  99.22 ( 99.46)
Epoch: [64][360/391]	Time  0.034 ( 0.035)	Data  0.001 ( 0.001)	Loss 2.9257e-01 (2.7857e-01)	Acc@1  90.62 ( 91.40)	Acc@5  99.22 ( 99.46)
Epoch: [64][370/391]	Time  0.036 ( 0.036)	Data  0.001 ( 0.001)	Loss 2.9974e-01 (2.7932e-01)	Acc@1  90.62 ( 91.37)	Acc@5 100.00 ( 99.46)
Epoch: [64][380/391]	Time  0.039 ( 0.035)	Data  0.001 ( 0.001)	Loss 3.0794e-01 (2.7989e-01)	Acc@1  89.84 ( 91.36)	Acc@5  98.44 ( 99.46)
Epoch: [64][390/391]	Time  0.023 ( 0.035)	Data  0.001 ( 0.001)	Loss 3.4421e-01 (2.8064e-01)	Acc@1  88.75 ( 91.34)	Acc@5  98.75 ( 99.46)
## e[64] optimizer.zero_grad (sum) time: 0.1568145751953125
## e[64]       loss.backward (sum) time: 3.205312967300415
## e[64]      optimizer.step (sum) time: 1.0709152221679688
## epoch[64] training(only) time: 13.926632165908813
# Switched to evaluate mode...
Test: [  0/100]	Time  0.157 ( 0.157)	Loss 1.3115e+00 (1.3115e+00)	Acc@1  66.00 ( 66.00)	Acc@5  89.00 ( 89.00)
Test: [ 10/100]	Time  0.022 ( 0.034)	Loss 1.4228e+00 (1.4515e+00)	Acc@1  64.00 ( 68.55)	Acc@5  91.00 ( 88.91)
Test: [ 20/100]	Time  0.024 ( 0.029)	Loss 1.3831e+00 (1.4022e+00)	Acc@1  73.00 ( 68.67)	Acc@5  94.00 ( 89.90)
Test: [ 30/100]	Time  0.023 ( 0.027)	Loss 1.7802e+00 (1.4351e+00)	Acc@1  60.00 ( 67.61)	Acc@5  88.00 ( 89.97)
Test: [ 40/100]	Time  0.023 ( 0.025)	Loss 1.4350e+00 (1.4309e+00)	Acc@1  68.00 ( 67.56)	Acc@5  90.00 ( 90.02)
Test: [ 50/100]	Time  0.018 ( 0.024)	Loss 1.4525e+00 (1.4390e+00)	Acc@1  71.00 ( 67.49)	Acc@5  93.00 ( 90.10)
Test: [ 60/100]	Time  0.023 ( 0.024)	Loss 1.6628e+00 (1.4206e+00)	Acc@1  63.00 ( 67.61)	Acc@5  87.00 ( 90.46)
Test: [ 70/100]	Time  0.024 ( 0.023)	Loss 1.6823e+00 (1.4207e+00)	Acc@1  67.00 ( 67.42)	Acc@5  86.00 ( 90.54)
Test: [ 80/100]	Time  0.024 ( 0.023)	Loss 1.4921e+00 (1.4247e+00)	Acc@1  72.00 ( 67.46)	Acc@5  88.00 ( 90.52)
Test: [ 90/100]	Time  0.024 ( 0.023)	Loss 1.6683e+00 (1.4116e+00)	Acc@1  63.00 ( 67.73)	Acc@5  88.00 ( 90.59)
 * Acc@1 68.000 Acc@5 90.730
### epoch[64] execution time: 16.310073375701904
EPOCH 65
REMOVING: module.fire5.expand_3x3.0.weight
REMOVING: module.fire5.expand_3x3.0.bias
i:   0, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.001081129959471121   to: 0.001001925963064497
i:   1, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.001148503378051790   to: 0.001021326936322857
i:   2, name:  module.fire6.squeeze.0.weight  changing lr from: 0.001235204432646363   to: 0.001061151228329592
i:   3, name:    module.fire6.squeeze.0.bias  changing lr from: 0.001340689557128065   to: 0.001120851076547718
i:   4, name:  module.fire6.squeeze.1.weight  changing lr from: 0.001464421173451601   to: 0.001199883735401119
i:   5, name:    module.fire6.squeeze.1.bias  changing lr from: 0.001605868005577559   to: 0.001297711853625865
i:   6, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.001764505365052820   to: 0.001413803820648656
i:   7, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.001939815409677686   to: 0.001547634083489379
i:   8, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.002131287376640438   to: 0.001698683435635655
i:   9, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.002338417791450009   to: 0.001866439279288339
i:  10, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.002560710653948983   to: 0.002050395862328623
i:  11, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.002797677602640335   to: 0.002250054491309383
i:  12, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.003048838058514524   to: 0.002464923721726108
i:  13, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.003313719349516785   to: 0.002694519526776356
i:  14, name:  module.fire7.squeeze.0.weight  changing lr from: 0.003591856816749288   to: 0.002938365445770701
i:  15, name:    module.fire7.squeeze.0.bias  changing lr from: 0.003882793903458298   to: 0.003195992713313477
i:  16, name:  module.fire7.squeeze.1.weight  changing lr from: 0.004186082227813175   to: 0.003466940370327359
i:  17, name:    module.fire7.squeeze.1.bias  changing lr from: 0.004501281640441840   to: 0.003750755357952989
i:  18, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.004827960267646347   to: 0.004046992595312947
i:  19, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.005165694541181936   to: 0.004355215042087967
i:  20, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.005514069215444594   to: 0.004674993746813932
i:  21, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.005872677372873908   to: 0.005005907881768806
i:  22, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.006241120418342272   to: 0.005347544765281508
i:  23, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.006619008063265258   to: 0.005699499872257396
i:  24, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.007005958300134767   to: 0.006061376833680287
i:  25, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.007401597368142742   to: 0.006432787425815789
i:  26, name:  module.fire8.squeeze.0.weight  changing lr from: 0.007805559710531856   to: 0.006813351549807977
i:  27, name:    module.fire8.squeeze.0.bias  changing lr from: 0.008217487924278382   to: 0.007202697202328789
i:  28, name:  module.fire8.squeeze.1.weight  changing lr from: 0.008637032702683418   to: 0.007600460437908896
i:  29, name:    module.fire8.squeeze.1.bias  changing lr from: 0.009063852771419488   to: 0.008006285323548183
i:  30, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.009497614818551901   to: 0.008419823886175310
i:  31, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.009937993419028884   to: 0.008840736053498093
i:  32, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.010384670954107535   to: 0.009268689588759000
i:  33, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.010837337526159424   to: 0.009703360019884654
i:  34, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.011295690869275472   to: 0.010144430563492856
i:  35, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.011759436256067884   to: 0.010591592044197334
i:  36, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.012228286401044508   to: 0.011044542809626728
i:  37, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.012701961360911042   to: 0.011502988641552699
i:  38, name:  module.fire9.squeeze.0.weight  changing lr from: 0.013180188432136409   to: 0.011966642663500726
i:  39, name:    module.fire9.squeeze.0.bias  changing lr from: 0.013662702046097548   to: 0.012435225245196808
i:  40, name:  module.fire9.squeeze.1.weight  changing lr from: 0.014149243662101962   to: 0.012908463904183931
i:  41, name:    module.fire9.squeeze.1.bias  changing lr from: 0.014639561658568917   to: 0.013386093204923365
i:  42, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.015133411222633529   to: 0.013867854655678274
i:  43, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.015630554238422460   to: 0.014353496603459769
i:  44, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.016130759174234476   to: 0.014842774127299330
i:  45, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.016633800968844831   to: 0.015335448930096206
i:  46, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.017139460917139034   to: 0.015831289229272995
i:  47, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.017647526555267991   to: 0.016330069646458861
i:  48, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.018157791545504214   to: 0.016831571096406046
i:  49, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.018670055560967021   to: 0.017335580675332508
i:  50, name:           module.conv10.weight  changing lr from: 0.019184124170373629   to: 0.017841891548871208
i:  51, name:             module.conv10.bias  changing lr from: 0.019699808722961315   to: 0.018350302839794726



# Switched to train mode...
Epoch: [65][  0/391]	Time  0.196 ( 0.196)	Data  0.156 ( 0.156)	Loss 2.4648e-01 (2.4648e-01)	Acc@1  92.97 ( 92.97)	Acc@5  99.22 ( 99.22)
Epoch: [65][ 10/391]	Time  0.034 ( 0.051)	Data  0.001 ( 0.015)	Loss 3.1634e-01 (2.8130e-01)	Acc@1  89.06 ( 91.41)	Acc@5  98.44 ( 99.43)
Epoch: [65][ 20/391]	Time  0.034 ( 0.043)	Data  0.001 ( 0.008)	Loss 2.0525e-01 (2.7033e-01)	Acc@1  93.75 ( 91.67)	Acc@5 100.00 ( 99.48)
Epoch: [65][ 30/391]	Time  0.035 ( 0.040)	Data  0.001 ( 0.006)	Loss 3.1084e-01 (2.6768e-01)	Acc@1  89.84 ( 91.73)	Acc@5  99.22 ( 99.50)
Epoch: [65][ 40/391]	Time  0.034 ( 0.039)	Data  0.001 ( 0.005)	Loss 2.7273e-01 (2.6314e-01)	Acc@1  96.09 ( 92.24)	Acc@5  99.22 ( 99.50)
Epoch: [65][ 50/391]	Time  0.030 ( 0.038)	Data  0.001 ( 0.004)	Loss 2.2303e-01 (2.6132e-01)	Acc@1  92.97 ( 92.17)	Acc@5 100.00 ( 99.54)
Epoch: [65][ 60/391]	Time  0.036 ( 0.038)	Data  0.001 ( 0.004)	Loss 2.5533e-01 (2.6093e-01)	Acc@1  93.75 ( 92.32)	Acc@5 100.00 ( 99.58)
Epoch: [65][ 70/391]	Time  0.034 ( 0.037)	Data  0.001 ( 0.003)	Loss 2.5923e-01 (2.6023e-01)	Acc@1  89.84 ( 92.28)	Acc@5 100.00 ( 99.59)
Epoch: [65][ 80/391]	Time  0.030 ( 0.037)	Data  0.001 ( 0.003)	Loss 2.6818e-01 (2.6286e-01)	Acc@1  91.41 ( 92.22)	Acc@5  99.22 ( 99.59)
Epoch: [65][ 90/391]	Time  0.034 ( 0.037)	Data  0.001 ( 0.003)	Loss 2.0590e-01 (2.6282e-01)	Acc@1  95.31 ( 92.31)	Acc@5 100.00 ( 99.56)
Epoch: [65][100/391]	Time  0.037 ( 0.037)	Data  0.001 ( 0.003)	Loss 3.5388e-01 (2.6164e-01)	Acc@1  86.72 ( 92.21)	Acc@5  99.22 ( 99.58)
Epoch: [65][110/391]	Time  0.035 ( 0.037)	Data  0.001 ( 0.002)	Loss 2.3648e-01 (2.6213e-01)	Acc@1  93.75 ( 92.15)	Acc@5  99.22 ( 99.59)
Epoch: [65][120/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.002)	Loss 3.1981e-01 (2.6251e-01)	Acc@1  89.06 ( 92.08)	Acc@5  99.22 ( 99.60)
Epoch: [65][130/391]	Time  0.036 ( 0.036)	Data  0.001 ( 0.002)	Loss 2.5925e-01 (2.6464e-01)	Acc@1  89.84 ( 92.04)	Acc@5 100.00 ( 99.60)
Epoch: [65][140/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.002)	Loss 1.7464e-01 (2.6327e-01)	Acc@1  96.88 ( 92.10)	Acc@5 100.00 ( 99.59)
Epoch: [65][150/391]	Time  0.042 ( 0.036)	Data  0.001 ( 0.002)	Loss 2.5985e-01 (2.6417e-01)	Acc@1  89.84 ( 92.06)	Acc@5 100.00 ( 99.61)
Epoch: [65][160/391]	Time  0.036 ( 0.036)	Data  0.001 ( 0.002)	Loss 2.9912e-01 (2.6360e-01)	Acc@1  89.06 ( 92.09)	Acc@5  99.22 ( 99.60)
Epoch: [65][170/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.002)	Loss 3.0964e-01 (2.6426e-01)	Acc@1  91.41 ( 92.07)	Acc@5  99.22 ( 99.59)
Epoch: [65][180/391]	Time  0.040 ( 0.036)	Data  0.001 ( 0.002)	Loss 2.2188e-01 (2.6505e-01)	Acc@1  94.53 ( 92.06)	Acc@5 100.00 ( 99.58)
Epoch: [65][190/391]	Time  0.035 ( 0.036)	Data  0.001 ( 0.002)	Loss 2.7660e-01 (2.6528e-01)	Acc@1  90.62 ( 92.05)	Acc@5 100.00 ( 99.59)
Epoch: [65][200/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.002)	Loss 2.9367e-01 (2.6634e-01)	Acc@1  91.41 ( 92.02)	Acc@5 100.00 ( 99.59)
Epoch: [65][210/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.002)	Loss 2.4646e-01 (2.6736e-01)	Acc@1  93.75 ( 91.95)	Acc@5  98.44 ( 99.59)
Epoch: [65][220/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.002)	Loss 2.1237e-01 (2.6797e-01)	Acc@1  95.31 ( 91.93)	Acc@5 100.00 ( 99.57)
Epoch: [65][230/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.002)	Loss 2.0980e-01 (2.6780e-01)	Acc@1  93.75 ( 91.95)	Acc@5 100.00 ( 99.58)
Epoch: [65][240/391]	Time  0.039 ( 0.036)	Data  0.001 ( 0.002)	Loss 3.2171e-01 (2.6856e-01)	Acc@1  89.84 ( 91.91)	Acc@5  99.22 ( 99.59)
Epoch: [65][250/391]	Time  0.035 ( 0.036)	Data  0.001 ( 0.002)	Loss 2.4507e-01 (2.6771e-01)	Acc@1  93.75 ( 91.95)	Acc@5 100.00 ( 99.59)
Epoch: [65][260/391]	Time  0.036 ( 0.036)	Data  0.001 ( 0.002)	Loss 2.5019e-01 (2.6790e-01)	Acc@1  89.84 ( 91.94)	Acc@5 100.00 ( 99.58)
Epoch: [65][270/391]	Time  0.035 ( 0.036)	Data  0.001 ( 0.002)	Loss 1.9064e-01 (2.6691e-01)	Acc@1  97.66 ( 91.98)	Acc@5 100.00 ( 99.60)
Epoch: [65][280/391]	Time  0.035 ( 0.036)	Data  0.001 ( 0.002)	Loss 3.1167e-01 (2.6698e-01)	Acc@1  90.62 ( 91.97)	Acc@5  99.22 ( 99.60)
Epoch: [65][290/391]	Time  0.035 ( 0.036)	Data  0.001 ( 0.002)	Loss 2.3972e-01 (2.6715e-01)	Acc@1  89.84 ( 91.97)	Acc@5 100.00 ( 99.60)
Epoch: [65][300/391]	Time  0.036 ( 0.036)	Data  0.001 ( 0.001)	Loss 2.5267e-01 (2.6721e-01)	Acc@1  94.53 ( 91.96)	Acc@5  99.22 ( 99.60)
Epoch: [65][310/391]	Time  0.035 ( 0.036)	Data  0.001 ( 0.001)	Loss 2.3752e-01 (2.6762e-01)	Acc@1  93.75 ( 91.95)	Acc@5 100.00 ( 99.57)
Epoch: [65][320/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.001)	Loss 3.1534e-01 (2.6722e-01)	Acc@1  92.97 ( 91.98)	Acc@5 100.00 ( 99.57)
Epoch: [65][330/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.001)	Loss 3.2124e-01 (2.6825e-01)	Acc@1  87.50 ( 91.92)	Acc@5 100.00 ( 99.58)
Epoch: [65][340/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.001)	Loss 3.3700e-01 (2.6848e-01)	Acc@1  88.28 ( 91.92)	Acc@5  98.44 ( 99.58)
Epoch: [65][350/391]	Time  0.033 ( 0.036)	Data  0.001 ( 0.001)	Loss 3.0595e-01 (2.6803e-01)	Acc@1  90.62 ( 91.92)	Acc@5  99.22 ( 99.59)
Epoch: [65][360/391]	Time  0.033 ( 0.036)	Data  0.001 ( 0.001)	Loss 2.8638e-01 (2.6793e-01)	Acc@1  89.84 ( 91.91)	Acc@5  99.22 ( 99.59)
Epoch: [65][370/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.001)	Loss 2.0330e-01 (2.6831e-01)	Acc@1  93.75 ( 91.88)	Acc@5 100.00 ( 99.59)
Epoch: [65][380/391]	Time  0.041 ( 0.036)	Data  0.001 ( 0.001)	Loss 2.1288e-01 (2.6827e-01)	Acc@1  91.41 ( 91.87)	Acc@5  99.22 ( 99.59)
Epoch: [65][390/391]	Time  0.023 ( 0.035)	Data  0.001 ( 0.001)	Loss 4.3338e-01 (2.6920e-01)	Acc@1  86.25 ( 91.84)	Acc@5  98.75 ( 99.58)
## e[65] optimizer.zero_grad (sum) time: 0.15070676803588867
## e[65]       loss.backward (sum) time: 3.147730588912964
## e[65]      optimizer.step (sum) time: 1.0277483463287354
## epoch[65] training(only) time: 13.95632553100586
# Switched to evaluate mode...
Test: [  0/100]	Time  0.153 ( 0.153)	Loss 1.2512e+00 (1.2512e+00)	Acc@1  72.00 ( 72.00)	Acc@5  89.00 ( 89.00)
Test: [ 10/100]	Time  0.018 ( 0.033)	Loss 1.3652e+00 (1.4513e+00)	Acc@1  65.00 ( 68.18)	Acc@5  91.00 ( 89.64)
Test: [ 20/100]	Time  0.022 ( 0.028)	Loss 1.2227e+00 (1.4285e+00)	Acc@1  74.00 ( 68.43)	Acc@5  93.00 ( 90.48)
Test: [ 30/100]	Time  0.024 ( 0.026)	Loss 1.6993e+00 (1.4513e+00)	Acc@1  66.00 ( 67.71)	Acc@5  90.00 ( 90.32)
Test: [ 40/100]	Time  0.017 ( 0.025)	Loss 1.4556e+00 (1.4454e+00)	Acc@1  69.00 ( 67.80)	Acc@5  88.00 ( 90.20)
Test: [ 50/100]	Time  0.024 ( 0.024)	Loss 1.5301e+00 (1.4507e+00)	Acc@1  66.00 ( 67.65)	Acc@5  89.00 ( 90.12)
Test: [ 60/100]	Time  0.024 ( 0.024)	Loss 1.5029e+00 (1.4252e+00)	Acc@1  65.00 ( 67.84)	Acc@5  88.00 ( 90.54)
Test: [ 70/100]	Time  0.019 ( 0.024)	Loss 1.6148e+00 (1.4242e+00)	Acc@1  67.00 ( 67.82)	Acc@5  89.00 ( 90.49)
Test: [ 80/100]	Time  0.018 ( 0.024)	Loss 1.5511e+00 (1.4294e+00)	Acc@1  71.00 ( 67.94)	Acc@5  89.00 ( 90.47)
Test: [ 90/100]	Time  0.022 ( 0.023)	Loss 1.7919e+00 (1.4181e+00)	Acc@1  63.00 ( 68.20)	Acc@5  87.00 ( 90.58)
 * Acc@1 68.410 Acc@5 90.720
### epoch[65] execution time: 16.310285329818726
EPOCH 66
REMOVING: module.fire5.expand_3x3.1.weight
REMOVING: module.fire5.expand_3x3.1.bias
i:   0, name:  module.fire6.squeeze.0.weight  changing lr from: 0.001061151228329592   to: 0.001000089430954608
i:   1, name:    module.fire6.squeeze.0.bias  changing lr from: 0.001120851076547718   to: 0.001012408294852112
i:   2, name:  module.fire6.squeeze.1.weight  changing lr from: 0.001199883735401119   to: 0.001045129144030775
i:   3, name:    module.fire6.squeeze.1.bias  changing lr from: 0.001297711853625865   to: 0.001097710912901394
i:   4, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.001413803820648656   to: 0.001169617316830456
i:   5, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.001547634083489379   to: 0.001260317230858542
i:   6, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.001698683435635655   to: 0.001369285037857564
i:   7, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.001866439279288339   to: 0.001496000947588138
i:   8, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.002050395862328623   to: 0.001639951288071267
i:   9, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.002250054491309383   to: 0.001800628770641443
i:  10, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.002464923721726108   to: 0.001977532730001601
i:  11, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.002694519526776356   to: 0.002170169340554178
i:  12, name:  module.fire7.squeeze.0.weight  changing lr from: 0.002938365445770701   to: 0.002378051810237041
i:  13, name:    module.fire7.squeeze.0.bias  changing lr from: 0.003195992713313477   to: 0.002600700553047746
i:  14, name:  module.fire7.squeeze.1.weight  changing lr from: 0.003466940370327359   to: 0.002837643341395767
i:  15, name:    module.fire7.squeeze.1.bias  changing lr from: 0.003750755357952989   to: 0.003088415439378416
i:  16, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.004046992595312947   to: 0.003352559718034181
i:  17, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.004355215042087967   to: 0.003629626753584846
i:  18, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.004674993746813932   to: 0.003919174909637739
i:  19, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.005005907881768806   to: 0.004220770404278883
i:  20, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.005347544765281508   to: 0.004533987362950075
i:  21, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.005699499872257396   to: 0.004858407857964086
i:  22, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.006061376833680287   to: 0.005193621935476489
i:  23, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.006432787425815789   to: 0.005539227630696308
i:  24, name:  module.fire8.squeeze.0.weight  changing lr from: 0.006813351549807977   to: 0.005894830972083497
i:  25, name:    module.fire8.squeeze.0.bias  changing lr from: 0.007202697202328789   to: 0.006260045975247352
i:  26, name:  module.fire8.squeeze.1.weight  changing lr from: 0.007600460437908896   to: 0.006634494627228127
i:  27, name:    module.fire8.squeeze.1.bias  changing lr from: 0.008006285323548183   to: 0.007017806861812103
i:  28, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.008419823886175310   to: 0.007409620526500132
i:  29, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.008840736053498093   to: 0.007809581341720872
i:  30, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.009268689588759000   to: 0.008217342852850799
i:  31, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.009703360019884654   to: 0.008632566375576477
i:  32, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.010144430563492856   to: 0.009054920935107763
i:  33, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.010591592044197334   to: 0.009484083199725882
i:  34, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.011044542809626728   to: 0.009919737409125207
i:  35, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.011502988641552699   to: 0.010361575297984593
i:  36, name:  module.fire9.squeeze.0.weight  changing lr from: 0.011966642663500726   to: 0.010809296015181769
i:  37, name:    module.fire9.squeeze.0.bias  changing lr from: 0.012435225245196808   to: 0.011262606039041889
i:  38, name:  module.fire9.squeeze.1.weight  changing lr from: 0.012908463904183931   to: 0.011721219088991496
i:  39, name:    module.fire9.squeeze.1.bias  changing lr from: 0.013386093204923365   to: 0.012184856033968544
i:  40, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.013867854655678274   to: 0.012653244797920311
i:  41, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.014353496603459769   to: 0.013126120262702705
i:  42, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.014842774127299330   to: 0.013603224168677003
i:  43, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.015335448930096206   to: 0.014084305013282943
i:  44, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.015831289229272995   to: 0.014569117947851672
i:  45, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.016330069646458861   to: 0.015057424672906106
i:  46, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.016831571096406046   to: 0.015548993332181738
i:  47, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.017335580675332508   to: 0.016043598405587507
i:  48, name:           module.conv10.weight  changing lr from: 0.017841891548871208   to: 0.016541020601311913
i:  49, name:             module.conv10.bias  changing lr from: 0.018350302839794726   to: 0.017041046747267870



# Switched to train mode...
Epoch: [66][  0/391]	Time  0.190 ( 0.190)	Data  0.151 ( 0.151)	Loss 1.9572e-01 (1.9572e-01)	Acc@1  93.75 ( 93.75)	Acc@5 100.00 (100.00)
Epoch: [66][ 10/391]	Time  0.037 ( 0.050)	Data  0.001 ( 0.014)	Loss 2.9308e-01 (2.7184e-01)	Acc@1  92.97 ( 92.33)	Acc@5  98.44 ( 99.36)
Epoch: [66][ 20/391]	Time  0.034 ( 0.043)	Data  0.001 ( 0.008)	Loss 3.1303e-01 (2.5681e-01)	Acc@1  91.41 ( 92.86)	Acc@5  99.22 ( 99.48)
Epoch: [66][ 30/391]	Time  0.035 ( 0.041)	Data  0.001 ( 0.006)	Loss 2.2236e-01 (2.5765e-01)	Acc@1  92.19 ( 92.82)	Acc@5 100.00 ( 99.47)
Epoch: [66][ 40/391]	Time  0.034 ( 0.039)	Data  0.001 ( 0.005)	Loss 3.1910e-01 (2.5335e-01)	Acc@1  89.84 ( 92.93)	Acc@5  98.44 ( 99.50)
Epoch: [66][ 50/391]	Time  0.033 ( 0.038)	Data  0.001 ( 0.004)	Loss 2.7853e-01 (2.5219e-01)	Acc@1  90.62 ( 92.77)	Acc@5 100.00 ( 99.54)
Epoch: [66][ 60/391]	Time  0.033 ( 0.038)	Data  0.001 ( 0.003)	Loss 3.1882e-01 (2.5273e-01)	Acc@1  89.06 ( 92.62)	Acc@5  99.22 ( 99.56)
Epoch: [66][ 70/391]	Time  0.036 ( 0.037)	Data  0.001 ( 0.003)	Loss 2.3078e-01 (2.5620e-01)	Acc@1  95.31 ( 92.47)	Acc@5  99.22 ( 99.56)
Epoch: [66][ 80/391]	Time  0.034 ( 0.037)	Data  0.001 ( 0.003)	Loss 2.3776e-01 (2.5469e-01)	Acc@1  89.84 ( 92.46)	Acc@5 100.00 ( 99.59)
Epoch: [66][ 90/391]	Time  0.033 ( 0.037)	Data  0.001 ( 0.003)	Loss 1.8723e-01 (2.5440e-01)	Acc@1  94.53 ( 92.52)	Acc@5 100.00 ( 99.61)
Epoch: [66][100/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.002)	Loss 2.1621e-01 (2.5344e-01)	Acc@1  92.97 ( 92.56)	Acc@5 100.00 ( 99.61)
Epoch: [66][110/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.002)	Loss 2.6664e-01 (2.5358e-01)	Acc@1  92.19 ( 92.50)	Acc@5  99.22 ( 99.61)
Epoch: [66][120/391]	Time  0.036 ( 0.036)	Data  0.001 ( 0.002)	Loss 2.8835e-01 (2.5640e-01)	Acc@1  91.41 ( 92.38)	Acc@5  99.22 ( 99.60)
Epoch: [66][130/391]	Time  0.034 ( 0.036)	Data  0.002 ( 0.002)	Loss 2.0247e-01 (2.5455e-01)	Acc@1  93.75 ( 92.46)	Acc@5 100.00 ( 99.62)
Epoch: [66][140/391]	Time  0.035 ( 0.036)	Data  0.001 ( 0.002)	Loss 2.4885e-01 (2.5678e-01)	Acc@1  92.97 ( 92.42)	Acc@5 100.00 ( 99.62)
Epoch: [66][150/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.002)	Loss 1.9981e-01 (2.5726e-01)	Acc@1  96.88 ( 92.44)	Acc@5 100.00 ( 99.63)
Epoch: [66][160/391]	Time  0.033 ( 0.036)	Data  0.001 ( 0.002)	Loss 2.8499e-01 (2.5894e-01)	Acc@1  91.41 ( 92.33)	Acc@5  99.22 ( 99.62)
Epoch: [66][170/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.002)	Loss 2.2604e-01 (2.5729e-01)	Acc@1  95.31 ( 92.38)	Acc@5  98.44 ( 99.62)
Epoch: [66][180/391]	Time  0.041 ( 0.036)	Data  0.001 ( 0.002)	Loss 2.7665e-01 (2.5647e-01)	Acc@1  92.19 ( 92.41)	Acc@5  99.22 ( 99.62)
Epoch: [66][190/391]	Time  0.038 ( 0.036)	Data  0.001 ( 0.002)	Loss 2.8684e-01 (2.5719e-01)	Acc@1  91.41 ( 92.39)	Acc@5  99.22 ( 99.62)
Epoch: [66][200/391]	Time  0.035 ( 0.036)	Data  0.001 ( 0.002)	Loss 2.0100e-01 (2.5825e-01)	Acc@1  94.53 ( 92.33)	Acc@5 100.00 ( 99.62)
Epoch: [66][210/391]	Time  0.034 ( 0.035)	Data  0.001 ( 0.002)	Loss 1.6210e-01 (2.5878e-01)	Acc@1  95.31 ( 92.32)	Acc@5 100.00 ( 99.63)
Epoch: [66][220/391]	Time  0.034 ( 0.035)	Data  0.001 ( 0.002)	Loss 2.5008e-01 (2.5944e-01)	Acc@1  89.84 ( 92.27)	Acc@5 100.00 ( 99.64)
Epoch: [66][230/391]	Time  0.034 ( 0.035)	Data  0.001 ( 0.002)	Loss 2.0547e-01 (2.6045e-01)	Acc@1  92.19 ( 92.22)	Acc@5 100.00 ( 99.63)
Epoch: [66][240/391]	Time  0.034 ( 0.035)	Data  0.001 ( 0.002)	Loss 1.7415e-01 (2.6001e-01)	Acc@1  94.53 ( 92.22)	Acc@5 100.00 ( 99.64)
Epoch: [66][250/391]	Time  0.035 ( 0.035)	Data  0.001 ( 0.002)	Loss 2.1773e-01 (2.5931e-01)	Acc@1  92.19 ( 92.22)	Acc@5 100.00 ( 99.65)
Epoch: [66][260/391]	Time  0.035 ( 0.035)	Data  0.001 ( 0.002)	Loss 2.8498e-01 (2.6001e-01)	Acc@1  92.97 ( 92.21)	Acc@5  99.22 ( 99.64)
Epoch: [66][270/391]	Time  0.034 ( 0.035)	Data  0.001 ( 0.001)	Loss 3.8353e-01 (2.6135e-01)	Acc@1  88.28 ( 92.15)	Acc@5 100.00 ( 99.64)
Epoch: [66][280/391]	Time  0.034 ( 0.035)	Data  0.001 ( 0.001)	Loss 2.7532e-01 (2.6249e-01)	Acc@1  89.06 ( 92.08)	Acc@5  99.22 ( 99.62)
Epoch: [66][290/391]	Time  0.036 ( 0.035)	Data  0.001 ( 0.001)	Loss 2.7997e-01 (2.6204e-01)	Acc@1  92.97 ( 92.07)	Acc@5  99.22 ( 99.62)
Epoch: [66][300/391]	Time  0.033 ( 0.035)	Data  0.001 ( 0.001)	Loss 2.3309e-01 (2.6158e-01)	Acc@1  93.75 ( 92.08)	Acc@5 100.00 ( 99.63)
Epoch: [66][310/391]	Time  0.034 ( 0.035)	Data  0.001 ( 0.001)	Loss 2.9135e-01 (2.6230e-01)	Acc@1  92.97 ( 92.06)	Acc@5  99.22 ( 99.62)
Epoch: [66][320/391]	Time  0.037 ( 0.035)	Data  0.001 ( 0.001)	Loss 1.7214e-01 (2.6176e-01)	Acc@1  94.53 ( 92.10)	Acc@5 100.00 ( 99.63)
Epoch: [66][330/391]	Time  0.034 ( 0.035)	Data  0.001 ( 0.001)	Loss 3.2547e-01 (2.6256e-01)	Acc@1  90.62 ( 92.07)	Acc@5  99.22 ( 99.62)
Epoch: [66][340/391]	Time  0.035 ( 0.035)	Data  0.001 ( 0.001)	Loss 2.3164e-01 (2.6220e-01)	Acc@1  95.31 ( 92.08)	Acc@5  99.22 ( 99.62)
Epoch: [66][350/391]	Time  0.034 ( 0.035)	Data  0.001 ( 0.001)	Loss 1.7467e-01 (2.6205e-01)	Acc@1  96.88 ( 92.11)	Acc@5 100.00 ( 99.62)
Epoch: [66][360/391]	Time  0.034 ( 0.035)	Data  0.001 ( 0.001)	Loss 3.4685e-01 (2.6257e-01)	Acc@1  88.28 ( 92.07)	Acc@5 100.00 ( 99.63)
Epoch: [66][370/391]	Time  0.035 ( 0.035)	Data  0.001 ( 0.001)	Loss 1.4837e-01 (2.6305e-01)	Acc@1  96.09 ( 92.08)	Acc@5 100.00 ( 99.61)
Epoch: [66][380/391]	Time  0.034 ( 0.035)	Data  0.002 ( 0.001)	Loss 2.0012e-01 (2.6283e-01)	Acc@1  95.31 ( 92.09)	Acc@5 100.00 ( 99.62)
Epoch: [66][390/391]	Time  0.024 ( 0.035)	Data  0.001 ( 0.001)	Loss 4.0874e-01 (2.6340e-01)	Acc@1  87.50 ( 92.08)	Acc@5  97.50 ( 99.61)
## e[66] optimizer.zero_grad (sum) time: 0.1466991901397705
## e[66]       loss.backward (sum) time: 3.146857738494873
## e[66]      optimizer.step (sum) time: 0.986314058303833
## epoch[66] training(only) time: 13.80122447013855
# Switched to evaluate mode...
Test: [  0/100]	Time  0.150 ( 0.150)	Loss 1.2521e+00 (1.2521e+00)	Acc@1  71.00 ( 71.00)	Acc@5  91.00 ( 91.00)
Test: [ 10/100]	Time  0.023 ( 0.033)	Loss 1.4440e+00 (1.4433e+00)	Acc@1  67.00 ( 68.18)	Acc@5  93.00 ( 89.18)
Test: [ 20/100]	Time  0.021 ( 0.027)	Loss 1.2703e+00 (1.4153e+00)	Acc@1  75.00 ( 68.48)	Acc@5  94.00 ( 90.52)
Test: [ 30/100]	Time  0.024 ( 0.026)	Loss 1.6911e+00 (1.4498e+00)	Acc@1  61.00 ( 67.71)	Acc@5  89.00 ( 90.39)
Test: [ 40/100]	Time  0.017 ( 0.025)	Loss 1.4289e+00 (1.4521e+00)	Acc@1  69.00 ( 67.59)	Acc@5  91.00 ( 90.37)
Test: [ 50/100]	Time  0.018 ( 0.024)	Loss 1.6009e+00 (1.4660e+00)	Acc@1  67.00 ( 67.39)	Acc@5  89.00 ( 90.14)
Test: [ 60/100]	Time  0.022 ( 0.023)	Loss 1.5939e+00 (1.4435e+00)	Acc@1  62.00 ( 67.52)	Acc@5  85.00 ( 90.41)
Test: [ 70/100]	Time  0.024 ( 0.023)	Loss 1.6094e+00 (1.4425e+00)	Acc@1  68.00 ( 67.39)	Acc@5  90.00 ( 90.51)
Test: [ 80/100]	Time  0.022 ( 0.023)	Loss 1.5414e+00 (1.4445e+00)	Acc@1  69.00 ( 67.44)	Acc@5  88.00 ( 90.47)
Test: [ 90/100]	Time  0.024 ( 0.023)	Loss 1.8311e+00 (1.4327e+00)	Acc@1  61.00 ( 67.77)	Acc@5  86.00 ( 90.62)
 * Acc@1 68.110 Acc@5 90.710
### epoch[66] execution time: 16.141650438308716
EPOCH 67
REMOVING: module.fire6.squeeze.0.weight
REMOVING: module.fire6.squeeze.0.bias
REMOVING: module.fire6.squeeze.1.weight
i:   0, name:    module.fire6.squeeze.1.bias  changing lr from: 0.001097710912901394   to: 0.001006300397652775
i:   1, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.001169617316830456   to: 0.001032470385370559
i:   2, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.001260317230858542   to: 0.001078474111421939
i:   3, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.001369285037857564   to: 0.001143781733666065
i:   4, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.001496000947588138   to: 0.001227868349964883
i:   5, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.001639951288071267   to: 0.001330214347322949
i:   6, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.001800628770641443   to: 0.001450305722326721
i:   7, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.001977532730001601   to: 0.001587634374263829
i:   8, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.002170169340554178   to: 0.001741698372257676
i:   9, name:  module.fire7.squeeze.0.weight  changing lr from: 0.002378051810237041   to: 0.001912002197707645
i:  10, name:    module.fire7.squeeze.0.bias  changing lr from: 0.002600700553047746   to: 0.002098056963280664
i:  11, name:  module.fire7.squeeze.1.weight  changing lr from: 0.002837643341395767   to: 0.002299380609655914
i:  12, name:    module.fire7.squeeze.1.bias  changing lr from: 0.003088415439378416   to: 0.002515498081180883
i:  13, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.003352559718034181   to: 0.002745941481554459
i:  14, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.003629626753584846   to: 0.002990250210610356
i:  15, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.003919174909637739   to: 0.003247971083233430
i:  16, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.004220770404278883   to: 0.003518658431400523
i:  17, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.004533987362950075   to: 0.003801874190298492
i:  18, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.004858407857964086   to: 0.004097187969433141
i:  19, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.005193621935476489   to: 0.004404177109605488
i:  20, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.005539227630696308   to: 0.004722426726594813
i:  21, name:  module.fire8.squeeze.0.weight  changing lr from: 0.005894830972083497   to: 0.005051529742352678
i:  22, name:    module.fire8.squeeze.0.bias  changing lr from: 0.006260045975247352   to: 0.005391086904477016
i:  23, name:  module.fire8.squeeze.1.weight  changing lr from: 0.006634494627228127   to: 0.005740706794702343
i:  24, name:    module.fire8.squeeze.1.bias  changing lr from: 0.007017806861812103   to: 0.006100005827108983
i:  25, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.007409620526500132   to: 0.006468608236722655
i:  26, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.007809581341720872   to: 0.006846146059145857
i:  27, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.008217342852850799   to: 0.007232259101831650
i:  28, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.008632566375576477   to: 0.007626594907583211
i:  29, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.009054920935107763   to: 0.008028808710833640
i:  30, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.009484083199725882   to: 0.008438563387235004
i:  31, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.009919737409125207   to: 0.008855529397058887
i:  32, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.010361575297984593   to: 0.009279384722886714
i:  33, name:  module.fire9.squeeze.0.weight  changing lr from: 0.010809296015181769   to: 0.009709814802043925
i:  34, name:    module.fire9.squeeze.0.bias  changing lr from: 0.011262606039041889   to: 0.010146512454209142
i:  35, name:  module.fire9.squeeze.1.weight  changing lr from: 0.011721219088991496   to: 0.010589177804607431
i:  36, name:    module.fire9.squeeze.1.bias  changing lr from: 0.012184856033968544   to: 0.011037518203175788
i:  37, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.012653244797920311   to: 0.011491248140068366
i:  38, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.013126120262702705   to: 0.011950089157849286
i:  39, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.013603224168677003   to: 0.012413769760702915
i:  40, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.014084305013282943   to: 0.012882025320972205
i:  41, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.014569117947851672   to: 0.013354597983320071
i:  42, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.015057424672906106   to: 0.013831236566790944
i:  43, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.015548993332181738   to: 0.014311696465034395
i:  44, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.016043598405587507   to: 0.014795739544938225
i:  45, name:           module.conv10.weight  changing lr from: 0.016541020601311913   to: 0.015283134043902698
i:  46, name:             module.conv10.bias  changing lr from: 0.017041046747267870   to: 0.015773654465975163



# Switched to train mode...
Epoch: [67][  0/391]	Time  0.185 ( 0.185)	Data  0.147 ( 0.147)	Loss 3.3386e-01 (3.3386e-01)	Acc@1  89.06 ( 89.06)	Acc@5  98.44 ( 98.44)
Epoch: [67][ 10/391]	Time  0.040 ( 0.049)	Data  0.001 ( 0.014)	Loss 2.7808e-01 (2.6192e-01)	Acc@1  91.41 ( 91.41)	Acc@5  99.22 ( 99.43)
Epoch: [67][ 20/391]	Time  0.034 ( 0.043)	Data  0.001 ( 0.008)	Loss 2.4982e-01 (2.5856e-01)	Acc@1  94.53 ( 91.89)	Acc@5  99.22 ( 99.59)
Epoch: [67][ 30/391]	Time  0.035 ( 0.040)	Data  0.001 ( 0.006)	Loss 2.6633e-01 (2.5492e-01)	Acc@1  92.19 ( 92.04)	Acc@5  99.22 ( 99.67)
Epoch: [67][ 40/391]	Time  0.033 ( 0.038)	Data  0.001 ( 0.004)	Loss 2.8254e-01 (2.5123e-01)	Acc@1  90.62 ( 92.09)	Acc@5  99.22 ( 99.71)
Epoch: [67][ 50/391]	Time  0.034 ( 0.038)	Data  0.001 ( 0.004)	Loss 2.2875e-01 (2.4827e-01)	Acc@1  94.53 ( 92.25)	Acc@5 100.00 ( 99.69)
Epoch: [67][ 60/391]	Time  0.035 ( 0.037)	Data  0.001 ( 0.003)	Loss 2.6167e-01 (2.4504e-01)	Acc@1  86.72 ( 92.47)	Acc@5 100.00 ( 99.69)
Epoch: [67][ 70/391]	Time  0.033 ( 0.037)	Data  0.001 ( 0.003)	Loss 1.6501e-01 (2.4657e-01)	Acc@1  95.31 ( 92.42)	Acc@5 100.00 ( 99.71)
Epoch: [67][ 80/391]	Time  0.035 ( 0.037)	Data  0.001 ( 0.003)	Loss 2.8386e-01 (2.4673e-01)	Acc@1  93.75 ( 92.54)	Acc@5 100.00 ( 99.73)
Epoch: [67][ 90/391]	Time  0.033 ( 0.036)	Data  0.001 ( 0.003)	Loss 3.6851e-01 (2.5018e-01)	Acc@1  90.62 ( 92.49)	Acc@5  98.44 ( 99.67)
Epoch: [67][100/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.002)	Loss 2.4777e-01 (2.4839e-01)	Acc@1  92.19 ( 92.65)	Acc@5 100.00 ( 99.68)
Epoch: [67][110/391]	Time  0.033 ( 0.036)	Data  0.001 ( 0.002)	Loss 1.9468e-01 (2.4774e-01)	Acc@1  95.31 ( 92.60)	Acc@5 100.00 ( 99.68)
Epoch: [67][120/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.002)	Loss 2.1560e-01 (2.4816e-01)	Acc@1  95.31 ( 92.55)	Acc@5 100.00 ( 99.65)
Epoch: [67][130/391]	Time  0.035 ( 0.036)	Data  0.001 ( 0.002)	Loss 2.7216e-01 (2.4700e-01)	Acc@1  92.97 ( 92.58)	Acc@5 100.00 ( 99.66)
Epoch: [67][140/391]	Time  0.037 ( 0.036)	Data  0.001 ( 0.002)	Loss 2.3063e-01 (2.4563e-01)	Acc@1  93.75 ( 92.63)	Acc@5  97.66 ( 99.66)
Epoch: [67][150/391]	Time  0.034 ( 0.035)	Data  0.001 ( 0.002)	Loss 1.7898e-01 (2.4529e-01)	Acc@1  96.88 ( 92.64)	Acc@5 100.00 ( 99.67)
Epoch: [67][160/391]	Time  0.035 ( 0.035)	Data  0.001 ( 0.002)	Loss 2.4174e-01 (2.4478e-01)	Acc@1  94.53 ( 92.66)	Acc@5  99.22 ( 99.67)
Epoch: [67][170/391]	Time  0.037 ( 0.035)	Data  0.001 ( 0.002)	Loss 2.4278e-01 (2.4555e-01)	Acc@1  92.19 ( 92.63)	Acc@5  99.22 ( 99.67)
Epoch: [67][180/391]	Time  0.033 ( 0.035)	Data  0.001 ( 0.002)	Loss 2.2383e-01 (2.4696e-01)	Acc@1  92.97 ( 92.60)	Acc@5 100.00 ( 99.65)
Epoch: [67][190/391]	Time  0.037 ( 0.035)	Data  0.001 ( 0.002)	Loss 2.7366e-01 (2.4827e-01)	Acc@1  91.41 ( 92.57)	Acc@5 100.00 ( 99.65)
Epoch: [67][200/391]	Time  0.034 ( 0.035)	Data  0.001 ( 0.002)	Loss 1.8253e-01 (2.4848e-01)	Acc@1  93.75 ( 92.53)	Acc@5 100.00 ( 99.66)
Epoch: [67][210/391]	Time  0.034 ( 0.035)	Data  0.001 ( 0.002)	Loss 3.1115e-01 (2.4963e-01)	Acc@1  92.19 ( 92.48)	Acc@5  97.66 ( 99.64)
Epoch: [67][220/391]	Time  0.033 ( 0.035)	Data  0.001 ( 0.002)	Loss 3.1270e-01 (2.5075e-01)	Acc@1  90.62 ( 92.42)	Acc@5  98.44 ( 99.64)
Epoch: [67][230/391]	Time  0.035 ( 0.035)	Data  0.001 ( 0.002)	Loss 2.4252e-01 (2.4987e-01)	Acc@1  90.62 ( 92.45)	Acc@5 100.00 ( 99.64)
Epoch: [67][240/391]	Time  0.034 ( 0.035)	Data  0.001 ( 0.002)	Loss 1.8976e-01 (2.5154e-01)	Acc@1  94.53 ( 92.39)	Acc@5 100.00 ( 99.62)
Epoch: [67][250/391]	Time  0.033 ( 0.035)	Data  0.001 ( 0.002)	Loss 2.3215e-01 (2.5173e-01)	Acc@1  93.75 ( 92.42)	Acc@5  99.22 ( 99.61)
Epoch: [67][260/391]	Time  0.033 ( 0.035)	Data  0.001 ( 0.001)	Loss 2.1594e-01 (2.5107e-01)	Acc@1  95.31 ( 92.45)	Acc@5 100.00 ( 99.61)
Epoch: [67][270/391]	Time  0.033 ( 0.035)	Data  0.001 ( 0.001)	Loss 1.8897e-01 (2.5039e-01)	Acc@1  95.31 ( 92.47)	Acc@5 100.00 ( 99.62)
Epoch: [67][280/391]	Time  0.033 ( 0.035)	Data  0.001 ( 0.001)	Loss 1.8078e-01 (2.4929e-01)	Acc@1  92.97 ( 92.50)	Acc@5 100.00 ( 99.62)
Epoch: [67][290/391]	Time  0.033 ( 0.035)	Data  0.001 ( 0.001)	Loss 1.7560e-01 (2.4854e-01)	Acc@1  95.31 ( 92.52)	Acc@5 100.00 ( 99.63)
Epoch: [67][300/391]	Time  0.035 ( 0.035)	Data  0.001 ( 0.001)	Loss 3.0839e-01 (2.4917e-01)	Acc@1  87.50 ( 92.51)	Acc@5  99.22 ( 99.62)
Epoch: [67][310/391]	Time  0.034 ( 0.035)	Data  0.001 ( 0.001)	Loss 2.0373e-01 (2.4865e-01)	Acc@1  95.31 ( 92.53)	Acc@5  99.22 ( 99.61)
Epoch: [67][320/391]	Time  0.034 ( 0.035)	Data  0.001 ( 0.001)	Loss 2.5728e-01 (2.4967e-01)	Acc@1  92.97 ( 92.49)	Acc@5  99.22 ( 99.61)
Epoch: [67][330/391]	Time  0.035 ( 0.035)	Data  0.001 ( 0.001)	Loss 2.6172e-01 (2.4979e-01)	Acc@1  92.19 ( 92.49)	Acc@5  99.22 ( 99.60)
Epoch: [67][340/391]	Time  0.033 ( 0.035)	Data  0.001 ( 0.001)	Loss 1.6637e-01 (2.4994e-01)	Acc@1  95.31 ( 92.49)	Acc@5 100.00 ( 99.60)
Epoch: [67][350/391]	Time  0.034 ( 0.035)	Data  0.001 ( 0.001)	Loss 1.8590e-01 (2.4987e-01)	Acc@1  93.75 ( 92.47)	Acc@5 100.00 ( 99.61)
Epoch: [67][360/391]	Time  0.034 ( 0.035)	Data  0.001 ( 0.001)	Loss 3.0611e-01 (2.5030e-01)	Acc@1  89.06 ( 92.46)	Acc@5 100.00 ( 99.61)
Epoch: [67][370/391]	Time  0.036 ( 0.035)	Data  0.001 ( 0.001)	Loss 3.2308e-01 (2.5087e-01)	Acc@1  87.50 ( 92.42)	Acc@5 100.00 ( 99.61)
Epoch: [67][380/391]	Time  0.036 ( 0.035)	Data  0.001 ( 0.001)	Loss 3.1009e-01 (2.5148e-01)	Acc@1  92.97 ( 92.39)	Acc@5  98.44 ( 99.60)
Epoch: [67][390/391]	Time  0.023 ( 0.035)	Data  0.001 ( 0.001)	Loss 2.9181e-01 (2.5143e-01)	Acc@1  91.25 ( 92.38)	Acc@5  98.75 ( 99.60)
## e[67] optimizer.zero_grad (sum) time: 0.13852691650390625
## e[67]       loss.backward (sum) time: 3.1139469146728516
## e[67]      optimizer.step (sum) time: 0.9563503265380859
## epoch[67] training(only) time: 13.679773569107056
# Switched to evaluate mode...
Test: [  0/100]	Time  0.153 ( 0.153)	Loss 1.2979e+00 (1.2979e+00)	Acc@1  69.00 ( 69.00)	Acc@5  91.00 ( 91.00)
Test: [ 10/100]	Time  0.025 ( 0.034)	Loss 1.4420e+00 (1.4494e+00)	Acc@1  67.00 ( 68.73)	Acc@5  90.00 ( 89.27)
Test: [ 20/100]	Time  0.026 ( 0.029)	Loss 1.2437e+00 (1.4108e+00)	Acc@1  75.00 ( 68.95)	Acc@5  93.00 ( 90.33)
Test: [ 30/100]	Time  0.018 ( 0.026)	Loss 1.7809e+00 (1.4426e+00)	Acc@1  58.00 ( 67.74)	Acc@5  90.00 ( 90.13)
Test: [ 40/100]	Time  0.022 ( 0.025)	Loss 1.4719e+00 (1.4417e+00)	Acc@1  70.00 ( 67.90)	Acc@5  91.00 ( 90.27)
Test: [ 50/100]	Time  0.024 ( 0.025)	Loss 1.4664e+00 (1.4476e+00)	Acc@1  68.00 ( 67.84)	Acc@5  93.00 ( 90.14)
Test: [ 60/100]	Time  0.018 ( 0.024)	Loss 1.6237e+00 (1.4270e+00)	Acc@1  63.00 ( 67.90)	Acc@5  84.00 ( 90.49)
Test: [ 70/100]	Time  0.018 ( 0.023)	Loss 1.6498e+00 (1.4297e+00)	Acc@1  68.00 ( 67.89)	Acc@5  90.00 ( 90.54)
Test: [ 80/100]	Time  0.018 ( 0.023)	Loss 1.5995e+00 (1.4360e+00)	Acc@1  73.00 ( 67.90)	Acc@5  87.00 ( 90.52)
Test: [ 90/100]	Time  0.024 ( 0.023)	Loss 1.6957e+00 (1.4220e+00)	Acc@1  63.00 ( 68.08)	Acc@5  89.00 ( 90.64)
 * Acc@1 68.310 Acc@5 90.750
### epoch[67] execution time: 16.018884658813477
EPOCH 68
REMOVING: module.fire6.squeeze.1.bias
REMOVING: module.fire6.expand_1x1.0.weight
i:   0, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.001078474111421939   to: 0.001002490326204652
i:   1, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.001143781733666065   to: 0.001022645583294645
i:   2, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.001227868349964883   to: 0.001062595613413458
i:   3, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.001330214347322949   to: 0.001121816985860202
i:   4, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.001450305722326721   to: 0.001199791004779271
i:   5, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.001587634374263829   to: 0.001296004058538429
i:   6, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.001741698372257676   to: 0.001409947940826300
i:   7, name:  module.fire7.squeeze.0.weight  changing lr from: 0.001912002197707645   to: 0.001541120144816326
i:   8, name:    module.fire7.squeeze.0.bias  changing lr from: 0.002098056963280664   to: 0.001689024131700772
i:   9, name:  module.fire7.squeeze.1.weight  changing lr from: 0.002299380609655914   to: 0.001853169574854984
i:  10, name:    module.fire7.squeeze.1.bias  changing lr from: 0.002515498081180883   to: 0.002033072580849182
i:  11, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.002745941481554459   to: 0.002228255888482599
i:  12, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.002990250210610356   to: 0.002438249046972750
i:  13, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.003247971083233430   to: 0.002662588574391349
i:  14, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.003518658431400523   to: 0.002900818097397694
i:  15, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.003801874190298492   to: 0.003152488473280523
i:  16, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.004097187969433141   to: 0.003417157895280114
i:  17, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.004404177109605488   to: 0.003694391982124361
i:  18, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.004722426726594813   to: 0.003983763852674870
i:  19, name:  module.fire8.squeeze.0.weight  changing lr from: 0.005051529742352678   to: 0.004284854186542857
i:  20, name:    module.fire8.squeeze.0.bias  changing lr from: 0.005391086904477016   to: 0.004597251271499092
i:  21, name:  module.fire8.squeeze.1.weight  changing lr from: 0.005740706794702343   to: 0.004920551038467224
i:  22, name:    module.fire8.squeeze.1.bias  changing lr from: 0.006100005827108983   to: 0.005254357084856664
i:  23, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.006468608236722655   to: 0.005598280686957773
i:  24, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.006846146059145857   to: 0.005951940802091265
i:  25, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.007232259101831650   to: 0.006314964061172095
i:  26, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.007626594907583211   to: 0.006686984752319019
i:  27, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.008028808710833640   to: 0.007067644796111505
i:  28, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.008438563387235004   to: 0.007456593713068654
i:  29, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.008855529397058887   to: 0.007853488583896718
i:  30, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.009279384722886714   to: 0.008257994003027014
i:  31, name:  module.fire9.squeeze.0.weight  changing lr from: 0.009709814802043925   to: 0.008669782025939959
i:  32, name:    module.fire9.squeeze.0.bias  changing lr from: 0.010146512454209142   to: 0.009088532110747293
i:  33, name:  module.fire9.squeeze.1.weight  changing lr from: 0.010589177804607431   to: 0.009513931054481145
i:  34, name:    module.fire9.squeeze.1.bias  changing lr from: 0.011037518203175788   to: 0.009945672924516091
i:  35, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.011491248140068366   to: 0.010383458985528993
i:  36, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.011950089157849286   to: 0.010826997622380180
i:  37, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.012413769760702915   to: 0.011276004259280409
i:  38, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.012882025320972205   to: 0.011730201275587986
i:  39, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.013354597983320071   to: 0.012189317918562780
i:  40, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.013831236566790944   to: 0.012653090213386082
i:  41, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.014311696465034395   to: 0.013121260870737794
i:  42, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.014795739544938225   to: 0.013593579192207467
i:  43, name:           module.conv10.weight  changing lr from: 0.015283134043902698   to: 0.014069800973798841
i:  44, name:             module.conv10.bias  changing lr from: 0.015773654465975163   to: 0.014549688407773903



# Switched to train mode...
Epoch: [68][  0/391]	Time  0.197 ( 0.197)	Data  0.158 ( 0.158)	Loss 2.3595e-01 (2.3595e-01)	Acc@1  92.97 ( 92.97)	Acc@5 100.00 (100.00)
Epoch: [68][ 10/391]	Time  0.034 ( 0.049)	Data  0.001 ( 0.015)	Loss 2.3390e-01 (2.5506e-01)	Acc@1  92.19 ( 92.05)	Acc@5 100.00 ( 99.36)
Epoch: [68][ 20/391]	Time  0.035 ( 0.042)	Data  0.001 ( 0.008)	Loss 2.5222e-01 (2.4769e-01)	Acc@1  92.19 ( 92.37)	Acc@5 100.00 ( 99.48)
Epoch: [68][ 30/391]	Time  0.035 ( 0.039)	Data  0.001 ( 0.006)	Loss 1.8360e-01 (2.4228e-01)	Acc@1  95.31 ( 92.52)	Acc@5 100.00 ( 99.57)
Epoch: [68][ 40/391]	Time  0.033 ( 0.038)	Data  0.001 ( 0.005)	Loss 1.8479e-01 (2.3928e-01)	Acc@1  95.31 ( 92.68)	Acc@5 100.00 ( 99.60)
Epoch: [68][ 50/391]	Time  0.035 ( 0.037)	Data  0.001 ( 0.004)	Loss 2.4106e-01 (2.3383e-01)	Acc@1  96.09 ( 93.03)	Acc@5 100.00 ( 99.65)
Epoch: [68][ 60/391]	Time  0.034 ( 0.037)	Data  0.001 ( 0.004)	Loss 2.6281e-01 (2.3612e-01)	Acc@1  89.84 ( 92.89)	Acc@5 100.00 ( 99.64)
Epoch: [68][ 70/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.003)	Loss 2.0093e-01 (2.3395e-01)	Acc@1  92.97 ( 92.89)	Acc@5 100.00 ( 99.65)
Epoch: [68][ 80/391]	Time  0.033 ( 0.036)	Data  0.001 ( 0.003)	Loss 2.0787e-01 (2.3871e-01)	Acc@1  92.97 ( 92.72)	Acc@5 100.00 ( 99.66)
Epoch: [68][ 90/391]	Time  0.033 ( 0.036)	Data  0.001 ( 0.003)	Loss 2.2583e-01 (2.4064e-01)	Acc@1  92.19 ( 92.71)	Acc@5  99.22 ( 99.61)
Epoch: [68][100/391]	Time  0.033 ( 0.036)	Data  0.001 ( 0.003)	Loss 2.4689e-01 (2.4158e-01)	Acc@1  92.97 ( 92.68)	Acc@5  99.22 ( 99.61)
Epoch: [68][110/391]	Time  0.033 ( 0.036)	Data  0.001 ( 0.002)	Loss 2.4221e-01 (2.4092e-01)	Acc@1  89.84 ( 92.71)	Acc@5 100.00 ( 99.62)
Epoch: [68][120/391]	Time  0.033 ( 0.035)	Data  0.001 ( 0.002)	Loss 1.5725e-01 (2.4329e-01)	Acc@1  96.09 ( 92.65)	Acc@5 100.00 ( 99.64)
Epoch: [68][130/391]	Time  0.033 ( 0.035)	Data  0.001 ( 0.002)	Loss 2.3396e-01 (2.4371e-01)	Acc@1  91.41 ( 92.67)	Acc@5 100.00 ( 99.65)
Epoch: [68][140/391]	Time  0.037 ( 0.035)	Data  0.001 ( 0.002)	Loss 2.6559e-01 (2.4378e-01)	Acc@1  92.97 ( 92.65)	Acc@5 100.00 ( 99.65)
Epoch: [68][150/391]	Time  0.034 ( 0.035)	Data  0.001 ( 0.002)	Loss 3.1628e-01 (2.4488e-01)	Acc@1  89.84 ( 92.63)	Acc@5  99.22 ( 99.65)
Epoch: [68][160/391]	Time  0.034 ( 0.035)	Data  0.001 ( 0.002)	Loss 2.1492e-01 (2.4464e-01)	Acc@1  93.75 ( 92.64)	Acc@5 100.00 ( 99.64)
Epoch: [68][170/391]	Time  0.036 ( 0.035)	Data  0.001 ( 0.002)	Loss 2.0463e-01 (2.4470e-01)	Acc@1  92.97 ( 92.64)	Acc@5 100.00 ( 99.64)
Epoch: [68][180/391]	Time  0.035 ( 0.035)	Data  0.001 ( 0.002)	Loss 1.8854e-01 (2.4514e-01)	Acc@1  92.19 ( 92.61)	Acc@5 100.00 ( 99.63)
Epoch: [68][190/391]	Time  0.033 ( 0.035)	Data  0.001 ( 0.002)	Loss 2.1942e-01 (2.4532e-01)	Acc@1  89.84 ( 92.59)	Acc@5 100.00 ( 99.64)
Epoch: [68][200/391]	Time  0.033 ( 0.035)	Data  0.001 ( 0.002)	Loss 2.5070e-01 (2.4632e-01)	Acc@1  92.97 ( 92.59)	Acc@5 100.00 ( 99.63)
Epoch: [68][210/391]	Time  0.039 ( 0.035)	Data  0.001 ( 0.002)	Loss 3.1958e-01 (2.4705e-01)	Acc@1  88.28 ( 92.56)	Acc@5 100.00 ( 99.63)
Epoch: [68][220/391]	Time  0.035 ( 0.035)	Data  0.001 ( 0.002)	Loss 2.1363e-01 (2.4709e-01)	Acc@1  94.53 ( 92.56)	Acc@5 100.00 ( 99.62)
Epoch: [68][230/391]	Time  0.045 ( 0.035)	Data  0.002 ( 0.002)	Loss 3.0130e-01 (2.4828e-01)	Acc@1  92.97 ( 92.53)	Acc@5  99.22 ( 99.62)
Epoch: [68][240/391]	Time  0.034 ( 0.035)	Data  0.001 ( 0.002)	Loss 2.7428e-01 (2.4895e-01)	Acc@1  88.28 ( 92.48)	Acc@5 100.00 ( 99.62)
Epoch: [68][250/391]	Time  0.034 ( 0.035)	Data  0.001 ( 0.002)	Loss 2.8782e-01 (2.5016e-01)	Acc@1  90.62 ( 92.42)	Acc@5 100.00 ( 99.61)
Epoch: [68][260/391]	Time  0.032 ( 0.035)	Data  0.001 ( 0.002)	Loss 2.8550e-01 (2.5055e-01)	Acc@1  89.84 ( 92.41)	Acc@5 100.00 ( 99.62)
Epoch: [68][270/391]	Time  0.035 ( 0.035)	Data  0.001 ( 0.002)	Loss 2.8140e-01 (2.5010e-01)	Acc@1  92.19 ( 92.44)	Acc@5  99.22 ( 99.62)
Epoch: [68][280/391]	Time  0.033 ( 0.035)	Data  0.001 ( 0.002)	Loss 2.2272e-01 (2.5022e-01)	Acc@1  94.53 ( 92.45)	Acc@5 100.00 ( 99.62)
Epoch: [68][290/391]	Time  0.032 ( 0.035)	Data  0.001 ( 0.002)	Loss 3.6832e-01 (2.5052e-01)	Acc@1  89.84 ( 92.44)	Acc@5  98.44 ( 99.62)
Epoch: [68][300/391]	Time  0.034 ( 0.035)	Data  0.001 ( 0.002)	Loss 2.3793e-01 (2.4962e-01)	Acc@1  91.41 ( 92.46)	Acc@5 100.00 ( 99.63)
Epoch: [68][310/391]	Time  0.034 ( 0.035)	Data  0.001 ( 0.001)	Loss 2.2223e-01 (2.4870e-01)	Acc@1  90.62 ( 92.48)	Acc@5 100.00 ( 99.63)
Epoch: [68][320/391]	Time  0.036 ( 0.035)	Data  0.001 ( 0.001)	Loss 1.9752e-01 (2.4936e-01)	Acc@1  92.97 ( 92.46)	Acc@5 100.00 ( 99.63)
Epoch: [68][330/391]	Time  0.035 ( 0.035)	Data  0.001 ( 0.001)	Loss 2.3578e-01 (2.4937e-01)	Acc@1  92.19 ( 92.45)	Acc@5 100.00 ( 99.63)
Epoch: [68][340/391]	Time  0.035 ( 0.035)	Data  0.001 ( 0.001)	Loss 2.7638e-01 (2.4926e-01)	Acc@1  91.41 ( 92.46)	Acc@5 100.00 ( 99.63)
Epoch: [68][350/391]	Time  0.033 ( 0.034)	Data  0.001 ( 0.001)	Loss 2.9754e-01 (2.4928e-01)	Acc@1  90.62 ( 92.46)	Acc@5 100.00 ( 99.64)
Epoch: [68][360/391]	Time  0.033 ( 0.034)	Data  0.001 ( 0.001)	Loss 1.9515e-01 (2.4915e-01)	Acc@1  95.31 ( 92.49)	Acc@5  99.22 ( 99.64)
Epoch: [68][370/391]	Time  0.033 ( 0.035)	Data  0.001 ( 0.001)	Loss 3.2161e-01 (2.4946e-01)	Acc@1  91.41 ( 92.49)	Acc@5 100.00 ( 99.64)
Epoch: [68][380/391]	Time  0.033 ( 0.034)	Data  0.001 ( 0.001)	Loss 2.3998e-01 (2.4880e-01)	Acc@1  92.97 ( 92.52)	Acc@5 100.00 ( 99.64)
Epoch: [68][390/391]	Time  0.032 ( 0.034)	Data  0.001 ( 0.001)	Loss 1.8202e-01 (2.4887e-01)	Acc@1  93.75 ( 92.53)	Acc@5 100.00 ( 99.64)
## e[68] optimizer.zero_grad (sum) time: 0.1326885223388672
## e[68]       loss.backward (sum) time: 3.0171523094177246
## e[68]      optimizer.step (sum) time: 0.8972761631011963
## epoch[68] training(only) time: 13.538851022720337
# Switched to evaluate mode...
Test: [  0/100]	Time  0.153 ( 0.153)	Loss 1.2567e+00 (1.2567e+00)	Acc@1  72.00 ( 72.00)	Acc@5  90.00 ( 90.00)
Test: [ 10/100]	Time  0.023 ( 0.033)	Loss 1.4462e+00 (1.4453e+00)	Acc@1  70.00 ( 68.55)	Acc@5  91.00 ( 89.45)
Test: [ 20/100]	Time  0.021 ( 0.028)	Loss 1.2409e+00 (1.4107e+00)	Acc@1  76.00 ( 68.52)	Acc@5  92.00 ( 90.29)
Test: [ 30/100]	Time  0.020 ( 0.026)	Loss 1.6670e+00 (1.4431e+00)	Acc@1  62.00 ( 67.90)	Acc@5  90.00 ( 90.13)
Test: [ 40/100]	Time  0.021 ( 0.025)	Loss 1.4577e+00 (1.4418e+00)	Acc@1  69.00 ( 68.27)	Acc@5  90.00 ( 90.15)
Test: [ 50/100]	Time  0.024 ( 0.025)	Loss 1.5156e+00 (1.4516e+00)	Acc@1  66.00 ( 68.04)	Acc@5  91.00 ( 90.10)
Test: [ 60/100]	Time  0.024 ( 0.025)	Loss 1.6438e+00 (1.4289e+00)	Acc@1  63.00 ( 68.13)	Acc@5  86.00 ( 90.43)
Test: [ 70/100]	Time  0.023 ( 0.024)	Loss 1.6207e+00 (1.4294e+00)	Acc@1  67.00 ( 68.03)	Acc@5  88.00 ( 90.49)
Test: [ 80/100]	Time  0.023 ( 0.024)	Loss 1.5101e+00 (1.4351e+00)	Acc@1  73.00 ( 68.09)	Acc@5  91.00 ( 90.52)
Test: [ 90/100]	Time  0.024 ( 0.024)	Loss 1.7797e+00 (1.4222e+00)	Acc@1  64.00 ( 68.30)	Acc@5  87.00 ( 90.65)
 * Acc@1 68.560 Acc@5 90.760
### epoch[68] execution time: 15.999672412872314
EPOCH 69
REMOVING: module.fire6.expand_1x1.0.bias
REMOVING: module.fire6.expand_1x1.1.weight
i:   0, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.001062595613413458   to: 0.001000524293140708
i:   1, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.001121816985860202   to: 0.001015184389752537
i:   2, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.001199791004779271   to: 0.001049589231723873
i:   3, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.001296004058538429   to: 0.001103221757881677
i:   4, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.001409947940826300   to: 0.001175569450770008
i:   5, name:  module.fire7.squeeze.0.weight  changing lr from: 0.001541120144816326   to: 0.001266124685572772
i:   6, name:    module.fire7.squeeze.0.bias  changing lr from: 0.001689024131700772   to: 0.001374385051193626
i:   7, name:  module.fire7.squeeze.1.weight  changing lr from: 0.001853169574854984   to: 0.001499853644807097
i:   8, name:    module.fire7.squeeze.1.bias  changing lr from: 0.002033072580849182   to: 0.001642039341152828
i:   9, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.002228255888482599   to: 0.001800457037803431
i:  10, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.002438249046972750   to: 0.001974627877594603
i:  11, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.002662588574391349   to: 0.002164079449365563
i:  12, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.002900818097397694   to: 0.002368345968116891
i:  13, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.003152488473280523   to: 0.002586968435653413
i:  14, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.003417157895280114   to: 0.002819494782739933
i:  15, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.003694391982124361   to: 0.003065479993759567
i:  16, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.003983763852674870   to: 0.003324486214825933
i:  17, name:  module.fire8.squeeze.0.weight  changing lr from: 0.004284854186542857   to: 0.003596082846264120
i:  18, name:    module.fire8.squeeze.0.bias  changing lr from: 0.004597251271499092   to: 0.003879846620338300
i:  19, name:  module.fire8.squeeze.1.weight  changing lr from: 0.004920551038467224   to: 0.004175361665069271
i:  20, name:    module.fire8.squeeze.1.bias  changing lr from: 0.005254357084856664   to: 0.004482219554950062
i:  21, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.005598280686957773   to: 0.004800019349334366
i:  22, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.005951940802091265   to: 0.005128367619240109
i:  23, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.006314964061172095   to: 0.005466878463278023
i:  24, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.006686984752319019   to: 0.005815173513385090
i:  25, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.007067644796111505   to: 0.006172881931011880
i:  26, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.007456593713068654   to: 0.006539640394384671
i:  27, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.007853488583896718   to: 0.006915093077434381
i:  28, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.008257994003027014   to: 0.007298891620957792
i:  29, name:  module.fire9.squeeze.0.weight  changing lr from: 0.008669782025939959   to: 0.007690695096549859
i:  30, name:    module.fire9.squeeze.0.bias  changing lr from: 0.009088532110747293   to: 0.008090169963820731
i:  31, name:  module.fire9.squeeze.1.weight  changing lr from: 0.009513931054481145   to: 0.008496990021386645
i:  32, name:    module.fire9.squeeze.1.bias  changing lr from: 0.009945672924516091   to: 0.008910836352100077
i:  33, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.010383458985528993   to: 0.009331397262961987
i:  34, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.010826997622380180   to: 0.009758368220137009
i:  35, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.011276004259280409   to: 0.010191451779471204
i:  36, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.011730201275587986   to: 0.010630357512891903
i:  37, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.012189317918562780   to: 0.011074801931049670
i:  38, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.012653090213386082   to: 0.011524508402543522
i:  39, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.013121260870737794   to: 0.011979207070052546
i:  40, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.013593579192207467   to: 0.012438634763680196
i:  41, name:           module.conv10.weight  changing lr from: 0.014069800973798841   to: 0.012902534911800372
i:  42, name:             module.conv10.bias  changing lr from: 0.014549688407773903   to: 0.013370657449679146



# Switched to train mode...
Epoch: [69][  0/391]	Time  0.191 ( 0.191)	Data  0.152 ( 0.152)	Loss 2.5181e-01 (2.5181e-01)	Acc@1  93.75 ( 93.75)	Acc@5 100.00 (100.00)
Epoch: [69][ 10/391]	Time  0.033 ( 0.049)	Data  0.001 ( 0.015)	Loss 2.1694e-01 (2.1543e-01)	Acc@1  91.41 ( 94.18)	Acc@5 100.00 ( 99.64)
Epoch: [69][ 20/391]	Time  0.035 ( 0.042)	Data  0.001 ( 0.008)	Loss 2.0583e-01 (2.1880e-01)	Acc@1  95.31 ( 93.82)	Acc@5  99.22 ( 99.70)
Epoch: [69][ 30/391]	Time  0.033 ( 0.039)	Data  0.001 ( 0.006)	Loss 2.5093e-01 (2.2047e-01)	Acc@1  93.75 ( 93.75)	Acc@5 100.00 ( 99.77)
Epoch: [69][ 40/391]	Time  0.033 ( 0.038)	Data  0.001 ( 0.005)	Loss 2.6082e-01 (2.3228e-01)	Acc@1  92.97 ( 93.24)	Acc@5 100.00 ( 99.73)
Epoch: [69][ 50/391]	Time  0.033 ( 0.037)	Data  0.001 ( 0.004)	Loss 2.8748e-01 (2.3789e-01)	Acc@1  89.06 ( 92.98)	Acc@5 100.00 ( 99.75)
Epoch: [69][ 60/391]	Time  0.034 ( 0.037)	Data  0.001 ( 0.003)	Loss 3.5147e-01 (2.3635e-01)	Acc@1  90.62 ( 93.11)	Acc@5  99.22 ( 99.73)
Epoch: [69][ 70/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.003)	Loss 1.3867e-01 (2.3777e-01)	Acc@1  96.09 ( 93.08)	Acc@5 100.00 ( 99.72)
Epoch: [69][ 80/391]	Time  0.032 ( 0.036)	Data  0.001 ( 0.003)	Loss 1.4924e-01 (2.3795e-01)	Acc@1  97.66 ( 93.10)	Acc@5 100.00 ( 99.64)
Epoch: [69][ 90/391]	Time  0.033 ( 0.036)	Data  0.001 ( 0.003)	Loss 2.8980e-01 (2.3921e-01)	Acc@1  90.62 ( 93.07)	Acc@5  98.44 ( 99.61)
Epoch: [69][100/391]	Time  0.033 ( 0.036)	Data  0.001 ( 0.002)	Loss 2.2876e-01 (2.3758e-01)	Acc@1  92.19 ( 93.08)	Acc@5 100.00 ( 99.65)
Epoch: [69][110/391]	Time  0.035 ( 0.036)	Data  0.001 ( 0.002)	Loss 3.2475e-01 (2.3837e-01)	Acc@1  91.41 ( 92.96)	Acc@5  99.22 ( 99.66)
Epoch: [69][120/391]	Time  0.033 ( 0.035)	Data  0.001 ( 0.002)	Loss 2.6092e-01 (2.3808e-01)	Acc@1  89.06 ( 92.93)	Acc@5  99.22 ( 99.65)
Epoch: [69][130/391]	Time  0.033 ( 0.035)	Data  0.001 ( 0.002)	Loss 2.7366e-01 (2.3615e-01)	Acc@1  90.62 ( 92.99)	Acc@5 100.00 ( 99.67)
Epoch: [69][140/391]	Time  0.034 ( 0.035)	Data  0.001 ( 0.002)	Loss 3.0312e-01 (2.3601e-01)	Acc@1  89.06 ( 92.99)	Acc@5  98.44 ( 99.66)
Epoch: [69][150/391]	Time  0.035 ( 0.035)	Data  0.001 ( 0.002)	Loss 2.5555e-01 (2.3722e-01)	Acc@1  92.97 ( 92.96)	Acc@5 100.00 ( 99.66)
Epoch: [69][160/391]	Time  0.032 ( 0.035)	Data  0.001 ( 0.002)	Loss 1.7320e-01 (2.3867e-01)	Acc@1  94.53 ( 92.93)	Acc@5 100.00 ( 99.65)
Epoch: [69][170/391]	Time  0.033 ( 0.035)	Data  0.001 ( 0.002)	Loss 1.7930e-01 (2.3897e-01)	Acc@1  94.53 ( 92.94)	Acc@5 100.00 ( 99.64)
Epoch: [69][180/391]	Time  0.033 ( 0.035)	Data  0.001 ( 0.002)	Loss 3.0648e-01 (2.3988e-01)	Acc@1  92.97 ( 92.91)	Acc@5 100.00 ( 99.64)
Epoch: [69][190/391]	Time  0.034 ( 0.035)	Data  0.001 ( 0.002)	Loss 1.9543e-01 (2.3939e-01)	Acc@1  92.97 ( 92.93)	Acc@5 100.00 ( 99.65)
Epoch: [69][200/391]	Time  0.034 ( 0.035)	Data  0.001 ( 0.002)	Loss 2.2123e-01 (2.3803e-01)	Acc@1  93.75 ( 92.96)	Acc@5 100.00 ( 99.65)
Epoch: [69][210/391]	Time  0.033 ( 0.035)	Data  0.001 ( 0.002)	Loss 1.9346e-01 (2.3696e-01)	Acc@1  94.53 ( 92.98)	Acc@5 100.00 ( 99.67)
Epoch: [69][220/391]	Time  0.033 ( 0.035)	Data  0.001 ( 0.002)	Loss 2.4621e-01 (2.3758e-01)	Acc@1  91.41 ( 92.93)	Acc@5 100.00 ( 99.66)
Epoch: [69][230/391]	Time  0.035 ( 0.035)	Data  0.001 ( 0.002)	Loss 1.7936e-01 (2.3758e-01)	Acc@1  98.44 ( 92.95)	Acc@5 100.00 ( 99.65)
Epoch: [69][240/391]	Time  0.035 ( 0.035)	Data  0.001 ( 0.002)	Loss 2.1895e-01 (2.3782e-01)	Acc@1  92.19 ( 92.95)	Acc@5  99.22 ( 99.65)
Epoch: [69][250/391]	Time  0.033 ( 0.035)	Data  0.001 ( 0.002)	Loss 2.1310e-01 (2.3720e-01)	Acc@1  92.97 ( 92.95)	Acc@5  98.44 ( 99.65)
Epoch: [69][260/391]	Time  0.032 ( 0.035)	Data  0.001 ( 0.002)	Loss 2.0120e-01 (2.3736e-01)	Acc@1  93.75 ( 92.96)	Acc@5  99.22 ( 99.65)
Epoch: [69][270/391]	Time  0.035 ( 0.035)	Data  0.001 ( 0.002)	Loss 3.7430e-01 (2.3862e-01)	Acc@1  86.72 ( 92.88)	Acc@5 100.00 ( 99.64)
Epoch: [69][280/391]	Time  0.034 ( 0.035)	Data  0.001 ( 0.002)	Loss 3.3455e-01 (2.3897e-01)	Acc@1  92.19 ( 92.87)	Acc@5  99.22 ( 99.64)
Epoch: [69][290/391]	Time  0.034 ( 0.035)	Data  0.001 ( 0.001)	Loss 3.6364e-01 (2.3930e-01)	Acc@1  86.72 ( 92.86)	Acc@5  97.66 ( 99.63)
Epoch: [69][300/391]	Time  0.034 ( 0.035)	Data  0.001 ( 0.001)	Loss 1.9669e-01 (2.3900e-01)	Acc@1  94.53 ( 92.88)	Acc@5  99.22 ( 99.62)
Epoch: [69][310/391]	Time  0.038 ( 0.035)	Data  0.005 ( 0.001)	Loss 2.8462e-01 (2.3890e-01)	Acc@1  92.19 ( 92.89)	Acc@5  99.22 ( 99.62)
Epoch: [69][320/391]	Time  0.034 ( 0.035)	Data  0.001 ( 0.001)	Loss 2.1747e-01 (2.3909e-01)	Acc@1  95.31 ( 92.88)	Acc@5 100.00 ( 99.63)
Epoch: [69][330/391]	Time  0.036 ( 0.035)	Data  0.001 ( 0.001)	Loss 2.9117e-01 (2.3961e-01)	Acc@1  93.75 ( 92.88)	Acc@5  99.22 ( 99.62)
Epoch: [69][340/391]	Time  0.033 ( 0.034)	Data  0.001 ( 0.001)	Loss 2.5108e-01 (2.3950e-01)	Acc@1  89.84 ( 92.89)	Acc@5 100.00 ( 99.62)
Epoch: [69][350/391]	Time  0.034 ( 0.034)	Data  0.001 ( 0.001)	Loss 2.1913e-01 (2.3984e-01)	Acc@1  92.19 ( 92.89)	Acc@5 100.00 ( 99.62)
Epoch: [69][360/391]	Time  0.033 ( 0.034)	Data  0.001 ( 0.001)	Loss 2.7768e-01 (2.3976e-01)	Acc@1  91.41 ( 92.89)	Acc@5 100.00 ( 99.63)
Epoch: [69][370/391]	Time  0.038 ( 0.034)	Data  0.001 ( 0.001)	Loss 2.7335e-01 (2.3998e-01)	Acc@1  89.84 ( 92.90)	Acc@5 100.00 ( 99.63)
Epoch: [69][380/391]	Time  0.033 ( 0.034)	Data  0.001 ( 0.001)	Loss 2.4404e-01 (2.3958e-01)	Acc@1  91.41 ( 92.91)	Acc@5 100.00 ( 99.64)
Epoch: [69][390/391]	Time  0.024 ( 0.034)	Data  0.001 ( 0.001)	Loss 3.5070e-01 (2.3976e-01)	Acc@1  93.75 ( 92.92)	Acc@5 100.00 ( 99.64)
## e[69] optimizer.zero_grad (sum) time: 0.12659525871276855
## e[69]       loss.backward (sum) time: 2.9766550064086914
## e[69]      optimizer.step (sum) time: 0.8726322650909424
## epoch[69] training(only) time: 13.519476413726807
# Switched to evaluate mode...
Test: [  0/100]	Time  0.150 ( 0.150)	Loss 1.3054e+00 (1.3054e+00)	Acc@1  70.00 ( 70.00)	Acc@5  88.00 ( 88.00)
Test: [ 10/100]	Time  0.021 ( 0.034)	Loss 1.4619e+00 (1.4638e+00)	Acc@1  61.00 ( 68.09)	Acc@5  91.00 ( 89.00)
Test: [ 20/100]	Time  0.023 ( 0.029)	Loss 1.2478e+00 (1.4187e+00)	Acc@1  75.00 ( 69.10)	Acc@5  92.00 ( 89.81)
Test: [ 30/100]	Time  0.024 ( 0.027)	Loss 1.7708e+00 (1.4473e+00)	Acc@1  61.00 ( 68.16)	Acc@5  90.00 ( 89.84)
Test: [ 40/100]	Time  0.022 ( 0.026)	Loss 1.4107e+00 (1.4480e+00)	Acc@1  68.00 ( 68.20)	Acc@5  93.00 ( 89.98)
Test: [ 50/100]	Time  0.024 ( 0.025)	Loss 1.4635e+00 (1.4561e+00)	Acc@1  67.00 ( 67.76)	Acc@5  91.00 ( 89.88)
Test: [ 60/100]	Time  0.024 ( 0.025)	Loss 1.6329e+00 (1.4373e+00)	Acc@1  62.00 ( 67.89)	Acc@5  89.00 ( 90.30)
Test: [ 70/100]	Time  0.024 ( 0.025)	Loss 1.6890e+00 (1.4404e+00)	Acc@1  70.00 ( 67.87)	Acc@5  88.00 ( 90.32)
Test: [ 80/100]	Time  0.024 ( 0.025)	Loss 1.4909e+00 (1.4452e+00)	Acc@1  70.00 ( 67.95)	Acc@5  90.00 ( 90.35)
Test: [ 90/100]	Time  0.024 ( 0.025)	Loss 1.7136e+00 (1.4317e+00)	Acc@1  64.00 ( 68.21)	Acc@5  89.00 ( 90.46)
 * Acc@1 68.530 Acc@5 90.580
### epoch[69] execution time: 16.00664186477661
EPOCH 70
REMOVING: module.fire6.expand_1x1.1.bias
REMOVING: module.fire6.expand_3x3.0.weight
REMOVING: module.fire6.expand_3x3.0.bias
i:   0, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.001103221757881677   to: 0.001009670864964517
i:   1, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.001175569450770008   to: 0.001039023113111897
i:   2, name:  module.fire7.squeeze.0.weight  changing lr from: 0.001266124685572772   to: 0.001087548957361666
i:   3, name:    module.fire7.squeeze.0.bias  changing lr from: 0.001374385051193626   to: 0.001154742020994247
i:   4, name:  module.fire7.squeeze.1.weight  changing lr from: 0.001499853644807097   to: 0.001240100641222196
i:   5, name:    module.fire7.squeeze.1.bias  changing lr from: 0.001642039341152828   to: 0.001343128189623249
i:   6, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.001800457037803431   to: 0.001463333366465174
i:   7, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.001974627877594603   to: 0.001600230470163127
i:   8, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.002164079449365563   to: 0.001753339643070189
i:   9, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.002368345968116891   to: 0.001922187094761551
i:  10, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.002586968435653413   to: 0.002106305303933475
i:  11, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.002819494782739933   to: 0.002305233199998751
i:  12, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.003065479993759567   to: 0.002518516325422137
i:  13, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.003324486214825933   to: 0.002745706979800721
i:  14, name:  module.fire8.squeeze.0.weight  changing lr from: 0.003596082846264120   to: 0.002986364346657399
i:  15, name:    module.fire8.squeeze.0.bias  changing lr from: 0.003879846620338300   to: 0.003240054603878377
i:  16, name:  module.fire8.squeeze.1.weight  changing lr from: 0.004175361665069271   to: 0.003506351018690340
i:  17, name:    module.fire8.squeeze.1.bias  changing lr from: 0.004482219554950062   to: 0.003784834028037264
i:  18, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.004800019349334366   to: 0.004075091305182654
i:  19, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.005128367619240109   to: 0.004376717813329905
i:  20, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.005466878463278023   to: 0.004689315847020197
i:  21, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.005815173513385090   to: 0.005012495062036043
i:  22, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.006172881931011880   to: 0.005345872494507608
i:  23, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.006539640394384671   to: 0.005689072569888814
i:  24, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.006915093077434381   to: 0.006041727102441241
i:  25, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.007298891620957792   to: 0.006403475285835530
i:  26, name:  module.fire9.squeeze.0.weight  changing lr from: 0.007690695096549859   to: 0.006773963675452826
i:  27, name:    module.fire9.squeeze.0.bias  changing lr from: 0.008090169963820731   to: 0.007152846162941911
i:  28, name:  module.fire9.squeeze.1.weight  changing lr from: 0.008496990021386645   to: 0.007539783943562744
i:  29, name:    module.fire9.squeeze.1.bias  changing lr from: 0.008910836352100077   to: 0.007934445476821751
i:  30, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.009331397262961987   to: 0.008336506440880707
i:  31, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.009758368220137009   to: 0.008745649681197931
i:  32, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.010191451779471204   to: 0.009161565153838373
i:  33, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.010630357512891903   to: 0.009583949863867430
i:  34, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.011074801931049670   to: 0.010012507799223296
i:  35, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.011524508402543522   to: 0.010446949860442489
i:  36, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.011979207070052546   to: 0.010886993786593736
i:  37, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.012438634763680196   to: 0.011332364077758138
i:  38, name:           module.conv10.weight  changing lr from: 0.012902534911800372   to: 0.011782791914374820
i:  39, name:             module.conv10.bias  changing lr from: 0.013370657449679146   to: 0.012238015073755000



# Switched to train mode...
Epoch: [70][  0/391]	Time  0.199 ( 0.199)	Data  0.161 ( 0.161)	Loss 2.8824e-01 (2.8824e-01)	Acc@1  91.41 ( 91.41)	Acc@5 100.00 (100.00)
Epoch: [70][ 10/391]	Time  0.033 ( 0.049)	Data  0.001 ( 0.016)	Loss 2.1769e-01 (2.3392e-01)	Acc@1  90.62 ( 92.61)	Acc@5 100.00 ( 99.86)
Epoch: [70][ 20/391]	Time  0.032 ( 0.042)	Data  0.001 ( 0.009)	Loss 2.2022e-01 (2.3439e-01)	Acc@1  92.97 ( 92.37)	Acc@5  99.22 ( 99.78)
Epoch: [70][ 30/391]	Time  0.032 ( 0.039)	Data  0.001 ( 0.006)	Loss 2.9581e-01 (2.3033e-01)	Acc@1  94.53 ( 92.89)	Acc@5  98.44 ( 99.77)
Epoch: [70][ 40/391]	Time  0.032 ( 0.038)	Data  0.001 ( 0.005)	Loss 2.5110e-01 (2.2849e-01)	Acc@1  92.19 ( 93.16)	Acc@5  99.22 ( 99.73)
Epoch: [70][ 50/391]	Time  0.036 ( 0.037)	Data  0.001 ( 0.004)	Loss 1.9588e-01 (2.2445e-01)	Acc@1  94.53 ( 93.31)	Acc@5 100.00 ( 99.75)
Epoch: [70][ 60/391]	Time  0.033 ( 0.036)	Data  0.001 ( 0.004)	Loss 2.1133e-01 (2.2595e-01)	Acc@1  93.75 ( 93.22)	Acc@5 100.00 ( 99.76)
Epoch: [70][ 70/391]	Time  0.033 ( 0.036)	Data  0.001 ( 0.003)	Loss 2.4719e-01 (2.2708e-01)	Acc@1  91.41 ( 93.28)	Acc@5 100.00 ( 99.71)
Epoch: [70][ 80/391]	Time  0.032 ( 0.035)	Data  0.001 ( 0.003)	Loss 2.1274e-01 (2.2720e-01)	Acc@1  93.75 ( 93.24)	Acc@5 100.00 ( 99.69)
Epoch: [70][ 90/391]	Time  0.032 ( 0.035)	Data  0.001 ( 0.003)	Loss 1.9477e-01 (2.3017e-01)	Acc@1  95.31 ( 93.12)	Acc@5 100.00 ( 99.68)
Epoch: [70][100/391]	Time  0.034 ( 0.035)	Data  0.001 ( 0.003)	Loss 1.4455e-01 (2.3022e-01)	Acc@1  96.09 ( 93.15)	Acc@5 100.00 ( 99.68)
Epoch: [70][110/391]	Time  0.043 ( 0.035)	Data  0.001 ( 0.002)	Loss 2.1104e-01 (2.2979e-01)	Acc@1  92.97 ( 93.21)	Acc@5 100.00 ( 99.67)
Epoch: [70][120/391]	Time  0.035 ( 0.035)	Data  0.001 ( 0.002)	Loss 2.0178e-01 (2.3039e-01)	Acc@1  96.09 ( 93.23)	Acc@5 100.00 ( 99.68)
Epoch: [70][130/391]	Time  0.032 ( 0.035)	Data  0.001 ( 0.002)	Loss 1.8432e-01 (2.3086e-01)	Acc@1  93.75 ( 93.21)	Acc@5 100.00 ( 99.70)
Epoch: [70][140/391]	Time  0.032 ( 0.034)	Data  0.001 ( 0.002)	Loss 2.7615e-01 (2.2979e-01)	Acc@1  92.19 ( 93.26)	Acc@5 100.00 ( 99.71)
Epoch: [70][150/391]	Time  0.038 ( 0.034)	Data  0.001 ( 0.002)	Loss 1.7678e-01 (2.2924e-01)	Acc@1  96.88 ( 93.29)	Acc@5  99.22 ( 99.72)
Epoch: [70][160/391]	Time  0.033 ( 0.034)	Data  0.001 ( 0.002)	Loss 1.6400e-01 (2.2968e-01)	Acc@1  95.31 ( 93.29)	Acc@5 100.00 ( 99.71)
Epoch: [70][170/391]	Time  0.032 ( 0.034)	Data  0.001 ( 0.002)	Loss 2.3940e-01 (2.2969e-01)	Acc@1  90.62 ( 93.20)	Acc@5 100.00 ( 99.73)
Epoch: [70][180/391]	Time  0.032 ( 0.034)	Data  0.001 ( 0.002)	Loss 2.3661e-01 (2.3094e-01)	Acc@1  92.97 ( 93.15)	Acc@5 100.00 ( 99.72)
Epoch: [70][190/391]	Time  0.035 ( 0.034)	Data  0.001 ( 0.002)	Loss 1.7790e-01 (2.3014e-01)	Acc@1  95.31 ( 93.20)	Acc@5 100.00 ( 99.71)
Epoch: [70][200/391]	Time  0.033 ( 0.034)	Data  0.001 ( 0.002)	Loss 2.1555e-01 (2.2969e-01)	Acc@1  96.09 ( 93.18)	Acc@5 100.00 ( 99.72)
Epoch: [70][210/391]	Time  0.032 ( 0.034)	Data  0.001 ( 0.002)	Loss 2.3744e-01 (2.3075e-01)	Acc@1  90.62 ( 93.09)	Acc@5  99.22 ( 99.71)
Epoch: [70][220/391]	Time  0.033 ( 0.034)	Data  0.001 ( 0.002)	Loss 1.9396e-01 (2.3166e-01)	Acc@1  93.75 ( 93.06)	Acc@5 100.00 ( 99.72)
Epoch: [70][230/391]	Time  0.032 ( 0.034)	Data  0.001 ( 0.002)	Loss 2.0527e-01 (2.3190e-01)	Acc@1  92.97 ( 93.07)	Acc@5 100.00 ( 99.73)
Epoch: [70][240/391]	Time  0.032 ( 0.034)	Data  0.001 ( 0.002)	Loss 2.5071e-01 (2.3224e-01)	Acc@1  92.97 ( 93.08)	Acc@5  99.22 ( 99.73)
Epoch: [70][250/391]	Time  0.033 ( 0.034)	Data  0.001 ( 0.002)	Loss 1.6295e-01 (2.3214e-01)	Acc@1  95.31 ( 93.05)	Acc@5 100.00 ( 99.73)
Epoch: [70][260/391]	Time  0.032 ( 0.034)	Data  0.001 ( 0.002)	Loss 2.4220e-01 (2.3259e-01)	Acc@1  92.19 ( 93.05)	Acc@5 100.00 ( 99.74)
Epoch: [70][270/391]	Time  0.033 ( 0.034)	Data  0.001 ( 0.002)	Loss 1.9433e-01 (2.3195e-01)	Acc@1  96.09 ( 93.08)	Acc@5 100.00 ( 99.73)
Epoch: [70][280/391]	Time  0.034 ( 0.034)	Data  0.001 ( 0.002)	Loss 2.1723e-01 (2.3213e-01)	Acc@1  91.41 ( 93.09)	Acc@5 100.00 ( 99.72)
Epoch: [70][290/391]	Time  0.032 ( 0.034)	Data  0.001 ( 0.002)	Loss 2.2913e-01 (2.3222e-01)	Acc@1  93.75 ( 93.09)	Acc@5 100.00 ( 99.72)
Epoch: [70][300/391]	Time  0.032 ( 0.034)	Data  0.001 ( 0.002)	Loss 1.9144e-01 (2.3293e-01)	Acc@1  95.31 ( 93.06)	Acc@5 100.00 ( 99.71)
Epoch: [70][310/391]	Time  0.035 ( 0.034)	Data  0.001 ( 0.002)	Loss 1.9819e-01 (2.3280e-01)	Acc@1  93.75 ( 93.07)	Acc@5 100.00 ( 99.71)
Epoch: [70][320/391]	Time  0.033 ( 0.034)	Data  0.001 ( 0.001)	Loss 3.3932e-01 (2.3337e-01)	Acc@1  91.41 ( 93.05)	Acc@5  99.22 ( 99.70)
Epoch: [70][330/391]	Time  0.032 ( 0.034)	Data  0.001 ( 0.001)	Loss 2.8803e-01 (2.3338e-01)	Acc@1  90.62 ( 93.04)	Acc@5 100.00 ( 99.71)
Epoch: [70][340/391]	Time  0.038 ( 0.034)	Data  0.001 ( 0.001)	Loss 2.9289e-01 (2.3383e-01)	Acc@1  91.41 ( 93.02)	Acc@5  99.22 ( 99.71)
Epoch: [70][350/391]	Time  0.034 ( 0.034)	Data  0.001 ( 0.001)	Loss 2.1285e-01 (2.3374e-01)	Acc@1  93.75 ( 93.02)	Acc@5 100.00 ( 99.71)
Epoch: [70][360/391]	Time  0.035 ( 0.034)	Data  0.001 ( 0.001)	Loss 2.1587e-01 (2.3385e-01)	Acc@1  93.75 ( 93.02)	Acc@5 100.00 ( 99.71)
Epoch: [70][370/391]	Time  0.034 ( 0.034)	Data  0.001 ( 0.001)	Loss 2.1310e-01 (2.3369e-01)	Acc@1  94.53 ( 93.03)	Acc@5  99.22 ( 99.70)
Epoch: [70][380/391]	Time  0.033 ( 0.034)	Data  0.001 ( 0.001)	Loss 3.1417e-01 (2.3440e-01)	Acc@1  92.19 ( 92.99)	Acc@5  99.22 ( 99.70)
Epoch: [70][390/391]	Time  0.023 ( 0.034)	Data  0.001 ( 0.001)	Loss 2.5941e-01 (2.3441e-01)	Acc@1  92.50 ( 92.98)	Acc@5 100.00 ( 99.70)
## e[70] optimizer.zero_grad (sum) time: 0.11818099021911621
## e[70]       loss.backward (sum) time: 2.9640984535217285
## e[70]      optimizer.step (sum) time: 0.8199188709259033
## epoch[70] training(only) time: 13.33468222618103
# Switched to evaluate mode...
Test: [  0/100]	Time  0.155 ( 0.155)	Loss 1.2751e+00 (1.2751e+00)	Acc@1  73.00 ( 73.00)	Acc@5  90.00 ( 90.00)
Test: [ 10/100]	Time  0.022 ( 0.034)	Loss 1.5036e+00 (1.4822e+00)	Acc@1  68.00 ( 68.18)	Acc@5  91.00 ( 89.00)
Test: [ 20/100]	Time  0.022 ( 0.029)	Loss 1.2235e+00 (1.4420e+00)	Acc@1  75.00 ( 68.81)	Acc@5  93.00 ( 89.95)
Test: [ 30/100]	Time  0.018 ( 0.026)	Loss 1.7608e+00 (1.4678e+00)	Acc@1  59.00 ( 67.65)	Acc@5  90.00 ( 90.03)
Test: [ 40/100]	Time  0.021 ( 0.025)	Loss 1.4582e+00 (1.4648e+00)	Acc@1  69.00 ( 67.76)	Acc@5  93.00 ( 90.07)
Test: [ 50/100]	Time  0.024 ( 0.024)	Loss 1.4947e+00 (1.4648e+00)	Acc@1  70.00 ( 67.73)	Acc@5  91.00 ( 90.10)
Test: [ 60/100]	Time  0.025 ( 0.024)	Loss 1.6557e+00 (1.4425e+00)	Acc@1  64.00 ( 68.00)	Acc@5  85.00 ( 90.48)
Test: [ 70/100]	Time  0.024 ( 0.024)	Loss 1.6609e+00 (1.4409e+00)	Acc@1  68.00 ( 67.93)	Acc@5  88.00 ( 90.54)
Test: [ 80/100]	Time  0.024 ( 0.024)	Loss 1.5736e+00 (1.4470e+00)	Acc@1  73.00 ( 67.90)	Acc@5  88.00 ( 90.41)
Test: [ 90/100]	Time  0.024 ( 0.024)	Loss 1.6853e+00 (1.4336e+00)	Acc@1  63.00 ( 68.09)	Acc@5  88.00 ( 90.56)
 * Acc@1 68.270 Acc@5 90.650
### epoch[70] execution time: 15.78369426727295
EPOCH 71
REMOVING: module.fire6.expand_3x3.1.weight
REMOVING: module.fire6.expand_3x3.1.bias
i:   0, name:  module.fire7.squeeze.0.weight  changing lr from: 0.001087548957361666   to: 0.001005739167342089
i:   1, name:    module.fire7.squeeze.0.bias  changing lr from: 0.001154742020994247   to: 0.001030515493733146
i:   2, name:  module.fire7.squeeze.1.weight  changing lr from: 0.001240100641222196   to: 0.001074401537419799
i:   3, name:    module.fire7.squeeze.1.bias  changing lr from: 0.001343128189623249   to: 0.001136897016397869
i:   4, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.001463333366465174   to: 0.001217506196283401
i:   5, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.001600230470163127   to: 0.001315738209514527
i:   6, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.001753339643070189   to: 0.001431107348879439
i:   7, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.001922187094761551   to: 0.001563133336580263
i:   8, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.002106305303933475   to: 0.001711341570004048
i:   9, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.002305233199998751   to: 0.001875263345333310
i:  10, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.002518516325422137   to: 0.002054436060090497
i:  11, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.002745706979800721   to: 0.002248403395672892
i:  12, name:  module.fire8.squeeze.0.weight  changing lr from: 0.002986364346657399   to: 0.002456715480897148
i:  13, name:    module.fire8.squeeze.0.bias  changing lr from: 0.003240054603878377   to: 0.002678929037535787
i:  14, name:  module.fire8.squeeze.1.weight  changing lr from: 0.003506351018690340   to: 0.002914607508792116
i:  15, name:    module.fire8.squeeze.1.bias  changing lr from: 0.003784834028037264   to: 0.003163321171624266
i:  16, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.004075091305182654   to: 0.003424647233794231
i:  17, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.004376717813329905   to: 0.003698169916484167
i:  18, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.004689315847020197   to: 0.003983480523288279
i:  19, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.005012495062036043   to: 0.004280177496356812
i:  20, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.005345872494507608   to: 0.004587866460436351
i:  21, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.005689072569888814   to: 0.004906160255520474
i:  22, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.006041727102441241   to: 0.005234678958794042
i:  23, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.006403475285835530   to: 0.005573049896525994
i:  24, name:  module.fire9.squeeze.0.weight  changing lr from: 0.006773963675452826   to: 0.005920907646536588
i:  25, name:    module.fire9.squeeze.0.bias  changing lr from: 0.007152846162941911   to: 0.006277894031837993
i:  26, name:  module.fire9.squeeze.1.weight  changing lr from: 0.007539783943562744   to: 0.006643658106020350
i:  27, name:    module.fire9.squeeze.1.bias  changing lr from: 0.007934445476821751   to: 0.007017856130929578
i:  28, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.008336506440880707   to: 0.007400151547158551
i:  29, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.008745649681197931   to: 0.007790214937848899
i:  30, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.009161565153838373   to: 0.008187723986277429
i:  31, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.009583949863867430   to: 0.008592363427679044
i:  32, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.010012507799223296   to: 0.009003824995735831
i:  33, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.010446949860442489   to: 0.009421807364141683
i:  34, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.010886993786593736   to: 0.009846016083630994
i:  35, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.011332364077758138   to: 0.010276163514841414
i:  36, name:           module.conv10.weight  changing lr from: 0.011782791914374820   to: 0.010711968757361395
i:  37, name:             module.conv10.bias  changing lr from: 0.012238015073755000   to: 0.011153157575295593



# Switched to train mode...
Epoch: [71][  0/391]	Time  0.192 ( 0.192)	Data  0.154 ( 0.154)	Loss 1.7586e-01 (1.7586e-01)	Acc@1  96.09 ( 96.09)	Acc@5 100.00 (100.00)
Epoch: [71][ 10/391]	Time  0.033 ( 0.048)	Data  0.002 ( 0.015)	Loss 2.8596e-01 (2.3391e-01)	Acc@1  90.62 ( 92.83)	Acc@5 100.00 ( 99.86)
Epoch: [71][ 20/391]	Time  0.032 ( 0.041)	Data  0.001 ( 0.008)	Loss 1.6539e-01 (2.2515e-01)	Acc@1  95.31 ( 93.38)	Acc@5 100.00 ( 99.74)
Epoch: [71][ 30/391]	Time  0.032 ( 0.038)	Data  0.001 ( 0.006)	Loss 1.1895e-01 (2.1840e-01)	Acc@1  97.66 ( 93.70)	Acc@5 100.00 ( 99.72)
Epoch: [71][ 40/391]	Time  0.032 ( 0.037)	Data  0.001 ( 0.005)	Loss 2.5478e-01 (2.1740e-01)	Acc@1  92.97 ( 93.77)	Acc@5  99.22 ( 99.73)
Epoch: [71][ 50/391]	Time  0.032 ( 0.036)	Data  0.001 ( 0.004)	Loss 1.9400e-01 (2.1884e-01)	Acc@1  96.09 ( 93.57)	Acc@5 100.00 ( 99.75)
Epoch: [71][ 60/391]	Time  0.032 ( 0.035)	Data  0.001 ( 0.003)	Loss 2.7881e-01 (2.1948e-01)	Acc@1  91.41 ( 93.46)	Acc@5  99.22 ( 99.72)
Epoch: [71][ 70/391]	Time  0.032 ( 0.035)	Data  0.001 ( 0.003)	Loss 2.0586e-01 (2.2190e-01)	Acc@1  93.75 ( 93.40)	Acc@5  99.22 ( 99.68)
Epoch: [71][ 80/391]	Time  0.032 ( 0.034)	Data  0.001 ( 0.003)	Loss 2.5065e-01 (2.2175e-01)	Acc@1  90.62 ( 93.41)	Acc@5 100.00 ( 99.69)
Epoch: [71][ 90/391]	Time  0.032 ( 0.034)	Data  0.001 ( 0.003)	Loss 2.3014e-01 (2.2071e-01)	Acc@1  89.84 ( 93.46)	Acc@5 100.00 ( 99.72)
Epoch: [71][100/391]	Time  0.033 ( 0.034)	Data  0.001 ( 0.003)	Loss 2.0521e-01 (2.2249e-01)	Acc@1  94.53 ( 93.35)	Acc@5  99.22 ( 99.71)
Epoch: [71][110/391]	Time  0.032 ( 0.034)	Data  0.001 ( 0.002)	Loss 1.5836e-01 (2.2201e-01)	Acc@1  96.09 ( 93.36)	Acc@5 100.00 ( 99.71)
Epoch: [71][120/391]	Time  0.033 ( 0.034)	Data  0.001 ( 0.002)	Loss 2.4433e-01 (2.2186e-01)	Acc@1  92.97 ( 93.39)	Acc@5  99.22 ( 99.71)
Epoch: [71][130/391]	Time  0.032 ( 0.034)	Data  0.001 ( 0.002)	Loss 2.0160e-01 (2.2248e-01)	Acc@1  96.88 ( 93.40)	Acc@5  99.22 ( 99.70)
Epoch: [71][140/391]	Time  0.035 ( 0.034)	Data  0.001 ( 0.002)	Loss 2.8221e-01 (2.2168e-01)	Acc@1  89.06 ( 93.44)	Acc@5 100.00 ( 99.71)
Epoch: [71][150/391]	Time  0.032 ( 0.034)	Data  0.001 ( 0.002)	Loss 2.0634e-01 (2.2072e-01)	Acc@1  94.53 ( 93.50)	Acc@5 100.00 ( 99.73)
Epoch: [71][160/391]	Time  0.032 ( 0.034)	Data  0.001 ( 0.002)	Loss 2.3987e-01 (2.2110e-01)	Acc@1  94.53 ( 93.46)	Acc@5  98.44 ( 99.71)
Epoch: [71][170/391]	Time  0.032 ( 0.034)	Data  0.001 ( 0.002)	Loss 1.6646e-01 (2.2092e-01)	Acc@1  94.53 ( 93.49)	Acc@5 100.00 ( 99.71)
Epoch: [71][180/391]	Time  0.033 ( 0.034)	Data  0.001 ( 0.002)	Loss 2.3586e-01 (2.2251e-01)	Acc@1  96.09 ( 93.46)	Acc@5  99.22 ( 99.70)
Epoch: [71][190/391]	Time  0.035 ( 0.034)	Data  0.001 ( 0.002)	Loss 2.3501e-01 (2.2304e-01)	Acc@1  96.09 ( 93.47)	Acc@5 100.00 ( 99.70)
Epoch: [71][200/391]	Time  0.032 ( 0.034)	Data  0.001 ( 0.002)	Loss 2.4713e-01 (2.2400e-01)	Acc@1  91.41 ( 93.42)	Acc@5 100.00 ( 99.70)
Epoch: [71][210/391]	Time  0.033 ( 0.033)	Data  0.001 ( 0.002)	Loss 3.0587e-01 (2.2446e-01)	Acc@1  89.84 ( 93.39)	Acc@5  99.22 ( 99.71)
Epoch: [71][220/391]	Time  0.039 ( 0.034)	Data  0.001 ( 0.002)	Loss 3.1757e-01 (2.2532e-01)	Acc@1  89.06 ( 93.38)	Acc@5 100.00 ( 99.71)
Epoch: [71][230/391]	Time  0.032 ( 0.034)	Data  0.001 ( 0.002)	Loss 2.0854e-01 (2.2462e-01)	Acc@1  93.75 ( 93.41)	Acc@5 100.00 ( 99.72)
Epoch: [71][240/391]	Time  0.031 ( 0.034)	Data  0.001 ( 0.002)	Loss 1.6902e-01 (2.2443e-01)	Acc@1  96.09 ( 93.41)	Acc@5 100.00 ( 99.72)
Epoch: [71][250/391]	Time  0.032 ( 0.034)	Data  0.001 ( 0.002)	Loss 2.0980e-01 (2.2541e-01)	Acc@1  94.53 ( 93.39)	Acc@5 100.00 ( 99.73)
Epoch: [71][260/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.8934e-01 (2.2634e-01)	Acc@1  95.31 ( 93.35)	Acc@5 100.00 ( 99.72)
Epoch: [71][270/391]	Time  0.034 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.3277e-01 (2.2587e-01)	Acc@1  93.75 ( 93.39)	Acc@5 100.00 ( 99.71)
Epoch: [71][280/391]	Time  0.033 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.9550e-01 (2.2634e-01)	Acc@1  92.97 ( 93.35)	Acc@5 100.00 ( 99.72)
Epoch: [71][290/391]	Time  0.033 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.8672e-01 (2.2631e-01)	Acc@1  92.97 ( 93.34)	Acc@5 100.00 ( 99.72)
Epoch: [71][300/391]	Time  0.037 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.1503e-01 (2.2779e-01)	Acc@1  94.53 ( 93.30)	Acc@5  99.22 ( 99.71)
Epoch: [71][310/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.8310e-01 (2.2777e-01)	Acc@1  89.84 ( 93.31)	Acc@5 100.00 ( 99.71)
Epoch: [71][320/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.9507e-01 (2.2765e-01)	Acc@1  95.31 ( 93.31)	Acc@5  99.22 ( 99.72)
Epoch: [71][330/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.001)	Loss 2.2490e-01 (2.2801e-01)	Acc@1  92.19 ( 93.27)	Acc@5  99.22 ( 99.71)
Epoch: [71][340/391]	Time  0.035 ( 0.033)	Data  0.001 ( 0.001)	Loss 2.2486e-01 (2.2842e-01)	Acc@1  94.53 ( 93.26)	Acc@5 100.00 ( 99.71)
Epoch: [71][350/391]	Time  0.033 ( 0.033)	Data  0.001 ( 0.001)	Loss 1.6992e-01 (2.2851e-01)	Acc@1  94.53 ( 93.25)	Acc@5 100.00 ( 99.71)
Epoch: [71][360/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.001)	Loss 2.2438e-01 (2.2825e-01)	Acc@1  96.09 ( 93.26)	Acc@5  99.22 ( 99.71)
Epoch: [71][370/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.001)	Loss 3.2721e-01 (2.2903e-01)	Acc@1  92.19 ( 93.22)	Acc@5  98.44 ( 99.71)
Epoch: [71][380/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.001)	Loss 1.8481e-01 (2.2863e-01)	Acc@1  95.31 ( 93.25)	Acc@5 100.00 ( 99.71)
Epoch: [71][390/391]	Time  0.023 ( 0.033)	Data  0.001 ( 0.001)	Loss 3.5674e-01 (2.2925e-01)	Acc@1  88.75 ( 93.22)	Acc@5 100.00 ( 99.71)
## e[71] optimizer.zero_grad (sum) time: 0.11352968215942383
## e[71]       loss.backward (sum) time: 3.010178804397583
## e[71]      optimizer.step (sum) time: 0.7874698638916016
## epoch[71] training(only) time: 13.084576606750488
# Switched to evaluate mode...
Test: [  0/100]	Time  0.158 ( 0.158)	Loss 1.3006e+00 (1.3006e+00)	Acc@1  69.00 ( 69.00)	Acc@5  89.00 ( 89.00)
Test: [ 10/100]	Time  0.022 ( 0.035)	Loss 1.4402e+00 (1.4814e+00)	Acc@1  67.00 ( 68.00)	Acc@5  93.00 ( 89.27)
Test: [ 20/100]	Time  0.024 ( 0.030)	Loss 1.1900e+00 (1.4318e+00)	Acc@1  76.00 ( 68.76)	Acc@5  94.00 ( 90.33)
Test: [ 30/100]	Time  0.022 ( 0.027)	Loss 1.6624e+00 (1.4608e+00)	Acc@1  62.00 ( 67.77)	Acc@5  92.00 ( 90.23)
Test: [ 40/100]	Time  0.021 ( 0.026)	Loss 1.4383e+00 (1.4570e+00)	Acc@1  68.00 ( 67.88)	Acc@5  91.00 ( 90.17)
Test: [ 50/100]	Time  0.017 ( 0.025)	Loss 1.5438e+00 (1.4688e+00)	Acc@1  63.00 ( 67.63)	Acc@5  91.00 ( 90.18)
Test: [ 60/100]	Time  0.024 ( 0.025)	Loss 1.6148e+00 (1.4447e+00)	Acc@1  63.00 ( 67.97)	Acc@5  88.00 ( 90.59)
Test: [ 70/100]	Time  0.024 ( 0.025)	Loss 1.6084e+00 (1.4451e+00)	Acc@1  69.00 ( 67.96)	Acc@5  89.00 ( 90.66)
Test: [ 80/100]	Time  0.024 ( 0.025)	Loss 1.5744e+00 (1.4516e+00)	Acc@1  73.00 ( 68.06)	Acc@5  88.00 ( 90.53)
Test: [ 90/100]	Time  0.024 ( 0.025)	Loss 1.7364e+00 (1.4411e+00)	Acc@1  60.00 ( 68.21)	Acc@5  87.00 ( 90.66)
 * Acc@1 68.480 Acc@5 90.810
### epoch[71] execution time: 15.58661675453186
EPOCH 72
REMOVING: module.fire7.squeeze.0.weight
REMOVING: module.fire7.squeeze.0.bias
i:   0, name:  module.fire7.squeeze.1.weight  changing lr from: 0.001074401537419799   to: 0.001003069530313571
i:   1, name:    module.fire7.squeeze.1.bias  changing lr from: 0.001136897016397869   to: 0.001023730732969574
i:   2, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.001217506196283401   to: 0.001063428588839609
i:   3, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.001315738209514527   to: 0.001121668857547208
i:   4, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.001431107348879439   to: 0.001197961691925286
i:   5, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.001563133336580263   to: 0.001291821955445720
i:   6, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.001711341570004048   to: 0.001402769514421103
i:   7, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.001875263345333310   to: 0.001530329506157884
i:   8, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.002054436060090497   to: 0.001674032584202994
i:   9, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.002248403395672892   to: 0.001833415141788557
i:  10, name:  module.fire8.squeeze.0.weight  changing lr from: 0.002456715480897148   to: 0.002008019514542663
i:  11, name:    module.fire8.squeeze.0.bias  changing lr from: 0.002678929037535787   to: 0.002197394163497334
i:  12, name:  module.fire8.squeeze.1.weight  changing lr from: 0.002914607508792116   to: 0.002401093839389167
i:  13, name:    module.fire8.squeeze.1.bias  changing lr from: 0.003163321171624266   to: 0.002618679729212130
i:  14, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.003424647233794231   to: 0.002849719585947285
i:  15, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.003698169916484167   to: 0.003093787842359857
i:  16, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.003983480523288279   to: 0.003350465709720218
i:  17, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.004280177496356812   to: 0.003619341262272474
i:  18, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.004587866460436351   to: 0.003900009508242085
i:  19, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.004906160255520474   to: 0.004192072448142386
i:  20, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.005234678958794042   to: 0.004495139121109131
i:  21, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.005573049896525994   to: 0.004808825639962443
i:  22, name:  module.fire9.squeeze.0.weight  changing lr from: 0.005920907646536588   to: 0.005132755215666017
i:  23, name:    module.fire9.squeeze.0.bias  changing lr from: 0.006277894031837993   to: 0.005466558171825502
i:  24, name:  module.fire9.squeeze.1.weight  changing lr from: 0.006643658106020350   to: 0.005809871949840211
i:  25, name:    module.fire9.squeeze.1.bias  changing lr from: 0.007017856130929578   to: 0.006162341105295754
i:  26, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.007400151547158551   to: 0.006523617296159189
i:  27, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.007790214937848899   to: 0.006893359263313258
i:  28, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.008187723986277429   to: 0.007271232803942090
i:  29, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.008592363427679044   to: 0.007656910738257094
i:  30, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.009003824995735831   to: 0.008050072870029379
i:  31, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.009421807364141683   to: 0.008450405941372785
i:  32, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.009846016083630994   to: 0.008857603582200752
i:  33, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.010276163514841414   to: 0.009271366254759737
i:  34, name:           module.conv10.weight  changing lr from: 0.010711968757361395   to: 0.009691401193622412
i:  35, name:             module.conv10.bias  changing lr from: 0.011153157575295593   to: 0.010117422341504662



# Switched to train mode...
Epoch: [72][  0/391]	Time  0.194 ( 0.194)	Data  0.155 ( 0.155)	Loss 2.0490e-01 (2.0490e-01)	Acc@1  96.09 ( 96.09)	Acc@5 100.00 (100.00)
Epoch: [72][ 10/391]	Time  0.035 ( 0.050)	Data  0.001 ( 0.015)	Loss 1.9692e-01 (1.9490e-01)	Acc@1  94.53 ( 95.31)	Acc@5  99.22 ( 99.72)
Epoch: [72][ 20/391]	Time  0.033 ( 0.042)	Data  0.001 ( 0.008)	Loss 1.8685e-01 (2.1275e-01)	Acc@1  95.31 ( 94.20)	Acc@5 100.00 ( 99.70)
Epoch: [72][ 30/391]	Time  0.032 ( 0.038)	Data  0.001 ( 0.006)	Loss 1.7908e-01 (2.1109e-01)	Acc@1  94.53 ( 94.23)	Acc@5 100.00 ( 99.77)
Epoch: [72][ 40/391]	Time  0.032 ( 0.037)	Data  0.001 ( 0.005)	Loss 2.5325e-01 (2.1943e-01)	Acc@1  92.97 ( 93.60)	Acc@5  99.22 ( 99.77)
Epoch: [72][ 50/391]	Time  0.031 ( 0.036)	Data  0.001 ( 0.004)	Loss 2.5139e-01 (2.1578e-01)	Acc@1  89.84 ( 93.69)	Acc@5 100.00 ( 99.82)
Epoch: [72][ 60/391]	Time  0.032 ( 0.036)	Data  0.001 ( 0.004)	Loss 2.5457e-01 (2.1363e-01)	Acc@1  94.53 ( 93.79)	Acc@5 100.00 ( 99.85)
Epoch: [72][ 70/391]	Time  0.034 ( 0.035)	Data  0.001 ( 0.003)	Loss 3.6091e-01 (2.1461e-01)	Acc@1  91.41 ( 93.90)	Acc@5  99.22 ( 99.83)
Epoch: [72][ 80/391]	Time  0.032 ( 0.035)	Data  0.001 ( 0.003)	Loss 2.4427e-01 (2.1530e-01)	Acc@1  95.31 ( 93.90)	Acc@5  99.22 ( 99.84)
Epoch: [72][ 90/391]	Time  0.034 ( 0.035)	Data  0.001 ( 0.003)	Loss 2.1857e-01 (2.1816e-01)	Acc@1  96.09 ( 93.78)	Acc@5 100.00 ( 99.85)
Epoch: [72][100/391]	Time  0.034 ( 0.034)	Data  0.001 ( 0.003)	Loss 2.4431e-01 (2.1742e-01)	Acc@1  90.62 ( 93.73)	Acc@5 100.00 ( 99.82)
Epoch: [72][110/391]	Time  0.035 ( 0.034)	Data  0.001 ( 0.002)	Loss 2.6802e-01 (2.1841e-01)	Acc@1  92.97 ( 93.69)	Acc@5 100.00 ( 99.81)
Epoch: [72][120/391]	Time  0.033 ( 0.034)	Data  0.001 ( 0.002)	Loss 2.3010e-01 (2.1812e-01)	Acc@1  91.41 ( 93.67)	Acc@5 100.00 ( 99.81)
Epoch: [72][130/391]	Time  0.033 ( 0.034)	Data  0.001 ( 0.002)	Loss 2.8054e-01 (2.2059e-01)	Acc@1  90.62 ( 93.53)	Acc@5 100.00 ( 99.80)
Epoch: [72][140/391]	Time  0.032 ( 0.034)	Data  0.001 ( 0.002)	Loss 1.6399e-01 (2.1916e-01)	Acc@1  96.88 ( 93.58)	Acc@5 100.00 ( 99.80)
Epoch: [72][150/391]	Time  0.032 ( 0.034)	Data  0.001 ( 0.002)	Loss 2.7128e-01 (2.1999e-01)	Acc@1  91.41 ( 93.61)	Acc@5  99.22 ( 99.78)
Epoch: [72][160/391]	Time  0.032 ( 0.034)	Data  0.001 ( 0.002)	Loss 2.2166e-01 (2.2025e-01)	Acc@1  94.53 ( 93.63)	Acc@5 100.00 ( 99.77)
Epoch: [72][170/391]	Time  0.032 ( 0.034)	Data  0.001 ( 0.002)	Loss 2.8652e-01 (2.2119e-01)	Acc@1  89.84 ( 93.54)	Acc@5  99.22 ( 99.76)
Epoch: [72][180/391]	Time  0.032 ( 0.034)	Data  0.001 ( 0.002)	Loss 3.1039e-01 (2.2170e-01)	Acc@1  87.50 ( 93.50)	Acc@5  99.22 ( 99.74)
Epoch: [72][190/391]	Time  0.031 ( 0.034)	Data  0.001 ( 0.002)	Loss 2.8049e-01 (2.2241e-01)	Acc@1  93.75 ( 93.47)	Acc@5  99.22 ( 99.73)
Epoch: [72][200/391]	Time  0.032 ( 0.034)	Data  0.001 ( 0.002)	Loss 2.3720e-01 (2.2288e-01)	Acc@1  92.97 ( 93.46)	Acc@5 100.00 ( 99.73)
Epoch: [72][210/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.9873e-01 (2.2365e-01)	Acc@1  95.31 ( 93.44)	Acc@5 100.00 ( 99.72)
Epoch: [72][220/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.8563e-01 (2.2234e-01)	Acc@1  92.97 ( 93.48)	Acc@5 100.00 ( 99.72)
Epoch: [72][230/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.0168e-01 (2.2213e-01)	Acc@1  92.97 ( 93.48)	Acc@5 100.00 ( 99.72)
Epoch: [72][240/391]	Time  0.033 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.7468e-01 (2.2322e-01)	Acc@1  92.97 ( 93.46)	Acc@5  98.44 ( 99.72)
Epoch: [72][250/391]	Time  0.036 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.1701e-01 (2.2325e-01)	Acc@1  93.75 ( 93.48)	Acc@5 100.00 ( 99.71)
Epoch: [72][260/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.1193e-01 (2.2301e-01)	Acc@1  94.53 ( 93.49)	Acc@5 100.00 ( 99.71)
Epoch: [72][270/391]	Time  0.035 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.7576e-01 (2.2377e-01)	Acc@1  95.31 ( 93.44)	Acc@5 100.00 ( 99.71)
Epoch: [72][280/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.6105e-01 (2.2408e-01)	Acc@1  94.53 ( 93.44)	Acc@5  99.22 ( 99.71)
Epoch: [72][290/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.2610e-01 (2.2456e-01)	Acc@1  93.75 ( 93.42)	Acc@5  99.22 ( 99.69)
Epoch: [72][300/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.7451e-01 (2.2398e-01)	Acc@1  94.53 ( 93.46)	Acc@5 100.00 ( 99.70)
Epoch: [72][310/391]	Time  0.033 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.1964e-01 (2.2394e-01)	Acc@1  93.75 ( 93.50)	Acc@5 100.00 ( 99.69)
Epoch: [72][320/391]	Time  0.033 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.7323e-01 (2.2430e-01)	Acc@1  92.19 ( 93.51)	Acc@5 100.00 ( 99.68)
Epoch: [72][330/391]	Time  0.033 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.5349e-01 (2.2507e-01)	Acc@1  91.41 ( 93.48)	Acc@5  99.22 ( 99.68)
Epoch: [72][340/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.3581e-01 (2.2594e-01)	Acc@1  94.53 ( 93.44)	Acc@5  99.22 ( 99.67)
Epoch: [72][350/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.8458e-01 (2.2583e-01)	Acc@1  90.62 ( 93.45)	Acc@5  99.22 ( 99.67)
Epoch: [72][360/391]	Time  0.040 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.4335e-01 (2.2672e-01)	Acc@1  92.97 ( 93.41)	Acc@5  98.44 ( 99.67)
Epoch: [72][370/391]	Time  0.033 ( 0.033)	Data  0.001 ( 0.001)	Loss 2.2526e-01 (2.2633e-01)	Acc@1  92.19 ( 93.41)	Acc@5  99.22 ( 99.67)
Epoch: [72][380/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.001)	Loss 1.6812e-01 (2.2596e-01)	Acc@1  96.09 ( 93.41)	Acc@5  99.22 ( 99.67)
Epoch: [72][390/391]	Time  0.023 ( 0.033)	Data  0.001 ( 0.001)	Loss 3.2470e-01 (2.2628e-01)	Acc@1  87.50 ( 93.40)	Acc@5 100.00 ( 99.67)
## e[72] optimizer.zero_grad (sum) time: 0.10809159278869629
## e[72]       loss.backward (sum) time: 2.88287353515625
## e[72]      optimizer.step (sum) time: 0.780264139175415
## epoch[72] training(only) time: 13.041595935821533
# Switched to evaluate mode...
Test: [  0/100]	Time  0.156 ( 0.156)	Loss 1.3336e+00 (1.3336e+00)	Acc@1  72.00 ( 72.00)	Acc@5  88.00 ( 88.00)
Test: [ 10/100]	Time  0.024 ( 0.036)	Loss 1.4728e+00 (1.4870e+00)	Acc@1  71.00 ( 68.36)	Acc@5  90.00 ( 88.73)
Test: [ 20/100]	Time  0.022 ( 0.030)	Loss 1.2225e+00 (1.4304e+00)	Acc@1  76.00 ( 68.86)	Acc@5  94.00 ( 90.00)
Test: [ 30/100]	Time  0.024 ( 0.027)	Loss 1.8077e+00 (1.4618e+00)	Acc@1  60.00 ( 67.90)	Acc@5  91.00 ( 90.19)
Test: [ 40/100]	Time  0.020 ( 0.026)	Loss 1.4434e+00 (1.4598e+00)	Acc@1  68.00 ( 68.00)	Acc@5  90.00 ( 90.15)
Test: [ 50/100]	Time  0.022 ( 0.025)	Loss 1.4631e+00 (1.4669e+00)	Acc@1  68.00 ( 67.78)	Acc@5  90.00 ( 90.04)
Test: [ 60/100]	Time  0.019 ( 0.024)	Loss 1.6205e+00 (1.4427e+00)	Acc@1  62.00 ( 67.85)	Acc@5  86.00 ( 90.48)
Test: [ 70/100]	Time  0.019 ( 0.023)	Loss 1.6549e+00 (1.4437e+00)	Acc@1  68.00 ( 67.82)	Acc@5  88.00 ( 90.46)
Test: [ 80/100]	Time  0.024 ( 0.023)	Loss 1.5323e+00 (1.4493e+00)	Acc@1  73.00 ( 67.78)	Acc@5  88.00 ( 90.40)
Test: [ 90/100]	Time  0.024 ( 0.023)	Loss 1.7775e+00 (1.4380e+00)	Acc@1  65.00 ( 68.01)	Acc@5  87.00 ( 90.53)
 * Acc@1 68.240 Acc@5 90.690
### epoch[72] execution time: 15.41752576828003
EPOCH 73
REMOVING: module.fire7.squeeze.1.weight
REMOVING: module.fire7.squeeze.1.bias
i:   0, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.001063428588839609   to: 0.001001384510484820
i:   1, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.001121668857547208   to: 0.001018375610920601
i:   2, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.001197961691925286   to: 0.001054321688277159
i:   3, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.001291821955445720   to: 0.001108734484818834
i:   4, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.001402769514421103   to: 0.001181129993004647
i:   5, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.001530329506157884   to: 0.001271028770646153
i:   6, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.001674032584202994   to: 0.001377956231293325
i:   7, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.001833415141788557   to: 0.001501442910997702
i:   8, name:  module.fire8.squeeze.0.weight  changing lr from: 0.002008019514542663   to: 0.001641024712565863
i:   9, name:    module.fire8.squeeze.0.bias  changing lr from: 0.002197394163497334   to: 0.001796243128380636
i:  10, name:  module.fire8.squeeze.1.weight  changing lr from: 0.002401093839389167   to: 0.001966645442831493
i:  11, name:    module.fire8.squeeze.1.bias  changing lr from: 0.002618679729212130   to: 0.002151784915360637
i:  12, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.002849719585947285   to: 0.002351220945095966
i:  13, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.003093787842359857   to: 0.002564519218008326
i:  14, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.003350465709720218   to: 0.002791251837495888
i:  15, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.003619341262272474   to: 0.003030997439265958
i:  16, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.003900009508242085   to: 0.003283341291351177
i:  17, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.004192072448142386   to: 0.003547875380065917
i:  18, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.004495139121109131   to: 0.003824198482676394
i:  19, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.004808825639962443   to: 0.004111916227528572
i:  20, name:  module.fire9.squeeze.0.weight  changing lr from: 0.005132755215666017   to: 0.004410641142347165
i:  21, name:    module.fire9.squeeze.0.bias  changing lr from: 0.005466558171825502   to: 0.004719992691390578
i:  22, name:  module.fire9.squeeze.1.weight  changing lr from: 0.005809871949840211   to: 0.005039597302118093
i:  23, name:    module.fire9.squeeze.1.bias  changing lr from: 0.006162341105295754   to: 0.005369088381998127
i:  24, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.006523617296159189   to: 0.005708106326059647
i:  25, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.006893359263313258   to: 0.006056298515762914
i:  26, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.007271232803942090   to: 0.006413319309740478
i:  27, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.007656910738257094   to: 0.006778830026934989
i:  28, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.008050072870029379   to: 0.007152498922636868
i:  29, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.008450405941372785   to: 0.007534001157901876
i:  30, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.008857603582200752   to: 0.007923018762806478
i:  31, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.009271366254759737   to: 0.008319240593977918
i:  32, name:           module.conv10.weight  changing lr from: 0.009691401193622412   to: 0.008722362286814977
i:  33, name:             module.conv10.bias  changing lr from: 0.010117422341504662   to: 0.009132086202795479



# Switched to train mode...
Epoch: [73][  0/391]	Time  0.190 ( 0.190)	Data  0.151 ( 0.151)	Loss 2.4601e-01 (2.4601e-01)	Acc@1  91.41 ( 91.41)	Acc@5  99.22 ( 99.22)
Epoch: [73][ 10/391]	Time  0.032 ( 0.047)	Data  0.001 ( 0.015)	Loss 1.8794e-01 (2.1699e-01)	Acc@1  92.97 ( 93.04)	Acc@5 100.00 ( 99.72)
Epoch: [73][ 20/391]	Time  0.031 ( 0.040)	Data  0.001 ( 0.008)	Loss 2.5792e-01 (2.1838e-01)	Acc@1  92.19 ( 93.53)	Acc@5 100.00 ( 99.70)
Epoch: [73][ 30/391]	Time  0.045 ( 0.038)	Data  0.001 ( 0.006)	Loss 1.6655e-01 (2.1418e-01)	Acc@1  95.31 ( 93.95)	Acc@5 100.00 ( 99.72)
Epoch: [73][ 40/391]	Time  0.032 ( 0.037)	Data  0.001 ( 0.005)	Loss 2.3304e-01 (2.1360e-01)	Acc@1  95.31 ( 94.00)	Acc@5 100.00 ( 99.77)
Epoch: [73][ 50/391]	Time  0.033 ( 0.036)	Data  0.001 ( 0.004)	Loss 1.6812e-01 (2.1368e-01)	Acc@1  96.09 ( 93.87)	Acc@5 100.00 ( 99.79)
Epoch: [73][ 60/391]	Time  0.033 ( 0.035)	Data  0.001 ( 0.003)	Loss 3.3229e-01 (2.1422e-01)	Acc@1  89.84 ( 93.89)	Acc@5 100.00 ( 99.82)
Epoch: [73][ 70/391]	Time  0.032 ( 0.035)	Data  0.001 ( 0.003)	Loss 1.7333e-01 (2.1624e-01)	Acc@1  93.75 ( 93.79)	Acc@5 100.00 ( 99.79)
Epoch: [73][ 80/391]	Time  0.031 ( 0.034)	Data  0.001 ( 0.003)	Loss 2.0986e-01 (2.1365e-01)	Acc@1  96.09 ( 93.87)	Acc@5  98.44 ( 99.77)
Epoch: [73][ 90/391]	Time  0.034 ( 0.034)	Data  0.001 ( 0.003)	Loss 2.9124e-01 (2.1722e-01)	Acc@1  90.62 ( 93.75)	Acc@5  99.22 ( 99.76)
Epoch: [73][100/391]	Time  0.032 ( 0.034)	Data  0.001 ( 0.003)	Loss 1.4511e-01 (2.1586e-01)	Acc@1  97.66 ( 93.84)	Acc@5 100.00 ( 99.77)
Epoch: [73][110/391]	Time  0.035 ( 0.034)	Data  0.001 ( 0.002)	Loss 2.1110e-01 (2.1396e-01)	Acc@1  92.19 ( 93.88)	Acc@5 100.00 ( 99.77)
Epoch: [73][120/391]	Time  0.033 ( 0.034)	Data  0.001 ( 0.002)	Loss 1.6084e-01 (2.1494e-01)	Acc@1  94.53 ( 93.85)	Acc@5 100.00 ( 99.78)
Epoch: [73][130/391]	Time  0.032 ( 0.034)	Data  0.001 ( 0.002)	Loss 1.4131e-01 (2.1468e-01)	Acc@1  95.31 ( 93.83)	Acc@5 100.00 ( 99.77)
Epoch: [73][140/391]	Time  0.032 ( 0.034)	Data  0.001 ( 0.002)	Loss 3.1707e-01 (2.1353e-01)	Acc@1  91.41 ( 93.87)	Acc@5  97.66 ( 99.77)
Epoch: [73][150/391]	Time  0.032 ( 0.034)	Data  0.001 ( 0.002)	Loss 2.4142e-01 (2.1483e-01)	Acc@1  92.19 ( 93.81)	Acc@5 100.00 ( 99.78)
Epoch: [73][160/391]	Time  0.032 ( 0.034)	Data  0.001 ( 0.002)	Loss 1.5264e-01 (2.1397e-01)	Acc@1  96.88 ( 93.85)	Acc@5  99.22 ( 99.77)
Epoch: [73][170/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.2537e-01 (2.1433e-01)	Acc@1  92.19 ( 93.80)	Acc@5 100.00 ( 99.77)
Epoch: [73][180/391]	Time  0.035 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.8357e-01 (2.1482e-01)	Acc@1  94.53 ( 93.76)	Acc@5 100.00 ( 99.77)
Epoch: [73][190/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.0964e-01 (2.1345e-01)	Acc@1  93.75 ( 93.77)	Acc@5  99.22 ( 99.78)
Epoch: [73][200/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.0422e-01 (2.1485e-01)	Acc@1  92.19 ( 93.70)	Acc@5 100.00 ( 99.77)
Epoch: [73][210/391]	Time  0.037 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.3098e-01 (2.1615e-01)	Acc@1  93.75 ( 93.68)	Acc@5  99.22 ( 99.75)
Epoch: [73][220/391]	Time  0.033 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.1319e-01 (2.1593e-01)	Acc@1  93.75 ( 93.70)	Acc@5  99.22 ( 99.75)
Epoch: [73][230/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.4868e-01 (2.1547e-01)	Acc@1  95.31 ( 93.68)	Acc@5  99.22 ( 99.74)
Epoch: [73][240/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.6610e-01 (2.1556e-01)	Acc@1  92.19 ( 93.64)	Acc@5 100.00 ( 99.74)
Epoch: [73][250/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.6916e-01 (2.1571e-01)	Acc@1  95.31 ( 93.63)	Acc@5 100.00 ( 99.75)
Epoch: [73][260/391]	Time  0.033 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.5729e-01 (2.1609e-01)	Acc@1  96.09 ( 93.66)	Acc@5 100.00 ( 99.75)
Epoch: [73][270/391]	Time  0.033 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.3825e-01 (2.1627e-01)	Acc@1  96.09 ( 93.68)	Acc@5  99.22 ( 99.75)
Epoch: [73][280/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.3757e-01 (2.1668e-01)	Acc@1  96.88 ( 93.68)	Acc@5 100.00 ( 99.75)
Epoch: [73][290/391]	Time  0.033 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.6744e-01 (2.1750e-01)	Acc@1  89.84 ( 93.66)	Acc@5  99.22 ( 99.74)
Epoch: [73][300/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.2295e-01 (2.1708e-01)	Acc@1  96.09 ( 93.70)	Acc@5  99.22 ( 99.74)
Epoch: [73][310/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.7583e-01 (2.1813e-01)	Acc@1  91.41 ( 93.65)	Acc@5  98.44 ( 99.73)
Epoch: [73][320/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.9008e-01 (2.1800e-01)	Acc@1  96.09 ( 93.65)	Acc@5 100.00 ( 99.72)
Epoch: [73][330/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.6813e-01 (2.1867e-01)	Acc@1  93.75 ( 93.63)	Acc@5  99.22 ( 99.71)
Epoch: [73][340/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.7194e-01 (2.1889e-01)	Acc@1  96.88 ( 93.59)	Acc@5 100.00 ( 99.71)
Epoch: [73][350/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.001)	Loss 1.8875e-01 (2.1931e-01)	Acc@1  92.19 ( 93.56)	Acc@5 100.00 ( 99.71)
Epoch: [73][360/391]	Time  0.033 ( 0.033)	Data  0.001 ( 0.001)	Loss 2.1072e-01 (2.1963e-01)	Acc@1  92.19 ( 93.53)	Acc@5 100.00 ( 99.71)
Epoch: [73][370/391]	Time  0.035 ( 0.033)	Data  0.001 ( 0.001)	Loss 1.5571e-01 (2.1975e-01)	Acc@1  97.66 ( 93.52)	Acc@5 100.00 ( 99.71)
Epoch: [73][380/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.001)	Loss 3.0485e-01 (2.2015e-01)	Acc@1  91.41 ( 93.52)	Acc@5  98.44 ( 99.71)
Epoch: [73][390/391]	Time  0.023 ( 0.033)	Data  0.001 ( 0.001)	Loss 1.7670e-01 (2.1987e-01)	Acc@1  96.25 ( 93.55)	Acc@5 100.00 ( 99.71)
## e[73] optimizer.zero_grad (sum) time: 0.10243082046508789
## e[73]       loss.backward (sum) time: 2.7319233417510986
## e[73]      optimizer.step (sum) time: 0.764235258102417
## epoch[73] training(only) time: 12.972252607345581
# Switched to evaluate mode...
Test: [  0/100]	Time  0.156 ( 0.156)	Loss 1.2974e+00 (1.2974e+00)	Acc@1  74.00 ( 74.00)	Acc@5  89.00 ( 89.00)
Test: [ 10/100]	Time  0.025 ( 0.035)	Loss 1.5441e+00 (1.4819e+00)	Acc@1  69.00 ( 68.73)	Acc@5  91.00 ( 89.27)
Test: [ 20/100]	Time  0.021 ( 0.029)	Loss 1.2037e+00 (1.4292e+00)	Acc@1  75.00 ( 69.19)	Acc@5  93.00 ( 90.29)
Test: [ 30/100]	Time  0.023 ( 0.027)	Loss 1.7749e+00 (1.4589e+00)	Acc@1  58.00 ( 68.35)	Acc@5  92.00 ( 90.42)
Test: [ 40/100]	Time  0.024 ( 0.026)	Loss 1.4401e+00 (1.4558e+00)	Acc@1  65.00 ( 68.20)	Acc@5  92.00 ( 90.49)
Test: [ 50/100]	Time  0.021 ( 0.026)	Loss 1.4761e+00 (1.4666e+00)	Acc@1  66.00 ( 67.98)	Acc@5  91.00 ( 90.35)
Test: [ 60/100]	Time  0.024 ( 0.025)	Loss 1.5794e+00 (1.4400e+00)	Acc@1  66.00 ( 68.13)	Acc@5  86.00 ( 90.72)
Test: [ 70/100]	Time  0.021 ( 0.025)	Loss 1.6730e+00 (1.4391e+00)	Acc@1  68.00 ( 68.14)	Acc@5  89.00 ( 90.79)
Test: [ 80/100]	Time  0.021 ( 0.025)	Loss 1.4855e+00 (1.4450e+00)	Acc@1  73.00 ( 68.14)	Acc@5  88.00 ( 90.68)
Test: [ 90/100]	Time  0.024 ( 0.024)	Loss 1.7134e+00 (1.4315e+00)	Acc@1  65.00 ( 68.48)	Acc@5  85.00 ( 90.74)
 * Acc@1 68.720 Acc@5 90.840
### epoch[73] execution time: 15.438745737075806
EPOCH 74
REMOVING: module.fire7.expand_1x1.0.weight
REMOVING: module.fire7.expand_1x1.0.bias
i:   0, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.001054321688277159   to: 0.001000445491874213
i:   1, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.001108734484818834   to: 0.001014195875105333
i:   2, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.001181129993004647   to: 0.001046811488842940
i:   3, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.001271028770646153   to: 0.001097809994158216
i:   4, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.001377956231293325   to: 0.001166713170187582
i:   5, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.001501442910997702   to: 0.001253047226559294
i:   6, name:  module.fire8.squeeze.0.weight  changing lr from: 0.001641024712565863   to: 0.001356343091512007
i:   7, name:    module.fire8.squeeze.0.bias  changing lr from: 0.001796243128380636   to: 0.001476136676824973
i:   8, name:  module.fire8.squeeze.1.weight  changing lr from: 0.001966645442831493   to: 0.001611969120644568
i:   9, name:    module.fire8.squeeze.1.bias  changing lr from: 0.002151784915360637   to: 0.001763387009257405
i:  10, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.002351220945095966   to: 0.001929942578825466
i:  11, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.002564519218008326   to: 0.002111193898065144
i:  12, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.002791251837495888   to: 0.002306705032817740
i:  13, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.003030997439265958   to: 0.002516046193426279
i:  14, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.003283341291351177   to: 0.002738793865800231
i:  15, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.003547875380065917   to: 0.002974530927018076
i:  16, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.003824198482676394   to: 0.003222846746285440
i:  17, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.004111916227528572   to: 0.003483337272036129
i:  18, name:  module.fire9.squeeze.0.weight  changing lr from: 0.004410641142347165   to: 0.003755605105932696
i:  19, name:    module.fire9.squeeze.0.bias  changing lr from: 0.004719992691390578   to: 0.004039259564493585
i:  20, name:  module.fire9.squeeze.1.weight  changing lr from: 0.005039597302118093   to: 0.004333916729045217
i:  21, name:    module.fire9.squeeze.1.bias  changing lr from: 0.005369088381998127   to: 0.004639199484668921
i:  22, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.005708106326059647   to: 0.004954737548785315
i:  23, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.006056298515762914   to: 0.005280167489991715
i:  24, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.006413319309740478   to: 0.005615132737742789
i:  25, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.006778830026934989   to: 0.005959283583438673
i:  26, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.007152498922636868   to: 0.006312277173460934
i:  27, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.007534001157901876   to: 0.006673777494672717
i:  28, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.007923018762806478   to: 0.007043455352876360
i:  29, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.008319240593977918   to: 0.007420988344699868
i:  30, name:           module.conv10.weight  changing lr from: 0.008722362286814977   to: 0.007806060823361893
i:  31, name:             module.conv10.bias  changing lr from: 0.009132086202795479   to: 0.008198363858743906



# Switched to train mode...
Epoch: [74][  0/391]	Time  0.190 ( 0.190)	Data  0.150 ( 0.150)	Loss 1.4446e-01 (1.4446e-01)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [74][ 10/391]	Time  0.032 ( 0.048)	Data  0.001 ( 0.015)	Loss 1.8479e-01 (2.0568e-01)	Acc@1  96.09 ( 93.96)	Acc@5 100.00 ( 99.93)
Epoch: [74][ 20/391]	Time  0.035 ( 0.041)	Data  0.001 ( 0.008)	Loss 2.9158e-01 (2.1746e-01)	Acc@1  91.41 ( 93.97)	Acc@5  99.22 ( 99.78)
Epoch: [74][ 30/391]	Time  0.031 ( 0.038)	Data  0.001 ( 0.006)	Loss 1.7895e-01 (2.1560e-01)	Acc@1  96.09 ( 93.83)	Acc@5 100.00 ( 99.80)
Epoch: [74][ 40/391]	Time  0.032 ( 0.037)	Data  0.001 ( 0.005)	Loss 2.3072e-01 (2.1416e-01)	Acc@1  92.97 ( 93.90)	Acc@5 100.00 ( 99.81)
Epoch: [74][ 50/391]	Time  0.031 ( 0.036)	Data  0.001 ( 0.004)	Loss 2.0874e-01 (2.1697e-01)	Acc@1  94.53 ( 93.81)	Acc@5  99.22 ( 99.79)
Epoch: [74][ 60/391]	Time  0.033 ( 0.035)	Data  0.001 ( 0.003)	Loss 2.3721e-01 (2.1729e-01)	Acc@1  92.19 ( 93.76)	Acc@5 100.00 ( 99.78)
Epoch: [74][ 70/391]	Time  0.032 ( 0.035)	Data  0.001 ( 0.003)	Loss 2.2043e-01 (2.1820e-01)	Acc@1  95.31 ( 93.77)	Acc@5 100.00 ( 99.77)
Epoch: [74][ 80/391]	Time  0.031 ( 0.035)	Data  0.001 ( 0.003)	Loss 1.8061e-01 (2.1564e-01)	Acc@1  96.88 ( 93.83)	Acc@5 100.00 ( 99.79)
Epoch: [74][ 90/391]	Time  0.032 ( 0.034)	Data  0.001 ( 0.003)	Loss 2.2095e-01 (2.1839e-01)	Acc@1  94.53 ( 93.78)	Acc@5 100.00 ( 99.75)
Epoch: [74][100/391]	Time  0.038 ( 0.034)	Data  0.001 ( 0.003)	Loss 2.9554e-01 (2.1987e-01)	Acc@1  89.06 ( 93.73)	Acc@5 100.00 ( 99.72)
Epoch: [74][110/391]	Time  0.031 ( 0.034)	Data  0.001 ( 0.002)	Loss 1.8310e-01 (2.1898e-01)	Acc@1  94.53 ( 93.75)	Acc@5 100.00 ( 99.73)
Epoch: [74][120/391]	Time  0.031 ( 0.034)	Data  0.001 ( 0.002)	Loss 2.0685e-01 (2.2050e-01)	Acc@1  93.75 ( 93.70)	Acc@5 100.00 ( 99.74)
Epoch: [74][130/391]	Time  0.031 ( 0.034)	Data  0.001 ( 0.002)	Loss 2.6607e-01 (2.2138e-01)	Acc@1  92.19 ( 93.68)	Acc@5  99.22 ( 99.74)
Epoch: [74][140/391]	Time  0.032 ( 0.034)	Data  0.002 ( 0.002)	Loss 2.1445e-01 (2.2157e-01)	Acc@1  92.97 ( 93.65)	Acc@5 100.00 ( 99.73)
Epoch: [74][150/391]	Time  0.032 ( 0.034)	Data  0.001 ( 0.002)	Loss 2.8058e-01 (2.2181e-01)	Acc@1  88.28 ( 93.59)	Acc@5  99.22 ( 99.74)
Epoch: [74][160/391]	Time  0.030 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.5773e-01 (2.2016e-01)	Acc@1  96.09 ( 93.66)	Acc@5 100.00 ( 99.75)
Epoch: [74][170/391]	Time  0.035 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.8215e-01 (2.1904e-01)	Acc@1  95.31 ( 93.69)	Acc@5 100.00 ( 99.76)
Epoch: [74][180/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.3664e-01 (2.1857e-01)	Acc@1  93.75 ( 93.70)	Acc@5  98.44 ( 99.75)
Epoch: [74][190/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.2711e-01 (2.1806e-01)	Acc@1  94.53 ( 93.73)	Acc@5  99.22 ( 99.75)
Epoch: [74][200/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.8101e-01 (2.1754e-01)	Acc@1  96.88 ( 93.75)	Acc@5 100.00 ( 99.75)
Epoch: [74][210/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.8145e-01 (2.1731e-01)	Acc@1  96.88 ( 93.76)	Acc@5 100.00 ( 99.76)
Epoch: [74][220/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.1737e-01 (2.1834e-01)	Acc@1  96.09 ( 93.73)	Acc@5 100.00 ( 99.75)
Epoch: [74][230/391]	Time  0.034 ( 0.033)	Data  0.002 ( 0.002)	Loss 2.1676e-01 (2.1814e-01)	Acc@1  92.97 ( 93.70)	Acc@5 100.00 ( 99.75)
Epoch: [74][240/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.3724e-01 (2.1902e-01)	Acc@1  91.41 ( 93.62)	Acc@5 100.00 ( 99.75)
Epoch: [74][250/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.3253e-01 (2.1887e-01)	Acc@1  92.19 ( 93.61)	Acc@5 100.00 ( 99.75)
Epoch: [74][260/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.6641e-01 (2.1937e-01)	Acc@1  92.19 ( 93.60)	Acc@5  99.22 ( 99.74)
Epoch: [74][270/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.7625e-01 (2.2025e-01)	Acc@1  94.53 ( 93.56)	Acc@5 100.00 ( 99.75)
Epoch: [74][280/391]	Time  0.033 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.1871e-01 (2.1929e-01)	Acc@1  93.75 ( 93.59)	Acc@5  99.22 ( 99.76)
Epoch: [74][290/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.0017e-01 (2.1964e-01)	Acc@1  95.31 ( 93.59)	Acc@5  99.22 ( 99.74)
Epoch: [74][300/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.4435e-01 (2.1982e-01)	Acc@1  96.88 ( 93.60)	Acc@5  99.22 ( 99.74)
Epoch: [74][310/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.7272e-01 (2.2018e-01)	Acc@1  96.09 ( 93.57)	Acc@5 100.00 ( 99.74)
Epoch: [74][320/391]	Time  0.033 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.5342e-01 (2.2017e-01)	Acc@1  93.75 ( 93.57)	Acc@5 100.00 ( 99.74)
Epoch: [74][330/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.7435e-01 (2.2002e-01)	Acc@1  93.75 ( 93.58)	Acc@5 100.00 ( 99.74)
Epoch: [74][340/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.2133e-01 (2.1972e-01)	Acc@1  89.84 ( 93.59)	Acc@5 100.00 ( 99.74)
Epoch: [74][350/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.5739e-01 (2.1966e-01)	Acc@1  90.62 ( 93.60)	Acc@5 100.00 ( 99.75)
Epoch: [74][360/391]	Time  0.038 ( 0.033)	Data  0.001 ( 0.001)	Loss 2.1988e-01 (2.1938e-01)	Acc@1  94.53 ( 93.61)	Acc@5  99.22 ( 99.75)
Epoch: [74][370/391]	Time  0.035 ( 0.033)	Data  0.001 ( 0.001)	Loss 1.5362e-01 (2.1906e-01)	Acc@1  95.31 ( 93.62)	Acc@5 100.00 ( 99.76)
Epoch: [74][380/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.001)	Loss 1.2884e-01 (2.1842e-01)	Acc@1  96.88 ( 93.63)	Acc@5 100.00 ( 99.76)
Epoch: [74][390/391]	Time  0.023 ( 0.033)	Data  0.001 ( 0.001)	Loss 2.2268e-01 (2.1746e-01)	Acc@1  92.50 ( 93.67)	Acc@5 100.00 ( 99.77)
## e[74] optimizer.zero_grad (sum) time: 0.09626269340515137
## e[74]       loss.backward (sum) time: 2.7076284885406494
## e[74]      optimizer.step (sum) time: 0.7214853763580322
## epoch[74] training(only) time: 12.978948593139648
# Switched to evaluate mode...
Test: [  0/100]	Time  0.160 ( 0.160)	Loss 1.2891e+00 (1.2891e+00)	Acc@1  72.00 ( 72.00)	Acc@5  89.00 ( 89.00)
Test: [ 10/100]	Time  0.024 ( 0.034)	Loss 1.4604e+00 (1.4771e+00)	Acc@1  66.00 ( 68.82)	Acc@5  91.00 ( 88.82)
Test: [ 20/100]	Time  0.024 ( 0.029)	Loss 1.1987e+00 (1.4271e+00)	Acc@1  75.00 ( 69.24)	Acc@5  92.00 ( 90.00)
Test: [ 30/100]	Time  0.022 ( 0.027)	Loss 1.7505e+00 (1.4516e+00)	Acc@1  57.00 ( 68.45)	Acc@5  90.00 ( 90.10)
Test: [ 40/100]	Time  0.024 ( 0.026)	Loss 1.4387e+00 (1.4504e+00)	Acc@1  66.00 ( 68.32)	Acc@5  90.00 ( 90.10)
Test: [ 50/100]	Time  0.019 ( 0.025)	Loss 1.5048e+00 (1.4565e+00)	Acc@1  66.00 ( 68.04)	Acc@5  91.00 ( 90.04)
Test: [ 60/100]	Time  0.017 ( 0.024)	Loss 1.5993e+00 (1.4311e+00)	Acc@1  65.00 ( 68.26)	Acc@5  87.00 ( 90.44)
Test: [ 70/100]	Time  0.020 ( 0.024)	Loss 1.6425e+00 (1.4307e+00)	Acc@1  68.00 ( 68.27)	Acc@5  87.00 ( 90.49)
Test: [ 80/100]	Time  0.024 ( 0.024)	Loss 1.5481e+00 (1.4373e+00)	Acc@1  71.00 ( 68.30)	Acc@5  88.00 ( 90.48)
Test: [ 90/100]	Time  0.024 ( 0.023)	Loss 1.7092e+00 (1.4240e+00)	Acc@1  65.00 ( 68.54)	Acc@5  86.00 ( 90.59)
 * Acc@1 68.860 Acc@5 90.710
### epoch[74] execution time: 15.362384796142578
EPOCH 75
REMOVING: module.fire7.expand_1x1.1.weight
REMOVING: module.fire7.expand_1x1.1.bias
i:   0, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.001046811488842940   to: 0.001000049431371019
i:   1, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.001097809994158216   to: 0.001010973022261990
i:   2, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.001166713170187582   to: 0.001040664539663676
i:   3, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.001253047226559294   to: 0.001088647495717814
i:   4, name:  module.fire8.squeeze.0.weight  changing lr from: 0.001356343091512007   to: 0.001154449398874196
i:   5, name:    module.fire8.squeeze.0.bias  changing lr from: 0.001476136676824973   to: 0.001237602063164399
i:   6, name:  module.fire8.squeeze.1.weight  changing lr from: 0.001611969120644568   to: 0.001337641893638152
i:   7, name:    module.fire8.squeeze.1.bias  changing lr from: 0.001763387009257405   to: 0.001454110149052678
i:   8, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.001929942578825466   to: 0.001586553182871835
i:   9, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.002111193898065144   to: 0.001734522663598503
i:  10, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.002306705032817740   to: 0.001897575775430082
i:  11, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.002516046193426279   to: 0.002075275400194481
i:  12, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.002738793865800231   to: 0.002267190281490821
i:  13, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.002974530927018076   to: 0.002472895171927419
i:  14, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.003222846746285440   to: 0.002691970964317580
i:  15, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.003483337272036129   to: 0.002924004807662622
i:  16, name:  module.fire9.squeeze.0.weight  changing lr from: 0.003755605105932696   to: 0.003168590208721139
i:  17, name:    module.fire9.squeeze.0.bias  changing lr from: 0.004039259564493585   to: 0.003425327119933096
i:  18, name:  module.fire9.squeeze.1.weight  changing lr from: 0.004333916729045217   to: 0.003693822014438513
i:  19, name:    module.fire9.squeeze.1.bias  changing lr from: 0.004639199484668921   to: 0.003973687948901189
i:  20, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.004954737548785315   to: 0.004264544614820386
i:  21, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.005280167489991715   to: 0.004566018378985614
i:  22, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.005615132737742789   to: 0.004877742313703270
i:  23, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.005959283583438673   to: 0.005199356217397760
i:  24, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.006312277173460934   to: 0.005530506626164743
i:  25, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.006673777494672717   to: 0.005870846816829261
i:  26, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.007043455352876360   to: 0.006220036802037986
i:  27, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.007420988344699868   to: 0.006577743317891787
i:  28, name:           module.conv10.weight  changing lr from: 0.007806060823361893   to: 0.006943639804602369
i:  29, name:             module.conv10.bias  changing lr from: 0.008198363858743906   to: 0.007317406380634905



# Switched to train mode...
Epoch: [75][  0/391]	Time  0.188 ( 0.188)	Data  0.150 ( 0.150)	Loss 2.1609e-01 (2.1609e-01)	Acc@1  92.97 ( 92.97)	Acc@5 100.00 (100.00)
Epoch: [75][ 10/391]	Time  0.036 ( 0.048)	Data  0.001 ( 0.015)	Loss 2.1371e-01 (1.9235e-01)	Acc@1  92.97 ( 94.32)	Acc@5 100.00 ( 99.93)
Epoch: [75][ 20/391]	Time  0.034 ( 0.041)	Data  0.001 ( 0.008)	Loss 2.7443e-01 (1.9853e-01)	Acc@1  89.84 ( 94.38)	Acc@5  99.22 ( 99.78)
Epoch: [75][ 30/391]	Time  0.031 ( 0.038)	Data  0.001 ( 0.006)	Loss 1.8996e-01 (2.0190e-01)	Acc@1  95.31 ( 94.15)	Acc@5 100.00 ( 99.77)
Epoch: [75][ 40/391]	Time  0.033 ( 0.036)	Data  0.001 ( 0.005)	Loss 1.4250e-01 (2.0505e-01)	Acc@1  96.09 ( 94.00)	Acc@5 100.00 ( 99.81)
Epoch: [75][ 50/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.004)	Loss 2.1541e-01 (2.0360e-01)	Acc@1  93.75 ( 94.09)	Acc@5  99.22 ( 99.79)
Epoch: [75][ 60/391]	Time  0.037 ( 0.035)	Data  0.001 ( 0.004)	Loss 2.2431e-01 (2.0615e-01)	Acc@1  93.75 ( 93.97)	Acc@5 100.00 ( 99.81)
Epoch: [75][ 70/391]	Time  0.034 ( 0.035)	Data  0.001 ( 0.003)	Loss 1.3135e-01 (2.0647e-01)	Acc@1  97.66 ( 93.98)	Acc@5 100.00 ( 99.78)
Epoch: [75][ 80/391]	Time  0.032 ( 0.034)	Data  0.001 ( 0.003)	Loss 1.7334e-01 (2.0577e-01)	Acc@1  97.66 ( 94.08)	Acc@5 100.00 ( 99.78)
Epoch: [75][ 90/391]	Time  0.032 ( 0.034)	Data  0.001 ( 0.003)	Loss 2.6027e-01 (2.0721e-01)	Acc@1  91.41 ( 94.07)	Acc@5  99.22 ( 99.75)
Epoch: [75][100/391]	Time  0.031 ( 0.034)	Data  0.001 ( 0.003)	Loss 2.2400e-01 (2.0656e-01)	Acc@1  92.19 ( 94.08)	Acc@5 100.00 ( 99.75)
Epoch: [75][110/391]	Time  0.031 ( 0.034)	Data  0.001 ( 0.002)	Loss 2.9254e-01 (2.1131e-01)	Acc@1  90.62 ( 94.00)	Acc@5 100.00 ( 99.73)
Epoch: [75][120/391]	Time  0.031 ( 0.034)	Data  0.001 ( 0.002)	Loss 1.5559e-01 (2.1094e-01)	Acc@1  96.09 ( 94.01)	Acc@5 100.00 ( 99.74)
Epoch: [75][130/391]	Time  0.032 ( 0.034)	Data  0.001 ( 0.002)	Loss 1.5338e-01 (2.1105e-01)	Acc@1  98.44 ( 94.00)	Acc@5 100.00 ( 99.76)
Epoch: [75][140/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.3053e-01 (2.1023e-01)	Acc@1  92.19 ( 93.98)	Acc@5 100.00 ( 99.77)
Epoch: [75][150/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.5215e-01 (2.0950e-01)	Acc@1  96.09 ( 94.00)	Acc@5 100.00 ( 99.76)
Epoch: [75][160/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.6901e-01 (2.0801e-01)	Acc@1  95.31 ( 94.07)	Acc@5  99.22 ( 99.77)
Epoch: [75][170/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.3240e-01 (2.0802e-01)	Acc@1  93.75 ( 94.05)	Acc@5 100.00 ( 99.77)
Epoch: [75][180/391]	Time  0.033 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.7092e-01 (2.0821e-01)	Acc@1  91.41 ( 94.04)	Acc@5  99.22 ( 99.77)
Epoch: [75][190/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.5565e-01 (2.0761e-01)	Acc@1  96.09 ( 94.06)	Acc@5 100.00 ( 99.78)
Epoch: [75][200/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.8100e-01 (2.0827e-01)	Acc@1  96.09 ( 94.04)	Acc@5 100.00 ( 99.77)
Epoch: [75][210/391]	Time  0.034 ( 0.033)	Data  0.001 ( 0.002)	Loss 3.1076e-01 (2.0853e-01)	Acc@1  89.06 ( 94.02)	Acc@5  99.22 ( 99.76)
Epoch: [75][220/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.1040e-01 (2.0994e-01)	Acc@1  92.97 ( 93.97)	Acc@5 100.00 ( 99.77)
Epoch: [75][230/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.0087e-01 (2.1054e-01)	Acc@1  93.75 ( 93.94)	Acc@5  99.22 ( 99.76)
Epoch: [75][240/391]	Time  0.033 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.1032e-01 (2.1084e-01)	Acc@1  94.53 ( 93.95)	Acc@5 100.00 ( 99.76)
Epoch: [75][250/391]	Time  0.035 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.9183e-01 (2.1062e-01)	Acc@1  94.53 ( 93.99)	Acc@5 100.00 ( 99.76)
Epoch: [75][260/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.0957e-01 (2.1001e-01)	Acc@1  93.75 ( 94.01)	Acc@5  99.22 ( 99.75)
Epoch: [75][270/391]	Time  0.029 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.6030e-01 (2.1075e-01)	Acc@1  92.97 ( 93.97)	Acc@5 100.00 ( 99.75)
Epoch: [75][280/391]	Time  0.033 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.3702e-01 (2.1097e-01)	Acc@1  96.09 ( 93.94)	Acc@5 100.00 ( 99.75)
Epoch: [75][290/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.3015e-01 (2.1095e-01)	Acc@1  92.19 ( 93.95)	Acc@5 100.00 ( 99.76)
Epoch: [75][300/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.5700e-01 (2.1207e-01)	Acc@1  89.84 ( 93.92)	Acc@5  99.22 ( 99.76)
Epoch: [75][310/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.5225e-01 (2.1288e-01)	Acc@1  91.41 ( 93.87)	Acc@5  99.22 ( 99.74)
Epoch: [75][320/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.6583e-01 (2.1323e-01)	Acc@1  92.97 ( 93.85)	Acc@5 100.00 ( 99.74)
Epoch: [75][330/391]	Time  0.033 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.3798e-01 (2.1325e-01)	Acc@1  91.41 ( 93.86)	Acc@5 100.00 ( 99.74)
Epoch: [75][340/391]	Time  0.035 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.0063e-01 (2.1352e-01)	Acc@1  96.09 ( 93.87)	Acc@5 100.00 ( 99.74)
Epoch: [75][350/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.9775e-01 (2.1449e-01)	Acc@1  92.97 ( 93.83)	Acc@5 100.00 ( 99.74)
Epoch: [75][360/391]	Time  0.036 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.2501e-01 (2.1457e-01)	Acc@1  92.97 ( 93.82)	Acc@5 100.00 ( 99.74)
Epoch: [75][370/391]	Time  0.036 ( 0.033)	Data  0.001 ( 0.001)	Loss 2.2154e-01 (2.1467e-01)	Acc@1  93.75 ( 93.80)	Acc@5  99.22 ( 99.74)
Epoch: [75][380/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.001)	Loss 2.3334e-01 (2.1524e-01)	Acc@1  94.53 ( 93.80)	Acc@5 100.00 ( 99.74)
Epoch: [75][390/391]	Time  0.022 ( 0.033)	Data  0.001 ( 0.001)	Loss 2.2774e-01 (2.1526e-01)	Acc@1  95.00 ( 93.80)	Acc@5 100.00 ( 99.74)
## e[75] optimizer.zero_grad (sum) time: 0.09157896041870117
## e[75]       loss.backward (sum) time: 2.6501858234405518
## e[75]      optimizer.step (sum) time: 0.6895961761474609
## epoch[75] training(only) time: 12.889148473739624
# Switched to evaluate mode...
Test: [  0/100]	Time  0.156 ( 0.156)	Loss 1.2411e+00 (1.2411e+00)	Acc@1  71.00 ( 71.00)	Acc@5  91.00 ( 91.00)
Test: [ 10/100]	Time  0.022 ( 0.034)	Loss 1.4762e+00 (1.4649e+00)	Acc@1  69.00 ( 68.27)	Acc@5  91.00 ( 89.55)
Test: [ 20/100]	Time  0.025 ( 0.028)	Loss 1.2021e+00 (1.4187e+00)	Acc@1  77.00 ( 69.00)	Acc@5  93.00 ( 90.57)
Test: [ 30/100]	Time  0.026 ( 0.025)	Loss 1.7680e+00 (1.4488e+00)	Acc@1  62.00 ( 68.45)	Acc@5  89.00 ( 90.52)
Test: [ 40/100]	Time  0.018 ( 0.024)	Loss 1.4179e+00 (1.4548e+00)	Acc@1  67.00 ( 68.39)	Acc@5  91.00 ( 90.46)
Test: [ 50/100]	Time  0.023 ( 0.023)	Loss 1.5255e+00 (1.4634e+00)	Acc@1  67.00 ( 68.27)	Acc@5  91.00 ( 90.35)
Test: [ 60/100]	Time  0.021 ( 0.023)	Loss 1.5994e+00 (1.4385e+00)	Acc@1  66.00 ( 68.49)	Acc@5  84.00 ( 90.59)
Test: [ 70/100]	Time  0.020 ( 0.023)	Loss 1.6783e+00 (1.4387e+00)	Acc@1  70.00 ( 68.58)	Acc@5  86.00 ( 90.56)
Test: [ 80/100]	Time  0.023 ( 0.023)	Loss 1.5550e+00 (1.4449e+00)	Acc@1  70.00 ( 68.64)	Acc@5  90.00 ( 90.49)
Test: [ 90/100]	Time  0.018 ( 0.022)	Loss 1.7558e+00 (1.4326e+00)	Acc@1  63.00 ( 68.85)	Acc@5  87.00 ( 90.59)
 * Acc@1 69.150 Acc@5 90.680
### epoch[75] execution time: 15.182708263397217
EPOCH 76
REMOVING: module.fire7.expand_3x3.0.weight
REMOVING: module.fire7.expand_3x3.0.bias
REMOVING: module.fire7.expand_3x3.1.weight
i:   0, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.001088647495717814   to: 0.001008521301549080
i:   1, name:  module.fire8.squeeze.0.weight  changing lr from: 0.001154449398874196   to: 0.001035680321383708
i:   2, name:    module.fire8.squeeze.0.bias  changing lr from: 0.001237602063164399   to: 0.001081032182975549
i:   3, name:  module.fire8.squeeze.1.weight  changing lr from: 0.001337641893638152   to: 0.001144110063154496
i:   4, name:    module.fire8.squeeze.1.bias  changing lr from: 0.001454110149052678   to: 0.001224451328897041
i:   5, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.001586553182871835   to: 0.001321597819700337
i:   6, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.001734522663598503   to: 0.001435096107656280
i:   7, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.001897575775430082   to: 0.001564497736254899
i:   8, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.002075275400194481   to: 0.001709359438914053
i:   9, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.002267190281490821   to: 0.001869243338200188
i:  10, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.002472895171927419   to: 0.002043717126673283
i:  11, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.002691970964317580   to: 0.002232354230257177
i:  12, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.002924004807662622   to: 0.002434733955005807
i:  13, name:  module.fire9.squeeze.0.weight  changing lr from: 0.003168590208721139   to: 0.002650441618104853
i:  14, name:    module.fire9.squeeze.0.bias  changing lr from: 0.003425327119933096   to: 0.002879068663918188
i:  15, name:  module.fire9.squeeze.1.weight  changing lr from: 0.003693822014438513   to: 0.003120212765859070
i:  16, name:    module.fire9.squeeze.1.bias  changing lr from: 0.003973687948901189   to: 0.003373477914836681
i:  17, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.004264544614820386   to: 0.003638474495000248
i:  18, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.004566018378985614   to: 0.003914819347475267
i:  19, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.004877742313703270   to: 0.004202135822758828
i:  20, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.005199356217397760   to: 0.004500053822414778
i:  21, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.005530506626164743   to: 0.004808209830683568
i:  22, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.005870846816829261   to: 0.005126246936596212
i:  23, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.006220036802037986   to: 0.005453814847157400
i:  24, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.006577743317891787   to: 0.005790569892139241
i:  25, name:           module.conv10.weight  changing lr from: 0.006943639804602369   to: 0.006136175021003542
i:  26, name:             module.conv10.bias  changing lr from: 0.007317406380634905   to: 0.006490299792448495



# Switched to train mode...
Epoch: [76][  0/391]	Time  0.191 ( 0.191)	Data  0.154 ( 0.154)	Loss 2.2660e-01 (2.2660e-01)	Acc@1  90.62 ( 90.62)	Acc@5  99.22 ( 99.22)
Epoch: [76][ 10/391]	Time  0.030 ( 0.047)	Data  0.001 ( 0.015)	Loss 2.8416e-01 (2.0153e-01)	Acc@1  92.19 ( 94.46)	Acc@5  99.22 ( 99.72)
Epoch: [76][ 20/391]	Time  0.041 ( 0.040)	Data  0.001 ( 0.008)	Loss 2.8953e-01 (2.0857e-01)	Acc@1  91.41 ( 94.05)	Acc@5  99.22 ( 99.78)
Epoch: [76][ 30/391]	Time  0.031 ( 0.037)	Data  0.001 ( 0.006)	Loss 1.9118e-01 (2.0656e-01)	Acc@1  95.31 ( 94.13)	Acc@5 100.00 ( 99.77)
Epoch: [76][ 40/391]	Time  0.032 ( 0.036)	Data  0.001 ( 0.005)	Loss 2.0884e-01 (2.0560e-01)	Acc@1  96.09 ( 94.13)	Acc@5  99.22 ( 99.79)
Epoch: [76][ 50/391]	Time  0.032 ( 0.035)	Data  0.001 ( 0.004)	Loss 2.6539e-01 (2.0953e-01)	Acc@1  90.62 ( 94.06)	Acc@5  98.44 ( 99.74)
Epoch: [76][ 60/391]	Time  0.030 ( 0.035)	Data  0.001 ( 0.004)	Loss 2.5527e-01 (2.1198e-01)	Acc@1  89.84 ( 93.97)	Acc@5  99.22 ( 99.73)
Epoch: [76][ 70/391]	Time  0.031 ( 0.034)	Data  0.001 ( 0.003)	Loss 2.0004e-01 (2.0964e-01)	Acc@1  92.97 ( 94.04)	Acc@5 100.00 ( 99.74)
Epoch: [76][ 80/391]	Time  0.031 ( 0.034)	Data  0.001 ( 0.003)	Loss 1.8800e-01 (2.0856e-01)	Acc@1  93.75 ( 94.00)	Acc@5 100.00 ( 99.76)
Epoch: [76][ 90/391]	Time  0.035 ( 0.034)	Data  0.001 ( 0.003)	Loss 1.8516e-01 (2.1034e-01)	Acc@1  95.31 ( 93.88)	Acc@5 100.00 ( 99.76)
Epoch: [76][100/391]	Time  0.031 ( 0.034)	Data  0.001 ( 0.003)	Loss 2.0675e-01 (2.0982e-01)	Acc@1  92.19 ( 93.91)	Acc@5 100.00 ( 99.77)
Epoch: [76][110/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.8224e-01 (2.1086e-01)	Acc@1  94.53 ( 93.82)	Acc@5 100.00 ( 99.77)
Epoch: [76][120/391]	Time  0.035 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.1142e-01 (2.1186e-01)	Acc@1  92.97 ( 93.70)	Acc@5 100.00 ( 99.77)
Epoch: [76][130/391]	Time  0.034 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.2760e-01 (2.1154e-01)	Acc@1  91.41 ( 93.68)	Acc@5  99.22 ( 99.77)
Epoch: [76][140/391]	Time  0.033 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.0150e-01 (2.1214e-01)	Acc@1  95.31 ( 93.72)	Acc@5 100.00 ( 99.77)
Epoch: [76][150/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.9016e-01 (2.1303e-01)	Acc@1  92.97 ( 93.66)	Acc@5 100.00 ( 99.76)
Epoch: [76][160/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.7236e-01 (2.1187e-01)	Acc@1  96.09 ( 93.72)	Acc@5 100.00 ( 99.76)
Epoch: [76][170/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.2784e-01 (2.1078e-01)	Acc@1  89.84 ( 93.76)	Acc@5 100.00 ( 99.77)
Epoch: [76][180/391]	Time  0.033 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.4177e-01 (2.1006e-01)	Acc@1  92.19 ( 93.78)	Acc@5 100.00 ( 99.77)
Epoch: [76][190/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.1576e-01 (2.0993e-01)	Acc@1  92.19 ( 93.76)	Acc@5 100.00 ( 99.78)
Epoch: [76][200/391]	Time  0.036 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.4004e-01 (2.0898e-01)	Acc@1  98.44 ( 93.85)	Acc@5 100.00 ( 99.78)
Epoch: [76][210/391]	Time  0.029 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.8458e-01 (2.0839e-01)	Acc@1  90.62 ( 93.88)	Acc@5  99.22 ( 99.77)
Epoch: [76][220/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.1248e-01 (2.0793e-01)	Acc@1  94.53 ( 93.92)	Acc@5 100.00 ( 99.77)
Epoch: [76][230/391]	Time  0.032 ( 0.033)	Data  0.002 ( 0.002)	Loss 1.9695e-01 (2.0821e-01)	Acc@1  92.97 ( 93.89)	Acc@5 100.00 ( 99.77)
Epoch: [76][240/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.0955e-01 (2.0833e-01)	Acc@1  92.97 ( 93.89)	Acc@5 100.00 ( 99.77)
Epoch: [76][250/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.9414e-01 (2.0859e-01)	Acc@1  94.53 ( 93.88)	Acc@5 100.00 ( 99.76)
Epoch: [76][260/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.4243e-01 (2.0825e-01)	Acc@1  98.44 ( 93.91)	Acc@5 100.00 ( 99.76)
Epoch: [76][270/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.3513e-01 (2.0843e-01)	Acc@1  93.75 ( 93.92)	Acc@5  99.22 ( 99.75)
Epoch: [76][280/391]	Time  0.035 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.7230e-01 (2.0834e-01)	Acc@1  96.09 ( 93.93)	Acc@5  99.22 ( 99.76)
Epoch: [76][290/391]	Time  0.033 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.4169e-01 (2.0802e-01)	Acc@1  96.09 ( 93.94)	Acc@5 100.00 ( 99.76)
Epoch: [76][300/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.7201e-01 (2.0820e-01)	Acc@1  89.84 ( 93.97)	Acc@5  99.22 ( 99.76)
Epoch: [76][310/391]	Time  0.033 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.4750e-01 (2.0888e-01)	Acc@1  93.75 ( 93.95)	Acc@5 100.00 ( 99.76)
Epoch: [76][320/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.5009e-01 (2.0884e-01)	Acc@1  96.09 ( 93.95)	Acc@5 100.00 ( 99.76)
Epoch: [76][330/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.6432e-01 (2.0917e-01)	Acc@1  89.06 ( 93.92)	Acc@5 100.00 ( 99.76)
Epoch: [76][340/391]	Time  0.035 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.6125e-01 (2.0882e-01)	Acc@1  94.53 ( 93.94)	Acc@5 100.00 ( 99.76)
Epoch: [76][350/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.3989e-01 (2.0989e-01)	Acc@1  94.53 ( 93.92)	Acc@5  99.22 ( 99.76)
Epoch: [76][360/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.8103e-01 (2.0977e-01)	Acc@1  94.53 ( 93.94)	Acc@5 100.00 ( 99.76)
Epoch: [76][370/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.0075e-01 (2.1086e-01)	Acc@1  94.53 ( 93.90)	Acc@5 100.00 ( 99.76)
Epoch: [76][380/391]	Time  0.030 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.9912e-01 (2.1082e-01)	Acc@1  96.09 ( 93.92)	Acc@5  99.22 ( 99.75)
Epoch: [76][390/391]	Time  0.021 ( 0.032)	Data  0.000 ( 0.002)	Loss 3.6165e-01 (2.1127e-01)	Acc@1  88.75 ( 93.89)	Acc@5 100.00 ( 99.76)
## e[76] optimizer.zero_grad (sum) time: 0.08264780044555664
## e[76]       loss.backward (sum) time: 2.670067071914673
## e[76]      optimizer.step (sum) time: 0.6361868381500244
## epoch[76] training(only) time: 12.801945209503174
# Switched to evaluate mode...
Test: [  0/100]	Time  0.158 ( 0.158)	Loss 1.2571e+00 (1.2571e+00)	Acc@1  72.00 ( 72.00)	Acc@5  91.00 ( 91.00)
Test: [ 10/100]	Time  0.024 ( 0.035)	Loss 1.4380e+00 (1.4636e+00)	Acc@1  71.00 ( 69.64)	Acc@5  91.00 ( 89.45)
Test: [ 20/100]	Time  0.024 ( 0.029)	Loss 1.2161e+00 (1.4118e+00)	Acc@1  76.00 ( 70.24)	Acc@5  93.00 ( 90.14)
Test: [ 30/100]	Time  0.023 ( 0.027)	Loss 1.7804e+00 (1.4448e+00)	Acc@1  57.00 ( 69.06)	Acc@5  91.00 ( 90.29)
Test: [ 40/100]	Time  0.018 ( 0.025)	Loss 1.4386e+00 (1.4467e+00)	Acc@1  68.00 ( 69.05)	Acc@5  91.00 ( 90.37)
Test: [ 50/100]	Time  0.024 ( 0.024)	Loss 1.5113e+00 (1.4567e+00)	Acc@1  70.00 ( 68.59)	Acc@5  90.00 ( 90.25)
Test: [ 60/100]	Time  0.024 ( 0.024)	Loss 1.6376e+00 (1.4320e+00)	Acc@1  66.00 ( 68.64)	Acc@5  87.00 ( 90.67)
Test: [ 70/100]	Time  0.021 ( 0.024)	Loss 1.6898e+00 (1.4343e+00)	Acc@1  70.00 ( 68.63)	Acc@5  87.00 ( 90.72)
Test: [ 80/100]	Time  0.021 ( 0.024)	Loss 1.5248e+00 (1.4408e+00)	Acc@1  74.00 ( 68.73)	Acc@5  87.00 ( 90.64)
Test: [ 90/100]	Time  0.022 ( 0.024)	Loss 1.7302e+00 (1.4268e+00)	Acc@1  63.00 ( 68.91)	Acc@5  86.00 ( 90.71)
 * Acc@1 69.210 Acc@5 90.810
### epoch[76] execution time: 15.242131233215332
EPOCH 77
REMOVING: module.fire7.expand_3x3.1.bias
REMOVING: module.fire8.squeeze.0.weight
i:   0, name:    module.fire8.squeeze.0.bias  changing lr from: 0.001081032182975549   to: 0.001006684925930772
i:   1, name:  module.fire8.squeeze.1.weight  changing lr from: 0.001144110063154496   to: 0.001031688484983378
i:   2, name:    module.fire8.squeeze.1.bias  changing lr from: 0.001224451328897041   to: 0.001074779600293984
i:   3, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.001321597819700337   to: 0.001135497053327027
i:   4, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.001435096107656280   to: 0.001213383709259207
i:   5, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.001564497736254899   to: 0.001307986795944504
i:   6, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.001709359438914053   to: 0.001418858161030522
i:   7, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.001869243338200188   to: 0.001545554508228330
i:   8, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.002043717126673283   to: 0.001687637613706971
i:   9, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.002232354230257177   to: 0.001844674523552469
i:  10, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.002434733955005807   to: 0.002016237733200620
i:  11, name:  module.fire9.squeeze.0.weight  changing lr from: 0.002650441618104853   to: 0.002201905349722088
i:  12, name:    module.fire9.squeeze.0.bias  changing lr from: 0.002879068663918188   to: 0.002401261237808415
i:  13, name:  module.fire9.squeeze.1.weight  changing lr from: 0.003120212765859070   to: 0.002613895150277761
i:  14, name:    module.fire9.squeeze.1.bias  changing lr from: 0.003373477914836681   to: 0.002839402843889920
i:  15, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.003638474495000248   to: 0.003077386181231672
i:  16, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.003914819347475267   to: 0.003327453219404918
i:  17, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.004202135822758828   to: 0.003589218286223017
i:  18, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.004500053822414778   to: 0.003862302044593246
i:  19, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.004808209830683568   to: 0.004146331545737230
i:  20, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.005126246936596212   to: 0.004440940271875315
i:  21, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.005453814847157400   to: 0.004745768168975672
i:  22, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.005790569892139241   to: 0.005060461670144711
i:  23, name:           module.conv10.weight  changing lr from: 0.006136175021003542   to: 0.005384673710211318
i:  24, name:             module.conv10.bias  changing lr from: 0.006490299792448495   to: 0.005718063732034539



# Switched to train mode...
Epoch: [77][  0/391]	Time  0.193 ( 0.193)	Data  0.153 ( 0.153)	Loss 1.6683e-01 (1.6683e-01)	Acc@1  94.53 ( 94.53)	Acc@5 100.00 (100.00)
Epoch: [77][ 10/391]	Time  0.032 ( 0.047)	Data  0.001 ( 0.015)	Loss 2.7985e-01 (1.9124e-01)	Acc@1  93.75 ( 94.39)	Acc@5 100.00 ( 99.72)
Epoch: [77][ 20/391]	Time  0.031 ( 0.041)	Data  0.001 ( 0.008)	Loss 1.8839e-01 (2.0324e-01)	Acc@1  95.31 ( 93.90)	Acc@5 100.00 ( 99.70)
Epoch: [77][ 30/391]	Time  0.031 ( 0.038)	Data  0.001 ( 0.006)	Loss 2.6021e-01 (2.0542e-01)	Acc@1  92.19 ( 94.00)	Acc@5  99.22 ( 99.75)
Epoch: [77][ 40/391]	Time  0.036 ( 0.037)	Data  0.001 ( 0.005)	Loss 2.3171e-01 (2.0418e-01)	Acc@1  93.75 ( 94.17)	Acc@5  99.22 ( 99.73)
Epoch: [77][ 50/391]	Time  0.032 ( 0.036)	Data  0.001 ( 0.004)	Loss 1.9781e-01 (2.0460e-01)	Acc@1  95.31 ( 94.13)	Acc@5 100.00 ( 99.74)
Epoch: [77][ 60/391]	Time  0.033 ( 0.035)	Data  0.001 ( 0.004)	Loss 2.3509e-01 (2.0362e-01)	Acc@1  92.97 ( 94.24)	Acc@5  99.22 ( 99.73)
Epoch: [77][ 70/391]	Time  0.030 ( 0.035)	Data  0.001 ( 0.003)	Loss 2.7324e-01 (2.0583e-01)	Acc@1  93.75 ( 94.21)	Acc@5  98.44 ( 99.70)
Epoch: [77][ 80/391]	Time  0.032 ( 0.034)	Data  0.001 ( 0.003)	Loss 2.9799e-01 (2.0669e-01)	Acc@1  90.62 ( 94.13)	Acc@5 100.00 ( 99.72)
Epoch: [77][ 90/391]	Time  0.033 ( 0.034)	Data  0.001 ( 0.003)	Loss 1.5408e-01 (2.0431e-01)	Acc@1  95.31 ( 94.15)	Acc@5 100.00 ( 99.73)
Epoch: [77][100/391]	Time  0.030 ( 0.034)	Data  0.001 ( 0.003)	Loss 2.7378e-01 (2.0467e-01)	Acc@1  92.19 ( 94.10)	Acc@5  99.22 ( 99.74)
Epoch: [77][110/391]	Time  0.028 ( 0.034)	Data  0.001 ( 0.003)	Loss 1.4540e-01 (2.0526e-01)	Acc@1  95.31 ( 94.15)	Acc@5 100.00 ( 99.72)
Epoch: [77][120/391]	Time  0.033 ( 0.034)	Data  0.001 ( 0.002)	Loss 1.5794e-01 (2.0418e-01)	Acc@1  95.31 ( 94.14)	Acc@5 100.00 ( 99.72)
Epoch: [77][130/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.7910e-01 (2.0380e-01)	Acc@1  96.09 ( 94.22)	Acc@5 100.00 ( 99.74)
Epoch: [77][140/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.9510e-01 (2.0579e-01)	Acc@1  96.09 ( 94.14)	Acc@5  99.22 ( 99.74)
Epoch: [77][150/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.4142e-01 (2.0794e-01)	Acc@1  92.97 ( 94.09)	Acc@5  99.22 ( 99.74)
Epoch: [77][160/391]	Time  0.030 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.9030e-01 (2.0758e-01)	Acc@1  90.62 ( 94.14)	Acc@5  99.22 ( 99.74)
Epoch: [77][170/391]	Time  0.033 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.9268e-01 (2.0706e-01)	Acc@1  94.53 ( 94.15)	Acc@5 100.00 ( 99.74)
Epoch: [77][180/391]	Time  0.033 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.1513e-01 (2.0673e-01)	Acc@1  95.31 ( 94.16)	Acc@5  99.22 ( 99.74)
Epoch: [77][190/391]	Time  0.030 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.6486e-01 (2.0562e-01)	Acc@1  96.09 ( 94.21)	Acc@5 100.00 ( 99.74)
Epoch: [77][200/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.5753e-01 (2.0452e-01)	Acc@1  96.88 ( 94.27)	Acc@5  99.22 ( 99.74)
Epoch: [77][210/391]	Time  0.039 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.6795e-01 (2.0468e-01)	Acc@1  93.75 ( 94.25)	Acc@5 100.00 ( 99.74)
Epoch: [77][220/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.7554e-01 (2.0479e-01)	Acc@1  90.62 ( 94.22)	Acc@5 100.00 ( 99.75)
Epoch: [77][230/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.7091e-01 (2.0425e-01)	Acc@1  95.31 ( 94.24)	Acc@5 100.00 ( 99.75)
Epoch: [77][240/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.9864e-01 (2.0512e-01)	Acc@1  96.09 ( 94.25)	Acc@5 100.00 ( 99.75)
Epoch: [77][250/391]	Time  0.030 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.3187e-01 (2.0529e-01)	Acc@1  91.41 ( 94.22)	Acc@5 100.00 ( 99.76)
Epoch: [77][260/391]	Time  0.030 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.6499e-01 (2.0462e-01)	Acc@1  96.09 ( 94.24)	Acc@5 100.00 ( 99.75)
Epoch: [77][270/391]	Time  0.040 ( 0.033)	Data  0.000 ( 0.002)	Loss 1.4680e-01 (2.0380e-01)	Acc@1  95.31 ( 94.28)	Acc@5 100.00 ( 99.76)
Epoch: [77][280/391]	Time  0.034 ( 0.033)	Data  0.001 ( 0.002)	Loss 3.1487e-01 (2.0434e-01)	Acc@1  89.84 ( 94.23)	Acc@5 100.00 ( 99.76)
Epoch: [77][290/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 3.0322e-01 (2.0446e-01)	Acc@1  90.62 ( 94.24)	Acc@5  98.44 ( 99.76)
Epoch: [77][300/391]	Time  0.035 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.5365e-01 (2.0405e-01)	Acc@1  96.88 ( 94.27)	Acc@5 100.00 ( 99.76)
Epoch: [77][310/391]	Time  0.033 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.9966e-01 (2.0420e-01)	Acc@1  92.97 ( 94.26)	Acc@5 100.00 ( 99.76)
Epoch: [77][320/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.0926e-01 (2.0334e-01)	Acc@1  91.41 ( 94.27)	Acc@5 100.00 ( 99.77)
Epoch: [77][330/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.6400e-01 (2.0372e-01)	Acc@1  97.66 ( 94.26)	Acc@5 100.00 ( 99.77)
Epoch: [77][340/391]	Time  0.034 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.4992e-01 (2.0403e-01)	Acc@1  95.31 ( 94.24)	Acc@5 100.00 ( 99.77)
Epoch: [77][350/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.4923e-01 (2.0485e-01)	Acc@1  96.09 ( 94.22)	Acc@5 100.00 ( 99.76)
Epoch: [77][360/391]	Time  0.035 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.8570e-01 (2.0479e-01)	Acc@1  93.75 ( 94.21)	Acc@5 100.00 ( 99.77)
Epoch: [77][370/391]	Time  0.033 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.3736e-01 (2.0527e-01)	Acc@1  95.31 ( 94.19)	Acc@5  99.22 ( 99.77)
Epoch: [77][380/391]	Time  0.040 ( 0.033)	Data  0.001 ( 0.002)	Loss 3.0106e-01 (2.0572e-01)	Acc@1  90.62 ( 94.17)	Acc@5  99.22 ( 99.76)
Epoch: [77][390/391]	Time  0.022 ( 0.033)	Data  0.001 ( 0.002)	Loss 3.3672e-01 (2.0672e-01)	Acc@1  90.00 ( 94.12)	Acc@5  98.75 ( 99.76)
## e[77] optimizer.zero_grad (sum) time: 0.07614564895629883
## e[77]       loss.backward (sum) time: 2.5412423610687256
## e[77]      optimizer.step (sum) time: 0.6028480529785156
## epoch[77] training(only) time: 12.855164766311646
# Switched to evaluate mode...
Test: [  0/100]	Time  0.146 ( 0.146)	Loss 1.3053e+00 (1.3053e+00)	Acc@1  72.00 ( 72.00)	Acc@5  90.00 ( 90.00)
Test: [ 10/100]	Time  0.023 ( 0.034)	Loss 1.4617e+00 (1.4796e+00)	Acc@1  71.00 ( 68.64)	Acc@5  92.00 ( 89.27)
Test: [ 20/100]	Time  0.021 ( 0.029)	Loss 1.2045e+00 (1.4282e+00)	Acc@1  76.00 ( 69.24)	Acc@5  94.00 ( 90.19)
Test: [ 30/100]	Time  0.024 ( 0.027)	Loss 1.7358e+00 (1.4563e+00)	Acc@1  62.00 ( 68.29)	Acc@5  92.00 ( 90.35)
Test: [ 40/100]	Time  0.016 ( 0.025)	Loss 1.4108e+00 (1.4544e+00)	Acc@1  67.00 ( 68.24)	Acc@5  91.00 ( 90.37)
Test: [ 50/100]	Time  0.024 ( 0.025)	Loss 1.5116e+00 (1.4639e+00)	Acc@1  69.00 ( 68.20)	Acc@5  91.00 ( 90.31)
Test: [ 60/100]	Time  0.018 ( 0.024)	Loss 1.5941e+00 (1.4380e+00)	Acc@1  65.00 ( 68.41)	Acc@5  86.00 ( 90.72)
Test: [ 70/100]	Time  0.020 ( 0.024)	Loss 1.6389e+00 (1.4378e+00)	Acc@1  68.00 ( 68.44)	Acc@5  87.00 ( 90.77)
Test: [ 80/100]	Time  0.021 ( 0.024)	Loss 1.5339e+00 (1.4417e+00)	Acc@1  70.00 ( 68.48)	Acc@5  90.00 ( 90.63)
Test: [ 90/100]	Time  0.024 ( 0.024)	Loss 1.7524e+00 (1.4294e+00)	Acc@1  66.00 ( 68.80)	Acc@5  87.00 ( 90.73)
 * Acc@1 69.000 Acc@5 90.870
### epoch[77] execution time: 15.272936820983887
EPOCH 78
REMOVING: module.fire8.squeeze.0.bias
REMOVING: module.fire8.squeeze.1.weight
i:   0, name:    module.fire8.squeeze.1.bias  changing lr from: 0.001074779600293984   to: 0.001005335479050528
i:   1, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.001135497053327027   to: 0.001028546281756925
i:   2, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.001213383709259207   to: 0.001069733097291952
i:   3, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.001307986795944504   to: 0.001128440245871042
i:   4, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.001418858161030522   to: 0.001204216033518750
i:   5, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.001545554508228330   to: 0.001296613027309639
i:   6, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.001687637613706971   to: 0.001405188309214843
i:   7, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.001844674523552469   to: 0.001529503709529888
i:   8, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.002016237733200620   to: 0.001669126020829503
i:   9, name:  module.fire9.squeeze.0.weight  changing lr from: 0.002201905349722088   to: 0.001823627193364796
i:  10, name:    module.fire9.squeeze.0.bias  changing lr from: 0.002401261237808415   to: 0.001992584512788558
i:  11, name:  module.fire9.squeeze.1.weight  changing lr from: 0.002613895150277761   to: 0.002175580761064893
i:  12, name:    module.fire9.squeeze.1.bias  changing lr from: 0.002839402843889920   to: 0.002372204361390106
i:  13, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.003077386181231672   to: 0.002582049507923378
i:  14, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.003327453219404918   to: 0.002804716281096863
i:  15, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.003589218286223017   to: 0.003039810749247784
i:  16, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.003862302044593246   to: 0.003286945057287066
i:  17, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.004146331545737230   to: 0.003545737503092893
i:  18, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.004440940271875315   to: 0.003815812602291096
i:  19, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.004745768168975672   to: 0.004096801142058558
i:  20, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.005060461670144711   to: 0.004388340224561398
i:  21, name:           module.conv10.weight  changing lr from: 0.005384673710211318   to: 0.004690073300614627
i:  22, name:             module.conv10.bias  changing lr from: 0.005718063732034539   to: 0.005001650194126833



# Switched to train mode...
Epoch: [78][  0/391]	Time  0.188 ( 0.188)	Data  0.151 ( 0.151)	Loss 1.8645e-01 (1.8645e-01)	Acc@1  96.09 ( 96.09)	Acc@5 100.00 (100.00)
Epoch: [78][ 10/391]	Time  0.031 ( 0.047)	Data  0.001 ( 0.015)	Loss 1.9572e-01 (1.9363e-01)	Acc@1  95.31 ( 95.03)	Acc@5  99.22 ( 99.86)
Epoch: [78][ 20/391]	Time  0.032 ( 0.040)	Data  0.001 ( 0.008)	Loss 1.9349e-01 (2.0596e-01)	Acc@1  94.53 ( 94.16)	Acc@5 100.00 ( 99.85)
Epoch: [78][ 30/391]	Time  0.030 ( 0.037)	Data  0.001 ( 0.006)	Loss 3.3022e-01 (2.1296e-01)	Acc@1  89.84 ( 93.75)	Acc@5  99.22 ( 99.87)
Epoch: [78][ 40/391]	Time  0.036 ( 0.036)	Data  0.001 ( 0.005)	Loss 1.7682e-01 (2.1574e-01)	Acc@1  96.09 ( 93.77)	Acc@5 100.00 ( 99.81)
Epoch: [78][ 50/391]	Time  0.031 ( 0.035)	Data  0.001 ( 0.004)	Loss 1.8739e-01 (2.1077e-01)	Acc@1  93.75 ( 93.98)	Acc@5 100.00 ( 99.82)
Epoch: [78][ 60/391]	Time  0.034 ( 0.035)	Data  0.001 ( 0.004)	Loss 1.5989e-01 (2.1113e-01)	Acc@1  96.88 ( 93.99)	Acc@5 100.00 ( 99.82)
Epoch: [78][ 70/391]	Time  0.029 ( 0.034)	Data  0.001 ( 0.003)	Loss 1.9066e-01 (2.0870e-01)	Acc@1  95.31 ( 94.06)	Acc@5 100.00 ( 99.83)
Epoch: [78][ 80/391]	Time  0.032 ( 0.034)	Data  0.001 ( 0.003)	Loss 2.3651e-01 (2.0940e-01)	Acc@1  93.75 ( 94.09)	Acc@5  99.22 ( 99.81)
Epoch: [78][ 90/391]	Time  0.031 ( 0.034)	Data  0.001 ( 0.003)	Loss 2.2202e-01 (2.0853e-01)	Acc@1  92.19 ( 94.08)	Acc@5 100.00 ( 99.83)
Epoch: [78][100/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.003)	Loss 1.6369e-01 (2.0805e-01)	Acc@1  95.31 ( 94.07)	Acc@5  99.22 ( 99.83)
Epoch: [78][110/391]	Time  0.037 ( 0.033)	Data  0.001 ( 0.003)	Loss 2.0647e-01 (2.0785e-01)	Acc@1  93.75 ( 94.07)	Acc@5 100.00 ( 99.82)
Epoch: [78][120/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.2632e-01 (2.0494e-01)	Acc@1  96.09 ( 94.14)	Acc@5 100.00 ( 99.84)
Epoch: [78][130/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.6112e-01 (2.0567e-01)	Acc@1  97.66 ( 94.14)	Acc@5 100.00 ( 99.83)
Epoch: [78][140/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.8535e-01 (2.0603e-01)	Acc@1  95.31 ( 94.13)	Acc@5 100.00 ( 99.84)
Epoch: [78][150/391]	Time  0.030 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.7819e-01 (2.0623e-01)	Acc@1  92.19 ( 94.11)	Acc@5 100.00 ( 99.84)
Epoch: [78][160/391]	Time  0.029 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.2780e-01 (2.0510e-01)	Acc@1  95.31 ( 94.16)	Acc@5 100.00 ( 99.85)
Epoch: [78][170/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.0020e-01 (2.0439e-01)	Acc@1  94.53 ( 94.13)	Acc@5  99.22 ( 99.85)
Epoch: [78][180/391]	Time  0.030 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.9812e-01 (2.0540e-01)	Acc@1  87.50 ( 94.07)	Acc@5 100.00 ( 99.85)
Epoch: [78][190/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.2115e-01 (2.0627e-01)	Acc@1  91.41 ( 94.05)	Acc@5 100.00 ( 99.84)
Epoch: [78][200/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.3149e-01 (2.0703e-01)	Acc@1  91.41 ( 94.01)	Acc@5 100.00 ( 99.84)
Epoch: [78][210/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.2563e-01 (2.0762e-01)	Acc@1  92.19 ( 94.00)	Acc@5 100.00 ( 99.84)
Epoch: [78][220/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.5760e-01 (2.0670e-01)	Acc@1  96.88 ( 94.03)	Acc@5 100.00 ( 99.85)
Epoch: [78][230/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.5361e-01 (2.0645e-01)	Acc@1  91.41 ( 94.05)	Acc@5 100.00 ( 99.84)
Epoch: [78][240/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.3435e-01 (2.0603e-01)	Acc@1  97.66 ( 94.04)	Acc@5 100.00 ( 99.84)
Epoch: [78][250/391]	Time  0.038 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.8454e-01 (2.0637e-01)	Acc@1  94.53 ( 94.03)	Acc@5 100.00 ( 99.84)
Epoch: [78][260/391]	Time  0.033 ( 0.033)	Data  0.002 ( 0.002)	Loss 1.9923e-01 (2.0609e-01)	Acc@1  92.97 ( 94.04)	Acc@5 100.00 ( 99.84)
Epoch: [78][270/391]	Time  0.031 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.0366e-01 (2.0646e-01)	Acc@1  92.97 ( 94.04)	Acc@5 100.00 ( 99.84)
Epoch: [78][280/391]	Time  0.037 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.9074e-01 (2.0715e-01)	Acc@1  95.31 ( 94.00)	Acc@5 100.00 ( 99.83)
Epoch: [78][290/391]	Time  0.033 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.0607e-01 (2.0690e-01)	Acc@1  93.75 ( 94.01)	Acc@5  99.22 ( 99.83)
Epoch: [78][300/391]	Time  0.035 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.8439e-01 (2.0639e-01)	Acc@1  96.09 ( 94.02)	Acc@5 100.00 ( 99.83)
Epoch: [78][310/391]	Time  0.034 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.6180e-01 (2.0602e-01)	Acc@1  89.84 ( 94.05)	Acc@5 100.00 ( 99.83)
Epoch: [78][320/391]	Time  0.030 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.3344e-01 (2.0626e-01)	Acc@1  91.41 ( 94.02)	Acc@5 100.00 ( 99.83)
Epoch: [78][330/391]	Time  0.030 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.9870e-01 (2.0581e-01)	Acc@1  94.53 ( 94.05)	Acc@5  99.22 ( 99.83)
Epoch: [78][340/391]	Time  0.030 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.6881e-01 (2.0632e-01)	Acc@1  91.41 ( 94.02)	Acc@5  99.22 ( 99.83)
Epoch: [78][350/391]	Time  0.034 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.3539e-01 (2.0644e-01)	Acc@1  96.88 ( 94.02)	Acc@5 100.00 ( 99.83)
Epoch: [78][360/391]	Time  0.031 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.5810e-01 (2.0694e-01)	Acc@1  94.53 ( 94.00)	Acc@5 100.00 ( 99.82)
Epoch: [78][370/391]	Time  0.030 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.6889e-01 (2.0687e-01)	Acc@1  96.09 ( 94.00)	Acc@5 100.00 ( 99.82)
Epoch: [78][380/391]	Time  0.033 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.8149e-01 (2.0667e-01)	Acc@1  95.31 ( 94.02)	Acc@5 100.00 ( 99.82)
Epoch: [78][390/391]	Time  0.022 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.0753e-01 (2.0670e-01)	Acc@1  92.50 ( 94.00)	Acc@5 100.00 ( 99.82)
## e[78] optimizer.zero_grad (sum) time: 0.07128691673278809
## e[78]       loss.backward (sum) time: 2.550565481185913
## e[78]      optimizer.step (sum) time: 0.5592186450958252
## epoch[78] training(only) time: 12.68532681465149
# Switched to evaluate mode...
Test: [  0/100]	Time  0.152 ( 0.152)	Loss 1.2874e+00 (1.2874e+00)	Acc@1  72.00 ( 72.00)	Acc@5  89.00 ( 89.00)
Test: [ 10/100]	Time  0.024 ( 0.035)	Loss 1.4885e+00 (1.4843e+00)	Acc@1  68.00 ( 69.09)	Acc@5  91.00 ( 89.27)
Test: [ 20/100]	Time  0.024 ( 0.030)	Loss 1.1957e+00 (1.4330e+00)	Acc@1  76.00 ( 69.71)	Acc@5  93.00 ( 90.10)
Test: [ 30/100]	Time  0.034 ( 0.028)	Loss 1.7885e+00 (1.4590e+00)	Acc@1  62.00 ( 68.71)	Acc@5  90.00 ( 90.32)
Test: [ 40/100]	Time  0.020 ( 0.027)	Loss 1.4156e+00 (1.4543e+00)	Acc@1  67.00 ( 68.56)	Acc@5  91.00 ( 90.32)
Test: [ 50/100]	Time  0.024 ( 0.026)	Loss 1.5177e+00 (1.4654e+00)	Acc@1  68.00 ( 68.29)	Acc@5  89.00 ( 90.22)
Test: [ 60/100]	Time  0.024 ( 0.025)	Loss 1.6070e+00 (1.4404e+00)	Acc@1  66.00 ( 68.43)	Acc@5  85.00 ( 90.52)
Test: [ 70/100]	Time  0.018 ( 0.025)	Loss 1.6450e+00 (1.4404e+00)	Acc@1  68.00 ( 68.38)	Acc@5  87.00 ( 90.55)
Test: [ 80/100]	Time  0.022 ( 0.024)	Loss 1.5404e+00 (1.4446e+00)	Acc@1  73.00 ( 68.43)	Acc@5  88.00 ( 90.51)
Test: [ 90/100]	Time  0.023 ( 0.024)	Loss 1.7897e+00 (1.4321e+00)	Acc@1  65.00 ( 68.73)	Acc@5  89.00 ( 90.66)
 * Acc@1 68.960 Acc@5 90.810
### epoch[78] execution time: 15.125380277633667
EPOCH 79
REMOVING: module.fire8.squeeze.1.bias
REMOVING: module.fire8.expand_1x1.0.weight
i:   0, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.001069733097291952   to: 0.001004369505446367
i:   1, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.001128440245871042   to: 0.001026136172790403
i:   2, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.001204216033518750   to: 0.001065761458848346
i:   3, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.001296613027309639   to: 0.001122795155163180
i:   4, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.001405188309214843   to: 0.001196790949251835
i:   5, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.001529503709529888   to: 0.001287306695836942
i:   6, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.001669126020829503   to: 0.001393904667140432
i:   7, name:  module.fire9.squeeze.0.weight  changing lr from: 0.001823627193364796   to: 0.001516151783188795
i:   8, name:    module.fire9.squeeze.0.bias  changing lr from: 0.001992584512788558   to: 0.001653619823050389
i:   9, name:  module.fire9.squeeze.1.weight  changing lr from: 0.002175580761064893   to: 0.001805885617896413
i:  10, name:    module.fire9.squeeze.1.bias  changing lr from: 0.002372204361390106   to: 0.001972531226748080
i:  11, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.002582049507923378   to: 0.002153144095744069
i:  12, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.002804716281096863   to: 0.002347317201734177
i:  13, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.003039810749247784   to: 0.002554649180977081
i:  14, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.003286945057287066   to: 0.002774744443692950
i:  15, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.003545737503092893   to: 0.003007213275194497
i:  16, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.003815812602291096   to: 0.003251671924293802
i:  17, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.004096801142058558   to: 0.003507742679656028
i:  18, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.004388340224561398   to: 0.003775053934746230
i:  19, name:           module.conv10.weight  changing lr from: 0.004690073300614627   to: 0.004053240241990141
i:  20, name:             module.conv10.bias  changing lr from: 0.005001650194126833   to: 0.004341942356746003



# Switched to train mode...
Epoch: [79][  0/391]	Time  0.189 ( 0.189)	Data  0.152 ( 0.152)	Loss 2.0827e-01 (2.0827e-01)	Acc@1  96.09 ( 96.09)	Acc@5 100.00 (100.00)
Epoch: [79][ 10/391]	Time  0.031 ( 0.045)	Data  0.001 ( 0.015)	Loss 2.2708e-01 (2.0543e-01)	Acc@1  93.75 ( 94.67)	Acc@5 100.00 ( 99.72)
Epoch: [79][ 20/391]	Time  0.030 ( 0.039)	Data  0.001 ( 0.008)	Loss 2.6667e-01 (2.1255e-01)	Acc@1  93.75 ( 94.49)	Acc@5 100.00 ( 99.63)
Epoch: [79][ 30/391]	Time  0.030 ( 0.036)	Data  0.001 ( 0.006)	Loss 2.3142e-01 (2.0454e-01)	Acc@1  93.75 ( 94.41)	Acc@5  99.22 ( 99.67)
Epoch: [79][ 40/391]	Time  0.029 ( 0.035)	Data  0.001 ( 0.005)	Loss 2.3756e-01 (2.0652e-01)	Acc@1  92.97 ( 94.17)	Acc@5 100.00 ( 99.73)
Epoch: [79][ 50/391]	Time  0.033 ( 0.035)	Data  0.001 ( 0.004)	Loss 2.8586e-01 (2.0974e-01)	Acc@1  92.97 ( 94.07)	Acc@5 100.00 ( 99.72)
Epoch: [79][ 60/391]	Time  0.030 ( 0.034)	Data  0.001 ( 0.004)	Loss 2.9246e-01 (2.1214e-01)	Acc@1  92.19 ( 93.99)	Acc@5  99.22 ( 99.72)
Epoch: [79][ 70/391]	Time  0.033 ( 0.034)	Data  0.001 ( 0.003)	Loss 1.9374e-01 (2.0981e-01)	Acc@1  93.75 ( 94.08)	Acc@5 100.00 ( 99.75)
Epoch: [79][ 80/391]	Time  0.030 ( 0.033)	Data  0.001 ( 0.003)	Loss 1.8361e-01 (2.1264e-01)	Acc@1  96.09 ( 94.05)	Acc@5  99.22 ( 99.73)
Epoch: [79][ 90/391]	Time  0.029 ( 0.033)	Data  0.001 ( 0.003)	Loss 2.3687e-01 (2.1403e-01)	Acc@1  93.75 ( 93.95)	Acc@5 100.00 ( 99.75)
Epoch: [79][100/391]	Time  0.028 ( 0.033)	Data  0.001 ( 0.003)	Loss 1.3446e-01 (2.1219e-01)	Acc@1  94.53 ( 93.95)	Acc@5 100.00 ( 99.76)
Epoch: [79][110/391]	Time  0.030 ( 0.033)	Data  0.001 ( 0.003)	Loss 1.4420e-01 (2.1128e-01)	Acc@1  96.88 ( 93.98)	Acc@5 100.00 ( 99.77)
Epoch: [79][120/391]	Time  0.035 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.3676e-01 (2.1089e-01)	Acc@1  92.19 ( 93.95)	Acc@5  99.22 ( 99.75)
Epoch: [79][130/391]	Time  0.030 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.2425e-01 (2.0924e-01)	Acc@1  92.97 ( 94.01)	Acc@5 100.00 ( 99.76)
Epoch: [79][140/391]	Time  0.034 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.4606e-01 (2.0751e-01)	Acc@1  97.66 ( 94.04)	Acc@5 100.00 ( 99.77)
Epoch: [79][150/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.5108e-01 (2.0770e-01)	Acc@1  89.06 ( 94.04)	Acc@5 100.00 ( 99.75)
Epoch: [79][160/391]	Time  0.036 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.1376e-01 (2.0902e-01)	Acc@1  92.97 ( 93.96)	Acc@5 100.00 ( 99.75)
Epoch: [79][170/391]	Time  0.035 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.8319e-01 (2.0771e-01)	Acc@1  96.09 ( 93.99)	Acc@5 100.00 ( 99.75)
Epoch: [79][180/391]	Time  0.030 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.7429e-01 (2.0812e-01)	Acc@1  95.31 ( 93.95)	Acc@5  99.22 ( 99.75)
Epoch: [79][190/391]	Time  0.030 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.8047e-01 (2.0792e-01)	Acc@1  93.75 ( 93.97)	Acc@5 100.00 ( 99.75)
Epoch: [79][200/391]	Time  0.032 ( 0.032)	Data  0.002 ( 0.002)	Loss 2.5960e-01 (2.0866e-01)	Acc@1  90.62 ( 93.94)	Acc@5  98.44 ( 99.74)
Epoch: [79][210/391]	Time  0.031 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.5967e-01 (2.0860e-01)	Acc@1  96.09 ( 93.96)	Acc@5  99.22 ( 99.73)
Epoch: [79][220/391]	Time  0.033 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.0715e-01 (2.0843e-01)	Acc@1  92.97 ( 93.96)	Acc@5 100.00 ( 99.73)
Epoch: [79][230/391]	Time  0.030 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.5238e-01 (2.0945e-01)	Acc@1  96.88 ( 93.93)	Acc@5 100.00 ( 99.73)
Epoch: [79][240/391]	Time  0.030 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.3127e-01 (2.0907e-01)	Acc@1  94.53 ( 93.95)	Acc@5  99.22 ( 99.74)
Epoch: [79][250/391]	Time  0.030 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.8193e-01 (2.0959e-01)	Acc@1  96.09 ( 93.94)	Acc@5 100.00 ( 99.74)
Epoch: [79][260/391]	Time  0.034 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.1574e-01 (2.0869e-01)	Acc@1  92.97 ( 93.96)	Acc@5 100.00 ( 99.75)
Epoch: [79][270/391]	Time  0.030 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.4206e-01 (2.0793e-01)	Acc@1  96.88 ( 93.97)	Acc@5 100.00 ( 99.75)
Epoch: [79][280/391]	Time  0.030 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.1142e-01 (2.0845e-01)	Acc@1  94.53 ( 93.96)	Acc@5 100.00 ( 99.74)
Epoch: [79][290/391]	Time  0.029 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.1621e-01 (2.0771e-01)	Acc@1  92.97 ( 94.00)	Acc@5 100.00 ( 99.74)
Epoch: [79][300/391]	Time  0.030 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.4059e-01 (2.0709e-01)	Acc@1  97.66 ( 94.03)	Acc@5 100.00 ( 99.74)
Epoch: [79][310/391]	Time  0.030 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.2788e-01 (2.0728e-01)	Acc@1  92.19 ( 94.00)	Acc@5 100.00 ( 99.74)
Epoch: [79][320/391]	Time  0.030 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.5817e-01 (2.0767e-01)	Acc@1  93.75 ( 93.98)	Acc@5  99.22 ( 99.74)
Epoch: [79][330/391]	Time  0.032 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.5971e-01 (2.0796e-01)	Acc@1  98.44 ( 93.97)	Acc@5 100.00 ( 99.74)
Epoch: [79][340/391]	Time  0.030 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.3835e-01 (2.0819e-01)	Acc@1  91.41 ( 93.97)	Acc@5  99.22 ( 99.74)
Epoch: [79][350/391]	Time  0.029 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.6662e-01 (2.0871e-01)	Acc@1  91.41 ( 93.94)	Acc@5  99.22 ( 99.73)
Epoch: [79][360/391]	Time  0.032 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.9166e-01 (2.0846e-01)	Acc@1  96.09 ( 93.94)	Acc@5 100.00 ( 99.74)
Epoch: [79][370/391]	Time  0.034 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.3345e-01 (2.0884e-01)	Acc@1  92.97 ( 93.93)	Acc@5 100.00 ( 99.74)
Epoch: [79][380/391]	Time  0.032 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.4641e-01 (2.0883e-01)	Acc@1  89.06 ( 93.94)	Acc@5 100.00 ( 99.74)
Epoch: [79][390/391]	Time  0.022 ( 0.032)	Data  0.001 ( 0.002)	Loss 3.2830e-01 (2.0914e-01)	Acc@1  87.50 ( 93.91)	Acc@5  98.75 ( 99.74)
## e[79] optimizer.zero_grad (sum) time: 0.06482911109924316
## e[79]       loss.backward (sum) time: 2.429187059402466
## e[79]      optimizer.step (sum) time: 0.5165684223175049
## epoch[79] training(only) time: 12.575847387313843
# Switched to evaluate mode...
Test: [  0/100]	Time  0.144 ( 0.144)	Loss 1.3127e+00 (1.3127e+00)	Acc@1  71.00 ( 71.00)	Acc@5  88.00 ( 88.00)
Test: [ 10/100]	Time  0.019 ( 0.033)	Loss 1.4509e+00 (1.4763e+00)	Acc@1  67.00 ( 69.00)	Acc@5  92.00 ( 89.09)
Test: [ 20/100]	Time  0.024 ( 0.028)	Loss 1.1777e+00 (1.4246e+00)	Acc@1  76.00 ( 69.38)	Acc@5  93.00 ( 90.05)
Test: [ 30/100]	Time  0.024 ( 0.027)	Loss 1.7604e+00 (1.4535e+00)	Acc@1  61.00 ( 68.39)	Acc@5  90.00 ( 90.10)
Test: [ 40/100]	Time  0.024 ( 0.026)	Loss 1.3728e+00 (1.4483e+00)	Acc@1  68.00 ( 68.32)	Acc@5  90.00 ( 90.07)
Test: [ 50/100]	Time  0.024 ( 0.026)	Loss 1.4493e+00 (1.4578e+00)	Acc@1  68.00 ( 68.14)	Acc@5  92.00 ( 90.12)
Test: [ 60/100]	Time  0.022 ( 0.025)	Loss 1.6560e+00 (1.4353e+00)	Acc@1  65.00 ( 68.23)	Acc@5  86.00 ( 90.52)
Test: [ 70/100]	Time  0.022 ( 0.025)	Loss 1.6454e+00 (1.4371e+00)	Acc@1  68.00 ( 68.24)	Acc@5  86.00 ( 90.58)
Test: [ 80/100]	Time  0.017 ( 0.024)	Loss 1.5514e+00 (1.4426e+00)	Acc@1  71.00 ( 68.30)	Acc@5  89.00 ( 90.51)
Test: [ 90/100]	Time  0.022 ( 0.024)	Loss 1.7705e+00 (1.4302e+00)	Acc@1  64.00 ( 68.62)	Acc@5  88.00 ( 90.65)
 * Acc@1 68.850 Acc@5 90.790
### epoch[79] execution time: 15.003410816192627
EPOCH 80
REMOVING: module.fire8.expand_1x1.0.bias
REMOVING: module.fire8.expand_1x1.1.weight
i:   0, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.001065761458848346   to: 0.001003706272527948
i:   1, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.001122795155163180   to: 0.001024363606799349
i:   2, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.001196790949251835   to: 0.001062756700030997
i:   3, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.001287306695836942   to: 0.001118440746658211
i:   4, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.001393904667140432   to: 0.001190974754867984
i:   5, name:  module.fire9.squeeze.0.weight  changing lr from: 0.001516151783188795   to: 0.001279921813565021
i:   6, name:    module.fire9.squeeze.0.bias  changing lr from: 0.001653619823050389   to: 0.001384849338856824
i:   7, name:  module.fire9.squeeze.1.weight  changing lr from: 0.001805885617896413   to: 0.001505329300982121
i:   8, name:    module.fire9.squeeze.1.bias  changing lr from: 0.001972531226748080   to: 0.001640938432578486
i:   9, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.002153144095744069   to: 0.001791258419157192
i:  10, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.002347317201734177   to: 0.001955876072625034
i:  11, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.002554649180977081   to: 0.002134383488665630
i:  12, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.002774744443692950   to: 0.002326378188765048
i:  13, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.003007213275194497   to: 0.002531463247639936
i:  14, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.003251671924293802   to: 0.002749247406799559
i:  15, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.003507742679656028   to: 0.002979345174947167
i:  16, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.003775053934746230   to: 0.003221376915900558
i:  17, name:           module.conv10.weight  changing lr from: 0.004053240241990141   to: 0.003474968924686333
i:  18, name:             module.conv10.bias  changing lr from: 0.004341942356746003   to: 0.003739753492438124



# Switched to train mode...
Epoch: [80][  0/391]	Time  0.180 ( 0.180)	Data  0.144 ( 0.144)	Loss 2.1431e-01 (2.1431e-01)	Acc@1  93.75 ( 93.75)	Acc@5 100.00 (100.00)
Epoch: [80][ 10/391]	Time  0.030 ( 0.045)	Data  0.001 ( 0.014)	Loss 1.6712e-01 (1.9157e-01)	Acc@1  95.31 ( 95.03)	Acc@5 100.00 ( 99.72)
Epoch: [80][ 20/391]	Time  0.031 ( 0.039)	Data  0.001 ( 0.008)	Loss 1.9621e-01 (2.0351e-01)	Acc@1  93.75 ( 94.42)	Acc@5 100.00 ( 99.74)
Epoch: [80][ 30/391]	Time  0.035 ( 0.037)	Data  0.001 ( 0.006)	Loss 2.0118e-01 (2.0407e-01)	Acc@1  93.75 ( 94.35)	Acc@5 100.00 ( 99.80)
Epoch: [80][ 40/391]	Time  0.030 ( 0.035)	Data  0.001 ( 0.005)	Loss 1.7240e-01 (1.9926e-01)	Acc@1  94.53 ( 94.40)	Acc@5 100.00 ( 99.83)
Epoch: [80][ 50/391]	Time  0.032 ( 0.035)	Data  0.001 ( 0.004)	Loss 2.2096e-01 (2.0066e-01)	Acc@1  93.75 ( 94.36)	Acc@5 100.00 ( 99.80)
Epoch: [80][ 60/391]	Time  0.030 ( 0.034)	Data  0.001 ( 0.004)	Loss 2.1695e-01 (2.0248e-01)	Acc@1  94.53 ( 94.21)	Acc@5 100.00 ( 99.80)
Epoch: [80][ 70/391]	Time  0.030 ( 0.034)	Data  0.001 ( 0.003)	Loss 1.5365e-01 (2.0081e-01)	Acc@1  98.44 ( 94.25)	Acc@5 100.00 ( 99.80)
Epoch: [80][ 80/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.003)	Loss 2.0522e-01 (1.9910e-01)	Acc@1  95.31 ( 94.22)	Acc@5 100.00 ( 99.83)
Epoch: [80][ 90/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.003)	Loss 3.0679e-01 (2.0277e-01)	Acc@1  89.06 ( 94.14)	Acc@5 100.00 ( 99.80)
Epoch: [80][100/391]	Time  0.029 ( 0.033)	Data  0.001 ( 0.003)	Loss 2.0527e-01 (2.0132e-01)	Acc@1  93.75 ( 94.15)	Acc@5  99.22 ( 99.81)
Epoch: [80][110/391]	Time  0.030 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.7232e-01 (2.0098e-01)	Acc@1  93.75 ( 94.14)	Acc@5 100.00 ( 99.82)
Epoch: [80][120/391]	Time  0.037 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.4235e-01 (2.0175e-01)	Acc@1  92.19 ( 94.09)	Acc@5 100.00 ( 99.81)
Epoch: [80][130/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.0533e-01 (2.0304e-01)	Acc@1  92.97 ( 94.01)	Acc@5 100.00 ( 99.80)
Epoch: [80][140/391]	Time  0.029 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.9704e-01 (2.0293e-01)	Acc@1  95.31 ( 94.02)	Acc@5 100.00 ( 99.80)
Epoch: [80][150/391]	Time  0.030 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.6598e-01 (2.0172e-01)	Acc@1  94.53 ( 94.09)	Acc@5 100.00 ( 99.80)
Epoch: [80][160/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.3769e-01 (2.0164e-01)	Acc@1  96.09 ( 94.09)	Acc@5 100.00 ( 99.80)
Epoch: [80][170/391]	Time  0.033 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.8035e-01 (2.0252e-01)	Acc@1  92.97 ( 94.07)	Acc@5 100.00 ( 99.79)
Epoch: [80][180/391]	Time  0.033 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.1239e-01 (2.0252e-01)	Acc@1  92.19 ( 94.09)	Acc@5 100.00 ( 99.78)
Epoch: [80][190/391]	Time  0.036 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.5832e-01 (2.0269e-01)	Acc@1  92.19 ( 94.05)	Acc@5 100.00 ( 99.79)
Epoch: [80][200/391]	Time  0.030 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.7193e-01 (2.0199e-01)	Acc@1  96.09 ( 94.08)	Acc@5 100.00 ( 99.79)
Epoch: [80][210/391]	Time  0.030 ( 0.032)	Data  0.001 ( 0.002)	Loss 3.4446e-01 (2.0382e-01)	Acc@1  90.62 ( 94.02)	Acc@5 100.00 ( 99.79)
Epoch: [80][220/391]	Time  0.034 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.4749e-01 (2.0414e-01)	Acc@1  94.53 ( 93.99)	Acc@5 100.00 ( 99.78)
Epoch: [80][230/391]	Time  0.031 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.6970e-01 (2.0429e-01)	Acc@1  94.53 ( 94.02)	Acc@5  99.22 ( 99.78)
Epoch: [80][240/391]	Time  0.032 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.0912e-01 (2.0301e-01)	Acc@1  92.97 ( 94.08)	Acc@5 100.00 ( 99.79)
Epoch: [80][250/391]	Time  0.033 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.9299e-01 (2.0422e-01)	Acc@1  93.75 ( 94.01)	Acc@5 100.00 ( 99.79)
Epoch: [80][260/391]	Time  0.032 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.0861e-01 (2.0459e-01)	Acc@1  94.53 ( 93.99)	Acc@5 100.00 ( 99.79)
Epoch: [80][270/391]	Time  0.032 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.0792e-01 (2.0510e-01)	Acc@1  92.19 ( 93.95)	Acc@5  99.22 ( 99.79)
Epoch: [80][280/391]	Time  0.029 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.8452e-01 (2.0515e-01)	Acc@1  94.53 ( 93.96)	Acc@5 100.00 ( 99.79)
Epoch: [80][290/391]	Time  0.031 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.3860e-01 (2.0511e-01)	Acc@1  93.75 ( 93.98)	Acc@5 100.00 ( 99.78)
Epoch: [80][300/391]	Time  0.031 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.1749e-01 (2.0553e-01)	Acc@1  92.19 ( 93.96)	Acc@5  99.22 ( 99.78)
Epoch: [80][310/391]	Time  0.033 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.1871e-01 (2.0632e-01)	Acc@1  93.75 ( 93.94)	Acc@5  99.22 ( 99.77)
Epoch: [80][320/391]	Time  0.028 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.7715e-01 (2.0627e-01)	Acc@1  98.44 ( 93.95)	Acc@5  99.22 ( 99.76)
Epoch: [80][330/391]	Time  0.031 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.5501e-01 (2.0611e-01)	Acc@1  95.31 ( 93.95)	Acc@5 100.00 ( 99.77)
Epoch: [80][340/391]	Time  0.034 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.1787e-01 (2.0611e-01)	Acc@1  92.19 ( 93.95)	Acc@5 100.00 ( 99.78)
Epoch: [80][350/391]	Time  0.031 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.2082e-01 (2.0633e-01)	Acc@1  94.53 ( 93.95)	Acc@5 100.00 ( 99.78)
Epoch: [80][360/391]	Time  0.032 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.6386e-01 (2.0594e-01)	Acc@1  96.88 ( 93.98)	Acc@5 100.00 ( 99.78)
Epoch: [80][370/391]	Time  0.030 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.3995e-01 (2.0595e-01)	Acc@1  94.53 ( 93.98)	Acc@5  99.22 ( 99.77)
Epoch: [80][380/391]	Time  0.030 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.6258e-01 (2.0579e-01)	Acc@1  92.97 ( 93.99)	Acc@5  99.22 ( 99.77)
Epoch: [80][390/391]	Time  0.021 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.1195e-01 (2.0578e-01)	Acc@1  95.00 ( 93.98)	Acc@5  98.75 ( 99.77)
## e[80] optimizer.zero_grad (sum) time: 0.06023049354553223
## e[80]       loss.backward (sum) time: 2.374000072479248
## e[80]      optimizer.step (sum) time: 0.4606008529663086
## epoch[80] training(only) time: 12.611027002334595
# Switched to evaluate mode...
Test: [  0/100]	Time  0.153 ( 0.153)	Loss 1.3118e+00 (1.3118e+00)	Acc@1  72.00 ( 72.00)	Acc@5  88.00 ( 88.00)
Test: [ 10/100]	Time  0.024 ( 0.035)	Loss 1.4542e+00 (1.4682e+00)	Acc@1  69.00 ( 68.64)	Acc@5  91.00 ( 89.27)
Test: [ 20/100]	Time  0.018 ( 0.028)	Loss 1.1724e+00 (1.4223e+00)	Acc@1  76.00 ( 69.43)	Acc@5  94.00 ( 89.90)
Test: [ 30/100]	Time  0.024 ( 0.026)	Loss 1.7642e+00 (1.4549e+00)	Acc@1  60.00 ( 68.32)	Acc@5  89.00 ( 89.97)
Test: [ 40/100]	Time  0.023 ( 0.025)	Loss 1.4011e+00 (1.4519e+00)	Acc@1  67.00 ( 68.20)	Acc@5  92.00 ( 90.02)
Test: [ 50/100]	Time  0.018 ( 0.024)	Loss 1.4790e+00 (1.4617e+00)	Acc@1  68.00 ( 68.02)	Acc@5  89.00 ( 90.02)
Test: [ 60/100]	Time  0.024 ( 0.024)	Loss 1.6342e+00 (1.4395e+00)	Acc@1  62.00 ( 68.08)	Acc@5  88.00 ( 90.46)
Test: [ 70/100]	Time  0.021 ( 0.024)	Loss 1.6617e+00 (1.4415e+00)	Acc@1  69.00 ( 68.14)	Acc@5  87.00 ( 90.42)
Test: [ 80/100]	Time  0.026 ( 0.024)	Loss 1.5543e+00 (1.4469e+00)	Acc@1  73.00 ( 68.26)	Acc@5  89.00 ( 90.40)
Test: [ 90/100]	Time  0.019 ( 0.023)	Loss 1.7510e+00 (1.4344e+00)	Acc@1  66.00 ( 68.52)	Acc@5  88.00 ( 90.56)
 * Acc@1 68.810 Acc@5 90.690
### epoch[80] execution time: 14.977240085601807
EPOCH 81
REMOVING: module.fire8.expand_1x1.1.bias
REMOVING: module.fire8.expand_3x3.0.weight
i:   0, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.001062756700030997   to: 0.001003285693309052
i:   1, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.001118440746658211   to: 0.001023154955715848
i:   2, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.001190974754867984   to: 0.001060632015731526
i:   3, name:  module.fire9.squeeze.0.weight  changing lr from: 0.001279921813565021   to: 0.001115277401700664
i:   4, name:    module.fire9.squeeze.0.bias  changing lr from: 0.001384849338856824   to: 0.001186655380664685
i:   5, name:  module.fire9.squeeze.1.weight  changing lr from: 0.001505329300982121   to: 0.001274334220832600
i:   6, name:    module.fire9.squeeze.1.bias  changing lr from: 0.001640938432578486   to: 0.001377886434028008
i:   7, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.001791258419157192   to: 0.001496888999011630
i:   8, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.001955876072625034   to: 0.001630923566551200
i:   9, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.002134383488665630   to: 0.001779576647083491
i:  10, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.002326378188765048   to: 0.001942439781786120
i:  11, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.002531463247639936   to: 0.002119109697850068
i:  12, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.002749247406799559   to: 0.002309188448717436
i:  13, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.002979345174947167   to: 0.002512283540022647
i:  14, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.003221376915900558   to: 0.002728008041950036
i:  15, name:           module.conv10.weight  changing lr from: 0.003474968924686333   to: 0.002955980688694964
i:  16, name:             module.conv10.bias  changing lr from: 0.003739753492438124   to: 0.003195825965691140



# Switched to train mode...
Epoch: [81][  0/391]	Time  0.177 ( 0.177)	Data  0.143 ( 0.143)	Loss 2.4263e-01 (2.4263e-01)	Acc@1  91.41 ( 91.41)	Acc@5 100.00 (100.00)
Epoch: [81][ 10/391]	Time  0.046 ( 0.046)	Data  0.001 ( 0.014)	Loss 1.9646e-01 (2.1121e-01)	Acc@1  94.53 ( 93.32)	Acc@5 100.00 ( 99.93)
Epoch: [81][ 20/391]	Time  0.034 ( 0.039)	Data  0.001 ( 0.008)	Loss 2.6399e-01 (2.1343e-01)	Acc@1  92.19 ( 93.79)	Acc@5  99.22 ( 99.85)
Epoch: [81][ 30/391]	Time  0.030 ( 0.037)	Data  0.001 ( 0.006)	Loss 2.1065e-01 (2.0781e-01)	Acc@1  93.75 ( 94.13)	Acc@5 100.00 ( 99.85)
Epoch: [81][ 40/391]	Time  0.031 ( 0.035)	Data  0.001 ( 0.005)	Loss 2.4530e-01 (2.1203e-01)	Acc@1  89.84 ( 93.85)	Acc@5 100.00 ( 99.81)
Epoch: [81][ 50/391]	Time  0.027 ( 0.035)	Data  0.001 ( 0.004)	Loss 1.4637e-01 (2.0770e-01)	Acc@1  96.88 ( 94.07)	Acc@5 100.00 ( 99.82)
Epoch: [81][ 60/391]	Time  0.032 ( 0.034)	Data  0.001 ( 0.004)	Loss 3.4756e-01 (2.1086e-01)	Acc@1  89.06 ( 94.02)	Acc@5  99.22 ( 99.80)
Epoch: [81][ 70/391]	Time  0.029 ( 0.033)	Data  0.001 ( 0.003)	Loss 2.2927e-01 (2.1442e-01)	Acc@1  92.19 ( 94.01)	Acc@5 100.00 ( 99.76)
Epoch: [81][ 80/391]	Time  0.029 ( 0.033)	Data  0.001 ( 0.003)	Loss 2.1059e-01 (2.1249e-01)	Acc@1  93.75 ( 94.03)	Acc@5  99.22 ( 99.75)
Epoch: [81][ 90/391]	Time  0.028 ( 0.033)	Data  0.001 ( 0.003)	Loss 1.5854e-01 (2.1256e-01)	Acc@1  95.31 ( 94.01)	Acc@5 100.00 ( 99.76)
Epoch: [81][100/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.003)	Loss 2.8056e-01 (2.1159e-01)	Acc@1  90.62 ( 93.99)	Acc@5 100.00 ( 99.78)
Epoch: [81][110/391]	Time  0.028 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.4957e-01 (2.1020e-01)	Acc@1  96.88 ( 94.00)	Acc@5 100.00 ( 99.78)
Epoch: [81][120/391]	Time  0.029 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.4935e-01 (2.1052e-01)	Acc@1  93.75 ( 94.00)	Acc@5 100.00 ( 99.77)
Epoch: [81][130/391]	Time  0.031 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.9844e-01 (2.0969e-01)	Acc@1  94.53 ( 94.04)	Acc@5  99.22 ( 99.77)
Epoch: [81][140/391]	Time  0.032 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.0962e-01 (2.1042e-01)	Acc@1  96.09 ( 94.02)	Acc@5  99.22 ( 99.76)
Epoch: [81][150/391]	Time  0.033 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.8961e-01 (2.0966e-01)	Acc@1  95.31 ( 94.01)	Acc@5 100.00 ( 99.75)
Epoch: [81][160/391]	Time  0.031 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.0311e-01 (2.0961e-01)	Acc@1  92.97 ( 93.98)	Acc@5 100.00 ( 99.76)
Epoch: [81][170/391]	Time  0.029 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.9981e-01 (2.0872e-01)	Acc@1  92.97 ( 94.02)	Acc@5 100.00 ( 99.76)
Epoch: [81][180/391]	Time  0.033 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.6543e-01 (2.0811e-01)	Acc@1  96.09 ( 94.03)	Acc@5  99.22 ( 99.76)
Epoch: [81][190/391]	Time  0.040 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.0395e-01 (2.0876e-01)	Acc@1  93.75 ( 93.99)	Acc@5 100.00 ( 99.75)
Epoch: [81][200/391]	Time  0.029 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.8769e-01 (2.0853e-01)	Acc@1  92.97 ( 93.97)	Acc@5 100.00 ( 99.76)
Epoch: [81][210/391]	Time  0.030 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.5948e-01 (2.0797e-01)	Acc@1  93.75 ( 93.99)	Acc@5  99.22 ( 99.76)
Epoch: [81][220/391]	Time  0.029 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.5543e-01 (2.0721e-01)	Acc@1  88.28 ( 94.01)	Acc@5  99.22 ( 99.75)
Epoch: [81][230/391]	Time  0.033 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.1975e-01 (2.0702e-01)	Acc@1  93.75 ( 94.03)	Acc@5  99.22 ( 99.76)
Epoch: [81][240/391]	Time  0.029 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.2319e-01 (2.0738e-01)	Acc@1  93.75 ( 94.04)	Acc@5  99.22 ( 99.76)
Epoch: [81][250/391]	Time  0.029 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.6904e-01 (2.0756e-01)	Acc@1  94.53 ( 94.03)	Acc@5 100.00 ( 99.76)
Epoch: [81][260/391]	Time  0.029 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.2862e-01 (2.0853e-01)	Acc@1  92.97 ( 94.00)	Acc@5 100.00 ( 99.75)
Epoch: [81][270/391]	Time  0.029 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.2604e-01 (2.0880e-01)	Acc@1  95.31 ( 93.98)	Acc@5 100.00 ( 99.76)
Epoch: [81][280/391]	Time  0.034 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.0710e-01 (2.0870e-01)	Acc@1  93.75 ( 93.99)	Acc@5 100.00 ( 99.76)
Epoch: [81][290/391]	Time  0.031 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.7305e-01 (2.0886e-01)	Acc@1  94.53 ( 93.98)	Acc@5 100.00 ( 99.76)
Epoch: [81][300/391]	Time  0.029 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.9764e-01 (2.0875e-01)	Acc@1  94.53 ( 93.97)	Acc@5 100.00 ( 99.77)
Epoch: [81][310/391]	Time  0.034 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.9867e-01 (2.0788e-01)	Acc@1  92.97 ( 94.00)	Acc@5 100.00 ( 99.78)
Epoch: [81][320/391]	Time  0.030 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.7386e-01 (2.0760e-01)	Acc@1  94.53 ( 94.01)	Acc@5 100.00 ( 99.78)
Epoch: [81][330/391]	Time  0.030 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.1758e-01 (2.0796e-01)	Acc@1  92.97 ( 93.98)	Acc@5 100.00 ( 99.78)
Epoch: [81][340/391]	Time  0.029 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.6531e-01 (2.0752e-01)	Acc@1  94.53 ( 94.00)	Acc@5 100.00 ( 99.78)
Epoch: [81][350/391]	Time  0.032 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.7611e-01 (2.0782e-01)	Acc@1  96.88 ( 94.01)	Acc@5 100.00 ( 99.77)
Epoch: [81][360/391]	Time  0.035 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.2292e-01 (2.0763e-01)	Acc@1  91.41 ( 93.99)	Acc@5 100.00 ( 99.77)
Epoch: [81][370/391]	Time  0.038 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.4499e-01 (2.0676e-01)	Acc@1  96.09 ( 94.02)	Acc@5  99.22 ( 99.78)
Epoch: [81][380/391]	Time  0.029 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.9282e-01 (2.0689e-01)	Acc@1  96.88 ( 94.01)	Acc@5 100.00 ( 99.78)
Epoch: [81][390/391]	Time  0.018 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.7106e-01 (2.0661e-01)	Acc@1  96.25 ( 94.01)	Acc@5 100.00 ( 99.78)
## e[81] optimizer.zero_grad (sum) time: 0.05442070960998535
## e[81]       loss.backward (sum) time: 2.3562822341918945
## e[81]      optimizer.step (sum) time: 0.41787123680114746
## epoch[81] training(only) time: 12.434386491775513
# Switched to evaluate mode...
Test: [  0/100]	Time  0.154 ( 0.154)	Loss 1.2838e+00 (1.2838e+00)	Acc@1  72.00 ( 72.00)	Acc@5  88.00 ( 88.00)
Test: [ 10/100]	Time  0.022 ( 0.036)	Loss 1.4609e+00 (1.4714e+00)	Acc@1  70.00 ( 69.27)	Acc@5  91.00 ( 89.45)
Test: [ 20/100]	Time  0.025 ( 0.030)	Loss 1.1819e+00 (1.4171e+00)	Acc@1  77.00 ( 69.76)	Acc@5  93.00 ( 90.24)
Test: [ 30/100]	Time  0.023 ( 0.028)	Loss 1.7565e+00 (1.4490e+00)	Acc@1  60.00 ( 68.55)	Acc@5  89.00 ( 90.19)
Test: [ 40/100]	Time  0.021 ( 0.026)	Loss 1.4176e+00 (1.4477e+00)	Acc@1  66.00 ( 68.49)	Acc@5  92.00 ( 90.17)
Test: [ 50/100]	Time  0.021 ( 0.025)	Loss 1.4872e+00 (1.4575e+00)	Acc@1  68.00 ( 68.25)	Acc@5  89.00 ( 90.08)
Test: [ 60/100]	Time  0.022 ( 0.025)	Loss 1.6193e+00 (1.4338e+00)	Acc@1  65.00 ( 68.33)	Acc@5  86.00 ( 90.44)
Test: [ 70/100]	Time  0.021 ( 0.024)	Loss 1.6350e+00 (1.4342e+00)	Acc@1  69.00 ( 68.25)	Acc@5  87.00 ( 90.49)
Test: [ 80/100]	Time  0.024 ( 0.024)	Loss 1.5301e+00 (1.4397e+00)	Acc@1  73.00 ( 68.31)	Acc@5  89.00 ( 90.47)
Test: [ 90/100]	Time  0.018 ( 0.024)	Loss 1.7123e+00 (1.4272e+00)	Acc@1  64.00 ( 68.56)	Acc@5  88.00 ( 90.60)
 * Acc@1 68.890 Acc@5 90.740
### epoch[81] execution time: 14.861055374145508
EPOCH 82
REMOVING: module.fire8.expand_3x3.0.bias
REMOVING: module.fire8.expand_3x3.1.weight
i:   0, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.001060632015731526   to: 0.001003066399462587
i:   1, name:  module.fire9.squeeze.0.weight  changing lr from: 0.001115277401700664   to: 0.001022455597948134
i:   2, name:    module.fire9.squeeze.0.bias  changing lr from: 0.001186655380664685   to: 0.001059319875281760
i:   3, name:  module.fire9.squeeze.1.weight  changing lr from: 0.001274334220832600   to: 0.001113225024591373
i:   4, name:    module.fire9.squeeze.1.bias  changing lr from: 0.001377886434028008   to: 0.001183740509379848
i:   5, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.001496888999011630   to: 0.001270439721296356
i:   6, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.001630923566551200   to: 0.001372900218340305
i:   7, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.001779576647083491   to: 0.001490703944372700
i:   8, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.001942439781786120   to: 0.001623437430783142
i:   9, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.002119109697850068   to: 0.001770691981134602
i:  10, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.002309188448717436   to: 0.001932063839581693
i:  11, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.002512283540022647   to: 0.002107154343832318
i:  12, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.002728008041950036   to: 0.002295570063397211
i:  13, name:           module.conv10.weight  changing lr from: 0.002955980688694964   to: 0.002496922923846145
i:  14, name:             module.conv10.bias  changing lr from: 0.003195825965691140   to: 0.002710830317765122



# Switched to train mode...
Epoch: [82][  0/391]	Time  0.175 ( 0.175)	Data  0.141 ( 0.141)	Loss 1.9174e-01 (1.9174e-01)	Acc@1  93.75 ( 93.75)	Acc@5  98.44 ( 98.44)
Epoch: [82][ 10/391]	Time  0.031 ( 0.044)	Data  0.001 ( 0.014)	Loss 1.6116e-01 (1.8346e-01)	Acc@1  96.09 ( 95.03)	Acc@5 100.00 ( 99.57)
Epoch: [82][ 20/391]	Time  0.030 ( 0.038)	Data  0.001 ( 0.008)	Loss 2.3786e-01 (1.9151e-01)	Acc@1  92.97 ( 94.79)	Acc@5 100.00 ( 99.48)
Epoch: [82][ 30/391]	Time  0.029 ( 0.036)	Data  0.001 ( 0.006)	Loss 1.9064e-01 (1.9038e-01)	Acc@1  96.09 ( 94.53)	Acc@5  99.22 ( 99.60)
Epoch: [82][ 40/391]	Time  0.027 ( 0.034)	Data  0.001 ( 0.005)	Loss 1.5668e-01 (1.9250e-01)	Acc@1  95.31 ( 94.46)	Acc@5 100.00 ( 99.66)
Epoch: [82][ 50/391]	Time  0.027 ( 0.034)	Data  0.001 ( 0.004)	Loss 1.7338e-01 (1.9453e-01)	Acc@1  96.09 ( 94.41)	Acc@5 100.00 ( 99.71)
Epoch: [82][ 60/391]	Time  0.029 ( 0.033)	Data  0.001 ( 0.004)	Loss 2.0112e-01 (1.9331e-01)	Acc@1  93.75 ( 94.48)	Acc@5 100.00 ( 99.73)
Epoch: [82][ 70/391]	Time  0.028 ( 0.033)	Data  0.001 ( 0.003)	Loss 1.3742e-01 (1.9309e-01)	Acc@1  96.88 ( 94.55)	Acc@5 100.00 ( 99.74)
Epoch: [82][ 80/391]	Time  0.029 ( 0.033)	Data  0.001 ( 0.003)	Loss 2.0325e-01 (1.9585e-01)	Acc@1  93.75 ( 94.50)	Acc@5 100.00 ( 99.74)
Epoch: [82][ 90/391]	Time  0.034 ( 0.033)	Data  0.001 ( 0.003)	Loss 1.9794e-01 (1.9795e-01)	Acc@1  94.53 ( 94.45)	Acc@5  99.22 ( 99.72)
Epoch: [82][100/391]	Time  0.035 ( 0.032)	Data  0.001 ( 0.003)	Loss 2.5356e-01 (1.9770e-01)	Acc@1  92.19 ( 94.45)	Acc@5 100.00 ( 99.73)
Epoch: [82][110/391]	Time  0.036 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.5667e-01 (1.9688e-01)	Acc@1  96.09 ( 94.46)	Acc@5 100.00 ( 99.75)
Epoch: [82][120/391]	Time  0.034 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.8526e-01 (1.9876e-01)	Acc@1  96.09 ( 94.41)	Acc@5  99.22 ( 99.75)
Epoch: [82][130/391]	Time  0.029 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.2058e-01 (2.0037e-01)	Acc@1  93.75 ( 94.33)	Acc@5 100.00 ( 99.74)
Epoch: [82][140/391]	Time  0.028 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.8748e-01 (2.0058e-01)	Acc@1  94.53 ( 94.31)	Acc@5 100.00 ( 99.75)
Epoch: [82][150/391]	Time  0.031 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.5581e-01 (2.0008e-01)	Acc@1  96.88 ( 94.37)	Acc@5 100.00 ( 99.76)
Epoch: [82][160/391]	Time  0.030 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.7343e-01 (2.0066e-01)	Acc@1  97.66 ( 94.36)	Acc@5 100.00 ( 99.76)
Epoch: [82][170/391]	Time  0.034 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.5074e-01 (1.9997e-01)	Acc@1  97.66 ( 94.42)	Acc@5 100.00 ( 99.76)
Epoch: [82][180/391]	Time  0.033 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.0333e-01 (2.0135e-01)	Acc@1  94.53 ( 94.33)	Acc@5  99.22 ( 99.74)
Epoch: [82][190/391]	Time  0.030 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.7580e-01 (2.0144e-01)	Acc@1  96.09 ( 94.35)	Acc@5 100.00 ( 99.75)
Epoch: [82][200/391]	Time  0.036 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.5422e-01 (2.0036e-01)	Acc@1  95.31 ( 94.40)	Acc@5 100.00 ( 99.74)
Epoch: [82][210/391]	Time  0.027 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.3711e-01 (1.9968e-01)	Acc@1  92.19 ( 94.42)	Acc@5 100.00 ( 99.75)
Epoch: [82][220/391]	Time  0.028 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.6712e-01 (1.9951e-01)	Acc@1  92.97 ( 94.44)	Acc@5  99.22 ( 99.74)
Epoch: [82][230/391]	Time  0.029 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.2469e-01 (1.9971e-01)	Acc@1  92.97 ( 94.46)	Acc@5 100.00 ( 99.74)
Epoch: [82][240/391]	Time  0.028 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.3548e-01 (1.9896e-01)	Acc@1  94.53 ( 94.47)	Acc@5 100.00 ( 99.75)
Epoch: [82][250/391]	Time  0.032 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.6035e-01 (1.9994e-01)	Acc@1  94.53 ( 94.46)	Acc@5 100.00 ( 99.74)
Epoch: [82][260/391]	Time  0.028 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.1825e-01 (1.9924e-01)	Acc@1  91.41 ( 94.45)	Acc@5 100.00 ( 99.75)
Epoch: [82][270/391]	Time  0.036 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.8921e-01 (1.9907e-01)	Acc@1  94.53 ( 94.44)	Acc@5 100.00 ( 99.75)
Epoch: [82][280/391]	Time  0.031 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.2765e-01 (1.9938e-01)	Acc@1  98.44 ( 94.44)	Acc@5 100.00 ( 99.74)
Epoch: [82][290/391]	Time  0.032 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.4178e-01 (1.9929e-01)	Acc@1  91.41 ( 94.43)	Acc@5 100.00 ( 99.75)
Epoch: [82][300/391]	Time  0.035 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.4625e-01 (1.9860e-01)	Acc@1  96.88 ( 94.46)	Acc@5 100.00 ( 99.75)
Epoch: [82][310/391]	Time  0.032 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.5419e-01 (1.9978e-01)	Acc@1  92.19 ( 94.41)	Acc@5  99.22 ( 99.75)
Epoch: [82][320/391]	Time  0.031 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.5142e-01 (2.0022e-01)	Acc@1  96.09 ( 94.40)	Acc@5 100.00 ( 99.74)
Epoch: [82][330/391]	Time  0.029 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.1150e-01 (2.0080e-01)	Acc@1  94.53 ( 94.39)	Acc@5 100.00 ( 99.75)
Epoch: [82][340/391]	Time  0.032 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.3161e-01 (2.0117e-01)	Acc@1  90.62 ( 94.37)	Acc@5 100.00 ( 99.74)
Epoch: [82][350/391]	Time  0.035 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.6636e-01 (2.0047e-01)	Acc@1  93.75 ( 94.40)	Acc@5 100.00 ( 99.74)
Epoch: [82][360/391]	Time  0.029 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.2823e-01 (2.0081e-01)	Acc@1  96.09 ( 94.40)	Acc@5  99.22 ( 99.74)
Epoch: [82][370/391]	Time  0.029 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.6532e-01 (2.0089e-01)	Acc@1  96.09 ( 94.38)	Acc@5 100.00 ( 99.74)
Epoch: [82][380/391]	Time  0.031 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.3547e-01 (2.0073e-01)	Acc@1  91.41 ( 94.38)	Acc@5 100.00 ( 99.74)
Epoch: [82][390/391]	Time  0.021 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.9785e-01 (2.0087e-01)	Acc@1  96.25 ( 94.37)	Acc@5 100.00 ( 99.74)
## e[82] optimizer.zero_grad (sum) time: 0.05008435249328613
## e[82]       loss.backward (sum) time: 2.3408284187316895
## e[82]      optimizer.step (sum) time: 0.3744163513183594
## epoch[82] training(only) time: 12.360116243362427
# Switched to evaluate mode...
Test: [  0/100]	Time  0.149 ( 0.149)	Loss 1.2807e+00 (1.2807e+00)	Acc@1  72.00 ( 72.00)	Acc@5  90.00 ( 90.00)
Test: [ 10/100]	Time  0.021 ( 0.034)	Loss 1.4811e+00 (1.4691e+00)	Acc@1  68.00 ( 68.55)	Acc@5  91.00 ( 89.27)
Test: [ 20/100]	Time  0.023 ( 0.029)	Loss 1.2129e+00 (1.4243e+00)	Acc@1  76.00 ( 68.95)	Acc@5  93.00 ( 90.24)
Test: [ 30/100]	Time  0.021 ( 0.027)	Loss 1.7364e+00 (1.4490e+00)	Acc@1  64.00 ( 68.26)	Acc@5  89.00 ( 90.32)
Test: [ 40/100]	Time  0.021 ( 0.026)	Loss 1.4230e+00 (1.4476e+00)	Acc@1  68.00 ( 68.24)	Acc@5  93.00 ( 90.34)
Test: [ 50/100]	Time  0.024 ( 0.025)	Loss 1.4695e+00 (1.4577e+00)	Acc@1  70.00 ( 68.02)	Acc@5  90.00 ( 90.29)
Test: [ 60/100]	Time  0.017 ( 0.024)	Loss 1.5846e+00 (1.4331e+00)	Acc@1  65.00 ( 68.23)	Acc@5  88.00 ( 90.70)
Test: [ 70/100]	Time  0.024 ( 0.024)	Loss 1.6732e+00 (1.4346e+00)	Acc@1  68.00 ( 68.30)	Acc@5  87.00 ( 90.76)
Test: [ 80/100]	Time  0.017 ( 0.024)	Loss 1.5353e+00 (1.4406e+00)	Acc@1  72.00 ( 68.36)	Acc@5  91.00 ( 90.72)
Test: [ 90/100]	Time  0.022 ( 0.023)	Loss 1.7847e+00 (1.4282e+00)	Acc@1  64.00 ( 68.60)	Acc@5  88.00 ( 90.79)
 * Acc@1 68.920 Acc@5 90.890
### epoch[82] execution time: 14.752703666687012
EPOCH 83
REMOVING: module.fire8.expand_3x3.1.bias
REMOVING: module.fire9.squeeze.0.weight
i:   0, name:    module.fire9.squeeze.0.bias  changing lr from: 0.001059319875281760   to: 0.001003023954831738
i:   1, name:  module.fire9.squeeze.1.weight  changing lr from: 0.001113225024591373   to: 0.001022228139766423
i:   2, name:    module.fire9.squeeze.1.bias  changing lr from: 0.001183740509379848   to: 0.001058770252822366
i:   3, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.001270439721296356   to: 0.001112221282993524
i:   4, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.001372900218340305   to: 0.001182155827637237
i:   5, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.001490703944372700   to: 0.001268152345366118
i:   6, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.001623437430783142   to: 0.001369793389827222
i:   7, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.001770691981134602   to: 0.001486665825219396
i:   8, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.001932063839581693   to: 0.001618361024374059
i:   9, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.002107154343832318   to: 0.001764475050199076
i:  10, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.002295570063397211   to: 0.001924608821260220
i:  11, name:           module.conv10.weight  changing lr from: 0.002496922923846145   to: 0.002098368262249433
i:  12, name:             module.conv10.bias  changing lr from: 0.002710830317765122   to: 0.002285364440064529



# Switched to train mode...
Epoch: [83][  0/391]	Time  0.187 ( 0.187)	Data  0.151 ( 0.151)	Loss 1.6516e-01 (1.6516e-01)	Acc@1  96.09 ( 96.09)	Acc@5 100.00 (100.00)
Epoch: [83][ 10/391]	Time  0.034 ( 0.045)	Data  0.001 ( 0.015)	Loss 2.0193e-01 (1.9929e-01)	Acc@1  93.75 ( 93.89)	Acc@5 100.00 ( 99.79)
Epoch: [83][ 20/391]	Time  0.029 ( 0.038)	Data  0.001 ( 0.008)	Loss 2.3171e-01 (1.9605e-01)	Acc@1  94.53 ( 94.27)	Acc@5  99.22 ( 99.85)
Epoch: [83][ 30/391]	Time  0.034 ( 0.036)	Data  0.002 ( 0.006)	Loss 1.9653e-01 (1.9622e-01)	Acc@1  92.97 ( 94.20)	Acc@5 100.00 ( 99.82)
Epoch: [83][ 40/391]	Time  0.028 ( 0.034)	Data  0.001 ( 0.005)	Loss 2.1385e-01 (1.9647e-01)	Acc@1  92.97 ( 94.26)	Acc@5 100.00 ( 99.85)
Epoch: [83][ 50/391]	Time  0.034 ( 0.034)	Data  0.001 ( 0.004)	Loss 1.8267e-01 (1.9060e-01)	Acc@1  94.53 ( 94.67)	Acc@5 100.00 ( 99.83)
Epoch: [83][ 60/391]	Time  0.034 ( 0.033)	Data  0.001 ( 0.004)	Loss 1.7731e-01 (1.9054e-01)	Acc@1  95.31 ( 94.75)	Acc@5 100.00 ( 99.83)
Epoch: [83][ 70/391]	Time  0.034 ( 0.033)	Data  0.001 ( 0.003)	Loss 1.7668e-01 (1.8902e-01)	Acc@1  94.53 ( 94.86)	Acc@5 100.00 ( 99.83)
Epoch: [83][ 80/391]	Time  0.028 ( 0.032)	Data  0.001 ( 0.003)	Loss 1.9631e-01 (1.8767e-01)	Acc@1  95.31 ( 94.95)	Acc@5 100.00 ( 99.83)
Epoch: [83][ 90/391]	Time  0.029 ( 0.032)	Data  0.001 ( 0.003)	Loss 1.9531e-01 (1.8987e-01)	Acc@1  94.53 ( 94.80)	Acc@5 100.00 ( 99.84)
Epoch: [83][100/391]	Time  0.033 ( 0.032)	Data  0.001 ( 0.003)	Loss 1.3499e-01 (1.9153e-01)	Acc@1  96.09 ( 94.77)	Acc@5 100.00 ( 99.82)
Epoch: [83][110/391]	Time  0.029 ( 0.032)	Data  0.001 ( 0.003)	Loss 3.3103e-01 (1.9314e-01)	Acc@1  89.06 ( 94.68)	Acc@5  99.22 ( 99.82)
Epoch: [83][120/391]	Time  0.031 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.9690e-01 (1.9397e-01)	Acc@1  93.75 ( 94.68)	Acc@5 100.00 ( 99.81)
Epoch: [83][130/391]	Time  0.031 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.8791e-01 (1.9409e-01)	Acc@1  96.09 ( 94.68)	Acc@5 100.00 ( 99.82)
Epoch: [83][140/391]	Time  0.030 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.2562e-01 (1.9330e-01)	Acc@1  96.09 ( 94.68)	Acc@5 100.00 ( 99.82)
Epoch: [83][150/391]	Time  0.031 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.8076e-01 (1.9635e-01)	Acc@1  90.62 ( 94.55)	Acc@5 100.00 ( 99.81)
Epoch: [83][160/391]	Time  0.034 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.2060e-01 (1.9534e-01)	Acc@1  94.53 ( 94.57)	Acc@5 100.00 ( 99.81)
Epoch: [83][170/391]	Time  0.029 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.6731e-01 (1.9524e-01)	Acc@1  96.09 ( 94.57)	Acc@5  99.22 ( 99.81)
Epoch: [83][180/391]	Time  0.031 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.2540e-01 (1.9545e-01)	Acc@1  90.62 ( 94.56)	Acc@5  99.22 ( 99.81)
Epoch: [83][190/391]	Time  0.028 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.7132e-01 (1.9643e-01)	Acc@1  96.09 ( 94.52)	Acc@5  99.22 ( 99.80)
Epoch: [83][200/391]	Time  0.029 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.2875e-01 (1.9793e-01)	Acc@1  93.75 ( 94.47)	Acc@5  99.22 ( 99.80)
Epoch: [83][210/391]	Time  0.030 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.3417e-01 (1.9817e-01)	Acc@1  89.84 ( 94.41)	Acc@5  99.22 ( 99.80)
Epoch: [83][220/391]	Time  0.029 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.8126e-01 (1.9861e-01)	Acc@1  95.31 ( 94.41)	Acc@5 100.00 ( 99.80)
Epoch: [83][230/391]	Time  0.033 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.4347e-01 (1.9831e-01)	Acc@1  92.97 ( 94.42)	Acc@5 100.00 ( 99.79)
Epoch: [83][240/391]	Time  0.038 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.0368e-01 (1.9852e-01)	Acc@1  93.75 ( 94.40)	Acc@5 100.00 ( 99.80)
Epoch: [83][250/391]	Time  0.029 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.2747e-01 (1.9821e-01)	Acc@1  97.66 ( 94.42)	Acc@5 100.00 ( 99.80)
Epoch: [83][260/391]	Time  0.035 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.0148e-01 (1.9896e-01)	Acc@1  93.75 ( 94.39)	Acc@5 100.00 ( 99.80)
Epoch: [83][270/391]	Time  0.032 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.5894e-01 (1.9912e-01)	Acc@1  96.88 ( 94.37)	Acc@5 100.00 ( 99.80)
Epoch: [83][280/391]	Time  0.030 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.9743e-01 (2.0006e-01)	Acc@1  90.62 ( 94.33)	Acc@5 100.00 ( 99.80)
Epoch: [83][290/391]	Time  0.029 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.8552e-01 (1.9958e-01)	Acc@1  94.53 ( 94.35)	Acc@5 100.00 ( 99.80)
Epoch: [83][300/391]	Time  0.035 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.3388e-01 (1.9998e-01)	Acc@1  94.53 ( 94.33)	Acc@5 100.00 ( 99.79)
Epoch: [83][310/391]	Time  0.033 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.8153e-01 (1.9996e-01)	Acc@1  93.75 ( 94.32)	Acc@5 100.00 ( 99.80)
Epoch: [83][320/391]	Time  0.031 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.7791e-01 (1.9944e-01)	Acc@1  95.31 ( 94.36)	Acc@5  98.44 ( 99.78)
Epoch: [83][330/391]	Time  0.030 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.6323e-01 (1.9937e-01)	Acc@1  94.53 ( 94.37)	Acc@5 100.00 ( 99.79)
Epoch: [83][340/391]	Time  0.029 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.4513e-01 (1.9922e-01)	Acc@1  89.84 ( 94.36)	Acc@5  99.22 ( 99.79)
Epoch: [83][350/391]	Time  0.031 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.6437e-01 (1.9886e-01)	Acc@1  93.75 ( 94.38)	Acc@5 100.00 ( 99.79)
Epoch: [83][360/391]	Time  0.028 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.0285e-01 (1.9874e-01)	Acc@1  92.19 ( 94.37)	Acc@5  99.22 ( 99.79)
Epoch: [83][370/391]	Time  0.037 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.7866e-01 (1.9845e-01)	Acc@1  95.31 ( 94.38)	Acc@5  99.22 ( 99.79)
Epoch: [83][380/391]	Time  0.029 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.0281e-01 (1.9854e-01)	Acc@1  93.75 ( 94.39)	Acc@5 100.00 ( 99.79)
Epoch: [83][390/391]	Time  0.020 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.5244e-01 (1.9861e-01)	Acc@1  92.50 ( 94.39)	Acc@5 100.00 ( 99.79)
## e[83] optimizer.zero_grad (sum) time: 0.04404282569885254
## e[83]       loss.backward (sum) time: 2.257476568222046
## e[83]      optimizer.step (sum) time: 0.3281137943267822
## epoch[83] training(only) time: 12.175068855285645
# Switched to evaluate mode...
Test: [  0/100]	Time  0.156 ( 0.156)	Loss 1.2928e+00 (1.2928e+00)	Acc@1  73.00 ( 73.00)	Acc@5  91.00 ( 91.00)
Test: [ 10/100]	Time  0.024 ( 0.036)	Loss 1.4441e+00 (1.4759e+00)	Acc@1  69.00 ( 69.55)	Acc@5  91.00 ( 89.45)
Test: [ 20/100]	Time  0.024 ( 0.030)	Loss 1.2143e+00 (1.4300e+00)	Acc@1  76.00 ( 69.76)	Acc@5  93.00 ( 90.33)
Test: [ 30/100]	Time  0.024 ( 0.028)	Loss 1.7504e+00 (1.4578e+00)	Acc@1  61.00 ( 68.77)	Acc@5  90.00 ( 90.26)
Test: [ 40/100]	Time  0.021 ( 0.027)	Loss 1.4165e+00 (1.4561e+00)	Acc@1  67.00 ( 68.66)	Acc@5  92.00 ( 90.37)
Test: [ 50/100]	Time  0.024 ( 0.026)	Loss 1.5046e+00 (1.4682e+00)	Acc@1  68.00 ( 68.33)	Acc@5  89.00 ( 90.29)
Test: [ 60/100]	Time  0.021 ( 0.025)	Loss 1.6242e+00 (1.4445e+00)	Acc@1  65.00 ( 68.46)	Acc@5  88.00 ( 90.70)
Test: [ 70/100]	Time  0.024 ( 0.025)	Loss 1.6873e+00 (1.4457e+00)	Acc@1  68.00 ( 68.42)	Acc@5  87.00 ( 90.72)
Test: [ 80/100]	Time  0.023 ( 0.025)	Loss 1.5349e+00 (1.4507e+00)	Acc@1  73.00 ( 68.51)	Acc@5  89.00 ( 90.68)
Test: [ 90/100]	Time  0.023 ( 0.025)	Loss 1.7627e+00 (1.4366e+00)	Acc@1  65.00 ( 68.78)	Acc@5  88.00 ( 90.77)
 * Acc@1 69.070 Acc@5 90.860
### epoch[83] execution time: 14.681113004684448
EPOCH 84
REMOVING: module.fire9.squeeze.0.bias
REMOVING: module.fire9.squeeze.1.weight
i:   0, name:    module.fire9.squeeze.1.bias  changing lr from: 0.001058770252822366   to: 0.001003149200086217
i:   1, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.001112221282993524   to: 0.001022450765790477
i:   2, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.001182155827637237   to: 0.001058948984684287
i:   3, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.001268152345366118   to: 0.001112219973221495
i:   4, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.001369793389827222   to: 0.001181843400108284
i:   5, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.001486665825219396   to: 0.001267402734158117
i:   6, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.001618361024374059   to: 0.001368485473486380
i:   7, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.001764475050199076   to: 0.001484683356872134
i:   8, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.001924608821260220   to: 0.001615592558089739
i:   9, name:           module.conv10.weight  changing lr from: 0.002098368262249433   to: 0.001760813863988175
i:  10, name:             module.conv10.bias  changing lr from: 0.002285364440064529   to: 0.001919952837071525



# Switched to train mode...
Epoch: [84][  0/391]	Time  0.185 ( 0.185)	Data  0.150 ( 0.150)	Loss 1.8614e-01 (1.8614e-01)	Acc@1  92.19 ( 92.19)	Acc@5 100.00 (100.00)
Epoch: [84][ 10/391]	Time  0.032 ( 0.045)	Data  0.001 ( 0.015)	Loss 2.0613e-01 (1.8996e-01)	Acc@1  92.97 ( 94.89)	Acc@5 100.00 ( 99.72)
Epoch: [84][ 20/391]	Time  0.029 ( 0.038)	Data  0.001 ( 0.008)	Loss 1.6536e-01 (1.9026e-01)	Acc@1  96.09 ( 94.98)	Acc@5 100.00 ( 99.70)
Epoch: [84][ 30/391]	Time  0.028 ( 0.035)	Data  0.001 ( 0.006)	Loss 1.9005e-01 (1.9098e-01)	Acc@1  92.19 ( 94.98)	Acc@5 100.00 ( 99.75)
Epoch: [84][ 40/391]	Time  0.034 ( 0.034)	Data  0.001 ( 0.005)	Loss 2.1016e-01 (1.9665e-01)	Acc@1  96.09 ( 94.76)	Acc@5 100.00 ( 99.75)
Epoch: [84][ 50/391]	Time  0.028 ( 0.034)	Data  0.001 ( 0.004)	Loss 1.7738e-01 (2.0054e-01)	Acc@1  97.66 ( 94.61)	Acc@5 100.00 ( 99.75)
Epoch: [84][ 60/391]	Time  0.027 ( 0.033)	Data  0.001 ( 0.004)	Loss 1.5441e-01 (1.9767e-01)	Acc@1  96.09 ( 94.62)	Acc@5 100.00 ( 99.74)
Epoch: [84][ 70/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.003)	Loss 1.7688e-01 (1.9880e-01)	Acc@1  95.31 ( 94.47)	Acc@5 100.00 ( 99.77)
Epoch: [84][ 80/391]	Time  0.028 ( 0.033)	Data  0.001 ( 0.003)	Loss 2.1706e-01 (1.9967e-01)	Acc@1  95.31 ( 94.43)	Acc@5  99.22 ( 99.75)
Epoch: [84][ 90/391]	Time  0.031 ( 0.032)	Data  0.001 ( 0.003)	Loss 1.6869e-01 (1.9939e-01)	Acc@1  92.97 ( 94.45)	Acc@5 100.00 ( 99.75)
Epoch: [84][100/391]	Time  0.032 ( 0.032)	Data  0.001 ( 0.003)	Loss 2.0737e-01 (1.9824e-01)	Acc@1  92.97 ( 94.45)	Acc@5 100.00 ( 99.75)
Epoch: [84][110/391]	Time  0.033 ( 0.032)	Data  0.001 ( 0.003)	Loss 2.1755e-01 (1.9840e-01)	Acc@1  92.97 ( 94.39)	Acc@5  99.22 ( 99.75)
Epoch: [84][120/391]	Time  0.028 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.1103e-01 (1.9856e-01)	Acc@1  94.53 ( 94.42)	Acc@5  99.22 ( 99.75)
Epoch: [84][130/391]	Time  0.028 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.0579e-01 (1.9742e-01)	Acc@1  94.53 ( 94.48)	Acc@5 100.00 ( 99.76)
Epoch: [84][140/391]	Time  0.031 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.9866e-01 (1.9809e-01)	Acc@1  95.31 ( 94.40)	Acc@5 100.00 ( 99.77)
Epoch: [84][150/391]	Time  0.037 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.7272e-01 (1.9765e-01)	Acc@1  93.75 ( 94.41)	Acc@5 100.00 ( 99.77)
Epoch: [84][160/391]	Time  0.039 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.1020e-01 (1.9813e-01)	Acc@1  93.75 ( 94.36)	Acc@5 100.00 ( 99.77)
Epoch: [84][170/391]	Time  0.030 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.9585e-01 (1.9803e-01)	Acc@1  92.97 ( 94.36)	Acc@5 100.00 ( 99.77)
Epoch: [84][180/391]	Time  0.030 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.6906e-01 (1.9947e-01)	Acc@1  89.84 ( 94.30)	Acc@5 100.00 ( 99.76)
Epoch: [84][190/391]	Time  0.031 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.8378e-01 (1.9923e-01)	Acc@1  96.88 ( 94.36)	Acc@5 100.00 ( 99.76)
Epoch: [84][200/391]	Time  0.030 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.3567e-01 (1.9915e-01)	Acc@1  92.97 ( 94.37)	Acc@5 100.00 ( 99.76)
Epoch: [84][210/391]	Time  0.033 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.3928e-01 (1.9904e-01)	Acc@1  95.31 ( 94.34)	Acc@5 100.00 ( 99.77)
Epoch: [84][220/391]	Time  0.029 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.6667e-01 (1.9835e-01)	Acc@1  96.88 ( 94.37)	Acc@5 100.00 ( 99.77)
Epoch: [84][230/391]	Time  0.030 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.4133e-01 (1.9803e-01)	Acc@1  92.19 ( 94.38)	Acc@5  99.22 ( 99.76)
Epoch: [84][240/391]	Time  0.033 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.6064e-01 (1.9673e-01)	Acc@1  96.88 ( 94.44)	Acc@5 100.00 ( 99.76)
Epoch: [84][250/391]	Time  0.029 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.4888e-01 (1.9619e-01)	Acc@1  92.19 ( 94.45)	Acc@5  99.22 ( 99.76)
Epoch: [84][260/391]	Time  0.030 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.0121e-01 (1.9623e-01)	Acc@1  94.53 ( 94.48)	Acc@5 100.00 ( 99.76)
Epoch: [84][270/391]	Time  0.031 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.6448e-01 (1.9602e-01)	Acc@1  91.41 ( 94.49)	Acc@5 100.00 ( 99.76)
Epoch: [84][280/391]	Time  0.033 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.5507e-01 (1.9632e-01)	Acc@1  93.75 ( 94.47)	Acc@5 100.00 ( 99.77)
Epoch: [84][290/391]	Time  0.032 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.5736e-01 (1.9645e-01)	Acc@1  89.84 ( 94.47)	Acc@5 100.00 ( 99.77)
Epoch: [84][300/391]	Time  0.026 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.5489e-01 (1.9744e-01)	Acc@1  91.41 ( 94.41)	Acc@5 100.00 ( 99.77)
Epoch: [84][310/391]	Time  0.029 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.6559e-01 (1.9841e-01)	Acc@1  95.31 ( 94.38)	Acc@5 100.00 ( 99.77)
Epoch: [84][320/391]	Time  0.029 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.6311e-01 (1.9902e-01)	Acc@1  91.41 ( 94.33)	Acc@5 100.00 ( 99.77)
Epoch: [84][330/391]	Time  0.028 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.5310e-01 (1.9929e-01)	Acc@1  96.88 ( 94.31)	Acc@5  99.22 ( 99.77)
Epoch: [84][340/391]	Time  0.031 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.5392e-01 (1.9870e-01)	Acc@1  96.88 ( 94.34)	Acc@5  99.22 ( 99.77)
Epoch: [84][350/391]	Time  0.033 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.3020e-01 (1.9845e-01)	Acc@1  91.41 ( 94.36)	Acc@5 100.00 ( 99.77)
Epoch: [84][360/391]	Time  0.028 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.2433e-01 (1.9866e-01)	Acc@1  96.88 ( 94.33)	Acc@5 100.00 ( 99.77)
Epoch: [84][370/391]	Time  0.036 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.7059e-01 (1.9847e-01)	Acc@1  96.09 ( 94.33)	Acc@5 100.00 ( 99.77)
Epoch: [84][380/391]	Time  0.029 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.0625e-01 (1.9831e-01)	Acc@1  95.31 ( 94.35)	Acc@5 100.00 ( 99.77)
Epoch: [84][390/391]	Time  0.020 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.3661e-01 (1.9844e-01)	Acc@1  92.50 ( 94.33)	Acc@5 100.00 ( 99.78)
## e[84] optimizer.zero_grad (sum) time: 0.03887367248535156
## e[84]       loss.backward (sum) time: 2.174649715423584
## e[84]      optimizer.step (sum) time: 0.2743048667907715
## epoch[84] training(only) time: 12.256408452987671
# Switched to evaluate mode...
Test: [  0/100]	Time  0.159 ( 0.159)	Loss 1.3109e+00 (1.3109e+00)	Acc@1  72.00 ( 72.00)	Acc@5  89.00 ( 89.00)
Test: [ 10/100]	Time  0.024 ( 0.036)	Loss 1.4725e+00 (1.4786e+00)	Acc@1  68.00 ( 68.55)	Acc@5  91.00 ( 89.36)
Test: [ 20/100]	Time  0.025 ( 0.030)	Loss 1.2267e+00 (1.4265e+00)	Acc@1  76.00 ( 69.19)	Acc@5  93.00 ( 90.33)
Test: [ 30/100]	Time  0.022 ( 0.027)	Loss 1.7546e+00 (1.4562e+00)	Acc@1  63.00 ( 68.03)	Acc@5  89.00 ( 90.35)
Test: [ 40/100]	Time  0.018 ( 0.025)	Loss 1.4273e+00 (1.4526e+00)	Acc@1  67.00 ( 68.29)	Acc@5  92.00 ( 90.41)
Test: [ 50/100]	Time  0.017 ( 0.024)	Loss 1.4872e+00 (1.4634e+00)	Acc@1  67.00 ( 68.04)	Acc@5  88.00 ( 90.27)
Test: [ 60/100]	Time  0.016 ( 0.024)	Loss 1.6393e+00 (1.4401e+00)	Acc@1  63.00 ( 68.18)	Acc@5  86.00 ( 90.66)
Test: [ 70/100]	Time  0.018 ( 0.023)	Loss 1.6698e+00 (1.4424e+00)	Acc@1  69.00 ( 68.21)	Acc@5  87.00 ( 90.66)
Test: [ 80/100]	Time  0.024 ( 0.023)	Loss 1.5523e+00 (1.4481e+00)	Acc@1  71.00 ( 68.28)	Acc@5  89.00 ( 90.60)
Test: [ 90/100]	Time  0.024 ( 0.023)	Loss 1.7613e+00 (1.4356e+00)	Acc@1  67.00 ( 68.60)	Acc@5  87.00 ( 90.73)
 * Acc@1 68.850 Acc@5 90.840
### epoch[84] execution time: 14.627177715301514
EPOCH 85
REMOVING: module.fire9.squeeze.1.bias
REMOVING: module.fire9.expand_1x1.0.weight
i:   0, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.001058948984684287   to: 0.001003446719752992
i:   1, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.001112219973221495   to: 0.001023115710064964
i:   2, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.001181843400108284   to: 0.001059836245524220
i:   3, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.001267402734158117   to: 0.001113189502407707
i:   4, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.001368485473486380   to: 0.001182760158637774
i:   5, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.001484683356872134   to: 0.001268136636463984
i:   6, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.001615592558089739   to: 0.001368911326934018
i:   7, name:           module.conv10.weight  changing lr from: 0.001760813863988175   to: 0.001484680796958326
i:   8, name:             module.conv10.bias  changing lr from: 0.001919952837071525   to: 0.001615045979749002



# Switched to train mode...
Epoch: [85][  0/391]	Time  0.185 ( 0.185)	Data  0.151 ( 0.151)	Loss 1.7457e-01 (1.7457e-01)	Acc@1  95.31 ( 95.31)	Acc@5 100.00 (100.00)
Epoch: [85][ 10/391]	Time  0.034 ( 0.046)	Data  0.004 ( 0.015)	Loss 1.9633e-01 (1.8538e-01)	Acc@1  92.97 ( 94.67)	Acc@5 100.00 (100.00)
Epoch: [85][ 20/391]	Time  0.030 ( 0.039)	Data  0.001 ( 0.008)	Loss 2.3947e-01 (1.7915e-01)	Acc@1  92.19 ( 95.20)	Acc@5 100.00 ( 99.93)
Epoch: [85][ 30/391]	Time  0.033 ( 0.036)	Data  0.001 ( 0.006)	Loss 2.0888e-01 (1.8627e-01)	Acc@1  92.97 ( 94.98)	Acc@5 100.00 ( 99.90)
Epoch: [85][ 40/391]	Time  0.028 ( 0.035)	Data  0.001 ( 0.005)	Loss 2.4240e-01 (1.8781e-01)	Acc@1  91.41 ( 94.78)	Acc@5 100.00 ( 99.90)
Epoch: [85][ 50/391]	Time  0.028 ( 0.034)	Data  0.001 ( 0.004)	Loss 1.4994e-01 (1.8809e-01)	Acc@1  96.88 ( 94.73)	Acc@5 100.00 ( 99.89)
Epoch: [85][ 60/391]	Time  0.033 ( 0.033)	Data  0.001 ( 0.004)	Loss 1.9418e-01 (1.9101e-01)	Acc@1  96.88 ( 94.62)	Acc@5 100.00 ( 99.90)
Epoch: [85][ 70/391]	Time  0.028 ( 0.033)	Data  0.001 ( 0.003)	Loss 1.6659e-01 (1.9199e-01)	Acc@1  96.88 ( 94.65)	Acc@5 100.00 ( 99.88)
Epoch: [85][ 80/391]	Time  0.029 ( 0.032)	Data  0.001 ( 0.003)	Loss 2.1357e-01 (1.9332e-01)	Acc@1  92.97 ( 94.67)	Acc@5 100.00 ( 99.85)
Epoch: [85][ 90/391]	Time  0.030 ( 0.032)	Data  0.001 ( 0.003)	Loss 1.5106e-01 (1.9486e-01)	Acc@1  97.66 ( 94.59)	Acc@5 100.00 ( 99.81)
Epoch: [85][100/391]	Time  0.028 ( 0.032)	Data  0.001 ( 0.003)	Loss 1.4291e-01 (1.9550e-01)	Acc@1  96.88 ( 94.59)	Acc@5 100.00 ( 99.75)
Epoch: [85][110/391]	Time  0.031 ( 0.032)	Data  0.001 ( 0.003)	Loss 1.7273e-01 (1.9319e-01)	Acc@1  95.31 ( 94.69)	Acc@5 100.00 ( 99.77)
Epoch: [85][120/391]	Time  0.028 ( 0.032)	Data  0.001 ( 0.003)	Loss 2.4696e-01 (1.9468e-01)	Acc@1  92.97 ( 94.62)	Acc@5 100.00 ( 99.78)
Epoch: [85][130/391]	Time  0.028 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.7794e-01 (1.9583e-01)	Acc@1  94.53 ( 94.56)	Acc@5 100.00 ( 99.79)
Epoch: [85][140/391]	Time  0.027 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.8567e-01 (1.9751e-01)	Acc@1  95.31 ( 94.50)	Acc@5 100.00 ( 99.79)
Epoch: [85][150/391]	Time  0.028 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.0382e-01 (1.9719e-01)	Acc@1  93.75 ( 94.54)	Acc@5  99.22 ( 99.78)
Epoch: [85][160/391]	Time  0.039 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.5856e-01 (1.9825e-01)	Acc@1  90.62 ( 94.49)	Acc@5 100.00 ( 99.79)
Epoch: [85][170/391]	Time  0.034 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.9396e-01 (1.9775e-01)	Acc@1  95.31 ( 94.52)	Acc@5  99.22 ( 99.78)
Epoch: [85][180/391]	Time  0.027 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.6924e-01 (1.9743e-01)	Acc@1  95.31 ( 94.52)	Acc@5 100.00 ( 99.76)
Epoch: [85][190/391]	Time  0.027 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.7754e-01 (1.9784e-01)	Acc@1  95.31 ( 94.50)	Acc@5 100.00 ( 99.76)
Epoch: [85][200/391]	Time  0.030 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.9389e-01 (1.9744e-01)	Acc@1  98.44 ( 94.52)	Acc@5 100.00 ( 99.77)
Epoch: [85][210/391]	Time  0.036 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.1789e-01 (1.9777e-01)	Acc@1  98.44 ( 94.52)	Acc@5 100.00 ( 99.77)
Epoch: [85][220/391]	Time  0.030 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.0634e-01 (1.9787e-01)	Acc@1  93.75 ( 94.52)	Acc@5  99.22 ( 99.78)
Epoch: [85][230/391]	Time  0.028 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.8104e-01 (1.9825e-01)	Acc@1  94.53 ( 94.51)	Acc@5 100.00 ( 99.78)
Epoch: [85][240/391]	Time  0.028 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.2904e-01 (1.9917e-01)	Acc@1  97.66 ( 94.45)	Acc@5 100.00 ( 99.78)
Epoch: [85][250/391]	Time  0.028 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.6375e-01 (1.9859e-01)	Acc@1  97.66 ( 94.48)	Acc@5 100.00 ( 99.79)
Epoch: [85][260/391]	Time  0.031 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.9668e-01 (1.9845e-01)	Acc@1  94.53 ( 94.47)	Acc@5 100.00 ( 99.79)
Epoch: [85][270/391]	Time  0.029 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.8725e-01 (1.9835e-01)	Acc@1  96.09 ( 94.47)	Acc@5 100.00 ( 99.80)
Epoch: [85][280/391]	Time  0.031 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.7395e-01 (1.9840e-01)	Acc@1  96.09 ( 94.46)	Acc@5 100.00 ( 99.79)
Epoch: [85][290/391]	Time  0.030 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.5927e-01 (1.9815e-01)	Acc@1  96.88 ( 94.46)	Acc@5 100.00 ( 99.80)
Epoch: [85][300/391]	Time  0.032 ( 0.031)	Data  0.003 ( 0.002)	Loss 2.0240e-01 (1.9780e-01)	Acc@1  92.19 ( 94.45)	Acc@5 100.00 ( 99.80)
Epoch: [85][310/391]	Time  0.027 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.6625e-01 (1.9817e-01)	Acc@1  95.31 ( 94.45)	Acc@5  99.22 ( 99.80)
Epoch: [85][320/391]	Time  0.028 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.3087e-01 (1.9909e-01)	Acc@1  93.75 ( 94.42)	Acc@5  99.22 ( 99.80)
Epoch: [85][330/391]	Time  0.027 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.4936e-01 (1.9843e-01)	Acc@1  95.31 ( 94.43)	Acc@5 100.00 ( 99.80)
Epoch: [85][340/391]	Time  0.032 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.1978e-01 (1.9798e-01)	Acc@1  94.53 ( 94.46)	Acc@5 100.00 ( 99.80)
Epoch: [85][350/391]	Time  0.027 ( 0.031)	Data  0.000 ( 0.002)	Loss 2.1977e-01 (1.9845e-01)	Acc@1  92.19 ( 94.43)	Acc@5 100.00 ( 99.81)
Epoch: [85][360/391]	Time  0.033 ( 0.031)	Data  0.002 ( 0.002)	Loss 1.4050e-01 (1.9853e-01)	Acc@1  96.88 ( 94.42)	Acc@5 100.00 ( 99.81)
Epoch: [85][370/391]	Time  0.030 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.6599e-01 (1.9887e-01)	Acc@1  95.31 ( 94.39)	Acc@5 100.00 ( 99.81)
Epoch: [85][380/391]	Time  0.026 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.2489e-01 (1.9852e-01)	Acc@1  92.19 ( 94.40)	Acc@5 100.00 ( 99.81)
Epoch: [85][390/391]	Time  0.019 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.7207e-01 (1.9862e-01)	Acc@1  86.25 ( 94.37)	Acc@5  98.75 ( 99.81)
## e[85] optimizer.zero_grad (sum) time: 0.03267502784729004
## e[85]       loss.backward (sum) time: 2.0416722297668457
## e[85]      optimizer.step (sum) time: 0.2333545684814453
## epoch[85] training(only) time: 12.019960403442383
# Switched to evaluate mode...
Test: [  0/100]	Time  0.150 ( 0.150)	Loss 1.3268e+00 (1.3268e+00)	Acc@1  70.00 ( 70.00)	Acc@5  88.00 ( 88.00)
Test: [ 10/100]	Time  0.024 ( 0.035)	Loss 1.4887e+00 (1.4721e+00)	Acc@1  69.00 ( 69.18)	Acc@5  91.00 ( 89.09)
Test: [ 20/100]	Time  0.024 ( 0.029)	Loss 1.2059e+00 (1.4227e+00)	Acc@1  75.00 ( 69.38)	Acc@5  94.00 ( 90.33)
Test: [ 30/100]	Time  0.024 ( 0.027)	Loss 1.7665e+00 (1.4538e+00)	Acc@1  59.00 ( 68.32)	Acc@5  90.00 ( 90.35)
Test: [ 40/100]	Time  0.021 ( 0.026)	Loss 1.4364e+00 (1.4537e+00)	Acc@1  68.00 ( 68.37)	Acc@5  93.00 ( 90.39)
Test: [ 50/100]	Time  0.024 ( 0.026)	Loss 1.4612e+00 (1.4648e+00)	Acc@1  68.00 ( 68.24)	Acc@5  90.00 ( 90.27)
Test: [ 60/100]	Time  0.018 ( 0.025)	Loss 1.6407e+00 (1.4413e+00)	Acc@1  63.00 ( 68.36)	Acc@5  86.00 ( 90.67)
Test: [ 70/100]	Time  0.023 ( 0.025)	Loss 1.6644e+00 (1.4426e+00)	Acc@1  68.00 ( 68.35)	Acc@5  88.00 ( 90.63)
Test: [ 80/100]	Time  0.024 ( 0.024)	Loss 1.5332e+00 (1.4488e+00)	Acc@1  74.00 ( 68.40)	Acc@5  89.00 ( 90.58)
Test: [ 90/100]	Time  0.021 ( 0.024)	Loss 1.7163e+00 (1.4352e+00)	Acc@1  63.00 ( 68.68)	Acc@5  88.00 ( 90.71)
 * Acc@1 68.890 Acc@5 90.840
### epoch[85] execution time: 14.488914966583252
EPOCH 86
REMOVING: module.fire9.expand_1x1.0.bias
REMOVING: module.fire9.expand_1x1.1.weight
i:   0, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.001059836245524220   to: 0.001003933423372998
i:   1, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.001113189502407707   to: 0.001024227839703445
i:   2, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.001182760158637774   to: 0.001061425135423954
i:   3, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.001268136636463984   to: 0.001115111479985164
i:   4, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.001368911326934018   to: 0.001184876498997799
i:   5, name:           module.conv10.weight  changing lr from: 0.001484680796958326   to: 0.001270313511625136
i:   6, name:             module.conv10.bias  changing lr from: 0.001615045979749002   to: 0.001371019750210400



# Switched to train mode...
Epoch: [86][  0/391]	Time  0.192 ( 0.192)	Data  0.155 ( 0.155)	Loss 8.4908e-02 (8.4908e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [86][ 10/391]	Time  0.033 ( 0.045)	Data  0.001 ( 0.015)	Loss 2.3350e-01 (2.0624e-01)	Acc@1  93.75 ( 94.11)	Acc@5 100.00 ( 99.57)
Epoch: [86][ 20/391]	Time  0.030 ( 0.038)	Data  0.001 ( 0.009)	Loss 1.3187e-01 (1.9807e-01)	Acc@1  96.09 ( 94.61)	Acc@5 100.00 ( 99.70)
Epoch: [86][ 30/391]	Time  0.030 ( 0.035)	Data  0.001 ( 0.006)	Loss 2.1859e-01 (1.9429e-01)	Acc@1  92.19 ( 94.61)	Acc@5 100.00 ( 99.75)
Epoch: [86][ 40/391]	Time  0.030 ( 0.034)	Data  0.001 ( 0.005)	Loss 1.9660e-01 (1.9790e-01)	Acc@1  95.31 ( 94.44)	Acc@5 100.00 ( 99.73)
Epoch: [86][ 50/391]	Time  0.028 ( 0.033)	Data  0.001 ( 0.004)	Loss 1.6236e-01 (1.9696e-01)	Acc@1  95.31 ( 94.47)	Acc@5 100.00 ( 99.72)
Epoch: [86][ 60/391]	Time  0.030 ( 0.033)	Data  0.001 ( 0.004)	Loss 2.7026e-01 (1.9636e-01)	Acc@1  91.41 ( 94.49)	Acc@5 100.00 ( 99.74)
Epoch: [86][ 70/391]	Time  0.029 ( 0.032)	Data  0.001 ( 0.003)	Loss 1.9636e-01 (1.9594e-01)	Acc@1  94.53 ( 94.56)	Acc@5 100.00 ( 99.76)
Epoch: [86][ 80/391]	Time  0.027 ( 0.032)	Data  0.001 ( 0.003)	Loss 2.3960e-01 (1.9771e-01)	Acc@1  92.97 ( 94.55)	Acc@5 100.00 ( 99.76)
Epoch: [86][ 90/391]	Time  0.027 ( 0.032)	Data  0.001 ( 0.003)	Loss 1.7776e-01 (2.0026e-01)	Acc@1  96.09 ( 94.39)	Acc@5  99.22 ( 99.75)
Epoch: [86][100/391]	Time  0.033 ( 0.032)	Data  0.001 ( 0.003)	Loss 2.2532e-01 (2.0082e-01)	Acc@1  93.75 ( 94.41)	Acc@5  98.44 ( 99.75)
Epoch: [86][110/391]	Time  0.027 ( 0.031)	Data  0.001 ( 0.003)	Loss 2.1871e-01 (2.0002e-01)	Acc@1  92.19 ( 94.38)	Acc@5 100.00 ( 99.77)
Epoch: [86][120/391]	Time  0.031 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.1503e-01 (1.9854e-01)	Acc@1  91.41 ( 94.38)	Acc@5  99.22 ( 99.77)
Epoch: [86][130/391]	Time  0.028 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.6033e-01 (1.9947e-01)	Acc@1  96.09 ( 94.32)	Acc@5 100.00 ( 99.76)
Epoch: [86][140/391]	Time  0.037 ( 0.031)	Data  0.002 ( 0.002)	Loss 2.0267e-01 (1.9959e-01)	Acc@1  92.97 ( 94.31)	Acc@5 100.00 ( 99.76)
Epoch: [86][150/391]	Time  0.036 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.9091e-01 (2.0029e-01)	Acc@1  94.53 ( 94.32)	Acc@5 100.00 ( 99.76)
Epoch: [86][160/391]	Time  0.027 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.3870e-01 (1.9985e-01)	Acc@1  91.41 ( 94.34)	Acc@5 100.00 ( 99.76)
Epoch: [86][170/391]	Time  0.029 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.5015e-01 (1.9897e-01)	Acc@1  96.88 ( 94.40)	Acc@5 100.00 ( 99.77)
Epoch: [86][180/391]	Time  0.030 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.8579e-01 (1.9818e-01)	Acc@1  96.09 ( 94.41)	Acc@5 100.00 ( 99.78)
Epoch: [86][190/391]	Time  0.038 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.3749e-01 (1.9796e-01)	Acc@1  95.31 ( 94.43)	Acc@5 100.00 ( 99.78)
Epoch: [86][200/391]	Time  0.029 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.1096e-01 (1.9795e-01)	Acc@1  92.97 ( 94.43)	Acc@5  99.22 ( 99.78)
Epoch: [86][210/391]	Time  0.027 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.1772e-01 (1.9829e-01)	Acc@1  92.19 ( 94.45)	Acc@5 100.00 ( 99.79)
Epoch: [86][220/391]	Time  0.029 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.5532e-01 (1.9769e-01)	Acc@1  96.09 ( 94.48)	Acc@5 100.00 ( 99.79)
Epoch: [86][230/391]	Time  0.032 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.2996e-01 (1.9881e-01)	Acc@1  90.62 ( 94.43)	Acc@5 100.00 ( 99.80)
Epoch: [86][240/391]	Time  0.028 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.5468e-01 (1.9897e-01)	Acc@1  96.09 ( 94.41)	Acc@5 100.00 ( 99.80)
Epoch: [86][250/391]	Time  0.029 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.9087e-01 (1.9899e-01)	Acc@1  96.09 ( 94.41)	Acc@5 100.00 ( 99.81)
Epoch: [86][260/391]	Time  0.037 ( 0.031)	Data  0.005 ( 0.002)	Loss 2.0934e-01 (2.0032e-01)	Acc@1  91.41 ( 94.35)	Acc@5 100.00 ( 99.80)
Epoch: [86][270/391]	Time  0.027 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.1093e-01 (1.9995e-01)	Acc@1  93.75 ( 94.37)	Acc@5 100.00 ( 99.81)
Epoch: [86][280/391]	Time  0.029 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.4023e-01 (2.0028e-01)	Acc@1  93.75 ( 94.36)	Acc@5 100.00 ( 99.80)
Epoch: [86][290/391]	Time  0.027 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.6346e-01 (2.0026e-01)	Acc@1  95.31 ( 94.37)	Acc@5 100.00 ( 99.80)
Epoch: [86][300/391]	Time  0.028 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.9036e-01 (2.0038e-01)	Acc@1  92.97 ( 94.35)	Acc@5 100.00 ( 99.81)
Epoch: [86][310/391]	Time  0.027 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.6172e-01 (2.0006e-01)	Acc@1  96.88 ( 94.37)	Acc@5 100.00 ( 99.81)
Epoch: [86][320/391]	Time  0.027 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.7694e-01 (2.0033e-01)	Acc@1  95.31 ( 94.36)	Acc@5 100.00 ( 99.80)
Epoch: [86][330/391]	Time  0.030 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.0473e-01 (2.0035e-01)	Acc@1  92.97 ( 94.34)	Acc@5 100.00 ( 99.80)
Epoch: [86][340/391]	Time  0.027 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.9034e-01 (2.0040e-01)	Acc@1  96.09 ( 94.33)	Acc@5  99.22 ( 99.80)
Epoch: [86][350/391]	Time  0.035 ( 0.030)	Data  0.002 ( 0.002)	Loss 1.2674e-01 (2.0018e-01)	Acc@1  96.88 ( 94.32)	Acc@5 100.00 ( 99.80)
Epoch: [86][360/391]	Time  0.035 ( 0.030)	Data  0.001 ( 0.002)	Loss 2.1043e-01 (2.0004e-01)	Acc@1  93.75 ( 94.32)	Acc@5 100.00 ( 99.80)
Epoch: [86][370/391]	Time  0.028 ( 0.030)	Data  0.001 ( 0.002)	Loss 2.0094e-01 (2.0061e-01)	Acc@1  92.19 ( 94.30)	Acc@5 100.00 ( 99.80)
Epoch: [86][380/391]	Time  0.035 ( 0.030)	Data  0.001 ( 0.002)	Loss 2.8534e-01 (2.0060e-01)	Acc@1  90.62 ( 94.29)	Acc@5  99.22 ( 99.80)
Epoch: [86][390/391]	Time  0.020 ( 0.030)	Data  0.001 ( 0.002)	Loss 1.7400e-01 (2.0067e-01)	Acc@1  92.50 ( 94.28)	Acc@5 100.00 ( 99.79)
## e[86] optimizer.zero_grad (sum) time: 0.027522563934326172
## e[86]       loss.backward (sum) time: 2.027780294418335
## e[86]      optimizer.step (sum) time: 0.18523335456848145
## epoch[86] training(only) time: 11.976746082305908
# Switched to evaluate mode...
Test: [  0/100]	Time  0.150 ( 0.150)	Loss 1.3215e+00 (1.3215e+00)	Acc@1  71.00 ( 71.00)	Acc@5  88.00 ( 88.00)
Test: [ 10/100]	Time  0.024 ( 0.035)	Loss 1.4653e+00 (1.4684e+00)	Acc@1  68.00 ( 68.73)	Acc@5  91.00 ( 89.36)
Test: [ 20/100]	Time  0.029 ( 0.029)	Loss 1.1999e+00 (1.4182e+00)	Acc@1  75.00 ( 69.24)	Acc@5  94.00 ( 90.19)
Test: [ 30/100]	Time  0.024 ( 0.028)	Loss 1.7429e+00 (1.4485e+00)	Acc@1  61.00 ( 68.19)	Acc@5  91.00 ( 90.26)
Test: [ 40/100]	Time  0.024 ( 0.027)	Loss 1.4084e+00 (1.4442e+00)	Acc@1  67.00 ( 68.24)	Acc@5  93.00 ( 90.27)
Test: [ 50/100]	Time  0.024 ( 0.026)	Loss 1.4439e+00 (1.4519e+00)	Acc@1  69.00 ( 68.12)	Acc@5  92.00 ( 90.24)
Test: [ 60/100]	Time  0.024 ( 0.026)	Loss 1.6236e+00 (1.4284e+00)	Acc@1  62.00 ( 68.25)	Acc@5  86.00 ( 90.62)
Test: [ 70/100]	Time  0.019 ( 0.025)	Loss 1.6448e+00 (1.4312e+00)	Acc@1  68.00 ( 68.20)	Acc@5  86.00 ( 90.65)
Test: [ 80/100]	Time  0.024 ( 0.025)	Loss 1.5137e+00 (1.4361e+00)	Acc@1  73.00 ( 68.28)	Acc@5  89.00 ( 90.59)
Test: [ 90/100]	Time  0.021 ( 0.024)	Loss 1.7547e+00 (1.4226e+00)	Acc@1  64.00 ( 68.58)	Acc@5  88.00 ( 90.75)
 * Acc@1 68.880 Acc@5 90.860
### epoch[86] execution time: 14.454490900039673
EPOCH 87
REMOVING: module.fire9.expand_1x1.1.bias
REMOVING: module.fire9.expand_3x3.0.weight
i:   0, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.001061425135423954   to: 0.001004637233038102
i:   1, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.001115111479985164   to: 0.001025803343559833
i:   2, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.001184876498997799   to: 0.001063720370616826
i:   3, name:           module.conv10.weight  changing lr from: 0.001270313511625136   to: 0.001117979411353114
i:   4, name:             module.conv10.bias  changing lr from: 0.001371019750210400   to: 0.001188174978340949



# Switched to train mode...
Epoch: [87][  0/391]	Time  0.183 ( 0.183)	Data  0.150 ( 0.150)	Loss 3.5146e-01 (3.5146e-01)	Acc@1  89.84 ( 89.84)	Acc@5  97.66 ( 97.66)
Epoch: [87][ 10/391]	Time  0.026 ( 0.043)	Data  0.001 ( 0.015)	Loss 1.6165e-01 (1.8095e-01)	Acc@1  97.66 ( 95.17)	Acc@5 100.00 ( 99.72)
Epoch: [87][ 20/391]	Time  0.026 ( 0.036)	Data  0.001 ( 0.008)	Loss 2.2861e-01 (1.9255e-01)	Acc@1  92.97 ( 94.94)	Acc@5  99.22 ( 99.63)
Epoch: [87][ 30/391]	Time  0.028 ( 0.034)	Data  0.001 ( 0.006)	Loss 1.3975e-01 (1.9449e-01)	Acc@1  96.88 ( 94.83)	Acc@5 100.00 ( 99.62)
Epoch: [87][ 40/391]	Time  0.028 ( 0.033)	Data  0.001 ( 0.005)	Loss 2.2080e-01 (1.9645e-01)	Acc@1  92.19 ( 94.55)	Acc@5 100.00 ( 99.68)
Epoch: [87][ 50/391]	Time  0.031 ( 0.032)	Data  0.001 ( 0.004)	Loss 2.2278e-01 (1.9905e-01)	Acc@1  92.19 ( 94.30)	Acc@5  99.22 ( 99.68)
Epoch: [87][ 60/391]	Time  0.027 ( 0.032)	Data  0.001 ( 0.004)	Loss 1.9777e-01 (1.9676e-01)	Acc@1  95.31 ( 94.40)	Acc@5  99.22 ( 99.69)
Epoch: [87][ 70/391]	Time  0.027 ( 0.031)	Data  0.001 ( 0.003)	Loss 1.9319e-01 (1.9495e-01)	Acc@1  95.31 ( 94.49)	Acc@5  99.22 ( 99.72)
Epoch: [87][ 80/391]	Time  0.027 ( 0.031)	Data  0.001 ( 0.003)	Loss 2.0367e-01 (1.9656e-01)	Acc@1  93.75 ( 94.40)	Acc@5 100.00 ( 99.75)
Epoch: [87][ 90/391]	Time  0.036 ( 0.031)	Data  0.001 ( 0.003)	Loss 2.0743e-01 (1.9896e-01)	Acc@1  96.09 ( 94.33)	Acc@5 100.00 ( 99.76)
Epoch: [87][100/391]	Time  0.032 ( 0.031)	Data  0.001 ( 0.003)	Loss 1.6234e-01 (2.0055e-01)	Acc@1  95.31 ( 94.28)	Acc@5 100.00 ( 99.75)
Epoch: [87][110/391]	Time  0.027 ( 0.031)	Data  0.001 ( 0.003)	Loss 1.8214e-01 (2.0033e-01)	Acc@1  95.31 ( 94.31)	Acc@5 100.00 ( 99.75)
Epoch: [87][120/391]	Time  0.036 ( 0.031)	Data  0.001 ( 0.003)	Loss 1.5860e-01 (1.9960e-01)	Acc@1  94.53 ( 94.34)	Acc@5 100.00 ( 99.77)
Epoch: [87][130/391]	Time  0.039 ( 0.031)	Data  0.004 ( 0.002)	Loss 1.5153e-01 (1.9974e-01)	Acc@1  96.09 ( 94.32)	Acc@5 100.00 ( 99.77)
Epoch: [87][140/391]	Time  0.030 ( 0.031)	Data  0.000 ( 0.002)	Loss 2.0523e-01 (1.9912e-01)	Acc@1  92.19 ( 94.25)	Acc@5 100.00 ( 99.78)
Epoch: [87][150/391]	Time  0.027 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.7678e-01 (1.9795e-01)	Acc@1  95.31 ( 94.27)	Acc@5 100.00 ( 99.79)
Epoch: [87][160/391]	Time  0.027 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.9498e-01 (1.9887e-01)	Acc@1  94.53 ( 94.23)	Acc@5 100.00 ( 99.78)
Epoch: [87][170/391]	Time  0.030 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.8157e-01 (1.9707e-01)	Acc@1  94.53 ( 94.31)	Acc@5 100.00 ( 99.79)
Epoch: [87][180/391]	Time  0.031 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.6890e-01 (1.9857e-01)	Acc@1  90.62 ( 94.28)	Acc@5  98.44 ( 99.76)
Epoch: [87][190/391]	Time  0.031 ( 0.030)	Data  0.001 ( 0.002)	Loss 2.8750e-01 (2.0011e-01)	Acc@1  92.19 ( 94.21)	Acc@5  98.44 ( 99.75)
Epoch: [87][200/391]	Time  0.028 ( 0.030)	Data  0.001 ( 0.002)	Loss 1.8250e-01 (2.0156e-01)	Acc@1  95.31 ( 94.13)	Acc@5 100.00 ( 99.75)
Epoch: [87][210/391]	Time  0.027 ( 0.030)	Data  0.001 ( 0.002)	Loss 1.5467e-01 (2.0179e-01)	Acc@1  95.31 ( 94.12)	Acc@5 100.00 ( 99.76)
Epoch: [87][220/391]	Time  0.027 ( 0.030)	Data  0.001 ( 0.002)	Loss 3.0523e-01 (2.0255e-01)	Acc@1  86.72 ( 94.08)	Acc@5  98.44 ( 99.74)
Epoch: [87][230/391]	Time  0.027 ( 0.030)	Data  0.001 ( 0.002)	Loss 2.0226e-01 (2.0272e-01)	Acc@1  93.75 ( 94.07)	Acc@5  99.22 ( 99.74)
Epoch: [87][240/391]	Time  0.027 ( 0.030)	Data  0.001 ( 0.002)	Loss 1.4075e-01 (2.0250e-01)	Acc@1  96.88 ( 94.08)	Acc@5 100.00 ( 99.75)
Epoch: [87][250/391]	Time  0.029 ( 0.030)	Data  0.001 ( 0.002)	Loss 2.1044e-01 (2.0260e-01)	Acc@1  92.97 ( 94.06)	Acc@5 100.00 ( 99.75)
Epoch: [87][260/391]	Time  0.027 ( 0.030)	Data  0.001 ( 0.002)	Loss 2.0226e-01 (2.0119e-01)	Acc@1  93.75 ( 94.11)	Acc@5 100.00 ( 99.76)
Epoch: [87][270/391]	Time  0.027 ( 0.030)	Data  0.001 ( 0.002)	Loss 2.0430e-01 (2.0150e-01)	Acc@1  96.09 ( 94.12)	Acc@5  99.22 ( 99.75)
Epoch: [87][280/391]	Time  0.034 ( 0.030)	Data  0.001 ( 0.002)	Loss 2.2950e-01 (2.0170e-01)	Acc@1  91.41 ( 94.08)	Acc@5  99.22 ( 99.76)
Epoch: [87][290/391]	Time  0.027 ( 0.030)	Data  0.001 ( 0.002)	Loss 1.6911e-01 (2.0130e-01)	Acc@1  93.75 ( 94.09)	Acc@5 100.00 ( 99.76)
Epoch: [87][300/391]	Time  0.027 ( 0.030)	Data  0.001 ( 0.002)	Loss 1.7710e-01 (2.0097e-01)	Acc@1  96.09 ( 94.11)	Acc@5 100.00 ( 99.77)
Epoch: [87][310/391]	Time  0.033 ( 0.030)	Data  0.001 ( 0.002)	Loss 2.0981e-01 (2.0086e-01)	Acc@1  94.53 ( 94.10)	Acc@5 100.00 ( 99.77)
Epoch: [87][320/391]	Time  0.027 ( 0.030)	Data  0.001 ( 0.002)	Loss 2.0192e-01 (2.0043e-01)	Acc@1  95.31 ( 94.13)	Acc@5  99.22 ( 99.77)
Epoch: [87][330/391]	Time  0.027 ( 0.030)	Data  0.001 ( 0.002)	Loss 1.7957e-01 (1.9979e-01)	Acc@1  95.31 ( 94.16)	Acc@5 100.00 ( 99.77)
Epoch: [87][340/391]	Time  0.030 ( 0.030)	Data  0.001 ( 0.002)	Loss 2.0494e-01 (2.0057e-01)	Acc@1  94.53 ( 94.15)	Acc@5 100.00 ( 99.77)
Epoch: [87][350/391]	Time  0.027 ( 0.030)	Data  0.001 ( 0.002)	Loss 2.5165e-01 (2.0072e-01)	Acc@1  92.97 ( 94.15)	Acc@5 100.00 ( 99.78)
Epoch: [87][360/391]	Time  0.031 ( 0.030)	Data  0.001 ( 0.002)	Loss 1.9207e-01 (2.0047e-01)	Acc@1  94.53 ( 94.17)	Acc@5  99.22 ( 99.77)
Epoch: [87][370/391]	Time  0.027 ( 0.030)	Data  0.001 ( 0.002)	Loss 2.7802e-01 (2.0103e-01)	Acc@1  92.97 ( 94.15)	Acc@5  99.22 ( 99.77)
Epoch: [87][380/391]	Time  0.027 ( 0.030)	Data  0.001 ( 0.002)	Loss 1.4878e-01 (2.0057e-01)	Acc@1  96.88 ( 94.17)	Acc@5 100.00 ( 99.78)
Epoch: [87][390/391]	Time  0.020 ( 0.030)	Data  0.001 ( 0.002)	Loss 2.2926e-01 (2.0070e-01)	Acc@1  92.50 ( 94.16)	Acc@5  98.75 ( 99.77)
## e[87] optimizer.zero_grad (sum) time: 0.020827293395996094
## e[87]       loss.backward (sum) time: 1.984541416168213
## e[87]      optimizer.step (sum) time: 0.13468360900878906
## epoch[87] training(only) time: 11.775712728500366
# Switched to evaluate mode...
Test: [  0/100]	Time  0.156 ( 0.156)	Loss 1.3172e+00 (1.3172e+00)	Acc@1  72.00 ( 72.00)	Acc@5  88.00 ( 88.00)
Test: [ 10/100]	Time  0.024 ( 0.035)	Loss 1.4703e+00 (1.4782e+00)	Acc@1  69.00 ( 69.09)	Acc@5  91.00 ( 89.18)
Test: [ 20/100]	Time  0.023 ( 0.029)	Loss 1.2029e+00 (1.4311e+00)	Acc@1  77.00 ( 69.81)	Acc@5  93.00 ( 90.19)
Test: [ 30/100]	Time  0.019 ( 0.027)	Loss 1.7884e+00 (1.4620e+00)	Acc@1  63.00 ( 68.71)	Acc@5  89.00 ( 90.32)
Test: [ 40/100]	Time  0.024 ( 0.025)	Loss 1.4334e+00 (1.4578e+00)	Acc@1  67.00 ( 68.71)	Acc@5  93.00 ( 90.39)
Test: [ 50/100]	Time  0.018 ( 0.024)	Loss 1.4486e+00 (1.4658e+00)	Acc@1  69.00 ( 68.57)	Acc@5  90.00 ( 90.37)
Test: [ 60/100]	Time  0.017 ( 0.024)	Loss 1.6197e+00 (1.4407e+00)	Acc@1  66.00 ( 68.74)	Acc@5  88.00 ( 90.74)
Test: [ 70/100]	Time  0.024 ( 0.023)	Loss 1.6831e+00 (1.4418e+00)	Acc@1  68.00 ( 68.68)	Acc@5  88.00 ( 90.73)
Test: [ 80/100]	Time  0.018 ( 0.023)	Loss 1.5672e+00 (1.4472e+00)	Acc@1  73.00 ( 68.72)	Acc@5  88.00 ( 90.57)
Test: [ 90/100]	Time  0.022 ( 0.023)	Loss 1.7905e+00 (1.4345e+00)	Acc@1  64.00 ( 68.92)	Acc@5  86.00 ( 90.67)
 * Acc@1 69.200 Acc@5 90.790
### epoch[87] execution time: 14.12250828742981
EPOCH 88
REMOVING: module.fire9.expand_3x3.0.bias
REMOVING: module.fire9.expand_3x3.1.weight
i:   0, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.001063720370616826   to: 0.001005595870043812
i:   1, name:           module.conv10.weight  changing lr from: 0.001117979411353114   to: 0.001027868518844992
i:   2, name:             module.conv10.bias  changing lr from: 0.001188174978340949   to: 0.001066737070941547



# Switched to train mode...
Epoch: [88][  0/391]	Time  0.186 ( 0.186)	Data  0.152 ( 0.152)	Loss 1.0253e-01 (1.0253e-01)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [88][ 10/391]	Time  0.027 ( 0.044)	Data  0.001 ( 0.015)	Loss 3.1092e-01 (1.8514e-01)	Acc@1  87.50 ( 94.53)	Acc@5 100.00 ( 99.79)
Epoch: [88][ 20/391]	Time  0.032 ( 0.037)	Data  0.001 ( 0.008)	Loss 1.4721e-01 (1.9132e-01)	Acc@1  95.31 ( 94.42)	Acc@5 100.00 ( 99.85)
Epoch: [88][ 30/391]	Time  0.034 ( 0.035)	Data  0.001 ( 0.006)	Loss 2.1188e-01 (1.9945e-01)	Acc@1  93.75 ( 94.15)	Acc@5 100.00 ( 99.80)
Epoch: [88][ 40/391]	Time  0.032 ( 0.034)	Data  0.001 ( 0.005)	Loss 2.1775e-01 (1.9411e-01)	Acc@1  92.19 ( 94.47)	Acc@5 100.00 ( 99.79)
Epoch: [88][ 50/391]	Time  0.026 ( 0.032)	Data  0.001 ( 0.004)	Loss 2.4156e-01 (1.9521e-01)	Acc@1  90.62 ( 94.47)	Acc@5  99.22 ( 99.79)
Epoch: [88][ 60/391]	Time  0.027 ( 0.032)	Data  0.001 ( 0.004)	Loss 1.8115e-01 (1.9583e-01)	Acc@1  93.75 ( 94.36)	Acc@5 100.00 ( 99.78)
Epoch: [88][ 70/391]	Time  0.026 ( 0.031)	Data  0.001 ( 0.003)	Loss 1.9779e-01 (1.9612e-01)	Acc@1  93.75 ( 94.37)	Acc@5 100.00 ( 99.79)
Epoch: [88][ 80/391]	Time  0.028 ( 0.031)	Data  0.001 ( 0.003)	Loss 2.7008e-01 (1.9646e-01)	Acc@1  91.41 ( 94.25)	Acc@5  99.22 ( 99.80)
Epoch: [88][ 90/391]	Time  0.027 ( 0.031)	Data  0.001 ( 0.003)	Loss 1.6415e-01 (1.9688e-01)	Acc@1  96.09 ( 94.29)	Acc@5 100.00 ( 99.80)
Epoch: [88][100/391]	Time  0.034 ( 0.031)	Data  0.000 ( 0.003)	Loss 1.8912e-01 (1.9731e-01)	Acc@1  95.31 ( 94.26)	Acc@5 100.00 ( 99.81)
Epoch: [88][110/391]	Time  0.032 ( 0.031)	Data  0.001 ( 0.003)	Loss 1.7293e-01 (1.9623e-01)	Acc@1  96.09 ( 94.36)	Acc@5 100.00 ( 99.82)
Epoch: [88][120/391]	Time  0.036 ( 0.031)	Data  0.001 ( 0.003)	Loss 2.7097e-01 (1.9737e-01)	Acc@1  92.19 ( 94.30)	Acc@5  99.22 ( 99.83)
Epoch: [88][130/391]	Time  0.031 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.0351e-01 (1.9736e-01)	Acc@1  95.31 ( 94.30)	Acc@5 100.00 ( 99.84)
Epoch: [88][140/391]	Time  0.028 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.1617e-01 (1.9828e-01)	Acc@1  92.19 ( 94.28)	Acc@5 100.00 ( 99.82)
Epoch: [88][150/391]	Time  0.032 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.3972e-01 (1.9928e-01)	Acc@1  92.19 ( 94.27)	Acc@5 100.00 ( 99.81)
Epoch: [88][160/391]	Time  0.028 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.8849e-01 (2.0100e-01)	Acc@1  93.75 ( 94.19)	Acc@5  99.22 ( 99.81)
Epoch: [88][170/391]	Time  0.032 ( 0.030)	Data  0.001 ( 0.002)	Loss 1.8320e-01 (1.9976e-01)	Acc@1  95.31 ( 94.25)	Acc@5 100.00 ( 99.81)
Epoch: [88][180/391]	Time  0.027 ( 0.030)	Data  0.001 ( 0.002)	Loss 2.3363e-01 (2.0044e-01)	Acc@1  92.19 ( 94.22)	Acc@5 100.00 ( 99.80)
Epoch: [88][190/391]	Time  0.026 ( 0.030)	Data  0.000 ( 0.002)	Loss 1.4761e-01 (2.0122e-01)	Acc@1  96.09 ( 94.19)	Acc@5 100.00 ( 99.79)
Epoch: [88][200/391]	Time  0.027 ( 0.030)	Data  0.001 ( 0.002)	Loss 1.8915e-01 (2.0142e-01)	Acc@1  94.53 ( 94.20)	Acc@5 100.00 ( 99.79)
Epoch: [88][210/391]	Time  0.027 ( 0.030)	Data  0.001 ( 0.002)	Loss 1.6755e-01 (2.0256e-01)	Acc@1  92.19 ( 94.15)	Acc@5 100.00 ( 99.79)
Epoch: [88][220/391]	Time  0.030 ( 0.030)	Data  0.001 ( 0.002)	Loss 2.2842e-01 (2.0224e-01)	Acc@1  96.09 ( 94.18)	Acc@5  99.22 ( 99.78)
Epoch: [88][230/391]	Time  0.031 ( 0.030)	Data  0.001 ( 0.002)	Loss 2.1885e-01 (2.0187e-01)	Acc@1  94.53 ( 94.21)	Acc@5  99.22 ( 99.78)
Epoch: [88][240/391]	Time  0.030 ( 0.030)	Data  0.001 ( 0.002)	Loss 1.8333e-01 (2.0197e-01)	Acc@1  95.31 ( 94.22)	Acc@5 100.00 ( 99.78)
Epoch: [88][250/391]	Time  0.031 ( 0.030)	Data  0.001 ( 0.002)	Loss 1.4777e-01 (2.0095e-01)	Acc@1  96.88 ( 94.24)	Acc@5 100.00 ( 99.78)
Epoch: [88][260/391]	Time  0.027 ( 0.030)	Data  0.001 ( 0.002)	Loss 1.8847e-01 (2.0127e-01)	Acc@1  94.53 ( 94.25)	Acc@5 100.00 ( 99.78)
Epoch: [88][270/391]	Time  0.028 ( 0.030)	Data  0.001 ( 0.002)	Loss 1.4906e-01 (2.0002e-01)	Acc@1  96.88 ( 94.30)	Acc@5 100.00 ( 99.78)
Epoch: [88][280/391]	Time  0.032 ( 0.030)	Data  0.001 ( 0.002)	Loss 2.5389e-01 (1.9980e-01)	Acc@1  92.19 ( 94.30)	Acc@5 100.00 ( 99.79)
Epoch: [88][290/391]	Time  0.029 ( 0.030)	Data  0.002 ( 0.002)	Loss 1.8670e-01 (2.0031e-01)	Acc@1  95.31 ( 94.28)	Acc@5 100.00 ( 99.78)
Epoch: [88][300/391]	Time  0.036 ( 0.030)	Data  0.001 ( 0.002)	Loss 1.6112e-01 (2.0016e-01)	Acc@1  95.31 ( 94.27)	Acc@5 100.00 ( 99.78)
Epoch: [88][310/391]	Time  0.027 ( 0.030)	Data  0.001 ( 0.002)	Loss 1.7643e-01 (2.0040e-01)	Acc@1  93.75 ( 94.28)	Acc@5 100.00 ( 99.78)
Epoch: [88][320/391]	Time  0.027 ( 0.030)	Data  0.001 ( 0.002)	Loss 2.3781e-01 (2.0010e-01)	Acc@1  92.19 ( 94.27)	Acc@5  99.22 ( 99.78)
Epoch: [88][330/391]	Time  0.030 ( 0.030)	Data  0.004 ( 0.002)	Loss 1.7749e-01 (2.0038e-01)	Acc@1  95.31 ( 94.27)	Acc@5 100.00 ( 99.79)
Epoch: [88][340/391]	Time  0.026 ( 0.030)	Data  0.001 ( 0.002)	Loss 1.8326e-01 (2.0012e-01)	Acc@1  93.75 ( 94.27)	Acc@5 100.00 ( 99.79)
Epoch: [88][350/391]	Time  0.030 ( 0.030)	Data  0.001 ( 0.002)	Loss 2.7668e-01 (1.9984e-01)	Acc@1  89.84 ( 94.27)	Acc@5  99.22 ( 99.79)
Epoch: [88][360/391]	Time  0.030 ( 0.030)	Data  0.001 ( 0.002)	Loss 2.0151e-01 (1.9950e-01)	Acc@1  96.88 ( 94.29)	Acc@5 100.00 ( 99.79)
Epoch: [88][370/391]	Time  0.026 ( 0.030)	Data  0.000 ( 0.002)	Loss 1.5820e-01 (1.9945e-01)	Acc@1  96.88 ( 94.31)	Acc@5 100.00 ( 99.79)
Epoch: [88][380/391]	Time  0.027 ( 0.030)	Data  0.001 ( 0.002)	Loss 2.2385e-01 (1.9943e-01)	Acc@1  93.75 ( 94.30)	Acc@5 100.00 ( 99.80)
Epoch: [88][390/391]	Time  0.021 ( 0.030)	Data  0.001 ( 0.002)	Loss 2.8730e-01 (2.0019e-01)	Acc@1  91.25 ( 94.26)	Acc@5 100.00 ( 99.80)
## e[88] optimizer.zero_grad (sum) time: 0.0159761905670166
## e[88]       loss.backward (sum) time: 1.9457645416259766
## e[88]      optimizer.step (sum) time: 0.08517265319824219
## epoch[88] training(only) time: 11.790382862091064
# Switched to evaluate mode...
Test: [  0/100]	Time  0.146 ( 0.146)	Loss 1.3078e+00 (1.3078e+00)	Acc@1  71.00 ( 71.00)	Acc@5  90.00 ( 90.00)
Test: [ 10/100]	Time  0.023 ( 0.032)	Loss 1.4580e+00 (1.4720e+00)	Acc@1  69.00 ( 68.73)	Acc@5  92.00 ( 89.64)
Test: [ 20/100]	Time  0.025 ( 0.028)	Loss 1.1923e+00 (1.4191e+00)	Acc@1  76.00 ( 69.24)	Acc@5  94.00 ( 90.29)
Test: [ 30/100]	Time  0.023 ( 0.026)	Loss 1.7685e+00 (1.4507e+00)	Acc@1  61.00 ( 68.10)	Acc@5  90.00 ( 90.32)
Test: [ 40/100]	Time  0.019 ( 0.025)	Loss 1.4339e+00 (1.4503e+00)	Acc@1  68.00 ( 68.12)	Acc@5  93.00 ( 90.39)
Test: [ 50/100]	Time  0.018 ( 0.024)	Loss 1.4827e+00 (1.4609e+00)	Acc@1  69.00 ( 67.94)	Acc@5  90.00 ( 90.31)
Test: [ 60/100]	Time  0.018 ( 0.024)	Loss 1.6060e+00 (1.4358e+00)	Acc@1  64.00 ( 68.18)	Acc@5  86.00 ( 90.62)
Test: [ 70/100]	Time  0.019 ( 0.024)	Loss 1.6634e+00 (1.4362e+00)	Acc@1  68.00 ( 68.25)	Acc@5  87.00 ( 90.65)
Test: [ 80/100]	Time  0.022 ( 0.023)	Loss 1.5528e+00 (1.4412e+00)	Acc@1  74.00 ( 68.36)	Acc@5  88.00 ( 90.56)
Test: [ 90/100]	Time  0.018 ( 0.023)	Loss 1.7404e+00 (1.4280e+00)	Acc@1  64.00 ( 68.64)	Acc@5  88.00 ( 90.65)
 * Acc@1 68.920 Acc@5 90.770
### epoch[88] execution time: 14.127058744430542
EPOCH 89
REMOVING: module.fire9.expand_3x3.1.bias
REMOVING: module.conv10.weight
i:   0, name:             module.conv10.bias  changing lr from: 0.001066737070941547   to: 0.001006855733852490



# Switched to train mode...
Epoch: [89][  0/391]	Time  0.178 ( 0.178)	Data  0.144 ( 0.144)	Loss 2.9664e-01 (2.9664e-01)	Acc@1  90.62 ( 90.62)	Acc@5 100.00 (100.00)
Epoch: [89][ 10/391]	Time  0.027 ( 0.044)	Data  0.001 ( 0.014)	Loss 2.3188e-01 (2.2180e-01)	Acc@1  92.19 ( 92.97)	Acc@5 100.00 ( 99.86)
Epoch: [89][ 20/391]	Time  0.025 ( 0.037)	Data  0.001 ( 0.008)	Loss 2.2149e-01 (2.1308e-01)	Acc@1  95.31 ( 93.90)	Acc@5  99.22 ( 99.81)
Epoch: [89][ 30/391]	Time  0.028 ( 0.035)	Data  0.001 ( 0.006)	Loss 1.3325e-01 (2.0476e-01)	Acc@1  97.66 ( 94.15)	Acc@5 100.00 ( 99.85)
Epoch: [89][ 40/391]	Time  0.026 ( 0.033)	Data  0.001 ( 0.005)	Loss 1.5886e-01 (2.0540e-01)	Acc@1  95.31 ( 94.02)	Acc@5 100.00 ( 99.87)
Epoch: [89][ 50/391]	Time  0.028 ( 0.033)	Data  0.001 ( 0.004)	Loss 1.5094e-01 (2.0293e-01)	Acc@1  96.09 ( 94.03)	Acc@5 100.00 ( 99.88)
Epoch: [89][ 60/391]	Time  0.027 ( 0.032)	Data  0.001 ( 0.004)	Loss 1.7256e-01 (1.9947e-01)	Acc@1  94.53 ( 94.19)	Acc@5 100.00 ( 99.88)
Epoch: [89][ 70/391]	Time  0.033 ( 0.031)	Data  0.002 ( 0.003)	Loss 2.1229e-01 (2.0044e-01)	Acc@1  92.97 ( 94.12)	Acc@5 100.00 ( 99.88)
Epoch: [89][ 80/391]	Time  0.026 ( 0.031)	Data  0.001 ( 0.003)	Loss 1.5738e-01 (1.9894e-01)	Acc@1  96.09 ( 94.13)	Acc@5 100.00 ( 99.88)
Epoch: [89][ 90/391]	Time  0.028 ( 0.031)	Data  0.001 ( 0.003)	Loss 2.2050e-01 (1.9766e-01)	Acc@1  94.53 ( 94.21)	Acc@5  99.22 ( 99.86)
Epoch: [89][100/391]	Time  0.031 ( 0.031)	Data  0.001 ( 0.003)	Loss 2.1015e-01 (1.9573e-01)	Acc@1  94.53 ( 94.31)	Acc@5 100.00 ( 99.85)
Epoch: [89][110/391]	Time  0.026 ( 0.031)	Data  0.001 ( 0.003)	Loss 2.6786e-01 (1.9781e-01)	Acc@1  90.62 ( 94.19)	Acc@5  99.22 ( 99.85)
Epoch: [89][120/391]	Time  0.026 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.1073e-01 (1.9571e-01)	Acc@1  93.75 ( 94.29)	Acc@5 100.00 ( 99.86)
Epoch: [89][130/391]	Time  0.039 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.3394e-01 (1.9571e-01)	Acc@1  96.09 ( 94.36)	Acc@5 100.00 ( 99.84)
Epoch: [89][140/391]	Time  0.027 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.5379e-01 (1.9496e-01)	Acc@1  95.31 ( 94.40)	Acc@5 100.00 ( 99.86)
Epoch: [89][150/391]	Time  0.035 ( 0.030)	Data  0.001 ( 0.002)	Loss 1.6719e-01 (1.9377e-01)	Acc@1  95.31 ( 94.43)	Acc@5 100.00 ( 99.84)
Epoch: [89][160/391]	Time  0.027 ( 0.030)	Data  0.002 ( 0.002)	Loss 2.1586e-01 (1.9434e-01)	Acc@1  92.97 ( 94.41)	Acc@5 100.00 ( 99.84)
Epoch: [89][170/391]	Time  0.028 ( 0.030)	Data  0.001 ( 0.002)	Loss 1.9934e-01 (1.9473e-01)	Acc@1  92.97 ( 94.38)	Acc@5 100.00 ( 99.85)
Epoch: [89][180/391]	Time  0.029 ( 0.030)	Data  0.001 ( 0.002)	Loss 1.8788e-01 (1.9355e-01)	Acc@1  94.53 ( 94.42)	Acc@5  99.22 ( 99.84)
Epoch: [89][190/391]	Time  0.026 ( 0.030)	Data  0.001 ( 0.002)	Loss 1.5397e-01 (1.9336e-01)	Acc@1  94.53 ( 94.43)	Acc@5 100.00 ( 99.84)
Epoch: [89][200/391]	Time  0.027 ( 0.030)	Data  0.001 ( 0.002)	Loss 2.3199e-01 (1.9401e-01)	Acc@1  93.75 ( 94.41)	Acc@5 100.00 ( 99.84)
Epoch: [89][210/391]	Time  0.026 ( 0.030)	Data  0.001 ( 0.002)	Loss 1.7883e-01 (1.9447e-01)	Acc@1  93.75 ( 94.41)	Acc@5 100.00 ( 99.84)
Epoch: [89][220/391]	Time  0.032 ( 0.030)	Data  0.001 ( 0.002)	Loss 2.4014e-01 (1.9535e-01)	Acc@1  92.97 ( 94.38)	Acc@5 100.00 ( 99.83)
Epoch: [89][230/391]	Time  0.027 ( 0.030)	Data  0.001 ( 0.002)	Loss 2.1244e-01 (1.9659e-01)	Acc@1  95.31 ( 94.35)	Acc@5 100.00 ( 99.82)
Epoch: [89][240/391]	Time  0.026 ( 0.030)	Data  0.001 ( 0.002)	Loss 2.2247e-01 (1.9720e-01)	Acc@1  92.19 ( 94.30)	Acc@5 100.00 ( 99.82)
Epoch: [89][250/391]	Time  0.026 ( 0.030)	Data  0.001 ( 0.002)	Loss 2.1954e-01 (1.9745e-01)	Acc@1  92.97 ( 94.32)	Acc@5 100.00 ( 99.82)
Epoch: [89][260/391]	Time  0.027 ( 0.030)	Data  0.001 ( 0.002)	Loss 2.7383e-01 (1.9823e-01)	Acc@1  89.06 ( 94.30)	Acc@5  99.22 ( 99.81)
Epoch: [89][270/391]	Time  0.027 ( 0.030)	Data  0.001 ( 0.002)	Loss 1.7905e-01 (1.9839e-01)	Acc@1  95.31 ( 94.31)	Acc@5 100.00 ( 99.81)
Epoch: [89][280/391]	Time  0.026 ( 0.030)	Data  0.001 ( 0.002)	Loss 1.6556e-01 (1.9901e-01)	Acc@1  94.53 ( 94.30)	Acc@5 100.00 ( 99.81)
Epoch: [89][290/391]	Time  0.027 ( 0.030)	Data  0.002 ( 0.002)	Loss 2.2677e-01 (1.9913e-01)	Acc@1  92.97 ( 94.30)	Acc@5  99.22 ( 99.81)
Epoch: [89][300/391]	Time  0.026 ( 0.030)	Data  0.001 ( 0.002)	Loss 2.7605e-01 (1.9971e-01)	Acc@1  92.19 ( 94.27)	Acc@5 100.00 ( 99.81)
Epoch: [89][310/391]	Time  0.026 ( 0.030)	Data  0.001 ( 0.002)	Loss 1.6883e-01 (1.9930e-01)	Acc@1  95.31 ( 94.29)	Acc@5 100.00 ( 99.81)
Epoch: [89][320/391]	Time  0.026 ( 0.030)	Data  0.001 ( 0.002)	Loss 2.2001e-01 (1.9945e-01)	Acc@1  92.97 ( 94.29)	Acc@5 100.00 ( 99.81)
Epoch: [89][330/391]	Time  0.027 ( 0.030)	Data  0.001 ( 0.002)	Loss 2.2553e-01 (1.9940e-01)	Acc@1  93.75 ( 94.30)	Acc@5 100.00 ( 99.80)
Epoch: [89][340/391]	Time  0.033 ( 0.030)	Data  0.001 ( 0.002)	Loss 1.6540e-01 (1.9904e-01)	Acc@1  96.88 ( 94.33)	Acc@5 100.00 ( 99.80)
Epoch: [89][350/391]	Time  0.027 ( 0.030)	Data  0.001 ( 0.002)	Loss 1.6020e-01 (1.9883e-01)	Acc@1  94.53 ( 94.31)	Acc@5 100.00 ( 99.80)
Epoch: [89][360/391]	Time  0.032 ( 0.030)	Data  0.001 ( 0.002)	Loss 1.9727e-01 (1.9938e-01)	Acc@1  94.53 ( 94.30)	Acc@5  99.22 ( 99.80)
Epoch: [89][370/391]	Time  0.028 ( 0.030)	Data  0.001 ( 0.002)	Loss 1.8566e-01 (1.9968e-01)	Acc@1  95.31 ( 94.29)	Acc@5  99.22 ( 99.79)
Epoch: [89][380/391]	Time  0.037 ( 0.030)	Data  0.001 ( 0.002)	Loss 2.8501e-01 (2.0002e-01)	Acc@1  92.97 ( 94.29)	Acc@5 100.00 ( 99.79)
Epoch: [89][390/391]	Time  0.021 ( 0.030)	Data  0.001 ( 0.002)	Loss 4.5845e-01 (2.0097e-01)	Acc@1  86.25 ( 94.28)	Acc@5  97.50 ( 99.78)
## e[89] optimizer.zero_grad (sum) time: 0.008203744888305664
## e[89]       loss.backward (sum) time: 1.8304612636566162
## e[89]      optimizer.step (sum) time: 0.034128427505493164
## epoch[89] training(only) time: 11.655092477798462
# Switched to evaluate mode...
Test: [  0/100]	Time  0.153 ( 0.153)	Loss 1.2954e+00 (1.2954e+00)	Acc@1  71.00 ( 71.00)	Acc@5  90.00 ( 90.00)
Test: [ 10/100]	Time  0.020 ( 0.033)	Loss 1.4991e+00 (1.4814e+00)	Acc@1  69.00 ( 68.64)	Acc@5  92.00 ( 89.27)
Test: [ 20/100]	Time  0.020 ( 0.027)	Loss 1.1999e+00 (1.4327e+00)	Acc@1  74.00 ( 68.95)	Acc@5  93.00 ( 90.10)
Test: [ 30/100]	Time  0.024 ( 0.026)	Loss 1.7638e+00 (1.4634e+00)	Acc@1  59.00 ( 67.94)	Acc@5  89.00 ( 90.16)
Test: [ 40/100]	Time  0.023 ( 0.025)	Loss 1.4463e+00 (1.4624e+00)	Acc@1  68.00 ( 68.07)	Acc@5  91.00 ( 90.17)
Test: [ 50/100]	Time  0.018 ( 0.024)	Loss 1.4642e+00 (1.4708e+00)	Acc@1  70.00 ( 68.00)	Acc@5  90.00 ( 90.14)
Test: [ 60/100]	Time  0.021 ( 0.024)	Loss 1.6257e+00 (1.4452e+00)	Acc@1  63.00 ( 68.23)	Acc@5  87.00 ( 90.56)
Test: [ 70/100]	Time  0.022 ( 0.023)	Loss 1.6860e+00 (1.4476e+00)	Acc@1  68.00 ( 68.30)	Acc@5  86.00 ( 90.52)
Test: [ 80/100]	Time  0.017 ( 0.023)	Loss 1.5535e+00 (1.4527e+00)	Acc@1  73.00 ( 68.36)	Acc@5  88.00 ( 90.44)
Test: [ 90/100]	Time  0.023 ( 0.023)	Loss 1.7396e+00 (1.4387e+00)	Acc@1  65.00 ( 68.65)	Acc@5  89.00 ( 90.58)
 * Acc@1 68.850 Acc@5 90.740
### epoch[89] execution time: 14.006512641906738
### Training complete:
*** Model named parameters and requires_grad:
name:           module.stem.0.weight  req_grad: False 
name:             module.stem.0.bias  req_grad: False 
name:           module.stem.1.weight  req_grad: False 
name:             module.stem.1.bias  req_grad: False 
name:  module.fire2.squeeze.0.weight  req_grad: False 
name:    module.fire2.squeeze.0.bias  req_grad: False 
name:  module.fire2.squeeze.1.weight  req_grad: False 
name:    module.fire2.squeeze.1.bias  req_grad: False 
name: module.fire2.expand_1x1.0.weight  req_grad: False 
name: module.fire2.expand_1x1.0.bias  req_grad: False 
name: module.fire2.expand_1x1.1.weight  req_grad: False 
name: module.fire2.expand_1x1.1.bias  req_grad: False 
name: module.fire2.expand_3x3.0.weight  req_grad: False 
name: module.fire2.expand_3x3.0.bias  req_grad: False 
name: module.fire2.expand_3x3.1.weight  req_grad: False 
name: module.fire2.expand_3x3.1.bias  req_grad: False 
name:  module.fire3.squeeze.0.weight  req_grad: False 
name:    module.fire3.squeeze.0.bias  req_grad: False 
name:  module.fire3.squeeze.1.weight  req_grad: False 
name:    module.fire3.squeeze.1.bias  req_grad: False 
name: module.fire3.expand_1x1.0.weight  req_grad: False 
name: module.fire3.expand_1x1.0.bias  req_grad: False 
name: module.fire3.expand_1x1.1.weight  req_grad: False 
name: module.fire3.expand_1x1.1.bias  req_grad: False 
name: module.fire3.expand_3x3.0.weight  req_grad: False 
name: module.fire3.expand_3x3.0.bias  req_grad: False 
name: module.fire3.expand_3x3.1.weight  req_grad: False 
name: module.fire3.expand_3x3.1.bias  req_grad: False 
name:  module.fire4.squeeze.0.weight  req_grad: False 
name:    module.fire4.squeeze.0.bias  req_grad: False 
name:  module.fire4.squeeze.1.weight  req_grad: False 
name:    module.fire4.squeeze.1.bias  req_grad: False 
name: module.fire4.expand_1x1.0.weight  req_grad: False 
name: module.fire4.expand_1x1.0.bias  req_grad: False 
name: module.fire4.expand_1x1.1.weight  req_grad: False 
name: module.fire4.expand_1x1.1.bias  req_grad: False 
name: module.fire4.expand_3x3.0.weight  req_grad: False 
name: module.fire4.expand_3x3.0.bias  req_grad: False 
name: module.fire4.expand_3x3.1.weight  req_grad: False 
name: module.fire4.expand_3x3.1.bias  req_grad: False 
name:  module.fire5.squeeze.0.weight  req_grad: False 
name:    module.fire5.squeeze.0.bias  req_grad: False 
name:  module.fire5.squeeze.1.weight  req_grad: False 
name:    module.fire5.squeeze.1.bias  req_grad: False 
name: module.fire5.expand_1x1.0.weight  req_grad: False 
name: module.fire5.expand_1x1.0.bias  req_grad: False 
name: module.fire5.expand_1x1.1.weight  req_grad: False 
name: module.fire5.expand_1x1.1.bias  req_grad: False 
name: module.fire5.expand_3x3.0.weight  req_grad: False 
name: module.fire5.expand_3x3.0.bias  req_grad: False 
name: module.fire5.expand_3x3.1.weight  req_grad: False 
name: module.fire5.expand_3x3.1.bias  req_grad: False 
name:  module.fire6.squeeze.0.weight  req_grad: False 
name:    module.fire6.squeeze.0.bias  req_grad: False 
name:  module.fire6.squeeze.1.weight  req_grad: False 
name:    module.fire6.squeeze.1.bias  req_grad: False 
name: module.fire6.expand_1x1.0.weight  req_grad: False 
name: module.fire6.expand_1x1.0.bias  req_grad: False 
name: module.fire6.expand_1x1.1.weight  req_grad: False 
name: module.fire6.expand_1x1.1.bias  req_grad: False 
name: module.fire6.expand_3x3.0.weight  req_grad: False 
name: module.fire6.expand_3x3.0.bias  req_grad: False 
name: module.fire6.expand_3x3.1.weight  req_grad: False 
name: module.fire6.expand_3x3.1.bias  req_grad: False 
name:  module.fire7.squeeze.0.weight  req_grad: False 
name:    module.fire7.squeeze.0.bias  req_grad: False 
name:  module.fire7.squeeze.1.weight  req_grad: False 
name:    module.fire7.squeeze.1.bias  req_grad: False 
name: module.fire7.expand_1x1.0.weight  req_grad: False 
name: module.fire7.expand_1x1.0.bias  req_grad: False 
name: module.fire7.expand_1x1.1.weight  req_grad: False 
name: module.fire7.expand_1x1.1.bias  req_grad: False 
name: module.fire7.expand_3x3.0.weight  req_grad: False 
name: module.fire7.expand_3x3.0.bias  req_grad: False 
name: module.fire7.expand_3x3.1.weight  req_grad: False 
name: module.fire7.expand_3x3.1.bias  req_grad: False 
name:  module.fire8.squeeze.0.weight  req_grad: False 
name:    module.fire8.squeeze.0.bias  req_grad: False 
name:  module.fire8.squeeze.1.weight  req_grad: False 
name:    module.fire8.squeeze.1.bias  req_grad: False 
name: module.fire8.expand_1x1.0.weight  req_grad: False 
name: module.fire8.expand_1x1.0.bias  req_grad: False 
name: module.fire8.expand_1x1.1.weight  req_grad: False 
name: module.fire8.expand_1x1.1.bias  req_grad: False 
name: module.fire8.expand_3x3.0.weight  req_grad: False 
name: module.fire8.expand_3x3.0.bias  req_grad: False 
name: module.fire8.expand_3x3.1.weight  req_grad: False 
name: module.fire8.expand_3x3.1.bias  req_grad: False 
name:  module.fire9.squeeze.0.weight  req_grad: False 
name:    module.fire9.squeeze.0.bias  req_grad: False 
name:  module.fire9.squeeze.1.weight  req_grad: False 
name:    module.fire9.squeeze.1.bias  req_grad: False 
name: module.fire9.expand_1x1.0.weight  req_grad: False 
name: module.fire9.expand_1x1.0.bias  req_grad: False 
name: module.fire9.expand_1x1.1.weight  req_grad: False 
name: module.fire9.expand_1x1.1.bias  req_grad: False 
name: module.fire9.expand_3x3.0.weight  req_grad: False 
name: module.fire9.expand_3x3.0.bias  req_grad: False 
name: module.fire9.expand_3x3.1.weight  req_grad: False 
name: module.fire9.expand_3x3.1.bias  req_grad: False 
name:           module.conv10.weight  req_grad: False 
name:             module.conv10.bias  req_grad:  True 


*** Optimizer groups, parameters and req_grads
#        requires_grad:                            True
#           param_name:              module.conv10.bias
#                   lr:             0.00100685573385249
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False



*** Optimizer group lrs
# group:  0,   name:             module.conv10.bias,   req_grad:   True   lr: 0.001006855733852490,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
---------------
#### total training(only) time: 1368.9536917209625
##### Total run time: 1589.279055595398

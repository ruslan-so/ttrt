# Model: squeezenet
# Dataset: cifardecem
# Batch size: 128
# Freezeout: True
# Low precision: False
# Epochs: 90
# Initial learning rate: 0.1
# module_name: models_cifardecem.squeezenet
<function squeezenet at 0x7f646ead1f28>
# model requested: 'squeezenet'
# printing out the model
SqueezeNet(
  (stem): Sequential(
    (0): Conv2d(3, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (fire2): Fire(
    (squeeze): Sequential(
      (0): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (expand_1x1): Sequential(
      (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (expand_3x3): Sequential(
      (0): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
  )
  (fire3): Fire(
    (squeeze): Sequential(
      (0): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (expand_1x1): Sequential(
      (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (expand_3x3): Sequential(
      (0): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
  )
  (fire4): Fire(
    (squeeze): Sequential(
      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (expand_1x1): Sequential(
      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (expand_3x3): Sequential(
      (0): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
  )
  (fire5): Fire(
    (squeeze): Sequential(
      (0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (expand_1x1): Sequential(
      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (expand_3x3): Sequential(
      (0): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
  )
  (fire6): Fire(
    (squeeze): Sequential(
      (0): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (expand_1x1): Sequential(
      (0): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (expand_3x3): Sequential(
      (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
  )
  (fire7): Fire(
    (squeeze): Sequential(
      (0): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (expand_1x1): Sequential(
      (0): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (expand_3x3): Sequential(
      (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
  )
  (fire8): Fire(
    (squeeze): Sequential(
      (0): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (expand_1x1): Sequential(
      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (expand_3x3): Sequential(
      (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
  )
  (fire9): Fire(
    (squeeze): Sequential(
      (0): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (expand_1x1): Sequential(
      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (expand_3x3): Sequential(
      (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
  )
  (conv10): Conv2d(512, 10, kernel_size=(1, 1), stride=(1, 1))
  (avg): AdaptiveAvgPool2d(output_size=1)
  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
)
# model is full precision
PARAM TOTAL COUNT: 102
PARAM TO FREEZE COUNT: 102

module.stem.0.weight
[0.1, 0.10088384267912825, 0.10053591041744064, 0.0999578198101117, 0.09915225683538814, 0.09812296437474749, 0.09687472482237458, 0.09541333786475781, 0.09374559353364734, 0.0918792406575792, 0.0898229508585488, 0.08758627826111579, 0.08517961510114358, 0.08261414344042829, 0.07990178321156519, 0.0770551368344512, 0.07408743066175172, 0.07101245352539297, 0.06784449266961103, 0.06459826736823124, 0.06128886053461177, 0.05793164864201136, 0.054542230279991735, 0.05113635367880273, 0.04772984353849288, 0.044338527502719036, 0.040978162618878995, 0.03766436212625511, 0.034412522912332426, 0.031237753974350746, 0.028154806218479014, 0.025178003922785554, 0.022321178182447728, 0.019597602646433312, 0.017019931844240544, 0.01460014238924829, 0.01234947733186318, 0.010278393921015021, 0.0083965150167161, 0.006712584379435493, 0.005234426044027662, 0.003968907966975204, 0.002921910115851916, 0.0020982971492716097, 0.001501895814259612, 0.0011354771660654897, 0.0010007436930289206, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.stem.0.bias
[0.1, 0.10088553567013014, 0.10054266676383303, 0.09997296313149238, 0.0991790332028882, 0.09816451204431016, 0.09693404471514046, 0.09549326500010952, 0.09384876961460016, 0.09200808800110345, 0.08997964785511511, 0.08777273653831481, 0.08539745855570091, 0.08286468929137482, 0.08018602521479878, 0.07737373078551167, 0.07444068229940325, 0.07140030893365108, 0.0682665312602498, 0.06505369750965323, 0.0617765178763512, 0.058449997167167284, 0.05508936610065251, 0.05171001157212554, 0.048327406203646464, 0.04495703750148394, 0.04161433694543428, 0.03831460933466163, 0.035072962713554805, 0.031904239198440175, 0.028822947021865816, 0.025843194105596646, 0.022978623466462275, 0.02024235075080559, 0.017646904183536174, 0.015204167206735463, 0.01292532407044733, 0.010820808624770743, 0.008900256547713335, 0.007172461227534282, 0.005645333501572674, 0.004325865435899644, 0.003220098311632024, 0.00233309496448471, 0.001668916604206632, 0.0012306042200347137, 0.0010201646573020852, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.stem.1.weight
[0.1, 0.10088719995079998, 0.10054930875724394, 0.0999878509850621, 0.09920535993282756, 0.09820536620170793, 0.096992381765386, 0.09557187961202561, 0.09395026905013826, 0.09213486678977055, 0.09013386392949395, 0.087956288998152, 0.0856119672181204, 0.08311147617388426, 0.08046609808595613, 0.07768776890547491, 0.0747890244591706, 0.07178294388768972, 0.06868309063248672, 0.06550345123754962, 0.06225837224208589, 0.05896249544890939, 0.055630691860597214, 0.052277994581496824, 0.04891953098832961, 0.04557045447543743, 0.04224587608263742, 0.03896079631418069, 0.035730037456447504, 0.03256817669976214, 0.029489480366081306, 0.0265078395393214, 0.023636707388760666, 0.02088903846831284, 0.018277230265554358, 0.015813067264236137, 0.013507667772669579, 0.011371433757897682, 0.009414003911999192, 0.007644210162291009, 0.006070037821654799, 0.004698589558789484, 0.003536053350956108, 0.002587674563812297, 0.0018577322843120517, 0.0013495200134569997, 0.0010653308060134083, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.stem.1.bias
[0.1, 0.1008888360760043, 0.10055583860073712, 0.10000248826643972, 0.09923124557689228, 0.09824553990664374, 0.09704975425210248, 0.09564920574229314, 0.09405012199593964, 0.09225961343000363, 0.09028564164281064, 0.08813698401234948, 0.08582319466716118, 0.08335456200336218, 0.08074206293670494, 0.07799731409309685, 0.07513252015461143, 0.07216041959067432, 0.06909422801573344, 0.06594757942527647, 0.06273446557149345, 0.05946917374815365, 0.05616622326134002, 0.05284030086852764, 0.04950619547308011, 0.046178732364548405, 0.042872707297176293, 0.0396028206997365, 0.0363836123092367, 0.03322939651915079, 0.030154198729653026, 0.027171692982877083, 0.024295141160509067, 0.02153733401407501, 0.018910534290135752, 0.016426422203285863, 0.014096043499414113, 0.011929760340165234, 0.009937205226997942, 0.008127238169718536, 0.00650790728994261, 0.005086413034663916, 0.0038690761590565994, 0.0028613096208773663, 0.0020675945114404285, 0.0014914601301897691, 0.0011354682914681438, 0.001001201933263656, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire2.squeeze.0.weight
[0.1, 0.10089044458858155, 0.10056225844985306, 0.10001687976651251, 0.09925669850600122, 0.09828504594714907, 0.09710618008178971, 0.09572526695531863, 0.09414835802796394, 0.0923823636559779, 0.0904350228089599, 0.08831486915601666, 0.08603119366937689, 0.08359400390934, 0.08101398016898063, 0.07830242867079255, 0.0754712320203744, 0.07253279713427992, 0.069500000870224, 0.06638613359790489, 0.06320484095772752, 0.05997006406265329, 0.056695978405225736, 0.05339693173749356, 0.05008738119605566, 0.046781829947759125, 0.043494763633682855, 0.04024058688992277, 0.0370335602233585, 0.033887737519025476, 0.03081690445294859, 0.027834518080325905, 0.024953647863799878, 0.022186918400243116, 0.019546454097042126, 0.017043826040319843, 0.014690001287931537, 0.012495294809443381, 0.010469324283703119, 0.008620967952089536, 0.006958325712136919, 0.005488683622030876, 0.004218481971524157, 0.0031532870591930266, 0.0022977667997119136, 0.0016556702680409867, 0.0012298112701681564, 0.0010220560124021441, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire2.squeeze.0.bias
[0.1, 0.10089202601963099, 0.10056857041374144, 0.10003103017390096, 0.0992817269144817, 0.0983238968457006, 0.0971616767965594, 0.09580008634804892, 0.09424500615378345, 0.09250315254169772, 0.09058204850650045, 0.08848999121816692, 0.0862360161868004, 0.08382985823863245, 0.0812819094717055, 0.07860317437282519, 0.0758052222896307, 0.07290013746305424, 0.06990046683597721, 0.06681916586349566, 0.06366954255883815, 0.06046520001659933, 0.0572199776615293, 0.05394789147662238, 0.05066307346865839, 0.04737971063264163, 0.04411198367874813, 0.04087400578641672, 0.037679761650102686, 0.034543047079952725, 0.03147740941826369, 0.028496089029063643, 0.02561196211351966, 0.022837485098150173, 0.020184640836026863, 0.017664886853320967, 0.015289105864714974, 0.013067558771401911, 0.011009840344671468, 0.009124837786484128, 0.0074206923460084446, 0.005904764157897851, 0.004583600454169278, 0.0034629072869751913, 0.002547524884396939, 0.0018414067456971597, 0.0013476025663177174, 0.0010682450663694156, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire2.squeeze.1.weight
[0.1, 0.10089358088879381, 0.10057477655626441, 0.10004494407736048, 0.09930633882414173, 0.09836210486519137, 0.09721626158205665, 0.09587368655968853, 0.0943400948237113, 0.0926220145129048, 0.09072675909045531, 0.08866239621226549, 0.08643771338484343, 0.08406218055895759, 0.08154590981828683, 0.07889961233466221, 0.07613455277313148, 0.07326250134093348, 0.07029568368449833, 0.06724672884775038, 0.06412861551324298, 0.06095461675496409, 0.05773824353798676, 0.054493187205473276, 0.051233261197852466, 0.04797234225225747, 0.044724311332524525, 0.04150299454119958, 0.03832210426507646, 0.03519518080479637, 0.0321355347369774, 0.029156190254225268, 0.026269829724213246, 0.023488739703830298, 0.020824758638202597, 0.018289226467221094, 0.015892936354088595, 0.013646088741366386, 0.011558247930092962, 0.009638301366807298, 0.007894421811782553, 0.006334032549510598, 0.004963775789528468, 0.003789484392097053, 0.0028161570390888117, 0.0020479369557765293, 0.0014880942740992877, 0.0011390121124810572, 0.0010021764314569405, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire2.squeeze.1.bias
[0.1, 0.10089510970452692, 0.10058087889707105, 0.10005862596812203, 0.09933054208824099, 0.09839968201475957, 0.09726995127520384, 0.09594608978121684, 0.09443365194172937, 0.0927389833588162, 0.0908691942040129, 0.08883212938679633, 0.08663633564038947, 0.08429102566298666, 0.08180603946484816, 0.07919180308343672, 0.07645928483981164, 0.07361994931981133, 0.07068570927310137, 0.0676688756319013, 0.06458210585909185, 0.06143835084241413, 0.05825080055757192, 0.05503282872821369, 0.051797936714979675, 0.04855969686903355, 0.045331695587745455, 0.04212747631144268, 0.038960482700391284, 0.03584400223041625, 0.03279111044381088, 0.029814616089436904, 0.02692700738218652, 0.024140399607280295, 0.02146648428923332, 0.018916480138756808, 0.016501085983402775, 0.014230435879436794, 0.012114056593271711, 0.01016082763085388, 0.008378943982703085, 0.0067758817409134635, 0.005358366732373109, 0.004132346299805383, 0.0031029643490274087, 0.0022745397671180326, 0.0016505483020442294, 0.0012336079797717438, 0.0010254681200445028, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire2.expand_1x1.0.weight
[0.1, 0.10089661296436964, 0.10058687941264395, 0.10007208024217291, 0.09935434439536371, 0.09843664005547902, 0.09732276237177027, 0.09601731776470844, 0.09452570487621764, 0.09285409224369184, 0.09100939279012303, 0.08899923523583653, 0.08683193255005983, 0.08451644757279282, 0.08206235594914933, 0.0794798065294547, 0.07677947939886381, 0.07397254171006719, 0.0710706015017386, 0.06808565969370671, 0.06503006045737392, 0.061916440166625036, 0.0587576751403376, 0.055566828392604434, 0.052357095610881504, 0.049141750585467533, 0.045934090315990786, 0.04274738002191408, 0.0395947982844661, 0.036489382546863534, 0.03344397519820684, 0.030471170464018562, 0.02758326232305773, 0.024792193665799035, 0.02210950690483107, 0.019546296241423473, 0.01711316178566369, 0.01482016571989856, 0.012676790686766148, 0.010691900573903245, 0.00887370385750269, 0.007229719656312549, 0.005766746636460168, 0.004490834895694761, 0.0034072609433204773, 0.0025205058792901794, 0.0018342368626999164, 0.0013512919463204757, 0.001073668339882954, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire2.expand_1x1.0.bias
[0.1, 0.10089809115520323, 0.10059278003731885, 0.10008531120247993, 0.09937775327319563, 0.09847299050591395, 0.09737471103377204, 0.09608739183246072, 0.09461628047048758, 0.09296737371823127, 0.0911473931029838, 0.08916375750962725, 0.08702455293863431, 0.0847384995446695, 0.08231491609015379, 0.07976368195869184, 0.07709519688320941, 0.07432033855296251, 0.07145041827222752, 0.06849713485142321, 0.06547252691862042, 0.06238892384583496, 0.059258895490145215, 0.05609520095450753, 0.05291073657713862, 0.04971848336147821, 0.04653145406102657, 0.04336264013475745, 0.040224958789334866, 0.03713120032400894, 0.034093975992830955, 0.03112566659672003, 0.02823837201493847, 0.025443861881702973, 0.02275352760899157, 0.02017833595111822, 0.017728784300362295, 0.015414857895883722, 0.013245989120355552, 0.011231019050234915, 0.0093781614164077, 0.007694969122115341, 0.006188303454649119, 0.004864306116315714, 0.003728374188685634, 0.002785138132179398, 0.002038442910672577, 0.0014913323180627317, 0.001146036570688618, 0.0010039632161793536, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire2.expand_1x1.1.weight
[0.1, 0.10089954475350396, 0.10059858266427779, 0.10009832306115585, 0.0994007760922079, 0.09850874464754225, 0.09742581309670516, 0.09615633288593171, 0.09470540505312175, 0.09307885973079895, 0.09128323271941496, 0.08932573922513154, 0.08721424486760798, 0.08495723407429068, 0.08256377598820312, 0.08004348802622593, 0.07740649723429759, 0.07466339959481848, 0.07182521744977012, 0.06890335521063175, 0.06590955353306177, 0.06285584214047941, 0.05975449148611146, 0.05661796344773611, 0.05345886125324284, 0.0502898788382178, 0.04712374983904671, 0.04397319642649159, 0.0408508781853387, 0.037769341245530226, 0.03474096786918116, 0.03177792669605163, 0.028892123847398612, 0.026095155084682138, 0.0233982592153622, 0.020812272933011924, 0.01834758727320839, 0.016014105860171275, 0.013821205111922197, 0.011777696563869417, 0.009891791462209393, 0.00817106776941634, 0.006622439714398692, 0.00525213000967638, 0.004065644847215921, 0.0030677517733956818, 0.0022624605320039565, 0.0016530069522469484, 0.0012418399465079547, 0.0010306116701034754, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire2.expand_1x1.1.bias
[0.1, 0.10090097422558925, 0.10060428914651687, 0.10011111994157135, 0.09942342006925006, 0.09854391353004979, 0.09747608407661626, 0.09622416141449207, 0.09479310444812197, 0.09318858163847883, 0.09141694855011402, 0.08948522267656941, 0.08740105564386809, 0.08517270290218665, 0.08280899102576128, 0.08031928275055389, 0.07771343988816484, 0.07500178426289174, 0.07219505682666373, 0.06930437511379813, 0.06634118920410255, 0.06331723636875423, 0.06024449457860529, 0.057135135059069045, 0.05400147407951923, 0.050855924168165485, 0.047710944945644596, 0.04457899377207722, 0.04147247640307847, 0.03840369785017579, 0.035384813640277075, 0.03242778166725192, 0.029544314826343832, 0.02674583461902912, 0.024043425912095896, 0.021447793030143304, 0.018969217355420193, 0.01661751660295157, 0.014402005932265278, 0.012331461049756482, 0.0104140834478429, 0.008657467918599226, 0.007068572470550482, 0.005653690767784696, 0.004418427200554508, 0.0033676746861137524, 0.0025055952877207233, 0.0018356037285765727, 0.0013603538660010342, 0.0010817281794213032, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire2.expand_3x3.0.weight
[0.1, 0.10090238002785763, 0.10060990129778898, 0.10012370588041329, 0.09944569227105456, 0.0985785079764991, 0.097525539177014, 0.09629089750399414, 0.09487940398486856, 0.09329657021795794, 0.09154857685079151, 0.08964224944592161, 0.08758503182847453, 0.08538495701951053, 0.08305061586869207, 0.08059112350874371, 0.07801608376269197, 0.07533555164286782, 0.07255999408810583, 0.06970024909245302, 0.0667674833849818, 0.06377314882595868, 0.060728937689633146, 0.05764673700825815, 0.054538582155619776, 0.05141660985132321, 0.04829301076934344, 0.04517998193589512, 0.04208967910249823, 0.03903416928021309, 0.036025383620389005, 0.033075070825917714, 0.030194751274911537, 0.027395672035943675, 0.02468876295050745, 0.022084593954183336, 0.01959333380316634, 0.017224710367318107, 0.014987972644791604, 0.01289185464655333, 0.010944541291827085, 0.009153636447630502, 0.00752613323720358, 0.006068386733268882, 0.004786089142750576, 0.003684247579851251, 0.002767164514277936, 0.002038420970963161, 0.0015008625468828298, 0.00115658829957228, 0.0010069425507287836, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire2.expand_3x3.0.bias
[0.1, 0.10090376260702254, 0.1006154208935224, 0.10013608482969137, 0.09946759961765515, 0.09861253858837576, 0.097574193295625, 0.09635656084516225, 0.09496432850789299, 0.09340285567623953, 0.09167815323318283, 0.08979686041339414, 0.08776621924552962, 0.08559404667407196, 0.08328870446803616, 0.08085906703237541, 0.07831448724599725, 0.07566476045789623, 0.07292008677999995, 0.07009103182188178, 0.06718848601849207, 0.0642236227074755, 0.06120785511745556, 0.05815279243285975, 0.05507019510441405, 0.05197192957733801, 0.04886992261151475, 0.045776115369479814, 0.04270241744896713, 0.03966066103696351, 0.03666255536175552, 0.03371964161830527, 0.03084324854046984, 0.028044448791088805, 0.025334016337816054, 0.02272238497877733, 0.020219608177709132, 0.017835320363193016, 0.015578699840964098, 0.013458433462062287, 0.011482683182836545, 0.009659054645528745, 0.007994567900386478, 0.006495630382009681, 0.005168012243958541, 0.004016824146572056, 0.0030464975835030263, 0.0022607678227020917, 0.0016626595275198433, 0.0012544751132781298, 0.0010377858841321798, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire2.expand_3x3.1.weight
[0.1, 0.10090512240033983, 0.10062084967171599, 0.10014826065869414, 0.09948914888572148, 0.09864601575051515, 0.09762206103099763, 0.09642117074180685, 0.09504790238646658, 0.09350746766118656, 0.0918057126759335, 0.08994909576783583, 0.08794466299112269, 0.08580002137661548, 0.08352331006225483, 0.08112316940422577, 0.07860870818590751, 0.07598946904909336, 0.07327539227867283, 0.0704767780782167, 0.06760424747963358, 0.0646687020352492, 0.061681282445281864, 0.05865332627772647, 0.0555963249411052, 0.05252188007337714, 0.049441659512515765, 0.046367353015850626, 0.04331062789622265, 0.04028308474331867, 0.037296213398227335, 0.03436134934829723, 0.03148963070778384, 0.028691955947547615, 0.025978942534223805, 0.02336088663583249, 0.02084772404675027, 0.01844899248033747, 0.0161737953723241, 0.014030767332324657, 0.012028041374596714, 0.01017321805240613, 0.008473336613137029, 0.006934848283615996, 0.005563591787035454, 0.00436477118439193, 0.00334293612453354, 0.002501964577769371, 0.0018450481185690306, 0.001374679813205553, 0.0010926447583096957, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire2.expand_3x3.1.bias
[0.1, 0.10090645983582973, 0.1006261893338114, 0.10016023715589589, 0.09951034671181187, 0.09867894963591267, 0.09766915668895707, 0.09648474611886654, 0.09513014952400789, 0.09361043527189589, 0.09193128953535587, 0.0900989950171023, 0.08812040744233705, 0.08600292990732283, 0.08375448517990974, 0.08138348605565499, 0.07889880388045178, 0.07630973535744329, 0.07362596776241714, 0.07085754269783069, 0.06801481852108529, 0.06510843158762829, 0.06214925645389564, 0.05914836518900001, 0.05611698594740444, 0.0530664609575858, 0.050008204083878176, 0.046953658120283265, 0.043914251976037065, 0.040901357913128086, 0.03792624899576724, 0.03500005691101667, 0.03213373031839644, 0.029337993884308133, 0.026623308154552595, 0.023999830415083148, 0.0214773766874376, 0.019065385001047847, 0.016772880079846758, 0.014608439575301935, 0.01258016197221868, 0.010695636287395994, 0.008961913674511511, 0.00738548104147867, 0.005972236778989342, 0.004727468691056552, 0.0036558342101322854, 0.002761342970827579, 0.00204734180743738, 0.0015165022314033373, 0.0011708104355690576, 0.00101155986262793, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire3.squeeze.0.weight
[0.1, 0.10090777533249282, 0.10063144154554313, 0.10017201803081582, 0.09953119959554654, 0.09871135021042028, 0.09771549428891504, 0.09654730553028062, 0.09521109336731105, 0.09371178706890432, 0.09205491755605487, 0.09024659699835974, 0.08829349626630612, 0.08620282032251886, 0.08398228164274923, 0.08164007176465436, 0.07918483106932382, 0.07662561690702868, 0.07397187018477686, 0.07123338053893268, 0.06842025022137849, 0.06554285683244197, 0.06261181503806638, 0.059637937412449174, 0.056632194550599514, 0.053605674597959264, 0.05056954234638186, 0.04753499804736372, 0.0445132360944653, 0.041515403727342304, 0.03855255990972676, 0.03563563453305684, 0.03277538809625282, 0.029982372010379645, 0.027266889674631752, 0.024638958467230618, 0.0221082727914496, 0.01968416831308925, 0.017375587521330366, 0.015191046740010261, 0.013138604711017486, 0.011225832865700103, 0.009459787393956153, 0.007846983214043025, 0.006393369939130588, 0.005104309929257327, 0.003984558509655566, 0.003038246428419821, 0.002268864618232113, 0.0016792513183576598, 0.0012715816044180086, 0.001047359364565991, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire3.squeeze.0.bias
[0.1, 0.10090906930052064, 0.10063660793776688, 0.10018360691583056, 0.09955171390270323, 0.09874322723733216, 0.09776108757003736, 0.0966088671666962, 0.09529075691559788, 0.09381155108422734, 0.09217662988142138, 0.09039193988832261, 0.08846397242930809, 0.08639973996156264, 0.08420675056917352, 0.08189298065451674, 0.07946684592626324, 0.07693717078952789, 0.07431315624949623, 0.07160434644527107, 0.06882059393566255, 0.06597202386318572, 0.06306899712660888, 0.06012207269600253, 0.05714196920735823, 0.05413952597646569, 0.051125663573850205, 0.04811134410416795, 0.045107531334532235, 0.042125150816792946, 0.03917505014881379, 0.0362679595192857, 0.03341445267958439, 0.03062490848462598, 0.027909473142605543, 0.0252780233109247, 0.022740130172537027, 0.020305024623373635, 0.017981563697470178, 0.01577819835191487, 0.013702942728790912, 0.011763345005914676, 0.00996645994239212, 0.00831882321885168, 0.006826427665683737, 0.005494701465750229, 0.004328488410846192, 0.0033320302837245843, 0.002508951429765465, 0.0018622455744055012, 0.0013942649342761119, 0.0011067116616552898, 0.0010006316533517127, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire3.squeeze.1.weight
[0.1, 0.10091034214150087, 0.10064169010726709, 0.1001950073679415, 0.09957189586823754, 0.09877459028186202, 0.09780594999727267, 0.09666944886301242, 0.0953691627293964, 0.0939097548312317, 0.09229645906399137, 0.09053506121342003, 0.08863187820588758, 0.08659373545390553, 0.0844279423780522, 0.08214226619309294, 0.07974490405230636, 0.07724445364991606, 0.07464988238705648, 0.07197049521185375, 0.06921590124895653, 0.06639597933819481, 0.06352084260595472, 0.06060080219632842, 0.05764633029211025, 0.05466802255825736, 0.05167656014250446, 0.04868267136941066, 0.04569709326521514, 0.04273053305148608, 0.039793629745658365, 0.036896916006172745, 0.03405078035905192, 0.03126542994138065, 0.028550853895303666, 0.02591678754382193, 0.023372677476864192, 0.020927647672846023, 0.018590466777215237, 0.016369516655332882, 0.014272762332469453, 0.01230772342872043, 0.01048144719128486, 0.008800483220821852, 0.00727085998252363, 0.005898063186144425, 0.004687016112520986, 0.00364206195713978, 0.002766948254072892, 0.0020648134361427256, 0.0015381755795153933, 0.0011889233730881068, 0.001018309345057027, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire3.squeeze.1.bias
[0.1, 0.10091159424861718, 0.10064668961754383, 0.10020622287049813, 0.09959175159922935, 0.0988054487155151, 0.09785009476724532, 0.09672906810576536, 0.09544633293924834, 0.09400642531434311, 0.09241443707566975, 0.09067599785988555, 0.08879725518799467, 0.08678485272629968, 0.08464590679286904, 0.08238798119259919, 0.08001906046986046, 0.07754752167331128, 0.07498210473272687, 0.07233188155259694, 0.06960622393178433, 0.06681477042268828, 0.06396739224710567, 0.06107415838931977, 0.058145299989855584, 0.05519117416581305, 0.052222227385718314, 0.0492489585284078, 0.046281881756577214, 0.04333148933628353, 0.040408214533878384, 0.037522394721577944, 0.034684234822136714, 0.031903771221892856, 0.029190836279797284, 0.026555023557930338, 0.024005653896459228, 0.021551742453002978, 0.019201966822961027, 0.016964636353539536, 0.01484766275998816, 0.012858532147954738, 0.01100427854089344, 0.009291459006139775, 0.007726130467611835, 0.006313828287133993, 0.005059546690124072, 0.003967721104863219, 0.0030422124778012086, 0.002286293620361501, 0.0017026376355271482, 0.0012933084651336958, 0.0010597535912959912, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire3.expand_1x1.0.weight
[0.1, 0.10091282600684416, 0.10065160799957994, 0.10021725683487843, 0.09961128707775802, 0.09883581172035705, 0.09789353481401551, 0.09678774204035674, 0.09552228925424809, 0.09410158903859013, 0.09253059531781793, 0.09081478608376599, 0.08896014429413135, 0.08697313701014103, 0.0848606928461701, 0.08263017780994217, 0.08028936961755737, 0.07784643057290935, 0.0753098791060605, 0.07268856006981919, 0.06999161389809441, 0.0672284447335708, 0.06440868763584183, 0.06154217498434503, 0.05863890219325089, 0.05570899285785624, 0.052762663454015146, 0.049810187713699, 0.04686186080090696, 0.04392796341284369, 0.04101872593154231, 0.03814429275093413, 0.035314686903755686, 0.03253977511163721, 0.029829233380241682, 0.02719251325942276, 0.024638808886051067, 0.022177024924429252, 0.01981574551608621, 0.017563204347221178, 0.015427255938171715, 0.013415348255017466, 0.01153449673882248, 0.009791259843074777, 0.008191716164623108, 0.0067414432478545665, 0.0054454981360219975, 0.004308399737537749, 0.003334113068722127, 0.002526035427951078, 0.0018869845494136443, 0.0014191887777863057, 0.0011242792980848228, 0.0010032844477878048, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire3.expand_1x1.0.bias
[0.1, 0.10091403779313711, 0.10065644675258877, 0.10022811260212752, 0.0996305081637073, 0.09886568829318243, 0.09793628281470981, 0.09684548747812945, 0.09559705297041608, 0.09419527201898598, 0.09264496463120404, 0.09095146152084509, 0.08912058577849694, 0.08715863284893174, 0.08507234888429298, 0.08286890754753035, 0.0805558853458439, 0.07814123557895283, 0.07563326099176766, 0.07304058522549921, 0.07037212316536941, 0.067637050286883, 0.06484477110606261, 0.062004886842130694, 0.0591271624038297, 0.056221492812898066, 0.05329786918015381, 0.05036634435117724, 0.047436998339719205, 0.04451990366769214, 0.041625090730921466, 0.03876251330974714, 0.0359420143430668, 0.033173292083505654, 0.03046586675008859, 0.02782904779307871, 0.025271901883541684, 0.022803221737703695, 0.02043149588329976, 0.018164879471870572, 0.016011166237369673, 0.01397776169750058, 0.012071657689930942, 0.01029940833094084, 0.008667107479170655, 0.007180367781959678, 0.005844301376324045, 0.004663502310933481, 0.0036420307495289234, 0.0027833990100969864, 0.002090559487805848, 0.0015658945032290253, 0.0012112081107640274, 0.0010277198954124925, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire3.expand_1x1.1.weight
[0.1, 0.10091522997661714, 0.10066120734474314, 0.10023879344455572, 0.09964942059750276, 0.09889508724958528, 0.09797835119502492, 0.09690232090329294, 0.09567064497890898, 0.09428749978974944, 0.0927575753058154, 0.0910860591964779, 0.08927861924012395, 0.08734138410584802, 0.08528092257235537, 0.08310422125454092, 0.08081866091326904, 0.07843199142868262, 0.07595230552190228, 0.07338801131422004, 0.0707478038168337, 0.06804063544779482, 0.06527568567614123, 0.06246232989614471, 0.05961010763721546, 0.05672869021725679, 0.0538278479491513, 0.05091741701157493, 0.048007266096472934, 0.045107262946290166, 0.04222724089442068, 0.039376965522331685, 0.03656610154642075, 0.03380418004688644, 0.031100566149732656, 0.0284644272714906, 0.025904702034334218, 0.02343006995699179, 0.021048922024225772, 0.01876933223467368, 0.016599030223526053, 0.014545375052872234, 0.01261533025858566, 0.010815440238360025, 0.009151808060959353, 0.007630074771926792, 0.006255400265922111, 0.005032445790546002, 0.003965358140977437, 0.0030577555990166307, 0.0023127156642117445, 0.0017327646186705728, 0.0013198689609407667, 0.001075428738004757, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire3.expand_1x1.1.bias
[0.1, 0.10091640291875158, 0.10066589121388603, 0.1002493025672972, 0.09966803000278247, 0.09892401722793404, 0.0980197521346074, 0.09695825847970167, 0.09574308577406938, 0.0943782974133667, 0.09286845709053268, 0.09121861353533292, 0.08943428363199667, 0.08752143397140005, 0.08548646089948281, 0.08333616912861415, 0.0810777489834292, 0.07871875235722275, 0.07626706745929986, 0.07373089243772475, 0.07111870796567103, 0.06843924888304052, 0.06570147498817856, 0.06291454107735422, 0.06008776633219065, 0.057230603157409535, 0.05435260557309333, 0.051463397267157644, 0.04857263941486222, 0.04568999837296899, 0.04282511335657355, 0.039987564206695185, 0.03718683935640705, 0.034432304102623726, 0.03173316928964168, 0.029098460509151394, 0.026536987919712363, 0.02405731678661162, 0.0216677388406165, 0.019376244551395, 0.017190496408318195, 0.015117803297990319, 0.0131650960641852, 0.011338904331914063, 0.009645334673121581, 0.008090050187022378, 0.00667825156335845, 0.005414659691899714, 0.004303499876339916, 0.0033484877053743083, 0.0025528166282048617, 0.0019191472760189889, 0.0014495985651494562, 0.001145740611665579, 0.001008589481088367, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire3.expand_3x3.0.weight
[0.1, 0.10091755697352973, 0.1006704997682235, 0.10025964310982992, 0.09968634188900356, 0.0989524866932534, 0.09806049757231255, 0.09701331605748938, 0.09581439546131772, 0.09446768948949541, 0.09297763920266576, 0.09134915837103831, 0.08958761727014541, 0.08769882497117143, 0.0856890101842564, 0.08356480071794747, 0.08133320162253498, 0.07900157208935071, 0.07657760118220759, 0.07406928248101206, 0.07148488772116722, 0.06883293951569693, 0.06612218325004522, 0.06336155824223466, 0.06056016826348896, 0.05772725151653496, 0.054872150170587, 0.05200427955347861, 0.04913309710253777, 0.04626807117659665, 0.04341864983198527, 0.040594229665477155, 0.03780412482693434, 0.03505753630383919, 0.032363521579004184, 0.029730964761520186, 0.027168547289442686, 0.02468471930083084, 0.02228767176754918, 0.019985309483727134, 0.017785224997953087, 0.015694673575166972, 0.013720549270820191, 0.011869362196203936, 0.010147217049917934, 0.008559792986277437, 0.007112324887046383, 0.005809586098257535, 0.00465587268904885, 0.003654989284425691, 0.0028102365186688785, 0.002124400150763566, 0.0015997418777430764, 0.0012379918762430323, 0.001040343096861406, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire3.expand_3x3.0.bias
[0.1, 0.10091869248763435, 0.10067503438700008, 0.1002698181474584, 0.09970436165398561, 0.09898050394101511, 0.09810059921134484, 0.09706750917956233, 0.09588459376488895, 0.09455570016371291, 0.09308515033735065, 0.09147772695572981, 0.08973865784270951, 0.08787359897362622, 0.08588861608036236, 0.08379016492376352, 0.08158507029756426, 0.07928050383210805, 0.0768839606700504, 0.07440323508990267, 0.0718463951566962, 0.06922175648221043, 0.06653785518010462, 0.06380342010391112, 0.061027344458180754, 0.05821865687510927, 0.05538649205071233, 0.052540061036049204, 0.04968862128011676, 0.04684144652184363, 0.04400779662910446, 0.041196887482846965, 0.038417861004277874, 0.035679755422588035, 0.03299147587991511, 0.030361765469145426, 0.02779917679874864, 0.02531204417712501, 0.022908456506930054, 0.020596230977532434, 0.018382887641165063, 0.01627562495545561, 0.014281296371879103, 0.01240638804627437, 0.010656997743916152, 0.009038815007750074, 0.0075571026542894095, 0.006216679657354168, 0.005021905475320331, 0.003976665872851065, 0.003084360283222492, 0.002347890752345121, 0.0017696525004385001, 0.0013515261320553187, 0.0010948715197902795, 0.0010005233815658034, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire3.expand_3x3.1.weight
[0.1, 0.10091980980060865, 0.10067949642115771, 0.1002798306927598, 0.09972209458639288, 0.09900807710084006, 0.09814006852428277, 0.09712085308795411, 0.09595370003541653, 0.09464235313611019, 0.09319101867680815, 0.0916043519694974, 0.08988744241896302, 0.08804579719797274, 0.08608532358242582, 0.08401231000312748, 0.08183340587496835, 0.07955560026820806, 0.07718619949027788, 0.07473280365001063, 0.07220328227947095, 0.0696057490915816, 0.06694853595451307, 0.06424016616631682, 0.061489327115526515, 0.05870484241542121, 0.05589564360133301, 0.05307074148178326, 0.050239197235340996, 0.047410093345914554, 0.044592504469703614, 0.04179546832725962, 0.03902795671402127, 0.03629884672231191, 0.03361689226710736, 0.030990696006908514, 0.02842868174978519, 0.025939067433102286, 0.0235298387635983, 0.021208723602368702, 0.018983167176917067, 0.016860308199783947, 0.014846955970355576, 0.012949568533300863, 0.011174231963695835, 0.009526640845280602, 0.008012080004467226, 0.006635407558688299, 0.0054010393334607935, 0.0043129346981488174, 0.0033745838658589484, 0.0025889966982048035, 0.0019586930508509173, 0.0014856946908036396, 0.0011715188113751154, 0.0010171731656219642, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire3.expand_3x3.1.bias
[0.1, 0.10092090924501924, 0.10068388719397792, 0.10028968369699456, 0.09973954586815688, 0.09903521414011394, 0.09817891675799084, 0.09717336273004518, 0.09602173325736674, 0.0947276716697336, 0.09329527189946407, 0.09172906552972873, 0.09003400745829711, 0.08821546022207345, 0.08627917703201299, 0.08423128357209005, 0.08207825861989926, 0.07982691355019907, 0.07748437078624087, 0.07505804126705572, 0.07255560100198376, 0.06998496678661938, 0.06735427115699748, 0.06467183666125688, 0.06194614953017578, 0.05918583282987573, 0.05639961918162925, 0.053596323135075424, 0.05078481328224449, 0.04797398420061233, 0.045172728313946475, 0.04238990775996572, 0.0396343263538137, 0.03691470173604335, 0.03423963779322602, 0.0316175974384361, 0.029056875837723567, 0.02656557416727627, 0.024151573984294225, 0.021822512292657272, 0.01958575738226893, 0.01744838551851202, 0.015417158555561632, 0.013498502544379315, 0.011698487403063972, 0.010022807713875696, 0.008476764707683498, 0.007065249492831021, 0.005792727581478695, 0.004663224762374429, 0.0036803143647468556, 0.002847105953613054, 0.0021662354922647392, 0.0016398570030551943, 0.0012696357528691128, 0.001056742984833974, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire4.squeeze.0.weight
[0.1, 0.10092199114661499, 0.1006882080017082, 0.10029938005148265, 0.09975672057684076, 0.09906192286751836, 0.09821715493842101, 0.09722505276464971, 0.0960887120563251, 0.09481167859887568, 0.0933979371889314, 0.0918518992003472, 0.09017838881915421, 0.08838262799039105, 0.08647022012378594, 0.08444713260913402, 0.08231967819592786, 0.08009449529534365, 0.07777852726604723, 0.07537900074845623, 0.07290340311506287, 0.07035945910718008, 0.06775510673101309, 0.0650984724882689, 0.062397846018593106, 0.05966165423295853, 0.05689843501871873, 0.0541168105983759, 0.05132546062519316, 0.048533095099602686, 0.045748427190919816, 0.0429801460491691, 0.040236889691859165, 0.037527218050309015, 0.03485958625963094, 0.0322423182757147, 0.02968358090153736, 0.027191358303845836, 0.02477342709972918, 0.022437332090819263, 0.020190362720837837, 0.018039530329950648, 0.015991546276903107, 0.014052800997204427, 0.012229344062705604, 0.010526865304792882, 0.008950677060099, 0.007505697594131405, 0.0061964357545423445, 0.005026976901927277, 0.004000970162053129, 0.0031216170392936553, 0.002391661426801899, 0.0018133810445919766, 0.0013885803322459358, 0.0011185848184232564, 0.0010042369847420454, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire4.squeeze.0.bias
[0.1, 0.1009230558244818, 0.100692460114173, 0.10030892258894594, 0.09977362368794696, 0.0990882109364798, 0.09825479387530651, 0.09727593756797248, 0.09615465470613845, 0.09489439633721748, 0.09349904124285503, 0.09197288400094275, 0.09032062176790823, 0.08854733982196189, 0.08665849591179545, 0.0846599034589029, 0.08255771366522363, 0.08035839658117593, 0.07806872119234923, 0.07569573458614343, 0.07324674026247571, 0.07072927565530944, 0.0681510889341884, 0.06552011515717614, 0.06284445184859591, 0.060132334076737494, 0.05739210910823542, 0.05463221071712712, 0.051861133227661296, 0.049087405370746934, 0.046319564034506516, 0.04356612798972331, 0.040835571671049654, 0.0381362990946714, 0.03547661799270409, 0.032864714243929005, 0.030308626679565437, 0.027816222341621084, 0.025395172269969613, 0.02305292789267704, 0.020796698092242313, 0.018633427018336386, 0.01656977271532743, 0.014612086630371425, 0.012766394065137597, 0.011038375631333596, 0.009433349767106247, 0.007956256368127822, 0.00661164158374829, 0.005403643825006576, 0.004335981027565632, 0.0034119392087727123, 0.0026343623540634456, 0.0020056436638373524, 0.0015277181877445247, 0.0012020568690536406, 0.0010296620174312923, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire4.squeeze.1.weight
[0.1, 0.10092410359119364, 0.10069664477536933, 0.10031831408481795, 0.09979026007716969, 0.099114085848538, 0.09829184416675009, 0.09732603123943871, 0.09621957913591433, 0.0949758468858239, 0.09359861028161937, 0.09209205041579414, 0.09046074098768696, 0.08870963441838764, 0.08684404681589804, 0.08486964183619189, 0.08279241348916873, 0.08061866794170099, 0.0783550043730171, 0.07600829494054143, 0.07358566391701145, 0.07109446606220914, 0.06854226429496668, 0.06593680673323143, 0.06328600317189269, 0.060597901069780746, 0.05788066111873779, 0.055142532468929806, 0.052391827685611604, 0.04963689751337278, 0.04688610552447678, 0.04414780272825678, 0.04143030221865111, 0.03874185393684411, 0.03609061962562981, 0.03348464805153322, 0.030931850569911365, 0.028439977107214832, 0.026016592633324388, 0.023669054195389012, 0.021404488582887717, 0.01922977069172029, 0.01715150265301097, 0.015175993789986804, 0.013309241463778522, 0.011556912866293713, 0.009924327815436312, 0.00841644260490354, 0.007037834957590294, 0.005792690128279914, 0.004684788197811934, 0.003717492597299659, 0.0028937398972363965, 0.002216030892489334, 0.0016864230102455072, 0.0013065240639584244, 0.0010774873722573955, 0.001000008257637818, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire4.squeeze.1.bias
[0.1, 0.10092513475295983, 0.10070076320404789, 0.10032755725852169, 0.09980663452259358, 0.09913955495663615, 0.09832831620370941, 0.09737534760739922, 0.09628350293688095, 0.09505605184099414, 0.09369667005691967, 0.09220942840278105, 0.0905987805871321, 0.08886954987183732, 0.08702691462828432, 0.08507639283018167, 0.08302382552938022, 0.08087535936420165, 0.07863742815265447, 0.07631673362565916, 0.07392022535797842, 0.07145507995695202, 0.0689286795713575, 0.0663485897847544, 0.06372253695951316, 0.06105838509937383, 0.05836411229982291, 0.05564778685680969, 0.052917543105347464, 0.05018155706035356, 0.04744802193267425, 0.04472512359361461, 0.04202101606144737, 0.03934379708330933, 0.03670148388560762, 0.034101989165554396, 0.031553097395725496, 0.02906244151260201, 0.02663748005890323, 0.024285474848160876, 0.022013469218420664, 0.01982826694019249, 0.017736411841812016, 0.015744168213227765, 0.013857502046896446, 0.012082063171963059, 0.01042316833522668, 0.008885785279557915, 0.007474517867447122, 0.006193592294232163, 0.005046844432292212, 0.004037708344106349, 0.0031692059985761237, 0.0024439382214076757, 0.0018640769066533161, 0.001431358512736174, 0.0011470788624346243, 0.0010120892623986014, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire4.expand_1x1.0.weight
[0.1, 0.10092614960976859, 0.10070481659427986, 0.10033665477471641, 0.09982275170683995, 0.09916462546833463, 0.09836422017438187, 0.09742390023471373, 0.09634644336910968, 0.09513503240196902, 0.09379324586019792, 0.09232504740218506, 0.09073477410909286, 0.08902712367305214, 0.0872071405201061, 0.08528020090889714, 0.08325199704911485, 0.08112852028661975, 0.0789160434049142, 0.07662110209524188, 0.07425047565005385, 0.07181116693687291, 0.06931038171171365, 0.06675550733316651, 0.06415409094002544, 0.06151381715692196, 0.05884248539382408, 0.056147986806457474, 0.053438280985708346, 0.05072137244486768, 0.048005286974174055, 0.04529804793250395, 0.04260765254624446, 0.039942048285361666, 0.037309109386450316, 0.03471661359211603, 0.032172219175402174, 0.029683442317131825, 0.027257634902992312, 0.02490196280595, 0.022623384718149866, 0.020428631594830195, 0.018324186770975692, 0.016316266809444903, 0.014410803137146287, 0.012613424523510674, 0.010929440453018534, 0.009363825440899785, 0.007921204338338372, 0.006605838670589464, 0.005421614048367462, 0.004372028689691309, 0.0034601830860937536, 0.002688770843721077, 0.0020600707263784095, 0.0015759399240259145, 0.0012378085666106754, 0.0010466754994404683, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire4.expand_1x1.0.bias
[0.1, 0.10092714845552711, 0.10070880611600971, 0.10034560924451413, 0.09983861621916178, 0.09918930444895005, 0.09839956606849108, 0.09747170242421475, 0.09640841736810286, 0.09521280937849752, 0.09388836253094383, 0.09243893634537843, 0.09086875453925003, 0.08918239271934586, 0.08738476504819066, 0.0854811099238737, 0.083476974715033, 0.08137819959548041, 0.07919090052557436, 0.07692145142993351, 0.07457646562342667, 0.07216277653956467, 0.06968741781745301, 0.06715760280533288, 0.06458070354043881, 0.061964229266426765, 0.059315804550974176, 0.056643147067318655, 0.05395404510448144, 0.051256334871712085, 0.04855787766329046, 0.04586653695022968, 0.04319015546563571, 0.040536532350498596, 0.037913400426513824, 0.03532840366216213, 0.03278907489771312, 0.03030281389406338, 0.02787686576937607, 0.025518299886358942, 0.023233989251704758, 0.021030590487725178, 0.018914524434541953, 0.016891957439362382, 0.014968783387362416, 0.013150606526541136, 0.011442725136596027, 0.009850116089408407, 0.008377420346131492, 0.007028929433142694, 0.005808572936270766, 0.004719907049739935, 0.003766104213200105, 0.002949943867041887, 0.0022738043529354816, 0.0017396559831961526, 0.0013490552991724295, 0.0011031405353884517, 0.0010026283026582253, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire4.expand_1x1.1.weight
[0.1, 0.10092813157819809, 0.10071273291559446, 0.1003544232266667, 0.09985423255748915, 0.09921359882462162, 0.09843436368147745, 0.09751876722405467, 0.09646944155124935, 0.09528940319826394, 0.09398204446486222, 0.09255112366340014, 0.09100075431466668, 0.08933539332259398, 0.08755982816183128, 0.08567916311501499, 0.0836988045992992, 0.08162444562432901, 0.07946204942633564, 0.07721783232540154, 0.0748982458551757, 0.07250995821641203, 0.07005983510764682, 0.06755491998812196, 0.06500241382969299, 0.062409654415929716, 0.05978409524791931, 0.05713328411741191, 0.05446484140890526, 0.05178643819304451, 0.049105774174312625, 0.04643055555640588, 0.04376847288892602, 0.0411271789590738, 0.03851426679189934, 0.03593724782235313, 0.03340353030188692, 0.03092039800168027, 0.0284949892737148, 0.026134276529890667, 0.02384504619817689, 0.021633879213416758, 0.01950713209887165, 0.01747091869288936, 0.015531092573227451, 0.013693230229557547, 0.011962615032524809, 0.010344222045447497, 0.008842703722319094, 0.007462376533227188, 0.006207208555637777, 0.005080808067216702, 0.004086413172980746, 0.003226882496597782, 0.0025046869625958857, 0.001921902693105492, 0.0014802050395545821, 0.0011808637664741208, 0.0010247394012591663, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire4.expand_1x1.1.bias
[0.1, 0.10092909925993304, 0.10071659811632981, 0.10036309922872419, 0.09986960513042593, 0.09923751538530658, 0.09846862261859482, 0.09756510743293834, 0.09652953222415012, 0.0953648339141781, 0.09407431562190754, 0.09266163729541813, 0.09113080533226284, 0.08948616121720593, 0.08773236920964353, 0.08587440311562607, 0.08391753218199693, 0.08186730615265253, 0.07972953952930427, 0.07751029508137956, 0.07521586665182829, 0.07285276130759794, 0.07042768088539897, 0.0679475029850976, 0.06541926146463901, 0.06285012649181793, 0.06024738420947057, 0.05761841607175783, 0.05497067791014271, 0.05231167878843174, 0.049648959706847566, 0.04699007221552918, 0.04434255699811217, 0.04171392248612664, 0.03911162356486324, 0.03654304043109768, 0.034015457662634245, 0.03153604355902753, 0.029111829812072682, 0.026749691563719254, 0.02445632790796519, 0.02223824289202797, 0.02010172707067398, 0.018052839666019227, 0.01609739138339586, 0.014240927932019865, 0.012488714297195676, 0.010845719808661846, 0.009316604047424935, 0.007905703631049692, 0.006617019914883398, 0.005454207644093616, 0.004420564588702624, 0.0035190221910141478, 0.002752137251956093, 0.0021220846799174567, 0.0016306513226438104, 0.0012792308996841186, 0.0010688200497608704, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire4.expand_3x3.0.weight
[0.1, 0.10093005177720211, 0.10072040281896336, 0.10037163970816534, 0.09988473825919918, 0.09926106078770619, 0.09850235229891555, 0.09761073560524379, 0.09658870538681646, 0.09543912121153057, 0.09416519953418682, 0.09277050469707777, 0.09125893895721147, 0.08963473156807374, 0.08790242694647761, 0.08606687195760808, 0.08413320235383792, 0.08210682840525761, 0.07999341976212423, 0.07779888959158311, 0.07552937803304648, 0.07319123501851986, 0.07079100250594383, 0.06833539617526062, 0.06583128663841914, 0.06328568021589112, 0.06070569933348452, 0.05809856259430242, 0.055471564581604654, 0.05283205544908252, 0.05018742035565118, 0.04754505880229998, 0.0449123639288148, 0.0422967018282984, 0.03970539093736564, 0.03714568155967801, 0.034624735580109436, 0.032149606426301526, 0.029727219333674462, 0.02736435196911054, 0.025067615467524104, 0.022843435934376002, 0.020698036465887276, 0.01863741973725849, 0.01666735120761099, 0.014793342988642367, 0.01302063842212962, 0.011354197409431686, 0.009798682534038, 0.00835844601599135, 0.007037517534685549, 0.005839592954109029, 0.004768023982080077, 0.0038258087924066425, 0.003015583636209173, 0.002339615465877331, 0.0017997955922984467, 0.0013976343931040127, 0.0011342570867405191, 0.0010104005841881749, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire4.expand_3x3.0.bias
[0.1, 0.100930989400921, 0.1007241481021954, 0.10038004707350079, 0.09989963617956249, 0.09928424155812432, 0.0985355619592461, 0.09765566405603329, 0.09664697673974305, 0.09551228441501464, 0.09425471931373199, 0.09287775284873596, 0.091385186031253, 0.08978113897849266, 0.08807003954037745, 0.0862566110767997, 0.08434585941914574, 0.082343059052079, 0.08025373855372614, 0.07808366533445757, 0.07583882971638954, 0.07352542839755555, 0.0711498473463925, 0.06871864417376045, 0.06623853003115643, 0.06371635108509108, 0.06115906961876647, 0.05857374481322284, 0.05596751326100591, 0.05334756926614598, 0.05072114498482862, 0.04809549046157737, 0.04547785361605721, 0.042875460235743366, 0.04029549402968442, 0.037745076798419736, 0.03523124877479052, 0.0327609491899125, 0.030340997117955945, 0.027978072652609966, 0.025678698467191858, 0.02344922180930331, 0.021295796979736076, 0.019224368343992555, 0.01724065392331684, 0.015350129610531782, 0.013558014054253397, 0.01186925425320793, 0.010288511900418257, 0.008820150514954567, 0.007468223396771872, 0.006236462437883682, 0.005128267820757758, 0.004146698632371098, 0.0032944644198327926, 0.00257391771088537, 0.0019870475199307786, 0.001535473857507407, 0.0012204432583741256, 0.0010428253405459212, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire4.expand_3x3.1.weight
[0.1, 0.10093191239657447, 0.10072783502316746, 0.10038832368534974, 0.09991430304365441, 0.09930706409526016, 0.0985682606579551, 0.0976999048659572, 0.09670436168985833, 0.0955843424956172, 0.09434289766014291, 0.09298340826358069, 0.09150957688092634, 0.08992541749804782, 0.08823524457957806, 0.08644366131845281, 0.08455554709909557, 0.08257604420839391, 0.08051054383065993, 0.0783646713647174, 0.07614427110310482, 0.07385539031512053, 0.07150426277705978, 0.06909729179449912, 0.06664103276286729, 0.06414217531379846, 0.06160752509589305, 0.05904398523950543, 0.05645853755603987, 0.05385822352295834, 0.05125012510628751, 0.04864134547285493, 0.04603898964478483, 0.043450145148940966, 0.040881862714017864, 0.03834113706785212, 0.03583488788725204, 0.03336994095222943, 0.030953009555959365, 0.02859067622109847, 0.02628937477225727, 0.024055372813452214, 0.02189475465826021, 0.019813404759165477, 0.01781699168122877, 0.01591095266372704, 0.014100478811809813, 0.01239050095850272, 0.010785676235563497, 0.009290375389764231, 0.007908670879144541, 0.006644325781655269, 0.005500783546400028, 0.0044811586153874145, 0.0035882279413352418, 0.0028244234246283632, 0.0021918252900279037, 0.0016921564211705258, 0.0013267776682876922, 0.0010966841419244747, 0.001002502502751811, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire4.expand_3x3.1.bias
[0.1, 0.10093282102433705, 0.10073146461793905, 0.100396471857491, 0.09992874292181293, 0.09932953467293636, 0.09860045727871597, 0.0977434698860527, 0.09676087535635436, 0.09565531407738082, 0.09442975686810225, 0.09308749699563608, 0.09163214132571454, 0.09006760063046285, 0.08839807907953262, 0.08662806294282938, 0.08476230853519195, 0.08280582943541812, 0.080763883013981, 0.07864195630563864, 0.07644575126489897, 0.07418116944396129, 0.07185429613430704, 0.0694713840145538, 0.06703883634851356, 0.06456318977860458, 0.06205109676085362, 0.05950930768868884, 0.05694465275355897, 0.054364023591122856, 0.051774354762328445, 0.04918260511914471, 0.04659573910501982, 0.044020708040314, 0.04146443144299637, 0.03893377843479967, 0.036435549282797866, 0.033976457126007054, 0.03156310993611343, 0.02920199276080241, 0.026899450297404294, 0.02466166984368357, 0.022494664671585785, 0.02040425786861967, 0.018396066690294928, 0.01647548746566333, 0.014647681096524527, 0.012917559189262035, 0.011289770856575974, 0.00976869022457777, 0.008358404678817738, 0.007062703880830145, 0.005885069584709973, 0.004828666281085991, 0.0038963326936311596, 0.0030905741509607335, 0.0024135558544158492, 0.0018670970598231853, 0.0014526661888652473, 0.0011713768831977992, 0.001023985011917632, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire5.squeeze.0.weight
[0.1, 0.10093371553919077, 0.10073503790195285, 0.1004044938578886, 0.09994295980434742, 0.09935165944276468, 0.09863216053416608, 0.09778637074244007, 0.09681653257639869, 0.09572521744403828, 0.09451531883476375, 0.093190044647653, 0.09175290868610278, 0.0902077213414059, 0.08855857948996204, 0.0868098556309081, 0.08496618629296807, 0.08303245974126103, 0.08101380301666027, 0.07891556834206775, 0.07674331893164572, 0.07450281424063072, 0.07219999469483815, 0.0698409659403453, 0.06743198265511323, 0.06497943196546832, 0.06248981651141339, 0.05996973720566822, 0.05742587573215191, 0.0548649768303103, 0.05229383041225919, 0.04971925356015787, 0.047148072451544475, 0.04458710426055611, 0.042043139083020334, 0.039522921933341594, 0.0370331348609154, 0.03458037923348678, 0.03217115823442619, 0.029811859620329336, 0.027508738784657163, 0.025267902172320514, 0.023095291089183775, 0.020996665949414746, 0.01897759100244661, 0.017043419580047094, 0.01519927990261007, 0.013450061482302555, 0.01180040215911769, 0.010254675804205683, 0.008816980723086298, 0.007491128789489964, 0.006280635338637907, 0.005188709846758266, 0.004218247421549947, 0.003371821126156576, 0.0026516751570023526, 0.0020597188935780487, 0.0015975218359534187, 0.0012663094434385393, 0.00106695988542747, 0.001000001713038822, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire5.squeeze.0.bias
[0.1, 0.1009345961910399, 0.10073855587048863, 0.10041239190969319, 0.09995695760326878, 0.0993734444367503, 0.09866337896948446, 0.0978286188409181, 0.09687134791073027, 0.09579407054552258, 0.0945996050670147, 0.09329107637888528, 0.09187190779154775, 0.0903458120662489, 0.0887167817019196, 0.0869890784901894, 0.0851672223658903, 0.08325597958221856, 0.08126035024149014, 0.07918555521411133, 0.07703702247998617, 0.07482037292809418, 0.0725414056513883, 0.07020608277548417, 0.06782051386083127, 0.06539093991917178, 0.06292371708610309, 0.06042529999245865, 0.05790222487801027, 0.05536109249166905, 0.05280855082292055, 0.05025127770967133, 0.047695963368007764, 0.04514929288957124, 0.042617928752339995, 0.04010849339057163, 0.037627551869506094, 0.03518159471015479, 0.032777020909108716, 0.03042012119778842, 0.028117061584932202, 0.025873867225377795, 0.023696406657339276, 0.02159037644941709, 0.019561286297506537, 0.01761444461059394, 0.01575494462314999, 0.013987651070452262, 0.012317187461696667, 0.010747923984192866, 0.009283966070288464, 0.007929143656932569, 0.0066870011659770625, 0.005560788231429164, 0.004553451197913643, 0.0036676254125864276, 0.002905628330664955, 0.002269453452612185, 0.001760765108835687, 0.0013808941055457316, 0.0011308342431634636, 0.00101123971638759, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire5.squeeze.1.weight
[0.1, 0.10093546322482311, 0.10074201949910638, 0.10042016819221927, 0.09997074015397911, 0.09939489556983638, 0.09869412096588964, 0.09787022537146145, 0.09692533564914169, 0.09586189100435341, 0.09468263668861476, 0.09339061691275181, 0.09198916698835652, 0.09048190471777656, 0.0888727210548635, 0.08716577006058823, 0.08536545817945294, 0.0834764328643825, 0.0815035705794594, 0.0794519642114731, 0.07732690992278052, 0.07513389347941636, 0.07287857608974722, 0.07056677979022628, 0.06820447241597503, 0.06579775219498987, 0.06335283200574346, 0.060876023338818946, 0.058373720003980036, 0.05585238162473656, 0.053318516963013575, 0.050778667116971134, 0.04823938863534915, 0.045707236591926825, 0.043188747663789745, 0.040690423257087556, 0.03821871272384242, 0.03577999671313381, 0.033380570699637846, 0.031026628732042, 0.02872424744328796, 0.026479370363919896, 0.02429779257903262, 0.022185145768427506, 0.02014688366859435, 0.018188267994048664, 0.016314354854368295, 0.01452998170199312, 0.012839754844481816, 0.011248037553462393, 0.009758938800973099, 0.008376302652270174, 0.007103698342484787, 0.005944411062746185, 0.004901433479555855, 0.003977458009305822, 0.0031748698678838107, 0.0024957409133075197, 0.0019418242972832392, 0.0015145499394955955, 0.0012150208363112694, 0.0010440102134259047, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire5.squeeze.1.bias
[0.1, 0.10093631688062268, 0.10074542974407846, 0.1004278248418995, 0.0999843112169218, 0.09941601864239039, 0.09872439474405985, 0.09791120131262143, 0.09697850981585003, 0.09592869612190286, 0.09476443444721172, 0.09348869054438527, 0.09210471414747386, 0.09061603069384146, 0.08902643234373181, 0.08733996832040458, 0.08556093459544867, 0.08369386294554743, 0.0817435094085715, 0.0797148421684058, 0.07761302889937163, 0.07544342360248184, 0.07321155296706136, 0.07092310229247459, 0.06858390100582148, 0.06619990781249345, 0.06377719551741555, 0.06132193555563993, 0.058840382271696516, 0.05633885698774619, 0.053823731901120324, 0.0513014138522645, 0.04877832800443524, 0.046260901476722426, 0.043755546972089554, 0.04126864644213668, 0.03880653483019694, 0.036375483934178464, 0.03398168643025822, 0.031631240098124465, 0.029330132287951585, 0.027084224668674595, 0.02489923829641465, 0.02278073904109105, 0.020734123408342887, 0.01876460479287654, 0.016877200198256233, 0.015076717456966437, 0.013367742983301185, 0.011754630090277229, 0.010241487900331987, 0.008832170878054161, 0.007530269011610562, 0.0063390986678803106, 0.005261694144591349, 0.004300799940978644, 0.003458863766653319, 0.0027380303064912562, 0.0021401357574242544, 0.0016667031510500465, 0.0013189384739761825, 0.001097727595780478, 0.0010036340124134782, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire5.expand_1x1.0.weight
[0.1, 0.10093715739377138, 0.10074878754281179, 0.100435363953216, 0.099997674479193, 0.0994368193426334, 0.09875420836747714, 0.097951557435833, 0.09703088417475841, 0.09599450288454181, 0.09484501872123619, 0.09358532114806713, 0.09221857667217695, 0.0907482208849622, 0.08917794982601297, 0.08751171069236244, 0.08575369191640095, 0.08390831263739572, 0.08198021159308166, 0.07997423545924667, 0.07789542666662203, 0.07574901072570292, 0.0735403830913605, 0.07127509560026393, 0.06895884251520516, 0.0665974462114062, 0.0641968425407898, 0.061763065911003334, 0.059302234116702546, 0.05682053296122519, 0.05432420070731092, 0.05181951239595367, 0.04931276407280449, 0.0468102569617748, 0.044318281625623124, 0.041843102153340736, 0.03939094041408447, 0.03696796041723788, 0.03458025281791468, 0.03223381960685296, 0.029934559023185727, 0.027688250728012034, 0.025500541276038326, 0.02337692992180996, 0.021322754796211596, 0.01934317948798489, 0.017443180063993674, 0.015627532560863383, 0.013900800979437623, 0.01226732581222973, 0.010731213132708379, 0.009296324273843276, 0.007966266121855975, 0.006744382049574759, 0.005633743512184075, 0.004637142326494619, 0.0037570836531415847, 0.002995779699351652, 0.002355144158108357, 0.0018367873976938833, 0.0014420124136994609, 0.0011718115536798015, 0.0010268640226848693, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire5.expand_1x1.0.bias
[0.1, 0.10093798499495639, 0.1007520938142596, 0.10044278757960995, 0.10001083355611551, 0.09945730324901414, 0.09878356974569726, 0.09799130430962916, 0.09708247223461033, 0.09605932796966948, 0.0949244095266766, 0.09368053218455036, 0.09233078150567656, 0.09087850568186151, 0.0893273072288068, 0.087681034049708, 0.0859437698901453, 0.0841198242079434, 0.08221372148312953, 0.08023018999450743, 0.07817415009068791, 0.07605070198467122, 0.07386511310225753, 0.07162280501566945, 0.06932933999479898, 0.06699040720943956, 0.06461180861673045, 0.06219944456882057, 0.05975929917645384, 0.057297425464782864, 0.054819930358233494, 0.05233295953166681, 0.049842682165416985, 0.047355275642021084, 0.0448769102226029, 0.04241373374092183, 0.03997185635305526, 0.037557335380544156, 0.03517616028460007, 0.032834237808646353, 0.030537377326049355, 0.028291276429385594, 0.02610150679699242, 0.023973500371861772, 0.02191253588716115, 0.019923725771807028, 0.018012003468572842, 0.01618211119618963, 0.014438588185797498, 0.012785759420927717, 0.011227724908947866, 0.009768349510582728, 0.00841125335273989, 0.007159802848422275, 0.006017102346003378, 0.004985986428580013, 0.004069012882504996, 0.0032684563525416867, 0.002586302699379827, 0.002024244073509073, 0.0015836747176701518, 0.0012656875082960365, 0.001071071244522458, 0.0010003086914925899, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire5.expand_1x1.1.weight
[0.1, 0.10093879991032112, 0.1007553494593235, 0.10045009773436926, 0.10002379199277608, 0.09947747583252861, 0.09881248663754685, 0.09803045230376553, 0.09713328725403904, 0.09612318775162737, 0.09500262652373581, 0.09377434670826988, 0.09244135513862384, 0.09100691498294185, 0.08947453775587058, 0.0878479747223588, 0.08613120771454724, 0.08432843938422935, 0.08244408291474457, 0.08048275121748966, 0.07844924563949512, 0.07634854420971038, 0.07418578945277109, 0.07196627580008036, 0.06969543662902175, 0.06737883096203183, 0.06502212985809347, 0.06263110252996293, 0.06021160222111645, 0.05776955187698921, 0.055310929645583685, 0.05284175424294179, 0.050368070219306504, 0.04789593316204121, 0.04543139487152999, 0.04298048854634873, 0.04054921401397324, 0.03814352304318013, 0.03576930477409552, 0.03343237130155879, 0.031138443447093673, 0.028893136754316564, 0.02670194774206565, 0.024570240448903054, 0.02250323330192923, 0.020505986342054607, 0.018583388837001415, 0.016740147312358677, 0.014980774029990714, 0.013309575942003927, 0.011730644147312508, 0.010247843876613798, 0.008864805030289451, 0.007584913292396472, 0.0064113018425003936, 0.005346843685640467, 0.004394144619203093, 0.003555536853920365, 0.0028330733046099277, 0.0022285225646320786, 0.0017433645763668894, 0.0013787870083099888, 0.0011356823476557634, 0.0010146457154855562, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire5.expand_1x1.1.bias
[0.1, 0.10093960236156418, 0.10075855536124588, 0.10045729639149566, 0.1000365532655268, 0.0994973424589871, 0.09884096665424998, 0.09806901159325672, 0.09718334224651382, 0.09618609830750041, 0.09507968902337093, 0.09386678737444155, 0.09255032361652232, 0.0911334782016958, 0.08961967409464539, 0.08801256850309586, 0.08631604404234508, 0.08453419935523218, 0.0826713392102036, 0.08073196410139918, 0.07872075937588344, 0.07664258391428966, 0.07450245839222326, 0.0723055531507838, 0.07005717570550929, 0.06776275792392002, 0.06542784290263969, 0.06305807157579768, 0.06065916908706494, 0.05823693095824774, 0.055797209087854516, 0.053345897613461694, 0.05088891867203428, 0.04843220809260219, 0.045981701055858165, 0.04354331775532179, 0.0411229490947112, 0.03872644245607621, 0.036359587573075586, 0.03402810254352747, 0.03173762001502518, 0.029493673576992743, 0.02730168439205546, 0.025166948099023246, 0.02309462201912741, 0.021089712696419707, 0.019157063802434936, 0.017301344434337975, 0.015527037834826136, 0.013838430561038294, 0.012239602128637728, 0.010734415156087695, 0.009326506032930008, 0.008019276134611574, 0.006815883605082395, 0.005719235727018267, 0.004731981898100434, 0.0038565072303210096, 0.003094926787777779, 0.002449080476879089, 0.001920528601303755, 0.0015105480924548047, 0.0012201294245138097, 0.001049974221548821, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire5.expand_3x3.0.weight
[0.1, 0.10094039256603643, 0.10076171238599303, 0.10046438548655115, 0.1000491207834517, 0.09951690839122941, 0.09886901726248525, 0.09810699216232606, 0.09723264998518533, 0.0962480754228065, 0.09515561599371787, 0.0939578764460506, 0.09265771254704439, 0.09125822427404928, 0.08976274842325795, 0.08817485065379116, 0.0864983169861063, 0.08473714477499873, 0.08289553317871937, 0.08097787314693264, 0.07898873695138693, 0.07693286728425909, 0.07481516595016593, 0.07264068217880452, 0.07041460058608713, 0.06814222881247514, 0.06582898486798604, 0.06348038421404632, 0.061102026612991446, 0.058699582776567276, 0.05627878084526708, 0.053845392730741154, 0.051405220353843296, 0.04896408181112617, 0.04652779750276897, 0.044102176255012795, 0.0416930014701915, 0.03930601733738077, 0.036946915136543385, 0.034621319668825326, 0.032334775845357294, 0.030092735466537818, 0.027900544223319806, 0.02576342895149394, 0.023686485169357716, 0.021674664928484695, 0.019732765006561105, 0.017865415470441317, 0.016077068636691783, 0.01437198845594436, 0.01275424034637011, 0.011227681500513502, 0.009795951688598342, 0.00846246458023337, 0.007230399605208665, 0.006102694372789741, 0.005082037667583494, 0.004170863038676109, 0.003371342997328452, 0.0026853838370632425, 0.0021146210884943387, 0.001660415619735516, 0.0013238503916861812, 0.0011057278759305392, 0.0010065681414067541, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire5.expand_3x3.0.bias
[0.1, 0.10094117073683527, 0.10076482138262921, 0.10047136691748454, 0.10006149788979954, 0.09953617879128991, 0.09889664578737532, 0.09814440380827139, 0.09728122300763216, 0.09630913459707685, 0.0952304260664024, 0.09404763580073, 0.09276354710725193, 0.09138118166563523, 0.08990379241749409, 0.08833485591166355, 0.0866780641232872, 0.08493731576597013, 0.08311670711744101, 0.08122052238031204, 0.07925322360061955, 0.07721944016786893, 0.0751239579212916, 0.0729717078879492, 0.07076775467918603, 0.06851728457273493, 0.06622559330852139, 0.06389807362688442, 0.061540202578538844, 0.05915752863614117, 0.056755658637787136, 0.05434024459316553, 0.051916970383415695, 0.04949153838598584, 0.047069656055966594, 0.044657022495475804, 0.042259315042699475, 0.03988217591214688, 0.03753119891755762, 0.03521191630870407, 0.03292978575306421, 0.030690177492999418, 0.02849836170865835, 0.02635949611634446, 0.02427861383152992, 0.02226061152507662, 0.020310237900534746, 0.01843208251963337, 0.016630565002259234, 0.014909924626337313, 0.013274210352087083, 0.011727271294128667, 0.01027274766385965, 0.008914062203417034, 0.007654412131381244, 0.006496761619175572, 0.005443834815865472, 0.0044981094377711354, 0.003661810937978526, 0.0029369072694688187, 0.002325104254189341, 0.0018278415689637444, 0.0014462893576868631, 0.0011813454777766343, 0.0010336333873624585, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire5.expand_3x3.1.weight
[0.1, 0.10094193708289698, 0.1007678831836816, 0.10047824254543872, 0.10007368786338308, 0.09955515872251337, 0.09892385941541049, 0.09818125614524784, 0.09732907362051005, 0.09636929104932877, 0.09530413754273866, 0.09413608693752995, 0.09286785205072112, 0.0915023783789962, 0.09004283725773946, 0.08849261849555619, 0.08685532250138561, 0.08513475192249102, 0.08333490281274811, 0.08145995535174316, 0.07951426413623619, 0.07750234806653739, 0.07542887985128566, 0.07329867515500495, 0.07111668141364291, 0.06888796634406856, 0.06661770617421513, 0.06431117362120435, 0.0619737256453731, 0.059610791008643506, 0.05722785766613288, 0.0548304600202863, 0.05242416606713475, 0.050014564464531334, 0.04760725155240016, 0.045207818355143564, 0.0428218375963946, 0.040454850756273475, 0.03811235520120745, 0.03579979141620564, 0.03352253036924182, 0.03128586103709165, 0.029094978121595907, 0.02695496998487881, 0.024870806831542025, 0.022847329165281607, 0.02088923654673739, 0.019001076678684982, 0.01718723484392026, 0.0154519237203668, 0.013799173597061183, 0.012232823013739496, 0.010756509845764678, 0.009373662855100332, 0.008087493726953865, 0.00690098961058399, 0.005816906181596775, 0.004837761241843008, 0.003965828871781435, 0.003203134148888969, 0.0025514484443844012, 0.002012285309189248, 0.0015868969586804661, 0.0012762713643993497, 0.0010811299594711212, 0.0010019259630644974, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire5.expand_3x3.1.bias
[0.1, 0.10094269180908678, 0.10077089860549697, 0.1004850141955389, 0.10008569391994637, 0.09957385315162298, 0.09895066519730744, 0.09821755860797017, 0.09737621390410643, 0.09642855972343274, 0.09537676839981735, 0.09422325098357923, 0.0929706517145708, 0.09162184196071398, 0.09017991363588389, 0.08864817211222946, 0.08703012864317738, 0.08532949231448886, 0.08355016154181982, 0.08169621513427504, 0.0797719029444411, 0.0777816361263321, 0.07572997702357925, 0.07362162871104454, 0.0714614242138322, 0.06925431542841176, 0.06700536177124886, 0.0647197185809651, 0.06240262530061278, 0.06005939346715488, 0.057695394535682065, 0.05531604756627761, 0.052926806801756425, 0.0505331491647533, 0.04814056170282196, 0.0457545290103242, 0.04338052065594267, 0.04102397864463749, 0.03869030494278781, 0.036384849095115, 0.03411289596177352, 0.03187965360371978, 0.02969024134413023, 0.027549678033235315, 0.025462870543470312, 0.02343460252131608, 0.021469523421614175, 0.019572137849492743, 0.017746795234335932, 0.015997679859466624, 0.01432880127039806, 0.012743985083642016, 0.011246864217142171, 0.009840870562436072, 0.008529227117635157, 0.007314940599257202, 0.006200794549846982, 0.0051893429571846774, 0.004282904399709141, 0.0034835567315765195, 0.002793132319537649, 0.002213213842553168, 0.0017451306637748347, 0.0013899557832095335, 0.0011485033780517897, 0.0010213269363228575, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire6.squeeze.0.weight
[0.1, 0.10094343511628673, 0.10077386844858967, 0.10049168365766242, 0.10009751921350038, 0.09959226695074144, 0.0989770700508052, 0.0982533204553358, 0.09742265571680153, 0.09648695529337598, 0.09544833629648475, 0.09430914870063918, 0.09307197002639467, 0.09173959950846491, 0.0903150517621863, 0.08880154996266326, 0.08720251855202744, 0.0855215754913107, 0.08376252407446334, 0.08192934432303899, 0.08002618398101617, 0.07805734913013232, 0.07602729444696303, 0.07394061312379173, 0.07180202647607407, 0.06961637326001165, 0.06738859872440459, 0.06512374342155476, 0.06282693180253546, 0.06050336062263234, 0.058158287183189064, 0.05579701743646163, 0.053424893980395655, 0.05104728397048894, 0.04866956697609053, 0.0462971228086121, 0.04393531934919161, 0.0415895004033505, 0.039264973610124126, 0.03696699843302236, 0.03470077425999198, 0.032471428639305605, 0.030284005677994857, 0.02814345462907728, 0.026054618693399447, 0.024022224061433273, 0.022050869219819413, 0.02014501454685279, 0.01830897222045148, 0.016546896461442872, 0.014862774134243056, 0.013260415726195941, 0.011743446725982216, 0.010315299420605665, 0.008979205129516447, 0.00773818689344275, 0.006595052634472981, 0.005552388802864227, 0.004612554524951961, 0.0037776762654017854, 0.003049643015880348, 0.0024301020210315875, 0.0019204550514286757, 0.001521855231934426, 0.0012352044326463631, 0.0010611512283295924, 0.0010000894309546084, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire6.squeeze.0.bias
[0.1, 0.10094416720148147, 0.10077679349798152, 0.1004982526871907, 0.10010916683762779, 0.09961040489936654, 0.09900308076339928, 0.09828855077397076, 0.0974684106994384, 0.09654449216842373, 0.09551885857921433, 0.0943938004915518, 0.09317183051109734, 0.09185567767799957, 0.09044828137209644, 0.0889527847483633, 0.08737252771726725, 0.0857110394857053, 0.0839720306751844, 0.08215938503484613, 0.08027715076784338, 0.07832953149043993, 0.07632087684402403, 0.07425567278100233, 0.07213853154626886, 0.06997418137662337, 0.06776745594114367, 0.06552328354609478, 0.06324667612848361, 0.06094271806284033, 0.05861655480622389, 0.05627338140681139, 0.053918430901734975, 0.05155696263007749, 0.049194250487127694, 0.04683557114612701, 0.044486192273812036, 0.042151360766071636, 0.0398362910299917, 0.03754615333845742, 0.035286062283321276, 0.03306106535292385, 0.030876131659477904, 0.028736140841490756, 0.02664587216600929, 0.024609993855025793, 0.022633052659882094, 0.020719463706955456, 0.01887350063730413, 0.017099286062293727, 0.01540078235652003, 0.013781782808590558, 0.01224590314952776, 0.010796573477713761, 0.009437030598410695, 0.00817031079496483, 0.006999243047838821, 0.005926442716615714, 0.004954305699085253, 0.004085003080456744, 0.0033204762846484872, 0.002662432738482561, 0.002112342058468163, 0.001671432768689445, 0.0013406895571280654, 0.0011208510765477178, 0.0010124082948521121, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire6.squeeze.1.weight
[0.1, 0.1009448882578422, 0.1007796745235337, 0.10050472300574359, 0.100120639826758, 0.09962827168630206, 0.0990287039950159, 0.09832325848169986, 0.09751349027960338, 0.09660118449818089, 0.09558835228787227, 0.09447722640658238, 0.09327025629763425, 0.09197010269004531, 0.09057963173303106, 0.08910190867766593, 0.08754019111963025, 0.08589792181793927, 0.08417872110548535, 0.08238637890812378, 0.0805248463898961, 0.07859822724280889, 0.07661076864036893, 0.07456685187481814, 0.07247098269870747, 0.07032778139210216, 0.06814197257731429, 0.06591837480361615, 0.06366188992489435, 0.06137749229366173, 0.059070217795247786, 0.05674515274634228, 0.054407422682364204, 0.05206218105837443, 0.04971459788844007, 0.04736984834849539, 0.04503310136782315, 0.04270950823430686, 0.040404191238572654, 0.038122232382054984, 0.03586866217387844, 0.03364844854125295, 0.03146648587782873, 0.029327584254154028, 0.027236458814020193, 0.025197719380070274, 0.02321586029158475, 0.021295250496846663, 0.019440123921927798, 0.017654570137126825, 0.015942525341635615, 0.014307763686307439, 0.012753888953655795, 0.011284326613425173, 0.009902316271246752, 0.008610904527026009, 0.007412938258805645, 0.0063110583469091815, 0.005307693852200339, 0.004405056661292033, 0.0036051366105093567, 0.0029096970993557287, 0.0023202712031521622, 0.0018381582934191556, 0.0014644211734516012, 0.0011998837354011186, 0.0010451291440307755, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire6.squeeze.1.bias
[0.1, 0.10094559847480829, 0.10078251228027087, 0.10051109630189657, 0.1001319411574128, 0.09964587191154528, 0.09905394628062704, 0.09835745233094291, 0.0975579056758189, 0.09665704617755502, 0.09565683416137882, 0.09455944614965815, 0.09336727012565556, 0.09208290033713117, 0.0907091316511012, 0.0892489534720369, 0.08770554323673796, 0.08608225950003626, 0.08438263462637563, 0.0826103671031713, 0.08076931349267565, 0.07886348003986354, 0.07689701395459872, 0.07487419438705226, 0.07279942311601062, 0.07067721497033656, 0.06851218800442604, 0.06630905344904015, 0.06407260545937947, 0.06180771068270999, 0.05951929766824171, 0.05721234614230485, 0.05489187617216158, 0.05256293724203338, 0.050230597265115376, 0.04789993155548795, 0.04557601178392372, 0.04326389494162255, 0.04096861233589015, 0.03869515864170642, 0.03644848103300801, 0.034233468417336044, 0.03205494079727493, 0.02991763878183286, 0.027826213270587232, 0.02578521533304349, 0.023799086305230283, 0.021872148125081217, 0.020008593927634318, 0.018212478920514318, 0.016487711559553486, 0.014838045043753339, 0.013267069148094536, 0.011778202411967632, 0.010374684700222712, 0.009059570153025876, 0.007835720539863904, 0.006705799032159254, 0.005672264408046539, 0.004737365701921402, 0.003903137310404347, 0.003171394565369639, 0.0025437297836723985, 0.002021508802169957, 0.0016058680055775591, 0.0012977118536258649, 0.0010977109129013942, 0.0010063003976527754, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire6.expand_1x1.0.weight
[0.1, 0.10094629803816738, 0.10078530750869763, 0.10051737423188158, 0.1001430737494234, 0.09966321008813202, 0.09907881403280837, 0.0983911409120388, 0.09760166790165066, 0.09671209085162287, 0.09572432064326693, 0.09464047908450396, 0.09346289435205483, 0.09219409599033379, 0.09083680947778866, 0.08939395037235909, 0.08786861804862951, 0.08626408904012915, 0.08458381000108095, 0.08283139030271783, 0.08101059428007007, 0.07912533314587818, 0.0771796565890011, 0.07517774407536663, 0.07312389587015078, 0.07102252380047061, 0.06887814177843339, 0.06669535610489924, 0.06447885557478528, 0.06223340140516631, 0.059963817007806924, 0.057674977628094405, 0.055371799872629184, 0.05305923114796797, 0.05074223903320624, 0.04842580060922855, 0.04611489176754816, 0.04381447652170167, 0.04152949634415835, 0.0392648595516495, 0.03702543076171897, 0.034816020443142914, 0.032641374582665354, 0.03050616449024626, 0.028414976764721125, 0.026372303441426784, 0.024382532342957036, 0.022449937653775277, 0.02057867073893099, 0.018772751226601738, 0.017036058373616474, 0.015372322732507465, 0.013785118137990621, 0.012277854030088187, 0.010853768130383912, 0.009515919487143077, 0.008267181904236798, 0.007110237767985711, 0.0060475722851837, 0.005081468144678707, 0.004214000613977941, 0.003447033081410366, 0.0027822130534224266, 0.0022209686156048672, 0.00176450536505282, 0.0014138038206486562, 0.001169617316830456, 0.0010324703853705588, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire6.expand_1x1.0.bias
[0.1, 0.10094698713013323, 0.10078806093510771, 0.10052355842027129, 0.1001540404671199, 0.09968029064394011, 0.09910331354424091, 0.09842433265649844, 0.09764478776973043, 0.09676633192040239, 0.09579082788713929, 0.09472034424067591, 0.09355715095742205, 0.09230371460594389, 0.09096269311656896, 0.08953693014520542, 0.08802944904332771, 0.08644344644691511, 0.08478228549793769, 0.08304948871276406, 0.08124873051261335, 0.07938382943189061, 0.07745874002092812, 0.07547754446030286, 0.07344444390451232, 0.07136374957336407, 0.06923987360997051, 0.0670773197247341, 0.06488067364516269, 0.06265459339176671, 0.06040379940065763, 0.05813306451379331, 0.055847203858096155, 0.05355106463490511, 0.05124951584141359, 0.04894743794588885, 0.04664971253856683, 0.04436121198016785, 0.042086789069983616, 0.03983126675544452, 0.03759942790498823, 0.035396005165916476, 0.03322567092874638, 0.03109302741933724, 0.02900259693980252, 0.026958812278901297, 0.02496600731224414, 0.023028407812245733, 0.021150122487312007, 0.01933513426926305, 0.017587291867467415, 0.015910301607596867, 0.014307719572307948, 0.012782944060516221, 0.011339208381252956, 0.00997957399738561, 0.008706924033740564, 0.00752395716339414, 0.006433181885096495, 0.005436911203962957, 0.004537257726712356, 0.0037361291818532533, 0.003035224374317496, 0.0024360295831190974, 0.0019398154096776856, 0.001547634083489379, 0.0012603172308585423, 0.001078474111421939, 0.0010024903262046516, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire6.expand_1x1.1.weight
[0.1, 0.10094766592942202, 0.10079077327188578, 0.1005296504606478, 0.10016484412049338, 0.09969711792345266, 0.09912745099015792, 0.09845703584018888, 0.09768727589569652, 0.09681978254353138, 0.0958563717620262, 0.09479906031949435, 0.0936500615524021, 0.0924117807320523, 0.09108681002947883, 0.0896779230890922, 0.08818806922243538, 0.08662036723420473, 0.08497809889346011, 0.08326470206369163, 0.08148376350612402, 0.0796390113713239, 0.07773430739482817, 0.07577363881313023, 0.0737611100169475, 0.07170093395924236, 0.0695974233359831, 0.06745498155810646, 0.06527809353358097, 0.06307131627886724, 0.06083926937942924, 0.058586625319265666, 0.05631809969970582, 0.054038441367944945, 0.05175242247598419, 0.049464828490784936, 0.04718044817655018, 0.04490406357010361, 0.042640439970351496, 0.04039431596278308, 0.03817039349989193, 0.03597332805828336, 0.03380771889307278, 0.03167809940997608, 0.029588927675246547, 0.027544577083324764, 0.0255493272017373, 0.0236073548124091, 0.02172272516814351, 0.019899383482573203, 0.018141146671396553, 0.01645169536218834, 0.01483456618951074, 0.013293144391454004, 0.01183065672310495, 0.010450164701777731, 0.00915455819814746, 0.007946549386702195, 0.006828667068177812, 0.005803251375860563, 0.004872448876838952, 0.00403820807846012, 0.003302275349396915, 0.002666191263864675, 0.0021312873766404384, 0.0016986834356356555, 0.0013692850378575641, 0.0011437817336660651, 0.0010226455832946448, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire6.expand_1x1.1.bias
[0.1, 0.10094833461132674, 0.10079344521780242, 0.10053565191625578, 0.10017548746633165, 0.09971369618948173, 0.09915123243073816, 0.09848925858644937, 0.09772914270205363, 0.0968724556448551, 0.09592096785764502, 0.09487664569987718, 0.09374164738395879, 0.09251831851505532, 0.09120918724362621, 0.08981695904070999, 0.08834451110675567, 0.08679488642555562, 0.0851712874755679, 0.08347706961162454, 0.08171573413070307, 0.07989092103609169, 0.078006401514902, 0.07606607014447495, 0.07407393684378687, 0.07203411858648855, 0.0699508308927034, 0.06782837911716814, 0.06567114955171971, 0.06348360036051634, 0.06127025236672628, 0.059035679709724224, 0.0567845003921039, 0.05452136673604205, 0.052250955768737034, 0.04997795955679183, 0.047707075509516146, 0.04544299667118737, 0.043190402022332264, 0.04095394681007307, 0.038738252927521484, 0.03654789936210241, 0.0343874127325474, 0.032261257934114065, 0.030173828911364012, 0.02812943957756875, 0.026132314899509512, 0.0241865821660951, 0.0222962624588426, 0.02046526234184767, 0.018697365788418515, 0.016996226361057822, 0.015365359660953655, 0.013808136062583454, 0.012327773748445636, 0.010927332058313682, 0.00960970516675701, 0.008377616101994756, 0.00723361111844335, 0.006180054434587578, 0.005219123347049864, 0.00435280373095524, 0.0035828859358909442, 0.0029109610859421034, 0.0023384177914500086, 0.001866439279288339, 0.0014960009475881377, 0.0012278683499648826, 0.0010625956134134576, 0.001000524293140708, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire6.expand_3x3.0.weight
[0.1, 0.10094899334778984, 0.10079607745830216, 0.10054156432064064, 0.1001859732093291, 0.09973002962485332, 0.09917466381344689, 0.09852100886914153, 0.09777039842195359, 0.09692436391692408, 0.09598463148956322, 0.09495311844407478, 0.09383192934154516, 0.092623351706079, 0.09132985135764107, 0.08995406738112771, 0.08849880674193111, 0.08696703855898325, 0.0853618880469631, 0.08368663014002711, 0.08194468281007215, 0.0801396000931633, 0.07827506483835465, 0.07635488119369721, 0.0743829668447647, 0.0723633450215325, 0.07030013628991791, 0.0681975501447294, 0.06605987642117693, 0.06389147654246674, 0.06169677462133747, 0.05948024843369296, 0.057246420282747915, 0.054999847772326055, 0.052745114508135515, 0.05048682074599367, 0.04822957400608102, 0.04597797967237422, 0.04373663159643716, 0.04151010272474149, 0.03930293576863898, 0.03711963393602165, 0.03496465174357929, 0.032842385928400324, 0.030757166477457992, 0.02871324779328495, 0.02671480001386002, 0.024765900504416946, 0.022870525538534598, 0.02103254218548068, 0.019255700420361472, 0.017543625473174812, 0.015899810432376243, 0.014327609118049162, 0.0128302292392193, 0.011410725849274883, 0.010071995112844827, 0.008816768396852182, 0.007647606697798809, 0.00656689541665118, 0.005576839491987572, 0.004679458901336708, 0.0038765845398860735, 0.003169854484968592, 0.0025607106539489825, 0.0020503958623286234, 0.0016399512880712667, 0.0013302143473229492, 0.0011218169858602015, 0.0010151843897525372, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire6.expand_3x3.0.bias
[0.1, 0.10094964230747422, 0.10079867066578471, 0.10054738917827198, 0.10019630400317146, 0.09974612233405505, 0.09919775097532574, 0.09855229451563441, 0.09781105310289853, 0.09697551982540409, 0.0960473777042664, 0.09502849630330773, 0.09392092796318047, 0.09272690366732156, 0.09144882854806535, 0.09008927704196709, 0.08865098770409544, 0.08713685769173996, 0.08554993692864495, 0.0838934219615244, 0.08217064952123349, 0.08038508980156578, 0.07854033946921529, 0.07664011441898294, 0.07468824228882108, 0.07268865474979296, 0.07064537958647732, 0.06856253258377097, 0.06644430923643146, 0.06429497629805994, 0.062118863186546205, 0.059920353263289074, 0.05770387500375779, 0.05547389307717966, 0.053234899353322596, 0.05099140385448711, 0.04874792567093372, 0.04650898385804467, 0.044279088333555816, 0.04206273079319463, 0.0398643756630229, 0.03768845110670895, 0.0355393401058434, 0.033421371631265684, 0.03133881192318469, 0.029295855897658235, 0.027296618696741437, 0.02534512739932428, 0.02344531290935565, 0.021601002037793235, 0.019815909794228665, 0.018093631903715265, 0.016437637563871187, 0.014851262456848046, 0.01333770203024066, 0.011900005060472278, 0.010541067511620893, 0.009263626702056382, 0.008070255790639018, 0.006963358593585905, 0.005945164742445291, 0.005017725192932664, 0.00418290809367488, 0.003442395023183891, 0.0027976776026403354, 0.0022500544913093825, 0.0018006287706414429, 0.0014503057223267215, 0.0011997910047792707, 0.0010495892317238732, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire6.expand_3x3.1.weight
[0.1, 0.10095028165583253, 0.10080122549987998, 0.10055312796515284, 0.10020648245159586, 0.0997619783448469, 0.0992204996452325, 0.09858312320972655, 0.09785111661036841, 0.09702593561339969, 0.09610922128413268, 0.09510279672330846, 0.09400866344143471, 0.09282899737831439, 0.09156614457568067, 0.0902226165115445, 0.08880108510553353, 0.08730437740515534, 0.08573546996355254, 0.08409748291993108, 0.08239367379443399, 0.08062743100980119, 0.07880226715269865, 0.07692181198811876, 0.07498980524074408, 0.07301008915763059, 0.07098660086700127, 0.06892336454834623, 0.06682448342940103, 0.06469413162591921, 0.0625365458404673, 0.060356016936751404, 0.05815688140623157, 0.055943512743994894, 0.05372031275103814, 0.05149170278025742, 0.04926211494355442, 0.04703598329754582, 0.04481773502540514, 0.04261178163237411, 0.04042251017245323, 0.038254274523719316, 0.03611138672962113, 0.03399810842347308, 0.031918642353201035, 0.029877124023195624, 0.027877613469895077, 0.02592408718745361, 0.02402043021955327, 0.022170428433086295, 0.0203777609890739, 0.018645993025794477, 0.016978568568672636, 0.01537880368102974, 0.013849879869316573, 0.012394837755944209, 0.01101657103229551, 0.009717820703943274, 0.008501169639520023, 0.007369037434079867, 0.006323675597168143, 0.005367163075168312, 0.004501402116831159, 0.0037281144902084166, 0.003048838058514524, 0.002464923721726108, 0.0019775327300016014, 0.0015876343742638292, 0.0012960040585384294, 0.0011032217578816775, 0.0010096708649645172, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire6.expand_3x3.1.bias
[0.1, 0.10095091155517498, 0.1008037426077165, 0.10055878212941487, 0.100216511109427, 0.09977760160983612, 0.09924291544603236, 0.09861350249450579, 0.09789059863137406, 0.09707562330569319, 0.0961701767523155, 0.0951760368497681, 0.09409515562932115, 0.09292965544210077, 0.0916818247917723, 0.09035411384097694, 0.08894912960034473, 0.08746963080953077, 0.08591852252032547, 0.08429885039247575, 0.08261379471341693, 0.08086666415365812, 0.07906088927008273, 0.0772000157699203, 0.0752876975486164, 0.07332768951527083, 0.07132384021973161, 0.06928008429582204, 0.06720043473553837, 0.06508897500938841, 0.0629498510483429, 0.060787263103143196, 0.058605457496950446, 0.05640871828752935, 0.05420135885533901, 0.05198771343404726, 0.04977212860009908, 0.04755895473804956, 0.04535253749841931, 0.04315720926484548, 0.040977280647282704, 0.038817032017957664, 0.03668070510669624, 0.034572494672126995, 0.03249654026511375, 0.03045691810059121, 0.02845763305376288, 0.026502610796377203, 0.024595690088522693, 0.02274061524107749, 0.020941028763613374, 0.01920046421219068, 0.017522339251087204, 0.01590994894208551, 0.014366459274494377, 0.012894900948609223, 0.011498163424817527, 0.01017898925003416, 0.008939968672606852, 0.007783534556265703, 0.006711957603103269, 0.005727341894965165, 0.004831620762005927, 0.004026552986522097, 0.0033137193495167854, 0.002694519526776356, 0.002170169340554178, 0.0017416983722576764, 0.0014099479408262996, 0.001175569450770008, 0.0010390231131118968, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire7.squeeze.0.weight
[0.1, 0.10095153216473539, 0.1008062226241837, 0.10056435309189993, 0.10022639248358994, 0.09979299600801726, 0.09926500389674123, 0.09864343977514863, 0.09792950867793755, 0.09712459471290039, 0.09623025837753552, 0.09524823353368989, 0.09418042404609779, 0.09302890009133279, 0.09179589414432857, 0.09048379665024991, 0.08909515139010463, 0.08763265054908105, 0.08609912949717272, 0.08449756129220834, 0.08283105091594485, 0.08110282925439762, 0.07931624683407834, 0.07747476732628439, 0.07558196083203282, 0.07364149696065773, 0.0716571377154893, 0.06963273020040754, 0.06757219916141044, 0.06547953937765623, 0.06335880791673146, 0.06121411626915967, 0.059049622377399594, 0.05686952257478631, 0.054678043450043526, 0.052479433653139465, 0.050277955658371974, 0.04807787750065264, 0.04588346450101016, 0.04369897099735531, 0.04152863209653895, 0.039376655463693636, 0.03724721316477667, 0.03514443357813011, 0.033072393390738045, 0.031035109694699026, 0.029036532199235777, 0.027080535573340815, 0.02517091193390384, 0.023311363493883776, 0.021505495384778934, 0.019756808667310208, 0.018068693543867625, 0.016444422785879632, 0.014887145388847178, 0.013399880467343868, 0.01198551140181811, 0.01064678024854479, 0.009386282423563892, 0.00820646167091274, 0.007109605324906564, 0.006097839875652866, 0.005173126846396491, 0.004337258990688186, 0.0035918568167492885, 0.0029383654457707012, 0.002378051810237041, 0.0019120021977076453, 0.001541120144816326, 0.0012661246855727717, 0.001087548957361666, 0.0010057391673420893, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire7.squeeze.0.bias
[0.1, 0.10095214364073586, 0.10080866617218831, 0.10056984224672863, 0.10023612903409987, 0.09980816534627786, 0.09928677041462246, 0.09867294232166035, 0.09796785609050129, 0.09717286143554489, 0.09628948017878397, 0.09531940333665018, 0.09426448788297832, 0.0931267531942862, 0.09190837718417418, 0.09061169213424461, 0.08923918022952156, 0.0877934688069173, 0.08627732532584112, 0.0846936520705781, 0.08304548059457864, 0.08133596591729414, 0.07956838048466713, 0.07774610790483735, 0.07587263647105512, 0.0739515524842007, 0.0719865333876921, 0.06998134072792313, 0.0679398129537065, 0.06586585806850669, 0.06376344614952703, 0.06163660174797217, 0.059489396185033266, 0.057325939758343714, 0.055150373873823814, 0.05296686311797647, 0.05077958728580923, 0.048592733379643455, 0.04641048759412683, 0.0442370273027919, 0.04207651306150062, 0.03993308064408205, 0.03781083312540923, 0.03571383302707023, 0.03364609454066836, 0.03161157584363837, 0.029614171522288114, 0.027657705116569453, 0.025745921800850453, 0.023882481214698784, 0.022070950457400748, 0.020314797259625962, 0.018617383345308613, 0.01698195799645288, 0.015411651833180523, 0.013909470820927687, 0.012478290516262508, 0.01112085056233823, 0.00983974944451942, 0.008637439516220018, 0.007516222304475056, 0.006478244104232444, 0.005525491869798576, 0.004659789411302255, 0.0038827939034582976, 0.0031959927133134772, 0.0026007005530477457, 0.0020980569632806636, 0.0016890241317007717, 0.0013743850511936265, 0.0011547420209942474, 0.0010305154937331465, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire7.squeeze.1.weight
[0.1, 0.10095274613644999, 0.10081107386290472, 0.10057525096185554, 0.10024572317502996, 0.09982311336087098, 0.09930822031723832, 0.09870201727155703, 0.09800565004126732, 0.09722043486805237, 0.09634785592993833, 0.0953895625359683, 0.09434736600875347, 0.09322323626079342, 0.09201929807103704, 0.09073782706872198, 0.08938124543208376, 0.08795211731006439, 0.08645314397567487, 0.0848871587201715, 0.0832571214976977, 0.08156611333051314, 0.0798173304853856, 0.07801407843215276, 0.07615976559587341, 0.07425789691437733, 0.07231206721339116, 0.07032595441176218, 0.06830331256962328, 0.06624796479263924, 0.06416379600574613, 0.06205474561004279, 0.05992480003671396, 0.057777985212059284, 0.0556183589478704, 0.05345000327153964, 0.05127701671039724, 0.04910350654486147, 0.04693358104504382, 0.04477134170548355, 0.04262087549268924, 0.04048624712014041, 0.03837149136535091, 0.03628060544351591, 0.034217541452157364, 0.03218619890104893, 0.030190417341540012, 0.02823396910921011, 0.02632055219357179, 0.024453783248298874, 0.022637190755192105, 0.02087420835480332, 0.019168168356324077, 0.017522295439006363, 0.015939700557020375, 0.014423375059270445, 0.012976185035283305, 0.011600865897855937, 0.010300017212702631, 0.009076097784874105, 0.007931421011235913, 0.006868150507790854, 0.005888296020110411, 0.004993709624604952, 0.004186082227813175, 0.0034669403703273586, 0.0028376433413957675, 0.0022993806096559145, 0.001853169574854984, 0.0014998536448070968, 0.0012401006412221963, 0.0010744015374197992, 0.001003069530313571, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire7.squeeze.1.bias
[0.1, 0.10095333980226438, 0.10081344629601958, 0.1005805805796122, 0.1002551772754571, 0.09983784371885496, 0.09932935882445669, 0.098730671632491, 0.09804289953746824, 0.09726732620266645, 0.09640539916429205, 0.09545872712978681, 0.09442907697532354, 0.09331837044809453, 0.09212868057954718, 0.09086222781626195, 0.08952137587569314, 0.08810862733450797, 0.08662661895775779, 0.08507811677759877, 0.08346601093074772, 0.08179331026430803, 0.08006313672003366, 0.0782787195075123, 0.07644338907714314, 0.0745605709041578, 0.07263377909528639, 0.07066660983000077, 0.06866273464857685, 0.06662589359950274, 0.0645598882590227, 0.06246857463584509, 0.0603558559742573, 0.058225675469079724, 0.056082008906055705, 0.053928857241413664, 0.05177023913445067, 0.04961018344707498, 0.04745272172430634, 0.04530188066976837, 0.043161674630217195, 0.041036098103132836, 0.03892911828135751, 0.036844667648695616, 0.034786636640294744, 0.03275886638150678, 0.030765141518781288, 0.028809183155971214, 0.02689464190923545, 0.025025091093499843, 0.023204020053193886, 0.021434827649710886, 0.019720815917745993, 0.018065183902352584, 0.016471021688219307, 0.014941304632311476, 0.013478887810641483, 0.012086500689532126, 0.01076674203131922, 0.009522075044001037, 0.008354822783887265, 0.007267163819828481, 0.006261128167117968, 0.005338593498655108, 0.0045012816404418395, 0.003750755357952989, 0.003088415439378416, 0.002515498081180883, 0.0020330725808491816, 0.001642039341152828, 0.0013431281896232486, 0.001136897016397869, 0.0010237307329695735, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire7.expand_1x1.0.weight
[0.1, 0.10095392478573909, 0.10081578405997108, 0.1005858324172375, 0.1002644936603867, 0.09985236001950158, 0.09935019106041443, 0.09875891228482069, 0.09807961342457125, 0.09731354643328748, 0.09646212317899981, 0.09552691284206301, 0.09450963902314316, 0.09341217656660705, 0.09223654810516779, 0.09098492033215548, 0.08965960000828276, 0.0882630297102651, 0.08679778332913098, 0.08526656132651862, 0.08367218575770208, 0.08201759507051919, 0.08030583868978698, 0.07854007139718566, 0.07672354751696887, 0.07485961491821627, 0.07295170884468206, 0.07100334558361139, 0.06901811598519268, 0.06699967884459014, 0.0649517541587528, 0.06287811627042823, 0.060782586912016615, 0.058669028162085114, 0.05654133532752395, 0.054403429764462524, 0.052259251651176286, 0.05011275272630461, 0.04796788900576245, 0.04582861349176917, 0.043698868887431616, 0.04158258033030842, 0.039483648158347845, 0.03740594072153162, 0.03535328725247263, 0.03332947080910649, 0.03133822130248335, 0.02938320862250974, 0.02746803587431021, 0.025596232737673558, 0.023771248961822727, 0.021996448007497574, 0.020275100848067714, 0.018610379941100676, 0.017005353381495402, 0.01546297924695698, 0.013986100146234248, 0.012577437980167288, 0.011239588925201011, 0.009975018648609713, 0.008786057764251037, 0.0076748975372247724, 0.0066435858453524725, 0.005694023404921028, 0.004827960267646347, 0.0040469925953129475, 0.003352559718034181, 0.0027459414815544586, 0.0022282558884825993, 0.0018004570378034315, 0.001463333366465174, 0.0012175061962834014, 0.0010634285888396092, 0.00100138451048482, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire7.expand_1x1.0.bias
[0.1, 0.10095450123166638, 0.10081808773218233, 0.10059100776739627, 0.10027367461165665, 0.09986666579567294, 0.09937072205543829, 0.09878674598412646, 0.09811580038941664, 0.097359106359236, 0.09651804103943967, 0.09559413512747318, 0.09458907008657859, 0.09350467508561411, 0.09234292367005702, 0.09110593017024798, 0.08979594585341413, 0.08841535482647356, 0.08696666969707821, 0.08545252700079169, 0.0838756824027245, 0.08223900568235927, 0.08054547551069349, 0.078798174029205, 0.0770002812405064, 0.07515506922089699, 0.073265896165345, 0.07133620027573835, 0.0693694935035264, 0.06736935515814155, 0.06533942539283226, 0.06328339857976353, 0.06120501658644161, 0.0591080619656994, 0.05699635107163671, 0.054873727114043806, 0.05274405316394892, 0.050611205123019316, 0.04847906466961119, 0.046351512194306325, 0.04423241973779237, 0.042125643943939584, 0.040035019040898984, 0.03796434986299603, 0.03591740492611952, 0.03389790956920846, 0.031909539174318664, 0.029955912477608423, 0.02804058498341715, 0.026167042493422478, 0.02433869476265299, 0.022558869293902148, 0.020830805281837006, 0.01915764771782363, 0.017542441666197606, 0.0159881267223971, 0.014497531663043944, 0.013073369297709508, 0.011718231531734995, 0.010434584649091395, 0.009224764823864102, 0.008090973868531248, 0.007035275226773479, 0.006059590218108024, 0.005165694541181936, 0.004355215042087967, 0.0036296267535848464, 0.002990250210610356, 0.0024382490469727503, 0.0019746278775946025, 0.0016002304701631268, 0.0013157382095145267, 0.001121668857547208, 0.0010183756109206012, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire7.expand_1x1.1.weight
[0.1, 0.10095506928212841, 0.10082035787928996, 0.10059610789868606, 0.10028272236882113, 0.09988076451516831, 0.09939095674792431, 0.09881417936367323, 0.09815146896329208, 0.0974040165889421, 0.09657316558349345, 0.09566040917623092, 0.09466738779917927, 0.09359588613887183, 0.09244782992886057, 0.09122528248873235, 0.08993044101585186, 0.08856563263649536, 0.08713331022347255, 0.08563604798775301, 0.08407653685202049, 0.08245757961446926, 0.08078208591153478, 0.07905306698861155, 0.0772736302881564, 0.07544697386490362, 0.07357638063822934, 0.07166521249199434, 0.06971690423246996, 0.06773495741520562, 0.06572293405193266, 0.06368445020881451, 0.061623169507548814, 0.05954279654100129, 0.05744707021520502, 0.055339757029691274, 0.05322464430822821, 0.051105533392134056, 0.048986232808397166, 0.046870551424882084, 0.04476229160492275, 0.04266524237360602, 0.040583172608026845, 0.03851982426375432, 0.03647890564968153, 0.03446408476334636, 0.03247898269870107, 0.030527167138178157, 0.028612145940749147, 0.026737360837499582, 0.024906181246051234, 0.023121898214947964, 0.021387718508888667, 0.019706758845437846, 0.01808204029357116, 0.016516482844123586, 0.015012900161898074, 0.013573994528866252, 0.01220235198754981, 0.01090043769331054, 0.009670591483902317, 0.008515023674247562, 0.007435811083995768, 0.006434893305003564, 0.005514069215444594, 0.0046749937468139316, 0.003919174909637739, 0.00324797108323343, 0.002662588574391349, 0.0021640794493655627, 0.001753339643070189, 0.0014311073488794393, 0.0011979616919252857, 0.0010543216882771592, 0.0010004454918742126, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire7.expand_1x1.1.bias
[0.1, 0.10095562907655327, 0.10082259505736699, 0.10060113405613239, 0.10029163913001476, 0.09989465958204106, 0.09941089998617664, 0.09884121893682123, 0.09818662752494407, 0.09744828754356216, 0.09662750942574719, 0.09572574991882042, 0.09474460949886382, 0.09368582953013598, 0.09255128917443445, 0.09134300205589008, 0.09006311268711237, 0.08871389266302941, 0.08729773662917728, 0.08581715803159465, 0.08427478465586591, 0.0826733539632303, 0.08101570823203455, 0.07930478951315227, 0.07754363440832344, 0.07573536868068141, 0.0738832017070331, 0.07199042078173844, 0.07006038528229894, 0.06809652070701037, 0.06610231259526199, 0.06408130034127228, 0.06203707091224151, 0.05997325248206982, 0.057893507991940124, 0.05580152864919485, 0.05370102737604472, 0.0515957322197374, 0.04948937973588142, 0.04738570835666928, 0.04528845175576997, 0.04320133222166694, 0.041128054051203046, 0.03907229697505774, 0.037037709626825045, 0.03502790306728389, 0.03304644437535417, 0.031096850317113147, 0.029182581104109262, 0.027307034252050767, 0.02547353855076939, 0.023685348156161214, 0.021945636814590504, 0.020257492230007543, 0.018623910583777475, 0.017047791216947078, 0.015531931484387106, 0.014079021789943517, 0.012691640811409388, 0.011372250923792342, 0.01012319382900036, 0.00894668639970278, 0.00784481674474281, 0.006819540503084775, 0.005872677372873908, 0.005005907881768806, 0.004220770404278883, 0.0035186584314005225, 0.0029008180973976944, 0.002368345968116891, 0.0019221870947615507, 0.0015631333365802628, 0.0012918219554457202, 0.0011087344848188343, 0.0010141958751053329, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire7.expand_3x3.0.weight
[0.1, 0.10095618075177012, 0.1008247998121411, 0.10060608746167317, 0.10030042705279739, 0.09990835433788699, 0.0994305565302067, 0.09886787109938608, 0.09822128430352786, 0.09749192946052443, 0.09668108496161232, 0.09579017203064649, 0.09482075223302186, 0.09377452473860848, 0.09265332334349763, 0.09145911325577925, 0.09019398765098424, 0.08886016400322932, 0.08745998019849516, 0.08599589043685002, 0.08447046093080174, 0.08288636540731764, 0.0812463804213963, 0.0795533804894053, 0.07781033305071561, 0.07602029326646292, 0.07418639866455311, 0.07231186364029775, 0.07039997382231855, 0.06845408031359644, 0.06647759381775889, 0.06447397866090125, 0.06244674671942019, 0.060399451264502205, 0.058335680734056865, 0.05625905244301071, 0.05417320624298636, 0.05208179814248018, 0.0499884938987204, 0.04789696259243814, 0.045810870196813014, 0.043733873151865624, 0.04166961195555934, 0.039621704782845095, 0.03759374114383298, 0.03558927559220696, 0.03361182149491004, 0.031664844874020305, 0.029751758331611724, 0.027875915068247784, 0.026040603005592355, 0.02424903902343958, 0.022504363321263595, 0.020809633914171368, 0.0191678212729058, 0.01758180311729382, 0.016054359372265802, 0.014588167295286537, 0.013185796783738973, 0.011849705870485373, 0.010582236415501118, 0.009385610001133093, 0.008261924038176893, 0.007213148089598242, 0.006241120418342272, 0.005347544765281508, 0.004533987362950075, 0.0038018741902984925, 0.003152488473280523, 0.002586968435653413, 0.002106305303933475, 0.0017113415700040482, 0.001402769514421103, 0.0011811299930046472, 0.0010468114888429404, 0.0010000494313710186, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire7.expand_3x3.0.bias
[0.1, 0.10095672444206277, 0.10082697267920765, 0.1006109693146319, 0.10030908825498022, 0.09992185206310414, 0.0994499310534939, 0.09889414213194922, 0.09825544738149715, 0.09753495239700474, 0.09673390437136982, 0.09585368993660213, 0.09489583276353243, 0.09386199092430428, 0.09275395402221412, 0.09157364009386809, 0.09032309228901779, 0.0890044753338225, 0.08762007178365988, 0.08617227807197168, 0.08466360036198396, 0.08309665020848261, 0.08147414003715372, 0.07979887844931421, 0.07807376536016028, 0.07630178697894945, 0.07448601063980567, 0.07262957949209561, 0.07073570705956682, 0.06880767167766648, 0.06684881081866959, 0.0648625153144399, 0.06285222348682437, 0.06082141519584129, 0.05877360581596487, 0.05671234015093366, 0.054641186297616086, 0.052563729469555204, 0.050483565790884005, 0.0484042960713543, 0.046329519573254666, 0.044262827781007145, 0.04220779818422746, 0.04016798808501076, 0.0381469284401622, 0.036148117749032004, 0.034175015997534974, 0.0322310386688376, 0.03031955083108058, 0.028443861312370658, 0.026607216973125403, 0.024812797085685352, 0.023063707830922597, 0.021362976921372425, 0.019713548360195315, 0.01811827734504175, 0.016579925325641415, 0.015101155223672058, 0.013684526823182587, 0.012332492339549896, 0.011047392174639115, 0.009831450865515939, 0.008686773233723221, 0.007615340741787912, 0.006619008063265258, 0.005699499872257396, 0.0048584078579640855, 0.004097187969433141, 0.0034171578952801145, 0.0028194947827399333, 0.0023052331999987513, 0.0018752633453333104, 0.0015303295061578838, 0.0012710287706461534, 0.0010978099941582155, 0.0010109730222619896, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire7.expand_3x3.1.weight
[0.1, 0.10095726027922221, 0.10082911418423811, 0.10061578079218043, 0.10031762481543356, 0.09993515597812526, 0.09946902814470804, 0.09892003820211978, 0.09828912469743473, 0.09757736623333389, 0.09678597962413793, 0.09591631781555504, 0.09496986757169999, 0.0939482469333389, 0.09285320245170475, 0.09168660620261292, 0.09045045258598122, 0.08914685491622625, 0.08777804180936444, 0.08634635337299518, 0.08485423720567892, 0.08330424421255002, 0.08169902424431784, 0.08004132156711152, 0.07833397017091337, 0.07657988892460106, 0.07478207658588218, 0.07294360667465143, 0.0710676222185354, 0.06915733037960756, 0.06721599697145995, 0.06524694087600459, 0.0632535283695501, 0.06123916736785332, 0.05920730159998455, 0.05716140472096692, 0.055104974373254345, 0.053041526207201255, 0.05097458787074591, 0.04890769297858291, 0.04684437507113499, 0.04478816157365175, 0.04274256776576285, 0.04071109077179527, 0.03869720358212857, 0.036704349115809276, 0.03473593433457508, 0.03279532441835096, 0.030885837012175257, 0.029010736554390706, 0.027173228695797108, 0.025376454819306678, 0.023623486669470607, 0.02191732110105923, 0.020260874955672276, 0.018656980075139242, 0.01710837846023421, 0.015617717582981812, 0.014187545860568772, 0.012820308298598353, 0.01151834231113593, 0.01028387372469217, 0.009119012972974821, 0.008025751488914795, 0.007005958300134767, 0.006061376833680287, 0.005193621935476489, 0.004404177109605488, 0.0036943919821243614, 0.003065479993759567, 0.002518516325422137, 0.0020544360600904966, 0.001674032584202994, 0.0013779562312933248, 0.0011667131701875823, 0.0010406645396636763, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire7.expand_3x3.1.bias
[0.1, 0.1009577883925979, 0.10083122484318359, 0.10062052304979141, 0.10032603877487667, 0.09994826924462329, 0.09948785230939526, 0.09894556536674902, 0.09832232404882546, 0.09761918067633774, 0.09683732248176534, 0.0959780696047544, 0.09504287286310904, 0.09403331130313736, 0.09295108953348807, 0.09179803484697967, 0.09057609413528174, 0.08928733060165793, 0.08793392027732086, 0.08651814834728114, 0.085042405291894, 0.08350918285061869, 0.08192106981480524, 0.08028074765661275, 0.07859098600143946, 0.07685463795150896, 0.07507463526850917, 0.07325398342341727, 0.07139575652186927, 0.06950309211364247, 0.06757918589501465, 0.06562728631294494, 0.06365068908018724, 0.06165273161059677, 0.05963678738402606, 0.05760626025032454, 0.05556457868205971, 0.05351518998566357, 0.05146155448077875, 0.049407139657632444, 0.047355414322302884, 0.04530984273976413, 0.043273878784598374, 0.041250960109252055, 0.03924450233968235, 0.037257893308194796, 0.03529448733320934, 0.03335759955561343, 0.031450500341265106, 0.029576409759096867, 0.02773849214414429, 0.025939850754679444, 0.024183522532469817, 0.022472472975010895, 0.020809591128389218, 0.019197684709231427, 0.01763947536397491, 0.01613759407346497, 0.014694576710637529, 0.013312859758788431, 0.011994776197658107, 0.010742551564278807, 0.009558300195234664, 0.008444021656679894, 0.007401597368142742, 0.006432787425815789, 0.0055392276306963075, 0.004722426726594813, 0.00398376385267487, 0.003324486214825933, 0.002745706979800721, 0.0022484033956728924, 0.0018334151417885572, 0.0015014429109977015, 0.0012530472265592943, 0.0010886474957178141, 0.0010085213015490805, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire8.squeeze.0.weight
[0.1, 0.10095830890914792, 0.10083330516247396, 0.10062519722168049, 0.10033433213665018, 0.09996119496669043, 0.09950640797162741, 0.09897072957409825, 0.09835505309477255, 0.09766040526261169, 0.0968879445026509, 0.09603895900415911, 0.09511486457239832, 0.09411720226756493, 0.09304763583485057, 0.091907948929908, 0.09070004214434907, 0.08942592983623528, 0.08808773677084639, 0.08668769457732904, 0.08522813802713472, 0.08371150114045295, 0.08214031312713299, 0.08051719416886322, 0.07884485104964174, 0.07712607264182536, 0.07536372525528423, 0.0735607478574186, 0.07172014717200839, 0.06984499266506952, 0.06793841142607841, 0.06600358295310112, 0.06404373385052364, 0.062062132448225685, 0.06006208335117105, 0.058046921928504316, 0.056020008751343636, 0.053984723988545716, 0.05194446176978882, 0.0499026245253739, 0.04786261731218343, 0.045827842135259984, 0.04380169227447414, 0.04178754662574295, 0.03978876406623563, 0.03780867785296343, 0.035850590064094884, 0.03391776609226606, 0.03201342919906939, 0.030140755139801956, 0.028302866867437406, 0.02650282932465331, 0.024743644332598992, 0.023028245584927654, 0.021359493755440724, 0.01974017172750353, 0.01817297995318749, 0.016660531949878443, 0.015205349941860964, 0.013809860654147167, 0.01247639126556415, 0.011207165527848995, 0.01000430005722346, 0.008869800804632243, 0.007805559710531856, 0.006813351549807977, 0.005894830972083497, 0.0050515297423526775, 0.004284854186542857, 0.0035960828462641196, 0.002986364346657399, 0.0024567154808971476, 0.002008019514542663, 0.0016410247125658631, 0.001356343091512007, 0.0011544493988741957, 0.0010356803213837076, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire8.squeeze.0.bias
[0.1, 0.10095882195348799, 0.10083535563921248, 0.10062980442123877, 0.10034250686747144, 0.09997393619199176, 0.09952469947561643, 0.09899553666596153, 0.09838731935865862, 0.09770104936173044, 0.09693785704549115, 0.09609899948068859, 0.09518585836795554, 0.0941999377619805, 0.09314286159414631, 0.09201637099771715, 0.09082232143998004, 0.08956267966606403, 0.08823952045947132, 0.08685502322465598, 0.08541146839727926, 0.08391123368805409, 0.08235679016636595, 0.08075069819012026, 0.07909560318852105, 0.07739423130472663, 0.07564938490555957, 0.07386393796566719, 0.07204083133373484, 0.07018306788855001, 0.06829370759289487, 0.06637586245341469, 0.06443269139476374, 0.062467395056471364, 0.06048321052109871, 0.05848340598236922, 0.0564712753620553, 0.054450132884487835, 0.05242330761762477, 0.05039413798967052, 0.04836596629027792, 0.04634213316538985, 0.04432597211478826, 0.042320804001413886, 0.040329931581500174, 0.038356634064531395, 0.036404161711984996, 0.03447573048375483, 0.03257451674107336, 0.030703652014657603, 0.02886621784669642, 0.0270652407151751, 0.025303687048897124, 0.02358445834141471, 0.021910386371915086, 0.020284228540935197, 0.018708663328587113, 0.017186285882774665, 0.01571960374466875, 0.014311032718481421, 0.012962892892341975, 0.011677404816829006, 0.01045668584745309, 0.009302746657114187, 0.008217487924278382, 0.007202697202328789, 0.006260045975247352, 0.005391086904477016, 0.0045972512714990916, 0.0038798466203383, 0.0032400546038783774, 0.002678929037535787, 0.002197394163497334, 0.0017962431283806359, 0.001476136676824973, 0.0012376020631643995, 0.001081032182975549, 0.0010066849259307723, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire8.squeeze.1.weight
[0.1, 0.10095932764793925, 0.1008373767613659, 0.1006343457414556, 0.10035056489817326, 0.09998649591289349, 0.09954273108729406, 0.09901999237974371, 0.09841913023075241, 0.09774112217939473, 0.09698707127295723, 0.09615820427239748, 0.09525586965653379, 0.09428153542821309, 0.09323678672602574, 0.09212332324545294, 0.09094295647364227, 0.08969760674230987, 0.08838930010356419, 0.08702016503373383, 0.08559242897056192, 0.08410841468940092, 0.0825705365243031, 0.08098129644015473, 0.07934327996224431, 0.07765915196988665, 0.07593165236094655, 0.07416359159431525, 0.07235784611759133, 0.07051735368740523, 0.06864510859000042, 0.06674415676984669, 0.06481759087421123, 0.06286854522174909, 0.060900190703298634, 0.05891572962317805, 0.05691839048937541, 0.05491142276110807, 0.05289809156229683, 0.05088167236955496, 0.04886544568333484, 0.046852691690901144, 0.04484668492981352, 0.04285068896060093, 0.040867951057294225, 0.038901696924455276, 0.03695512544929739, 0.0350314034974345, 0.03313366076072637, 0.031264984665601306, 0.029428415350140416, 0.02762694071809505, 0.02586349157788368, 0.02414093687447723, 0.022462079021929284, 0.020829649344145426, 0.019246303631308432, 0.017714617819188944, 0.016237083798370827, 0.014816105360209171, 0.013453994286116266, 0.012152966586538149, 0.010915138895740372, 0.009742525028268133, 0.008637032702683418, 0.007600460437908896, 0.0066344946272281265, 0.005740706794702343, 0.004920551038467224, 0.004175361665069271, 0.0035063510186903396, 0.0029146075087921157, 0.002401093839389167, 0.001966645442831493, 0.0016119691206445677, 0.001337641893638152, 0.0011441100631544956, 0.0010316884849833777, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire8.squeeze.1.bias
[0.1, 0.10095982611257533, 0.10083936900795053, 0.10063882225533204, 0.10035850812442637, 0.09999887706756708, 0.09956050699585788, 0.0990441023504952, 0.09845049297076257, 0.09778063276051582, 0.09703559815530205, 0.09621658639257552, 0.09532491358779044, 0.09436201261946198, 0.09332943082659427, 0.09222882752217541, 0.09106197132673549, 0.0898307373262519, 0.08853710405896985, 0.08718315033597925, 0.08577105190065794, 0.08430307793234884, 0.08278158739988978, 0.08120902527085548, 0.07958791858260356, 0.0779208723814379, 0.0762105655364152, 0.0744597464345216, 0.07267122856413714, 0.07084788599388507, 0.06899264875413155, 0.06710849812855722, 0.065198461863367, 0.0632656093018367, 0.06131304645201488, 0.05934391099550634, 0.05736136724535719, 0.055368601061144766, 0.053368814729442986, 0.05136522181789038, 0.0493610420111299, 0.047359495936918974, 0.045363799990724, 0.043377161167116075, 0.041402771906273284, 0.03944380496387154, 0.03750340831260738, 0.03558470008354584, 0.03369076355542277, 0.03182464219995296, 0.029989334791106617, 0.02818779058621307, 0.02642290458663542, 0.024697512885632263, 0.023014388110881967, 0.021376234968993435, 0.019785685899162936, 0.018245296842961455, 0.016757543137050357, 0.015324815535425522, 0.013949416367582061, 0.012633555838773299, 0.011379348478309258, 0.010188809741602217, 0.009063852771419488, 0.008006285323548183, 0.007017806861812103, 0.006100005827108983, 0.005254357084856664, 0.0044822195549500616, 0.0037848340280372643, 0.003163321171624266, 0.0026186797292121304, 0.0021517849153606374, 0.0017633870092574047, 0.0014541101490526777, 0.0012244513288970408, 0.0010747796002939839, 0.0010053354790505278, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire8.expand_1x1.0.weight
[0.1, 0.1009603174652679, 0.10084133284921414, 0.10064323501628503, 0.10036633840744603, 0.10001108254106905, 0.09957803131528431, 0.09906787211290416, 0.09848141471033926, 0.09781958999223948, 0.09708344847389933, 0.09627415863377355, 0.09539300505874973, 0.09444138640512166, 0.09342081317850033, 0.09233290533618622, 0.09117938971580884, 0.08996209729431498, 0.08868296028165644, 0.0873440090537905, 0.08594736892986132, 0.08449525679867798, 0.08298997759984367, 0.08143392066512195, 0.07982955592584713, 0.07817942999239878, 0.07648616211196356, 0.0747524400110005, 0.07298101562900909, 0.0711747007503719, 0.06933636254120526, 0.06746891899830253, 0.0655753343173938, 0.06365861418807381, 0.06172180102286665, 0.0597679691280003, 0.05780021982355587, 0.05582167652073805, 0.05383547976408022, 0.05184478224645356, 0.04985274380479346, 0.04786252640448589, 0.0458772891203753, 0.04390018312236085, 0.04193434667353995, 0.03998290014883888, 0.03804894108203745, 0.036135539249049185, 0.03424573179526189, 0.0323825184146724, 0.03054885658846825, 0.028747656890613694, 0.026981778367891465, 0.02525402400173403, 0.023567136259047092, 0.0219237927390882, 0.020326601923309685, 0.01877809903491235, 0.017280742014682254, 0.01583690761949789, 0.0144488876497006, 0.01311888531131681, 0.011849011718906, 0.010641282544585594, 0.009497614818551901, 0.00841982388617531, 0.007409620526500132, 0.006468608236722655, 0.005598280686957773, 0.004800019349334366, 0.004075091305182654, 0.003424647233794231, 0.002849719585947285, 0.0023512209450959657, 0.0019299425788254657, 0.0015865531828718352, 0.0013215978197003366, 0.0011354970533270273, 0.0010285462817569248, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire8.expand_1x1.0.bias
[0.1, 0.1009608018217316, 0.10084326874681354, 0.10064758505854277, 0.10037405757468318, 0.10002311516639768, 0.09959530808580959, 0.09909130710324725, 0.09851190245552516, 0.09785800260691013, 0.09713063282471562, 0.0963309335717572, 0.09546015871819, 0.0945196735755317, 0.09351095275595354, 0.09243557786019586, 0.09129523499773345, 0.09009171214307868, 0.08882689633236784, 0.08750277070462593, 0.08612141139234918, 0.08468498426628061, 0.08319574153948252, 0.08165601823603048, 0.08006822852986582, 0.07843486195954674, 0.07675847952483328, 0.07504170967122632, 0.07328724416875654, 0.07149783389148523, 0.06967628450433415, 0.06782545206400735, 0.06594823854090247, 0.06404758726903262, 0.062126478331092985, 0.06018792388590849, 0.05823496344558813, 0.056270659109791545, 0.054298090764579865, 0.05232035125337875, 0.050340541527625376, 0.04836176578470244, 0.046387126600782876, 0.044419720066216625, 0.0424626309310864, 0.040518927768544405, 0.038591658163513336, 0.03668384393429513, 0.03479847639458022, 0.03293851166328551, 0.031106866029575398, 0.02930641138033291, 0.0275399706972502, 0.025810313630599185, 0.02412015215662148, 0.02247213632534747, 0.0208688501055109, 0.019312807333074205, 0.01780644776971682, 0.016352133277466846, 0.014952144115473253, 0.013608675364725892, 0.012323833486328352, 0.011099633018720474, 0.009937993419028884, 0.008840736053498093, 0.007809581341720872, 0.0068461460591458575, 0.005951940802091265, 0.005128367619240109, 0.004376717813329905, 0.0036981699164841666, 0.0030937878423598565, 0.0025645192180083257, 0.002111193898065144, 0.0017345226635985026, 0.0014350961076562798, 0.0012133837092592073, 0.0010697330972919519, 0.0010043695054463666, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire8.expand_1x1.1.weight
[0.1, 0.10096127929556764, 0.10084517715398862, 0.10065187339753129, 0.10038166742050039, 0.10003497772552683, 0.09961234127537898, 0.09911441266129956, 0.09854196308915636, 0.09789587918497676, 0.09717716162171648, 0.09638692356938901, 0.09552638897095656, 0.09459689064665272, 0.09359986822967292, 0.09253686593642996, 0.09140953017482817, 0.09021960699426038, 0.08896893938127745, 0.08765946440511882, 0.08629321021752501, 0.08487229291147913, 0.08339891324374238, 0.08187535322626, 0.08030397259171687, 0.07868720513871702, 0.07702755496224781, 0.07532759257526699, 0.07358995092741982, 0.07181732132705258, 0.07001244927283823, 0.06817813020147072, 0.06631720515801393, 0.064432556395611, 0.06252710291136947, 0.06060379592533624, 0.05866561430956485, 0.056715559974354526, 0.05475665321880693, 0.052791928052901706, 0.050824427498336475, 0.048857198875408965, 0.04689328908324156, 0.04493573988065805, 0.042987583175021805, 0.0410518363263323, 0.039131497473852944, 0.037229540892508343, 0.035348912386243735, 0.0334925247254806, 0.03166325313573592, 0.02986393084439184, 0.028097344692513196, 0.026366230818509664, 0.024673270420327388, 0.02302108560273411, 0.02141223531612942, 0.019849211393170293, 0.018334434689350337, 0.016870251333510795, 0.015458929094089885, 0.01410265386673925, 0.01280352628874722, 0.011563558485512444, 0.010384670954107535, 0.009268689588759, 0.0082173428528508, 0.00723225910183165, 0.006314964061172095, 0.005466878463278023, 0.004689315847020197, 0.003983480523288279, 0.003350465709720218, 0.0027912518374958884, 0.00230670503281774, 0.0018975757754300818, 0.0015644977362548988, 0.0013079867959445038, 0.0011284402458710421, 0.001026136172790403, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire8.expand_1x1.1.bias
[0.1, 0.10096174999830676, 0.1008470585157322, 0.10065610103025245, 0.10038916970683319, 0.10004667295041736, 0.09962913478106548, 0.09913719403220492, 0.09857160337321476, 0.09793322815784156, 0.09722304510020809, 0.09644214078044062, 0.09559170998220129, 0.09467305386466898, 0.09368757797176579, 0.09263679008167455, 0.0915222978999383, 0.09034580659967058, 0.08910911621264048, 0.0878141188752239, 0.08646279593343482, 0.08505721491146571, 0.08359952634837536, 0.08209196050776402, 0.08053682396546996, 0.0789364960805082, 0.07729342535465114, 0.07561012568622061, 0.07388917252382331, 0.07213319892591429, 0.07034489153221728, 0.06852698645316573, 0.06668226508365376, 0.06481354984750162, 0.06292369987914723, 0.06101560664917014, 0.05909218954034147, 0.057156391380968, 0.05521117394236468, 0.05325951340734432, 0.05130439581665767, 0.04934881250035093, 0.04739575550103048, 0.04544821299603758, 0.04350916472553676, 0.041581577433513206, 0.03966840032865431, 0.03777256057206004, 0.03589695879868643, 0.03404446467937374, 0.032217912530250005, 0.030420096976227107, 0.028653768675224435, 0.026921630109662212, 0.025226331451663003, 0.02357046650828841, 0.021956568753013925, 0.020387107449514438, 0.018864483873690597, 0.017391027639716544, 0.01596899313573006, 0.014600556074618548, 0.013287810165178205, 0.012032763908739374, 0.010837337526159424, 0.009703360019884654, 0.008632566375576477, 0.007626594907583211, 0.006686984752319019, 0.00581517351338509, 0.005012495062036043, 0.004280177496356812, 0.0036193412622724736, 0.003030997439265958, 0.0025160461934262794, 0.002075275400194481, 0.0017093594389140535, 0.001418858161030522, 0.0012042160335187504, 0.0010657614588483457, 0.001003706272527948, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire8.expand_3x3.0.weight
[0.1, 0.10096221403945092, 0.10084891326895624, 0.10066026893565376, 0.10039656616383688, 0.10005820352400692, 0.09964569243045829, 0.09915965636830724, 0.09860082995113258, 0.09797005781065243, 0.09726829332011543, 0.09649659715333571, 0.09565613568154985, 0.09474817921051851, 0.09377410006053744, 0.09273537049225995, 0.0916335604814656, 0.09047033534613838, 0.08924745322944123, 0.08796676244239086, 0.08663019867024946, 0.08523978204685566, 0.08379761410131659, 0.08230587458167606, 0.0807668181603596, 0.079182771026376, 0.07755612736942573, 0.07588934576123074, 0.07418494543955471, 0.07244550250053021, 0.07067364600504811, 0.06887205400509387, 0.0670434494960369, 0.06519059630099082, 0.06331629489346483, 0.06142337816462064, 0.05951470714153178, 0.057593166662917444, 0.055661661018886366, 0.05372310956128117, 0.05178044229125785, 0.0498365954307694, 0.047894506984647145, 0.04595711229998745, 0.04402733962955522, 0.04210810570591016, 0.040202311332945224, 0.038312837001500066, 0.036442538535676576, 0.034594242776436517, 0.03277074330900553, 0.03097479624054116, 0.029209116034446477, 0.02747637140762589, 0.025779181296883804, 0.02412011090056297, 0.022501667801405167, 0.02092629817649419, 0.019396383100009903, 0.017914234944381303, 0.01648209388527782, 0.015102124515721838, 0.01377641257443966, 0.012506961793395766, 0.011295690869275472, 0.010144430563492856, 0.009054920935107763, 0.00802880871083364, 0.0070676447961115045, 0.00617288193101188, 0.005345872494507608, 0.004587866460436351, 0.0039000095082420854, 0.0032833412913511766, 0.002738793865800231, 0.0022671902814908208, 0.0018692433382001875, 0.0015455545082283298, 0.001296613027309639, 0.00112279515516318, 0.0010243636067993492, 0, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire8.expand_3x3.0.bias
[0.1, 0.1009626715265143, 0.10085074184265448, 0.10066437807499001, 0.10040385849051928, 0.10006957208117834, 0.0996620179830219, 0.09918180473094387, 0.09862964935005011, 0.0980063762850405, 0.09731291616919824, 0.09655030443482529, 0.09571967976719789, 0.09482228240435131, 0.09385945228523217, 0.09283262704898337, 0.09174333988834915, 0.09059321726040528, 0.08938397645803266, 0.08811742304576044, 0.08679544816380735, 0.0854200257043466, 0.08399320936421058, 0.08251712957843611, 0.0809939903392291, 0.07942606590509774, 0.07781569740506872, 0.07616528934305626, 0.0744773060076037, 0.07275426779235832, 0.0709987474327734, 0.06921336616465683, 0.06740078981030173, 0.0655637247980435, 0.0637049141211862, 0.061827133242332445, 0.05993318594923221, 0.058025900168338, 0.05610812374231792, 0.05418272017783076, 0.05225256436991277, 0.05032053830935994, 0.048389526779515225, 0.04646241304888638, 0.04454207456602528, 0.042631378663097554, 0.040733178274557316, 0.038850307677319486, 0.03698557825879072, 0.03514177431907735, 0.03332164891363838, 0.031527919742591365, 0.029763265092808334, 0.028030319838861575, 0.026331671508789622, 0.02466985642055849, 0.023047355894986576, 0.021466592550787846, 0.019929926687265516, 0.01843965276005734, 0.016997995955194436, 0.01560710886658941, 0.014269068281914644, 0.012985872081669625, 0.011759436256067884, 0.010591592044197334, 0.009484083199725882, 0.008438563387235004, 0.007456593713068654, 0.006539640394384671, 0.005689072569888814, 0.004906160255520474, 0.004192072448142386, 0.0035478753800659174, 0.0029745309270180756, 0.0024728951719274186, 0.0020437171266732826, 0.0016876376137069707, 0.0014051883092148433, 0.001196790949251835, 0.001062756700030997, 0.001003285693309052, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire8.expand_3x3.1.weight
[0.1, 0.10096312256506323, 0.10085254465806126, 0.1006684293921769, 0.10041104835535972, 0.10008078120970726, 0.09967811513142653, 0.09920364409220167, 0.09865806798302784, 0.09804219158180376, 0.09735692336620605, 0.09660327417359614, 0.09578235570993664, 0.09489537890991678, 0.09394365215070595, 0.09292857932196975, 0.09185165775499607, 0.09071447601398566, 0.0895187115527651, 0.08826612824037916, 0.08695857375921204, 0.08559797687947596, 0.08418634461408724, 0.0827257592581267, 0.08121837531725173, 0.0796664163295905, 0.07807217158580669, 0.07643799275217279, 0.07476629040163328, 0.07305953045797482, 0.07132023055834838, 0.06955095633950929, 0.06775431765325322, 0.06593296471663046, 0.06408958420261766, 0.06222689527701363, 0.0603476455874048, 0.058454607210117505, 0.056550572561135416, 0.054638350277013914, 0.0527207610718677, 0.05080063357654273, 0.04888080016611011, 0.0469640927818372, 0.04505333875379824, 0.04315135663028717, 0.041260952020184455, 0.03938491345441058, 0.03752600827257153, 0.03568697854086313, 0.0338705370072565, 0.03207936309993055, 0.030316098974854357, 0.028583345618349906, 0.026883659010383816, 0.025219546354248, 0.023593462378190655, 0.02200780571445292, 0.020464915361052743, 0.018967067231535018, 0.017516470797777395, 0.016115265830804075, 0.014765519244415205, 0.013469222046287567, 0.012228286401044508, 0.011044542809626728, 0.009919737409125207, 0.008855529397058887, 0.007853488583896718, 0.006915093077434381, 0.006041727102441241, 0.005234678958794042, 0.004495139121109131, 0.0038241984826763937, 0.00322284674628544, 0.00269197096431758, 0.002232354230257177, 0.0018446745235524689, 0.0015295037095298882, 0.0012873066958369419, 0.0011184407466582106, 0.0010231549557158483, 0, 0, 0, 0, 0, 0, 0, 0]
module.fire8.expand_3x3.1.bias
[0.1, 0.10096356725875544, 0.10085432212880713, 0.10067242381413713, 0.1004181373969147, 0.10009183345118947, 0.0996939875028503, 0.09922517933663683, 0.09868609215121359, 0.09807751156353794, 0.09740032446397301, 0.0966555177238137, 0.09584417675710964, 0.09496748393888088, 0.09402671688203133, 0.09302324657547115, 0.09195853538616133, 0.09083413492799229, 0.08965168380060194, 0.08841290520142864, 0.08711960441447889, 0.08577366617946958, 0.08437705194517862, 0.08293179701100667, 0.08144000756091566, 0.07990385759406667, 0.0783255857566299, 0.07670749207938406, 0.0750519346258592, 0.07336132605590814, 0.07163813010971387, 0.06988485801735725, 0.06810406483917715, 0.06629834574225642, 0.06447033221845977, 0.0626226882495354, 0.06075810642486856, 0.05887930401754515, 0.05698901902444342, 0.05509000617612463, 0.0531850329223377, 0.05127687539898795, 0.04936831438244746, 0.047462131237102856, 0.045561103862046086, 0.0436680026428153, 0.04178558641408534, 0.0399165984391912, 0.03806376241234407, 0.03622977848936531, 0.03441731935272341, 0.03262902631660806, 0.0308675054777174, 0.02913532391736828, 0.027435005960463738, 0.025769029496770086, 0.024139822369864186, 0.022549758839013542, 0.021001156119145444, 0.019496271003947237, 0.018037296577019135, 0.016626359015872227, 0.015265514493429687, 0.01395674618154586, 0.012701961360911042, 0.011502988641552699, 0.010361575297984593, 0.009279384722886714, 0.008257994003027014, 0.007298891620957792, 0.00640347528583553, 0.005573049896525994, 0.004808825639962443, 0.004111916227528572, 0.0034833372720361293, 0.0029240048076626217, 0.0024347339550058068, 0.00201623773320062, 0.0016691260208295026, 0.0013939046671404324, 0.0011909747548679841, 0.0010606320157315265, 0.0010030663994625869, 0, 0, 0, 0, 0, 0, 0]
module.fire9.squeeze.0.weight
[0.1, 0.10096400570937812, 0.10085607466107074, 0.10067636225113867, 0.10042512722441037, 0.1001027313019485, 0.09970963866025417, 0.09924641526295888, 0.09871372804596601, 0.09811234395721553, 0.09744312885245408, 0.09670704624860041, 0.09590515593650112, 0.09503861245507385, 0.09410866342903486, 0.09311664777260445, 0.09206399376177615, 0.09095221697792558, 0.08978291812571931, 0.08855778072846576, 0.08727856870422607, 0.08594712382617492, 0.08456536307086784, 0.08313527585823266, 0.08165892118725926, 0.08013842467151114, 0.07857597547872741, 0.07697382317892115, 0.07533427450551232, 0.07365969003415851, 0.07195248078406506, 0.07021510474666798, 0.06845006334668761, 0.0666598978406484, 0.06484718565804977, 0.0630145366904563, 0.06116458953384988, 0.05930000768965411, 0.057423475729900544, 0.05553769543205799, 0.053645381889090016, 0.051749259600341185, 0.04985205854888009, 0.04795651027094736, 0.04606534392316713, 0.04418128235318481, 0.04230703817938844, 0.0404453098853575, 0.03859877793466299, 0.03677010091161194, 0.034961911693493164, 0.03317681365983537, 0.031417376944134996, 0.029686134733451122, 0.02798557962119443, 0.026318160018362097, 0.024686276628385052, 0.023092278990663302, 0.021538462097765707, 0.020027063091164976, 0.01856025804026464, 0.01714015880935621, 0.015768810017016882, 0.014448186092325628, 0.013180188432136409, 0.011966642663500726, 0.010809296015181769, 0.009709814802043925, 0.00866978202593996, 0.007690695096549859, 0.006773963675452826, 0.005920907646536588, 0.005132755215666017, 0.004410641142347165, 0.003755605105932696, 0.0031685902087211387, 0.0026504416181048532, 0.0022019053497220878, 0.0018236271933647955, 0.0015161517831887954, 0.0012799218135650205, 0.001115277401700664, 0.0010224555979481344, 0, 0, 0, 0, 0, 0, 0]
module.fire9.squeeze.0.bias
[0.1, 0.10096443801688548, 0.10085780265372767, 0.1006802455971259, 0.10043201941832214, 0.10011347721392355, 0.09972507210362987, 0.0992673565856801, 0.09874098175093504, 0.0981466963567141, 0.09748534576170345, 0.0967578707234508, 0.09596530606015719, 0.09510877917866958, 0.09418950847076785, 0.09320880158002763, 0.09216805354172448, 0.09106874479842503, 0.08991243909408791, 0.08870078124967046, 0.08743549482340479, 0.08611837965907199, 0.08475130932576139, 0.08333622845275736, 0.08187514996334437, 0.0803701522114652, 0.07882337602530542, 0.07723702166200963, 0.07561334567786104, 0.07395465771837696, 0.07226331723288566, 0.07054173011825858, 0.06879234529657174, 0.06701765123156474, 0.06522017238885247, 0.06340246564492512, 0.061567116650044024, 0.05971673615020781, 0.0578539562734201, 0.05598142678554187, 0.054101811321054294, 0.052217783594093785, 0.050332023595148837, 0.04844721377882912, 0.04656603524812909, 0.0446911639406145, 0.042825266821956566, 0.04097099809222835, 0.039130995410360137, 0.037307876142124025, 0.03550423363698534, 0.03372263353911658, 0.03196561013782161, 0.03023566276256162, 0.028535252227710497, 0.02686679733209737, 0.025232671418315252, 0.023635198996690268, 0.02207665243871372, 0.020559248744640796, 0.019085146389853303, 0.01765644225447326, 0.016275168640594185, 0.014943290381373413, 0.013662702046097548, 0.012435225245196808, 0.01126260603904189, 0.010146512454209142, 0.009088532110747293, 0.008090169963820731, 0.007152846162941911, 0.006277894031837993, 0.0054665581718255024, 0.004719992691390578, 0.0040392595644935855, 0.003425327119933096, 0.0028790686639181876, 0.0024012612378084153, 0.001992584512788558, 0.0016536198230503887, 0.0013848493388568242, 0.0011866553806646853, 0.0010593198752817602, 0.001003023954831738, 0, 0, 0, 0, 0, 0]
module.fire9.squeeze.1.weight
[0.1, 0.10096486427943537, 0.10085950649849584, 0.10068407473004344, 0.10043881553094194, 0.10012407359553877, 0.09974029127122162, 0.09928800793673068, 0.09876785924410021, 0.09818057622529491, 0.09752698426479636, 0.09680800193958408, 0.09602463972814086, 0.09517799859029719, 0.09426926841991058, 0.09329972637255445, 0.09227073507056682, 0.09118374068798174, 0.09004027091803447, 0.08884193282609745, 0.0875904105910643, 0.08628746313835621, 0.08493492166787756, 0.08353468708039469, 0.08208872730595523, 0.0805990745381025, 0.07906782237777205, 0.07749712289088467, 0.07588918358377084, 0.07424626430067775, 0.0725706740477191, 0.07086476774773114, 0.06913094293059656, 0.06737163636368666, 0.06558932062715837, 0.0637865006389187, 0.06196571013414113, 0.06012950810428089, 0.058280475200594865, 0.05642121010721982, 0.05455432588890679, 0.05268244631854462, 0.050808202189633916, 0.048934227618894016, 0.04706315634419943, 0.0451976180230487, 0.043340234536768045, 0.04149361630564363, 0.03966035862016186, 0.03784303799351309, 0.036044208540485866, 0.03426639838784046, 0.03251210612120642, 0.030783797273498555, 0.029083900859785752, 0.027414805963483224, 0.025778858378665906, 0.024178357313221724, 0.02261555215747861, 0.02109263932284657, 0.019611759154917658, 0.018174992925362666, 0.01678435990685196, 0.015441814535111353, 0.014149243662101962, 0.012908463904183931, 0.011721219088991496, 0.010589177804607431, 0.009513931054481145, 0.008496990021386645, 0.007539783943562744, 0.00664365810602035, 0.005809871949840211, 0.0050395973021180925, 0.004333916729045217, 0.003693822014438513, 0.00312021276585907, 0.0026138951502777613, 0.002175580761064893, 0.0018058856178964126, 0.0015053293009821213, 0.0012743342208326005, 0.0011132250245913734, 0.0010222281397664226, 0, 0, 0, 0, 0, 0]
module.fire9.squeeze.1.bias
[0.1, 0.10096528459342491, 0.1008611865800778, 0.10068785051215293, 0.1004455170869332, 0.10013452281255393, 0.09975529954072222, 0.09930837386704067, 0.09879436639976809, 0.09821399089803283, 0.09756805328069527, 0.09685745050723571, 0.09608316933222194, 0.09524628493508569, 0.0943479594271111, 0.093389440237708, 0.0923720583822112, 0.09129722661361094, 0.09016643746078107, 0.08898126115592925, 0.08774334345414692, 0.08645440334808703, 0.08511623068094293, 0.08373068366104286, 0.08229968628151185, 0.08082522564858341, 0.07930934922227162, 0.07775416197323473, 0.07616182345977877, 0.07453454482905975, 0.07287458574664869, 0.0711842512587234, 0.06946588859124367, 0.06772188389055532, 0.0659546589099485, 0.06416666764677167, 0.06236039293477096, 0.0605383429963869, 0.05870304795979599, 0.05685705634553337, 0.05500293152757603, 0.05314324817379981, 0.051280588670753795, 0.04941753953771637, 0.04755668783501243, 0.045700617571579366, 0.0438519061167703, 0.04201312062137695, 0.04018681445284242, 0.03837552364961355, 0.036581763399556724, 0.034808024547327114, 0.03305677013554122, 0.03133043198455594, 0.029631407315603178, 0.027962055421969424, 0.026324694392842924, 0.024721597894377126, 0.0231549920124409, 0.02162705216143969, 0.02013990006349945, 0.018695600802208952, 0.017296159955011065, 0.015943520808225302, 0.014639561658568917, 0.013386093204923365, 0.012184856033968544, 0.011037518203175788, 0.009945672924516091, 0.008910836352100077, 0.00793444547682175, 0.007017856130929578, 0.006162341105295754, 0.005369088381998127, 0.0046391994846689205, 0.003973687948901189, 0.0033734779148366805, 0.00283940284388992, 0.002372204361390106, 0.00197253122674808, 0.0016409384325784863, 0.0013778864340280076, 0.0011837405093798484, 0.0010587702528223656, 0.0010031492000862165, 0, 0, 0, 0, 0]
module.fire9.expand_1x1.0.weight
[0.1, 0.10096569905352569, 0.10086284327629991, 0.10069157379034299, 0.10045212558387383, 0.10014482718889689, 0.09977010023044414, 0.0993284588480893, 0.09882050899052909, 0.09824694758419854, 0.09760856157706155, 0.0969062268588886, 0.09614090705950265, 0.09531365222664269, 0.09442559738525844, 0.0934779609802131, 0.09247204320453095, 0.09140922421548323, 0.09029096224096014, 0.089118791578727, 0.08789432049130955, 0.08661922899939695, 0.08529526657678976, 0.08392424975005566, 0.08250805960618622, 0.08104863921167432, 0.07954799094655338, 0.07800817375705617, 0.07643130033066255, 0.07481953419741237, 0.07317508676146024, 0.0715002142669454, 0.06979721470233924, 0.06806842464751824, 0.06631621606788782, 0.06454299305995606, 0.06275118855282222, 0.060943260970105974, 0.05912169085689711, 0.05728897747635373, 0.055447635380618546, 0.05360019096075826, 0.05174917898045922, 0.04989713909823589, 0.048046612382922946, 0.04620013782723283, 0.04436024886416162, 0.042529469891022936, 0.040710312805879334, 0.03890527356112306, 0.03711682873893483, 0.035347432153319404, 0.03359951148337973, 0.0318754649424495, 0.030177657987653497, 0.028508420074410862, 0.02687004146033429, 0.02526477006290956, 0.023694808375267884, 0.022162310444281866, 0.020669378915131577, 0.019218062146395876, 0.01781035139962686, 0.016448178107263522, 0.015133411222633529, 0.013867854655678274, 0.01265324479792031, 0.011491248140068366, 0.010383458985528993, 0.009331397262961987, 0.008336506440880707, 0.007400151547158551, 0.006523617296159189, 0.005708106326059647, 0.004954737548785315, 0.004264544614820386, 0.0036384744950002483, 0.003077386181231672, 0.0025820495079233777, 0.002153144095744069, 0.0017912584191571925, 0.00149688899901163, 0.0012704397212963561, 0.0011122212829935243, 0.001022450765790477, 0, 0, 0, 0, 0]
module.fire9.expand_1x1.0.bias
[0.1, 0.10096610775271786, 0.10086447695824846, 0.10069524539643251, 0.10045864249278766, 0.10015498900747861, 0.09978469660046586, 0.09934826727342241, 0.09884629268917522, 0.0982794533695938, 0.09764851777301371, 0.09695434125244527, 0.0961978648959802, 0.09538011425096796, 0.09450219793369158, 0.09356530612642776, 0.09257070896392885, 0.09151975481151398, 0.09041386843710376, 0.08925454907967689, 0.08804336841676702, 0.08678196843375535, 0.08547205919784773, 0.0841154165397538, 0.08271387964621119, 0.08126934856661876, 0.07978378163715875, 0.07825919282590028, 0.07669764900248313, 0.07510126713608349, 0.07347221142546032, 0.07181269036497279, 0.07012495375054699, 0.06841128962965029, 0.06667402119940842, 0.0649155036570707, 0.06313812100709296, 0.0613442828291667, 0.05953642101157633, 0.05771698645431281, 0.055888445746413266, 0.05405327782203121, 0.05221397059977054, 0.050373017609839456, 0.04853291461359672, 0.046696156220073254, 0.04486523250405594, 0.043042625630318236, 0.041230806488574696, 0.03943223134372062, 0.03764933850589858, 0.035884545024906074, 0.03414024341342548, 0.03241879840351887, 0.030722543740784536, 0.029053779020521798, 0.02741476657019288, 0.02580772838240838, 0.024234843102594335, 0.0226982430754248, 0.02120001145402356, 0.019742179375854495, 0.01832672320912924, 0.01695556187346452, 0.01563055423842246, 0.014353496603459769, 0.013126120262702705, 0.011950089157849286, 0.01082699762238018, 0.00975836822013701, 0.00874564968119793, 0.0077902149378488985, 0.006893359263313258, 0.006056298515762914, 0.005280167489991715, 0.0045660183789856135, 0.003914819347475267, 0.003327453219404918, 0.0028047162810968633, 0.0023473172017341773, 0.0019558760726250336, 0.0016309235665512003, 0.0013729002183403053, 0.001182155827637237, 0.0010589489846842873, 0.0010034467197529919, 0, 0, 0, 0]
module.fire9.expand_1x1.1.weight
[0.1, 0.10096651078232374, 0.10086608799040298, 0.10069886614746724, 0.10046506925866446, 0.10016501051099069, 0.09979909185375457, 0.09936780346013871, 0.09887172307057886, 0.09831151521884107, 0.09768793034183298, 0.09700180377434203, 0.09625405463004708, 0.09544568457030256, 0.09457777646234422, 0.0936514929287141, 0.09266807478984768, 0.09162883940190973, 0.09053517889210522, 0.08938855829382919, 0.08819051358415396, 0.08694264962628225, 0.0856466380197227, 0.08430421486106743, 0.08291717841837139, 0.08148738672224874, 0.08001675507691322, 0.07850725349449653, 0.07696090405608169, 0.07537977820298658, 0.07376599396192593, 0.07212171310776898, 0.07044913826769356, 0.06875050997061564, 0.06702810364584688, 0.06528422657500081, 0.06352121480123045, 0.061741429999938084, 0.059947256315148835, 0.05814109716578585, 0.05632537202612558, 0.05450251318474571, 0.052674962486307486, 0.05084516806053716, 0.04901558104278779, 0.047188652290575166, 0.045366829100485784, 0.04355255192985484, 0.04174825112760607, 0.039956343678632246, 0.038179229966077935, 0.03641929055586137, 0.034678883007742745, 0.03296033871721108, 0.031265959792419626, 0.029598015970353914, 0.027958741576363133, 0.02635033253112772, 0.024774943409072776, 0.023234684552167702, 0.021731619242977913, 0.02026776094075627, 0.018845070584275998, 0.017465453965018418, 0.016130759174234476, 0.01484277412729933, 0.013603224168677003, 0.012413769760702915, 0.011276004259280409, 0.010191451779471204, 0.009161565153838373, 0.008187723986277429, 0.00727123280394209, 0.006413319309740478, 0.005615132737742789, 0.00487774231370327, 0.004202135822758828, 0.0035892182862230166, 0.0030398107492477836, 0.0025546491809770805, 0.00213438348866563, 0.001779576647083491, 0.0014907039443727002, 0.0012681523453661183, 0.0011122199732214945, 0.0010231157100649636, 0, 0, 0, 0]
module.fire9.expand_1x1.1.bias
[0.1, 0.10096690823204053, 0.10086767673076641, 0.10070243684601017, 0.10047140730096882, 0.10017489390268618, 0.09981328913726517, 0.09938707165034542, 0.09889680561353402, 0.0983431399776281, 0.09772680761361768, 0.0970486243426058, 0.09630948785593, 0.09551037652691458, 0.09465234811582646, 0.09373653836974893, 0.09276415951922652, 0.0917364986736708, 0.09065491611765147, 0.08952084351032745, 0.08833578199040155, 0.08710130018910718, 0.08581903215385711, 0.08449067518530268, 0.08311798759066673, 0.08170278635632376, 0.08024694474270828, 0.07875238980473487, 0.07722109984101187, 0.07565510177522565, 0.07405646847316091, 0.07242731599890903, 0.07076980081389594, 0.06908611692243731, 0.0673784929675993, 0.0656491892812089, 0.06390049489191897, 0.06213472449528801, 0.06035421538988544, 0.058561324383477845, 0.0567584246733917, 0.054947902705181385, 0.05313215501376121, 0.05131358505118229, 0.049494600005253395, 0.04767760761321698, 0.04586501297469792, 0.0440592153681435, 0.042262605074968866, 0.04047756021561139, 0.0387064436016824, 0.036951599608382624, 0.03521535107132127, 0.033499996211846704, 0.03180780559495805, 0.030141019123824764, 0.028501843074892497, 0.02689244717749949, 0.025314961741869386, 0.023771474839282006, 0.022264029538154526, 0.02079462119969156, 0.01936519483668411, 0.01797764253895295, 0.01663380096884483, 0.015335448930096206, 0.014084305013282943, 0.012882025320972205, 0.011730201275587986, 0.010630357512891903, 0.00958394986386743, 0.008592363427679044, 0.007656910738257094, 0.006778830026934989, 0.005959283583438673, 0.00519935621739776, 0.004500053822414778, 0.003862302044593246, 0.0032869450572870656, 0.0027747444436929496, 0.0023263781887650483, 0.0019424397817861196, 0.0016234374307831415, 0.0013697933898272222, 0.0011818434001082837, 0.0010598362455242196, 0.0010039334233729982, 0, 0, 0]
module.fire9.expand_3x3.0.weight
[0.1, 0.10096730018997241, 0.10086924353099268, 0.10070595828042561, 0.10047765801413816, 0.10018464134714383, 0.09982729154301641, 0.09940607601258426, 0.0989215457025604, 0.09837433437490845, 0.09776515777788677, 0.0970948127098552, 0.09636417597706887, 0.09557420324682217, 0.09472592779744339, 0.09382045916677435, 0.0928589817009034, 0.09184275300504972, 0.09077310229862529, 0.08965142867662593, 0.08847919927962575, 0.08725794737476836, 0.08598927035026516, 0.08467482762602366, 0.08331633848313885, 0.08191557981508657, 0.08047438380356048, 0.0789946355219921, 0.0774782704698893, 0.0759272720412175, 0.07434366893013555, 0.07272953247747911, 0.07108697396146259, 0.0694181418361433, 0.06772521892125988, 0.06601041954712068, 0.06427598665827645, 0.06252418887976605, 0.06075731754977203, 0.05897768372256776, 0.057187615145675955, 0.055389453215192654, 0.05358554991325886, 0.051778264731685876, 0.0499699615857578, 0.04816300572224838, 0.046359760625696245, 0.044562584926985, 0.04277382931827201, 0.04099583347830091, 0.03923092301211954, 0.03748140640920635, 0.03574957202398351, 0.03403768508266689, 0.03234798472036727, 0.030682681052318667, 0.029043952283064434, 0.027433941857382238, 0.02585475565667454, 0.024308459244491806, 0.02279707516479104, 0.021322580296463608, 0.019886903267592765, 0.018491921932822713, 0.017139460917139034, 0.015831289229272995, 0.014569117947851672, 0.01335459798332007, 0.01218931791856278, 0.01107480193104967, 0.010012507799223296, 0.009003824995735831, 0.008050072870029379, 0.007152498922636868, 0.006312277173460934, 0.0055305066261647435, 0.004808209830683568, 0.00414633154573723, 0.003545737503092893, 0.0030072132751944973, 0.0025314632476399358, 0.002119109697850068, 0.0017706919811346024, 0.0014866658252193957, 0.0012674027341581175, 0.0011131895024077067, 0.0010242278397034445, 0, 0, 0]
module.fire9.expand_3x3.0.bias
[0.1, 0.10096768674266186, 0.10087078873651144, 0.10070943122515706, 0.10048382276807022, 0.10019425497101622, 0.09984110210914475, 0.09942482064322802, 0.09894594862967139, 0.09840510502505909, 0.09780298888613413, 0.09714037846624629, 0.09641813020943611, 0.09563717764345492, 0.0947985301731521, 0.0939032717757886, 0.0929525595999635, 0.09194762246996452, 0.09088975929747525, 0.08978033740269258, 0.08862079074702377, 0.08741261807964802, 0.08615738100033778, 0.08485670194104356, 0.08351226206885169, 0.08212579911302477, 0.08069910511893408, 0.07923402413178658, 0.0777324498131406, 0.07619632299329099, 0.07462762916268709, 0.07302839590562622, 0.07140069027953956, 0.06974661614325776, 0.06806831143770971, 0.06636794542256909, 0.06464771587242055, 0.06290984623606946, 0.06115658276266705, 0.059390191598365165, 0.05761295585725393, 0.055827172670367436, 0.054035150216572396, 0.052239204739177064, 0.050441657552116465, 0.04864483203958389, 0.046851050652986524, 0.04506263190910645, 0.04328188739334768, 0.04151111877194186, 0.039752614816974945, 0.03800864844808006, 0.036281473794619865, 0.03457332328215618, 0.03288640474697226, 0.031222898582377534, 0.02958495492048323, 0.027974690853091413, 0.026394187695289745, 0.024845488295288744, 0.02333059439397845, 0.021851464037617764, 0.0204100090470004, 0.019008092546368444, 0.01764752655526799, 0.01633006964645886, 0.015057424672906106, 0.013831236566790944, 0.012653090213386082, 0.011524508402543522, 0.010446949860442489, 0.009421807364141683, 0.008450405941372785, 0.007534001157901876, 0.0066737774946727165, 0.005870846816829261, 0.005126246936596212, 0.004440940271875315, 0.003815812602291096, 0.0032516719242938023, 0.002749247406799559, 0.002309188448717436, 0.0019320638395816927, 0.001618361024374059, 0.0013684854734863797, 0.0011827601586377736, 0.0010614251354239537, 0.0010046372330381017, 0, 0]
module.fire9.expand_3x3.1.weight
[0.1, 0.10096806797512041, 0.10087231268665012, 0.1007128564409993, 0.10048990290860008, 0.10020373686376219, 0.09985472382093617, 0.09944330956784873, 0.09897001959610643, 0.09843545842999545, 0.09784030885433398, 0.09718533104236429, 0.09647136158479792, 0.09569931242125417, 0.09487016967545693, 0.09398499239567774, 0.09304491120203341, 0.09205112684236653, 0.091004908658553, 0.08990759296519583, 0.08876058134277585, 0.08756533884743965, 0.08632339213971114, 0.08503632753451716, 0.08370578897501747, 0.0823334759328275, 0.08092114123731545, 0.07947058883674679, 0.07798367149413521, 0.07646228842074393, 0.0749083828502589, 0.07332393955673368, 0.07171098231947498, 0.07007157133810803, 0.06840780060112261, 0.06672179521126145, 0.06501570867116675, 0.06329172013275233, 0.06155203161381423, 0.05979886518543523, 0.05803446013377567, 0.05626107009987588, 0.05448096020112317, 0.052696404138060586, 0.050909681290232295, 0.04912307380477549, 0.04733886368147724, 0.04555932985801939, 0.04378674529913497, 0.04202337409339338, 0.04027146856132318, 0.038533266378565835, 0.03681098771773516, 0.03510683241263307, 0.033422977148443604, 0.031761572681494335, 0.030124741092136222, 0.028514573074250683, 0.02693312526484598, 0.025382417617153992, 0.023864430820582167, 0.0223811037708167, 0.020934331093307935, 0.01952596072330116, 0.018157791545504214, 0.016831571096406046, 0.015548993332181738, 0.014311696465034395, 0.013121260870737794, 0.011979207070052546, 0.010886993786593736, 0.009846016083630994, 0.008857603582200752, 0.007923018762806478, 0.00704345535287636, 0.006220036802037986, 0.0054538148471574, 0.004745768168975672, 0.004096801142058558, 0.003507742679656028, 0.002979345174947167, 0.0025122835400226465, 0.0021071543438323176, 0.001764475050199076, 0.0014846833568721344, 0.0012681366364639837, 0.0011151114799851638, 0.0010258033435598325, 0, 0]
module.fire9.expand_3x3.1.bias
[0.1, 0.10096844397085858, 0.10087381571475333, 0.10071623467536453, 0.10049589975796702, 0.10021308907836379, 0.09986815961183673, 0.0994615467425577, 0.09899376371402882, 0.09846540098124529, 0.0978771254653988, 0.09722967971206226, 0.096523880953918, 0.09576062007921325, 0.09494086050724418, 0.0940656369722885, 0.09313605421752115, 0.09215328560056212, 0.091118571612416, 0.09003321831167335, 0.08889859567594965, 0.08771613587264315, 0.08648733145119439, 0.0852137334591286, 0.08389694948425988, 0.0825386416255276, 0.0811405243950267, 0.0797043625538799, 0.07823196888468364, 0.07672520190333927, 0.07518596351315768, 0.07361619660419869, 0.07201788260087527, 0.07039303896091811, 0.0687437166288573, 0.06707199744723578, 0.06537999152882204, 0.0636698345931388, 0.06194368527067007, 0.060203722378148694, 0.05845214216836434, 0.05669115555796275, 0.05492298533673573, 0.05314986336192445, 0.05137402774107719, 0.04959772000701804, 0.047823182288491806, 0.046052654480056826, 0.044288371414797856, 0.04253256004342773, 0.0407874366233385, 0.03905520392115018, 0.03733804843228796, 0.03563813762109772, 0.033957617184983295, 0.032298608346018845, 0.030663205173455128, 0.029053471940499006, 0.027471440518702806, 0.025919107813252525, 0.02439843324239176, 0.022911336264163397, 0.021459693953590715, 0.02004533863335589, 0.01867005556096702, 0.01733558067533251, 0.016043598405587507, 0.014795739544938225, 0.013593579192207467, 0.012438634763680196, 0.011332364077758138, 0.010276163514841414, 0.009271366254759737, 0.008319240593977918, 0.007420988344699868, 0.006577743317891787, 0.005790569892139241, 0.005060461670144711, 0.004388340224561398, 0.00377505393474623, 0.0032213769159005583, 0.0027280080419500355, 0.0022955700633972113, 0.00192460882126022, 0.0016155925580897392, 0.0013689113269340183, 0.001184876498997799, 0.0010637203706168265, 0.001005595870043812, 0]
module.conv10.weight
[0.1, 0.10096881481191539, 0.10087529814829976, 0.10071956666254292, 0.10050181461527177, 0.10022231363202834, 0.09988141236444192, 0.09947953605531844, 0.09901718600818935, 0.09849493896198187, 0.09791344637159054, 0.09727343359524737, 0.09657569898970464, 0.09582111291435864, 0.09501061664555681, 0.09414522120244251, 0.09322600608580217, 0.09225411793148793, 0.09123076908009534, 0.0901572360646807, 0.08903485801840401, 0.08786503500408432, 0.08664922626775068, 0.0853889484183678, 0.08408577353600658, 0.08274132721081952, 0.08135728651526748, 0.07993537791212675, 0.07847737510088647, 0.07698509680522246, 0.07546040450430773, 0.07390520011078931, 0.07232142359832806, 0.07071105058166098, 0.06907608985220452, 0.06741858087227305, 0.06574059123103819, 0.06404421406540262, 0.06233156544900521, 0.060604781752614995, 0.058866016979206084, 0.057117440077038256, 0.05536123223409445, 0.053599584157250635, 0.051834693339571386, 0.05006876131914063, 0.04830399093284645, 0.04654258356854574, 0.0447867364190365, 0.04303863974126292, 0.041300474124172454, 0.03957440776863278, 0.03786259378280162, 0.03616716749632356, 0.0344902437967037, 0.03283391449118107, 0.0312002456973926, 0.029591275266082375, 0.028009010239071288, 0.026455424345658042, 0.024932455540574328, 0.02344200358656545, 0.021985927684612112, 0.020566044154749004, 0.01918412417037363, 0.017841891548871208, 0.016541020601311913, 0.015283134043902698, 0.01406980097379884, 0.012902534911800372, 0.01178279191437482, 0.010711968757361395, 0.009691401193622412, 0.008722362286814977, 0.007806060823361893, 0.006943639804602369, 0.0061361750210035424, 0.005384673710211318, 0.004690073300614627, 0.004053240241990141, 0.003474968924686333, 0.002955980688694964, 0.002496922923846145, 0.002098368262249433, 0.0017608138639881746, 0.0014846807969583257, 0.0012703135116251365, 0.0011179794113531142, 0.0010278685188449923, 0]
module.conv10.bias
[0.1, 0.10096918057888697, 0.10087676030901657, 0.10072285312395748, 0.10050764875692363, 0.10023141250687553, 0.0998944849114659, 0.0994972813272326, 0.09904029141755682, 0.09852407854901746, 0.09794927909688562, 0.09731660166061618, 0.0966268261903026, 0.09588080302517263, 0.09507945184530969, 0.09422376053789266, 0.09331478397935136, 0.0923536427349394, 0.09134152167732722, 0.09027966852591844, 0.08916939230869043, 0.08801206174845483, 0.08680910357552774, 0.08556200076888965, 0.08427229072800335, 0.08294156337754338, 0.08157145920737377, 0.08016366725019008, 0.07871992299931901, 0.07724200626924248, 0.07573173900148343, 0.07419098301855863, 0.07262163772876683, 0.07102563778464238, 0.06940495069796025, 0.06776157441423314, 0.06609753484969041, 0.06441488339377564, 0.06271569438024108, 0.061002062529957046, 0.05927610036858865, 0.057539935622322916, 0.0557957085948573, 0.05404556952888289, 0.05229167595531491, 0.05053619003353855, 0.04878127588594914, 0.047029096930071894, 0.0452818132115511, 0.04354157874129575, 0.04181053884006482, 0.04009082749376549, 0.038384564722724716, 0.03669385396817735, 0.035020779499192356, 0.03336740384323424, 0.031735765243527, 0.03012787514635496, 0.028545715721398458, 0.026991237418160913, 0.025466356561499877, 0.023972952989226082, 0.02251286773468297, 0.02108790075716334, 0.019699808722961315, 0.018350302839794726, 0.01704104674726787, 0.015773654465975163, 0.014549688407773903, 0.013370657449679146, 0.012238015073755, 0.011153157575295593, 0.010117422341504662, 0.00913208620279548, 0.008198363858743906, 0.007317406380634905, 0.0064902997924484946, 0.005718063732034539, 0.0050016501941268325, 0.004341942356746003, 0.0037397534924381243, 0.0031958259656911397, 0.002710830317765122, 0.0022853644400645293, 0.0019199528370715249, 0.0016150459797490016, 0.0013710197502103997, 0.0011881749783409492, 0.0010667370709415472, 0.00100685573385249]
*** Model named parameters and requires_grad:
name:           module.stem.0.weight  req_grad:  True 
name:             module.stem.0.bias  req_grad:  True 
name:           module.stem.1.weight  req_grad:  True 
name:             module.stem.1.bias  req_grad:  True 
name:  module.fire2.squeeze.0.weight  req_grad:  True 
name:    module.fire2.squeeze.0.bias  req_grad:  True 
name:  module.fire2.squeeze.1.weight  req_grad:  True 
name:    module.fire2.squeeze.1.bias  req_grad:  True 
name: module.fire2.expand_1x1.0.weight  req_grad:  True 
name: module.fire2.expand_1x1.0.bias  req_grad:  True 
name: module.fire2.expand_1x1.1.weight  req_grad:  True 
name: module.fire2.expand_1x1.1.bias  req_grad:  True 
name: module.fire2.expand_3x3.0.weight  req_grad:  True 
name: module.fire2.expand_3x3.0.bias  req_grad:  True 
name: module.fire2.expand_3x3.1.weight  req_grad:  True 
name: module.fire2.expand_3x3.1.bias  req_grad:  True 
name:  module.fire3.squeeze.0.weight  req_grad:  True 
name:    module.fire3.squeeze.0.bias  req_grad:  True 
name:  module.fire3.squeeze.1.weight  req_grad:  True 
name:    module.fire3.squeeze.1.bias  req_grad:  True 
name: module.fire3.expand_1x1.0.weight  req_grad:  True 
name: module.fire3.expand_1x1.0.bias  req_grad:  True 
name: module.fire3.expand_1x1.1.weight  req_grad:  True 
name: module.fire3.expand_1x1.1.bias  req_grad:  True 
name: module.fire3.expand_3x3.0.weight  req_grad:  True 
name: module.fire3.expand_3x3.0.bias  req_grad:  True 
name: module.fire3.expand_3x3.1.weight  req_grad:  True 
name: module.fire3.expand_3x3.1.bias  req_grad:  True 
name:  module.fire4.squeeze.0.weight  req_grad:  True 
name:    module.fire4.squeeze.0.bias  req_grad:  True 
name:  module.fire4.squeeze.1.weight  req_grad:  True 
name:    module.fire4.squeeze.1.bias  req_grad:  True 
name: module.fire4.expand_1x1.0.weight  req_grad:  True 
name: module.fire4.expand_1x1.0.bias  req_grad:  True 
name: module.fire4.expand_1x1.1.weight  req_grad:  True 
name: module.fire4.expand_1x1.1.bias  req_grad:  True 
name: module.fire4.expand_3x3.0.weight  req_grad:  True 
name: module.fire4.expand_3x3.0.bias  req_grad:  True 
name: module.fire4.expand_3x3.1.weight  req_grad:  True 
name: module.fire4.expand_3x3.1.bias  req_grad:  True 
name:  module.fire5.squeeze.0.weight  req_grad:  True 
name:    module.fire5.squeeze.0.bias  req_grad:  True 
name:  module.fire5.squeeze.1.weight  req_grad:  True 
name:    module.fire5.squeeze.1.bias  req_grad:  True 
name: module.fire5.expand_1x1.0.weight  req_grad:  True 
name: module.fire5.expand_1x1.0.bias  req_grad:  True 
name: module.fire5.expand_1x1.1.weight  req_grad:  True 
name: module.fire5.expand_1x1.1.bias  req_grad:  True 
name: module.fire5.expand_3x3.0.weight  req_grad:  True 
name: module.fire5.expand_3x3.0.bias  req_grad:  True 
name: module.fire5.expand_3x3.1.weight  req_grad:  True 
name: module.fire5.expand_3x3.1.bias  req_grad:  True 
name:  module.fire6.squeeze.0.weight  req_grad:  True 
name:    module.fire6.squeeze.0.bias  req_grad:  True 
name:  module.fire6.squeeze.1.weight  req_grad:  True 
name:    module.fire6.squeeze.1.bias  req_grad:  True 
name: module.fire6.expand_1x1.0.weight  req_grad:  True 
name: module.fire6.expand_1x1.0.bias  req_grad:  True 
name: module.fire6.expand_1x1.1.weight  req_grad:  True 
name: module.fire6.expand_1x1.1.bias  req_grad:  True 
name: module.fire6.expand_3x3.0.weight  req_grad:  True 
name: module.fire6.expand_3x3.0.bias  req_grad:  True 
name: module.fire6.expand_3x3.1.weight  req_grad:  True 
name: module.fire6.expand_3x3.1.bias  req_grad:  True 
name:  module.fire7.squeeze.0.weight  req_grad:  True 
name:    module.fire7.squeeze.0.bias  req_grad:  True 
name:  module.fire7.squeeze.1.weight  req_grad:  True 
name:    module.fire7.squeeze.1.bias  req_grad:  True 
name: module.fire7.expand_1x1.0.weight  req_grad:  True 
name: module.fire7.expand_1x1.0.bias  req_grad:  True 
name: module.fire7.expand_1x1.1.weight  req_grad:  True 
name: module.fire7.expand_1x1.1.bias  req_grad:  True 
name: module.fire7.expand_3x3.0.weight  req_grad:  True 
name: module.fire7.expand_3x3.0.bias  req_grad:  True 
name: module.fire7.expand_3x3.1.weight  req_grad:  True 
name: module.fire7.expand_3x3.1.bias  req_grad:  True 
name:  module.fire8.squeeze.0.weight  req_grad:  True 
name:    module.fire8.squeeze.0.bias  req_grad:  True 
name:  module.fire8.squeeze.1.weight  req_grad:  True 
name:    module.fire8.squeeze.1.bias  req_grad:  True 
name: module.fire8.expand_1x1.0.weight  req_grad:  True 
name: module.fire8.expand_1x1.0.bias  req_grad:  True 
name: module.fire8.expand_1x1.1.weight  req_grad:  True 
name: module.fire8.expand_1x1.1.bias  req_grad:  True 
name: module.fire8.expand_3x3.0.weight  req_grad:  True 
name: module.fire8.expand_3x3.0.bias  req_grad:  True 
name: module.fire8.expand_3x3.1.weight  req_grad:  True 
name: module.fire8.expand_3x3.1.bias  req_grad:  True 
name:  module.fire9.squeeze.0.weight  req_grad:  True 
name:    module.fire9.squeeze.0.bias  req_grad:  True 
name:  module.fire9.squeeze.1.weight  req_grad:  True 
name:    module.fire9.squeeze.1.bias  req_grad:  True 
name: module.fire9.expand_1x1.0.weight  req_grad:  True 
name: module.fire9.expand_1x1.0.bias  req_grad:  True 
name: module.fire9.expand_1x1.1.weight  req_grad:  True 
name: module.fire9.expand_1x1.1.bias  req_grad:  True 
name: module.fire9.expand_3x3.0.weight  req_grad:  True 
name: module.fire9.expand_3x3.0.bias  req_grad:  True 
name: module.fire9.expand_3x3.1.weight  req_grad:  True 
name: module.fire9.expand_3x3.1.bias  req_grad:  True 
name:           module.conv10.weight  req_grad:  True 
name:             module.conv10.bias  req_grad:  True 


*** Optimizer groups, parameters and req_grads
#        requires_grad:                            True
#           param_name:            module.stem.0.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:              module.stem.0.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:            module.stem.1.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:              module.stem.1.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:   module.fire2.squeeze.0.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:     module.fire2.squeeze.0.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:   module.fire2.squeeze.1.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:     module.fire2.squeeze.1.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire2.expand_1x1.0.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire2.expand_1x1.0.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire2.expand_1x1.1.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire2.expand_1x1.1.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire2.expand_3x3.0.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire2.expand_3x3.0.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire2.expand_3x3.1.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire2.expand_3x3.1.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:   module.fire3.squeeze.0.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:     module.fire3.squeeze.0.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:   module.fire3.squeeze.1.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:     module.fire3.squeeze.1.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire3.expand_1x1.0.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire3.expand_1x1.0.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire3.expand_1x1.1.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire3.expand_1x1.1.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire3.expand_3x3.0.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire3.expand_3x3.0.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire3.expand_3x3.1.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire3.expand_3x3.1.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:   module.fire4.squeeze.0.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:     module.fire4.squeeze.0.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:   module.fire4.squeeze.1.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:     module.fire4.squeeze.1.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire4.expand_1x1.0.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire4.expand_1x1.0.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire4.expand_1x1.1.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire4.expand_1x1.1.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire4.expand_3x3.0.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire4.expand_3x3.0.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire4.expand_3x3.1.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire4.expand_3x3.1.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:   module.fire5.squeeze.0.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:     module.fire5.squeeze.0.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:   module.fire5.squeeze.1.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:     module.fire5.squeeze.1.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire5.expand_1x1.0.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire5.expand_1x1.0.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire5.expand_1x1.1.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire5.expand_1x1.1.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire5.expand_3x3.0.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire5.expand_3x3.0.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire5.expand_3x3.1.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire5.expand_3x3.1.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:   module.fire6.squeeze.0.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:     module.fire6.squeeze.0.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:   module.fire6.squeeze.1.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:     module.fire6.squeeze.1.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire6.expand_1x1.0.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire6.expand_1x1.0.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire6.expand_1x1.1.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire6.expand_1x1.1.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire6.expand_3x3.0.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire6.expand_3x3.0.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire6.expand_3x3.1.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire6.expand_3x3.1.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:   module.fire7.squeeze.0.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:     module.fire7.squeeze.0.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:   module.fire7.squeeze.1.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:     module.fire7.squeeze.1.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire7.expand_1x1.0.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire7.expand_1x1.0.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire7.expand_1x1.1.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire7.expand_1x1.1.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire7.expand_3x3.0.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire7.expand_3x3.0.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire7.expand_3x3.1.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire7.expand_3x3.1.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:   module.fire8.squeeze.0.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:     module.fire8.squeeze.0.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:   module.fire8.squeeze.1.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:     module.fire8.squeeze.1.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire8.expand_1x1.0.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire8.expand_1x1.0.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire8.expand_1x1.1.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire8.expand_1x1.1.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire8.expand_3x3.0.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire8.expand_3x3.0.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire8.expand_3x3.1.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire8.expand_3x3.1.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:   module.fire9.squeeze.0.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:     module.fire9.squeeze.0.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:   module.fire9.squeeze.1.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:     module.fire9.squeeze.1.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire9.expand_1x1.0.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire9.expand_1x1.0.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire9.expand_1x1.1.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire9.expand_1x1.1.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire9.expand_3x3.0.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire9.expand_3x3.0.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire9.expand_3x3.1.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:  module.fire9.expand_3x3.1.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:            module.conv10.weight
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False

#        requires_grad:                            True
#           param_name:              module.conv10.bias
#                   lr:                             0.1
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False



*** Optimizer group lrs
# group:  0,   name:           module.stem.0.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group:  1,   name:             module.stem.0.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group:  2,   name:           module.stem.1.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group:  3,   name:             module.stem.1.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group:  4,   name:  module.fire2.squeeze.0.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group:  5,   name:    module.fire2.squeeze.0.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group:  6,   name:  module.fire2.squeeze.1.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group:  7,   name:    module.fire2.squeeze.1.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group:  8,   name: module.fire2.expand_1x1.0.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group:  9,   name: module.fire2.expand_1x1.0.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 10,   name: module.fire2.expand_1x1.1.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 11,   name: module.fire2.expand_1x1.1.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 12,   name: module.fire2.expand_3x3.0.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 13,   name: module.fire2.expand_3x3.0.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 14,   name: module.fire2.expand_3x3.1.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 15,   name: module.fire2.expand_3x3.1.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 16,   name:  module.fire3.squeeze.0.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 17,   name:    module.fire3.squeeze.0.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 18,   name:  module.fire3.squeeze.1.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 19,   name:    module.fire3.squeeze.1.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 20,   name: module.fire3.expand_1x1.0.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 21,   name: module.fire3.expand_1x1.0.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 22,   name: module.fire3.expand_1x1.1.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 23,   name: module.fire3.expand_1x1.1.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 24,   name: module.fire3.expand_3x3.0.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 25,   name: module.fire3.expand_3x3.0.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 26,   name: module.fire3.expand_3x3.1.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 27,   name: module.fire3.expand_3x3.1.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 28,   name:  module.fire4.squeeze.0.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 29,   name:    module.fire4.squeeze.0.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 30,   name:  module.fire4.squeeze.1.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 31,   name:    module.fire4.squeeze.1.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 32,   name: module.fire4.expand_1x1.0.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 33,   name: module.fire4.expand_1x1.0.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 34,   name: module.fire4.expand_1x1.1.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 35,   name: module.fire4.expand_1x1.1.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 36,   name: module.fire4.expand_3x3.0.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 37,   name: module.fire4.expand_3x3.0.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 38,   name: module.fire4.expand_3x3.1.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 39,   name: module.fire4.expand_3x3.1.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 40,   name:  module.fire5.squeeze.0.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 41,   name:    module.fire5.squeeze.0.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 42,   name:  module.fire5.squeeze.1.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 43,   name:    module.fire5.squeeze.1.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 44,   name: module.fire5.expand_1x1.0.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 45,   name: module.fire5.expand_1x1.0.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 46,   name: module.fire5.expand_1x1.1.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 47,   name: module.fire5.expand_1x1.1.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 48,   name: module.fire5.expand_3x3.0.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 49,   name: module.fire5.expand_3x3.0.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 50,   name: module.fire5.expand_3x3.1.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 51,   name: module.fire5.expand_3x3.1.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 52,   name:  module.fire6.squeeze.0.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 53,   name:    module.fire6.squeeze.0.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 54,   name:  module.fire6.squeeze.1.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 55,   name:    module.fire6.squeeze.1.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 56,   name: module.fire6.expand_1x1.0.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 57,   name: module.fire6.expand_1x1.0.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 58,   name: module.fire6.expand_1x1.1.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 59,   name: module.fire6.expand_1x1.1.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 60,   name: module.fire6.expand_3x3.0.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 61,   name: module.fire6.expand_3x3.0.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 62,   name: module.fire6.expand_3x3.1.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 63,   name: module.fire6.expand_3x3.1.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 64,   name:  module.fire7.squeeze.0.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 65,   name:    module.fire7.squeeze.0.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 66,   name:  module.fire7.squeeze.1.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 67,   name:    module.fire7.squeeze.1.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 68,   name: module.fire7.expand_1x1.0.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 69,   name: module.fire7.expand_1x1.0.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 70,   name: module.fire7.expand_1x1.1.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 71,   name: module.fire7.expand_1x1.1.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 72,   name: module.fire7.expand_3x3.0.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 73,   name: module.fire7.expand_3x3.0.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 74,   name: module.fire7.expand_3x3.1.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 75,   name: module.fire7.expand_3x3.1.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 76,   name:  module.fire8.squeeze.0.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 77,   name:    module.fire8.squeeze.0.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 78,   name:  module.fire8.squeeze.1.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 79,   name:    module.fire8.squeeze.1.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 80,   name: module.fire8.expand_1x1.0.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 81,   name: module.fire8.expand_1x1.0.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 82,   name: module.fire8.expand_1x1.1.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 83,   name: module.fire8.expand_1x1.1.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 84,   name: module.fire8.expand_3x3.0.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 85,   name: module.fire8.expand_3x3.0.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 86,   name: module.fire8.expand_3x3.1.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 87,   name: module.fire8.expand_3x3.1.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 88,   name:  module.fire9.squeeze.0.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 89,   name:    module.fire9.squeeze.0.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 90,   name:  module.fire9.squeeze.1.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 91,   name:    module.fire9.squeeze.1.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 92,   name: module.fire9.expand_1x1.0.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 93,   name: module.fire9.expand_1x1.0.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 94,   name: module.fire9.expand_1x1.1.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 95,   name: module.fire9.expand_1x1.1.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 96,   name: module.fire9.expand_3x3.0.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 97,   name: module.fire9.expand_3x3.0.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 98,   name: module.fire9.expand_3x3.1.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 99,   name: module.fire9.expand_3x3.1.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 100,   name:           module.conv10.weight,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
# group: 101,   name:             module.conv10.bias,   req_grad:   True   lr: 0.100000000000000006,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
---------------
# Model: squeezenet
# Dataset: cifardecem
# Freezeout: True
# Low precision: False
# Initial learning rate: 0.1
# Criterion: CrossEntropyLoss()
# Optimizer: SGD
#	param_name module.stem.0.weight
#	lr 0.1
#	momentum 0.9
#	weight_decay 0.0001
#	dampening 0
#	nesterov False
CIFAR10 loading and normalization
==> Preparing data..
# CIFAR10 / full precision
Files already downloaded and verified
Files already downloaded and verified
#--> Training data: <--#
#-->>
EPOCH 0
i:   0, name:           module.stem.0.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:   1, name:             module.stem.0.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:   2, name:           module.stem.1.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:   3, name:             module.stem.1.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i: 100, name:           module.conv10.weight  changing lr from: 0.100000000000000006   to: 0.100000000000000006
i: 101, name:             module.conv10.bias  changing lr from: 0.100000000000000006   to: 0.100000000000000006



# Switched to train mode...
Epoch: [0][  0/391]	Time  3.299 ( 3.299)	Data  0.121 ( 0.121)	Loss 2.2470e+00 (2.2470e+00)	Acc@1  20.31 ( 20.31)	Acc@5  64.06 ( 64.06)
Epoch: [0][ 10/391]	Time  0.042 ( 0.338)	Data  0.001 ( 0.012)	Loss 2.1400e+00 (2.2635e+00)	Acc@1  25.00 ( 18.39)	Acc@5  75.78 ( 63.42)
Epoch: [0][ 20/391]	Time  0.039 ( 0.196)	Data  0.001 ( 0.007)	Loss 2.3298e+00 (2.2011e+00)	Acc@1  14.84 ( 20.13)	Acc@5  75.00 ( 69.90)
Epoch: [0][ 30/391]	Time  0.039 ( 0.146)	Data  0.001 ( 0.005)	Loss 1.8564e+00 (2.1369e+00)	Acc@1  34.38 ( 22.53)	Acc@5  82.81 ( 73.54)
Epoch: [0][ 40/391]	Time  0.037 ( 0.120)	Data  0.001 ( 0.004)	Loss 2.0337e+00 (2.1111e+00)	Acc@1  30.47 ( 23.40)	Acc@5  77.34 ( 75.04)
Epoch: [0][ 50/391]	Time  0.039 ( 0.104)	Data  0.001 ( 0.003)	Loss 1.8182e+00 (2.0697e+00)	Acc@1  33.59 ( 24.74)	Acc@5  89.84 ( 76.72)
Epoch: [0][ 60/391]	Time  0.043 ( 0.094)	Data  0.001 ( 0.003)	Loss 1.8070e+00 (2.0528e+00)	Acc@1  41.41 ( 25.73)	Acc@5  83.59 ( 77.88)
Epoch: [0][ 70/391]	Time  0.042 ( 0.087)	Data  0.001 ( 0.003)	Loss 1.8206e+00 (2.0298e+00)	Acc@1  32.03 ( 26.72)	Acc@5  83.59 ( 78.70)
Epoch: [0][ 80/391]	Time  0.038 ( 0.081)	Data  0.001 ( 0.003)	Loss 1.9351e+00 (2.0006e+00)	Acc@1  32.03 ( 27.41)	Acc@5  82.81 ( 79.52)
Epoch: [0][ 90/391]	Time  0.040 ( 0.077)	Data  0.001 ( 0.002)	Loss 1.8744e+00 (1.9702e+00)	Acc@1  33.59 ( 28.29)	Acc@5  83.59 ( 80.36)
Epoch: [0][100/391]	Time  0.042 ( 0.073)	Data  0.001 ( 0.002)	Loss 1.5866e+00 (1.9473e+00)	Acc@1  35.16 ( 28.94)	Acc@5  91.41 ( 80.93)
Epoch: [0][110/391]	Time  0.039 ( 0.070)	Data  0.001 ( 0.002)	Loss 1.7158e+00 (1.9252e+00)	Acc@1  36.72 ( 29.57)	Acc@5  83.59 ( 81.51)
Epoch: [0][120/391]	Time  0.041 ( 0.068)	Data  0.002 ( 0.002)	Loss 1.7429e+00 (1.8994e+00)	Acc@1  34.38 ( 30.46)	Acc@5  89.84 ( 82.29)
Epoch: [0][130/391]	Time  0.040 ( 0.065)	Data  0.001 ( 0.002)	Loss 1.5929e+00 (1.8760e+00)	Acc@1  40.62 ( 31.28)	Acc@5  92.97 ( 82.98)
Epoch: [0][140/391]	Time  0.037 ( 0.064)	Data  0.001 ( 0.002)	Loss 1.6182e+00 (1.8600e+00)	Acc@1  37.50 ( 31.84)	Acc@5  89.06 ( 83.45)
Epoch: [0][150/391]	Time  0.041 ( 0.062)	Data  0.001 ( 0.002)	Loss 1.4860e+00 (1.8403e+00)	Acc@1  47.66 ( 32.43)	Acc@5  92.19 ( 83.96)
Epoch: [0][160/391]	Time  0.042 ( 0.061)	Data  0.001 ( 0.002)	Loss 1.6937e+00 (1.8253e+00)	Acc@1  39.84 ( 32.82)	Acc@5  83.59 ( 84.32)
Epoch: [0][170/391]	Time  0.038 ( 0.059)	Data  0.001 ( 0.002)	Loss 1.4420e+00 (1.8094e+00)	Acc@1  50.00 ( 33.37)	Acc@5  85.16 ( 84.71)
Epoch: [0][180/391]	Time  0.039 ( 0.058)	Data  0.001 ( 0.002)	Loss 1.7405e+00 (1.7943e+00)	Acc@1  38.28 ( 33.80)	Acc@5  87.50 ( 85.06)
Epoch: [0][190/391]	Time  0.036 ( 0.057)	Data  0.002 ( 0.002)	Loss 1.5214e+00 (1.7805e+00)	Acc@1  39.06 ( 34.28)	Acc@5  91.41 ( 85.40)
Epoch: [0][200/391]	Time  0.041 ( 0.057)	Data  0.001 ( 0.002)	Loss 1.4707e+00 (1.7664e+00)	Acc@1  39.84 ( 34.81)	Acc@5  89.84 ( 85.72)
Epoch: [0][210/391]	Time  0.038 ( 0.056)	Data  0.001 ( 0.002)	Loss 1.4248e+00 (1.7508e+00)	Acc@1  47.66 ( 35.32)	Acc@5  93.75 ( 86.06)
Epoch: [0][220/391]	Time  0.039 ( 0.055)	Data  0.001 ( 0.002)	Loss 1.4683e+00 (1.7407e+00)	Acc@1  46.88 ( 35.74)	Acc@5  90.62 ( 86.32)
Epoch: [0][230/391]	Time  0.043 ( 0.054)	Data  0.001 ( 0.002)	Loss 1.1886e+00 (1.7263e+00)	Acc@1  57.81 ( 36.25)	Acc@5  94.53 ( 86.62)
Epoch: [0][240/391]	Time  0.039 ( 0.054)	Data  0.001 ( 0.002)	Loss 1.5297e+00 (1.7146e+00)	Acc@1  39.84 ( 36.70)	Acc@5  91.41 ( 86.86)
Epoch: [0][250/391]	Time  0.041 ( 0.053)	Data  0.002 ( 0.002)	Loss 1.2931e+00 (1.7029e+00)	Acc@1  53.91 ( 37.19)	Acc@5  96.88 ( 87.10)
Epoch: [0][260/391]	Time  0.039 ( 0.053)	Data  0.001 ( 0.002)	Loss 1.5282e+00 (1.6943e+00)	Acc@1  42.19 ( 37.49)	Acc@5  92.19 ( 87.30)
Epoch: [0][270/391]	Time  0.039 ( 0.052)	Data  0.001 ( 0.002)	Loss 1.3688e+00 (1.6834e+00)	Acc@1  49.22 ( 37.91)	Acc@5  96.09 ( 87.50)
Epoch: [0][280/391]	Time  0.041 ( 0.052)	Data  0.001 ( 0.002)	Loss 1.4803e+00 (1.6719e+00)	Acc@1  46.88 ( 38.31)	Acc@5  94.53 ( 87.74)
Epoch: [0][290/391]	Time  0.038 ( 0.051)	Data  0.001 ( 0.002)	Loss 1.3247e+00 (1.6623e+00)	Acc@1  46.88 ( 38.71)	Acc@5  92.19 ( 87.89)
Epoch: [0][300/391]	Time  0.040 ( 0.051)	Data  0.001 ( 0.002)	Loss 1.4234e+00 (1.6506e+00)	Acc@1  46.88 ( 39.10)	Acc@5  92.19 ( 88.07)
Epoch: [0][310/391]	Time  0.042 ( 0.051)	Data  0.001 ( 0.002)	Loss 1.2874e+00 (1.6394e+00)	Acc@1  53.91 ( 39.51)	Acc@5  91.41 ( 88.25)
Epoch: [0][320/391]	Time  0.039 ( 0.050)	Data  0.001 ( 0.002)	Loss 1.4876e+00 (1.6293e+00)	Acc@1  44.53 ( 39.84)	Acc@5  91.41 ( 88.44)
Epoch: [0][330/391]	Time  0.037 ( 0.050)	Data  0.001 ( 0.002)	Loss 1.3611e+00 (1.6195e+00)	Acc@1  53.12 ( 40.23)	Acc@5  91.41 ( 88.60)
Epoch: [0][340/391]	Time  0.041 ( 0.050)	Data  0.001 ( 0.002)	Loss 1.2885e+00 (1.6114e+00)	Acc@1  52.34 ( 40.60)	Acc@5  95.31 ( 88.76)
Epoch: [0][350/391]	Time  0.046 ( 0.049)	Data  0.001 ( 0.002)	Loss 1.3093e+00 (1.6021e+00)	Acc@1  50.00 ( 40.97)	Acc@5  90.62 ( 88.90)
Epoch: [0][360/391]	Time  0.041 ( 0.049)	Data  0.001 ( 0.001)	Loss 1.3176e+00 (1.5953e+00)	Acc@1  52.34 ( 41.21)	Acc@5  91.41 ( 89.04)
Epoch: [0][370/391]	Time  0.042 ( 0.049)	Data  0.001 ( 0.001)	Loss 1.4627e+00 (1.5880e+00)	Acc@1  47.66 ( 41.45)	Acc@5  91.41 ( 89.16)
Epoch: [0][380/391]	Time  0.043 ( 0.049)	Data  0.001 ( 0.001)	Loss 1.2900e+00 (1.5797e+00)	Acc@1  57.03 ( 41.80)	Acc@5  94.53 ( 89.31)
Epoch: [0][390/391]	Time  0.253 ( 0.049)	Data  0.001 ( 0.001)	Loss 1.2273e+00 (1.5721e+00)	Acc@1  57.50 ( 42.13)	Acc@5  91.25 ( 89.43)
## e[0] optimizer.zero_grad (sum) time: 0.2757604122161865
## e[0]       loss.backward (sum) time: 4.234466552734375
## e[0]      optimizer.step (sum) time: 1.8357641696929932
## epoch[0] training(only) time: 19.14799976348877
# Switched to evaluate mode...
Test: [  0/100]	Time  0.254 ( 0.254)	Loss 1.0288e+00 (1.0288e+00)	Acc@1  62.00 ( 62.00)	Acc@5  95.00 ( 95.00)
Test: [ 10/100]	Time  0.018 ( 0.044)	Loss 1.1511e+00 (1.1959e+00)	Acc@1  56.00 ( 56.91)	Acc@5  97.00 ( 95.00)
Test: [ 20/100]	Time  0.020 ( 0.032)	Loss 1.1765e+00 (1.2321e+00)	Acc@1  60.00 ( 56.14)	Acc@5  94.00 ( 94.10)
Test: [ 30/100]	Time  0.020 ( 0.028)	Loss 1.1406e+00 (1.2578e+00)	Acc@1  58.00 ( 55.48)	Acc@5  97.00 ( 94.23)
Test: [ 40/100]	Time  0.018 ( 0.027)	Loss 1.1640e+00 (1.2584e+00)	Acc@1  59.00 ( 55.39)	Acc@5  95.00 ( 94.27)
Test: [ 50/100]	Time  0.020 ( 0.026)	Loss 1.2794e+00 (1.2412e+00)	Acc@1  54.00 ( 55.84)	Acc@5  96.00 ( 94.71)
Test: [ 60/100]	Time  0.018 ( 0.025)	Loss 1.2232e+00 (1.2489e+00)	Acc@1  52.00 ( 55.66)	Acc@5  95.00 ( 94.57)
Test: [ 70/100]	Time  0.021 ( 0.024)	Loss 1.3091e+00 (1.2585e+00)	Acc@1  48.00 ( 55.08)	Acc@5  94.00 ( 94.66)
Test: [ 80/100]	Time  0.017 ( 0.024)	Loss 1.1119e+00 (1.2513e+00)	Acc@1  60.00 ( 55.19)	Acc@5  97.00 ( 94.79)
Test: [ 90/100]	Time  0.017 ( 0.023)	Loss 1.0770e+00 (1.2515e+00)	Acc@1  58.00 ( 55.05)	Acc@5 100.00 ( 94.82)
 * Acc@1 55.250 Acc@5 94.850
### epoch[0] execution time: 21.596515655517578
EPOCH 1
i:   0, name:           module.stem.0.weight  changing lr from: 0.100000000000000006   to: 0.100883842679128255
i:   1, name:             module.stem.0.bias  changing lr from: 0.100000000000000006   to: 0.100885535670130144
i:   2, name:           module.stem.1.weight  changing lr from: 0.100000000000000006   to: 0.100887199950799977
i:   3, name:             module.stem.1.bias  changing lr from: 0.100000000000000006   to: 0.100888836076004296
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.100000000000000006   to: 0.100890444588581554
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.100000000000000006   to: 0.100892026019630987
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.100000000000000006   to: 0.100893580888793813
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.100000000000000006   to: 0.100895109704526920
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.100000000000000006   to: 0.100896612964369636
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.100000000000000006   to: 0.100898091155203234
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.100000000000000006   to: 0.100899544753503961
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.100000000000000006   to: 0.100900974225589246
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.100000000000000006   to: 0.100902380027857633
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.100000000000000006   to: 0.100903762607022537
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.100000000000000006   to: 0.100905122400339831
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.100000000000000006   to: 0.100906459835829729
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.100000000000000006   to: 0.100907775332492816
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.100000000000000006   to: 0.100909069300520640
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.100000000000000006   to: 0.100910342141500867
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.100000000000000006   to: 0.100911594248617176
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.100000000000000006   to: 0.100912826006844161
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.100000000000000006   to: 0.100914037793137110
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.100000000000000006   to: 0.100915229976617143
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.100000000000000006   to: 0.100916402918751577
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.100000000000000006   to: 0.100917556973529735
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.100000000000000006   to: 0.100918692487634354
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.100000000000000006   to: 0.100919809800608648
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.100000000000000006   to: 0.100920909245019244
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.100000000000000006   to: 0.100921991146614987
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.100000000000000006   to: 0.100923055824481800
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.100000000000000006   to: 0.100924103591193637
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.100000000000000006   to: 0.100925134752959833
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.100000000000000006   to: 0.100926149609768590
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.100000000000000006   to: 0.100927148455527110
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.100000000000000006   to: 0.100928131578198091
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.100000000000000006   to: 0.100929099259933042
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.100000000000000006   to: 0.100930051777202115
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.100000000000000006   to: 0.100930989400921003
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.100000000000000006   to: 0.100931912396574466
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.100000000000000006   to: 0.100932821024337052
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.100000000000000006   to: 0.100933715539190769
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.100000000000000006   to: 0.100934596191039894
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.100000000000000006   to: 0.100935463224823108
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.100000000000000006   to: 0.100936316880622684
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.100000000000000006   to: 0.100937157393771376
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.100000000000000006   to: 0.100937984994956390
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.100000000000000006   to: 0.100938799910321120
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.100000000000000006   to: 0.100939602361564185
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.100000000000000006   to: 0.100940392566036430
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.100000000000000006   to: 0.100941170736835270
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.100000000000000006   to: 0.100941937082896976
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.100000000000000006   to: 0.100942691809086785
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.100000000000000006   to: 0.100943435116286728
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.100000000000000006   to: 0.100944167201481472
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.100000000000000006   to: 0.100944888257842202
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.100000000000000006   to: 0.100945598474808287
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.100000000000000006   to: 0.100946298038167376
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.100000000000000006   to: 0.100946987130133226
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.100000000000000006   to: 0.100947665929422017
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.100000000000000006   to: 0.100948334611326740
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.100000000000000006   to: 0.100948993347789839
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.100000000000000006   to: 0.100949642307474219
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.100000000000000006   to: 0.100950281655832530
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.100000000000000006   to: 0.100950911555174980
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.100000000000000006   to: 0.100951532164735389
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.100000000000000006   to: 0.100952143640735861
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.100000000000000006   to: 0.100952746136449986
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.100000000000000006   to: 0.100953339802264383
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.100000000000000006   to: 0.100953924785739085
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.100000000000000006   to: 0.100954501231666383
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.100000000000000006   to: 0.100955069282128412
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.100000000000000006   to: 0.100955629076553269
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.100000000000000006   to: 0.100956180751770125
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.100000000000000006   to: 0.100956724442062773
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.100000000000000006   to: 0.100957260279222208
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.100000000000000006   to: 0.100957788392597905
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.100000000000000006   to: 0.100958308909147920
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.100000000000000006   to: 0.100958821953487987
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.100000000000000006   to: 0.100959327647939245
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.100000000000000006   to: 0.100959826112575327
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.100000000000000006   to: 0.100960317465267901
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.100000000000000006   to: 0.100960801821731602
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.100000000000000006   to: 0.100961279295567641
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.100000000000000006   to: 0.100961749998306760
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.100000000000000006   to: 0.100962214039450923
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.100000000000000006   to: 0.100962671526514294
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.100000000000000006   to: 0.100963122565063235
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.100000000000000006   to: 0.100963567258755438
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.100000000000000006   to: 0.100964005709378121
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.100000000000000006   to: 0.100964438016885483
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.100000000000000006   to: 0.100964864279435365
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.100000000000000006   to: 0.100965284593424909
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.100000000000000006   to: 0.100965699053525690
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.100000000000000006   to: 0.100966107752717860
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.100000000000000006   to: 0.100966510782323743
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.100000000000000006   to: 0.100966908232040534
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.100000000000000006   to: 0.100967300189972409
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.100000000000000006   to: 0.100967686742661863
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.100000000000000006   to: 0.100968067975120410
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.100000000000000006   to: 0.100968443970858579
i: 100, name:           module.conv10.weight  changing lr from: 0.100000000000000006   to: 0.100968814811915386
i: 101, name:             module.conv10.bias  changing lr from: 0.100000000000000006   to: 0.100969180578886972



# Switched to train mode...
Epoch: [1][  0/391]	Time  0.230 ( 0.230)	Data  0.180 ( 0.180)	Loss 1.3630e+00 (1.3630e+00)	Acc@1  50.78 ( 50.78)	Acc@5  93.75 ( 93.75)
Epoch: [1][ 10/391]	Time  0.039 ( 0.058)	Data  0.001 ( 0.017)	Loss 1.2388e+00 (1.2627e+00)	Acc@1  55.47 ( 54.55)	Acc@5  94.53 ( 95.31)
Epoch: [1][ 20/391]	Time  0.041 ( 0.049)	Data  0.001 ( 0.010)	Loss 1.3226e+00 (1.2666e+00)	Acc@1  54.69 ( 54.76)	Acc@5  92.97 ( 95.09)
Epoch: [1][ 30/391]	Time  0.041 ( 0.047)	Data  0.001 ( 0.007)	Loss 1.3265e+00 (1.2544e+00)	Acc@1  46.88 ( 54.49)	Acc@5  98.44 ( 95.34)
Epoch: [1][ 40/391]	Time  0.050 ( 0.045)	Data  0.001 ( 0.005)	Loss 1.1693e+00 (1.2533e+00)	Acc@1  60.94 ( 54.31)	Acc@5  92.97 ( 95.18)
Epoch: [1][ 50/391]	Time  0.040 ( 0.044)	Data  0.001 ( 0.004)	Loss 9.7463e-01 (1.2490e+00)	Acc@1  65.62 ( 54.52)	Acc@5  96.88 ( 94.96)
Epoch: [1][ 60/391]	Time  0.038 ( 0.044)	Data  0.001 ( 0.004)	Loss 1.2831e+00 (1.2446e+00)	Acc@1  49.22 ( 54.64)	Acc@5  97.66 ( 95.07)
Epoch: [1][ 70/391]	Time  0.036 ( 0.043)	Data  0.001 ( 0.004)	Loss 1.2254e+00 (1.2387e+00)	Acc@1  53.91 ( 54.95)	Acc@5  96.88 ( 95.05)
Epoch: [1][ 80/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.003)	Loss 1.2589e+00 (1.2329e+00)	Acc@1  57.81 ( 55.15)	Acc@5  95.31 ( 95.15)
Epoch: [1][ 90/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.003)	Loss 1.3725e+00 (1.2319e+00)	Acc@1  52.34 ( 55.38)	Acc@5  96.88 ( 95.15)
Epoch: [1][100/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.003)	Loss 1.1981e+00 (1.2293e+00)	Acc@1  59.38 ( 55.40)	Acc@5  95.31 ( 95.11)
Epoch: [1][110/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.003)	Loss 1.1589e+00 (1.2230e+00)	Acc@1  58.59 ( 55.47)	Acc@5  96.09 ( 95.13)
Epoch: [1][120/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.003)	Loss 1.1283e+00 (1.2191e+00)	Acc@1  62.50 ( 55.60)	Acc@5  93.75 ( 95.13)
Epoch: [1][130/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.2402e+00 (1.2137e+00)	Acc@1  55.47 ( 55.80)	Acc@5  94.53 ( 95.06)
Epoch: [1][140/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.2222e+00 (1.2129e+00)	Acc@1  57.81 ( 55.90)	Acc@5  95.31 ( 95.15)
Epoch: [1][150/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.0348e+00 (1.2060e+00)	Acc@1  62.50 ( 56.14)	Acc@5  99.22 ( 95.26)
Epoch: [1][160/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.2049e+00 (1.2017e+00)	Acc@1  53.91 ( 56.31)	Acc@5  93.75 ( 95.24)
Epoch: [1][170/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.1703e+00 (1.1983e+00)	Acc@1  59.38 ( 56.47)	Acc@5  93.75 ( 95.23)
Epoch: [1][180/391]	Time  0.043 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.3116e+00 (1.1943e+00)	Acc@1  55.47 ( 56.65)	Acc@5  92.97 ( 95.25)
Epoch: [1][190/391]	Time  0.037 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.1752e+00 (1.1913e+00)	Acc@1  56.25 ( 56.71)	Acc@5  95.31 ( 95.28)
Epoch: [1][200/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.1923e+00 (1.1878e+00)	Acc@1  61.72 ( 56.83)	Acc@5  92.19 ( 95.26)
Epoch: [1][210/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.1174e+00 (1.1856e+00)	Acc@1  61.72 ( 56.93)	Acc@5  93.75 ( 95.27)
Epoch: [1][220/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.0148e+00 (1.1826e+00)	Acc@1  58.59 ( 57.07)	Acc@5  96.09 ( 95.26)
Epoch: [1][230/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.0984e+00 (1.1800e+00)	Acc@1  58.59 ( 57.16)	Acc@5  96.88 ( 95.31)
Epoch: [1][240/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.0788e+00 (1.1769e+00)	Acc@1  57.03 ( 57.29)	Acc@5  96.88 ( 95.30)
Epoch: [1][250/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.0968e+00 (1.1742e+00)	Acc@1  59.38 ( 57.46)	Acc@5  96.88 ( 95.31)
Epoch: [1][260/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.2297e+00 (1.1710e+00)	Acc@1  55.47 ( 57.56)	Acc@5  93.75 ( 95.34)
Epoch: [1][270/391]	Time  0.048 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.0761e+00 (1.1681e+00)	Acc@1  60.94 ( 57.72)	Acc@5  95.31 ( 95.34)
Epoch: [1][280/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.0585e+00 (1.1632e+00)	Acc@1  63.28 ( 57.88)	Acc@5  96.88 ( 95.40)
Epoch: [1][290/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 9.0350e-01 (1.1597e+00)	Acc@1  66.41 ( 57.98)	Acc@5  97.66 ( 95.42)
Epoch: [1][300/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 9.4013e-01 (1.1567e+00)	Acc@1  64.84 ( 58.09)	Acc@5  94.53 ( 95.43)
Epoch: [1][310/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.1856e+00 (1.1547e+00)	Acc@1  57.03 ( 58.22)	Acc@5  96.88 ( 95.45)
Epoch: [1][320/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.0829e+00 (1.1530e+00)	Acc@1  62.50 ( 58.30)	Acc@5  92.97 ( 95.44)
Epoch: [1][330/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.1509e+00 (1.1515e+00)	Acc@1  58.59 ( 58.36)	Acc@5  95.31 ( 95.46)
Epoch: [1][340/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.1073e+00 (1.1483e+00)	Acc@1  62.50 ( 58.48)	Acc@5  96.09 ( 95.49)
Epoch: [1][350/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.0144e+00 (1.1456e+00)	Acc@1  67.19 ( 58.59)	Acc@5  94.53 ( 95.52)
Epoch: [1][360/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.1489e+00 (1.1437e+00)	Acc@1  58.59 ( 58.64)	Acc@5  97.66 ( 95.56)
Epoch: [1][370/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.001)	Loss 1.2531e+00 (1.1418e+00)	Acc@1  52.34 ( 58.74)	Acc@5  93.75 ( 95.56)
Epoch: [1][380/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.001)	Loss 1.0971e+00 (1.1409e+00)	Acc@1  58.59 ( 58.79)	Acc@5  95.31 ( 95.59)
Epoch: [1][390/391]	Time  0.028 ( 0.040)	Data  0.001 ( 0.001)	Loss 8.9690e-01 (1.1373e+00)	Acc@1  65.00 ( 58.94)	Acc@5  98.75 ( 95.60)
## e[1] optimizer.zero_grad (sum) time: 0.27205467224121094
## e[1]       loss.backward (sum) time: 3.9217357635498047
## e[1]      optimizer.step (sum) time: 1.892941951751709
## epoch[1] training(only) time: 15.924254179000854
# Switched to evaluate mode...
Test: [  0/100]	Time  0.187 ( 0.187)	Loss 1.0502e+00 (1.0502e+00)	Acc@1  62.00 ( 62.00)	Acc@5  96.00 ( 96.00)
Test: [ 10/100]	Time  0.017 ( 0.035)	Loss 9.7759e-01 (1.1858e+00)	Acc@1  63.00 ( 59.91)	Acc@5  99.00 ( 96.64)
Test: [ 20/100]	Time  0.024 ( 0.029)	Loss 9.9250e-01 (1.1504e+00)	Acc@1  62.00 ( 59.86)	Acc@5  97.00 ( 96.62)
Test: [ 30/100]	Time  0.018 ( 0.027)	Loss 1.0855e+00 (1.1659e+00)	Acc@1  63.00 ( 60.26)	Acc@5  98.00 ( 96.39)
Test: [ 40/100]	Time  0.024 ( 0.025)	Loss 1.2576e+00 (1.1723e+00)	Acc@1  60.00 ( 60.00)	Acc@5  96.00 ( 96.10)
Test: [ 50/100]	Time  0.017 ( 0.024)	Loss 1.1127e+00 (1.1546e+00)	Acc@1  65.00 ( 60.45)	Acc@5  97.00 ( 96.20)
Test: [ 60/100]	Time  0.021 ( 0.024)	Loss 1.2796e+00 (1.1621e+00)	Acc@1  50.00 ( 60.16)	Acc@5  97.00 ( 96.23)
Test: [ 70/100]	Time  0.024 ( 0.024)	Loss 1.0560e+00 (1.1638e+00)	Acc@1  54.00 ( 60.03)	Acc@5  95.00 ( 96.21)
Test: [ 80/100]	Time  0.016 ( 0.023)	Loss 1.1275e+00 (1.1627e+00)	Acc@1  60.00 ( 60.15)	Acc@5  96.00 ( 96.20)
Test: [ 90/100]	Time  0.021 ( 0.023)	Loss 1.3364e+00 (1.1676e+00)	Acc@1  54.00 ( 60.15)	Acc@5  97.00 ( 96.10)
 * Acc@1 60.010 Acc@5 96.150
### epoch[1] execution time: 18.293145179748535
EPOCH 2
i:   0, name:           module.stem.0.weight  changing lr from: 0.100883842679128255   to: 0.100535910417440644
i:   1, name:             module.stem.0.bias  changing lr from: 0.100885535670130144   to: 0.100542666763833027
i:   2, name:           module.stem.1.weight  changing lr from: 0.100887199950799977   to: 0.100549308757243938
i:   3, name:             module.stem.1.bias  changing lr from: 0.100888836076004296   to: 0.100555838600737121
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.100890444588581554   to: 0.100562258449853059
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.100892026019630987   to: 0.100568570413741440
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.100893580888793813   to: 0.100574776556264414
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.100895109704526920   to: 0.100580878897071055
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.100896612964369636   to: 0.100586879412643951
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.100898091155203234   to: 0.100592780037318849
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.100899544753503961   to: 0.100598582664277791
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.100900974225589246   to: 0.100604289146516868
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.100902380027857633   to: 0.100609901297788976
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.100903762607022537   to: 0.100615420893522406
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.100905122400339831   to: 0.100620849671715987
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.100906459835829729   to: 0.100626189333811400
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.100907775332492816   to: 0.100631441545543127
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.100909069300520640   to: 0.100636607937766881
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.100910342141500867   to: 0.100641690107267090
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.100911594248617176   to: 0.100646689617543833
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.100912826006844161   to: 0.100651607999579937
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.100914037793137110   to: 0.100656446752588766
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.100915229976617143   to: 0.100661207344743139
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.100916402918751577   to: 0.100665891213886027
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.100917556973529735   to: 0.100670499768223495
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.100918692487634354   to: 0.100675034387000081
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.100919809800608648   to: 0.100679496421157713
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.100920909245019244   to: 0.100683887193977917
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.100921991146614987   to: 0.100688208001708204
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.100923055824481800   to: 0.100692460114173002
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.100924103591193637   to: 0.100696644775369326
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.100925134752959833   to: 0.100700763204047888
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.100926149609768590   to: 0.100704816594279864
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.100927148455527110   to: 0.100708806116009714
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.100928131578198091   to: 0.100712732915594461
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.100929099259933042   to: 0.100716598116329811
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.100930051777202115   to: 0.100720402818963356
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.100930989400921003   to: 0.100724148102195404
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.100931912396574466   to: 0.100727835023167456
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.100932821024337052   to: 0.100731464617939054
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.100933715539190769   to: 0.100735037901952845
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.100934596191039894   to: 0.100738555870488633
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.100935463224823108   to: 0.100742019499106383
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.100936316880622684   to: 0.100745429744078463
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.100937157393771376   to: 0.100748787542811788
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.100937984994956390   to: 0.100752093814259605
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.100938799910321120   to: 0.100755349459323504
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.100939602361564185   to: 0.100758555361245880
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.100940392566036430   to: 0.100761712385993032
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.100941170736835270   to: 0.100764821382629211
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.100941937082896976   to: 0.100767883183681600
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.100942691809086785   to: 0.100770898605496970
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.100943435116286728   to: 0.100773868448589668
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.100944167201481472   to: 0.100776793497981521
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.100944888257842202   to: 0.100779674523533702
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.100945598474808287   to: 0.100782512280270867
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.100946298038167376   to: 0.100785307508697630
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.100946987130133226   to: 0.100788060935107712
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.100947665929422017   to: 0.100790773271885778
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.100948334611326740   to: 0.100793445217802424
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.100948993347789839   to: 0.100796077458302158
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.100949642307474219   to: 0.100798670665784712
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.100950281655832530   to: 0.100801225499879979
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.100950911555174980   to: 0.100803742607716504
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.100951532164735389   to: 0.100806222624183706
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.100952143640735861   to: 0.100808666172188310
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.100952746136449986   to: 0.100811073862904721
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.100953339802264383   to: 0.100813446296019585
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.100953924785739085   to: 0.100815784059971075
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.100954501231666383   to: 0.100818087732182329
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.100955069282128412   to: 0.100820357879289960
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.100955629076553269   to: 0.100822595057366987
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.100956180751770125   to: 0.100824799812141097
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.100956724442062773   to: 0.100826972679207649
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.100957260279222208   to: 0.100829114184238108
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.100957788392597905   to: 0.100831224843183589
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.100958308909147920   to: 0.100833305162473963
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.100958821953487987   to: 0.100835355639212476
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.100959327647939245   to: 0.100837376761365893
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.100959826112575327   to: 0.100839369007950527
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.100960317465267901   to: 0.100841332849214135
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.100960801821731602   to: 0.100843268746813541
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.100961279295567641   to: 0.100845177153988622
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.100961749998306760   to: 0.100847058515732196
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.100962214039450923   to: 0.100848913268956245
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.100962671526514294   to: 0.100850741842654482
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.100963122565063235   to: 0.100852544658061261
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.100963567258755438   to: 0.100854322128807128
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.100964005709378121   to: 0.100856074661070744
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.100964438016885483   to: 0.100857802653727666
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.100964864279435365   to: 0.100859506498495843
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.100965284593424909   to: 0.100861186580077797
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.100965699053525690   to: 0.100862843276299907
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.100966107752717860   to: 0.100864476958248461
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.100966510782323743   to: 0.100866087990402975
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.100966908232040534   to: 0.100867676730766409
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.100967300189972409   to: 0.100869243530992678
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.100967686742661863   to: 0.100870788736511438
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.100968067975120410   to: 0.100872312686650117
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.100968443970858579   to: 0.100873815714753332
i: 100, name:           module.conv10.weight  changing lr from: 0.100968814811915386   to: 0.100875298148299763
i: 101, name:             module.conv10.bias  changing lr from: 0.100969180578886972   to: 0.100876760309016572



# Switched to train mode...
Epoch: [2][  0/391]	Time  0.216 ( 0.216)	Data  0.174 ( 0.174)	Loss 1.0627e+00 (1.0627e+00)	Acc@1  62.50 ( 62.50)	Acc@5  97.66 ( 97.66)
Epoch: [2][ 10/391]	Time  0.038 ( 0.056)	Data  0.001 ( 0.017)	Loss 9.8940e-01 (1.0104e+00)	Acc@1  61.72 ( 63.71)	Acc@5  96.09 ( 97.02)
Epoch: [2][ 20/391]	Time  0.036 ( 0.048)	Data  0.001 ( 0.009)	Loss 1.0791e+00 (1.0232e+00)	Acc@1  64.06 ( 63.39)	Acc@5  95.31 ( 96.76)
Epoch: [2][ 30/391]	Time  0.040 ( 0.045)	Data  0.001 ( 0.007)	Loss 1.0388e+00 (1.0117e+00)	Acc@1  64.06 ( 63.68)	Acc@5  94.53 ( 96.98)
Epoch: [2][ 40/391]	Time  0.038 ( 0.044)	Data  0.001 ( 0.005)	Loss 1.0646e+00 (1.0087e+00)	Acc@1  57.03 ( 63.62)	Acc@5  92.97 ( 96.82)
Epoch: [2][ 50/391]	Time  0.039 ( 0.043)	Data  0.001 ( 0.004)	Loss 1.0997e+00 (1.0099e+00)	Acc@1  66.41 ( 63.73)	Acc@5  96.09 ( 96.58)
Epoch: [2][ 60/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.004)	Loss 9.3176e-01 (1.0072e+00)	Acc@1  61.72 ( 63.73)	Acc@5  96.09 ( 96.61)
Epoch: [2][ 70/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.003)	Loss 9.4780e-01 (1.0038e+00)	Acc@1  70.31 ( 64.06)	Acc@5  97.66 ( 96.67)
Epoch: [2][ 80/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.003)	Loss 9.2575e-01 (9.9759e-01)	Acc@1  71.88 ( 64.50)	Acc@5  96.09 ( 96.73)
Epoch: [2][ 90/391]	Time  0.046 ( 0.042)	Data  0.001 ( 0.003)	Loss 8.3836e-01 (9.8965e-01)	Acc@1  69.53 ( 64.78)	Acc@5  99.22 ( 96.79)
Epoch: [2][100/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.003)	Loss 9.4735e-01 (9.8605e-01)	Acc@1  65.62 ( 64.87)	Acc@5  96.88 ( 96.84)
Epoch: [2][110/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.003)	Loss 7.6427e-01 (9.7954e-01)	Acc@1  73.44 ( 65.13)	Acc@5  96.88 ( 96.84)
Epoch: [2][120/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 7.8332e-01 (9.7602e-01)	Acc@1  71.88 ( 65.22)	Acc@5  99.22 ( 96.87)
Epoch: [2][130/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.1176e+00 (9.7716e-01)	Acc@1  61.72 ( 65.17)	Acc@5  96.88 ( 96.83)
Epoch: [2][140/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.0937e+00 (9.7926e-01)	Acc@1  62.50 ( 65.14)	Acc@5  96.88 ( 96.83)
Epoch: [2][150/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 9.5660e-01 (9.7644e-01)	Acc@1  67.97 ( 65.25)	Acc@5  96.09 ( 96.83)
Epoch: [2][160/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 9.1432e-01 (9.7256e-01)	Acc@1  69.53 ( 65.44)	Acc@5  96.88 ( 96.87)
Epoch: [2][170/391]	Time  0.035 ( 0.041)	Data  0.001 ( 0.002)	Loss 7.8124e-01 (9.7009e-01)	Acc@1  67.97 ( 65.53)	Acc@5 100.00 ( 96.90)
Epoch: [2][180/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 9.9319e-01 (9.6937e-01)	Acc@1  68.75 ( 65.59)	Acc@5  95.31 ( 96.89)
Epoch: [2][190/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.0678e+00 (9.6846e-01)	Acc@1  59.38 ( 65.62)	Acc@5  97.66 ( 96.91)
Epoch: [2][200/391]	Time  0.037 ( 0.041)	Data  0.001 ( 0.002)	Loss 8.7243e-01 (9.6473e-01)	Acc@1  71.88 ( 65.70)	Acc@5  97.66 ( 96.96)
Epoch: [2][210/391]	Time  0.036 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.0048e+00 (9.6322e-01)	Acc@1  64.06 ( 65.75)	Acc@5  95.31 ( 96.95)
Epoch: [2][220/391]	Time  0.037 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.0368e+00 (9.6072e-01)	Acc@1  64.06 ( 65.85)	Acc@5  94.53 ( 96.95)
Epoch: [2][230/391]	Time  0.040 ( 0.040)	Data  0.001 ( 0.002)	Loss 1.0406e+00 (9.6013e-01)	Acc@1  62.50 ( 65.92)	Acc@5  96.09 ( 96.96)
Epoch: [2][240/391]	Time  0.042 ( 0.040)	Data  0.001 ( 0.002)	Loss 1.0152e+00 (9.5961e-01)	Acc@1  63.28 ( 65.94)	Acc@5  95.31 ( 96.94)
Epoch: [2][250/391]	Time  0.041 ( 0.040)	Data  0.001 ( 0.002)	Loss 8.2276e-01 (9.5551e-01)	Acc@1  75.00 ( 66.14)	Acc@5  98.44 ( 96.98)
Epoch: [2][260/391]	Time  0.038 ( 0.040)	Data  0.001 ( 0.002)	Loss 1.1529e+00 (9.5635e-01)	Acc@1  64.06 ( 66.11)	Acc@5  89.84 ( 96.94)
Epoch: [2][270/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 6.8212e-01 (9.5289e-01)	Acc@1  77.34 ( 66.24)	Acc@5  98.44 ( 96.97)
Epoch: [2][280/391]	Time  0.042 ( 0.040)	Data  0.001 ( 0.002)	Loss 8.1334e-01 (9.4997e-01)	Acc@1  72.66 ( 66.34)	Acc@5  97.66 ( 96.99)
Epoch: [2][290/391]	Time  0.038 ( 0.040)	Data  0.001 ( 0.002)	Loss 9.5739e-01 (9.4921e-01)	Acc@1  67.19 ( 66.38)	Acc@5  98.44 ( 97.02)
Epoch: [2][300/391]	Time  0.040 ( 0.040)	Data  0.001 ( 0.002)	Loss 9.2790e-01 (9.4886e-01)	Acc@1  67.97 ( 66.40)	Acc@5  96.09 ( 97.01)
Epoch: [2][310/391]	Time  0.041 ( 0.040)	Data  0.001 ( 0.002)	Loss 7.7730e-01 (9.4671e-01)	Acc@1  72.66 ( 66.52)	Acc@5  98.44 ( 97.03)
Epoch: [2][320/391]	Time  0.043 ( 0.040)	Data  0.001 ( 0.002)	Loss 8.7641e-01 (9.4482e-01)	Acc@1  72.66 ( 66.61)	Acc@5  98.44 ( 97.06)
Epoch: [2][330/391]	Time  0.038 ( 0.040)	Data  0.001 ( 0.002)	Loss 9.7928e-01 (9.4346e-01)	Acc@1  64.06 ( 66.67)	Acc@5  96.88 ( 97.06)
Epoch: [2][340/391]	Time  0.038 ( 0.040)	Data  0.001 ( 0.002)	Loss 1.0212e+00 (9.4185e-01)	Acc@1  64.84 ( 66.72)	Acc@5  95.31 ( 97.07)
Epoch: [2][350/391]	Time  0.038 ( 0.040)	Data  0.001 ( 0.001)	Loss 9.2761e-01 (9.4040e-01)	Acc@1  72.66 ( 66.76)	Acc@5  96.09 ( 97.06)
Epoch: [2][360/391]	Time  0.041 ( 0.040)	Data  0.002 ( 0.001)	Loss 7.7301e-01 (9.3924e-01)	Acc@1  73.44 ( 66.79)	Acc@5  99.22 ( 97.07)
Epoch: [2][370/391]	Time  0.040 ( 0.040)	Data  0.001 ( 0.001)	Loss 7.5347e-01 (9.3619e-01)	Acc@1  72.66 ( 66.90)	Acc@5  97.66 ( 97.09)
Epoch: [2][380/391]	Time  0.041 ( 0.040)	Data  0.001 ( 0.001)	Loss 7.1113e-01 (9.3510e-01)	Acc@1  75.78 ( 66.91)	Acc@5  96.88 ( 97.11)
Epoch: [2][390/391]	Time  0.027 ( 0.040)	Data  0.001 ( 0.001)	Loss 9.5744e-01 (9.3459e-01)	Acc@1  63.75 ( 66.91)	Acc@5  96.25 ( 97.10)
## e[2] optimizer.zero_grad (sum) time: 0.2726626396179199
## e[2]       loss.backward (sum) time: 3.9179019927978516
## e[2]      optimizer.step (sum) time: 1.8759100437164307
## epoch[2] training(only) time: 15.906827211380005
# Switched to evaluate mode...
Test: [  0/100]	Time  0.170 ( 0.170)	Loss 9.5876e-01 (9.5876e-01)	Acc@1  68.00 ( 68.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.017 ( 0.034)	Loss 8.7534e-01 (1.0857e+00)	Acc@1  74.00 ( 64.91)	Acc@5  95.00 ( 97.73)
Test: [ 20/100]	Time  0.022 ( 0.027)	Loss 1.0195e+00 (1.1114e+00)	Acc@1  69.00 ( 63.19)	Acc@5  96.00 ( 97.05)
Test: [ 30/100]	Time  0.019 ( 0.025)	Loss 1.0206e+00 (1.1184e+00)	Acc@1  65.00 ( 63.06)	Acc@5  97.00 ( 96.77)
Test: [ 40/100]	Time  0.021 ( 0.024)	Loss 1.1905e+00 (1.1278e+00)	Acc@1  60.00 ( 62.29)	Acc@5  96.00 ( 96.71)
Test: [ 50/100]	Time  0.020 ( 0.023)	Loss 1.1396e+00 (1.1135e+00)	Acc@1  64.00 ( 62.55)	Acc@5  96.00 ( 96.92)
Test: [ 60/100]	Time  0.017 ( 0.023)	Loss 1.1342e+00 (1.1197e+00)	Acc@1  65.00 ( 62.56)	Acc@5  98.00 ( 96.98)
Test: [ 70/100]	Time  0.020 ( 0.022)	Loss 1.0678e+00 (1.1111e+00)	Acc@1  64.00 ( 63.00)	Acc@5  98.00 ( 97.06)
Test: [ 80/100]	Time  0.018 ( 0.022)	Loss 9.3294e-01 (1.1090e+00)	Acc@1  70.00 ( 62.98)	Acc@5  98.00 ( 97.11)
Test: [ 90/100]	Time  0.020 ( 0.022)	Loss 1.1144e+00 (1.1141e+00)	Acc@1  58.00 ( 62.66)	Acc@5  98.00 ( 97.07)
 * Acc@1 62.610 Acc@5 97.050
### epoch[2] execution time: 18.146790027618408
EPOCH 3
i:   0, name:           module.stem.0.weight  changing lr from: 0.100535910417440644   to: 0.099957819810111703
i:   1, name:             module.stem.0.bias  changing lr from: 0.100542666763833027   to: 0.099972963131492384
i:   2, name:           module.stem.1.weight  changing lr from: 0.100549308757243938   to: 0.099987850985062104
i:   3, name:             module.stem.1.bias  changing lr from: 0.100555838600737121   to: 0.100002488266439718
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.100562258449853059   to: 0.100016879766512509
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.100568570413741440   to: 0.100031030173900956
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.100574776556264414   to: 0.100044944077360476
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.100580878897071055   to: 0.100058625968122025
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.100586879412643951   to: 0.100072080242172914
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.100592780037318849   to: 0.100085311202479932
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.100598582664277791   to: 0.100098323061155847
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.100604289146516868   to: 0.100111119941571347
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.100609901297788976   to: 0.100123705880413291
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.100615420893522406   to: 0.100136084829691371
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.100620849671715987   to: 0.100148260658694144
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.100626189333811400   to: 0.100160237155895893
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.100631441545543127   to: 0.100172018030815824
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.100636607937766881   to: 0.100183606915830559
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.100641690107267090   to: 0.100195007367941499
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.100646689617543833   to: 0.100206222870498129
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.100651607999579937   to: 0.100217256834878435
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.100656446752588766   to: 0.100228112602127523
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.100661207344743139   to: 0.100238793444555718
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.100665891213886027   to: 0.100249302567297194
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.100670499768223495   to: 0.100259643109829918
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.100675034387000081   to: 0.100269818147458403
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.100679496421157713   to: 0.100279830692759794
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.100683887193977917   to: 0.100289683696994564
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.100688208001708204   to: 0.100299380051482645
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.100692460114173002   to: 0.100308922588945942
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.100696644775369326   to: 0.100318314084817950
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.100700763204047888   to: 0.100327557258521688
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.100704816594279864   to: 0.100336654774716413
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.100708806116009714   to: 0.100345609244514133
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.100712732915594461   to: 0.100354423226666697
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.100716598116329811   to: 0.100363099228724190
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.100720402818963356   to: 0.100371639708165344
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.100724148102195404   to: 0.100380047073500789
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.100727835023167456   to: 0.100388323685349737
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.100731464617939054   to: 0.100396471857490996
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.100735037901952845   to: 0.100404493857888605
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.100738555870488633   to: 0.100412391909693186
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.100742019499106383   to: 0.100420168192219272
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.100745429744078463   to: 0.100427824841899493
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.100748787542811788   to: 0.100435363953216006
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.100752093814259605   to: 0.100442787579609949
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.100755349459323504   to: 0.100450097734369262
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.100758555361245880   to: 0.100457296391495657
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.100761712385993032   to: 0.100464385486551150
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.100764821382629211   to: 0.100471366917484539
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.100767883183681600   to: 0.100478242545438717
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.100770898605496970   to: 0.100485014195538902
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.100773868448589668   to: 0.100491683657662423
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.100776793497981521   to: 0.100498252687190703
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.100779674523533702   to: 0.100504723005743590
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.100782512280270867   to: 0.100511096301896571
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.100785307508697630   to: 0.100517374231881576
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.100788060935107712   to: 0.100523558420271289
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.100790773271885778   to: 0.100529650460647796
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.100793445217802424   to: 0.100535651916255783
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.100796077458302158   to: 0.100541564320640639
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.100798670665784712   to: 0.100547389178271981
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.100801225499879979   to: 0.100553127965152839
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.100803742607716504   to: 0.100558782129414867
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.100806222624183706   to: 0.100564353091899927
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.100808666172188310   to: 0.100569842246728630
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.100811073862904721   to: 0.100575250961855545
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.100813446296019585   to: 0.100580580579612194
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.100815784059971075   to: 0.100585832417237495
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.100818087732182329   to: 0.100591007767396268
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.100820357879289960   to: 0.100596107898686060
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.100822595057366987   to: 0.100601134056132385
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.100824799812141097   to: 0.100606087461673169
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.100826972679207649   to: 0.100610969314631898
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.100829114184238108   to: 0.100615780792180434
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.100831224843183589   to: 0.100620523049791410
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.100833305162473963   to: 0.100625197221680493
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.100835355639212476   to: 0.100629804421238769
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.100837376761365893   to: 0.100634345741455605
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.100839369007950527   to: 0.100638822255332036
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.100841332849214135   to: 0.100643235016285026
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.100843268746813541   to: 0.100647585058542766
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.100845177153988622   to: 0.100651873397531288
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.100847058515732196   to: 0.100656101030252451
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.100848913268956245   to: 0.100660268935653760
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.100850741842654482   to: 0.100664378074990013
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.100852544658061261   to: 0.100668429392176906
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.100854322128807128   to: 0.100672423814137130
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.100856074661070744   to: 0.100676362251138671
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.100857802653727666   to: 0.100680245597125906
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.100859506498495843   to: 0.100684074730043441
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.100861186580077797   to: 0.100687850512152927
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.100862843276299907   to: 0.100691573790342992
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.100864476958248461   to: 0.100695245396432514
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.100866087990402975   to: 0.100698866147467245
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.100867676730766409   to: 0.100702436846010171
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.100869243530992678   to: 0.100705958280425611
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.100870788736511438   to: 0.100709431225157062
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.100872312686650117   to: 0.100712856440999296
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.100873815714753332   to: 0.100716234675364530
i: 100, name:           module.conv10.weight  changing lr from: 0.100875298148299763   to: 0.100719566662542920
i: 101, name:             module.conv10.bias  changing lr from: 0.100876760309016572   to: 0.100722853123957484



# Switched to train mode...
Epoch: [3][  0/391]	Time  0.222 ( 0.222)	Data  0.180 ( 0.180)	Loss 9.2875e-01 (9.2875e-01)	Acc@1  65.62 ( 65.62)	Acc@5  95.31 ( 95.31)
Epoch: [3][ 10/391]	Time  0.040 ( 0.057)	Data  0.001 ( 0.017)	Loss 9.3223e-01 (8.7424e-01)	Acc@1  69.53 ( 70.03)	Acc@5  95.31 ( 97.51)
Epoch: [3][ 20/391]	Time  0.055 ( 0.050)	Data  0.001 ( 0.009)	Loss 7.1151e-01 (8.7135e-01)	Acc@1  74.22 ( 69.23)	Acc@5  97.66 ( 97.36)
Epoch: [3][ 30/391]	Time  0.042 ( 0.047)	Data  0.001 ( 0.007)	Loss 9.9255e-01 (8.7972e-01)	Acc@1  64.84 ( 69.13)	Acc@5  96.09 ( 97.10)
Epoch: [3][ 40/391]	Time  0.044 ( 0.045)	Data  0.001 ( 0.005)	Loss 9.8033e-01 (8.7183e-01)	Acc@1  69.53 ( 69.87)	Acc@5  98.44 ( 97.33)
Epoch: [3][ 50/391]	Time  0.041 ( 0.044)	Data  0.001 ( 0.004)	Loss 9.0033e-01 (8.6314e-01)	Acc@1  67.19 ( 70.10)	Acc@5  97.66 ( 97.37)
Epoch: [3][ 60/391]	Time  0.037 ( 0.044)	Data  0.001 ( 0.004)	Loss 9.7717e-01 (8.6202e-01)	Acc@1  64.06 ( 69.71)	Acc@5  96.09 ( 97.43)
Epoch: [3][ 70/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.003)	Loss 7.3369e-01 (8.5413e-01)	Acc@1  71.88 ( 69.75)	Acc@5  98.44 ( 97.45)
Epoch: [3][ 80/391]	Time  0.038 ( 0.043)	Data  0.001 ( 0.003)	Loss 9.4679e-01 (8.4971e-01)	Acc@1  66.41 ( 69.70)	Acc@5  97.66 ( 97.49)
Epoch: [3][ 90/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.003)	Loss 8.1745e-01 (8.4609e-01)	Acc@1  71.88 ( 69.85)	Acc@5  98.44 ( 97.54)
Epoch: [3][100/391]	Time  0.037 ( 0.042)	Data  0.001 ( 0.003)	Loss 9.5064e-01 (8.4595e-01)	Acc@1  67.19 ( 69.84)	Acc@5  98.44 ( 97.59)
Epoch: [3][110/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.003)	Loss 9.6488e-01 (8.5051e-01)	Acc@1  69.53 ( 69.77)	Acc@5  95.31 ( 97.57)
Epoch: [3][120/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 8.5733e-01 (8.4848e-01)	Acc@1  66.41 ( 69.85)	Acc@5  98.44 ( 97.59)
Epoch: [3][130/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 8.6880e-01 (8.4761e-01)	Acc@1  64.84 ( 69.95)	Acc@5  99.22 ( 97.57)
Epoch: [3][140/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 8.2961e-01 (8.4655e-01)	Acc@1  71.88 ( 69.97)	Acc@5  96.09 ( 97.59)
Epoch: [3][150/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 7.2890e-01 (8.4389e-01)	Acc@1  82.03 ( 70.12)	Acc@5  97.66 ( 97.64)
Epoch: [3][160/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 8.5552e-01 (8.4479e-01)	Acc@1  66.41 ( 70.08)	Acc@5  99.22 ( 97.66)
Epoch: [3][170/391]	Time  0.043 ( 0.041)	Data  0.001 ( 0.002)	Loss 7.3022e-01 (8.4057e-01)	Acc@1  75.00 ( 70.28)	Acc@5  97.66 ( 97.67)
Epoch: [3][180/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 7.7476e-01 (8.4103e-01)	Acc@1  76.56 ( 70.27)	Acc@5  99.22 ( 97.66)
Epoch: [3][190/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.8222e-01 (8.3822e-01)	Acc@1  77.34 ( 70.38)	Acc@5  97.66 ( 97.66)
Epoch: [3][200/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 6.8071e-01 (8.3543e-01)	Acc@1  76.56 ( 70.44)	Acc@5  98.44 ( 97.70)
Epoch: [3][210/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 9.3276e-01 (8.3583e-01)	Acc@1  63.28 ( 70.41)	Acc@5  96.09 ( 97.72)
Epoch: [3][220/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 6.9275e-01 (8.3390e-01)	Acc@1  72.66 ( 70.49)	Acc@5  98.44 ( 97.75)
Epoch: [3][230/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 9.2470e-01 (8.3168e-01)	Acc@1  71.88 ( 70.59)	Acc@5  98.44 ( 97.76)
Epoch: [3][240/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 6.5782e-01 (8.3072e-01)	Acc@1  79.69 ( 70.69)	Acc@5  97.66 ( 97.73)
Epoch: [3][250/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 7.6687e-01 (8.3062e-01)	Acc@1  70.31 ( 70.70)	Acc@5  98.44 ( 97.74)
Epoch: [3][260/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 7.0521e-01 (8.2885e-01)	Acc@1  71.09 ( 70.74)	Acc@5  99.22 ( 97.72)
Epoch: [3][270/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 6.9181e-01 (8.2643e-01)	Acc@1  74.22 ( 70.86)	Acc@5  98.44 ( 97.74)
Epoch: [3][280/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 6.5620e-01 (8.2478e-01)	Acc@1  75.78 ( 70.91)	Acc@5  97.66 ( 97.74)
Epoch: [3][290/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 7.8494e-01 (8.2314e-01)	Acc@1  80.47 ( 71.02)	Acc@5  98.44 ( 97.76)
Epoch: [3][300/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 9.2197e-01 (8.2337e-01)	Acc@1  66.41 ( 71.02)	Acc@5  97.66 ( 97.78)
Epoch: [3][310/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 6.9510e-01 (8.2117e-01)	Acc@1  75.00 ( 71.17)	Acc@5 100.00 ( 97.79)
Epoch: [3][320/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 7.5480e-01 (8.2076e-01)	Acc@1  71.88 ( 71.20)	Acc@5  98.44 ( 97.82)
Epoch: [3][330/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 8.5419e-01 (8.1864e-01)	Acc@1  71.09 ( 71.32)	Acc@5  97.66 ( 97.84)
Epoch: [3][340/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.8040e-01 (8.1775e-01)	Acc@1  80.47 ( 71.34)	Acc@5  99.22 ( 97.85)
Epoch: [3][350/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.001)	Loss 7.1673e-01 (8.1661e-01)	Acc@1  72.66 ( 71.42)	Acc@5  98.44 ( 97.84)
Epoch: [3][360/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.001)	Loss 6.9360e-01 (8.1351e-01)	Acc@1  78.12 ( 71.54)	Acc@5  98.44 ( 97.85)
Epoch: [3][370/391]	Time  0.044 ( 0.041)	Data  0.001 ( 0.001)	Loss 8.1065e-01 (8.1251e-01)	Acc@1  71.09 ( 71.58)	Acc@5  96.88 ( 97.85)
Epoch: [3][380/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.001)	Loss 8.1191e-01 (8.1044e-01)	Acc@1  69.53 ( 71.64)	Acc@5  98.44 ( 97.86)
Epoch: [3][390/391]	Time  0.031 ( 0.041)	Data  0.001 ( 0.001)	Loss 8.0448e-01 (8.0882e-01)	Acc@1  71.25 ( 71.68)	Acc@5  97.50 ( 97.86)
## e[3] optimizer.zero_grad (sum) time: 0.27448296546936035
## e[3]       loss.backward (sum) time: 3.98933482170105
## e[3]      optimizer.step (sum) time: 1.8278377056121826
## epoch[3] training(only) time: 16.000824451446533
# Switched to evaluate mode...
Test: [  0/100]	Time  0.176 ( 0.176)	Loss 8.8199e-01 (8.8199e-01)	Acc@1  66.00 ( 66.00)	Acc@5  96.00 ( 96.00)
Test: [ 10/100]	Time  0.023 ( 0.035)	Loss 8.3449e-01 (8.7555e-01)	Acc@1  75.00 ( 70.73)	Acc@5  98.00 ( 98.09)
Test: [ 20/100]	Time  0.017 ( 0.028)	Loss 7.3714e-01 (8.5173e-01)	Acc@1  73.00 ( 71.43)	Acc@5  98.00 ( 97.67)
Test: [ 30/100]	Time  0.020 ( 0.026)	Loss 9.7534e-01 (8.8178e-01)	Acc@1  65.00 ( 71.10)	Acc@5  96.00 ( 97.55)
Test: [ 40/100]	Time  0.018 ( 0.024)	Loss 8.7335e-01 (8.8564e-01)	Acc@1  73.00 ( 70.93)	Acc@5  97.00 ( 97.54)
Test: [ 50/100]	Time  0.020 ( 0.023)	Loss 8.7114e-01 (8.7778e-01)	Acc@1  80.00 ( 71.31)	Acc@5  97.00 ( 97.55)
Test: [ 60/100]	Time  0.024 ( 0.023)	Loss 9.6793e-01 (8.9148e-01)	Acc@1  64.00 ( 70.95)	Acc@5  98.00 ( 97.61)
Test: [ 70/100]	Time  0.026 ( 0.023)	Loss 9.7140e-01 (8.8833e-01)	Acc@1  66.00 ( 70.77)	Acc@5  98.00 ( 97.69)
Test: [ 80/100]	Time  0.024 ( 0.022)	Loss 8.3533e-01 (8.8402e-01)	Acc@1  69.00 ( 70.89)	Acc@5  97.00 ( 97.72)
Test: [ 90/100]	Time  0.027 ( 0.022)	Loss 8.1410e-01 (8.8911e-01)	Acc@1  73.00 ( 70.66)	Acc@5 100.00 ( 97.75)
 * Acc@1 70.550 Acc@5 97.840
### epoch[3] execution time: 18.299071788787842
EPOCH 4
i:   0, name:           module.stem.0.weight  changing lr from: 0.099957819810111703   to: 0.099152256835388142
i:   1, name:             module.stem.0.bias  changing lr from: 0.099972963131492384   to: 0.099179033202888206
i:   2, name:           module.stem.1.weight  changing lr from: 0.099987850985062104   to: 0.099205359932827558
i:   3, name:             module.stem.1.bias  changing lr from: 0.100002488266439718   to: 0.099231245576892280
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.100016879766512509   to: 0.099256698506001217
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.100031030173900956   to: 0.099281726914481699
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.100044944077360476   to: 0.099306338824141735
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.100058625968122025   to: 0.099330542088240992
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.100072080242172914   to: 0.099354344395363711
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.100085311202479932   to: 0.099377753273195632
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.100098323061155847   to: 0.099400776092207904
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.100111119941571347   to: 0.099423420069250062
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.100123705880413291   to: 0.099445692271054556
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.100136084829691371   to: 0.099467599617655153
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.100148260658694144   to: 0.099489148885721482
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.100160237155895893   to: 0.099510346711811873
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.100172018030815824   to: 0.099531199595546543
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.100183606915830559   to: 0.099551713902703232
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.100195007367941499   to: 0.099571895868237545
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.100206222870498129   to: 0.099591751599229353
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.100217256834878435   to: 0.099611287077758015
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.100228112602127523   to: 0.099630508163707304
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.100238793444555718   to: 0.099649420597502758
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.100249302567297194   to: 0.099668030002782473
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.100259643109829918   to: 0.099686341889003563
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.100269818147458403   to: 0.099704361653985607
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.100279830692759794   to: 0.099722094586392876
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.100289683696994564   to: 0.099739545868156879
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.100299380051482645   to: 0.099756720576840763
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.100308922588945942   to: 0.099773623687946955
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.100318314084817950   to: 0.099790260077169693
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.100327557258521688   to: 0.099806634522593585
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.100336654774716413   to: 0.099822751706839949
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.100345609244514133   to: 0.099838616219161777
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.100354423226666697   to: 0.099854232557489153
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.100363099228724190   to: 0.099869605130425934
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.100371639708165344   to: 0.099884738259199177
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.100380047073500789   to: 0.099899636179562490
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.100388323685349737   to: 0.099914303043654409
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.100396471857490996   to: 0.099928742921812932
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.100404493857888605   to: 0.099942959804347420
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.100412391909693186   to: 0.099956957603268781
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.100420168192219272   to: 0.099970740153979110
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.100427824841899493   to: 0.099984311216921806
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.100435363953216006   to: 0.099997674479192999
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.100442787579609949   to: 0.100010833556115508
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.100450097734369262   to: 0.100023791992776084
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.100457296391495657   to: 0.100036553265526795
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.100464385486551150   to: 0.100049120783451698
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.100471366917484539   to: 0.100061497889799539
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.100478242545438717   to: 0.100073687863383082
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.100485014195538902   to: 0.100085693919946372
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.100491683657662423   to: 0.100097519213500380
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.100498252687190703   to: 0.100109166837627786
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.100504723005743590   to: 0.100120639826758007
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.100511096301896571   to: 0.100131941157412793
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.100517374231881576   to: 0.100143073749423397
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.100523558420271289   to: 0.100154040467119898
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.100529650460647796   to: 0.100164844120493382
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.100535651916255783   to: 0.100175487466331647
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.100541564320640639   to: 0.100185973209329093
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.100547389178271981   to: 0.100196304003171463
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.100553127965152839   to: 0.100206482451595857
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.100558782129414867   to: 0.100216511109427003
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.100564353091899927   to: 0.100226392483589943
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.100569842246728630   to: 0.100236129034099869
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.100575250961855545   to: 0.100245723175029958
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.100580580579612194   to: 0.100255177275457102
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.100585832417237495   to: 0.100264493660386700
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.100591007767396268   to: 0.100273674611656649
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.100596107898686060   to: 0.100282722368821131
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.100601134056132385   to: 0.100291639130014765
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.100606087461673169   to: 0.100300427052797389
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.100610969314631898   to: 0.100309088254980222
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.100615780792180434   to: 0.100317624815433562
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.100620523049791410   to: 0.100326038774876669
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.100625197221680493   to: 0.100334332136650176
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.100629804421238769   to: 0.100342506867471440
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.100634345741455605   to: 0.100350564898173261
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.100638822255332036   to: 0.100358508124426371
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.100643235016285026   to: 0.100366338407446035
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.100647585058542766   to: 0.100374057574683179
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.100651873397531288   to: 0.100381667420500392
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.100656101030252451   to: 0.100389169706833190
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.100660268935653760   to: 0.100396566163836881
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.100664378074990013   to: 0.100403858490519277
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.100668429392176906   to: 0.100411048355359717
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.100672423814137130   to: 0.100418137396914700
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.100676362251138671   to: 0.100425127224410368
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.100680245597125906   to: 0.100432019418322138
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.100684074730043441   to: 0.100438815530941944
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.100687850512152927   to: 0.100445517086933195
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.100691573790342992   to: 0.100452125583873828
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.100695245396432514   to: 0.100458642492787659
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.100698866147467245   to: 0.100465069258664455
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.100702436846010171   to: 0.100471407300968818
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.100705958280425611   to: 0.100477658014138160
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.100709431225157062   to: 0.100483822768070219
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.100712856440999296   to: 0.100489902908600076
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.100716234675364530   to: 0.100495899757967022
i: 100, name:           module.conv10.weight  changing lr from: 0.100719566662542920   to: 0.100501814615271773
i: 101, name:             module.conv10.bias  changing lr from: 0.100722853123957484   to: 0.100507648756923626



# Switched to train mode...
Epoch: [4][  0/391]	Time  0.220 ( 0.220)	Data  0.177 ( 0.177)	Loss 9.5850e-01 (9.5850e-01)	Acc@1  68.75 ( 68.75)	Acc@5  98.44 ( 98.44)
Epoch: [4][ 10/391]	Time  0.042 ( 0.056)	Data  0.001 ( 0.017)	Loss 6.6277e-01 (7.5348e-01)	Acc@1  79.69 ( 74.79)	Acc@5 100.00 ( 98.01)
Epoch: [4][ 20/391]	Time  0.039 ( 0.048)	Data  0.001 ( 0.009)	Loss 6.6666e-01 (7.2737e-01)	Acc@1  78.12 ( 75.71)	Acc@5  98.44 ( 98.10)
Epoch: [4][ 30/391]	Time  0.039 ( 0.046)	Data  0.001 ( 0.007)	Loss 8.0615e-01 (7.4959e-01)	Acc@1  71.88 ( 74.27)	Acc@5  98.44 ( 97.98)
Epoch: [4][ 40/391]	Time  0.043 ( 0.045)	Data  0.001 ( 0.005)	Loss 6.9685e-01 (7.4340e-01)	Acc@1  75.00 ( 74.52)	Acc@5 100.00 ( 98.06)
Epoch: [4][ 50/391]	Time  0.040 ( 0.044)	Data  0.001 ( 0.004)	Loss 7.6281e-01 (7.3668e-01)	Acc@1  69.53 ( 74.71)	Acc@5  97.66 ( 98.12)
Epoch: [4][ 60/391]	Time  0.039 ( 0.043)	Data  0.001 ( 0.004)	Loss 7.1900e-01 (7.3951e-01)	Acc@1  75.00 ( 74.59)	Acc@5  99.22 ( 98.07)
Epoch: [4][ 70/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.003)	Loss 8.0736e-01 (7.4553e-01)	Acc@1  69.53 ( 74.34)	Acc@5  99.22 ( 98.04)
Epoch: [4][ 80/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.003)	Loss 8.7330e-01 (7.4656e-01)	Acc@1  70.31 ( 74.24)	Acc@5  98.44 ( 98.06)
Epoch: [4][ 90/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.003)	Loss 6.6935e-01 (7.4286e-01)	Acc@1  73.44 ( 74.21)	Acc@5  99.22 ( 98.14)
Epoch: [4][100/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.003)	Loss 8.5424e-01 (7.4085e-01)	Acc@1  71.88 ( 74.31)	Acc@5  95.31 ( 98.14)
Epoch: [4][110/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.003)	Loss 6.9441e-01 (7.4231e-01)	Acc@1  78.12 ( 74.34)	Acc@5  97.66 ( 98.14)
Epoch: [4][120/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 7.4613e-01 (7.4283e-01)	Acc@1  75.00 ( 74.19)	Acc@5  98.44 ( 98.18)
Epoch: [4][130/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.002)	Loss 7.8662e-01 (7.4203e-01)	Acc@1  72.66 ( 74.18)	Acc@5  97.66 ( 98.16)
Epoch: [4][140/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 7.6712e-01 (7.4506e-01)	Acc@1  75.00 ( 74.05)	Acc@5  96.88 ( 98.15)
Epoch: [4][150/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.002)	Loss 7.7682e-01 (7.4475e-01)	Acc@1  71.09 ( 74.04)	Acc@5  98.44 ( 98.16)
Epoch: [4][160/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.002)	Loss 7.0583e-01 (7.4360e-01)	Acc@1  74.22 ( 74.13)	Acc@5  97.66 ( 98.14)
Epoch: [4][170/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 7.8673e-01 (7.4263e-01)	Acc@1  72.66 ( 74.14)	Acc@5  99.22 ( 98.16)
Epoch: [4][180/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 8.1192e-01 (7.4166e-01)	Acc@1  71.09 ( 74.18)	Acc@5  99.22 ( 98.20)
Epoch: [4][190/391]	Time  0.043 ( 0.041)	Data  0.001 ( 0.002)	Loss 7.5690e-01 (7.4015e-01)	Acc@1  71.09 ( 74.24)	Acc@5  98.44 ( 98.21)
Epoch: [4][200/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 9.2522e-01 (7.3937e-01)	Acc@1  69.53 ( 74.31)	Acc@5  98.44 ( 98.24)
Epoch: [4][210/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 8.4980e-01 (7.3711e-01)	Acc@1  70.31 ( 74.40)	Acc@5  99.22 ( 98.24)
Epoch: [4][220/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 7.1460e-01 (7.3721e-01)	Acc@1  72.66 ( 74.38)	Acc@5  99.22 ( 98.24)
Epoch: [4][230/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 6.8663e-01 (7.3756e-01)	Acc@1  74.22 ( 74.39)	Acc@5  96.88 ( 98.24)
Epoch: [4][240/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 7.9203e-01 (7.3563e-01)	Acc@1  75.78 ( 74.47)	Acc@5  97.66 ( 98.24)
Epoch: [4][250/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 6.2980e-01 (7.3211e-01)	Acc@1  76.56 ( 74.62)	Acc@5  98.44 ( 98.27)
Epoch: [4][260/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.8279e-01 (7.3184e-01)	Acc@1  77.34 ( 74.66)	Acc@5 100.00 ( 98.29)
Epoch: [4][270/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 6.3574e-01 (7.3102e-01)	Acc@1  80.47 ( 74.67)	Acc@5  99.22 ( 98.29)
Epoch: [4][280/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 9.1206e-01 (7.3107e-01)	Acc@1  69.53 ( 74.66)	Acc@5  96.09 ( 98.28)
Epoch: [4][290/391]	Time  0.043 ( 0.041)	Data  0.001 ( 0.002)	Loss 6.0387e-01 (7.2905e-01)	Acc@1  76.56 ( 74.70)	Acc@5 100.00 ( 98.28)
Epoch: [4][300/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 6.7629e-01 (7.2810e-01)	Acc@1  73.44 ( 74.74)	Acc@5  98.44 ( 98.28)
Epoch: [4][310/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.6647e-01 (7.2696e-01)	Acc@1  82.81 ( 74.81)	Acc@5 100.00 ( 98.28)
Epoch: [4][320/391]	Time  0.055 ( 0.041)	Data  0.001 ( 0.002)	Loss 8.5750e-01 (7.2642e-01)	Acc@1  69.53 ( 74.80)	Acc@5  98.44 ( 98.29)
Epoch: [4][330/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.4922e-01 (7.2580e-01)	Acc@1  82.03 ( 74.83)	Acc@5 100.00 ( 98.28)
Epoch: [4][340/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 8.6599e-01 (7.2619e-01)	Acc@1  69.53 ( 74.84)	Acc@5  96.88 ( 98.28)
Epoch: [4][350/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.001)	Loss 5.9595e-01 (7.2507e-01)	Acc@1  82.81 ( 74.89)	Acc@5  99.22 ( 98.30)
Epoch: [4][360/391]	Time  0.043 ( 0.041)	Data  0.001 ( 0.001)	Loss 5.7474e-01 (7.2324e-01)	Acc@1  78.12 ( 74.92)	Acc@5  99.22 ( 98.30)
Epoch: [4][370/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.001)	Loss 7.1870e-01 (7.2250e-01)	Acc@1  75.78 ( 74.97)	Acc@5  96.88 ( 98.30)
Epoch: [4][380/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.001)	Loss 6.9891e-01 (7.2125e-01)	Acc@1  72.66 ( 74.97)	Acc@5  96.88 ( 98.31)
Epoch: [4][390/391]	Time  0.028 ( 0.041)	Data  0.001 ( 0.001)	Loss 4.2630e-01 (7.1981e-01)	Acc@1  86.25 ( 75.00)	Acc@5 100.00 ( 98.31)
## e[4] optimizer.zero_grad (sum) time: 0.27065277099609375
## e[4]       loss.backward (sum) time: 4.031875848770142
## e[4]      optimizer.step (sum) time: 1.8221189975738525
## epoch[4] training(only) time: 16.102309703826904
# Switched to evaluate mode...
Test: [  0/100]	Time  0.178 ( 0.178)	Loss 7.9910e-01 (7.9910e-01)	Acc@1  71.00 ( 71.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.021 ( 0.035)	Loss 7.4464e-01 (8.6534e-01)	Acc@1  76.00 ( 70.45)	Acc@5  97.00 ( 97.64)
Test: [ 20/100]	Time  0.024 ( 0.028)	Loss 8.7380e-01 (8.5700e-01)	Acc@1  66.00 ( 70.52)	Acc@5  99.00 ( 97.71)
Test: [ 30/100]	Time  0.018 ( 0.025)	Loss 7.9693e-01 (8.7343e-01)	Acc@1  73.00 ( 70.55)	Acc@5  99.00 ( 97.71)
Test: [ 40/100]	Time  0.017 ( 0.024)	Loss 6.5122e-01 (8.6613e-01)	Acc@1  79.00 ( 70.98)	Acc@5  98.00 ( 97.51)
Test: [ 50/100]	Time  0.023 ( 0.023)	Loss 7.7608e-01 (8.6084e-01)	Acc@1  77.00 ( 71.45)	Acc@5  97.00 ( 97.53)
Test: [ 60/100]	Time  0.018 ( 0.022)	Loss 8.1255e-01 (8.6096e-01)	Acc@1  69.00 ( 71.41)	Acc@5  97.00 ( 97.49)
Test: [ 70/100]	Time  0.022 ( 0.022)	Loss 7.7967e-01 (8.6260e-01)	Acc@1  74.00 ( 71.38)	Acc@5 100.00 ( 97.56)
Test: [ 80/100]	Time  0.020 ( 0.022)	Loss 7.6652e-01 (8.6018e-01)	Acc@1  71.00 ( 71.30)	Acc@5  98.00 ( 97.68)
Test: [ 90/100]	Time  0.024 ( 0.022)	Loss 9.8172e-01 (8.6749e-01)	Acc@1  69.00 ( 71.05)	Acc@5  99.00 ( 97.67)
 * Acc@1 71.040 Acc@5 97.610
### epoch[4] execution time: 18.3432719707489
EPOCH 5
i:   0, name:           module.stem.0.weight  changing lr from: 0.099152256835388142   to: 0.098122964374747490
i:   1, name:             module.stem.0.bias  changing lr from: 0.099179033202888206   to: 0.098164512044310162
i:   2, name:           module.stem.1.weight  changing lr from: 0.099205359932827558   to: 0.098205366201707930
i:   3, name:             module.stem.1.bias  changing lr from: 0.099231245576892280   to: 0.098245539906643739
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.099256698506001217   to: 0.098285045947149069
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.099281726914481699   to: 0.098323896845700601
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.099306338824141735   to: 0.098362104865191369
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.099330542088240992   to: 0.098399682014759571
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.099354344395363711   to: 0.098436640055479016
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.099377753273195632   to: 0.098472990505913946
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.099400776092207904   to: 0.098508744647542251
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.099423420069250062   to: 0.098543913530049793
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.099445692271054556   to: 0.098578507976499100
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.099467599617655153   to: 0.098612538588375764
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.099489148885721482   to: 0.098646015750515154
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.099510346711811873   to: 0.098678949635912672
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.099531199595546543   to: 0.098711350210420282
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.099551713902703232   to: 0.098743227237332157
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.099571895868237545   to: 0.098774590281862015
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.099591751599229353   to: 0.098805448715515096
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.099611287077758015   to: 0.098835811720357047
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.099630508163707304   to: 0.098865688293182430
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.099649420597502758   to: 0.098895087249585276
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.099668030002782473   to: 0.098924017227934036
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.099686341889003563   to: 0.098952486693253405
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.099704361653985607   to: 0.098980503941015111
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.099722094586392876   to: 0.099008077100840058
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.099739545868156879   to: 0.099035214140113945
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.099756720576840763   to: 0.099061922867518359
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.099773623687946955   to: 0.099088210936479806
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.099790260077169693   to: 0.099114085848537994
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.099806634522593585   to: 0.099139554956636150
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.099822751706839949   to: 0.099164625468334627
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.099838616219161777   to: 0.099189304448950050
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.099854232557489153   to: 0.099213598824621621
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.099869605130425934   to: 0.099237515385306577
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.099884738259199177   to: 0.099261060787706190
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.099899636179562490   to: 0.099284241558124320
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.099914303043654409   to: 0.099307064095260161
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.099928742921812932   to: 0.099329534672936357
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.099942959804347420   to: 0.099351659442764681
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.099956957603268781   to: 0.099373444436750294
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.099970740153979110   to: 0.099394895569836383
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.099984311216921806   to: 0.099416018642390386
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.099997674479192999   to: 0.099436819342633403
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.100010833556115508   to: 0.099457303249014140
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.100023791992776084   to: 0.099477475832528611
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.100036553265526795   to: 0.099497342458987101
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.100049120783451698   to: 0.099516908391229411
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.100061497889799539   to: 0.099536178791289912
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.100073687863383082   to: 0.099555158722513373
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.100085693919946372   to: 0.099573853151622982
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.100097519213500380   to: 0.099592266950741443
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.100109166837627786   to: 0.099610404899366539
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.100120639826758007   to: 0.099628271686302061
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.100131941157412793   to: 0.099645871911545281
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.100143073749423397   to: 0.099663210088132018
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.100154040467119898   to: 0.099680290643940114
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.100164844120493382   to: 0.099697117923452663
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.100175487466331647   to: 0.099713696189481726
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.100185973209329093   to: 0.099730029624853320
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.100196304003171463   to: 0.099746122334055054
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.100206482451595857   to: 0.099761978344846902
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.100216511109427003   to: 0.099777601609836120
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.100226392483589943   to: 0.099792996008017262
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.100236129034099869   to: 0.099808165346277858
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.100245723175029958   to: 0.099823113360870977
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.100255177275457102   to: 0.099837843718854957
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.100264493660386700   to: 0.099852360019501582
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.100273674611656649   to: 0.099866665795672938
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.100282722368821131   to: 0.099880764515168308
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.100291639130014765   to: 0.099894659582041065
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.100300427052797389   to: 0.099908354337886987
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.100309088254980222   to: 0.099921852063104138
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.100317624815433562   to: 0.099935155978125259
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.100326038774876669   to: 0.099948269244623286
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.100334332136650176   to: 0.099961194966690425
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.100342506867471440   to: 0.099973936191991755
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.100350564898173261   to: 0.099986495912893492
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.100358508124426371   to: 0.099998877067567077
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.100366338407446035   to: 0.100011082541069052
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.100374057574683179   to: 0.100023115166397683
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.100381667420500392   to: 0.100034977725526830
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.100389169706833190   to: 0.100046672950417359
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.100396566163836881   to: 0.100058203524006920
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.100403858490519277   to: 0.100069572081178337
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.100411048355359717   to: 0.100080781209707259
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.100418137396914700   to: 0.100091833451189466
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.100425127224410368   to: 0.100102731301948494
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.100432019418322138   to: 0.100113477213923552
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.100438815530941944   to: 0.100124073595538765
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.100445517086933195   to: 0.100134522812553931
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.100452125583873828   to: 0.100144827188896890
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.100458642492787659   to: 0.100154989007478615
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.100465069258664455   to: 0.100165010510990693
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.100471407300968818   to: 0.100174893902686177
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.100477658014138160   to: 0.100184641347143832
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.100483822768070219   to: 0.100194254971016222
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.100489902908600076   to: 0.100203736863762188
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.100495899757967022   to: 0.100213089078363793
i: 100, name:           module.conv10.weight  changing lr from: 0.100501814615271773   to: 0.100222313632028340
i: 101, name:             module.conv10.bias  changing lr from: 0.100507648756923626   to: 0.100231412506875533



# Switched to train mode...
Epoch: [5][  0/391]	Time  0.210 ( 0.210)	Data  0.168 ( 0.168)	Loss 5.8581e-01 (5.8581e-01)	Acc@1  78.12 ( 78.12)	Acc@5  99.22 ( 99.22)
Epoch: [5][ 10/391]	Time  0.041 ( 0.055)	Data  0.001 ( 0.016)	Loss 7.2300e-01 (7.0608e-01)	Acc@1  71.88 ( 74.15)	Acc@5  99.22 ( 98.22)
Epoch: [5][ 20/391]	Time  0.038 ( 0.049)	Data  0.001 ( 0.009)	Loss 6.4480e-01 (6.8671e-01)	Acc@1  75.78 ( 75.37)	Acc@5  99.22 ( 98.25)
Epoch: [5][ 30/391]	Time  0.039 ( 0.046)	Data  0.001 ( 0.006)	Loss 6.5920e-01 (6.8065e-01)	Acc@1  78.91 ( 75.83)	Acc@5  98.44 ( 98.34)
Epoch: [5][ 40/391]	Time  0.043 ( 0.045)	Data  0.001 ( 0.005)	Loss 5.7400e-01 (6.6483e-01)	Acc@1  78.91 ( 76.62)	Acc@5  99.22 ( 98.34)
Epoch: [5][ 50/391]	Time  0.038 ( 0.043)	Data  0.001 ( 0.004)	Loss 7.2415e-01 (6.6245e-01)	Acc@1  77.34 ( 76.64)	Acc@5  96.88 ( 98.44)
Epoch: [5][ 60/391]	Time  0.039 ( 0.043)	Data  0.001 ( 0.004)	Loss 6.1839e-01 (6.6808e-01)	Acc@1  78.91 ( 76.45)	Acc@5  99.22 ( 98.36)
Epoch: [5][ 70/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.003)	Loss 7.1298e-01 (6.6206e-01)	Acc@1  75.00 ( 76.65)	Acc@5  98.44 ( 98.39)
Epoch: [5][ 80/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.003)	Loss 7.1791e-01 (6.5820e-01)	Acc@1  76.56 ( 76.84)	Acc@5  98.44 ( 98.43)
Epoch: [5][ 90/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.003)	Loss 6.5990e-01 (6.6201e-01)	Acc@1  78.91 ( 76.66)	Acc@5  98.44 ( 98.48)
Epoch: [5][100/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.003)	Loss 7.4237e-01 (6.6573e-01)	Acc@1  77.34 ( 76.55)	Acc@5  96.09 ( 98.46)
Epoch: [5][110/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.4306e-01 (6.6396e-01)	Acc@1  78.12 ( 76.62)	Acc@5  99.22 ( 98.51)
Epoch: [5][120/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.9648e-01 (6.6417e-01)	Acc@1  76.56 ( 76.67)	Acc@5  99.22 ( 98.50)
Epoch: [5][130/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 7.2759e-01 (6.6425e-01)	Acc@1  77.34 ( 76.74)	Acc@5  99.22 ( 98.54)
Epoch: [5][140/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 4.7460e-01 (6.6358e-01)	Acc@1  86.72 ( 76.80)	Acc@5  98.44 ( 98.56)
Epoch: [5][150/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 7.1773e-01 (6.6516e-01)	Acc@1  77.34 ( 76.81)	Acc@5  99.22 ( 98.56)
Epoch: [5][160/391]	Time  0.045 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.8770e-01 (6.6523e-01)	Acc@1  76.56 ( 76.83)	Acc@5  99.22 ( 98.58)
Epoch: [5][170/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 6.1751e-01 (6.6509e-01)	Acc@1  85.16 ( 76.92)	Acc@5  96.88 ( 98.57)
Epoch: [5][180/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 7.2918e-01 (6.6698e-01)	Acc@1  75.78 ( 76.90)	Acc@5  96.88 ( 98.54)
Epoch: [5][190/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 6.0846e-01 (6.6473e-01)	Acc@1  84.38 ( 76.96)	Acc@5  99.22 ( 98.55)
Epoch: [5][200/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 7.9979e-01 (6.6599e-01)	Acc@1  73.44 ( 76.96)	Acc@5  98.44 ( 98.55)
Epoch: [5][210/391]	Time  0.045 ( 0.041)	Data  0.001 ( 0.002)	Loss 6.5946e-01 (6.6553e-01)	Acc@1  75.78 ( 76.93)	Acc@5 100.00 ( 98.58)
Epoch: [5][220/391]	Time  0.043 ( 0.041)	Data  0.001 ( 0.002)	Loss 7.2951e-01 (6.6628e-01)	Acc@1  78.12 ( 76.95)	Acc@5  99.22 ( 98.59)
Epoch: [5][230/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.9220e-01 (6.6639e-01)	Acc@1  82.03 ( 76.91)	Acc@5 100.00 ( 98.61)
Epoch: [5][240/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 6.1448e-01 (6.6540e-01)	Acc@1  77.34 ( 76.96)	Acc@5  99.22 ( 98.62)
Epoch: [5][250/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.8217e-01 (6.6675e-01)	Acc@1  81.25 ( 76.97)	Acc@5  99.22 ( 98.62)
Epoch: [5][260/391]	Time  0.044 ( 0.041)	Data  0.001 ( 0.002)	Loss 6.3952e-01 (6.6539e-01)	Acc@1  78.12 ( 77.02)	Acc@5 100.00 ( 98.62)
Epoch: [5][270/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 6.3861e-01 (6.6601e-01)	Acc@1  78.12 ( 77.02)	Acc@5  98.44 ( 98.62)
Epoch: [5][280/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 6.7908e-01 (6.6600e-01)	Acc@1  75.78 ( 77.05)	Acc@5 100.00 ( 98.62)
Epoch: [5][290/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 6.5969e-01 (6.6503e-01)	Acc@1  77.34 ( 77.06)	Acc@5  97.66 ( 98.63)
Epoch: [5][300/391]	Time  0.043 ( 0.041)	Data  0.001 ( 0.002)	Loss 6.5821e-01 (6.6470e-01)	Acc@1  78.12 ( 77.07)	Acc@5  99.22 ( 98.64)
Epoch: [5][310/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.7216e-01 (6.6148e-01)	Acc@1  80.47 ( 77.20)	Acc@5  96.09 ( 98.62)
Epoch: [5][320/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.001)	Loss 6.9948e-01 (6.5964e-01)	Acc@1  80.47 ( 77.28)	Acc@5  96.09 ( 98.62)
Epoch: [5][330/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.001)	Loss 6.2355e-01 (6.5789e-01)	Acc@1  79.69 ( 77.34)	Acc@5 100.00 ( 98.64)
Epoch: [5][340/391]	Time  0.045 ( 0.041)	Data  0.001 ( 0.001)	Loss 6.7861e-01 (6.5737e-01)	Acc@1  75.00 ( 77.33)	Acc@5  99.22 ( 98.63)
Epoch: [5][350/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.001)	Loss 6.8860e-01 (6.5592e-01)	Acc@1  76.56 ( 77.39)	Acc@5  98.44 ( 98.63)
Epoch: [5][360/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.001)	Loss 5.6386e-01 (6.5420e-01)	Acc@1  77.34 ( 77.44)	Acc@5 100.00 ( 98.64)
Epoch: [5][370/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.001)	Loss 6.4166e-01 (6.5355e-01)	Acc@1  78.91 ( 77.48)	Acc@5  97.66 ( 98.65)
Epoch: [5][380/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.001)	Loss 8.0085e-01 (6.5452e-01)	Acc@1  74.22 ( 77.42)	Acc@5  98.44 ( 98.64)
Epoch: [5][390/391]	Time  0.034 ( 0.041)	Data  0.001 ( 0.001)	Loss 7.9354e-01 (6.5473e-01)	Acc@1  73.75 ( 77.41)	Acc@5 100.00 ( 98.64)
## e[5] optimizer.zero_grad (sum) time: 0.27240514755249023
## e[5]       loss.backward (sum) time: 4.049726724624634
## e[5]      optimizer.step (sum) time: 1.7900426387786865
## epoch[5] training(only) time: 16.143518209457397
# Switched to evaluate mode...
Test: [  0/100]	Time  0.181 ( 0.181)	Loss 6.3146e-01 (6.3146e-01)	Acc@1  76.00 ( 76.00)	Acc@5  96.00 ( 96.00)
Test: [ 10/100]	Time  0.017 ( 0.037)	Loss 7.8646e-01 (7.1977e-01)	Acc@1  79.00 ( 76.36)	Acc@5  97.00 ( 97.91)
Test: [ 20/100]	Time  0.018 ( 0.029)	Loss 7.4404e-01 (7.1763e-01)	Acc@1  72.00 ( 75.81)	Acc@5 100.00 ( 98.14)
Test: [ 30/100]	Time  0.017 ( 0.026)	Loss 7.5901e-01 (7.3595e-01)	Acc@1  74.00 ( 75.35)	Acc@5  98.00 ( 98.23)
Test: [ 40/100]	Time  0.021 ( 0.024)	Loss 7.4861e-01 (7.3828e-01)	Acc@1  73.00 ( 75.39)	Acc@5  96.00 ( 98.24)
Test: [ 50/100]	Time  0.020 ( 0.024)	Loss 6.2188e-01 (7.2840e-01)	Acc@1  79.00 ( 75.57)	Acc@5  97.00 ( 98.22)
Test: [ 60/100]	Time  0.024 ( 0.023)	Loss 6.0513e-01 (7.2865e-01)	Acc@1  79.00 ( 75.74)	Acc@5  99.00 ( 98.26)
Test: [ 70/100]	Time  0.026 ( 0.023)	Loss 7.5337e-01 (7.2451e-01)	Acc@1  73.00 ( 75.63)	Acc@5  99.00 ( 98.32)
Test: [ 80/100]	Time  0.018 ( 0.023)	Loss 5.4434e-01 (7.1761e-01)	Acc@1  78.00 ( 75.91)	Acc@5  99.00 ( 98.37)
Test: [ 90/100]	Time  0.022 ( 0.023)	Loss 6.3713e-01 (7.1859e-01)	Acc@1  79.00 ( 75.85)	Acc@5 100.00 ( 98.37)
 * Acc@1 75.990 Acc@5 98.370
### epoch[5] execution time: 18.492194652557373
EPOCH 6
i:   0, name:           module.stem.0.weight  changing lr from: 0.098122964374747490   to: 0.096874724822374580
i:   1, name:             module.stem.0.bias  changing lr from: 0.098164512044310162   to: 0.096934044715140458
i:   2, name:           module.stem.1.weight  changing lr from: 0.098205366201707930   to: 0.096992381765385993
i:   3, name:             module.stem.1.bias  changing lr from: 0.098245539906643739   to: 0.097049754252102480
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.098285045947149069   to: 0.097106180081789714
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.098323896845700601   to: 0.097161676796559404
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.098362104865191369   to: 0.097216261582056651
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.098399682014759571   to: 0.097269951275203839
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.098436640055479016   to: 0.097322762371770274
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.098472990505913946   to: 0.097374711033772043
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.098508744647542251   to: 0.097425813096705158
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.098543913530049793   to: 0.097476084076616260
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.098578507976499100   to: 0.097525539177013995
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.098612538588375764   to: 0.097574193295625000
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.098646015750515154   to: 0.097622061030997631
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.098678949635912672   to: 0.097669156688957065
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.098711350210420282   to: 0.097715494288915045
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.098743227237332157   to: 0.097761087570037361
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.098774590281862015   to: 0.097805949997272670
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.098805448715515096   to: 0.097850094767245321
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.098835811720357047   to: 0.097893534814015512
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.098865688293182430   to: 0.097936282814709813
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.098895087249585276   to: 0.097978351195024918
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.098924017227934036   to: 0.098019752134607396
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.098952486693253405   to: 0.098060497572312555
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.098980503941015111   to: 0.098100599211344841
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.099008077100840058   to: 0.098140068524282767
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.099035214140113945   to: 0.098178916757990842
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.099061922867518359   to: 0.098217154938421009
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.099088210936479806   to: 0.098254793875306515
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.099114085848537994   to: 0.098291844166750089
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.099139554956636150   to: 0.098328316203709409
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.099164625468334627   to: 0.098364220174381872
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.099189304448950050   to: 0.098399566068491082
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.099213598824621621   to: 0.098434363681477455
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.099237515385306577   to: 0.098468622618594820
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.099261060787706190   to: 0.098502352298915546
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.099284241558124320   to: 0.098535561959246107
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.099307064095260161   to: 0.098568260657955098
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.099329534672936357   to: 0.098600457278715969
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.099351659442764681   to: 0.098632160534166083
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.099373444436750294   to: 0.098663378969484461
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.099394895569836383   to: 0.098694120965889642
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.099416018642390386   to: 0.098724394744059848
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.099436819342633403   to: 0.098754208367477142
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.099457303249014140   to: 0.098783569745697256
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.099477475832528611   to: 0.098812486637546854
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.099497342458987101   to: 0.098840966654249976
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.099516908391229411   to: 0.098869017262485245
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.099536178791289912   to: 0.098896645787375323
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.099555158722513373   to: 0.098923859415410487
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.099573853151622982   to: 0.098950665197307441
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.099592266950741443   to: 0.098977070050805194
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.099610404899366539   to: 0.099003080763399282
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.099628271686302061   to: 0.099028703995015899
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.099645871911545281   to: 0.099053946280627039
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.099663210088132018   to: 0.099078814032808368
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.099680290643940114   to: 0.099103313544240915
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.099697117923452663   to: 0.099127450990157920
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.099713696189481726   to: 0.099151232430738159
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.099730029624853320   to: 0.099174663813446889
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.099746122334055054   to: 0.099197750975325738
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.099761978344846902   to: 0.099220499645232496
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.099777601609836120   to: 0.099242915446032365
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.099792996008017262   to: 0.099265003896741227
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.099808165346277858   to: 0.099286770414622458
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.099823113360870977   to: 0.099308220317238322
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.099837843718854957   to: 0.099329358824456690
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.099852360019501582   to: 0.099350191060414428
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.099866665795672938   to: 0.099370722055438288
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.099880764515168308   to: 0.099390956747924308
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.099894659582041065   to: 0.099410899986176637
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.099908354337886987   to: 0.099430556530206701
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.099921852063104138   to: 0.099449931053493895
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.099935155978125259   to: 0.099469028144708038
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.099948269244623286   to: 0.099487852309395261
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.099961194966690425   to: 0.099506407971627409
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.099973936191991755   to: 0.099524699475616429
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.099986495912893492   to: 0.099542731087294056
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.099998877067567077   to: 0.099560506995857875
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.100011082541069052   to: 0.099578031315284310
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.100023115166397683   to: 0.099595308085809589
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.100034977725526830   to: 0.099612341275378977
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.100046672950417359   to: 0.099629134781065484
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.100058203524006920   to: 0.099645692430458288
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.100069572081178337   to: 0.099662017983021906
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.100080781209707259   to: 0.099678115131426534
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.100091833451189466   to: 0.099693987502850301
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.100102731301948494   to: 0.099709638660254174
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.100113477213923552   to: 0.099725072103629867
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.100124073595538765   to: 0.099740291271221623
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.100134522812553931   to: 0.099755299540722223
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.100144827188896890   to: 0.099770100230444136
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.100154989007478615   to: 0.099784696600465864
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.100165010510990693   to: 0.099799091853754573
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.100174893902686177   to: 0.099813289137265171
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.100184641347143832   to: 0.099827291543016408
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.100194254971016222   to: 0.099841102109144750
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.100203736863762188   to: 0.099854723820936173
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.100213089078363793   to: 0.099868159611836732
i: 100, name:           module.conv10.weight  changing lr from: 0.100222313632028340   to: 0.099881412364441924
i: 101, name:             module.conv10.bias  changing lr from: 0.100231412506875533   to: 0.099894484911465894



# Switched to train mode...
Epoch: [6][  0/391]	Time  0.216 ( 0.216)	Data  0.173 ( 0.173)	Loss 6.6746e-01 (6.6746e-01)	Acc@1  72.66 ( 72.66)	Acc@5  99.22 ( 99.22)
Epoch: [6][ 10/391]	Time  0.039 ( 0.057)	Data  0.001 ( 0.017)	Loss 5.8461e-01 (6.5489e-01)	Acc@1  80.47 ( 76.92)	Acc@5 100.00 ( 98.51)
Epoch: [6][ 20/391]	Time  0.040 ( 0.049)	Data  0.001 ( 0.009)	Loss 6.2120e-01 (6.3058e-01)	Acc@1  79.69 ( 78.16)	Acc@5  98.44 ( 98.51)
Epoch: [6][ 30/391]	Time  0.040 ( 0.046)	Data  0.001 ( 0.007)	Loss 6.3576e-01 (6.2955e-01)	Acc@1  78.91 ( 78.23)	Acc@5  99.22 ( 98.64)
Epoch: [6][ 40/391]	Time  0.039 ( 0.045)	Data  0.001 ( 0.005)	Loss 7.1922e-01 (6.3300e-01)	Acc@1  78.91 ( 78.30)	Acc@5  96.09 ( 98.70)
Epoch: [6][ 50/391]	Time  0.039 ( 0.044)	Data  0.001 ( 0.004)	Loss 5.9695e-01 (6.2806e-01)	Acc@1  78.91 ( 78.39)	Acc@5  98.44 ( 98.67)
Epoch: [6][ 60/391]	Time  0.039 ( 0.043)	Data  0.001 ( 0.004)	Loss 7.0389e-01 (6.2458e-01)	Acc@1  77.34 ( 78.55)	Acc@5  98.44 ( 98.72)
Epoch: [6][ 70/391]	Time  0.039 ( 0.043)	Data  0.001 ( 0.003)	Loss 5.8626e-01 (6.2396e-01)	Acc@1  75.78 ( 78.53)	Acc@5  99.22 ( 98.75)
Epoch: [6][ 80/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.003)	Loss 4.8531e-01 (6.1873e-01)	Acc@1  83.59 ( 78.73)	Acc@5  99.22 ( 98.78)
Epoch: [6][ 90/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.003)	Loss 6.5183e-01 (6.1666e-01)	Acc@1  77.34 ( 78.69)	Acc@5  97.66 ( 98.80)
Epoch: [6][100/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.003)	Loss 4.9957e-01 (6.1040e-01)	Acc@1  77.34 ( 78.83)	Acc@5  99.22 ( 98.84)
Epoch: [6][110/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 4.7723e-01 (6.0477e-01)	Acc@1  82.03 ( 79.05)	Acc@5  98.44 ( 98.83)
Epoch: [6][120/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.8984e-01 (6.0216e-01)	Acc@1  82.03 ( 79.18)	Acc@5  98.44 ( 98.81)
Epoch: [6][130/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.6229e-01 (5.9908e-01)	Acc@1  79.69 ( 79.30)	Acc@5  96.09 ( 98.79)
Epoch: [6][140/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.9066e-01 (5.9946e-01)	Acc@1  74.22 ( 79.28)	Acc@5 100.00 ( 98.80)
Epoch: [6][150/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.6288e-01 (6.0184e-01)	Acc@1  82.03 ( 79.18)	Acc@5 100.00 ( 98.80)
Epoch: [6][160/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.002)	Loss 7.3027e-01 (6.0283e-01)	Acc@1  77.34 ( 79.15)	Acc@5  99.22 ( 98.80)
Epoch: [6][170/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.9730e-01 (6.0391e-01)	Acc@1  81.25 ( 79.08)	Acc@5  97.66 ( 98.78)
Epoch: [6][180/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 6.8884e-01 (6.0374e-01)	Acc@1  81.25 ( 79.08)	Acc@5  98.44 ( 98.80)
Epoch: [6][190/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 6.6653e-01 (6.0545e-01)	Acc@1  77.34 ( 79.03)	Acc@5  97.66 ( 98.79)
Epoch: [6][200/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 7.6295e-01 (6.0903e-01)	Acc@1  74.22 ( 78.86)	Acc@5  97.66 ( 98.80)
Epoch: [6][210/391]	Time  0.040 ( 0.041)	Data  0.002 ( 0.002)	Loss 5.1373e-01 (6.1162e-01)	Acc@1  79.69 ( 78.79)	Acc@5 100.00 ( 98.79)
Epoch: [6][220/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 7.2684e-01 (6.1037e-01)	Acc@1  74.22 ( 78.83)	Acc@5  98.44 ( 98.80)
Epoch: [6][230/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 6.2836e-01 (6.0978e-01)	Acc@1  80.47 ( 78.88)	Acc@5  98.44 ( 98.78)
Epoch: [6][240/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 6.8401e-01 (6.0933e-01)	Acc@1  78.12 ( 78.91)	Acc@5  97.66 ( 98.76)
Epoch: [6][250/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.9658e-01 (6.0796e-01)	Acc@1  75.00 ( 78.95)	Acc@5  99.22 ( 98.77)
Epoch: [6][260/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 6.1034e-01 (6.0885e-01)	Acc@1  80.47 ( 78.92)	Acc@5 100.00 ( 98.78)
Epoch: [6][270/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.0914e-01 (6.0896e-01)	Acc@1  79.69 ( 78.91)	Acc@5  99.22 ( 98.78)
Epoch: [6][280/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.0065e-01 (6.0759e-01)	Acc@1  82.81 ( 78.94)	Acc@5  99.22 ( 98.77)
Epoch: [6][290/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 6.5171e-01 (6.0682e-01)	Acc@1  75.78 ( 78.95)	Acc@5  98.44 ( 98.77)
Epoch: [6][300/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.1622e-01 (6.0575e-01)	Acc@1  84.38 ( 79.02)	Acc@5  99.22 ( 98.78)
Epoch: [6][310/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 6.0932e-01 (6.0722e-01)	Acc@1  78.91 ( 79.00)	Acc@5  98.44 ( 98.78)
Epoch: [6][320/391]	Time  0.043 ( 0.041)	Data  0.001 ( 0.002)	Loss 7.1730e-01 (6.0734e-01)	Acc@1  75.78 ( 78.98)	Acc@5  97.66 ( 98.79)
Epoch: [6][330/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.001)	Loss 5.8071e-01 (6.0676e-01)	Acc@1  78.12 ( 78.98)	Acc@5  99.22 ( 98.79)
Epoch: [6][340/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.001)	Loss 5.3518e-01 (6.0535e-01)	Acc@1  82.03 ( 79.02)	Acc@5  99.22 ( 98.80)
Epoch: [6][350/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.001)	Loss 4.7679e-01 (6.0496e-01)	Acc@1  85.16 ( 79.04)	Acc@5  99.22 ( 98.80)
Epoch: [6][360/391]	Time  0.035 ( 0.041)	Data  0.001 ( 0.001)	Loss 5.6691e-01 (6.0443e-01)	Acc@1  83.59 ( 79.04)	Acc@5  98.44 ( 98.81)
Epoch: [6][370/391]	Time  0.043 ( 0.041)	Data  0.001 ( 0.001)	Loss 5.8776e-01 (6.0379e-01)	Acc@1  81.25 ( 79.04)	Acc@5 100.00 ( 98.81)
Epoch: [6][380/391]	Time  0.044 ( 0.041)	Data  0.001 ( 0.001)	Loss 7.3303e-01 (6.0300e-01)	Acc@1  75.00 ( 79.05)	Acc@5  99.22 ( 98.82)
Epoch: [6][390/391]	Time  0.028 ( 0.041)	Data  0.001 ( 0.001)	Loss 5.0358e-01 (6.0372e-01)	Acc@1  83.75 ( 79.02)	Acc@5 100.00 ( 98.82)
## e[6] optimizer.zero_grad (sum) time: 0.2709958553314209
## e[6]       loss.backward (sum) time: 3.968687057495117
## e[6]      optimizer.step (sum) time: 1.8088035583496094
## epoch[6] training(only) time: 16.047802686691284
# Switched to evaluate mode...
Test: [  0/100]	Time  0.182 ( 0.182)	Loss 6.0547e-01 (6.0547e-01)	Acc@1  79.00 ( 79.00)	Acc@5  98.00 ( 98.00)
Test: [ 10/100]	Time  0.017 ( 0.035)	Loss 7.3078e-01 (7.3138e-01)	Acc@1  76.00 ( 75.91)	Acc@5  98.00 ( 98.27)
Test: [ 20/100]	Time  0.023 ( 0.028)	Loss 7.4733e-01 (7.1157e-01)	Acc@1  72.00 ( 76.10)	Acc@5 100.00 ( 98.19)
Test: [ 30/100]	Time  0.018 ( 0.025)	Loss 8.7311e-01 (7.4053e-01)	Acc@1  67.00 ( 75.06)	Acc@5  99.00 ( 97.94)
Test: [ 40/100]	Time  0.017 ( 0.024)	Loss 7.6299e-01 (7.5490e-01)	Acc@1  80.00 ( 74.80)	Acc@5  98.00 ( 97.98)
Test: [ 50/100]	Time  0.021 ( 0.024)	Loss 6.3366e-01 (7.4696e-01)	Acc@1  81.00 ( 75.14)	Acc@5  98.00 ( 98.04)
Test: [ 60/100]	Time  0.024 ( 0.023)	Loss 6.4247e-01 (7.5143e-01)	Acc@1  78.00 ( 75.10)	Acc@5 100.00 ( 98.15)
Test: [ 70/100]	Time  0.026 ( 0.023)	Loss 6.4512e-01 (7.5017e-01)	Acc@1  75.00 ( 75.06)	Acc@5 100.00 ( 98.20)
Test: [ 80/100]	Time  0.018 ( 0.023)	Loss 6.4412e-01 (7.4502e-01)	Acc@1  75.00 ( 75.21)	Acc@5  98.00 ( 98.27)
Test: [ 90/100]	Time  0.020 ( 0.022)	Loss 6.6121e-01 (7.5119e-01)	Acc@1  75.00 ( 74.96)	Acc@5 100.00 ( 98.26)
 * Acc@1 74.950 Acc@5 98.260
### epoch[6] execution time: 18.326272010803223
EPOCH 7
i:   0, name:           module.stem.0.weight  changing lr from: 0.096874724822374580   to: 0.095413337864757808
i:   1, name:             module.stem.0.bias  changing lr from: 0.096934044715140458   to: 0.095493265000109517
i:   2, name:           module.stem.1.weight  changing lr from: 0.096992381765385993   to: 0.095571879612025609
i:   3, name:             module.stem.1.bias  changing lr from: 0.097049754252102480   to: 0.095649205742293145
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.097106180081789714   to: 0.095725266955318633
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.097161676796559404   to: 0.095800086348048916
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.097216261582056651   to: 0.095873686559688531
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.097269951275203839   to: 0.095946089781216840
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.097322762371770274   to: 0.096017317764708440
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.097374711033772043   to: 0.096087391832460720
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.097425813096705158   to: 0.096156332885931714
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.097476084076616260   to: 0.096224161414492068
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.097525539177013995   to: 0.096290897503994138
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.097574193295625000   to: 0.096356560845162254
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.097622061030997631   to: 0.096421170741806853
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.097669156688957065   to: 0.096484746118866538
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.097715494288915045   to: 0.096547305530280625
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.097761087570037361   to: 0.096608867166696200
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.097805949997272670   to: 0.096669448863012417
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.097850094767245321   to: 0.096729068105765356
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.097893534814015512   to: 0.096787742040356742
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.097936282814709813   to: 0.096845487478129447
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.097978351195024918   to: 0.096902320903292941
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.098019752134607396   to: 0.096958258479701673
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.098060497572312555   to: 0.097013316057489377
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.098100599211344841   to: 0.097067509179562333
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.098140068524282767   to: 0.097120853087954109
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.098178916757990842   to: 0.097173362730045176
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.098217154938421009   to: 0.097225052764649711
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.098254793875306515   to: 0.097275937567972481
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.098291844166750089   to: 0.097326031239438712
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.098328316203709409   to: 0.097375347607399215
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.098364220174381872   to: 0.097423900234713728
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.098399566068491082   to: 0.097471702424214754
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.098434363681477455   to: 0.097518767224054670
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.098468622618594820   to: 0.097565107432938336
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.098502352298915546   to: 0.097610735605243790
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.098535561959246107   to: 0.097655664056033292
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.098568260657955098   to: 0.097699904865957199
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.098600457278715969   to: 0.097743469886052703
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.098632160534166083   to: 0.097786370742440065
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.098663378969484461   to: 0.097828618840918105
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.098694120965889642   to: 0.097870225371461450
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.098724394744059848   to: 0.097911201312621432
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.098754208367477142   to: 0.097951557435833003
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.098783569745697256   to: 0.097991304309629157
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.098812486637546854   to: 0.098030452303765531
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.098840966654249976   to: 0.098069011593256719
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.098869017262485245   to: 0.098106992162326059
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.098896645787375323   to: 0.098144403808271385
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.098923859415410487   to: 0.098181256145247836
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.098950665197307441   to: 0.098217558607970171
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.098977070050805194   to: 0.098253320455335802
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.099003080763399282   to: 0.098288550773970765
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.099028703995015899   to: 0.098323258481699857
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.099053946280627039   to: 0.098357452330942910
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.099078814032808368   to: 0.098391140912038794
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.099103313544240915   to: 0.098424332656498442
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.099127450990157920   to: 0.098457035840188875
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.099151232430738159   to: 0.098489258586449371
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.099174663813446889   to: 0.098521008869141530
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.099197750975325738   to: 0.098552294515634409
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.099220499645232496   to: 0.098583123209726550
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.099242915446032365   to: 0.098613502494505789
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.099265003896741227   to: 0.098643439775148625
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.099286770414622458   to: 0.098672942321660351
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.099308220317238322   to: 0.098702017271557030
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.099329358824456690   to: 0.098730671632490996
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.099350191060414428   to: 0.098758912284820685
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.099370722055438288   to: 0.098786745984126456
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.099390956747924308   to: 0.098814179363673232
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.099410899986176637   to: 0.098841218936821226
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.099430556530206701   to: 0.098867871099386079
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.099449931053493895   to: 0.098894142131949220
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.099469028144708038   to: 0.098920038202119781
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.099487852309395261   to: 0.098945565366749019
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.099506407971627409   to: 0.098970729574098248
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.099524699475616429   to: 0.098995536665961531
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.099542731087294056   to: 0.099019992379743710
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.099560506995857875   to: 0.099044102350495197
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.099578031315284310   to: 0.099067872112904160
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.099595308085809589   to: 0.099091307103247248
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.099612341275378977   to: 0.099114412661299556
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.099629134781065484   to: 0.099137194032204917
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.099645692430458288   to: 0.099159656368307245
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.099662017983021906   to: 0.099181804730943873
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.099678115131426534   to: 0.099203644092201670
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.099693987502850301   to: 0.099225179336636826
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.099709638660254174   to: 0.099246415262958881
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.099725072103629867   to: 0.099267356585680103
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.099740291271221623   to: 0.099288007936730677
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.099755299540722223   to: 0.099308373867040667
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.099770100230444136   to: 0.099328458848089302
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.099784696600465864   to: 0.099348267273422414
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.099799091853754573   to: 0.099367803460138709
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.099813289137265171   to: 0.099387071650345424
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.099827291543016408   to: 0.099406076012584263
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.099841102109144750   to: 0.099424820643228023
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.099854723820936173   to: 0.099443309567848734
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.099868159611836732   to: 0.099461546742557694
i: 100, name:           module.conv10.weight  changing lr from: 0.099881412364441924   to: 0.099479536055318438
i: 101, name:             module.conv10.bias  changing lr from: 0.099894484911465894   to: 0.099497281327232595



# Switched to train mode...
Epoch: [7][  0/391]	Time  0.220 ( 0.220)	Data  0.175 ( 0.175)	Loss 6.0855e-01 (6.0855e-01)	Acc@1  75.00 ( 75.00)	Acc@5 100.00 (100.00)
Epoch: [7][ 10/391]	Time  0.040 ( 0.057)	Data  0.002 ( 0.017)	Loss 5.9730e-01 (5.6980e-01)	Acc@1  79.69 ( 79.83)	Acc@5  98.44 ( 99.29)
Epoch: [7][ 20/391]	Time  0.039 ( 0.049)	Data  0.001 ( 0.009)	Loss 5.3622e-01 (5.7843e-01)	Acc@1  79.69 ( 79.87)	Acc@5  99.22 ( 99.07)
Epoch: [7][ 30/391]	Time  0.042 ( 0.046)	Data  0.001 ( 0.007)	Loss 4.8143e-01 (5.6808e-01)	Acc@1  85.16 ( 80.24)	Acc@5  99.22 ( 99.14)
Epoch: [7][ 40/391]	Time  0.040 ( 0.045)	Data  0.001 ( 0.005)	Loss 7.8167e-01 (5.7036e-01)	Acc@1  74.22 ( 80.34)	Acc@5  97.66 ( 99.14)
Epoch: [7][ 50/391]	Time  0.041 ( 0.044)	Data  0.001 ( 0.004)	Loss 4.6113e-01 (5.6464e-01)	Acc@1  81.25 ( 80.48)	Acc@5  99.22 ( 99.19)
Epoch: [7][ 60/391]	Time  0.041 ( 0.044)	Data  0.001 ( 0.004)	Loss 6.2063e-01 (5.5865e-01)	Acc@1  79.69 ( 80.57)	Acc@5  99.22 ( 99.15)
Epoch: [7][ 70/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.003)	Loss 7.0963e-01 (5.5730e-01)	Acc@1  73.44 ( 80.67)	Acc@5  98.44 ( 99.11)
Epoch: [7][ 80/391]	Time  0.039 ( 0.043)	Data  0.002 ( 0.003)	Loss 5.3385e-01 (5.5593e-01)	Acc@1  82.81 ( 80.81)	Acc@5 100.00 ( 99.07)
Epoch: [7][ 90/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.003)	Loss 6.0387e-01 (5.5699e-01)	Acc@1  82.03 ( 80.84)	Acc@5 100.00 ( 99.06)
Epoch: [7][100/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.003)	Loss 5.2782e-01 (5.5332e-01)	Acc@1  81.25 ( 80.99)	Acc@5 100.00 ( 99.10)
Epoch: [7][110/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.003)	Loss 6.1196e-01 (5.5295e-01)	Acc@1  79.69 ( 80.97)	Acc@5  98.44 ( 99.04)
Epoch: [7][120/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.0671e-01 (5.5215e-01)	Acc@1  78.91 ( 80.99)	Acc@5 100.00 ( 99.06)
Epoch: [7][130/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 4.8243e-01 (5.5579e-01)	Acc@1  84.38 ( 80.84)	Acc@5  99.22 ( 99.02)
Epoch: [7][140/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 4.7551e-01 (5.5601e-01)	Acc@1  82.81 ( 80.84)	Acc@5 100.00 ( 99.01)
Epoch: [7][150/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.0043e-01 (5.5796e-01)	Acc@1  79.69 ( 80.78)	Acc@5  97.66 ( 98.99)
Epoch: [7][160/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.2069e-01 (5.5897e-01)	Acc@1  84.38 ( 80.84)	Acc@5  99.22 ( 99.00)
Epoch: [7][170/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.1762e-01 (5.5893e-01)	Acc@1  82.81 ( 80.86)	Acc@5  98.44 ( 98.99)
Epoch: [7][180/391]	Time  0.045 ( 0.042)	Data  0.001 ( 0.002)	Loss 4.8296e-01 (5.5944e-01)	Acc@1  83.59 ( 80.81)	Acc@5  98.44 ( 98.99)
Epoch: [7][190/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.3846e-01 (5.6230e-01)	Acc@1  84.38 ( 80.66)	Acc@5  98.44 ( 98.97)
Epoch: [7][200/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.3533e-01 (5.6250e-01)	Acc@1  81.25 ( 80.67)	Acc@5  98.44 ( 98.97)
Epoch: [7][210/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 6.3638e-01 (5.6160e-01)	Acc@1  75.78 ( 80.66)	Acc@5  98.44 ( 98.96)
Epoch: [7][220/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.8566e-01 (5.6097e-01)	Acc@1  78.91 ( 80.63)	Acc@5  98.44 ( 98.97)
Epoch: [7][230/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.7421e-01 (5.6172e-01)	Acc@1  82.03 ( 80.57)	Acc@5  99.22 ( 98.97)
Epoch: [7][240/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.4720e-01 (5.6330e-01)	Acc@1  80.47 ( 80.51)	Acc@5  98.44 ( 98.97)
Epoch: [7][250/391]	Time  0.043 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.7705e-01 (5.6302e-01)	Acc@1  81.25 ( 80.52)	Acc@5 100.00 ( 98.97)
Epoch: [7][260/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 6.3955e-01 (5.6052e-01)	Acc@1  75.78 ( 80.63)	Acc@5  99.22 ( 98.98)
Epoch: [7][270/391]	Time  0.036 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.6875e-01 (5.6098e-01)	Acc@1  80.47 ( 80.64)	Acc@5  98.44 ( 98.97)
Epoch: [7][280/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.2845e-01 (5.6140e-01)	Acc@1  83.59 ( 80.60)	Acc@5  98.44 ( 98.96)
Epoch: [7][290/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.8045e-01 (5.6153e-01)	Acc@1  85.16 ( 80.64)	Acc@5  99.22 ( 98.95)
Epoch: [7][300/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 8.5406e-01 (5.6311e-01)	Acc@1  67.97 ( 80.59)	Acc@5  97.66 ( 98.95)
Epoch: [7][310/391]	Time  0.039 ( 0.041)	Data  0.002 ( 0.002)	Loss 6.4853e-01 (5.6336e-01)	Acc@1  80.47 ( 80.57)	Acc@5  97.66 ( 98.95)
Epoch: [7][320/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.001)	Loss 5.4775e-01 (5.6346e-01)	Acc@1  82.03 ( 80.54)	Acc@5  99.22 ( 98.96)
Epoch: [7][330/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.001)	Loss 6.2376e-01 (5.6281e-01)	Acc@1  75.00 ( 80.55)	Acc@5 100.00 ( 98.96)
Epoch: [7][340/391]	Time  0.044 ( 0.041)	Data  0.001 ( 0.001)	Loss 5.6832e-01 (5.6208e-01)	Acc@1  77.34 ( 80.55)	Acc@5  97.66 ( 98.96)
Epoch: [7][350/391]	Time  0.036 ( 0.041)	Data  0.001 ( 0.001)	Loss 6.0165e-01 (5.6178e-01)	Acc@1  78.12 ( 80.54)	Acc@5  99.22 ( 98.98)
Epoch: [7][360/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.001)	Loss 6.0432e-01 (5.6013e-01)	Acc@1  76.56 ( 80.61)	Acc@5  99.22 ( 98.98)
Epoch: [7][370/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.001)	Loss 6.2816e-01 (5.6037e-01)	Acc@1  76.56 ( 80.58)	Acc@5  99.22 ( 98.98)
Epoch: [7][380/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.001)	Loss 4.4877e-01 (5.6112e-01)	Acc@1  82.81 ( 80.54)	Acc@5  99.22 ( 98.98)
Epoch: [7][390/391]	Time  0.028 ( 0.041)	Data  0.001 ( 0.001)	Loss 6.0341e-01 (5.6075e-01)	Acc@1  76.25 ( 80.53)	Acc@5 100.00 ( 98.98)
## e[7] optimizer.zero_grad (sum) time: 0.2725026607513428
## e[7]       loss.backward (sum) time: 4.023949384689331
## e[7]      optimizer.step (sum) time: 1.8205726146697998
## epoch[7] training(only) time: 16.085246324539185
# Switched to evaluate mode...
Test: [  0/100]	Time  0.169 ( 0.169)	Loss 6.6360e-01 (6.6360e-01)	Acc@1  80.00 ( 80.00)	Acc@5  98.00 ( 98.00)
Test: [ 10/100]	Time  0.025 ( 0.036)	Loss 6.7940e-01 (6.8630e-01)	Acc@1  76.00 ( 76.27)	Acc@5 100.00 ( 99.27)
Test: [ 20/100]	Time  0.021 ( 0.029)	Loss 6.1228e-01 (6.7079e-01)	Acc@1  72.00 ( 76.33)	Acc@5  99.00 ( 98.90)
Test: [ 30/100]	Time  0.017 ( 0.026)	Loss 7.6624e-01 (6.8364e-01)	Acc@1  75.00 ( 76.58)	Acc@5  97.00 ( 98.84)
Test: [ 40/100]	Time  0.018 ( 0.024)	Loss 7.4589e-01 (6.8010e-01)	Acc@1  75.00 ( 76.80)	Acc@5  97.00 ( 98.73)
Test: [ 50/100]	Time  0.021 ( 0.024)	Loss 5.9507e-01 (6.7426e-01)	Acc@1  78.00 ( 77.06)	Acc@5  99.00 ( 98.76)
Test: [ 60/100]	Time  0.021 ( 0.023)	Loss 6.7449e-01 (6.7715e-01)	Acc@1  79.00 ( 76.75)	Acc@5  99.00 ( 98.82)
Test: [ 70/100]	Time  0.022 ( 0.023)	Loss 6.4442e-01 (6.7579e-01)	Acc@1  74.00 ( 76.79)	Acc@5 100.00 ( 98.86)
Test: [ 80/100]	Time  0.024 ( 0.023)	Loss 6.8184e-01 (6.7270e-01)	Acc@1  73.00 ( 76.88)	Acc@5 100.00 ( 98.89)
Test: [ 90/100]	Time  0.021 ( 0.022)	Loss 5.9347e-01 (6.6995e-01)	Acc@1  76.00 ( 77.01)	Acc@5 100.00 ( 98.91)
 * Acc@1 77.030 Acc@5 98.920
### epoch[7] execution time: 18.390195846557617
EPOCH 8
i:   0, name:           module.stem.0.weight  changing lr from: 0.095413337864757808   to: 0.093745593533647337
i:   1, name:             module.stem.0.bias  changing lr from: 0.095493265000109517   to: 0.093848769614600161
i:   2, name:           module.stem.1.weight  changing lr from: 0.095571879612025609   to: 0.093950269050138258
i:   3, name:             module.stem.1.bias  changing lr from: 0.095649205742293145   to: 0.094050121995939637
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.095725266955318633   to: 0.094148358027963938
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.095800086348048916   to: 0.094245006153783450
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.095873686559688531   to: 0.094340094823711307
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.095946089781216840   to: 0.094433651941729368
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.096017317764708440   to: 0.094525704876217642
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.096087391832460720   to: 0.094616280470487577
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.096156332885931714   to: 0.094705405053121750
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.096224161414492068   to: 0.094793104448121973
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.096290897503994138   to: 0.094879403984868563
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.096356560845162254   to: 0.094964328507892992
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.096421170741806853   to: 0.095047902386466585
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.096484746118866538   to: 0.095130149524007890
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.096547305530280625   to: 0.095211093367311053
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.096608867166696200   to: 0.095290756915597880
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.096669448863012417   to: 0.095369162729396398
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.096729068105765356   to: 0.095446332939248341
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.096787742040356742   to: 0.095522289254248091
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.096845487478129447   to: 0.095597052970416083
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.096902320903292941   to: 0.095670644978908981
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.096958258479701673   to: 0.095743085774069384
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.097013316057489377   to: 0.095814395461317717
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.097067509179562333   to: 0.095884593764888948
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.097120853087954109   to: 0.095953700035416534
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.097173362730045176   to: 0.096021733257366737
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.097225052764649711   to: 0.096088712056325104
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.097275937567972481   to: 0.096154654706138445
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.097326031239438712   to: 0.096219579135914335
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.097375347607399215   to: 0.096283502936880955
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.097423900234713728   to: 0.096346443369109677
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.097471702424214754   to: 0.096408417368102864
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.097518767224054670   to: 0.096469441551249355
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.097565107432938336   to: 0.096529532224150116
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.097610735605243790   to: 0.096588705386816465
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.097655664056033292   to: 0.096646976739743054
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.097699904865957199   to: 0.096704361689858326
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.097743469886052703   to: 0.096760875356354359
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.097786370742440065   to: 0.096816532576398689
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.097828618840918105   to: 0.096871347910730266
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.097870225371461450   to: 0.096925335649141686
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.097911201312621432   to: 0.096978509815850031
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.097951557435833003   to: 0.097030884174758414
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.097991304309629157   to: 0.097082472234610334
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.098030452303765531   to: 0.097133287254039039
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.098069011593256719   to: 0.097183342246513815
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.098106992162326059   to: 0.097232649985185327
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.098144403808271385   to: 0.097281223007632159
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.098181256145247836   to: 0.097329073620510048
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.098217558607970171   to: 0.097376213904106432
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.098253320455335802   to: 0.097422655716801532
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.098288550773970765   to: 0.097468410699438401
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.098323258481699857   to: 0.097513490279603376
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.098357452330942910   to: 0.097557905675818901
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.098391140912038794   to: 0.097601667901650660
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.098424332656498442   to: 0.097644787769730429
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.098457035840188875   to: 0.097687275895696521
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.098489258586449371   to: 0.097729142702053629
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.098521008869141530   to: 0.097770398421953592
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.098552294515634409   to: 0.097811053102898532
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.098583123209726550   to: 0.097851116610368410
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.098613502494505789   to: 0.097890598631374059
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.098643439775148625   to: 0.097929508677937552
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.098672942321660351   to: 0.097967856090501293
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.098702017271557030   to: 0.098005650041267323
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.098730671632490996   to: 0.098042899537468239
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.098758912284820685   to: 0.098079613424571249
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.098786745984126456   to: 0.098115800389416641
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.098814179363673232   to: 0.098151468963292077
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.098841218936821226   to: 0.098186627524944073
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.098867871099386079   to: 0.098221284303527862
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.098894142131949220   to: 0.098255447381497149
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.098920038202119781   to: 0.098289124697434727
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.098945565366749019   to: 0.098322324048825460
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.098970729574098248   to: 0.098355053094772549
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.098995536665961531   to: 0.098387319358658618
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.099019992379743710   to: 0.098419130230752411
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.099044102350495197   to: 0.098450492970762568
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.099067872112904160   to: 0.098481414710339263
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.099091307103247248   to: 0.098511902455525158
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.099114412661299556   to: 0.098541963089156359
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.099137194032204917   to: 0.098571603373214758
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.099159656368307245   to: 0.098600829951132576
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.099181804730943873   to: 0.098629649350050114
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.099203644092201670   to: 0.098658067983027842
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.099225179336636826   to: 0.098686092151213586
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.099246415262958881   to: 0.098713728045966009
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.099267356585680103   to: 0.098740981750935042
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.099288007936730677   to: 0.098767859244100212
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.099308373867040667   to: 0.098794366399768088
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.099328458848089302   to: 0.098820508990529091
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.099348267273422414   to: 0.098846292689175219
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.099367803460138709   to: 0.098871723070578857
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.099387071650345424   to: 0.098896805613534020
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.099406076012584263   to: 0.098921545702560398
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.099424820643228023   to: 0.098945948629671390
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.099443309567848734   to: 0.098970019596106434
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.099461546742557694   to: 0.098993763714028821
i: 100, name:           module.conv10.weight  changing lr from: 0.099479536055318438   to: 0.099017186008189345
i: 101, name:             module.conv10.bias  changing lr from: 0.099497281327232595   to: 0.099040291417556825



# Switched to train mode...
Epoch: [8][  0/391]	Time  0.204 ( 0.204)	Data  0.163 ( 0.163)	Loss 5.6764e-01 (5.6764e-01)	Acc@1  80.47 ( 80.47)	Acc@5 100.00 (100.00)
Epoch: [8][ 10/391]	Time  0.039 ( 0.056)	Data  0.001 ( 0.016)	Loss 4.7148e-01 (5.4483e-01)	Acc@1  85.16 ( 81.82)	Acc@5  98.44 ( 99.22)
Epoch: [8][ 20/391]	Time  0.043 ( 0.049)	Data  0.001 ( 0.009)	Loss 3.5552e-01 (5.4054e-01)	Acc@1  89.06 ( 81.77)	Acc@5 100.00 ( 99.22)
Epoch: [8][ 30/391]	Time  0.041 ( 0.046)	Data  0.001 ( 0.006)	Loss 5.6335e-01 (5.2533e-01)	Acc@1  79.69 ( 81.91)	Acc@5 100.00 ( 99.27)
Epoch: [8][ 40/391]	Time  0.039 ( 0.044)	Data  0.001 ( 0.005)	Loss 5.5371e-01 (5.4090e-01)	Acc@1  79.69 ( 81.38)	Acc@5  98.44 ( 99.07)
Epoch: [8][ 50/391]	Time  0.041 ( 0.044)	Data  0.001 ( 0.004)	Loss 3.9254e-01 (5.3900e-01)	Acc@1  87.50 ( 81.46)	Acc@5 100.00 ( 99.08)
Epoch: [8][ 60/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.004)	Loss 5.8468e-01 (5.2888e-01)	Acc@1  79.69 ( 81.80)	Acc@5  97.66 ( 99.07)
Epoch: [8][ 70/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.003)	Loss 4.8752e-01 (5.3022e-01)	Acc@1  82.81 ( 81.78)	Acc@5  99.22 ( 99.10)
Epoch: [8][ 80/391]	Time  0.038 ( 0.043)	Data  0.001 ( 0.003)	Loss 7.1122e-01 (5.3436e-01)	Acc@1  75.78 ( 81.66)	Acc@5  98.44 ( 99.08)
Epoch: [8][ 90/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.003)	Loss 7.2511e-01 (5.3674e-01)	Acc@1  77.34 ( 81.49)	Acc@5  99.22 ( 99.06)
Epoch: [8][100/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.003)	Loss 5.4961e-01 (5.3445e-01)	Acc@1  81.25 ( 81.54)	Acc@5  97.66 ( 99.05)
Epoch: [8][110/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 4.9025e-01 (5.3498e-01)	Acc@1  83.59 ( 81.52)	Acc@5  98.44 ( 99.07)
Epoch: [8][120/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.5209e-01 (5.3576e-01)	Acc@1  78.91 ( 81.49)	Acc@5  99.22 ( 99.06)
Epoch: [8][130/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.9808e-01 (5.3998e-01)	Acc@1  74.22 ( 81.38)	Acc@5  98.44 ( 99.00)
Epoch: [8][140/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 3.5278e-01 (5.3740e-01)	Acc@1  87.50 ( 81.50)	Acc@5 100.00 ( 99.00)
Epoch: [8][150/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.2150e-01 (5.3679e-01)	Acc@1  84.38 ( 81.55)	Acc@5  99.22 ( 99.01)
Epoch: [8][160/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.6240e-01 (5.3704e-01)	Acc@1  79.69 ( 81.54)	Acc@5  99.22 ( 99.01)
Epoch: [8][170/391]	Time  0.048 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.1487e-01 (5.3874e-01)	Acc@1  82.03 ( 81.46)	Acc@5  99.22 ( 98.99)
Epoch: [8][180/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.0110e-01 (5.3824e-01)	Acc@1  84.38 ( 81.46)	Acc@5  98.44 ( 99.00)
Epoch: [8][190/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.2235e-01 (5.3910e-01)	Acc@1  82.03 ( 81.47)	Acc@5  99.22 ( 99.00)
Epoch: [8][200/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.6841e-01 (5.3767e-01)	Acc@1  85.94 ( 81.54)	Acc@5 100.00 ( 98.99)
Epoch: [8][210/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.3100e-01 (5.3741e-01)	Acc@1  83.59 ( 81.53)	Acc@5 100.00 ( 99.00)
Epoch: [8][220/391]	Time  0.047 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.8877e-01 (5.3572e-01)	Acc@1  84.38 ( 81.57)	Acc@5  99.22 ( 99.00)
Epoch: [8][230/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.1491e-01 (5.3423e-01)	Acc@1  81.25 ( 81.58)	Acc@5  99.22 ( 99.02)
Epoch: [8][240/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.7124e-01 (5.3502e-01)	Acc@1  79.69 ( 81.56)	Acc@5  99.22 ( 99.02)
Epoch: [8][250/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.1656e-01 (5.3274e-01)	Acc@1  82.03 ( 81.67)	Acc@5  97.66 ( 99.02)
Epoch: [8][260/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.4266e-01 (5.3225e-01)	Acc@1  82.81 ( 81.70)	Acc@5  96.88 ( 99.03)
Epoch: [8][270/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 6.4690e-01 (5.3358e-01)	Acc@1  75.00 ( 81.64)	Acc@5  99.22 ( 99.03)
Epoch: [8][280/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 6.1117e-01 (5.3219e-01)	Acc@1  81.25 ( 81.69)	Acc@5  99.22 ( 99.05)
Epoch: [8][290/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 6.6297e-01 (5.3083e-01)	Acc@1  72.66 ( 81.73)	Acc@5 100.00 ( 99.06)
Epoch: [8][300/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 6.1196e-01 (5.3111e-01)	Acc@1  78.91 ( 81.71)	Acc@5 100.00 ( 99.06)
Epoch: [8][310/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.001)	Loss 5.6778e-01 (5.3265e-01)	Acc@1  78.12 ( 81.64)	Acc@5 100.00 ( 99.06)
Epoch: [8][320/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.001)	Loss 5.3153e-01 (5.3457e-01)	Acc@1  82.03 ( 81.57)	Acc@5  98.44 ( 99.05)
Epoch: [8][330/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.001)	Loss 4.9077e-01 (5.3421e-01)	Acc@1  82.03 ( 81.59)	Acc@5 100.00 ( 99.05)
Epoch: [8][340/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.001)	Loss 4.7732e-01 (5.3370e-01)	Acc@1  82.03 ( 81.60)	Acc@5  98.44 ( 99.04)
Epoch: [8][350/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.001)	Loss 6.2381e-01 (5.3346e-01)	Acc@1  78.91 ( 81.60)	Acc@5  99.22 ( 99.05)
Epoch: [8][360/391]	Time  0.043 ( 0.041)	Data  0.001 ( 0.001)	Loss 5.2050e-01 (5.3412e-01)	Acc@1  81.25 ( 81.60)	Acc@5  98.44 ( 99.03)
Epoch: [8][370/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.001)	Loss 4.8954e-01 (5.3320e-01)	Acc@1  83.59 ( 81.62)	Acc@5 100.00 ( 99.03)
Epoch: [8][380/391]	Time  0.043 ( 0.041)	Data  0.001 ( 0.001)	Loss 4.2741e-01 (5.3200e-01)	Acc@1  86.72 ( 81.68)	Acc@5  99.22 ( 99.04)
Epoch: [8][390/391]	Time  0.030 ( 0.041)	Data  0.001 ( 0.001)	Loss 7.0028e-01 (5.3179e-01)	Acc@1  75.00 ( 81.68)	Acc@5 100.00 ( 99.05)
## e[8] optimizer.zero_grad (sum) time: 0.27069783210754395
## e[8]       loss.backward (sum) time: 4.099099397659302
## e[8]      optimizer.step (sum) time: 1.8308894634246826
## epoch[8] training(only) time: 16.159261465072632
# Switched to evaluate mode...
Test: [  0/100]	Time  0.162 ( 0.162)	Loss 5.0256e-01 (5.0256e-01)	Acc@1  81.00 ( 81.00)	Acc@5  98.00 ( 98.00)
Test: [ 10/100]	Time  0.021 ( 0.035)	Loss 6.2542e-01 (6.0684e-01)	Acc@1  78.00 ( 79.45)	Acc@5  97.00 ( 98.73)
Test: [ 20/100]	Time  0.019 ( 0.028)	Loss 4.9772e-01 (5.8422e-01)	Acc@1  82.00 ( 79.81)	Acc@5 100.00 ( 98.71)
Test: [ 30/100]	Time  0.021 ( 0.026)	Loss 6.5291e-01 (5.9255e-01)	Acc@1  80.00 ( 79.58)	Acc@5  97.00 ( 98.71)
Test: [ 40/100]	Time  0.022 ( 0.025)	Loss 5.5570e-01 (5.8993e-01)	Acc@1  81.00 ( 79.63)	Acc@5 100.00 ( 98.63)
Test: [ 50/100]	Time  0.024 ( 0.024)	Loss 5.8187e-01 (5.8408e-01)	Acc@1  78.00 ( 79.98)	Acc@5  99.00 ( 98.73)
Test: [ 60/100]	Time  0.018 ( 0.023)	Loss 5.0425e-01 (5.8395e-01)	Acc@1  76.00 ( 79.66)	Acc@5  99.00 ( 98.85)
Test: [ 70/100]	Time  0.018 ( 0.022)	Loss 5.6194e-01 (5.8303e-01)	Acc@1  78.00 ( 79.62)	Acc@5 100.00 ( 98.90)
Test: [ 80/100]	Time  0.024 ( 0.022)	Loss 5.3704e-01 (5.7824e-01)	Acc@1  82.00 ( 79.63)	Acc@5  98.00 ( 98.96)
Test: [ 90/100]	Time  0.020 ( 0.022)	Loss 4.4713e-01 (5.7754e-01)	Acc@1  84.00 ( 79.66)	Acc@5  98.00 ( 98.95)
 * Acc@1 79.750 Acc@5 99.010
### epoch[8] execution time: 18.478673458099365
EPOCH 9
i:   0, name:           module.stem.0.weight  changing lr from: 0.093745593533647337   to: 0.091879240657579200
i:   1, name:             module.stem.0.bias  changing lr from: 0.093848769614600161   to: 0.092008088001103452
i:   2, name:           module.stem.1.weight  changing lr from: 0.093950269050138258   to: 0.092134866789770550
i:   3, name:             module.stem.1.bias  changing lr from: 0.094050121995939637   to: 0.092259613430003634
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.094148358027963938   to: 0.092382363655977906
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.094245006153783450   to: 0.092503152541697720
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.094340094823711307   to: 0.092622014512904804
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.094433651941729368   to: 0.092738983358816196
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.094525704876217642   to: 0.092854092243691844
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.094616280470487577   to: 0.092967373718231272
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.094705405053121750   to: 0.093078859730798949
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.094793104448121973   to: 0.093188581638478832
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.094879403984868563   to: 0.093296570217957939
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.094964328507892992   to: 0.093402855676239530
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.095047902386466585   to: 0.093507467661186561
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.095130149524007890   to: 0.093610435271895887
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.095211093367311053   to: 0.093711787068904318
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.095290756915597880   to: 0.093811551084227340
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.095369162729396398   to: 0.093909754831231707
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.095446332939248341   to: 0.094006425314343112
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.095522289254248091   to: 0.094101589038590130
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.095597052970416083   to: 0.094195272018985976
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.095670644978908981   to: 0.094287499789749443
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.095743085774069384   to: 0.094378297413366702
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.095814395461317717   to: 0.094467689489495410
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.095884593764888948   to: 0.094555700163712911
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.095953700035416534   to: 0.094642353136110191
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.096021733257366737   to: 0.094727671669733601
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.096088712056325104   to: 0.094811678598875682
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.096154654706138445   to: 0.094894396337217482
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.096219579135914335   to: 0.094975846885823903
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.096283502936880955   to: 0.095056051840994138
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.096346443369109677   to: 0.095135032401969022
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.096408417368102864   to: 0.095212809378497520
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.096469441551249355   to: 0.095289403198263942
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.096529532224150116   to: 0.095364833914178104
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.096588705386816465   to: 0.095439121211530573
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.096646976739743054   to: 0.095512284415014637
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.096704361689858326   to: 0.095584342495617203
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.096760875356354359   to: 0.095655314077380815
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.096816532576398689   to: 0.095725217444038280
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.096871347910730266   to: 0.095794070545522580
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.096925335649141686   to: 0.095861891004353411
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.096978509815850031   to: 0.095928696121902857
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.097030884174758414   to: 0.095994502884541810
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.097082472234610334   to: 0.096059327969669484
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.097133287254039039   to: 0.096123187751627370
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.097183342246513815   to: 0.096186098307500412
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.097232649985185327   to: 0.096248075422806501
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.097281223007632159   to: 0.096309134597076851
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.097329073620510048   to: 0.096369291049328773
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.097376213904106432   to: 0.096428559723432741
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.097422655716801532   to: 0.096486955293375976
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.097468410699438401   to: 0.096544492168423729
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.097513490279603376   to: 0.096601184498180892
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.097557905675818901   to: 0.096657046177555023
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.097601667901650660   to: 0.096712090851622870
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.097644787769730429   to: 0.096766331920402390
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.097687275895696521   to: 0.096819782543531380
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.097729142702053629   to: 0.096872455644855096
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.097770398421953592   to: 0.096924363916924078
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.097811053102898532   to: 0.096975519825404088
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.097851116610368410   to: 0.097025935613399686
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.097890598631374059   to: 0.097075623305693193
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.097929508677937552   to: 0.097124594712900386
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.097967856090501293   to: 0.097172861435544891
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.098005650041267323   to: 0.097220434868052374
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.098042899537468239   to: 0.097267326202666454
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.098079613424571249   to: 0.097313546433287476
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.098115800389416641   to: 0.097359106359236003
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.098151468963292077   to: 0.097404016588942099
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.098186627524944073   to: 0.097448287543562162
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.098221284303527862   to: 0.097491929460524429
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.098255447381497149   to: 0.097534952397004743
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.098289124697434727   to: 0.097577366233333893
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.098322324048825460   to: 0.097619180676337736
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.098355053094772549   to: 0.097660405262611688
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.098387319358658618   to: 0.097701049361730435
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.098419130230752411   to: 0.097741122179394735
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.098450492970762568   to: 0.097780632760515823
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.098481414710339263   to: 0.097819589992239483
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.098511902455525158   to: 0.097858002606910133
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.098541963089156359   to: 0.097895879184976761
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.098571603373214758   to: 0.097933228157841556
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.098600829951132576   to: 0.097970057810652433
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.098629649350050114   to: 0.098006376285040497
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.098658067983027842   to: 0.098042191581803759
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.098686092151213586   to: 0.098077511563537945
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.098713728045966009   to: 0.098112343957215534
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.098740981750935042   to: 0.098146696356714094
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.098767859244100212   to: 0.098180576225294913
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.098794366399768088   to: 0.098213990898032830
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.098820508990529091   to: 0.098246947584198538
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.098846292689175219   to: 0.098279453369593803
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.098871723070578857   to: 0.098311515218841072
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.098896805613534020   to: 0.098343139977628100
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.098921545702560398   to: 0.098374334374908445
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.098945948629671390   to: 0.098405105025059086
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.098970019596106434   to: 0.098435458429995445
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.098993763714028821   to: 0.098465400981245288
i: 100, name:           module.conv10.weight  changing lr from: 0.099017186008189345   to: 0.098494938961981873
i: 101, name:             module.conv10.bias  changing lr from: 0.099040291417556825   to: 0.098524078549017458



# Switched to train mode...
Epoch: [9][  0/391]	Time  0.214 ( 0.214)	Data  0.173 ( 0.173)	Loss 7.0143e-01 (7.0143e-01)	Acc@1  78.12 ( 78.12)	Acc@5  96.88 ( 96.88)
Epoch: [9][ 10/391]	Time  0.039 ( 0.057)	Data  0.001 ( 0.017)	Loss 4.7272e-01 (4.7740e-01)	Acc@1  83.59 ( 83.74)	Acc@5 100.00 ( 99.08)
Epoch: [9][ 20/391]	Time  0.041 ( 0.050)	Data  0.001 ( 0.009)	Loss 3.9145e-01 (4.5858e-01)	Acc@1  84.38 ( 83.41)	Acc@5  99.22 ( 99.26)
Epoch: [9][ 30/391]	Time  0.041 ( 0.047)	Data  0.001 ( 0.007)	Loss 6.4594e-01 (4.7645e-01)	Acc@1  76.56 ( 82.99)	Acc@5  98.44 ( 99.19)
Epoch: [9][ 40/391]	Time  0.040 ( 0.045)	Data  0.001 ( 0.005)	Loss 4.2911e-01 (4.8171e-01)	Acc@1  84.38 ( 82.89)	Acc@5  99.22 ( 99.18)
Epoch: [9][ 50/391]	Time  0.039 ( 0.044)	Data  0.001 ( 0.004)	Loss 5.8989e-01 (4.7944e-01)	Acc@1  78.12 ( 83.03)	Acc@5  97.66 ( 99.16)
Epoch: [9][ 60/391]	Time  0.043 ( 0.044)	Data  0.001 ( 0.004)	Loss 4.1573e-01 (4.7610e-01)	Acc@1  85.16 ( 83.04)	Acc@5 100.00 ( 99.22)
Epoch: [9][ 70/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.003)	Loss 6.0006e-01 (4.7486e-01)	Acc@1  75.78 ( 83.11)	Acc@5  98.44 ( 99.26)
Epoch: [9][ 80/391]	Time  0.047 ( 0.043)	Data  0.001 ( 0.003)	Loss 7.3942e-01 (4.8037e-01)	Acc@1  71.88 ( 82.99)	Acc@5  98.44 ( 99.26)
Epoch: [9][ 90/391]	Time  0.038 ( 0.043)	Data  0.001 ( 0.003)	Loss 5.8469e-01 (4.8486e-01)	Acc@1  82.03 ( 82.86)	Acc@5  98.44 ( 99.22)
Epoch: [9][100/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.003)	Loss 5.2159e-01 (4.9150e-01)	Acc@1  81.25 ( 82.70)	Acc@5  99.22 ( 99.23)
Epoch: [9][110/391]	Time  0.048 ( 0.042)	Data  0.001 ( 0.003)	Loss 6.6073e-01 (4.9415e-01)	Acc@1  77.34 ( 82.71)	Acc@5  99.22 ( 99.21)
Epoch: [9][120/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 4.7568e-01 (4.9298e-01)	Acc@1  84.38 ( 82.74)	Acc@5 100.00 ( 99.23)
Epoch: [9][130/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 4.7408e-01 (4.9834e-01)	Acc@1  82.03 ( 82.63)	Acc@5  99.22 ( 99.18)
Epoch: [9][140/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 4.2068e-01 (4.9543e-01)	Acc@1  85.16 ( 82.73)	Acc@5  99.22 ( 99.17)
Epoch: [9][150/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.0083e-01 (4.9633e-01)	Acc@1  80.47 ( 82.79)	Acc@5  99.22 ( 99.17)
Epoch: [9][160/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.1806e-01 (4.9656e-01)	Acc@1  77.34 ( 82.80)	Acc@5  99.22 ( 99.16)
Epoch: [9][170/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.8401e-01 (4.9747e-01)	Acc@1  78.12 ( 82.87)	Acc@5  97.66 ( 99.15)
Epoch: [9][180/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 4.6171e-01 (4.9660e-01)	Acc@1  84.38 ( 82.86)	Acc@5  99.22 ( 99.16)
Epoch: [9][190/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.0763e-01 (4.9875e-01)	Acc@1  83.59 ( 82.80)	Acc@5 100.00 ( 99.17)
Epoch: [9][200/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.8564e-01 (4.9974e-01)	Acc@1  82.03 ( 82.78)	Acc@5  99.22 ( 99.18)
Epoch: [9][210/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.6726e-01 (5.0021e-01)	Acc@1  80.47 ( 82.78)	Acc@5  98.44 ( 99.18)
Epoch: [9][220/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.6599e-01 (4.9982e-01)	Acc@1  79.69 ( 82.76)	Acc@5 100.00 ( 99.20)
Epoch: [9][230/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.9424e-01 (4.9975e-01)	Acc@1  78.91 ( 82.79)	Acc@5 100.00 ( 99.21)
Epoch: [9][240/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 6.7747e-01 (5.0010e-01)	Acc@1  78.91 ( 82.76)	Acc@5  96.88 ( 99.20)
Epoch: [9][250/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.1792e-01 (4.9832e-01)	Acc@1  80.47 ( 82.85)	Acc@5  99.22 ( 99.19)
Epoch: [9][260/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 6.4404e-01 (4.9878e-01)	Acc@1  77.34 ( 82.82)	Acc@5  99.22 ( 99.19)
Epoch: [9][270/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 6.2868e-01 (5.0219e-01)	Acc@1  77.34 ( 82.70)	Acc@5  99.22 ( 99.17)
Epoch: [9][280/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.8528e-01 (5.0267e-01)	Acc@1  77.34 ( 82.66)	Acc@5  99.22 ( 99.18)
Epoch: [9][290/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.6522e-01 (5.0337e-01)	Acc@1  81.25 ( 82.62)	Acc@5  97.66 ( 99.18)
Epoch: [9][300/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.1943e-01 (5.0314e-01)	Acc@1  81.25 ( 82.67)	Acc@5  99.22 ( 99.19)
Epoch: [9][310/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.1350e-01 (5.0490e-01)	Acc@1  82.81 ( 82.60)	Acc@5  99.22 ( 99.19)
Epoch: [9][320/391]	Time  0.050 ( 0.041)	Data  0.002 ( 0.002)	Loss 6.9812e-01 (5.0672e-01)	Acc@1  74.22 ( 82.52)	Acc@5  97.66 ( 99.19)
Epoch: [9][330/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.5502e-01 (5.0660e-01)	Acc@1  80.47 ( 82.52)	Acc@5  99.22 ( 99.19)
Epoch: [9][340/391]	Time  0.053 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.7393e-01 (5.0611e-01)	Acc@1  82.03 ( 82.55)	Acc@5  99.22 ( 99.19)
Epoch: [9][350/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.9434e-01 (5.0647e-01)	Acc@1  85.16 ( 82.54)	Acc@5  97.66 ( 99.18)
Epoch: [9][360/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.001)	Loss 5.2091e-01 (5.0623e-01)	Acc@1  79.69 ( 82.52)	Acc@5  99.22 ( 99.19)
Epoch: [9][370/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.001)	Loss 4.5437e-01 (5.0677e-01)	Acc@1  82.81 ( 82.50)	Acc@5  98.44 ( 99.18)
Epoch: [9][380/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.001)	Loss 4.1331e-01 (5.0682e-01)	Acc@1  86.72 ( 82.48)	Acc@5 100.00 ( 99.19)
Epoch: [9][390/391]	Time  0.030 ( 0.041)	Data  0.001 ( 0.001)	Loss 3.2298e-01 (5.0563e-01)	Acc@1  87.50 ( 82.52)	Acc@5 100.00 ( 99.19)
## e[9] optimizer.zero_grad (sum) time: 0.2704753875732422
## e[9]       loss.backward (sum) time: 4.013481616973877
## e[9]      optimizer.step (sum) time: 1.7616996765136719
## epoch[9] training(only) time: 16.15529155731201
# Switched to evaluate mode...
Test: [  0/100]	Time  0.177 ( 0.177)	Loss 5.7696e-01 (5.7696e-01)	Acc@1  78.00 ( 78.00)	Acc@5  99.00 ( 99.00)
Test: [ 10/100]	Time  0.024 ( 0.035)	Loss 7.1449e-01 (5.5925e-01)	Acc@1  76.00 ( 80.64)	Acc@5  98.00 ( 99.18)
Test: [ 20/100]	Time  0.018 ( 0.027)	Loss 6.8410e-01 (5.6845e-01)	Acc@1  77.00 ( 81.14)	Acc@5  99.00 ( 98.86)
Test: [ 30/100]	Time  0.021 ( 0.025)	Loss 6.1962e-01 (5.7975e-01)	Acc@1  82.00 ( 80.87)	Acc@5  96.00 ( 98.74)
Test: [ 40/100]	Time  0.018 ( 0.024)	Loss 5.8643e-01 (5.8195e-01)	Acc@1  83.00 ( 80.54)	Acc@5  98.00 ( 98.80)
Test: [ 50/100]	Time  0.024 ( 0.023)	Loss 4.4254e-01 (5.7663e-01)	Acc@1  85.00 ( 80.88)	Acc@5  99.00 ( 98.78)
Test: [ 60/100]	Time  0.021 ( 0.022)	Loss 6.1903e-01 (5.8129e-01)	Acc@1  83.00 ( 80.56)	Acc@5 100.00 ( 98.85)
Test: [ 70/100]	Time  0.024 ( 0.022)	Loss 5.2112e-01 (5.8024e-01)	Acc@1  81.00 ( 80.62)	Acc@5  99.00 ( 98.89)
Test: [ 80/100]	Time  0.022 ( 0.022)	Loss 4.0323e-01 (5.7882e-01)	Acc@1  86.00 ( 80.65)	Acc@5 100.00 ( 98.95)
Test: [ 90/100]	Time  0.026 ( 0.022)	Loss 4.4863e-01 (5.7689e-01)	Acc@1  80.00 ( 80.62)	Acc@5 100.00 ( 98.92)
 * Acc@1 80.650 Acc@5 98.910
### epoch[9] execution time: 18.45727038383484
EPOCH 10
i:   0, name:           module.stem.0.weight  changing lr from: 0.091879240657579200   to: 0.089822950858548800
i:   1, name:             module.stem.0.bias  changing lr from: 0.092008088001103452   to: 0.089979647855115114
i:   2, name:           module.stem.1.weight  changing lr from: 0.092134866789770550   to: 0.090133863929493949
i:   3, name:             module.stem.1.bias  changing lr from: 0.092259613430003634   to: 0.090285641642810638
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.092382363655977906   to: 0.090435022808959903
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.092503152541697720   to: 0.090582048506500451
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.092622014512904804   to: 0.090726759090455314
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.092738983358816196   to: 0.090869194204012904
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.092854092243691844   to: 0.091009392790123031
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.092967373718231272   to: 0.091147393102983795
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.093078859730798949   to: 0.091283232719414964
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.093188581638478832   to: 0.091416948550114022
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.093296570217957939   to: 0.091548576850791513
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.093402855676239530   to: 0.091678153233182832
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.093507467661186561   to: 0.091805712675933501
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.093610435271895887   to: 0.091931289535355870
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.093711787068904318   to: 0.092054917556054869
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.093811551084227340   to: 0.092176629881421376
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.093909754831231707   to: 0.092296459063991365
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.094006425314343112   to: 0.092414437075669750
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.094101589038590130   to: 0.092530595317817932
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.094195272018985976   to: 0.092644964631204044
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.094287499789749443   to: 0.092757575305815396
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.094378297413366702   to: 0.092868457090532680
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.094467689489495410   to: 0.092977639202665760
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.094555700163712911   to: 0.093085150337350653
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.094642353136110191   to: 0.093191018676808152
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.094727671669733601   to: 0.093295271899464072
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.094811678598875682   to: 0.093397937188931399
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.094894396337217482   to: 0.093499041242855033
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.094975846885823903   to: 0.093598610281619365
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.095056051840994138   to: 0.093696670056919673
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.095135032401969022   to: 0.093793245860197924
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.095212809378497520   to: 0.093888362530943834
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.095289403198263942   to: 0.093982044464862219
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.095364833914178104   to: 0.094074315621907545
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.095439121211530573   to: 0.094165199534186825
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.095512284415014637   to: 0.094254719313731986
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.095584342495617203   to: 0.094342897660142908
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.095655314077380815   to: 0.094429756868102246
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.095725217444038280   to: 0.094515318834763745
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.095794070545522580   to: 0.094599605067014703
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.095861891004353411   to: 0.094682636688614763
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.095928696121902857   to: 0.094764434447211721
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.095994502884541810   to: 0.094845018721236185
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.096059327969669484   to: 0.094924409526676606
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.096123187751627370   to: 0.095002626523735811
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.096186098307500412   to: 0.095079689023370925
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.096248075422806501   to: 0.095155615993717871
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.096309134597076851   to: 0.095230426066402404
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.096369291049328773   to: 0.095304137542738657
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.096428559723432741   to: 0.095376768399817347
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.096486955293375976   to: 0.095448336296484748
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.096544492168423729   to: 0.095518858579214327
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.096601184498180892   to: 0.095588352287872269
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.096657046177555023   to: 0.095656834161378823
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.096712090851622870   to: 0.095724320643266927
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.096766331920402390   to: 0.095790827887139288
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.096819782543531380   to: 0.095856371762026202
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.096872455644855096   to: 0.095920967857645020
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.096924363916924078   to: 0.095984631489563224
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.096975519825404088   to: 0.096047377704266398
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.097025935613399686   to: 0.096109221284132684
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.097075623305693193   to: 0.096170176752315498
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.097124594712900386   to: 0.096230258377535516
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.097172861435544891   to: 0.096289480178783970
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.097220434868052374   to: 0.096347855929938331
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.097267326202666454   to: 0.096405399164292055
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.097313546433287476   to: 0.096462123178999812
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.097359106359236003   to: 0.096518041039439673
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.097404016588942099   to: 0.096573165583493450
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.097448287543562162   to: 0.096627509425747188
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.097491929460524429   to: 0.096681084961612318
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.097534952397004743   to: 0.096733904371369819
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.097577366233333893   to: 0.096785979624137930
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.097619180676337736   to: 0.096837322481765339
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.097660405262611688   to: 0.096887944502650897
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.097701049361730435   to: 0.096937857045491155
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.097741122179394735   to: 0.096987071272957234
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.097780632760515823   to: 0.097035598155302050
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.097819589992239483   to: 0.097083448473899325
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.097858002606910133   to: 0.097130632824715624
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.097895879184976761   to: 0.097177161621716482
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.097933228157841556   to: 0.097223045100208086
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.097970057810652433   to: 0.097268293320115426
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.098006376285040497   to: 0.097312916169198238
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.098042191581803759   to: 0.097356923366206050
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.098077511563537945   to: 0.097400324463973009
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.098112343957215534   to: 0.097443128852454083
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.098146696356714094   to: 0.097485345761703451
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.098180576225294913   to: 0.097526984264796363
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.098213990898032830   to: 0.097568053280695274
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.098246947584198538   to: 0.097608561577061548
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.098279453369593803   to: 0.097648517773013713
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.098311515218841072   to: 0.097687930341832985
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.098343139977628100   to: 0.097726807613617683
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.098374334374908445   to: 0.097765157777886774
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.098405105025059086   to: 0.097802988886134132
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.098435458429995445   to: 0.097840308854333979
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.098465400981245288   to: 0.097877125465398798
i: 100, name:           module.conv10.weight  changing lr from: 0.098494938961981873   to: 0.097913446371590537
i: 101, name:             module.conv10.bias  changing lr from: 0.098524078549017458   to: 0.097949279096885625



# Switched to train mode...
Epoch: [10][  0/391]	Time  0.218 ( 0.218)	Data  0.174 ( 0.174)	Loss 5.4797e-01 (5.4797e-01)	Acc@1  78.12 ( 78.12)	Acc@5  99.22 ( 99.22)
Epoch: [10][ 10/391]	Time  0.041 ( 0.057)	Data  0.001 ( 0.017)	Loss 5.3787e-01 (4.9503e-01)	Acc@1  79.69 ( 82.24)	Acc@5 100.00 ( 99.15)
Epoch: [10][ 20/391]	Time  0.039 ( 0.048)	Data  0.001 ( 0.009)	Loss 3.7038e-01 (4.9055e-01)	Acc@1  89.84 ( 82.63)	Acc@5  99.22 ( 99.07)
Epoch: [10][ 30/391]	Time  0.038 ( 0.045)	Data  0.001 ( 0.007)	Loss 5.0847e-01 (4.9396e-01)	Acc@1  81.25 ( 82.61)	Acc@5  98.44 ( 99.04)
Epoch: [10][ 40/391]	Time  0.039 ( 0.044)	Data  0.001 ( 0.005)	Loss 4.4339e-01 (4.8950e-01)	Acc@1  87.50 ( 83.00)	Acc@5 100.00 ( 99.01)
Epoch: [10][ 50/391]	Time  0.040 ( 0.044)	Data  0.001 ( 0.004)	Loss 5.1060e-01 (4.8937e-01)	Acc@1  82.81 ( 82.97)	Acc@5 100.00 ( 99.05)
Epoch: [10][ 60/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.004)	Loss 5.8373e-01 (4.9182e-01)	Acc@1  79.69 ( 82.83)	Acc@5  99.22 ( 99.04)
Epoch: [10][ 70/391]	Time  0.039 ( 0.043)	Data  0.001 ( 0.003)	Loss 5.1347e-01 (4.9101e-01)	Acc@1  80.47 ( 82.80)	Acc@5  99.22 ( 99.10)
Epoch: [10][ 80/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.003)	Loss 7.6394e-01 (4.9236e-01)	Acc@1  78.91 ( 82.81)	Acc@5  98.44 ( 99.14)
Epoch: [10][ 90/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.003)	Loss 4.6706e-01 (4.8779e-01)	Acc@1  88.28 ( 83.14)	Acc@5  98.44 ( 99.14)
Epoch: [10][100/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.003)	Loss 5.3582e-01 (4.8893e-01)	Acc@1  82.03 ( 83.05)	Acc@5 100.00 ( 99.13)
Epoch: [10][110/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.003)	Loss 4.5389e-01 (4.8739e-01)	Acc@1  85.16 ( 82.99)	Acc@5 100.00 ( 99.18)
Epoch: [10][120/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.002)	Loss 4.3260e-01 (4.8923e-01)	Acc@1  84.38 ( 82.88)	Acc@5 100.00 ( 99.19)
Epoch: [10][130/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.3655e-01 (4.8788e-01)	Acc@1  81.25 ( 82.92)	Acc@5 100.00 ( 99.19)
Epoch: [10][140/391]	Time  0.044 ( 0.042)	Data  0.002 ( 0.002)	Loss 6.1091e-01 (4.8563e-01)	Acc@1  84.38 ( 83.08)	Acc@5  99.22 ( 99.20)
Epoch: [10][150/391]	Time  0.037 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.6894e-01 (4.8373e-01)	Acc@1  88.28 ( 83.16)	Acc@5 100.00 ( 99.19)
Epoch: [10][160/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.0888e-01 (4.8100e-01)	Acc@1  86.72 ( 83.23)	Acc@5 100.00 ( 99.21)
Epoch: [10][170/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.2862e-01 (4.8100e-01)	Acc@1  82.81 ( 83.23)	Acc@5 100.00 ( 99.22)
Epoch: [10][180/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.3640e-01 (4.7920e-01)	Acc@1  82.81 ( 83.27)	Acc@5 100.00 ( 99.24)
Epoch: [10][190/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.6132e-01 (4.7852e-01)	Acc@1  79.69 ( 83.32)	Acc@5  99.22 ( 99.23)
Epoch: [10][200/391]	Time  0.035 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.9502e-01 (4.7830e-01)	Acc@1  85.94 ( 83.33)	Acc@5  99.22 ( 99.24)
Epoch: [10][210/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.8698e-01 (4.7903e-01)	Acc@1  86.72 ( 83.32)	Acc@5  99.22 ( 99.22)
Epoch: [10][220/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 6.2539e-01 (4.7943e-01)	Acc@1  75.00 ( 83.28)	Acc@5  98.44 ( 99.22)
Epoch: [10][230/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.1706e-01 (4.7901e-01)	Acc@1  87.50 ( 83.31)	Acc@5 100.00 ( 99.22)
Epoch: [10][240/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.9277e-01 (4.8010e-01)	Acc@1  82.81 ( 83.27)	Acc@5 100.00 ( 99.22)
Epoch: [10][250/391]	Time  0.037 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.9734e-01 (4.8039e-01)	Acc@1  78.91 ( 83.26)	Acc@5  99.22 ( 99.22)
Epoch: [10][260/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.6771e-01 (4.8227e-01)	Acc@1  78.12 ( 83.20)	Acc@5  99.22 ( 99.22)
Epoch: [10][270/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.1622e-01 (4.8339e-01)	Acc@1  83.59 ( 83.14)	Acc@5 100.00 ( 99.23)
Epoch: [10][280/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 7.1423e-01 (4.8440e-01)	Acc@1  73.44 ( 83.09)	Acc@5  98.44 ( 99.21)
Epoch: [10][290/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.8365e-01 (4.8334e-01)	Acc@1  85.16 ( 83.15)	Acc@5  99.22 ( 99.22)
Epoch: [10][300/391]	Time  0.046 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.5890e-01 (4.8304e-01)	Acc@1  88.28 ( 83.17)	Acc@5 100.00 ( 99.22)
Epoch: [10][310/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 6.4298e-01 (4.8232e-01)	Acc@1  80.47 ( 83.19)	Acc@5  97.66 ( 99.23)
Epoch: [10][320/391]	Time  0.049 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.4555e-01 (4.8227e-01)	Acc@1  88.28 ( 83.17)	Acc@5 100.00 ( 99.23)
Epoch: [10][330/391]	Time  0.046 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.2278e-01 (4.8170e-01)	Acc@1  85.94 ( 83.21)	Acc@5 100.00 ( 99.23)
Epoch: [10][340/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.3789e-01 (4.8115e-01)	Acc@1  82.03 ( 83.25)	Acc@5  99.22 ( 99.23)
Epoch: [10][350/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.1206e-01 (4.8062e-01)	Acc@1  84.38 ( 83.27)	Acc@5  97.66 ( 99.23)
Epoch: [10][360/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.001)	Loss 5.7766e-01 (4.8250e-01)	Acc@1  78.12 ( 83.20)	Acc@5  98.44 ( 99.23)
Epoch: [10][370/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.001)	Loss 3.2729e-01 (4.8135e-01)	Acc@1  87.50 ( 83.27)	Acc@5  99.22 ( 99.24)
Epoch: [10][380/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.001)	Loss 3.5681e-01 (4.8052e-01)	Acc@1  85.94 ( 83.29)	Acc@5  99.22 ( 99.25)
Epoch: [10][390/391]	Time  0.028 ( 0.041)	Data  0.001 ( 0.001)	Loss 5.7624e-01 (4.7977e-01)	Acc@1  80.00 ( 83.30)	Acc@5  98.75 ( 99.27)
## e[10] optimizer.zero_grad (sum) time: 0.271209716796875
## e[10]       loss.backward (sum) time: 4.008450508117676
## e[10]      optimizer.step (sum) time: 1.8360612392425537
## epoch[10] training(only) time: 16.06712555885315
# Switched to evaluate mode...
Test: [  0/100]	Time  0.174 ( 0.174)	Loss 6.9846e-01 (6.9846e-01)	Acc@1  75.00 ( 75.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.024 ( 0.036)	Loss 7.7773e-01 (6.7686e-01)	Acc@1  75.00 ( 76.91)	Acc@5  98.00 ( 98.91)
Test: [ 20/100]	Time  0.018 ( 0.030)	Loss 7.9009e-01 (6.5123e-01)	Acc@1  76.00 ( 78.38)	Acc@5  99.00 ( 98.86)
Test: [ 30/100]	Time  0.022 ( 0.027)	Loss 7.3982e-01 (6.7829e-01)	Acc@1  75.00 ( 77.74)	Acc@5  99.00 ( 98.74)
Test: [ 40/100]	Time  0.021 ( 0.026)	Loss 5.8691e-01 (6.8853e-01)	Acc@1  79.00 ( 77.41)	Acc@5  98.00 ( 98.61)
Test: [ 50/100]	Time  0.017 ( 0.025)	Loss 6.3237e-01 (6.7343e-01)	Acc@1  77.00 ( 77.90)	Acc@5  98.00 ( 98.59)
Test: [ 60/100]	Time  0.021 ( 0.024)	Loss 5.8244e-01 (6.7531e-01)	Acc@1  73.00 ( 77.67)	Acc@5 100.00 ( 98.61)
Test: [ 70/100]	Time  0.019 ( 0.023)	Loss 7.0409e-01 (6.7048e-01)	Acc@1  72.00 ( 77.68)	Acc@5  98.00 ( 98.62)
Test: [ 80/100]	Time  0.017 ( 0.023)	Loss 5.6875e-01 (6.7169e-01)	Acc@1  81.00 ( 77.74)	Acc@5 100.00 ( 98.67)
Test: [ 90/100]	Time  0.024 ( 0.023)	Loss 5.9612e-01 (6.6875e-01)	Acc@1  83.00 ( 77.76)	Acc@5  99.00 ( 98.67)
 * Acc@1 77.650 Acc@5 98.700
### epoch[10] execution time: 18.436289072036743
EPOCH 11
i:   0, name:           module.stem.0.weight  changing lr from: 0.089822950858548800   to: 0.087586278261115785
i:   1, name:             module.stem.0.bias  changing lr from: 0.089979647855115114   to: 0.087772736538314813
i:   2, name:           module.stem.1.weight  changing lr from: 0.090133863929493949   to: 0.087956288998151999
i:   3, name:             module.stem.1.bias  changing lr from: 0.090285641642810638   to: 0.088136984012349484
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.090435022808959903   to: 0.088314869156016662
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.090582048506500451   to: 0.088489991218166919
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.090726759090455314   to: 0.088662396212265487
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.090869194204012904   to: 0.088832129386796327
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.091009392790123031   to: 0.088999235235836527
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.091147393102983795   to: 0.089163757509627253
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.091283232719414964   to: 0.089325739225131540
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.091416948550114022   to: 0.089485222676569415
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.091548576850791513   to: 0.089642249445921612
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.091678153233182832   to: 0.089796860413394144
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.091805712675933501   to: 0.089949095767835829
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.091931289535355870   to: 0.090098995017102307
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.092054917556054869   to: 0.090246596998359740
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.092176629881421376   to: 0.090391939888322614
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.092296459063991365   to: 0.090535061213420032
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.092414437075669750   to: 0.090675997859885546
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.092530595317817932   to: 0.090814786083765989
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.092644964631204044   to: 0.090951461520845087
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.092757575305815396   to: 0.091086059196477900
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.092868457090532680   to: 0.091218613535332921
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.092977639202665760   to: 0.091349158371038311
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.093085150337350653   to: 0.091477726955729810
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.093191018676808152   to: 0.091604351969497400
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.093295271899464072   to: 0.091729065529728732
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.093397937188931399   to: 0.091851899200347198
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.093499041242855033   to: 0.091972884000942751
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.093598610281619365   to: 0.092092050415794144
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.093696670056919673   to: 0.092209428402781055
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.093793245860197924   to: 0.092325047402185056
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.093888362530943834   to: 0.092438936345378434
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.093982044464862219   to: 0.092551123663400139
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.094074315621907545   to: 0.092661637295418126
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.094165199534186825   to: 0.092770504697077774
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.094254719313731986   to: 0.092877752848735964
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.094342897660142908   to: 0.092983408263580689
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.094429756868102246   to: 0.093087496995636079
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.094515318834763745   to: 0.093190044647653000
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.094599605067014703   to: 0.093291076378885285
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.094682636688614763   to: 0.093390616912751814
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.094764434447211721   to: 0.093488690544385272
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.094845018721236185   to: 0.093585321148067127
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.094924409526676606   to: 0.093680532184550358
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.095002626523735811   to: 0.093774346708269882
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.095079689023370925   to: 0.093866787374441554
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.095155615993717871   to: 0.093957876446050595
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.095230426066402404   to: 0.094047635800730001
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.095304137542738657   to: 0.094136086937529950
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.095376768399817347   to: 0.094223250983579226
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.095448336296484748   to: 0.094309148700639181
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.095518858579214327   to: 0.094393800491551799
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.095588352287872269   to: 0.094477226406582376
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.095656834161378823   to: 0.094559446149658152
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.095724320643266927   to: 0.094640479084503959
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.095790827887139288   to: 0.094720344240675908
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.095856371762026202   to: 0.094799060319494352
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.095920967857645020   to: 0.094876645699877180
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.095984631489563224   to: 0.094953118444074780
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.096047377704266398   to: 0.095028496303307730
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.096109221284132684   to: 0.095102796723308458
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.096170176752315498   to: 0.095176036849768095
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.096230258377535516   to: 0.095248233533689886
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.096289480178783970   to: 0.095319403336650177
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.096347855929938331   to: 0.095389562535968295
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.096405399164292055   to: 0.095458727129786813
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.096462123178999812   to: 0.095526912842063008
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.096518041039439673   to: 0.095594135127473182
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.096573165583493450   to: 0.095660409176230921
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.096627509425747188   to: 0.095725749918820421
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.096681084961612318   to: 0.095790172030646492
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.096733904371369819   to: 0.095853689936602135
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.096785979624137930   to: 0.095916317815555041
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.096837322481765339   to: 0.095978069604754399
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.096887944502650897   to: 0.096038959004159111
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.096937857045491155   to: 0.096098999480688591
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.096987071272957234   to: 0.096158204272397477
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.097035598155302050   to: 0.096216586392575520
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.097083448473899325   to: 0.096274158633773546
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.097130632824715624   to: 0.096330933571757205
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.097177161621716482   to: 0.096386923569389008
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.097223045100208086   to: 0.096442140780440624
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.097268293320115426   to: 0.096496597153335709
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.097312916169198238   to: 0.096550304434825290
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.097356923366206050   to: 0.096603274173596140
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.097400324463973009   to: 0.096655517723813700
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.097443128852454083   to: 0.096707046248600409
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.097485345761703451   to: 0.096757870723450795
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.097526984264796363   to: 0.096808001939584082
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.097568053280695274   to: 0.096857450507235709
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.097608561577061548   to: 0.096906226858888597
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.097648517773013713   to: 0.096954341252445272
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.097687930341832985   to: 0.097001803774342032
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.097726807613617683   to: 0.097048624342605805
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.097765157777886774   to: 0.097094812709855205
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.097802988886134132   to: 0.097140378466246291
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.097840308854333979   to: 0.097185331042364292
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.097877125465398798   to: 0.097229679712062256
i: 100, name:           module.conv10.weight  changing lr from: 0.097913446371590537   to: 0.097273433595247372
i: 101, name:             module.conv10.bias  changing lr from: 0.097949279096885625   to: 0.097316601660616175



# Switched to train mode...
Epoch: [11][  0/391]	Time  0.218 ( 0.218)	Data  0.174 ( 0.174)	Loss 4.5002e-01 (4.5002e-01)	Acc@1  82.81 ( 82.81)	Acc@5 100.00 (100.00)
Epoch: [11][ 10/391]	Time  0.040 ( 0.057)	Data  0.001 ( 0.017)	Loss 3.8539e-01 (4.4160e-01)	Acc@1  85.94 ( 84.38)	Acc@5 100.00 ( 99.72)
Epoch: [11][ 20/391]	Time  0.041 ( 0.050)	Data  0.001 ( 0.009)	Loss 3.9158e-01 (4.3017e-01)	Acc@1  89.84 ( 84.78)	Acc@5  97.66 ( 99.40)
Epoch: [11][ 30/391]	Time  0.039 ( 0.046)	Data  0.001 ( 0.007)	Loss 4.6836e-01 (4.2563e-01)	Acc@1  81.25 ( 85.08)	Acc@5  98.44 ( 99.42)
Epoch: [11][ 40/391]	Time  0.041 ( 0.045)	Data  0.001 ( 0.005)	Loss 5.8733e-01 (4.4095e-01)	Acc@1  80.47 ( 84.83)	Acc@5  98.44 ( 99.28)
Epoch: [11][ 50/391]	Time  0.040 ( 0.044)	Data  0.001 ( 0.004)	Loss 4.6699e-01 (4.4116e-01)	Acc@1  88.28 ( 84.79)	Acc@5  97.66 ( 99.25)
Epoch: [11][ 60/391]	Time  0.040 ( 0.044)	Data  0.001 ( 0.004)	Loss 3.6515e-01 (4.4145e-01)	Acc@1  87.50 ( 84.77)	Acc@5  99.22 ( 99.32)
Epoch: [11][ 70/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.003)	Loss 3.5477e-01 (4.4366e-01)	Acc@1  84.38 ( 84.86)	Acc@5 100.00 ( 99.28)
Epoch: [11][ 80/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.003)	Loss 4.9781e-01 (4.5173e-01)	Acc@1  80.47 ( 84.64)	Acc@5  97.66 ( 99.28)
Epoch: [11][ 90/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.003)	Loss 5.2497e-01 (4.5401e-01)	Acc@1  79.69 ( 84.56)	Acc@5 100.00 ( 99.27)
Epoch: [11][100/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.003)	Loss 3.8873e-01 (4.5505e-01)	Acc@1  85.16 ( 84.42)	Acc@5  99.22 ( 99.30)
Epoch: [11][110/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.003)	Loss 4.9131e-01 (4.5459e-01)	Acc@1  81.25 ( 84.35)	Acc@5  99.22 ( 99.32)
Epoch: [11][120/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 4.8574e-01 (4.5725e-01)	Acc@1  85.16 ( 84.27)	Acc@5  98.44 ( 99.30)
Epoch: [11][130/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 4.9822e-01 (4.5937e-01)	Acc@1  83.59 ( 84.26)	Acc@5  99.22 ( 99.31)
Epoch: [11][140/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 3.4690e-01 (4.5859e-01)	Acc@1  86.72 ( 84.31)	Acc@5 100.00 ( 99.30)
Epoch: [11][150/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 4.6753e-01 (4.6011e-01)	Acc@1  82.81 ( 84.29)	Acc@5 100.00 ( 99.30)
Epoch: [11][160/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.0601e-01 (4.6013e-01)	Acc@1  84.38 ( 84.21)	Acc@5  99.22 ( 99.30)
Epoch: [11][170/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 3.6962e-01 (4.5777e-01)	Acc@1  85.16 ( 84.23)	Acc@5  99.22 ( 99.30)
Epoch: [11][180/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 4.1723e-01 (4.5824e-01)	Acc@1  82.81 ( 84.21)	Acc@5 100.00 ( 99.31)
Epoch: [11][190/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 4.8028e-01 (4.5849e-01)	Acc@1  84.38 ( 84.24)	Acc@5  98.44 ( 99.30)
Epoch: [11][200/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 3.9096e-01 (4.6034e-01)	Acc@1  85.16 ( 84.18)	Acc@5 100.00 ( 99.31)
Epoch: [11][210/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.0852e-01 (4.5973e-01)	Acc@1  83.59 ( 84.25)	Acc@5  98.44 ( 99.32)
Epoch: [11][220/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 3.5103e-01 (4.5859e-01)	Acc@1  87.50 ( 84.28)	Acc@5  99.22 ( 99.32)
Epoch: [11][230/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 4.6939e-01 (4.5744e-01)	Acc@1  83.59 ( 84.34)	Acc@5  99.22 ( 99.33)
Epoch: [11][240/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 3.6721e-01 (4.5545e-01)	Acc@1  89.06 ( 84.39)	Acc@5 100.00 ( 99.34)
Epoch: [11][250/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.4086e-01 (4.5582e-01)	Acc@1  83.59 ( 84.35)	Acc@5 100.00 ( 99.36)
Epoch: [11][260/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.9042e-01 (4.5601e-01)	Acc@1  75.78 ( 84.32)	Acc@5  99.22 ( 99.36)
Epoch: [11][270/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.6951e-01 (4.5512e-01)	Acc@1  88.28 ( 84.38)	Acc@5 100.00 ( 99.35)
Epoch: [11][280/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.7643e-01 (4.5469e-01)	Acc@1  85.16 ( 84.43)	Acc@5  97.66 ( 99.34)
Epoch: [11][290/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.0917e-01 (4.5442e-01)	Acc@1  80.47 ( 84.40)	Acc@5  99.22 ( 99.34)
Epoch: [11][300/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.6160e-01 (4.5290e-01)	Acc@1  84.38 ( 84.47)	Acc@5  97.66 ( 99.35)
Epoch: [11][310/391]	Time  0.036 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.8481e-01 (4.5264e-01)	Acc@1  87.50 ( 84.46)	Acc@5 100.00 ( 99.35)
Epoch: [11][320/391]	Time  0.037 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.3903e-01 (4.5381e-01)	Acc@1  84.38 ( 84.44)	Acc@5 100.00 ( 99.35)
Epoch: [11][330/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.0734e-01 (4.5402e-01)	Acc@1  82.81 ( 84.45)	Acc@5  99.22 ( 99.35)
Epoch: [11][340/391]	Time  0.036 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.4932e-01 (4.5466e-01)	Acc@1  85.94 ( 84.42)	Acc@5  98.44 ( 99.35)
Epoch: [11][350/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.2974e-01 (4.5517e-01)	Acc@1  86.72 ( 84.41)	Acc@5  99.22 ( 99.35)
Epoch: [11][360/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.6776e-01 (4.5577e-01)	Acc@1  75.00 ( 84.38)	Acc@5  99.22 ( 99.34)
Epoch: [11][370/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.2962e-01 (4.5627e-01)	Acc@1  84.38 ( 84.37)	Acc@5 100.00 ( 99.33)
Epoch: [11][380/391]	Time  0.043 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.8082e-01 (4.5555e-01)	Acc@1  83.59 ( 84.37)	Acc@5 100.00 ( 99.34)
Epoch: [11][390/391]	Time  0.032 ( 0.041)	Data  0.001 ( 0.001)	Loss 5.7362e-01 (4.5600e-01)	Acc@1  80.00 ( 84.34)	Acc@5  98.75 ( 99.33)
## e[11] optimizer.zero_grad (sum) time: 0.27443480491638184
## e[11]       loss.backward (sum) time: 3.9958980083465576
## e[11]      optimizer.step (sum) time: 1.8154406547546387
## epoch[11] training(only) time: 16.099854469299316
# Switched to evaluate mode...
Test: [  0/100]	Time  0.176 ( 0.176)	Loss 7.0678e-01 (7.0678e-01)	Acc@1  77.00 ( 77.00)	Acc@5  98.00 ( 98.00)
Test: [ 10/100]	Time  0.017 ( 0.035)	Loss 7.4686e-01 (5.9209e-01)	Acc@1  79.00 ( 80.36)	Acc@5  99.00 ( 99.09)
Test: [ 20/100]	Time  0.022 ( 0.027)	Loss 7.1774e-01 (5.6483e-01)	Acc@1  73.00 ( 80.33)	Acc@5 100.00 ( 99.10)
Test: [ 30/100]	Time  0.021 ( 0.025)	Loss 6.6622e-01 (5.8455e-01)	Acc@1  75.00 ( 79.94)	Acc@5 100.00 ( 99.06)
Test: [ 40/100]	Time  0.017 ( 0.024)	Loss 5.5302e-01 (5.9301e-01)	Acc@1  80.00 ( 79.90)	Acc@5  98.00 ( 98.95)
Test: [ 50/100]	Time  0.021 ( 0.023)	Loss 6.2429e-01 (5.8529e-01)	Acc@1  81.00 ( 80.14)	Acc@5  98.00 ( 98.96)
Test: [ 60/100]	Time  0.021 ( 0.023)	Loss 4.6056e-01 (5.8279e-01)	Acc@1  82.00 ( 80.08)	Acc@5 100.00 ( 99.00)
Test: [ 70/100]	Time  0.020 ( 0.023)	Loss 7.0542e-01 (5.8642e-01)	Acc@1  79.00 ( 80.15)	Acc@5 100.00 ( 99.00)
Test: [ 80/100]	Time  0.020 ( 0.023)	Loss 5.4505e-01 (5.8316e-01)	Acc@1  78.00 ( 80.31)	Acc@5  97.00 ( 98.95)
Test: [ 90/100]	Time  0.024 ( 0.023)	Loss 4.5917e-01 (5.8575e-01)	Acc@1  81.00 ( 80.23)	Acc@5  98.00 ( 98.86)
 * Acc@1 80.220 Acc@5 98.870
### epoch[11] execution time: 18.468271017074585
EPOCH 12
i:   0, name:           module.stem.0.weight  changing lr from: 0.087586278261115785   to: 0.085179615101143580
i:   1, name:             module.stem.0.bias  changing lr from: 0.087772736538314813   to: 0.085397458555700911
i:   2, name:           module.stem.1.weight  changing lr from: 0.087956288998151999   to: 0.085611967218120394
i:   3, name:             module.stem.1.bias  changing lr from: 0.088136984012349484   to: 0.085823194667161179
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.088314869156016662   to: 0.086031193669376893
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.088489991218166919   to: 0.086236016186800393
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.088662396212265487   to: 0.086437713384843434
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.088832129386796327   to: 0.086636335640389472
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.088999235235836527   to: 0.086831932550059832
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.089163757509627253   to: 0.087024552938634314
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.089325739225131540   to: 0.087214244867607982
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.089485222676569415   to: 0.087401055643868089
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.089642249445921612   to: 0.087585031828474533
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.089796860413394144   to: 0.087766219245529617
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.089949095767835829   to: 0.087944662991122691
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.090098995017102307   to: 0.088120407442337054
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.090246596998359740   to: 0.088293496266306115
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.090391939888322614   to: 0.088463972429308091
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.090535061213420032   to: 0.088631878205887582
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.090675997859885546   to: 0.088797255187994667
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.090814786083765989   to: 0.088960144294131349
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.090951461520845087   to: 0.089120585778496936
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.091086059196477900   to: 0.089278619240123952
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.091218613535332921   to: 0.089434283631996667
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.091349158371038311   to: 0.089587617270145414
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.091477726955729810   to: 0.089738657842709513
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.091604351969497400   to: 0.089887442418963015
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.091729065529728732   to: 0.090034007458297108
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.091851899200347198   to: 0.090178388819154215
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.091972884000942751   to: 0.090320621767908227
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.092092050415794144   to: 0.090460740987686958
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.092209428402781055   to: 0.090598780587132097
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.092325047402185056   to: 0.090734774109092864
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.092438936345378434   to: 0.090868754539250030
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.092551123663400139   to: 0.091000754314666685
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.092661637295418126   to: 0.091130805332262838
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.092770504697077774   to: 0.091258938957211475
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.092877752848735964   to: 0.091385186031252993
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.092983408263580689   to: 0.091509576880926341
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.093087496995636079   to: 0.091632141325714539
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.093190044647653000   to: 0.091752908686102780
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.093291076378885285   to: 0.091871907791547747
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.093390616912751814   to: 0.091989166988356519
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.093488690544385272   to: 0.092104714147473857
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.093585321148067127   to: 0.092218576672176950
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.093680532184550358   to: 0.092330781505676557
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.093774346708269882   to: 0.092441355138623837
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.093866787374441554   to: 0.092550323616522323
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.093957876446050595   to: 0.092657712547044385
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.094047635800730001   to: 0.092763547107251931
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.094136086937529950   to: 0.092867852050721122
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.094223250983579226   to: 0.092970651714570807
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.094309148700639181   to: 0.093071970026394668
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.094393800491551799   to: 0.093171830511097342
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.094477226406582376   to: 0.093270256297634246
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.094559446149658152   to: 0.093367270125655558
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.094640479084503959   to: 0.093462894352054834
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.094720344240675908   to: 0.093557150957422050
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.094799060319494352   to: 0.093650061552402103
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.094876645699877180   to: 0.093741647383958793
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.094953118444074780   to: 0.093831929341545162
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.095028496303307730   to: 0.093920927963180467
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.095102796723308458   to: 0.094008663441434714
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.095176036849768095   to: 0.094095155629321151
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.095248233533689886   to: 0.094180424046097791
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.095319403336650177   to: 0.094264487882978323
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.095389562535968295   to: 0.094347366008753472
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.095458727129786813   to: 0.094429076975323545
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.095526912842063008   to: 0.094509639023143160
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.095594135127473182   to: 0.094589070086578589
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.095660409176230921   to: 0.094667387799179270
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.095725749918820421   to: 0.094744609498863819
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.095790172030646492   to: 0.094820752233021860
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.095853689936602135   to: 0.094895832763532431
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.095916317815555041   to: 0.094969867571699992
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.095978069604754399   to: 0.095042872863109043
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.096038959004159111   to: 0.095114864572398317
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.096098999480688591   to: 0.095185858367955539
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.096158204272397477   to: 0.095255869656533793
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.096216586392575520   to: 0.095324913587790439
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.096274158633773546   to: 0.095393005058749730
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.096330933571757205   to: 0.095460158718189997
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.096386923569389008   to: 0.095526388970956555
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.096442140780440624   to: 0.095591709982201289
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.096496597153335709   to: 0.095656135681549848
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.096550304434825290   to: 0.095719679767197891
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.096603274173596140   to: 0.095782355709936637
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.096655517723813700   to: 0.095844176757109642
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.096707046248600409   to: 0.095905155936501119
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.096757870723450795   to: 0.095965306060157185
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.096808001939584082   to: 0.096024639728140862
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.096857450507235709   to: 0.096083169332221940
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.096906226858888597   to: 0.096140907059502650
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.096954341252445272   to: 0.096197864895980201
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.097001803774342032   to: 0.096254054630047076
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.097048624342605805   to: 0.096309487855930007
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.097094812709855205   to: 0.096364175977068867
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.097140378466246291   to: 0.096418130209436112
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.097185331042364292   to: 0.096471361584797924
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.097229679712062256   to: 0.096523880953918006
i: 100, name:           module.conv10.weight  changing lr from: 0.097273433595247372   to: 0.096575698989704639
i: 101, name:             module.conv10.bias  changing lr from: 0.097316601660616175   to: 0.096626826190302606



# Switched to train mode...
Epoch: [12][  0/391]	Time  0.221 ( 0.221)	Data  0.177 ( 0.177)	Loss 3.9729e-01 (3.9729e-01)	Acc@1  84.38 ( 84.38)	Acc@5 100.00 (100.00)
Epoch: [12][ 10/391]	Time  0.039 ( 0.056)	Data  0.001 ( 0.017)	Loss 5.3266e-01 (4.3792e-01)	Acc@1  78.91 ( 85.01)	Acc@5  98.44 ( 99.22)
Epoch: [12][ 20/391]	Time  0.036 ( 0.048)	Data  0.001 ( 0.009)	Loss 3.7246e-01 (4.4633e-01)	Acc@1  87.50 ( 84.75)	Acc@5  99.22 ( 99.37)
Epoch: [12][ 30/391]	Time  0.041 ( 0.045)	Data  0.001 ( 0.007)	Loss 4.1383e-01 (4.2879e-01)	Acc@1  89.06 ( 85.33)	Acc@5  99.22 ( 99.37)
Epoch: [12][ 40/391]	Time  0.040 ( 0.044)	Data  0.002 ( 0.005)	Loss 3.7376e-01 (4.3079e-01)	Acc@1  82.81 ( 85.04)	Acc@5 100.00 ( 99.43)
Epoch: [12][ 50/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.005)	Loss 4.9639e-01 (4.3126e-01)	Acc@1  82.81 ( 84.93)	Acc@5  99.22 ( 99.39)
Epoch: [12][ 60/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.004)	Loss 4.2722e-01 (4.3245e-01)	Acc@1  85.16 ( 84.96)	Acc@5 100.00 ( 99.39)
Epoch: [12][ 70/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.004)	Loss 4.0090e-01 (4.3520e-01)	Acc@1  85.16 ( 84.88)	Acc@5 100.00 ( 99.37)
Epoch: [12][ 80/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.003)	Loss 4.1448e-01 (4.3752e-01)	Acc@1  87.50 ( 84.89)	Acc@5  99.22 ( 99.33)
Epoch: [12][ 90/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.003)	Loss 5.6061e-01 (4.4036e-01)	Acc@1  82.81 ( 84.92)	Acc@5 100.00 ( 99.33)
Epoch: [12][100/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.003)	Loss 5.0833e-01 (4.3990e-01)	Acc@1  82.81 ( 84.85)	Acc@5 100.00 ( 99.33)
Epoch: [12][110/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.003)	Loss 4.5814e-01 (4.3568e-01)	Acc@1  84.38 ( 85.02)	Acc@5  98.44 ( 99.33)
Epoch: [12][120/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.003)	Loss 4.4667e-01 (4.3344e-01)	Acc@1  82.81 ( 85.10)	Acc@5  99.22 ( 99.32)
Epoch: [12][130/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.9399e-01 (4.3196e-01)	Acc@1  82.81 ( 85.12)	Acc@5  98.44 ( 99.33)
Epoch: [12][140/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.6732e-01 (4.3525e-01)	Acc@1  83.59 ( 85.00)	Acc@5  98.44 ( 99.32)
Epoch: [12][150/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.1171e-01 (4.3328e-01)	Acc@1  86.72 ( 85.14)	Acc@5  99.22 ( 99.34)
Epoch: [12][160/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.8404e-01 (4.3264e-01)	Acc@1  78.12 ( 85.16)	Acc@5  98.44 ( 99.34)
Epoch: [12][170/391]	Time  0.037 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.6468e-01 (4.3236e-01)	Acc@1  78.91 ( 85.06)	Acc@5 100.00 ( 99.36)
Epoch: [12][180/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.3691e-01 (4.3343e-01)	Acc@1  85.16 ( 85.04)	Acc@5  96.88 ( 99.34)
Epoch: [12][190/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.3974e-01 (4.3407e-01)	Acc@1  87.50 ( 85.04)	Acc@5  99.22 ( 99.35)
Epoch: [12][200/391]	Time  0.037 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.6822e-01 (4.3394e-01)	Acc@1  89.06 ( 85.08)	Acc@5  99.22 ( 99.35)
Epoch: [12][210/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.6812e-01 (4.3493e-01)	Acc@1  85.16 ( 85.09)	Acc@5  96.09 ( 99.34)
Epoch: [12][220/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.4600e-01 (4.3550e-01)	Acc@1  80.47 ( 85.03)	Acc@5 100.00 ( 99.36)
Epoch: [12][230/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.9478e-01 (4.3604e-01)	Acc@1  82.81 ( 85.01)	Acc@5  98.44 ( 99.36)
Epoch: [12][240/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.0464e-01 (4.3648e-01)	Acc@1  90.62 ( 84.99)	Acc@5 100.00 ( 99.37)
Epoch: [12][250/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.5642e-01 (4.3924e-01)	Acc@1  80.47 ( 84.89)	Acc@5  98.44 ( 99.37)
Epoch: [12][260/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.2031e-01 (4.3980e-01)	Acc@1  82.81 ( 84.87)	Acc@5  99.22 ( 99.37)
Epoch: [12][270/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.6561e-01 (4.3961e-01)	Acc@1  87.50 ( 84.85)	Acc@5 100.00 ( 99.38)
Epoch: [12][280/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.8716e-01 (4.4078e-01)	Acc@1  89.06 ( 84.79)	Acc@5  99.22 ( 99.37)
Epoch: [12][290/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.5866e-01 (4.3982e-01)	Acc@1  88.28 ( 84.81)	Acc@5 100.00 ( 99.38)
Epoch: [12][300/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.5026e-01 (4.3848e-01)	Acc@1  85.94 ( 84.89)	Acc@5  99.22 ( 99.39)
Epoch: [12][310/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.6294e-01 (4.3860e-01)	Acc@1  84.38 ( 84.90)	Acc@5  99.22 ( 99.39)
Epoch: [12][320/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.9546e-01 (4.3925e-01)	Acc@1  84.38 ( 84.92)	Acc@5 100.00 ( 99.40)
Epoch: [12][330/391]	Time  0.047 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.8258e-01 (4.4083e-01)	Acc@1  79.69 ( 84.85)	Acc@5  99.22 ( 99.40)
Epoch: [12][340/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.6870e-01 (4.4077e-01)	Acc@1  87.50 ( 84.86)	Acc@5  99.22 ( 99.39)
Epoch: [12][350/391]	Time  0.036 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.2040e-01 (4.4012e-01)	Acc@1  84.38 ( 84.86)	Acc@5  99.22 ( 99.39)
Epoch: [12][360/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.5934e-01 (4.4013e-01)	Acc@1  85.94 ( 84.87)	Acc@5 100.00 ( 99.40)
Epoch: [12][370/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.001)	Loss 3.5368e-01 (4.3999e-01)	Acc@1  88.28 ( 84.88)	Acc@5 100.00 ( 99.40)
Epoch: [12][380/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.001)	Loss 3.8867e-01 (4.3951e-01)	Acc@1  85.16 ( 84.89)	Acc@5  99.22 ( 99.40)
Epoch: [12][390/391]	Time  0.029 ( 0.041)	Data  0.001 ( 0.001)	Loss 2.7306e-01 (4.4031e-01)	Acc@1  93.75 ( 84.85)	Acc@5 100.00 ( 99.41)
## e[12] optimizer.zero_grad (sum) time: 0.27218127250671387
## e[12]       loss.backward (sum) time: 3.958709716796875
## e[12]      optimizer.step (sum) time: 1.827397108078003
## epoch[12] training(only) time: 16.021601676940918
# Switched to evaluate mode...
Test: [  0/100]	Time  0.168 ( 0.168)	Loss 6.1766e-01 (6.1766e-01)	Acc@1  77.00 ( 77.00)	Acc@5  99.00 ( 99.00)
Test: [ 10/100]	Time  0.022 ( 0.034)	Loss 6.7294e-01 (6.0085e-01)	Acc@1  77.00 ( 79.18)	Acc@5  99.00 ( 99.18)
Test: [ 20/100]	Time  0.021 ( 0.028)	Loss 7.5000e-01 (6.0297e-01)	Acc@1  72.00 ( 79.14)	Acc@5 100.00 ( 99.05)
Test: [ 30/100]	Time  0.021 ( 0.026)	Loss 6.3091e-01 (6.1554e-01)	Acc@1  81.00 ( 79.26)	Acc@5  98.00 ( 99.03)
Test: [ 40/100]	Time  0.018 ( 0.024)	Loss 5.5375e-01 (6.1647e-01)	Acc@1  79.00 ( 79.27)	Acc@5  98.00 ( 99.02)
Test: [ 50/100]	Time  0.017 ( 0.023)	Loss 5.0279e-01 (6.1070e-01)	Acc@1  82.00 ( 79.55)	Acc@5  98.00 ( 98.98)
Test: [ 60/100]	Time  0.019 ( 0.023)	Loss 5.4726e-01 (6.1058e-01)	Acc@1  80.00 ( 79.56)	Acc@5  99.00 ( 99.02)
Test: [ 70/100]	Time  0.021 ( 0.022)	Loss 5.7440e-01 (6.1000e-01)	Acc@1  82.00 ( 79.45)	Acc@5  99.00 ( 99.04)
Test: [ 80/100]	Time  0.024 ( 0.022)	Loss 4.4489e-01 (6.0634e-01)	Acc@1  85.00 ( 79.65)	Acc@5  99.00 ( 99.07)
Test: [ 90/100]	Time  0.020 ( 0.022)	Loss 4.4345e-01 (6.1177e-01)	Acc@1  79.00 ( 79.46)	Acc@5 100.00 ( 99.02)
 * Acc@1 79.530 Acc@5 99.010
### epoch[12] execution time: 18.27211308479309
EPOCH 13
i:   0, name:           module.stem.0.weight  changing lr from: 0.085179615101143580   to: 0.082614143440428292
i:   1, name:             module.stem.0.bias  changing lr from: 0.085397458555700911   to: 0.082864689291374818
i:   2, name:           module.stem.1.weight  changing lr from: 0.085611967218120394   to: 0.083111476173884258
i:   3, name:             module.stem.1.bias  changing lr from: 0.085823194667161179   to: 0.083354562003362179
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.086031193669376893   to: 0.083594003909340006
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.086236016186800393   to: 0.083829858238632454
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.086437713384843434   to: 0.084062180558957589
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.086636335640389472   to: 0.084291025662986657
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.086831932550059832   to: 0.084516447572792822
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.087024552938634314   to: 0.084738499544669499
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.087214244867607982   to: 0.084957234074290677
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.087401055643868089   to: 0.085172702902186648
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.087585031828474533   to: 0.085384957019510530
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.087766219245529617   to: 0.085594046674071958
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.087944662991122691   to: 0.085800021376615479
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.088120407442337054   to: 0.086002929907322834
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.088293496266306115   to: 0.086202820322518858
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.088463972429308091   to: 0.086399739961562638
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.088631878205887582   to: 0.086593735453905529
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.088797255187994667   to: 0.086784852726299683
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.088960144294131349   to: 0.086973137010141033
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.089120585778496936   to: 0.087158632848931744
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.089278619240123952   to: 0.087341384105848019
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.089434283631996667   to: 0.087521433971400053
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.089587617270145414   to: 0.087698824971171430
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.089738657842709513   to: 0.087873598973626219
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.089887442418963015   to: 0.088045797197972744
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.090034007458297108   to: 0.088215460222073452
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.090178388819154215   to: 0.088382627990391052
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.090320621767908227   to: 0.088547339821961890
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.090460740987686958   to: 0.088709634418387640
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.090598780587132097   to: 0.088869549871837317
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.090734774109092864   to: 0.089027123673052141
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.090868754539250030   to: 0.089182392719345860
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.091000754314666685   to: 0.089335393322593978
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.091130805332262838   to: 0.089486161217205928
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.091258938957211475   to: 0.089634731568073736
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.091385186031252993   to: 0.089781138978492658
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.091509576880926341   to: 0.089925417498047819
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.091632141325714539   to: 0.090067600630462846
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.091752908686102780   to: 0.090207721341405894
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.091871907791547747   to: 0.090345812066248907
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.091989166988356519   to: 0.090481904717776562
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.092104714147473857   to: 0.090616030693841457
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.092218576672176950   to: 0.090748220884962205
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.092330781505676557   to: 0.090878505681861510
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.092441355138623837   to: 0.091006914982941847
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.092550323616522323   to: 0.091133478201695803
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.092657712547044385   to: 0.091258224274049282
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.092763547107251931   to: 0.091381181665635233
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.092867852050721122   to: 0.091502378378996205
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.092970651714570807   to: 0.091621841960713976
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.093071970026394668   to: 0.091739599508464914
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.093171830511097342   to: 0.091855677677999570
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.093270256297634246   to: 0.091970102690045311
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.093367270125655558   to: 0.092082900337131166
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.093462894352054834   to: 0.092194095990333791
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.093557150957422050   to: 0.092303714605943887
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.093650061552402103   to: 0.092411780732052307
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.093741647383958793   to: 0.092518318515055320
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.093831929341545162   to: 0.092623351706078993
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.093920927963180467   to: 0.092726903667321559
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.094008663441434714   to: 0.092828997378314390
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.094095155629321151   to: 0.092929655442100773
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.094180424046097791   to: 0.093028900091332786
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.094264487882978323   to: 0.093126753194286205
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.094347366008753472   to: 0.093223236260793416
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.094429076975323545   to: 0.093318370448094531
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.094509639023143160   to: 0.093412176566607052
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.094589070086578589   to: 0.093504675085614108
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.094667387799179270   to: 0.093595886138871834
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.094744609498863819   to: 0.093685829530135975
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.094820752233021860   to: 0.093774524738608478
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.094895832763532431   to: 0.093861990924304278
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.094969867571699992   to: 0.093948246933338905
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.095042872863109043   to: 0.094033311303137357
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.095114864572398317   to: 0.094117202267564926
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.095185858367955539   to: 0.094199937761980504
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.095255869656533793   to: 0.094281535428213090
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.095324913587790439   to: 0.094362012619461977
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.095393005058749730   to: 0.094441386405121661
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.095460158718189997   to: 0.094519673575531704
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.095526388970956555   to: 0.094596890646652720
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.095591709982201289   to: 0.094673053864668982
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.095656135681549848   to: 0.094748179210518507
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.095719679767197891   to: 0.094822282404351310
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.095782355709936637   to: 0.094895378909916783
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.095844176757109642   to: 0.094967483938880881
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.095905155936501119   to: 0.095038612455073848
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.095965306060157185   to: 0.095108779178669584
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.096024639728140862   to: 0.095177998590297186
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.096083169332221940   to: 0.095246284935085690
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.096140907059502650   to: 0.095313652226642689
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.096197864895980201   to: 0.095380114250967957
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.096254054630047076   to: 0.095445684570302558
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.096309487855930007   to: 0.095510376526914575
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.096364175977068867   to: 0.095574203246822170
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.096418130209436112   to: 0.095637177643454918
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.096471361584797924   to: 0.095699312421254165
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.096523880953918006   to: 0.095760620079213252
i: 100, name:           module.conv10.weight  changing lr from: 0.096575698989704639   to: 0.095821112914358644
i: 101, name:             module.conv10.bias  changing lr from: 0.096626826190302606   to: 0.095880803025172628



# Switched to train mode...
Epoch: [13][  0/391]	Time  0.213 ( 0.213)	Data  0.172 ( 0.172)	Loss 4.1350e-01 (4.1350e-01)	Acc@1  85.94 ( 85.94)	Acc@5 100.00 (100.00)
Epoch: [13][ 10/391]	Time  0.041 ( 0.057)	Data  0.001 ( 0.016)	Loss 5.6553e-01 (4.3660e-01)	Acc@1  82.81 ( 85.30)	Acc@5  99.22 ( 99.57)
Epoch: [13][ 20/391]	Time  0.042 ( 0.050)	Data  0.001 ( 0.009)	Loss 3.5984e-01 (4.2678e-01)	Acc@1  89.06 ( 85.45)	Acc@5 100.00 ( 99.59)
Epoch: [13][ 30/391]	Time  0.039 ( 0.047)	Data  0.001 ( 0.006)	Loss 4.1547e-01 (4.2905e-01)	Acc@1  83.59 ( 85.16)	Acc@5  98.44 ( 99.52)
Epoch: [13][ 40/391]	Time  0.036 ( 0.045)	Data  0.001 ( 0.005)	Loss 3.2595e-01 (4.3567e-01)	Acc@1  89.84 ( 85.04)	Acc@5  99.22 ( 99.43)
Epoch: [13][ 50/391]	Time  0.041 ( 0.044)	Data  0.001 ( 0.004)	Loss 5.7389e-01 (4.3681e-01)	Acc@1  78.12 ( 84.67)	Acc@5 100.00 ( 99.48)
Epoch: [13][ 60/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.004)	Loss 4.9749e-01 (4.3195e-01)	Acc@1  83.59 ( 84.91)	Acc@5  98.44 ( 99.51)
Epoch: [13][ 70/391]	Time  0.038 ( 0.043)	Data  0.001 ( 0.003)	Loss 5.1185e-01 (4.3445e-01)	Acc@1  79.69 ( 84.95)	Acc@5  99.22 ( 99.48)
Epoch: [13][ 80/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.003)	Loss 3.1121e-01 (4.2959e-01)	Acc@1  88.28 ( 85.18)	Acc@5 100.00 ( 99.48)
Epoch: [13][ 90/391]	Time  0.036 ( 0.042)	Data  0.001 ( 0.003)	Loss 5.8422e-01 (4.3095e-01)	Acc@1  86.72 ( 85.18)	Acc@5  98.44 ( 99.48)
Epoch: [13][100/391]	Time  0.036 ( 0.041)	Data  0.001 ( 0.003)	Loss 5.4460e-01 (4.3316e-01)	Acc@1  80.47 ( 85.06)	Acc@5  99.22 ( 99.47)
Epoch: [13][110/391]	Time  0.037 ( 0.041)	Data  0.001 ( 0.003)	Loss 4.2683e-01 (4.3402e-01)	Acc@1  86.72 ( 85.09)	Acc@5  98.44 ( 99.42)
Epoch: [13][120/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.7950e-01 (4.3426e-01)	Acc@1  84.38 ( 84.97)	Acc@5 100.00 ( 99.42)
Epoch: [13][130/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.2438e-01 (4.3109e-01)	Acc@1  82.81 ( 85.06)	Acc@5  99.22 ( 99.43)
Epoch: [13][140/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.7525e-01 (4.3233e-01)	Acc@1  82.81 ( 85.05)	Acc@5 100.00 ( 99.45)
Epoch: [13][150/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.9875e-01 (4.3102e-01)	Acc@1  86.72 ( 85.05)	Acc@5 100.00 ( 99.41)
Epoch: [13][160/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.6614e-01 (4.3067e-01)	Acc@1  81.25 ( 85.16)	Acc@5 100.00 ( 99.40)
Epoch: [13][170/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.1244e-01 (4.2907e-01)	Acc@1  82.81 ( 85.22)	Acc@5 100.00 ( 99.42)
Epoch: [13][180/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.4197e-01 (4.2855e-01)	Acc@1  82.81 ( 85.25)	Acc@5  98.44 ( 99.42)
Epoch: [13][190/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.2203e-01 (4.2983e-01)	Acc@1  87.50 ( 85.18)	Acc@5  98.44 ( 99.42)
Epoch: [13][200/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.2468e-01 (4.3018e-01)	Acc@1  85.16 ( 85.18)	Acc@5  99.22 ( 99.41)
Epoch: [13][210/391]	Time  0.043 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.2070e-01 (4.2821e-01)	Acc@1  83.59 ( 85.19)	Acc@5  99.22 ( 99.42)
Epoch: [13][220/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.2846e-01 (4.2701e-01)	Acc@1  89.06 ( 85.24)	Acc@5 100.00 ( 99.41)
Epoch: [13][230/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.6903e-01 (4.2598e-01)	Acc@1  87.50 ( 85.28)	Acc@5  99.22 ( 99.42)
Epoch: [13][240/391]	Time  0.041 ( 0.041)	Data  0.002 ( 0.002)	Loss 4.2780e-01 (4.2566e-01)	Acc@1  85.94 ( 85.26)	Acc@5  99.22 ( 99.43)
Epoch: [13][250/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.5274e-01 (4.2549e-01)	Acc@1  90.62 ( 85.28)	Acc@5 100.00 ( 99.42)
Epoch: [13][260/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.2145e-01 (4.2785e-01)	Acc@1  82.81 ( 85.23)	Acc@5  99.22 ( 99.41)
Epoch: [13][270/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.1034e-01 (4.2928e-01)	Acc@1  80.47 ( 85.17)	Acc@5  99.22 ( 99.40)
Epoch: [13][280/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.1350e-01 (4.2902e-01)	Acc@1  83.59 ( 85.19)	Acc@5 100.00 ( 99.41)
Epoch: [13][290/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.8647e-01 (4.2907e-01)	Acc@1  76.56 ( 85.18)	Acc@5  99.22 ( 99.42)
Epoch: [13][300/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.8085e-01 (4.3013e-01)	Acc@1  80.47 ( 85.13)	Acc@5  98.44 ( 99.42)
Epoch: [13][310/391]	Time  0.043 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.3319e-01 (4.3055e-01)	Acc@1  89.06 ( 85.17)	Acc@5 100.00 ( 99.42)
Epoch: [13][320/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.9328e-01 (4.3015e-01)	Acc@1  87.50 ( 85.17)	Acc@5  99.22 ( 99.42)
Epoch: [13][330/391]	Time  0.041 ( 0.041)	Data  0.002 ( 0.002)	Loss 5.6871e-01 (4.3087e-01)	Acc@1  81.25 ( 85.12)	Acc@5  99.22 ( 99.43)
Epoch: [13][340/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.5742e-01 (4.3109e-01)	Acc@1  80.47 ( 85.08)	Acc@5  98.44 ( 99.42)
Epoch: [13][350/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.3598e-01 (4.3002e-01)	Acc@1  88.28 ( 85.13)	Acc@5 100.00 ( 99.41)
Epoch: [13][360/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.8423e-01 (4.3016e-01)	Acc@1  79.69 ( 85.13)	Acc@5  99.22 ( 99.41)
Epoch: [13][370/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.001)	Loss 4.0551e-01 (4.2912e-01)	Acc@1  85.94 ( 85.16)	Acc@5 100.00 ( 99.41)
Epoch: [13][380/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.001)	Loss 4.6680e-01 (4.2822e-01)	Acc@1  81.25 ( 85.18)	Acc@5  98.44 ( 99.42)
Epoch: [13][390/391]	Time  0.026 ( 0.041)	Data  0.001 ( 0.001)	Loss 3.3181e-01 (4.2793e-01)	Acc@1  86.25 ( 85.21)	Acc@5 100.00 ( 99.42)
## e[13] optimizer.zero_grad (sum) time: 0.27118659019470215
## e[13]       loss.backward (sum) time: 3.9673025608062744
## e[13]      optimizer.step (sum) time: 1.8157215118408203
## epoch[13] training(only) time: 16.008363723754883
# Switched to evaluate mode...
Test: [  0/100]	Time  0.166 ( 0.166)	Loss 4.1055e-01 (4.1055e-01)	Acc@1  83.00 ( 83.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.024 ( 0.036)	Loss 6.5305e-01 (4.9847e-01)	Acc@1  82.00 ( 83.27)	Acc@5  99.00 ( 99.55)
Test: [ 20/100]	Time  0.021 ( 0.029)	Loss 5.9181e-01 (4.9108e-01)	Acc@1  80.00 ( 83.33)	Acc@5 100.00 ( 99.57)
Test: [ 30/100]	Time  0.018 ( 0.026)	Loss 5.2642e-01 (5.0364e-01)	Acc@1  80.00 ( 83.65)	Acc@5  99.00 ( 99.29)
Test: [ 40/100]	Time  0.023 ( 0.025)	Loss 5.4064e-01 (5.1288e-01)	Acc@1  86.00 ( 83.39)	Acc@5 100.00 ( 99.22)
Test: [ 50/100]	Time  0.022 ( 0.025)	Loss 4.1701e-01 (5.1088e-01)	Acc@1  83.00 ( 83.51)	Acc@5 100.00 ( 99.16)
Test: [ 60/100]	Time  0.020 ( 0.024)	Loss 4.4426e-01 (5.0681e-01)	Acc@1  88.00 ( 83.61)	Acc@5 100.00 ( 99.23)
Test: [ 70/100]	Time  0.018 ( 0.023)	Loss 6.5234e-01 (5.0295e-01)	Acc@1  77.00 ( 83.63)	Acc@5 100.00 ( 99.30)
Test: [ 80/100]	Time  0.018 ( 0.023)	Loss 3.8193e-01 (4.9794e-01)	Acc@1  81.00 ( 83.58)	Acc@5 100.00 ( 99.31)
Test: [ 90/100]	Time  0.022 ( 0.023)	Loss 3.2237e-01 (5.0174e-01)	Acc@1  88.00 ( 83.40)	Acc@5 100.00 ( 99.33)
 * Acc@1 83.410 Acc@5 99.280
### epoch[13] execution time: 18.413359880447388
EPOCH 14
i:   0, name:           module.stem.0.weight  changing lr from: 0.082614143440428292   to: 0.079901783211565186
i:   1, name:             module.stem.0.bias  changing lr from: 0.082864689291374818   to: 0.080186025214798784
i:   2, name:           module.stem.1.weight  changing lr from: 0.083111476173884258   to: 0.080466098085956131
i:   3, name:             module.stem.1.bias  changing lr from: 0.083354562003362179   to: 0.080742062936704939
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.083594003909340006   to: 0.081013980168980634
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.083829858238632454   to: 0.081281909471705494
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.084062180558957589   to: 0.081545909818286827
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.084291025662986657   to: 0.081806039464848157
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.084516447572792822   to: 0.082062355949149332
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.084738499544669499   to: 0.082314916090153789
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.084957234074290677   to: 0.082563775988203122
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.085172702902186648   to: 0.082808991025761280
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.085384957019510530   to: 0.083050615868692071
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.085594046674071958   to: 0.083288704468036157
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.085800021376615479   to: 0.083523310062254830
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.086002929907322834   to: 0.083754485179909743
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.086202820322518858   to: 0.083982281642749235
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.086399739961562638   to: 0.084206750569173525
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.086593735453905529   to: 0.084427942378052206
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.086784852726299683   to: 0.084645906792869041
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.086973137010141033   to: 0.084860692846170094
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.087158632848931744   to: 0.085072348884292978
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.087341384105848019   to: 0.085280922572355367
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.087521433971400053   to: 0.085486460899482808
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.087698824971171430   to: 0.085689010184256398
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.087873598973626219   to: 0.085888616080362357
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.088045797197972744   to: 0.086085323582425821
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.088215460222073452   to: 0.086279177032012988
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.088382627990391052   to: 0.086470220123785940
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.088547339821961890   to: 0.086658495911795447
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.088709634418387640   to: 0.086844046815898038
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.088869549871837317   to: 0.087026914628284324
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.089027123673052141   to: 0.087207140520106100
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.089182392719345860   to: 0.087384765048190663
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.089335393322593978   to: 0.087559828161831277
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.089486161217205928   to: 0.087732369209643529
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.089634731568073736   to: 0.087902426946477610
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.089781138978492658   to: 0.088070039540377454
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.089925417498047819   to: 0.088235244579578057
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.090067600630462846   to: 0.088398079079532621
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.090207721341405894   to: 0.088558579489962042
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.090345812066248907   to: 0.088716781701919600
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.090481904717776562   to: 0.088872721054863504
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.090616030693841457   to: 0.089026432343731809
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.090748220884962205   to: 0.089177949826012973
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.090878505681861510   to: 0.089327307228806802
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.091006914982941847   to: 0.089474537755870581
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.091133478201695803   to: 0.089619674094645385
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.091258224274049282   to: 0.089762748423257946
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.091381181665635233   to: 0.089903792417494091
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.091502378378996205   to: 0.090042837257739455
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.091621841960713976   to: 0.090179913635883888
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.091739599508464914   to: 0.090315051762186294
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.091855677677999570   to: 0.090448281372096442
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.091970102690045311   to: 0.090579631733031060
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.092082900337131166   to: 0.090709131651101199
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.092194095990333791   to: 0.090836809477788660
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.092303714605943887   to: 0.090962693116568960
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.092411780732052307   to: 0.091086810029478826
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.092518318515055320   to: 0.091209187243626214
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.092623351706078993   to: 0.091329851357641073
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.092726903667321559   to: 0.091448828548065353
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.092828997378314390   to: 0.091566144575680672
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.092929655442100773   to: 0.091681824791772296
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.093028900091332786   to: 0.091795894144328566
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.093126753194286205   to: 0.091908377184174175
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.093223236260793416   to: 0.092019298071037037
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.093318370448094531   to: 0.092128680579547179
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.093412176566607052   to: 0.092236548105167793
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.093504675085614108   to: 0.092342923670057017
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.093595886138871834   to: 0.092447829928860567
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.093685829530135975   to: 0.092551289174434448
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.093774524738608478   to: 0.092653323343497629
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.093861990924304278   to: 0.092753954022214119
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.093948246933338905   to: 0.092853202451704753
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.094033311303137357   to: 0.092951089533488074
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.094117202267564926   to: 0.093047635834850567
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.094199937761980504   to: 0.093142861594146309
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.094281535428213090   to: 0.093236786726025742
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.094362012619461977   to: 0.093329430826594270
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.094441386405121661   to: 0.093420813178500331
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.094519673575531704   to: 0.093510952755953544
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.094596890646652720   to: 0.093599868229672922
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.094673053864668982   to: 0.093687577971765787
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.094748179210518507   to: 0.093774100060537435
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.094822282404351310   to: 0.093859452285232167
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.094895378909916783   to: 0.093943652150705950
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.094967483938880881   to: 0.094026716882031333
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.095038612455073848   to: 0.094108663429034858
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.095108779178669584   to: 0.094189508470767846
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.095177998590297186   to: 0.094269268419910582
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.095246284935085690   to: 0.094347959427111106
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.095313652226642689   to: 0.094425597385258436
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.095380114250967957   to: 0.094502197933691579
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.095445684570302558   to: 0.094577776462344221
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.095510376526914575   to: 0.094652348115826457
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.095574203246822170   to: 0.094725927797443391
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.095637177643454918   to: 0.094798530173152096
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.095699312421254165   to: 0.094870169675456931
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.095760620079213252   to: 0.094940860507244179
i: 100, name:           module.conv10.weight  changing lr from: 0.095821112914358644   to: 0.095010616645556809
i: 101, name:             module.conv10.bias  changing lr from: 0.095880803025172628   to: 0.095079451845309693



# Switched to train mode...
Epoch: [14][  0/391]	Time  0.210 ( 0.210)	Data  0.166 ( 0.166)	Loss 4.7155e-01 (4.7155e-01)	Acc@1  83.59 ( 83.59)	Acc@5 100.00 (100.00)
Epoch: [14][ 10/391]	Time  0.041 ( 0.057)	Data  0.001 ( 0.016)	Loss 4.4993e-01 (4.2055e-01)	Acc@1  85.94 ( 86.36)	Acc@5 100.00 ( 99.50)
Epoch: [14][ 20/391]	Time  0.042 ( 0.049)	Data  0.001 ( 0.009)	Loss 3.8494e-01 (4.0708e-01)	Acc@1  83.59 ( 86.35)	Acc@5 100.00 ( 99.52)
Epoch: [14][ 30/391]	Time  0.041 ( 0.046)	Data  0.001 ( 0.006)	Loss 3.7515e-01 (4.0717e-01)	Acc@1  82.03 ( 86.01)	Acc@5 100.00 ( 99.47)
Epoch: [14][ 40/391]	Time  0.038 ( 0.045)	Data  0.001 ( 0.005)	Loss 5.1312e-01 (4.1488e-01)	Acc@1  81.25 ( 85.79)	Acc@5  99.22 ( 99.52)
Epoch: [14][ 50/391]	Time  0.040 ( 0.044)	Data  0.002 ( 0.004)	Loss 4.3905e-01 (4.1723e-01)	Acc@1  81.25 ( 85.66)	Acc@5 100.00 ( 99.51)
Epoch: [14][ 60/391]	Time  0.042 ( 0.044)	Data  0.001 ( 0.004)	Loss 5.5427e-01 (4.2432e-01)	Acc@1  78.12 ( 85.41)	Acc@5 100.00 ( 99.51)
Epoch: [14][ 70/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.003)	Loss 3.9077e-01 (4.2554e-01)	Acc@1  86.72 ( 85.42)	Acc@5 100.00 ( 99.53)
Epoch: [14][ 80/391]	Time  0.038 ( 0.043)	Data  0.001 ( 0.003)	Loss 4.5873e-01 (4.2756e-01)	Acc@1  82.03 ( 85.30)	Acc@5  99.22 ( 99.52)
Epoch: [14][ 90/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.003)	Loss 3.5983e-01 (4.2267e-01)	Acc@1  88.28 ( 85.45)	Acc@5 100.00 ( 99.53)
Epoch: [14][100/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.003)	Loss 3.0048e-01 (4.2205e-01)	Acc@1  88.28 ( 85.47)	Acc@5 100.00 ( 99.53)
Epoch: [14][110/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 3.3541e-01 (4.2096e-01)	Acc@1  88.28 ( 85.53)	Acc@5 100.00 ( 99.51)
Epoch: [14][120/391]	Time  0.036 ( 0.042)	Data  0.001 ( 0.002)	Loss 3.6327e-01 (4.1828e-01)	Acc@1  89.84 ( 85.61)	Acc@5 100.00 ( 99.53)
Epoch: [14][130/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.1169e-01 (4.1783e-01)	Acc@1  82.03 ( 85.62)	Acc@5  98.44 ( 99.53)
Epoch: [14][140/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.5236e-01 (4.1633e-01)	Acc@1  84.38 ( 85.65)	Acc@5  99.22 ( 99.51)
Epoch: [14][150/391]	Time  0.043 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.6192e-01 (4.1441e-01)	Acc@1  85.94 ( 85.66)	Acc@5 100.00 ( 99.52)
Epoch: [14][160/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.3750e-01 (4.1541e-01)	Acc@1  82.81 ( 85.65)	Acc@5 100.00 ( 99.49)
Epoch: [14][170/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.8378e-01 (4.1449e-01)	Acc@1  82.81 ( 85.62)	Acc@5  99.22 ( 99.50)
Epoch: [14][180/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.3111e-01 (4.1363e-01)	Acc@1  85.16 ( 85.64)	Acc@5  99.22 ( 99.48)
Epoch: [14][190/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.6598e-01 (4.1218e-01)	Acc@1  90.62 ( 85.68)	Acc@5 100.00 ( 99.49)
Epoch: [14][200/391]	Time  0.036 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.9450e-01 (4.1198e-01)	Acc@1  89.06 ( 85.69)	Acc@5 100.00 ( 99.49)
Epoch: [14][210/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.0363e-01 (4.1066e-01)	Acc@1  89.06 ( 85.76)	Acc@5 100.00 ( 99.49)
Epoch: [14][220/391]	Time  0.045 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.5822e-01 (4.0932e-01)	Acc@1  87.50 ( 85.82)	Acc@5  99.22 ( 99.48)
Epoch: [14][230/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.9275e-01 (4.1047e-01)	Acc@1  84.38 ( 85.80)	Acc@5  99.22 ( 99.48)
Epoch: [14][240/391]	Time  0.039 ( 0.041)	Data  0.002 ( 0.002)	Loss 4.1960e-01 (4.1172e-01)	Acc@1  87.50 ( 85.75)	Acc@5  99.22 ( 99.48)
Epoch: [14][250/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.4855e-01 (4.1131e-01)	Acc@1  84.38 ( 85.78)	Acc@5  99.22 ( 99.49)
Epoch: [14][260/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.1405e-01 (4.0989e-01)	Acc@1  85.94 ( 85.81)	Acc@5  97.66 ( 99.49)
Epoch: [14][270/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.4662e-01 (4.0982e-01)	Acc@1  82.03 ( 85.84)	Acc@5 100.00 ( 99.50)
Epoch: [14][280/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.7615e-01 (4.1040e-01)	Acc@1  85.16 ( 85.80)	Acc@5  99.22 ( 99.50)
Epoch: [14][290/391]	Time  0.040 ( 0.041)	Data  0.002 ( 0.002)	Loss 4.0643e-01 (4.1020e-01)	Acc@1  86.72 ( 85.85)	Acc@5  97.66 ( 99.49)
Epoch: [14][300/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.4415e-01 (4.1109e-01)	Acc@1  87.50 ( 85.82)	Acc@5 100.00 ( 99.49)
Epoch: [14][310/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.4979e-01 (4.1235e-01)	Acc@1  82.81 ( 85.74)	Acc@5  99.22 ( 99.50)
Epoch: [14][320/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.6808e-01 (4.1293e-01)	Acc@1  82.03 ( 85.71)	Acc@5  99.22 ( 99.50)
Epoch: [14][330/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.0641e-01 (4.1240e-01)	Acc@1  79.69 ( 85.75)	Acc@5  99.22 ( 99.49)
Epoch: [14][340/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.2590e-01 (4.1286e-01)	Acc@1  85.16 ( 85.75)	Acc@5 100.00 ( 99.49)
Epoch: [14][350/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.2926e-01 (4.1348e-01)	Acc@1  85.16 ( 85.73)	Acc@5  99.22 ( 99.49)
Epoch: [14][360/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.001)	Loss 3.3274e-01 (4.1281e-01)	Acc@1  88.28 ( 85.75)	Acc@5  99.22 ( 99.49)
Epoch: [14][370/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.001)	Loss 5.4343e-01 (4.1221e-01)	Acc@1  84.38 ( 85.79)	Acc@5 100.00 ( 99.49)
Epoch: [14][380/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.001)	Loss 3.1829e-01 (4.1167e-01)	Acc@1  90.62 ( 85.82)	Acc@5 100.00 ( 99.49)
Epoch: [14][390/391]	Time  0.027 ( 0.041)	Data  0.001 ( 0.001)	Loss 5.1751e-01 (4.1170e-01)	Acc@1  76.25 ( 85.82)	Acc@5 100.00 ( 99.49)
## e[14] optimizer.zero_grad (sum) time: 0.27220582962036133
## e[14]       loss.backward (sum) time: 4.018619060516357
## e[14]      optimizer.step (sum) time: 1.8252615928649902
## epoch[14] training(only) time: 16.023128986358643
# Switched to evaluate mode...
Test: [  0/100]	Time  0.171 ( 0.171)	Loss 5.3379e-01 (5.3379e-01)	Acc@1  84.00 ( 84.00)	Acc@5  99.00 ( 99.00)
Test: [ 10/100]	Time  0.021 ( 0.035)	Loss 5.5231e-01 (5.6795e-01)	Acc@1  85.00 ( 83.27)	Acc@5 100.00 ( 99.18)
Test: [ 20/100]	Time  0.024 ( 0.028)	Loss 6.0785e-01 (5.6666e-01)	Acc@1  79.00 ( 82.10)	Acc@5 100.00 ( 99.10)
Test: [ 30/100]	Time  0.018 ( 0.026)	Loss 5.9724e-01 (5.8899e-01)	Acc@1  79.00 ( 81.48)	Acc@5  99.00 ( 98.90)
Test: [ 40/100]	Time  0.017 ( 0.025)	Loss 6.1555e-01 (6.0428e-01)	Acc@1  84.00 ( 80.98)	Acc@5  99.00 ( 98.80)
Test: [ 50/100]	Time  0.023 ( 0.024)	Loss 5.0088e-01 (5.8467e-01)	Acc@1  81.00 ( 81.41)	Acc@5  98.00 ( 98.82)
Test: [ 60/100]	Time  0.017 ( 0.023)	Loss 5.2753e-01 (5.8099e-01)	Acc@1  81.00 ( 81.38)	Acc@5 100.00 ( 98.89)
Test: [ 70/100]	Time  0.018 ( 0.023)	Loss 5.0276e-01 (5.7329e-01)	Acc@1  78.00 ( 81.41)	Acc@5 100.00 ( 98.96)
Test: [ 80/100]	Time  0.024 ( 0.022)	Loss 4.7909e-01 (5.7201e-01)	Acc@1  81.00 ( 81.51)	Acc@5  99.00 ( 98.94)
Test: [ 90/100]	Time  0.017 ( 0.022)	Loss 5.8139e-01 (5.7259e-01)	Acc@1  81.00 ( 81.54)	Acc@5  99.00 ( 98.90)
 * Acc@1 81.530 Acc@5 98.930
### epoch[14] execution time: 18.32036542892456
EPOCH 15
i:   0, name:           module.stem.0.weight  changing lr from: 0.079901783211565186   to: 0.077055136834451199
i:   1, name:             module.stem.0.bias  changing lr from: 0.080186025214798784   to: 0.077373730785511671
i:   2, name:           module.stem.1.weight  changing lr from: 0.080466098085956131   to: 0.077687768905474908
i:   3, name:             module.stem.1.bias  changing lr from: 0.080742062936704939   to: 0.077997314093096848
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.081013980168980634   to: 0.078302428670792554
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.081281909471705494   to: 0.078603174372825185
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.081545909818286827   to: 0.078899612334662209
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.081806039464848157   to: 0.079191803083436721
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.082062355949149332   to: 0.079479806529454702
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.082314916090153789   to: 0.079763681958691837
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.082563775988203122   to: 0.080043488026225934
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.082808991025761280   to: 0.080319282750553889
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.083050615868692071   to: 0.080591123508743714
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.083288704468036157   to: 0.080859067032375415
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.083523310062254830   to: 0.081123169404225773
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.083754485179909743   to: 0.081383486055654986
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.083982281642749235   to: 0.081640071764654362
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.084206750569173525   to: 0.081892980654516737
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.084427942378052206   to: 0.082142266193092936
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.084645906792869041   to: 0.082387981192599186
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.084860692846170094   to: 0.082630177809942168
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.085072348884292978   to: 0.082868907547530346
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.085280922572355367   to: 0.083104221254540922
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.085486460899482808   to: 0.083336169128614149
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.085689010184256398   to: 0.083564800717947474
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.085888616080362357   to: 0.083790164923763524
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.086085323582425821   to: 0.084012310003127477
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.086279177032012988   to: 0.084231283572090046
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.086470220123785940   to: 0.084447132609134015
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.086658495911795447   to: 0.084659903458902896
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.086844046815898038   to: 0.084869641836191889
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.087026914628284324   to: 0.085076392830181674
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.087207140520106100   to: 0.085280200908897139
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.087384765048190663   to: 0.085481109923873699
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.087559828161831277   to: 0.085679163115014986
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.087732369209643529   to: 0.085874403115626066
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.087902426946477610   to: 0.086066871957608079
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.088070039540377454   to: 0.086256611076799702
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.088235244579578057   to: 0.086443661318452811
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.088398079079532621   to: 0.086628062942829376
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.088558579489962042   to: 0.086809855630908095
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.088716781701919600   to: 0.086989078490189400
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.088872721054863504   to: 0.087165770060588232
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.089026432343731809   to: 0.087339968320404582
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.089177949826012973   to: 0.087511710692362438
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.089327307228806802   to: 0.087681034049708007
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.089474537755870581   to: 0.087847974722358793
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.089619674094645385   to: 0.088012568503095856
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.089762748423257946   to: 0.088174850653791159
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.089903792417494091   to: 0.088334855911663554
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.090042837257739455   to: 0.088492618495556188
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.090179913635883888   to: 0.088648172112229459
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.090315051762186294   to: 0.088801549962663262
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.090448281372096442   to: 0.088952784748363295
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.090579631733031060   to: 0.089101908677665931
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.090709131651101199   to: 0.089248953472036902
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.090836809477788660   to: 0.089393950372359088
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.090962693116568960   to: 0.089536930145205418
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.091086810029478826   to: 0.089677923089092199
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.091209187243626214   to: 0.089816959040709993
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.091329851357641073   to: 0.089954067381127711
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.091448828548065353   to: 0.090089277041967092
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.091566144575680672   to: 0.090222616511544507
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.091681824791772296   to: 0.090354113840976941
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.091795894144328566   to: 0.090483796650249915
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.091908377184174175   to: 0.090611692134244609
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.092019298071037037   to: 0.090737827068721980
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.092128680579547179   to: 0.090862227816261951
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.092236548105167793   to: 0.090984920332155481
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.092342923670057017   to: 0.091105930170247984
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.092447829928860567   to: 0.091225282488732351
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.092551289174434448   to: 0.091343002055890077
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.092653323343497629   to: 0.091459113255779254
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.092753954022214119   to: 0.091573640093868092
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.092853202451704753   to: 0.091686606202612916
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.092951089533488074   to: 0.091798034846979668
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.093047635834850567   to: 0.091907948929908001
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.093142861594146309   to: 0.092016370997717145
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.093236786726025742   to: 0.092123323245452943
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.093329430826594270   to: 0.092228827522175413
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.093420813178500331   to: 0.092332905336186225
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.093510952755953544   to: 0.092435577860195864
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.093599868229672922   to: 0.092536865936429957
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.093687577971765787   to: 0.092636790081674553
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.093774100060537435   to: 0.092735370492259953
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.093859452285232167   to: 0.092832627048983374
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.093943652150705950   to: 0.092928579321969754
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.094026716882031333   to: 0.093023246575471147
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.094108663429034858   to: 0.093116647772604449
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.094189508470767846   to: 0.093208801580027631
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.094269268419910582   to: 0.093299726372554445
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.094347959427111106   to: 0.093389440237707996
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.094425597385258436   to: 0.093477960980213104
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.094502197933691579   to: 0.093565306126427758
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.094577776462344221   to: 0.093651492928714095
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.094652348115826457   to: 0.093736538369748934
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.094725927797443391   to: 0.093820459166774353
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.094798530173152096   to: 0.093903271775788597
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.094870169675456931   to: 0.093984992395677744
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.094940860507244179   to: 0.094065636972288494
i: 100, name:           module.conv10.weight  changing lr from: 0.095010616645556809   to: 0.094145221202442508
i: 101, name:             module.conv10.bias  changing lr from: 0.095079451845309693   to: 0.094223760537892665



# Switched to train mode...
Epoch: [15][  0/391]	Time  0.213 ( 0.213)	Data  0.169 ( 0.169)	Loss 2.7871e-01 (2.7871e-01)	Acc@1  87.50 ( 87.50)	Acc@5 100.00 (100.00)
Epoch: [15][ 10/391]	Time  0.039 ( 0.056)	Data  0.001 ( 0.016)	Loss 2.7575e-01 (3.6568e-01)	Acc@1  90.62 ( 87.14)	Acc@5  99.22 ( 99.64)
Epoch: [15][ 20/391]	Time  0.037 ( 0.049)	Data  0.001 ( 0.009)	Loss 3.1452e-01 (3.7654e-01)	Acc@1  88.28 ( 87.02)	Acc@5  99.22 ( 99.52)
Epoch: [15][ 30/391]	Time  0.044 ( 0.046)	Data  0.001 ( 0.006)	Loss 4.5941e-01 (3.8915e-01)	Acc@1  84.38 ( 86.59)	Acc@5  98.44 ( 99.52)
Epoch: [15][ 40/391]	Time  0.038 ( 0.044)	Data  0.001 ( 0.005)	Loss 3.4547e-01 (3.8569e-01)	Acc@1  87.50 ( 86.55)	Acc@5 100.00 ( 99.62)
Epoch: [15][ 50/391]	Time  0.038 ( 0.043)	Data  0.001 ( 0.004)	Loss 3.7573e-01 (3.8547e-01)	Acc@1  86.72 ( 86.49)	Acc@5 100.00 ( 99.59)
Epoch: [15][ 60/391]	Time  0.038 ( 0.043)	Data  0.001 ( 0.004)	Loss 3.6257e-01 (3.8085e-01)	Acc@1  88.28 ( 86.69)	Acc@5 100.00 ( 99.56)
Epoch: [15][ 70/391]	Time  0.035 ( 0.042)	Data  0.001 ( 0.003)	Loss 3.6571e-01 (3.7948e-01)	Acc@1  83.59 ( 86.72)	Acc@5 100.00 ( 99.55)
Epoch: [15][ 80/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.003)	Loss 4.9722e-01 (3.7859e-01)	Acc@1  82.03 ( 86.81)	Acc@5  97.66 ( 99.50)
Epoch: [15][ 90/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.003)	Loss 3.7569e-01 (3.8248e-01)	Acc@1  85.94 ( 86.60)	Acc@5  99.22 ( 99.49)
Epoch: [15][100/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.003)	Loss 3.8039e-01 (3.8857e-01)	Acc@1  86.72 ( 86.42)	Acc@5  99.22 ( 99.48)
Epoch: [15][110/391]	Time  0.051 ( 0.042)	Data  0.001 ( 0.003)	Loss 4.2666e-01 (3.9007e-01)	Acc@1  88.28 ( 86.39)	Acc@5  99.22 ( 99.46)
Epoch: [15][120/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 4.6082e-01 (3.9023e-01)	Acc@1  86.72 ( 86.49)	Acc@5 100.00 ( 99.46)
Epoch: [15][130/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 6.5469e-01 (3.9265e-01)	Acc@1  79.69 ( 86.44)	Acc@5  98.44 ( 99.45)
Epoch: [15][140/391]	Time  0.043 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.5006e-01 (3.9225e-01)	Acc@1  89.06 ( 86.43)	Acc@5 100.00 ( 99.48)
Epoch: [15][150/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.1488e-01 (3.9307e-01)	Acc@1  87.50 ( 86.38)	Acc@5 100.00 ( 99.47)
Epoch: [15][160/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.9192e-01 (3.9326e-01)	Acc@1  83.59 ( 86.37)	Acc@5  99.22 ( 99.46)
Epoch: [15][170/391]	Time  0.037 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.3579e-01 (3.9282e-01)	Acc@1  84.38 ( 86.42)	Acc@5 100.00 ( 99.47)
Epoch: [15][180/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.6064e-01 (3.9232e-01)	Acc@1  82.81 ( 86.48)	Acc@5  98.44 ( 99.47)
Epoch: [15][190/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.2309e-01 (3.8984e-01)	Acc@1  87.50 ( 86.52)	Acc@5  99.22 ( 99.48)
Epoch: [15][200/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.0671e-01 (3.8832e-01)	Acc@1  85.16 ( 86.54)	Acc@5  99.22 ( 99.50)
Epoch: [15][210/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.4025e-01 (3.8806e-01)	Acc@1  86.72 ( 86.60)	Acc@5 100.00 ( 99.49)
Epoch: [15][220/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.2525e-01 (3.8820e-01)	Acc@1  87.50 ( 86.57)	Acc@5 100.00 ( 99.49)
Epoch: [15][230/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.2788e-01 (3.8711e-01)	Acc@1  86.72 ( 86.62)	Acc@5  99.22 ( 99.49)
Epoch: [15][240/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.4739e-01 (3.8790e-01)	Acc@1  83.59 ( 86.61)	Acc@5  99.22 ( 99.47)
Epoch: [15][250/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.7241e-01 (3.8701e-01)	Acc@1  89.06 ( 86.66)	Acc@5  99.22 ( 99.47)
Epoch: [15][260/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.1915e-01 (3.8759e-01)	Acc@1  79.69 ( 86.64)	Acc@5  98.44 ( 99.48)
Epoch: [15][270/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.2472e-01 (3.8765e-01)	Acc@1  82.03 ( 86.63)	Acc@5  99.22 ( 99.46)
Epoch: [15][280/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.2294e-01 (3.8774e-01)	Acc@1  89.84 ( 86.60)	Acc@5  99.22 ( 99.46)
Epoch: [15][290/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.4831e-01 (3.8850e-01)	Acc@1  90.62 ( 86.58)	Acc@5 100.00 ( 99.46)
Epoch: [15][300/391]	Time  0.037 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.7793e-01 (3.8962e-01)	Acc@1  88.28 ( 86.52)	Acc@5 100.00 ( 99.48)
Epoch: [15][310/391]	Time  0.036 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.7816e-01 (3.8946e-01)	Acc@1  82.81 ( 86.51)	Acc@5 100.00 ( 99.48)
Epoch: [15][320/391]	Time  0.036 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.7899e-01 (3.8994e-01)	Acc@1  89.84 ( 86.48)	Acc@5 100.00 ( 99.48)
Epoch: [15][330/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.4983e-01 (3.9001e-01)	Acc@1  89.84 ( 86.49)	Acc@5  99.22 ( 99.49)
Epoch: [15][340/391]	Time  0.045 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.6403e-01 (3.9107e-01)	Acc@1  85.94 ( 86.45)	Acc@5  99.22 ( 99.49)
Epoch: [15][350/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.001)	Loss 3.9093e-01 (3.9109e-01)	Acc@1  85.16 ( 86.46)	Acc@5 100.00 ( 99.50)
Epoch: [15][360/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.001)	Loss 4.2981e-01 (3.9202e-01)	Acc@1  85.94 ( 86.45)	Acc@5 100.00 ( 99.50)
Epoch: [15][370/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.001)	Loss 4.2447e-01 (3.9283e-01)	Acc@1  82.81 ( 86.42)	Acc@5  99.22 ( 99.50)
Epoch: [15][380/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.001)	Loss 3.5192e-01 (3.9337e-01)	Acc@1  88.28 ( 86.41)	Acc@5 100.00 ( 99.50)
Epoch: [15][390/391]	Time  0.028 ( 0.041)	Data  0.001 ( 0.001)	Loss 4.7928e-01 (3.9404e-01)	Acc@1  78.75 ( 86.37)	Acc@5  98.75 ( 99.49)
## e[15] optimizer.zero_grad (sum) time: 0.27162933349609375
## e[15]       loss.backward (sum) time: 3.9583652019500732
## e[15]      optimizer.step (sum) time: 1.8503234386444092
## epoch[15] training(only) time: 16.005361795425415
# Switched to evaluate mode...
Test: [  0/100]	Time  0.179 ( 0.179)	Loss 6.2757e-01 (6.2757e-01)	Acc@1  78.00 ( 78.00)	Acc@5  98.00 ( 98.00)
Test: [ 10/100]	Time  0.022 ( 0.034)	Loss 6.3841e-01 (5.5777e-01)	Acc@1  80.00 ( 80.91)	Acc@5 100.00 ( 99.18)
Test: [ 20/100]	Time  0.025 ( 0.027)	Loss 5.3887e-01 (5.4327e-01)	Acc@1  83.00 ( 81.38)	Acc@5 100.00 ( 99.29)
Test: [ 30/100]	Time  0.022 ( 0.025)	Loss 5.8507e-01 (5.4258e-01)	Acc@1  79.00 ( 81.77)	Acc@5  99.00 ( 99.19)
Test: [ 40/100]	Time  0.021 ( 0.024)	Loss 5.0850e-01 (5.4088e-01)	Acc@1  84.00 ( 81.71)	Acc@5  99.00 ( 99.17)
Test: [ 50/100]	Time  0.019 ( 0.023)	Loss 4.3450e-01 (5.3685e-01)	Acc@1  83.00 ( 81.88)	Acc@5  99.00 ( 99.24)
Test: [ 60/100]	Time  0.018 ( 0.023)	Loss 4.4675e-01 (5.3393e-01)	Acc@1  83.00 ( 82.00)	Acc@5  99.00 ( 99.21)
Test: [ 70/100]	Time  0.024 ( 0.023)	Loss 6.3398e-01 (5.3350e-01)	Acc@1  76.00 ( 82.01)	Acc@5 100.00 ( 99.25)
Test: [ 80/100]	Time  0.022 ( 0.023)	Loss 3.2615e-01 (5.3007e-01)	Acc@1  90.00 ( 82.30)	Acc@5 100.00 ( 99.28)
Test: [ 90/100]	Time  0.016 ( 0.023)	Loss 3.3768e-01 (5.3422e-01)	Acc@1  88.00 ( 82.29)	Acc@5 100.00 ( 99.32)
 * Acc@1 82.390 Acc@5 99.340
### epoch[15] execution time: 18.336888313293457
EPOCH 16
i:   0, name:           module.stem.0.weight  changing lr from: 0.077055136834451199   to: 0.074087430661751719
i:   1, name:             module.stem.0.bias  changing lr from: 0.077373730785511671   to: 0.074440682299403246
i:   2, name:           module.stem.1.weight  changing lr from: 0.077687768905474908   to: 0.074789024459170600
i:   3, name:             module.stem.1.bias  changing lr from: 0.077997314093096848   to: 0.075132520154611429
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.078302428670792554   to: 0.075471232020374396
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.078603174372825185   to: 0.075805222289630700
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.078899612334662209   to: 0.076134552773131484
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.079191803083436721   to: 0.076459284839811639
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.079479806529454702   to: 0.076779479398863815
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.079763681958691837   to: 0.077095196883209413
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.080043488026225934   to: 0.077406497234297586
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.080319282750553889   to: 0.077713439888164842
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.080591123508743714   to: 0.078016083762691965
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.080859067032375415   to: 0.078314487245997252
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.081123169404225773   to: 0.078608708185907511
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.081383486055654986   to: 0.078898803880451784
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.081640071764654362   to: 0.079184831069323822
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.081892980654516737   to: 0.079466845926263241
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.082142266193092936   to: 0.079744904052306359
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.082387981192599186   to: 0.080019060469860459
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.082630177809942168   to: 0.080289369617557366
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.082868907547530346   to: 0.080555885345843903
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.083104221254540922   to: 0.080818660913269044
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.083336169128614149   to: 0.081077748983429204
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.083564800717947474   to: 0.081333201622534976
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.083790164923763524   to: 0.081585070297564261
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.084012310003127477   to: 0.081833405874968346
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.084231283572090046   to: 0.082078258619899258
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.084447132609134015   to: 0.082319678195927865
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.084659903458902896   to: 0.082557713665223631
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.084869641836191889   to: 0.082792413489168729
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.085076392830181674   to: 0.083023825529380216
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.085280200908897139   to: 0.083251997049114845
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.085481109923873699   to: 0.083476974715033000
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.085679163115014986   to: 0.083698804599299195
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.085874403115626066   to: 0.083917532181996934
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.086066871957608079   to: 0.084133202353837921
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.086256611076799702   to: 0.084345859419145741
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.086443661318452811   to: 0.084555547099095574
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.086628062942829376   to: 0.084762308535191955
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.086809855630908095   to: 0.084966186292968066
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.086989078490189400   to: 0.085167222365890305
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.087165770060588232   to: 0.085365458179452944
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.087339968320404582   to: 0.085560934595448668
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.087511710692362438   to: 0.085753691916400948
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.087681034049708007   to: 0.085943769890145294
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.087847974722358793   to: 0.086131207714547242
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.088012568503095856   to: 0.086316044042345080
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.088174850653791159   to: 0.086498316986106299
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.088334855911663554   to: 0.086678064123287199
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.088492618495556188   to: 0.086855322501385612
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.088648172112229459   to: 0.087030128643177385
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.088801549962663262   to: 0.087202518552027444
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.088952784748363295   to: 0.087372527717267251
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.089101908677665931   to: 0.087540191119630253
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.089248953472036902   to: 0.087705543236737959
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.089393950372359088   to: 0.087868618048629513
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.089536930145205418   to: 0.088029449043327712
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.089677923089092199   to: 0.088188069222435383
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.089816959040709993   to: 0.088344511106755674
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.089954067381127711   to: 0.088498806741931113
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.090089277041967092   to: 0.088650987704095435
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.090222616511544507   to: 0.088801085105533528
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.090354113840976941   to: 0.088949129600344734
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.090483796650249915   to: 0.089095151390104627
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.090611692134244609   to: 0.089239180229521556
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.090737827068721980   to: 0.089381245432083756
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.090862227816261951   to: 0.089521375875693143
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.090984920332155481   to: 0.089659600008282755
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.091105930170247984   to: 0.089795945853414133
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.091225282488732351   to: 0.089930441015851861
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.091343002055890077   to: 0.090063112687112368
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.091459113255779254   to: 0.090193987650984242
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.091573640093868092   to: 0.090323092289017790
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.091686606202612916   to: 0.090450452585981223
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.091798034846979668   to: 0.090576094135281740
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.091907948929908001   to: 0.090700042144349069
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.092016370997717145   to: 0.090822321439980036
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.092123323245452943   to: 0.090942956473642270
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.092228827522175413   to: 0.091061971326735491
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.092332905336186225   to: 0.091179389715808842
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.092435577860195864   to: 0.091295234997733454
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.092536865936429957   to: 0.091409530174828169
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.092636790081674553   to: 0.091522297899938307
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.092735370492259953   to: 0.091633560481465606
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.092832627048983374   to: 0.091743339888349151
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.092928579321969754   to: 0.091851657754996069
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.093023246575471147   to: 0.091958535386161333
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.093116647772604449   to: 0.092063993761776153
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.093208801580027631   to: 0.092168053541724485
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.093299726372554445   to: 0.092270735070566823
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.093389440237707996   to: 0.092372058382211200
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.093477960980213104   to: 0.092472043204530951
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.093565306126427758   to: 0.092570708963928855
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.093651492928714095   to: 0.092668074789847676
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.093736538369748934   to: 0.092764159519226522
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.093820459166774353   to: 0.092858981700903398
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.093903271775788597   to: 0.092952559599963500
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.093984992395677744   to: 0.093044911202033412
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.094065636972288494   to: 0.093136054217521150
i: 100, name:           module.conv10.weight  changing lr from: 0.094145221202442508   to: 0.093226006085802171
i: 101, name:             module.conv10.bias  changing lr from: 0.094223760537892665   to: 0.093314783979351362



# Switched to train mode...
Epoch: [16][  0/391]	Time  0.213 ( 0.213)	Data  0.171 ( 0.171)	Loss 4.5160e-01 (4.5160e-01)	Acc@1  80.47 ( 80.47)	Acc@5  99.22 ( 99.22)
Epoch: [16][ 10/391]	Time  0.040 ( 0.057)	Data  0.001 ( 0.016)	Loss 4.5865e-01 (3.5258e-01)	Acc@1  85.16 ( 87.57)	Acc@5  99.22 ( 99.36)
Epoch: [16][ 20/391]	Time  0.039 ( 0.049)	Data  0.001 ( 0.009)	Loss 3.0456e-01 (3.5817e-01)	Acc@1  85.94 ( 86.94)	Acc@5 100.00 ( 99.63)
Epoch: [16][ 30/391]	Time  0.043 ( 0.046)	Data  0.001 ( 0.006)	Loss 3.5393e-01 (3.6342e-01)	Acc@1  88.28 ( 86.97)	Acc@5 100.00 ( 99.62)
Epoch: [16][ 40/391]	Time  0.039 ( 0.045)	Data  0.001 ( 0.005)	Loss 3.7519e-01 (3.6633e-01)	Acc@1  88.28 ( 87.10)	Acc@5  99.22 ( 99.62)
Epoch: [16][ 50/391]	Time  0.041 ( 0.044)	Data  0.001 ( 0.004)	Loss 4.2044e-01 (3.7189e-01)	Acc@1  86.72 ( 86.95)	Acc@5  99.22 ( 99.57)
Epoch: [16][ 60/391]	Time  0.041 ( 0.044)	Data  0.001 ( 0.004)	Loss 4.9347e-01 (3.8184e-01)	Acc@1  84.38 ( 86.69)	Acc@5  99.22 ( 99.56)
Epoch: [16][ 70/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.003)	Loss 5.6174e-01 (3.9005e-01)	Acc@1  79.69 ( 86.44)	Acc@5  99.22 ( 99.57)
Epoch: [16][ 80/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.003)	Loss 3.2440e-01 (3.8821e-01)	Acc@1  86.72 ( 86.40)	Acc@5 100.00 ( 99.59)
Epoch: [16][ 90/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.003)	Loss 4.6064e-01 (3.9215e-01)	Acc@1  84.38 ( 86.33)	Acc@5  99.22 ( 99.55)
Epoch: [16][100/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.003)	Loss 4.5122e-01 (3.9096e-01)	Acc@1  82.81 ( 86.46)	Acc@5  99.22 ( 99.55)
Epoch: [16][110/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 3.3630e-01 (3.8748e-01)	Acc@1  90.62 ( 86.57)	Acc@5 100.00 ( 99.56)
Epoch: [16][120/391]	Time  0.037 ( 0.042)	Data  0.001 ( 0.002)	Loss 4.1477e-01 (3.8871e-01)	Acc@1  85.94 ( 86.51)	Acc@5  99.22 ( 99.53)
Epoch: [16][130/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 5.0235e-01 (3.9092e-01)	Acc@1  81.25 ( 86.44)	Acc@5 100.00 ( 99.52)
Epoch: [16][140/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.9924e-01 (3.8901e-01)	Acc@1  90.62 ( 86.53)	Acc@5 100.00 ( 99.52)
Epoch: [16][150/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 3.6583e-01 (3.8614e-01)	Acc@1  88.28 ( 86.63)	Acc@5  99.22 ( 99.54)
Epoch: [16][160/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 4.6192e-01 (3.8663e-01)	Acc@1  83.59 ( 86.60)	Acc@5  99.22 ( 99.53)
Epoch: [16][170/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.2251e-01 (3.8641e-01)	Acc@1  89.06 ( 86.63)	Acc@5 100.00 ( 99.53)
Epoch: [16][180/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.5942e-01 (3.8370e-01)	Acc@1  87.50 ( 86.73)	Acc@5  99.22 ( 99.54)
Epoch: [16][190/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.1895e-01 (3.8249e-01)	Acc@1  89.84 ( 86.77)	Acc@5 100.00 ( 99.53)
Epoch: [16][200/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.4021e-01 (3.8233e-01)	Acc@1  83.59 ( 86.75)	Acc@5  99.22 ( 99.54)
Epoch: [16][210/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.6010e-01 (3.8557e-01)	Acc@1  84.38 ( 86.62)	Acc@5  99.22 ( 99.52)
Epoch: [16][220/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.8981e-01 (3.8726e-01)	Acc@1  82.81 ( 86.54)	Acc@5  99.22 ( 99.52)
Epoch: [16][230/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.3793e-01 (3.8724e-01)	Acc@1  88.28 ( 86.53)	Acc@5 100.00 ( 99.52)
Epoch: [16][240/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.0201e-01 (3.8759e-01)	Acc@1  84.38 ( 86.53)	Acc@5 100.00 ( 99.52)
Epoch: [16][250/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.6544e-01 (3.8516e-01)	Acc@1  88.28 ( 86.61)	Acc@5 100.00 ( 99.54)
Epoch: [16][260/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.6837e-01 (3.8487e-01)	Acc@1  84.38 ( 86.62)	Acc@5  99.22 ( 99.54)
Epoch: [16][270/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.5061e-01 (3.8624e-01)	Acc@1  86.72 ( 86.57)	Acc@5 100.00 ( 99.52)
Epoch: [16][280/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.9824e-01 (3.8780e-01)	Acc@1  86.72 ( 86.50)	Acc@5 100.00 ( 99.51)
Epoch: [16][290/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 6.6399e-01 (3.8858e-01)	Acc@1  74.22 ( 86.47)	Acc@5  99.22 ( 99.50)
Epoch: [16][300/391]	Time  0.043 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.6170e-01 (3.8845e-01)	Acc@1  92.19 ( 86.47)	Acc@5 100.00 ( 99.51)
Epoch: [16][310/391]	Time  0.044 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.0981e-01 (3.8928e-01)	Acc@1  83.59 ( 86.44)	Acc@5  99.22 ( 99.52)
Epoch: [16][320/391]	Time  0.043 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.6234e-01 (3.8948e-01)	Acc@1  90.62 ( 86.41)	Acc@5 100.00 ( 99.52)
Epoch: [16][330/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.001)	Loss 4.8895e-01 (3.8956e-01)	Acc@1  81.25 ( 86.43)	Acc@5  97.66 ( 99.51)
Epoch: [16][340/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.001)	Loss 2.8066e-01 (3.9037e-01)	Acc@1  92.19 ( 86.40)	Acc@5 100.00 ( 99.50)
Epoch: [16][350/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.001)	Loss 4.1208e-01 (3.8973e-01)	Acc@1  83.59 ( 86.40)	Acc@5  99.22 ( 99.50)
Epoch: [16][360/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.001)	Loss 3.8781e-01 (3.8869e-01)	Acc@1  85.94 ( 86.43)	Acc@5  99.22 ( 99.49)
Epoch: [16][370/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.001)	Loss 4.1729e-01 (3.8827e-01)	Acc@1  84.38 ( 86.46)	Acc@5  99.22 ( 99.49)
Epoch: [16][380/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.001)	Loss 5.8583e-01 (3.8840e-01)	Acc@1  82.03 ( 86.47)	Acc@5  99.22 ( 99.49)
Epoch: [16][390/391]	Time  0.028 ( 0.041)	Data  0.001 ( 0.001)	Loss 2.6815e-01 (3.8806e-01)	Acc@1  92.50 ( 86.49)	Acc@5 100.00 ( 99.50)
## e[16] optimizer.zero_grad (sum) time: 0.26969456672668457
## e[16]       loss.backward (sum) time: 3.9707744121551514
## e[16]      optimizer.step (sum) time: 1.8105368614196777
## epoch[16] training(only) time: 16.140285968780518
# Switched to evaluate mode...
Test: [  0/100]	Time  0.176 ( 0.176)	Loss 4.7360e-01 (4.7360e-01)	Acc@1  81.00 ( 81.00)	Acc@5  99.00 ( 99.00)
Test: [ 10/100]	Time  0.017 ( 0.035)	Loss 6.2171e-01 (4.9832e-01)	Acc@1  83.00 ( 82.64)	Acc@5 100.00 ( 99.73)
Test: [ 20/100]	Time  0.021 ( 0.029)	Loss 5.7290e-01 (5.1751e-01)	Acc@1  79.00 ( 82.71)	Acc@5 100.00 ( 99.43)
Test: [ 30/100]	Time  0.023 ( 0.027)	Loss 5.2528e-01 (5.3120e-01)	Acc@1  84.00 ( 82.74)	Acc@5  99.00 ( 99.29)
Test: [ 40/100]	Time  0.020 ( 0.025)	Loss 4.8232e-01 (5.3502e-01)	Acc@1  84.00 ( 82.54)	Acc@5  98.00 ( 99.07)
Test: [ 50/100]	Time  0.022 ( 0.024)	Loss 4.2408e-01 (5.2673e-01)	Acc@1  85.00 ( 82.82)	Acc@5 100.00 ( 99.08)
Test: [ 60/100]	Time  0.024 ( 0.024)	Loss 5.6104e-01 (5.2759e-01)	Acc@1  83.00 ( 82.67)	Acc@5 100.00 ( 99.11)
Test: [ 70/100]	Time  0.021 ( 0.023)	Loss 4.8682e-01 (5.2938e-01)	Acc@1  81.00 ( 82.54)	Acc@5 100.00 ( 99.13)
Test: [ 80/100]	Time  0.018 ( 0.023)	Loss 3.4071e-01 (5.2584e-01)	Acc@1  85.00 ( 82.54)	Acc@5 100.00 ( 99.16)
Test: [ 90/100]	Time  0.021 ( 0.023)	Loss 4.7641e-01 (5.2334e-01)	Acc@1  82.00 ( 82.68)	Acc@5 100.00 ( 99.14)
 * Acc@1 82.710 Acc@5 99.160
### epoch[16] execution time: 18.489436626434326
EPOCH 17
i:   0, name:           module.stem.0.weight  changing lr from: 0.074087430661751719   to: 0.071012453525392968
i:   1, name:             module.stem.0.bias  changing lr from: 0.074440682299403246   to: 0.071400308933651083
i:   2, name:           module.stem.1.weight  changing lr from: 0.074789024459170600   to: 0.071782943887689715
i:   3, name:             module.stem.1.bias  changing lr from: 0.075132520154611429   to: 0.072160419590674318
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.075471232020374396   to: 0.072532797134279917
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.075805222289630700   to: 0.072900137463054238
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.076134552773131484   to: 0.073262501340933484
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.076459284839811639   to: 0.073619949319811334
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.076779479398863815   to: 0.073972541710067188
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.077095196883209413   to: 0.074320338552962509
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.077406497234297586   to: 0.074663399594818478
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.077713439888164842   to: 0.075001784262891738
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.078016083762691965   to: 0.075335551642867815
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.078314487245997252   to: 0.075664760457896232
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.078608708185907511   to: 0.075989469049093358
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.078898803880451784   to: 0.076309735357443287
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.079184831069323822   to: 0.076625616907028682
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.079466845926263241   to: 0.076937170789527887
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.079744904052306359   to: 0.077244453649916056
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.080019060469860459   to: 0.077547521673311276
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.080289369617557366   to: 0.077846430572909353
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.080555885345843903   to: 0.078141235578952833
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.080818660913269044   to: 0.078431991428682624
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.081077748983429204   to: 0.078718752357222754
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.081333201622534976   to: 0.079001572089350713
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.081585070297564261   to: 0.079280503832108051
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.081833405874968346   to: 0.079555600268208057
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.082078258619899258   to: 0.079826913550199066
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.082319678195927865   to: 0.080094495295343654
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.082557713665223631   to: 0.080358396581175925
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.082792413489168729   to: 0.080618667941700986
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.083023825529380216   to: 0.080875359364201649
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.083251997049114845   to: 0.081128520286619751
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.083476974715033000   to: 0.081378199595480413
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.083698804599299195   to: 0.081624445624329009
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.083917532181996934   to: 0.081867306152652530
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.084133202353837921   to: 0.082106828405257612
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.084345859419145741   to: 0.082343059052079004
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.084555547099095574   to: 0.082576044208393914
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.084762308535191955   to: 0.082805829435418116
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.084966186292968066   to: 0.083032459741261028
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.085167222365890305   to: 0.083255979582218559
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.085365458179452944   to: 0.083476432864382499
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.085560934595448668   to: 0.083693862945547426
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.085753691916400948   to: 0.083908312637395718
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.085943769890145294   to: 0.084119824207943394
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.086131207714547242   to: 0.084328439384229348
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.086316044042345080   to: 0.084534199355232181
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.086498316986106299   to: 0.084737144774998732
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.086678064123287199   to: 0.084937315765970134
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.086855322501385612   to: 0.085134751922491023
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.087030128643177385   to: 0.085329492314488858
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.087202518552027444   to: 0.085521575491310703
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.087372527717267251   to: 0.085711039485705298
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.087540191119630253   to: 0.085897921817939274
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.087705543236737959   to: 0.086082259500036257
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.087868618048629513   to: 0.086264089040129152
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.088029449043327712   to: 0.086443446446915109
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.088188069222435383   to: 0.086620367234204729
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.088344511106755674   to: 0.086794886425555620
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.088498806741931113   to: 0.086967038558983245
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.088650987704095435   to: 0.087136857691739955
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.088801085105533528   to: 0.087304377405155342
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.088949129600344734   to: 0.087469630809530768
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.089095151390104627   to: 0.087632650549081051
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.089239180229521556   to: 0.087793468806917296
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.089381245432083756   to: 0.087952117310064387
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.089521375875693143   to: 0.088108627334507972
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.089659600008282755   to: 0.088263029710265103
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.089795945853414133   to: 0.088415354826473558
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.089930441015851861   to: 0.088565632636495362
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.090063112687112368   to: 0.088713892663029412
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.090193987650984242   to: 0.088860164003229325
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.090323092289017790   to: 0.089004475333822497
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.090450452585981223   to: 0.089146854916226245
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.090576094135281740   to: 0.089287330601657930
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.090700042144349069   to: 0.089425929836235277
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.090822321439980036   to: 0.089562679666064030
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.090942956473642270   to: 0.089697606742309866
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.091061971326735491   to: 0.089830737326251894
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.091179389715808842   to: 0.089962097294314980
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.091295234997733454   to: 0.090091712143078678
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.091409530174828169   to: 0.090219606994260376
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.091522297899938307   to: 0.090345806599670578
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.091633560481465606   to: 0.090470335346138381
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.091743339888349151   to: 0.090593217260405284
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.091851657754996069   to: 0.090714476013985662
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.091958535386161333   to: 0.090834134927992291
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.092063993761776153   to: 0.090952216977925576
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.092168053541724485   to: 0.091068744798425028
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.092270735070566823   to: 0.091183740687981740
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.092372058382211200   to: 0.091297226613610935
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.092472043204530951   to: 0.091409224215483226
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.092570708963928855   to: 0.091519754811513976
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.092668074789847676   to: 0.091628839401909731
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.092764159519226522   to: 0.091736498673670799
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.092858981700903398   to: 0.091842753005049724
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.092952559599963500   to: 0.091947622469964518
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.093044911202033412   to: 0.092051126842366535
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.093136054217521150   to: 0.092153285600562115
i: 100, name:           module.conv10.weight  changing lr from: 0.093226006085802171   to: 0.092254117931487925
i: 101, name:             module.conv10.bias  changing lr from: 0.093314783979351362   to: 0.092353642734939401



# Switched to train mode...
Epoch: [17][  0/391]	Time  0.212 ( 0.212)	Data  0.170 ( 0.170)	Loss 2.7694e-01 (2.7694e-01)	Acc@1  89.06 ( 89.06)	Acc@5 100.00 (100.00)
Epoch: [17][ 10/391]	Time  0.043 ( 0.056)	Data  0.002 ( 0.016)	Loss 3.8996e-01 (3.5432e-01)	Acc@1  87.50 ( 87.22)	Acc@5  99.22 ( 99.64)
Epoch: [17][ 20/391]	Time  0.040 ( 0.049)	Data  0.001 ( 0.009)	Loss 2.9032e-01 (3.6385e-01)	Acc@1  89.84 ( 87.13)	Acc@5 100.00 ( 99.70)
Epoch: [17][ 30/391]	Time  0.042 ( 0.046)	Data  0.001 ( 0.006)	Loss 2.8939e-01 (3.6081e-01)	Acc@1  90.62 ( 87.53)	Acc@5  98.44 ( 99.55)
Epoch: [17][ 40/391]	Time  0.041 ( 0.045)	Data  0.001 ( 0.005)	Loss 3.7150e-01 (3.6925e-01)	Acc@1  89.06 ( 87.44)	Acc@5  99.22 ( 99.45)
Epoch: [17][ 50/391]	Time  0.041 ( 0.044)	Data  0.001 ( 0.004)	Loss 3.6422e-01 (3.6964e-01)	Acc@1  85.94 ( 87.41)	Acc@5 100.00 ( 99.43)
Epoch: [17][ 60/391]	Time  0.038 ( 0.043)	Data  0.001 ( 0.004)	Loss 3.8547e-01 (3.6847e-01)	Acc@1  86.72 ( 87.35)	Acc@5  99.22 ( 99.41)
Epoch: [17][ 70/391]	Time  0.039 ( 0.043)	Data  0.001 ( 0.003)	Loss 3.5917e-01 (3.6711e-01)	Acc@1  83.59 ( 87.28)	Acc@5 100.00 ( 99.45)
Epoch: [17][ 80/391]	Time  0.039 ( 0.043)	Data  0.001 ( 0.003)	Loss 3.1254e-01 (3.6089e-01)	Acc@1  88.28 ( 87.46)	Acc@5 100.00 ( 99.47)
Epoch: [17][ 90/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.003)	Loss 3.2414e-01 (3.6037e-01)	Acc@1  92.19 ( 87.53)	Acc@5 100.00 ( 99.49)
Epoch: [17][100/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.003)	Loss 2.5064e-01 (3.5731e-01)	Acc@1  91.41 ( 87.60)	Acc@5 100.00 ( 99.51)
Epoch: [17][110/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.003)	Loss 4.3984e-01 (3.5771e-01)	Acc@1  83.59 ( 87.59)	Acc@5  98.44 ( 99.51)
Epoch: [17][120/391]	Time  0.041 ( 0.042)	Data  0.002 ( 0.002)	Loss 3.8248e-01 (3.5669e-01)	Acc@1  86.72 ( 87.58)	Acc@5 100.00 ( 99.54)
Epoch: [17][130/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 4.2742e-01 (3.6062e-01)	Acc@1  89.84 ( 87.58)	Acc@5  98.44 ( 99.51)
Epoch: [17][140/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 3.7997e-01 (3.5977e-01)	Acc@1  87.50 ( 87.57)	Acc@5  99.22 ( 99.52)
Epoch: [17][150/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 3.7694e-01 (3.5910e-01)	Acc@1  88.28 ( 87.57)	Acc@5  99.22 ( 99.53)
Epoch: [17][160/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 4.0848e-01 (3.6173e-01)	Acc@1  86.72 ( 87.47)	Acc@5 100.00 ( 99.54)
Epoch: [17][170/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.7706e-01 (3.6027e-01)	Acc@1  92.19 ( 87.54)	Acc@5 100.00 ( 99.55)
Epoch: [17][180/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.4661e-01 (3.6052e-01)	Acc@1  86.72 ( 87.53)	Acc@5  99.22 ( 99.55)
Epoch: [17][190/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.9782e-01 (3.6343e-01)	Acc@1  92.97 ( 87.44)	Acc@5  98.44 ( 99.53)
Epoch: [17][200/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.8775e-01 (3.6396e-01)	Acc@1  82.03 ( 87.45)	Acc@5  99.22 ( 99.53)
Epoch: [17][210/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.1801e-01 (3.6398e-01)	Acc@1  86.72 ( 87.38)	Acc@5  99.22 ( 99.54)
Epoch: [17][220/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.3419e-01 (3.6449e-01)	Acc@1  88.28 ( 87.40)	Acc@5 100.00 ( 99.53)
Epoch: [17][230/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.5961e-01 (3.6448e-01)	Acc@1  86.72 ( 87.40)	Acc@5 100.00 ( 99.52)
Epoch: [17][240/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.7883e-01 (3.6581e-01)	Acc@1  86.72 ( 87.37)	Acc@5 100.00 ( 99.52)
Epoch: [17][250/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.3610e-01 (3.6628e-01)	Acc@1  88.28 ( 87.36)	Acc@5 100.00 ( 99.53)
Epoch: [17][260/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.6821e-01 (3.6731e-01)	Acc@1  89.06 ( 87.35)	Acc@5  99.22 ( 99.53)
Epoch: [17][270/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.2008e-01 (3.6878e-01)	Acc@1  89.84 ( 87.27)	Acc@5 100.00 ( 99.54)
Epoch: [17][280/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.9411e-01 (3.7132e-01)	Acc@1  87.50 ( 87.19)	Acc@5  99.22 ( 99.54)
Epoch: [17][290/391]	Time  0.044 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.1085e-01 (3.7025e-01)	Acc@1  87.50 ( 87.24)	Acc@5 100.00 ( 99.55)
Epoch: [17][300/391]	Time  0.036 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.4842e-01 (3.6992e-01)	Acc@1  85.94 ( 87.22)	Acc@5 100.00 ( 99.55)
Epoch: [17][310/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.1669e-01 (3.6968e-01)	Acc@1  92.97 ( 87.25)	Acc@5 100.00 ( 99.55)
Epoch: [17][320/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.7972e-01 (3.7012e-01)	Acc@1  90.62 ( 87.27)	Acc@5 100.00 ( 99.55)
Epoch: [17][330/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.3635e-01 (3.6915e-01)	Acc@1  85.94 ( 87.30)	Acc@5 100.00 ( 99.56)
Epoch: [17][340/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.5269e-01 (3.6902e-01)	Acc@1  89.84 ( 87.31)	Acc@5 100.00 ( 99.56)
Epoch: [17][350/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.001)	Loss 2.8482e-01 (3.6897e-01)	Acc@1  90.62 ( 87.31)	Acc@5 100.00 ( 99.57)
Epoch: [17][360/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.001)	Loss 2.9286e-01 (3.6905e-01)	Acc@1  89.06 ( 87.30)	Acc@5 100.00 ( 99.55)
Epoch: [17][370/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.001)	Loss 3.1336e-01 (3.6932e-01)	Acc@1  90.62 ( 87.31)	Acc@5  99.22 ( 99.55)
Epoch: [17][380/391]	Time  0.043 ( 0.041)	Data  0.001 ( 0.001)	Loss 4.6790e-01 (3.6910e-01)	Acc@1  82.03 ( 87.31)	Acc@5 100.00 ( 99.55)
Epoch: [17][390/391]	Time  0.028 ( 0.041)	Data  0.001 ( 0.001)	Loss 4.9496e-01 (3.6952e-01)	Acc@1  87.50 ( 87.34)	Acc@5  98.75 ( 99.55)
## e[17] optimizer.zero_grad (sum) time: 0.27689266204833984
## e[17]       loss.backward (sum) time: 3.9833428859710693
## e[17]      optimizer.step (sum) time: 1.80202317237854
## epoch[17] training(only) time: 16.071719646453857
# Switched to evaluate mode...
Test: [  0/100]	Time  0.177 ( 0.177)	Loss 4.4774e-01 (4.4774e-01)	Acc@1  86.00 ( 86.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.024 ( 0.034)	Loss 5.6956e-01 (4.7802e-01)	Acc@1  81.00 ( 84.27)	Acc@5  98.00 ( 99.45)
Test: [ 20/100]	Time  0.020 ( 0.028)	Loss 6.2012e-01 (4.8387e-01)	Acc@1  81.00 ( 84.33)	Acc@5  98.00 ( 99.33)
Test: [ 30/100]	Time  0.022 ( 0.025)	Loss 4.8006e-01 (4.9186e-01)	Acc@1  82.00 ( 84.29)	Acc@5  98.00 ( 99.13)
Test: [ 40/100]	Time  0.019 ( 0.025)	Loss 5.0781e-01 (4.9441e-01)	Acc@1  88.00 ( 84.37)	Acc@5  99.00 ( 99.15)
Test: [ 50/100]	Time  0.020 ( 0.024)	Loss 3.2830e-01 (4.8585e-01)	Acc@1  87.00 ( 84.47)	Acc@5 100.00 ( 99.16)
Test: [ 60/100]	Time  0.022 ( 0.023)	Loss 3.8653e-01 (4.7945e-01)	Acc@1  87.00 ( 84.54)	Acc@5  99.00 ( 99.20)
Test: [ 70/100]	Time  0.018 ( 0.023)	Loss 4.3086e-01 (4.7274e-01)	Acc@1  86.00 ( 84.65)	Acc@5 100.00 ( 99.23)
Test: [ 80/100]	Time  0.024 ( 0.023)	Loss 3.6599e-01 (4.7130e-01)	Acc@1  86.00 ( 84.74)	Acc@5 100.00 ( 99.23)
Test: [ 90/100]	Time  0.018 ( 0.023)	Loss 4.4194e-01 (4.7519e-01)	Acc@1  85.00 ( 84.63)	Acc@5  99.00 ( 99.24)
 * Acc@1 84.790 Acc@5 99.260
### epoch[17] execution time: 18.403313159942627
EPOCH 18
i:   0, name:           module.stem.0.weight  changing lr from: 0.071012453525392968   to: 0.067844492669611026
i:   1, name:             module.stem.0.bias  changing lr from: 0.071400308933651083   to: 0.068266531260249799
i:   2, name:           module.stem.1.weight  changing lr from: 0.071782943887689715   to: 0.068683090632486718
i:   3, name:             module.stem.1.bias  changing lr from: 0.072160419590674318   to: 0.069094228015733436
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.072532797134279917   to: 0.069500000870223996
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.072900137463054238   to: 0.069900466835977212
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.073262501340933484   to: 0.070295683684498331
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.073619949319811334   to: 0.070685709273101374
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.073972541710067188   to: 0.071070601501738606
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.074320338552962509   to: 0.071450418272227520
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.074663399594818478   to: 0.071825217449770121
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.075001784262891738   to: 0.072195056826663731
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.075335551642867815   to: 0.072559994088105831
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.075664760457896232   to: 0.072920086779999949
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.075989469049093358   to: 0.073275392278672830
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.076309735357443287   to: 0.073625967762417144
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.076625616907028682   to: 0.073971870184776856
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.076937170789527887   to: 0.074313156249496234
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.077244453649916056   to: 0.074649882387056485
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.077547521673311276   to: 0.074982104732726873
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.077846430572909353   to: 0.075309879106060504
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.078141235578952833   to: 0.075633260991767662
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.078431991428682624   to: 0.075952305521902283
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.078718752357222754   to: 0.076267067459299856
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.079001572089350713   to: 0.076577601182207591
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.079280503832108051   to: 0.076883960670050405
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.079555600268208057   to: 0.077186199490277885
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.079826913550199066   to: 0.077484370786240875
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.080094495295343654   to: 0.077778527266047226
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.080358396581175925   to: 0.078068721192349227
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.080618667941700986   to: 0.078355004373017095
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.080875359364201649   to: 0.078637428152654468
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.081128520286619751   to: 0.078916043404914205
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.081378199595480413   to: 0.079190900525574356
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.081624445624329009   to: 0.079462049426335640
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.081867306152652530   to: 0.079729539529304269
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.082106828405257612   to: 0.079993419762124235
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.082343059052079004   to: 0.080253738553726139
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.082576044208393914   to: 0.080510543830659934
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.082805829435418116   to: 0.080763883013981005
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.083032459741261028   to: 0.081013803016660266
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.083255979582218559   to: 0.081260350241490142
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.083476432864382499   to: 0.081503570579459395
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.083693862945547426   to: 0.081743509408571502
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.083908312637395718   to: 0.081980211593081664
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.084119824207943394   to: 0.082213721483129526
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.084328439384229348   to: 0.082444082914744574
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.084534199355232181   to: 0.082671339210203601
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.084737144774998732   to: 0.082895533178719366
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.084937315765970134   to: 0.083116707117441013
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.085134751922491023   to: 0.083334902812748107
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.085329492314488858   to: 0.083550161541819823
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.085521575491310703   to: 0.083762524074463343
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.085711039485705298   to: 0.083972030675184398
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.085897921817939274   to: 0.084178721105485355
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.086082259500036257   to: 0.084382634626375630
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.086264089040129152   to: 0.084583810001080950
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.086443446446915109   to: 0.084782285497937690
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.086620367234204729   to: 0.084978098893460113
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.086794886425555620   to: 0.085171287475567903
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.086967038558983245   to: 0.085361888046963097
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.087136857691739955   to: 0.085549936928644946
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.087304377405155342   to: 0.085735469963552538
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.087469630809530768   to: 0.085918522520325474
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.087632650549081051   to: 0.086099129497172716
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.087793468806917296   to: 0.086277325325841120
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.087952117310064387   to: 0.086453143975674870
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.088108627334507972   to: 0.086626618957757792
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.088263029710265103   to: 0.086797783329130976
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.088415354826473558   to: 0.086966669697078211
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.088565632636495362   to: 0.087133310223472552
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.088713892663029412   to: 0.087297736629177280
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.088860164003229325   to: 0.087459980198495157
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.089004475333822497   to: 0.087620071783659881
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.089146854916226245   to: 0.087778041809364438
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.089287330601657930   to: 0.087933920277320859
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.089425929836235277   to: 0.088087736770846387
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.089562679666064030   to: 0.088239520459471324
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.089697606742309866   to: 0.088389300103564189
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.089830737326251894   to: 0.088537104058969848
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.089962097294314980   to: 0.088682960281656439
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.090091712143078678   to: 0.088826896332367844
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.090219606994260376   to: 0.088968939381277451
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.090345806599670578   to: 0.089109116212640477
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.090470335346138381   to: 0.089247453229441234
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.090593217260405284   to: 0.089383976458032657
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.090714476013985662   to: 0.089518711552765098
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.090834134927992291   to: 0.089651683800601942
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.090952216977925576   to: 0.089782918125719313
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.091068744798425028   to: 0.089912439094087915
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.091183740687981740   to: 0.090040270918034473
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.091297226613610935   to: 0.090166437460781068
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.091409224215483226   to: 0.090290962240960143
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.091519754811513976   to: 0.090413868437103764
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.091628839401909731   to: 0.090535178892105217
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.091736498673670799   to: 0.090654916117651474
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.091842753005049724   to: 0.090773102298625286
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.091947622469964518   to: 0.090889759297475253
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.092051126842366535   to: 0.091004908658552999
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.092153285600562115   to: 0.091118571612416002
i: 100, name:           module.conv10.weight  changing lr from: 0.092254117931487925   to: 0.091230769080095336
i: 101, name:             module.conv10.bias  changing lr from: 0.092353642734939401   to: 0.091341521677327217



# Switched to train mode...
Epoch: [18][  0/391]	Time  0.213 ( 0.213)	Data  0.170 ( 0.170)	Loss 4.7946e-01 (4.7946e-01)	Acc@1  80.47 ( 80.47)	Acc@5  99.22 ( 99.22)
Epoch: [18][ 10/391]	Time  0.039 ( 0.056)	Data  0.001 ( 0.016)	Loss 3.8476e-01 (3.5170e-01)	Acc@1  88.28 ( 87.29)	Acc@5 100.00 ( 99.79)
Epoch: [18][ 20/391]	Time  0.041 ( 0.049)	Data  0.001 ( 0.009)	Loss 2.1845e-01 (3.4160e-01)	Acc@1  91.41 ( 87.50)	Acc@5 100.00 ( 99.78)
Epoch: [18][ 30/391]	Time  0.039 ( 0.046)	Data  0.001 ( 0.006)	Loss 2.7161e-01 (3.4112e-01)	Acc@1  90.62 ( 87.47)	Acc@5 100.00 ( 99.75)
Epoch: [18][ 40/391]	Time  0.040 ( 0.045)	Data  0.001 ( 0.005)	Loss 3.2994e-01 (3.4744e-01)	Acc@1  87.50 ( 87.44)	Acc@5 100.00 ( 99.70)
Epoch: [18][ 50/391]	Time  0.039 ( 0.044)	Data  0.001 ( 0.004)	Loss 3.3078e-01 (3.4368e-01)	Acc@1  88.28 ( 87.65)	Acc@5  99.22 ( 99.68)
Epoch: [18][ 60/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.004)	Loss 3.4433e-01 (3.4193e-01)	Acc@1  87.50 ( 87.79)	Acc@5 100.00 ( 99.72)
Epoch: [18][ 70/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.003)	Loss 4.7048e-01 (3.4684e-01)	Acc@1  86.72 ( 87.64)	Acc@5  98.44 ( 99.70)
Epoch: [18][ 80/391]	Time  0.039 ( 0.043)	Data  0.001 ( 0.003)	Loss 3.6048e-01 (3.4821e-01)	Acc@1  86.72 ( 87.56)	Acc@5 100.00 ( 99.70)
Epoch: [18][ 90/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.003)	Loss 3.0360e-01 (3.4639e-01)	Acc@1  90.62 ( 87.71)	Acc@5 100.00 ( 99.67)
Epoch: [18][100/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.003)	Loss 4.0874e-01 (3.4665e-01)	Acc@1  86.72 ( 87.69)	Acc@5  99.22 ( 99.66)
Epoch: [18][110/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.003)	Loss 4.1400e-01 (3.4642e-01)	Acc@1  84.38 ( 87.78)	Acc@5 100.00 ( 99.66)
Epoch: [18][120/391]	Time  0.041 ( 0.042)	Data  0.002 ( 0.002)	Loss 2.6072e-01 (3.4616e-01)	Acc@1  92.97 ( 87.82)	Acc@5 100.00 ( 99.66)
Epoch: [18][130/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 4.0086e-01 (3.4953e-01)	Acc@1  89.06 ( 87.76)	Acc@5  98.44 ( 99.65)
Epoch: [18][140/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 3.0154e-01 (3.5322e-01)	Acc@1  89.06 ( 87.61)	Acc@5 100.00 ( 99.65)
Epoch: [18][150/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 4.6011e-01 (3.5421e-01)	Acc@1  83.59 ( 87.61)	Acc@5  99.22 ( 99.64)
Epoch: [18][160/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 3.7860e-01 (3.5735e-01)	Acc@1  87.50 ( 87.52)	Acc@5  99.22 ( 99.63)
Epoch: [18][170/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.7568e-01 (3.5465e-01)	Acc@1  92.19 ( 87.61)	Acc@5 100.00 ( 99.63)
Epoch: [18][180/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.7619e-01 (3.5466e-01)	Acc@1  87.50 ( 87.61)	Acc@5 100.00 ( 99.61)
Epoch: [18][190/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.4869e-01 (3.5538e-01)	Acc@1  89.06 ( 87.57)	Acc@5 100.00 ( 99.60)
Epoch: [18][200/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.7331e-01 (3.5351e-01)	Acc@1  89.84 ( 87.62)	Acc@5 100.00 ( 99.60)
Epoch: [18][210/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.5559e-01 (3.5209e-01)	Acc@1  91.41 ( 87.74)	Acc@5  99.22 ( 99.60)
Epoch: [18][220/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.2588e-01 (3.5274e-01)	Acc@1  82.81 ( 87.71)	Acc@5 100.00 ( 99.60)
Epoch: [18][230/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.6140e-01 (3.5444e-01)	Acc@1  81.25 ( 87.69)	Acc@5 100.00 ( 99.59)
Epoch: [18][240/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.6923e-01 (3.5519e-01)	Acc@1  82.81 ( 87.64)	Acc@5 100.00 ( 99.60)
Epoch: [18][250/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.1057e-01 (3.5521e-01)	Acc@1  85.16 ( 87.64)	Acc@5  99.22 ( 99.60)
Epoch: [18][260/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.0049e-01 (3.5494e-01)	Acc@1  88.28 ( 87.64)	Acc@5 100.00 ( 99.61)
Epoch: [18][270/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.1362e-01 (3.5700e-01)	Acc@1  85.94 ( 87.59)	Acc@5  98.44 ( 99.61)
Epoch: [18][280/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.6189e-01 (3.5667e-01)	Acc@1  83.59 ( 87.59)	Acc@5 100.00 ( 99.61)
Epoch: [18][290/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.6528e-01 (3.5721e-01)	Acc@1  81.25 ( 87.59)	Acc@5  97.66 ( 99.60)
Epoch: [18][300/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.1889e-01 (3.5701e-01)	Acc@1  90.62 ( 87.61)	Acc@5  99.22 ( 99.60)
Epoch: [18][310/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.0218e-01 (3.5689e-01)	Acc@1  85.16 ( 87.61)	Acc@5 100.00 ( 99.61)
Epoch: [18][320/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.3081e-01 (3.5715e-01)	Acc@1  87.50 ( 87.59)	Acc@5  99.22 ( 99.62)
Epoch: [18][330/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.4454e-01 (3.5748e-01)	Acc@1  89.06 ( 87.58)	Acc@5 100.00 ( 99.61)
Epoch: [18][340/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.2864e-01 (3.5702e-01)	Acc@1  89.84 ( 87.59)	Acc@5 100.00 ( 99.62)
Epoch: [18][350/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.001)	Loss 3.4417e-01 (3.5611e-01)	Acc@1  88.28 ( 87.63)	Acc@5  99.22 ( 99.61)
Epoch: [18][360/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.001)	Loss 4.0780e-01 (3.5585e-01)	Acc@1  86.72 ( 87.64)	Acc@5 100.00 ( 99.61)
Epoch: [18][370/391]	Time  0.037 ( 0.041)	Data  0.001 ( 0.001)	Loss 2.7193e-01 (3.5507e-01)	Acc@1  90.62 ( 87.69)	Acc@5 100.00 ( 99.61)
Epoch: [18][380/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.001)	Loss 4.5154e-01 (3.5582e-01)	Acc@1  84.38 ( 87.67)	Acc@5  97.66 ( 99.61)
Epoch: [18][390/391]	Time  0.028 ( 0.041)	Data  0.001 ( 0.001)	Loss 4.5607e-01 (3.5713e-01)	Acc@1  85.00 ( 87.62)	Acc@5 100.00 ( 99.60)
## e[18] optimizer.zero_grad (sum) time: 0.27044057846069336
## e[18]       loss.backward (sum) time: 3.97007417678833
## e[18]      optimizer.step (sum) time: 1.7967467308044434
## epoch[18] training(only) time: 16.03824496269226
# Switched to evaluate mode...
Test: [  0/100]	Time  0.169 ( 0.169)	Loss 3.7069e-01 (3.7069e-01)	Acc@1  85.00 ( 85.00)	Acc@5  99.00 ( 99.00)
Test: [ 10/100]	Time  0.021 ( 0.035)	Loss 4.8294e-01 (4.6335e-01)	Acc@1  81.00 ( 83.36)	Acc@5  99.00 ( 99.27)
Test: [ 20/100]	Time  0.021 ( 0.029)	Loss 6.3731e-01 (4.7345e-01)	Acc@1  81.00 ( 83.71)	Acc@5  98.00 ( 99.14)
Test: [ 30/100]	Time  0.021 ( 0.026)	Loss 4.9789e-01 (4.9121e-01)	Acc@1  85.00 ( 83.84)	Acc@5  98.00 ( 99.16)
Test: [ 40/100]	Time  0.021 ( 0.025)	Loss 4.7287e-01 (4.9468e-01)	Acc@1  84.00 ( 83.73)	Acc@5 100.00 ( 99.15)
Test: [ 50/100]	Time  0.020 ( 0.024)	Loss 4.3228e-01 (4.8605e-01)	Acc@1  86.00 ( 84.12)	Acc@5  99.00 ( 99.14)
Test: [ 60/100]	Time  0.021 ( 0.023)	Loss 4.4652e-01 (4.8286e-01)	Acc@1  85.00 ( 84.21)	Acc@5 100.00 ( 99.21)
Test: [ 70/100]	Time  0.017 ( 0.023)	Loss 6.2418e-01 (4.8217e-01)	Acc@1  82.00 ( 84.27)	Acc@5 100.00 ( 99.24)
Test: [ 80/100]	Time  0.022 ( 0.022)	Loss 3.5624e-01 (4.8287e-01)	Acc@1  88.00 ( 84.32)	Acc@5 100.00 ( 99.25)
Test: [ 90/100]	Time  0.022 ( 0.022)	Loss 3.1933e-01 (4.8384e-01)	Acc@1  90.00 ( 84.16)	Acc@5 100.00 ( 99.24)
 * Acc@1 84.240 Acc@5 99.250
### epoch[18] execution time: 18.331721305847168
EPOCH 19
i:   0, name:           module.stem.0.weight  changing lr from: 0.067844492669611026   to: 0.064598267368231238
i:   1, name:             module.stem.0.bias  changing lr from: 0.068266531260249799   to: 0.065053697509653230
i:   2, name:           module.stem.1.weight  changing lr from: 0.068683090632486718   to: 0.065503451237549623
i:   3, name:             module.stem.1.bias  changing lr from: 0.069094228015733436   to: 0.065947579425276473
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.069500000870223996   to: 0.066386133597904892
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.069900466835977212   to: 0.066819165863495664
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.070295683684498331   to: 0.067246728847750376
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.070685709273101374   to: 0.067668875631901299
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.071070601501738606   to: 0.068085659693706710
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.071450418272227520   to: 0.068497134851423211
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.071825217449770121   to: 0.068903355210631748
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.072195056826663731   to: 0.069304375113798125
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.072559994088105831   to: 0.069700249092453023
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.072920086779999949   to: 0.070091031821881783
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.073275392278672830   to: 0.070476778078216701
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.073625967762417144   to: 0.070857542697830692
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.073971870184776856   to: 0.071233380538932675
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.074313156249496234   to: 0.071604346445271069
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.074649882387056485   to: 0.071970495211853752
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.074982104732726873   to: 0.072331881552596941
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.075309879106060504   to: 0.072688560069819191
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.075633260991767662   to: 0.073040585225499208
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.075952305521902283   to: 0.073388011314220042
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.076267067459299856   to: 0.073730892437724752
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.076577601182207591   to: 0.074069282481012064
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.076883960670050405   to: 0.074403235089902667
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.077186199490277885   to: 0.074732803650010629
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.077484370786240875   to: 0.075058041267055717
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.077778527266047226   to: 0.075379000748456229
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.078068721192349227   to: 0.075695734586143426
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.078355004373017095   to: 0.076008294940541427
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.078637428152654468   to: 0.076316733625659161
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.078916043404914205   to: 0.076621102095241880
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.079190900525574356   to: 0.076921451429933507
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.079462049426335640   to: 0.077217832325401539
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.079729539529304269   to: 0.077510295081379563
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.079993419762124235   to: 0.077798889591583112
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.080253738553726139   to: 0.078083665334457569
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.080510543830659934   to: 0.078364671364717406
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.080763883013981005   to: 0.078641956305638638
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.081013803016660266   to: 0.078915568342067755
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.081260350241490142   to: 0.079185555214111331
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.081503570579459395   to: 0.079451964211473103
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.081743509408571502   to: 0.079714842168405797
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.081980211593081664   to: 0.079974235459246673
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.082213721483129526   to: 0.080230189994507428
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.082444082914744574   to: 0.080482751217489656
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.082671339210203601   to: 0.080731964101399184
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.082895533178719366   to: 0.080977873146932638
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.083116707117441013   to: 0.081220522380312035
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.083334902812748107   to: 0.081459955351743163
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.083550161541819823   to: 0.081696215134275038
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.083762524074463343   to: 0.081929344323038986
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.083972030675184398   to: 0.082159385034846127
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.084178721105485355   to: 0.082386378908123781
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.084382634626375630   to: 0.082610367103171295
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.084583810001080950   to: 0.082831390302717828
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.084782285497937690   to: 0.083049488712764061
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.084978098893460113   to: 0.083264702063691631
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.085171287475567903   to: 0.083477069611624544
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.085361888046963097   to: 0.083686630140027113
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.085549936928644946   to: 0.083893421961524398
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.085735469963552538   to: 0.084097482919931077
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.085918522520325474   to: 0.084298850392475755
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.086099129497172716   to: 0.084497561292208340
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.086277325325841120   to: 0.084693652070578093
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.086453143975674870   to: 0.084887158720171496
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.086626618957757792   to: 0.085078116777598772
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.086797783329130976   to: 0.085266561326518622
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.086966669697078211   to: 0.085452527000791687
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.087133310223472552   to: 0.085636047987753011
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.087297736629177280   to: 0.085817158031594648
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.087459980198495157   to: 0.085995890436850020
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.087620071783659881   to: 0.086172278071971684
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.087778041809364438   to: 0.086346353372995177
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.087933920277320859   to: 0.086518148347281137
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.088087736770846387   to: 0.086687694577329041
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.088239520459471324   to: 0.086855023224655978
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.088389300103564189   to: 0.087020165033733832
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.088537104058969848   to: 0.087183150335979245
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.088682960281656439   to: 0.087344009053790500
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.088826896332367844   to: 0.087502770704625935
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.088968939381277451   to: 0.087659464405118820
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.089109116212640477   to: 0.087814118875223904
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.089247453229441234   to: 0.087966762442390864
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.089383976458032657   to: 0.088117423045760437
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.089518711552765098   to: 0.088266128240379160
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.089651683800601942   to: 0.088412905201428638
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.089782918125719313   to: 0.088557780728465763
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.089912439094087915   to: 0.088700781249670457
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.090040270918034473   to: 0.088841932826097453
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.090166437460781068   to: 0.088981261155929248
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.090290962240960143   to: 0.089118791578727000
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.090413868437103764   to: 0.089254549079676893
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.090535178892105217   to: 0.089388558293829190
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.090654916117651474   to: 0.089520843510327450
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.090773102298625286   to: 0.089651428676625927
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.090889759297475253   to: 0.089780337402692575
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.091004908658552999   to: 0.089907592965195834
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.091118571612416002   to: 0.090033218311673352
i: 100, name:           module.conv10.weight  changing lr from: 0.091230769080095336   to: 0.090157236064680693
i: 101, name:             module.conv10.bias  changing lr from: 0.091341521677327217   to: 0.090279668525918441



# Switched to train mode...
Epoch: [19][  0/391]	Time  0.223 ( 0.223)	Data  0.177 ( 0.177)	Loss 2.7418e-01 (2.7418e-01)	Acc@1  90.62 ( 90.62)	Acc@5 100.00 (100.00)
Epoch: [19][ 10/391]	Time  0.042 ( 0.057)	Data  0.001 ( 0.017)	Loss 3.4864e-01 (3.1148e-01)	Acc@1  86.72 ( 89.49)	Acc@5 100.00 ( 99.79)
Epoch: [19][ 20/391]	Time  0.043 ( 0.049)	Data  0.002 ( 0.009)	Loss 4.6352e-01 (3.4047e-01)	Acc@1  84.38 ( 88.24)	Acc@5 100.00 ( 99.59)
Epoch: [19][ 30/391]	Time  0.041 ( 0.047)	Data  0.001 ( 0.007)	Loss 3.3690e-01 (3.3053e-01)	Acc@1  86.72 ( 88.36)	Acc@5 100.00 ( 99.67)
Epoch: [19][ 40/391]	Time  0.043 ( 0.045)	Data  0.001 ( 0.005)	Loss 2.6441e-01 (3.2166e-01)	Acc@1  92.97 ( 88.68)	Acc@5  99.22 ( 99.66)
Epoch: [19][ 50/391]	Time  0.039 ( 0.044)	Data  0.001 ( 0.004)	Loss 3.9021e-01 (3.1660e-01)	Acc@1  86.72 ( 88.91)	Acc@5 100.00 ( 99.68)
Epoch: [19][ 60/391]	Time  0.040 ( 0.044)	Data  0.001 ( 0.004)	Loss 3.2961e-01 (3.1393e-01)	Acc@1  86.72 ( 88.95)	Acc@5 100.00 ( 99.69)
Epoch: [19][ 70/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.004)	Loss 3.4577e-01 (3.1816e-01)	Acc@1  89.06 ( 88.86)	Acc@5  99.22 ( 99.66)
Epoch: [19][ 80/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.003)	Loss 2.4270e-01 (3.1907e-01)	Acc@1  91.41 ( 88.77)	Acc@5 100.00 ( 99.64)
Epoch: [19][ 90/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.003)	Loss 2.9966e-01 (3.2135e-01)	Acc@1  92.19 ( 88.80)	Acc@5 100.00 ( 99.62)
Epoch: [19][100/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.003)	Loss 2.9197e-01 (3.2249e-01)	Acc@1  89.06 ( 88.67)	Acc@5  99.22 ( 99.61)
Epoch: [19][110/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.003)	Loss 3.8642e-01 (3.2569e-01)	Acc@1  85.16 ( 88.56)	Acc@5 100.00 ( 99.60)
Epoch: [19][120/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.002)	Loss 3.2943e-01 (3.2558e-01)	Acc@1  85.16 ( 88.55)	Acc@5  99.22 ( 99.60)
Epoch: [19][130/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 3.6164e-01 (3.2607e-01)	Acc@1  89.84 ( 88.58)	Acc@5  99.22 ( 99.58)
Epoch: [19][140/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 4.3163e-01 (3.2776e-01)	Acc@1  85.16 ( 88.51)	Acc@5  99.22 ( 99.58)
Epoch: [19][150/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 3.6866e-01 (3.2654e-01)	Acc@1  86.72 ( 88.51)	Acc@5 100.00 ( 99.59)
Epoch: [19][160/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 3.5760e-01 (3.3109e-01)	Acc@1  87.50 ( 88.36)	Acc@5 100.00 ( 99.58)
Epoch: [19][170/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 3.9515e-01 (3.3363e-01)	Acc@1  85.16 ( 88.28)	Acc@5 100.00 ( 99.60)
Epoch: [19][180/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.9521e-01 (3.3437e-01)	Acc@1  89.84 ( 88.24)	Acc@5  99.22 ( 99.61)
Epoch: [19][190/391]	Time  0.043 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.1890e-01 (3.3764e-01)	Acc@1  85.16 ( 88.08)	Acc@5 100.00 ( 99.61)
Epoch: [19][200/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.5964e-01 (3.4067e-01)	Acc@1  86.72 ( 88.01)	Acc@5 100.00 ( 99.61)
Epoch: [19][210/391]	Time  0.039 ( 0.041)	Data  0.002 ( 0.002)	Loss 3.7223e-01 (3.4085e-01)	Acc@1  85.16 ( 87.93)	Acc@5  98.44 ( 99.61)
Epoch: [19][220/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.6859e-01 (3.4220e-01)	Acc@1  92.19 ( 87.87)	Acc@5 100.00 ( 99.62)
Epoch: [19][230/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.9770e-01 (3.4435e-01)	Acc@1  88.28 ( 87.81)	Acc@5  99.22 ( 99.61)
Epoch: [19][240/391]	Time  0.043 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.4878e-01 (3.4554e-01)	Acc@1  88.28 ( 87.78)	Acc@5  99.22 ( 99.62)
Epoch: [19][250/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.8494e-01 (3.4616e-01)	Acc@1  86.72 ( 87.78)	Acc@5 100.00 ( 99.61)
Epoch: [19][260/391]	Time  0.044 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.3812e-01 (3.4669e-01)	Acc@1  89.84 ( 87.75)	Acc@5  99.22 ( 99.61)
Epoch: [19][270/391]	Time  0.037 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.3397e-01 (3.4837e-01)	Acc@1  84.38 ( 87.71)	Acc@5  99.22 ( 99.61)
Epoch: [19][280/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.9702e-01 (3.4946e-01)	Acc@1  91.41 ( 87.70)	Acc@5 100.00 ( 99.60)
Epoch: [19][290/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.1003e-01 (3.4881e-01)	Acc@1  87.50 ( 87.71)	Acc@5 100.00 ( 99.61)
Epoch: [19][300/391]	Time  0.037 ( 0.040)	Data  0.001 ( 0.002)	Loss 1.9299e-01 (3.4902e-01)	Acc@1  93.75 ( 87.70)	Acc@5 100.00 ( 99.60)
Epoch: [19][310/391]	Time  0.041 ( 0.040)	Data  0.001 ( 0.002)	Loss 3.6596e-01 (3.4906e-01)	Acc@1  88.28 ( 87.71)	Acc@5  99.22 ( 99.60)
Epoch: [19][320/391]	Time  0.041 ( 0.040)	Data  0.001 ( 0.002)	Loss 2.8149e-01 (3.4860e-01)	Acc@1  90.62 ( 87.74)	Acc@5 100.00 ( 99.61)
Epoch: [19][330/391]	Time  0.041 ( 0.040)	Data  0.002 ( 0.002)	Loss 3.4599e-01 (3.4851e-01)	Acc@1  88.28 ( 87.75)	Acc@5  99.22 ( 99.60)
Epoch: [19][340/391]	Time  0.040 ( 0.040)	Data  0.001 ( 0.002)	Loss 3.6276e-01 (3.4834e-01)	Acc@1  89.84 ( 87.78)	Acc@5  98.44 ( 99.60)
Epoch: [19][350/391]	Time  0.040 ( 0.040)	Data  0.001 ( 0.002)	Loss 3.6271e-01 (3.4924e-01)	Acc@1  85.16 ( 87.74)	Acc@5  99.22 ( 99.61)
Epoch: [19][360/391]	Time  0.039 ( 0.040)	Data  0.001 ( 0.002)	Loss 3.7856e-01 (3.4958e-01)	Acc@1  87.50 ( 87.72)	Acc@5  98.44 ( 99.61)
Epoch: [19][370/391]	Time  0.039 ( 0.040)	Data  0.001 ( 0.002)	Loss 3.7768e-01 (3.5093e-01)	Acc@1  86.72 ( 87.68)	Acc@5 100.00 ( 99.60)
Epoch: [19][380/391]	Time  0.041 ( 0.040)	Data  0.001 ( 0.002)	Loss 3.5570e-01 (3.5010e-01)	Acc@1  88.28 ( 87.70)	Acc@5  99.22 ( 99.61)
Epoch: [19][390/391]	Time  0.028 ( 0.040)	Data  0.001 ( 0.002)	Loss 3.2637e-01 (3.4938e-01)	Acc@1  88.75 ( 87.73)	Acc@5  98.75 ( 99.61)
## e[19] optimizer.zero_grad (sum) time: 0.27086853981018066
## e[19]       loss.backward (sum) time: 3.9196975231170654
## e[19]      optimizer.step (sum) time: 1.8697550296783447
## epoch[19] training(only) time: 15.904630184173584
# Switched to evaluate mode...
Test: [  0/100]	Time  0.175 ( 0.175)	Loss 4.1740e-01 (4.1740e-01)	Acc@1  86.00 ( 86.00)	Acc@5  98.00 ( 98.00)
Test: [ 10/100]	Time  0.021 ( 0.035)	Loss 5.9098e-01 (4.7471e-01)	Acc@1  81.00 ( 85.45)	Acc@5  99.00 ( 99.18)
Test: [ 20/100]	Time  0.024 ( 0.029)	Loss 4.8176e-01 (4.8707e-01)	Acc@1  84.00 ( 84.24)	Acc@5  99.00 ( 99.24)
Test: [ 30/100]	Time  0.016 ( 0.025)	Loss 5.4301e-01 (5.1472e-01)	Acc@1  81.00 ( 83.65)	Acc@5  99.00 ( 99.10)
Test: [ 40/100]	Time  0.017 ( 0.024)	Loss 5.5111e-01 (5.1533e-01)	Acc@1  87.00 ( 83.76)	Acc@5  99.00 ( 99.20)
Test: [ 50/100]	Time  0.025 ( 0.024)	Loss 2.7903e-01 (5.0651e-01)	Acc@1  90.00 ( 83.94)	Acc@5  99.00 ( 99.14)
Test: [ 60/100]	Time  0.023 ( 0.023)	Loss 4.9664e-01 (5.0898e-01)	Acc@1  88.00 ( 83.87)	Acc@5 100.00 ( 99.21)
Test: [ 70/100]	Time  0.024 ( 0.023)	Loss 5.8371e-01 (5.0849e-01)	Acc@1  82.00 ( 83.82)	Acc@5  99.00 ( 99.21)
Test: [ 80/100]	Time  0.019 ( 0.022)	Loss 2.8758e-01 (5.0335e-01)	Acc@1  86.00 ( 83.86)	Acc@5 100.00 ( 99.25)
Test: [ 90/100]	Time  0.020 ( 0.022)	Loss 3.0865e-01 (5.0081e-01)	Acc@1  88.00 ( 83.87)	Acc@5 100.00 ( 99.26)
 * Acc@1 84.020 Acc@5 99.270
### epoch[19] execution time: 18.228788375854492
EPOCH 20
i:   0, name:           module.stem.0.weight  changing lr from: 0.064598267368231238   to: 0.061288860534611772
i:   1, name:             module.stem.0.bias  changing lr from: 0.065053697509653230   to: 0.061776517876351203
i:   2, name:           module.stem.1.weight  changing lr from: 0.065503451237549623   to: 0.062258372242085892
i:   3, name:             module.stem.1.bias  changing lr from: 0.065947579425276473   to: 0.062734465571493453
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.066386133597904892   to: 0.063204840957727521
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.066819165863495664   to: 0.063669542558838152
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.067246728847750376   to: 0.064128615513242976
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.067668875631901299   to: 0.064582105859091854
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.068085659693706710   to: 0.065030060457373917
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.068497134851423211   to: 0.065472526918620419
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.068903355210631748   to: 0.065909553533061771
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.069304375113798125   to: 0.066341189204102549
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.069700249092453023   to: 0.066767483384981799
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.070091031821881783   to: 0.067188486018492075
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.070476778078216701   to: 0.067604247479633575
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.070857542697830692   to: 0.068014818521085291
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.071233380538932675   to: 0.068420250221378487
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.071604346445271069   to: 0.068820593935662547
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.071970495211853752   to: 0.069215901248956532
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.072331881552596941   to: 0.069606223931784325
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.072688560069819191   to: 0.069991613898094412
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.073040585225499208   to: 0.070372123165369407
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.073388011314220042   to: 0.070747803816833696
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.073730892437724752   to: 0.071118707965671032
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.074069282481012064   to: 0.071484887721167220
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.074403235089902667   to: 0.071846395156696205
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.074732803650010629   to: 0.072203282279470954
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.075058041267055717   to: 0.072555601001983758
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.075379000748456229   to: 0.072903403115062868
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.075695734586143426   to: 0.073246740262475712
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.076008294940541427   to: 0.073585663917011448
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.076316733625659161   to: 0.073920225357978417
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.076621102095241880   to: 0.074250475650053854
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.076921451429933507   to: 0.074576465623426666
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.077217832325401539   to: 0.074898245855175696
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.077510295081379563   to: 0.075215866651828292
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.077798889591583112   to: 0.075529378033046476
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.078083665334457569   to: 0.075838829716389541
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.078364671364717406   to: 0.076144271103104816
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.078641956305638638   to: 0.076445751264898970
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.078915568342067755   to: 0.076743318931645724
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.079185555214111331   to: 0.077037022479986172
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.079451964211473103   to: 0.077326909922780518
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.079714842168405797   to: 0.077613028899371633
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.079974235459246673   to: 0.077895426666622025
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.080230189994507428   to: 0.078174150090687913
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.080482751217489656   to: 0.078449245639495124
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.080731964101399184   to: 0.078720759375883437
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.080977873146932638   to: 0.078988736951386931
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.081220522380312035   to: 0.079253223600619552
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.081459955351743163   to: 0.079514264136236190
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.081696215134275038   to: 0.079771902944441100
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.081929344323038986   to: 0.080026183981016172
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.082159385034846127   to: 0.080277150767843378
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.082386378908123781   to: 0.080524846389896099
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.082610367103171295   to: 0.080769313492675646
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.082831390302717828   to: 0.081010594280070070
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.083049488712764061   to: 0.081248730512613346
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.083264702063691631   to: 0.081483763506124018
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.083477069611624544   to: 0.081715734130703072
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.083686630140027113   to: 0.081944682810072153
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.083893421961524398   to: 0.082170649521233485
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.084097482919931077   to: 0.082393673794433991
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.084298850392475755   to: 0.082613794713416927
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.084497561292208340   to: 0.082831050915944851
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.084693652070578093   to: 0.083045480594578641
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.084887158720171496   to: 0.083257121497697706
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.085078116777598772   to: 0.083466010930747722
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.085266561326518622   to: 0.083672185757702078
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.085452527000791687   to: 0.083875682402724500
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.085636047987753011   to: 0.084076536852020489
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.085817158031594648   to: 0.084274784655865909
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.085995890436850020   to: 0.084470460930801738
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.086172278071971684   to: 0.084663600361983962
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.086346353372995177   to: 0.084854237205678917
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.086518148347281137   to: 0.085042405291893997
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.086687694577329041   to: 0.085228138027134720
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.086855023224655978   to: 0.085411468397279255
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.087020165033733832   to: 0.085592428970561921
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.087183150335979245   to: 0.085771051900657938
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.087344009053790500   to: 0.085947368929861323
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.087502770704625935   to: 0.086121411392349176
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.087659464405118820   to: 0.086293210217525007
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.087814118875223904   to: 0.086462795933434825
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.087966762442390864   to: 0.086630198670249459
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.088117423045760437   to: 0.086795448163807354
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.088266128240379160   to: 0.086958573759212038
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.088412905201428638   to: 0.087119604414478885
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.088557780728465763   to: 0.087278568704226067
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.088700781249670457   to: 0.087435494823404791
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.088841932826097453   to: 0.087590410591064302
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.088981261155929248   to: 0.087743343454146916
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.089118791578727000   to: 0.087894320491309547
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.089254549079676893   to: 0.088043368416767021
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.089388558293829190   to: 0.088190513584153959
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.089520843510327450   to: 0.088335781990401555
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.089651428676625927   to: 0.088479199279625748
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.089780337402692575   to: 0.088620790747023767
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.089907592965195834   to: 0.088760581342775854
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.090033218311673352   to: 0.088898595675949654
i: 100, name:           module.conv10.weight  changing lr from: 0.090157236064680693   to: 0.089034858018404009
i: 101, name:             module.conv10.bias  changing lr from: 0.090279668525918441   to: 0.089169392308690434



# Switched to train mode...
Epoch: [20][  0/391]	Time  0.210 ( 0.210)	Data  0.159 ( 0.159)	Loss 3.2428e-01 (3.2428e-01)	Acc@1  89.84 ( 89.84)	Acc@5  99.22 ( 99.22)
Epoch: [20][ 10/391]	Time  0.039 ( 0.055)	Data  0.001 ( 0.015)	Loss 4.2016e-01 (3.3614e-01)	Acc@1  85.94 ( 88.57)	Acc@5 100.00 ( 99.57)
Epoch: [20][ 20/391]	Time  0.036 ( 0.048)	Data  0.002 ( 0.009)	Loss 3.6259e-01 (3.2510e-01)	Acc@1  88.28 ( 88.65)	Acc@5  99.22 ( 99.67)
Epoch: [20][ 30/391]	Time  0.040 ( 0.045)	Data  0.001 ( 0.006)	Loss 3.1182e-01 (3.2790e-01)	Acc@1  90.62 ( 88.41)	Acc@5 100.00 ( 99.72)
Epoch: [20][ 40/391]	Time  0.043 ( 0.044)	Data  0.002 ( 0.005)	Loss 3.3793e-01 (3.2500e-01)	Acc@1  89.06 ( 88.45)	Acc@5 100.00 ( 99.75)
Epoch: [20][ 50/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.004)	Loss 4.5075e-01 (3.2625e-01)	Acc@1  87.50 ( 88.59)	Acc@5  97.66 ( 99.66)
Epoch: [20][ 60/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.004)	Loss 3.2282e-01 (3.2591e-01)	Acc@1  89.06 ( 88.55)	Acc@5 100.00 ( 99.72)
Epoch: [20][ 70/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.003)	Loss 3.5915e-01 (3.2692e-01)	Acc@1  89.06 ( 88.55)	Acc@5 100.00 ( 99.72)
Epoch: [20][ 80/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.003)	Loss 2.6469e-01 (3.2735e-01)	Acc@1  91.41 ( 88.61)	Acc@5 100.00 ( 99.71)
Epoch: [20][ 90/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.003)	Loss 2.7405e-01 (3.2648e-01)	Acc@1  90.62 ( 88.66)	Acc@5 100.00 ( 99.72)
Epoch: [20][100/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.003)	Loss 3.4018e-01 (3.2894e-01)	Acc@1  92.19 ( 88.67)	Acc@5 100.00 ( 99.68)
Epoch: [20][110/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 3.3293e-01 (3.3050e-01)	Acc@1  88.28 ( 88.59)	Acc@5 100.00 ( 99.69)
Epoch: [20][120/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.7433e-01 (3.3130e-01)	Acc@1  90.62 ( 88.55)	Acc@5  99.22 ( 99.70)
Epoch: [20][130/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.3466e-01 (3.3288e-01)	Acc@1  88.28 ( 88.47)	Acc@5  98.44 ( 99.69)
Epoch: [20][140/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.1751e-01 (3.3420e-01)	Acc@1  87.50 ( 88.39)	Acc@5 100.00 ( 99.68)
Epoch: [20][150/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.4156e-01 (3.3155e-01)	Acc@1  88.28 ( 88.55)	Acc@5 100.00 ( 99.69)
Epoch: [20][160/391]	Time  0.042 ( 0.041)	Data  0.002 ( 0.002)	Loss 3.0639e-01 (3.3131e-01)	Acc@1  90.62 ( 88.53)	Acc@5  99.22 ( 99.69)
Epoch: [20][170/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.6879e-01 (3.3440e-01)	Acc@1  89.06 ( 88.45)	Acc@5  99.22 ( 99.67)
Epoch: [20][180/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.4353e-01 (3.3466e-01)	Acc@1  89.06 ( 88.48)	Acc@5  99.22 ( 99.66)
Epoch: [20][190/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.7867e-01 (3.3611e-01)	Acc@1  89.06 ( 88.42)	Acc@5  99.22 ( 99.64)
Epoch: [20][200/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.2969e-01 (3.3392e-01)	Acc@1  89.06 ( 88.50)	Acc@5  99.22 ( 99.65)
Epoch: [20][210/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.4168e-01 (3.3379e-01)	Acc@1  88.28 ( 88.48)	Acc@5 100.00 ( 99.67)
Epoch: [20][220/391]	Time  0.052 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.7518e-01 (3.3446e-01)	Acc@1  88.28 ( 88.47)	Acc@5  99.22 ( 99.67)
Epoch: [20][230/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.1907e-01 (3.3413e-01)	Acc@1  89.84 ( 88.49)	Acc@5 100.00 ( 99.68)
Epoch: [20][240/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.1620e-01 (3.3224e-01)	Acc@1  89.84 ( 88.58)	Acc@5 100.00 ( 99.69)
Epoch: [20][250/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.4737e-01 (3.3255e-01)	Acc@1  87.50 ( 88.59)	Acc@5  99.22 ( 99.68)
Epoch: [20][260/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.8590e-01 (3.3165e-01)	Acc@1  92.19 ( 88.61)	Acc@5  99.22 ( 99.67)
Epoch: [20][270/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.1873e-01 (3.3217e-01)	Acc@1  89.06 ( 88.60)	Acc@5  99.22 ( 99.67)
Epoch: [20][280/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.1319e-01 (3.3418e-01)	Acc@1  84.38 ( 88.51)	Acc@5 100.00 ( 99.67)
Epoch: [20][290/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.2500e-01 (3.3508e-01)	Acc@1  88.28 ( 88.46)	Acc@5  99.22 ( 99.67)
Epoch: [20][300/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.8890e-01 (3.3622e-01)	Acc@1  87.50 ( 88.44)	Acc@5 100.00 ( 99.68)
Epoch: [20][310/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.6766e-01 (3.3453e-01)	Acc@1  89.84 ( 88.49)	Acc@5 100.00 ( 99.69)
Epoch: [20][320/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.4379e-01 (3.3483e-01)	Acc@1  88.28 ( 88.47)	Acc@5 100.00 ( 99.69)
Epoch: [20][330/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.1231e-01 (3.3584e-01)	Acc@1  86.72 ( 88.41)	Acc@5 100.00 ( 99.69)
Epoch: [20][340/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.001)	Loss 2.7735e-01 (3.3579e-01)	Acc@1  89.84 ( 88.40)	Acc@5 100.00 ( 99.70)
Epoch: [20][350/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.001)	Loss 3.4007e-01 (3.3521e-01)	Acc@1  91.41 ( 88.45)	Acc@5 100.00 ( 99.70)
Epoch: [20][360/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.001)	Loss 4.4894e-01 (3.3562e-01)	Acc@1  83.59 ( 88.46)	Acc@5 100.00 ( 99.70)
Epoch: [20][370/391]	Time  0.045 ( 0.041)	Data  0.001 ( 0.001)	Loss 3.0765e-01 (3.3641e-01)	Acc@1  85.94 ( 88.45)	Acc@5 100.00 ( 99.69)
Epoch: [20][380/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.001)	Loss 3.4936e-01 (3.3817e-01)	Acc@1  87.50 ( 88.39)	Acc@5  98.44 ( 99.68)
Epoch: [20][390/391]	Time  0.028 ( 0.041)	Data  0.001 ( 0.001)	Loss 3.4216e-01 (3.3787e-01)	Acc@1  90.00 ( 88.41)	Acc@5  98.75 ( 99.69)
## e[20] optimizer.zero_grad (sum) time: 0.2706303596496582
## e[20]       loss.backward (sum) time: 3.969729423522949
## e[20]      optimizer.step (sum) time: 1.8204982280731201
## epoch[20] training(only) time: 16.032667636871338
# Switched to evaluate mode...
Test: [  0/100]	Time  0.174 ( 0.174)	Loss 4.2468e-01 (4.2468e-01)	Acc@1  83.00 ( 83.00)	Acc@5  99.00 ( 99.00)
Test: [ 10/100]	Time  0.024 ( 0.036)	Loss 7.0041e-01 (4.6962e-01)	Acc@1  81.00 ( 84.91)	Acc@5 100.00 ( 99.45)
Test: [ 20/100]	Time  0.021 ( 0.029)	Loss 5.3128e-01 (4.7663e-01)	Acc@1  80.00 ( 84.24)	Acc@5 100.00 ( 99.24)
Test: [ 30/100]	Time  0.022 ( 0.026)	Loss 5.5401e-01 (4.8806e-01)	Acc@1  84.00 ( 84.45)	Acc@5  99.00 ( 99.16)
Test: [ 40/100]	Time  0.017 ( 0.025)	Loss 4.9870e-01 (4.8554e-01)	Acc@1  86.00 ( 84.63)	Acc@5  98.00 ( 99.17)
Test: [ 50/100]	Time  0.020 ( 0.024)	Loss 4.3697e-01 (4.7795e-01)	Acc@1  87.00 ( 85.00)	Acc@5  98.00 ( 99.16)
Test: [ 60/100]	Time  0.019 ( 0.024)	Loss 4.7856e-01 (4.7559e-01)	Acc@1  90.00 ( 85.07)	Acc@5  99.00 ( 99.21)
Test: [ 70/100]	Time  0.020 ( 0.023)	Loss 4.1884e-01 (4.7163e-01)	Acc@1  85.00 ( 85.03)	Acc@5 100.00 ( 99.21)
Test: [ 80/100]	Time  0.023 ( 0.023)	Loss 2.7268e-01 (4.6842e-01)	Acc@1  87.00 ( 85.06)	Acc@5 100.00 ( 99.26)
Test: [ 90/100]	Time  0.022 ( 0.023)	Loss 3.1320e-01 (4.6784e-01)	Acc@1  89.00 ( 84.99)	Acc@5 100.00 ( 99.25)
 * Acc@1 85.020 Acc@5 99.260
### epoch[20] execution time: 18.422658681869507
EPOCH 21
i:   0, name:           module.stem.0.weight  changing lr from: 0.061288860534611772   to: 0.057931648642011363
i:   1, name:             module.stem.0.bias  changing lr from: 0.061776517876351203   to: 0.058449997167167284
i:   2, name:           module.stem.1.weight  changing lr from: 0.062258372242085892   to: 0.058962495448909392
i:   3, name:             module.stem.1.bias  changing lr from: 0.062734465571493453   to: 0.059469173748153650
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.063204840957727521   to: 0.059970064062653289
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.063669542558838152   to: 0.060465200016599330
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.064128615513242976   to: 0.060954616754964087
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.064582105859091854   to: 0.061438350842414127
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.065030060457373917   to: 0.061916440166625036
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.065472526918620419   to: 0.062388923845834957
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.065909553533061771   to: 0.062855842140479415
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.066341189204102549   to: 0.063317236368754234
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.066767483384981799   to: 0.063773148825958678
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.067188486018492075   to: 0.064223622707475503
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.067604247479633575   to: 0.064668702035249201
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.068014818521085291   to: 0.065108431587628288
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.068420250221378487   to: 0.065542856832441973
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.068820593935662547   to: 0.065972023863185722
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.069215901248956532   to: 0.066395979338194813
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.069606223931784325   to: 0.066814770422688283
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.069991613898094412   to: 0.067228444733570800
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.070372123165369407   to: 0.067637050286882994
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.070747803816833696   to: 0.068040635447794817
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.071118707965671032   to: 0.068439248883040524
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.071484887721167220   to: 0.068832939515696925
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.071846395156696205   to: 0.069221756482210434
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.072203282279470954   to: 0.069605749091581598
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.072555601001983758   to: 0.069984966786619376
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.072903403115062868   to: 0.070359459107180083
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.073246740262475712   to: 0.070729275655309440
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.073585663917011448   to: 0.071094466062209136
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.073920225357978417   to: 0.071455079956952022
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.074250475650053854   to: 0.071811166936872908
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.074576465623426666   to: 0.072162776539564669
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.074898245855175696   to: 0.072509958216412027
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.075215866651828292   to: 0.072852761307597935
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.075529378033046476   to: 0.073191235018519860
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.075838829716389541   to: 0.073525428397555548
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.076144271103104816   to: 0.073855390315120534
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.076445751264898970   to: 0.074181169443961290
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.076743318931645724   to: 0.074502814240630724
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.077037022479986172   to: 0.074820372928094181
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.077326909922780518   to: 0.075133893479416361
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.077613028899371633   to: 0.075443423602481838
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.077895426666622025   to: 0.075749010725702920
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.078174150090687913   to: 0.076050701984671218
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.078449245639495124   to: 0.076348544209710378
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.078720759375883437   to: 0.076642583914289658
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.078988736951386931   to: 0.076932867284259090
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.079253223600619552   to: 0.077219440167868927
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.079514264136236190   to: 0.077502348066537385
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.079771902944441100   to: 0.077781636126332099
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.080026183981016172   to: 0.078057349130132320
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.080277150767843378   to: 0.078329531490439933
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.080524846389896099   to: 0.078598227242808891
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.080769313492675646   to: 0.078863480039863543
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.081010594280070070   to: 0.079125333145878177
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.081248730512613346   to: 0.079383829431890610
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.081483763506124018   to: 0.079639011371323898
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.081715734130703072   to: 0.079890921036091689
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.081944682810072153   to: 0.080139600093163302
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.082170649521233485   to: 0.080385089801565779
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.082393673794433991   to: 0.080627431009801187
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.082613794713416927   to: 0.080866664153658119
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.082831050915944851   to: 0.081102829254397615
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.083045480594578641   to: 0.081335965917294140
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.083257121497697706   to: 0.081566113330513140
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.083466010930747722   to: 0.081793310264308028
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.083672185757702078   to: 0.082017595070519186
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.083875682402724500   to: 0.082239005682359270
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.084076536852020489   to: 0.082457579614469256
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.084274784655865909   to: 0.082673353963230306
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.084470460930801738   to: 0.082886365407317641
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.084663600361983962   to: 0.083096650208482614
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.084854237205678917   to: 0.083304244212550019
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.085042405291893997   to: 0.083509182850618688
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.085228138027134720   to: 0.083711501140452949
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.085411468397279255   to: 0.083911233688054088
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.085592428970561921   to: 0.084108414689400918
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.085771051900657938   to: 0.084303077932348841
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.085947368929861323   to: 0.084495256798677976
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.086121411392349176   to: 0.084684984266280613
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.086293210217525007   to: 0.084872292911479130
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.086462795933434825   to: 0.085057214911465714
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.086630198670249459   to: 0.085239782046855658
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.086795448163807354   to: 0.085420025704346605
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.086958573759212038   to: 0.085597976879475957
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.087119604414478885   to: 0.085773666179469576
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.087278568704226067   to: 0.085947123826174920
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.087435494823404791   to: 0.086118379659071986
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.087590410591064302   to: 0.086287463138356210
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.087743343454146916   to: 0.086454403348087031
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.087894320491309547   to: 0.086619228999396947
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.088043368416767021   to: 0.086781968433755352
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.088190513584153959   to: 0.086942649626282245
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.088335781990401555   to: 0.087101300189107181
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.088479199279625748   to: 0.087257947374768358
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.088620790747023767   to: 0.087412618079648022
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.088760581342775854   to: 0.087565338847439653
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.088898595675949654   to: 0.087716135872643153
i: 100, name:           module.conv10.weight  changing lr from: 0.089034858018404009   to: 0.087865035004084324
i: 101, name:             module.conv10.bias  changing lr from: 0.089169392308690434   to: 0.088012061748454828



# Switched to train mode...
Epoch: [21][  0/391]	Time  0.225 ( 0.225)	Data  0.174 ( 0.174)	Loss 4.1223e-01 (4.1223e-01)	Acc@1  85.16 ( 85.16)	Acc@5 100.00 (100.00)
Epoch: [21][ 10/391]	Time  0.040 ( 0.057)	Data  0.001 ( 0.017)	Loss 2.7977e-01 (3.4342e-01)	Acc@1  87.50 ( 88.00)	Acc@5 100.00 ( 99.57)
Epoch: [21][ 20/391]	Time  0.039 ( 0.050)	Data  0.001 ( 0.009)	Loss 2.5398e-01 (3.1567e-01)	Acc@1  90.62 ( 89.29)	Acc@5  99.22 ( 99.52)
Epoch: [21][ 30/391]	Time  0.042 ( 0.047)	Data  0.001 ( 0.007)	Loss 2.8021e-01 (3.1762e-01)	Acc@1  92.19 ( 89.39)	Acc@5  99.22 ( 99.55)
Epoch: [21][ 40/391]	Time  0.042 ( 0.045)	Data  0.001 ( 0.005)	Loss 3.4208e-01 (3.2440e-01)	Acc@1  89.06 ( 88.99)	Acc@5  99.22 ( 99.54)
Epoch: [21][ 50/391]	Time  0.039 ( 0.044)	Data  0.001 ( 0.004)	Loss 3.4837e-01 (3.2774e-01)	Acc@1  87.50 ( 88.68)	Acc@5 100.00 ( 99.56)
Epoch: [21][ 60/391]	Time  0.038 ( 0.043)	Data  0.001 ( 0.004)	Loss 3.2848e-01 (3.2102e-01)	Acc@1  87.50 ( 88.96)	Acc@5 100.00 ( 99.56)
Epoch: [21][ 70/391]	Time  0.038 ( 0.043)	Data  0.001 ( 0.003)	Loss 3.2302e-01 (3.1669e-01)	Acc@1  86.72 ( 89.18)	Acc@5 100.00 ( 99.56)
Epoch: [21][ 80/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.003)	Loss 3.2855e-01 (3.1602e-01)	Acc@1  89.06 ( 89.23)	Acc@5 100.00 ( 99.59)
Epoch: [21][ 90/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.003)	Loss 3.9027e-01 (3.1688e-01)	Acc@1  85.94 ( 89.17)	Acc@5  99.22 ( 99.61)
Epoch: [21][100/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.003)	Loss 2.3774e-01 (3.1784e-01)	Acc@1  90.62 ( 89.04)	Acc@5 100.00 ( 99.63)
Epoch: [21][110/391]	Time  0.052 ( 0.042)	Data  0.001 ( 0.003)	Loss 4.1052e-01 (3.1576e-01)	Acc@1  85.16 ( 89.10)	Acc@5  98.44 ( 99.63)
Epoch: [21][120/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.002)	Loss 4.6211e-01 (3.1620e-01)	Acc@1  85.94 ( 89.11)	Acc@5  99.22 ( 99.61)
Epoch: [21][130/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 3.0093e-01 (3.1506e-01)	Acc@1  89.84 ( 89.17)	Acc@5 100.00 ( 99.62)
Epoch: [21][140/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 3.3288e-01 (3.1359e-01)	Acc@1  85.94 ( 89.15)	Acc@5 100.00 ( 99.64)
Epoch: [21][150/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 3.5728e-01 (3.1311e-01)	Acc@1  85.94 ( 89.14)	Acc@5  99.22 ( 99.64)
Epoch: [21][160/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.8694e-01 (3.1247e-01)	Acc@1  89.84 ( 89.18)	Acc@5 100.00 ( 99.63)
Epoch: [21][170/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.0988e-01 (3.1210e-01)	Acc@1  85.16 ( 89.20)	Acc@5  99.22 ( 99.62)
Epoch: [21][180/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.6505e-01 (3.1241e-01)	Acc@1  90.62 ( 89.18)	Acc@5 100.00 ( 99.62)
Epoch: [21][190/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.5731e-01 (3.1358e-01)	Acc@1  81.25 ( 89.06)	Acc@5 100.00 ( 99.64)
Epoch: [21][200/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.3124e-01 (3.1496e-01)	Acc@1  87.50 ( 88.99)	Acc@5  98.44 ( 99.63)
Epoch: [21][210/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.4986e-01 (3.1652e-01)	Acc@1  89.06 ( 88.96)	Acc@5  99.22 ( 99.63)
Epoch: [21][220/391]	Time  0.043 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.1507e-01 (3.1731e-01)	Acc@1  87.50 ( 88.92)	Acc@5  98.44 ( 99.64)
Epoch: [21][230/391]	Time  0.043 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.0386e-01 (3.1766e-01)	Acc@1  88.28 ( 88.92)	Acc@5 100.00 ( 99.64)
Epoch: [21][240/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.2301e-01 (3.1774e-01)	Acc@1  89.06 ( 88.90)	Acc@5 100.00 ( 99.65)
Epoch: [21][250/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.8490e-01 (3.1777e-01)	Acc@1  88.28 ( 88.90)	Acc@5  99.22 ( 99.65)
Epoch: [21][260/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.9529e-01 (3.1797e-01)	Acc@1  89.84 ( 88.88)	Acc@5  99.22 ( 99.64)
Epoch: [21][270/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.1886e-01 (3.1963e-01)	Acc@1  89.84 ( 88.85)	Acc@5 100.00 ( 99.65)
Epoch: [21][280/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.2462e-01 (3.2046e-01)	Acc@1  92.97 ( 88.81)	Acc@5 100.00 ( 99.63)
Epoch: [21][290/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.2664e-01 (3.2131e-01)	Acc@1  88.28 ( 88.79)	Acc@5 100.00 ( 99.64)
Epoch: [21][300/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.7144e-01 (3.2082e-01)	Acc@1  92.19 ( 88.82)	Acc@5 100.00 ( 99.64)
Epoch: [21][310/391]	Time  0.046 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.9834e-01 (3.2249e-01)	Acc@1  86.72 ( 88.76)	Acc@5  99.22 ( 99.64)
Epoch: [21][320/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.9298e-01 (3.2210e-01)	Acc@1  85.16 ( 88.76)	Acc@5 100.00 ( 99.65)
Epoch: [21][330/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.5327e-01 (3.2353e-01)	Acc@1  91.41 ( 88.71)	Acc@5 100.00 ( 99.64)
Epoch: [21][340/391]	Time  0.056 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.5701e-01 (3.2375e-01)	Acc@1  87.50 ( 88.72)	Acc@5 100.00 ( 99.65)
Epoch: [21][350/391]	Time  0.039 ( 0.041)	Data  0.002 ( 0.002)	Loss 2.6205e-01 (3.2354e-01)	Acc@1  90.62 ( 88.74)	Acc@5 100.00 ( 99.64)
Epoch: [21][360/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.001)	Loss 2.5698e-01 (3.2320e-01)	Acc@1  92.19 ( 88.76)	Acc@5 100.00 ( 99.65)
Epoch: [21][370/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.001)	Loss 1.9297e-01 (3.2323e-01)	Acc@1  92.19 ( 88.76)	Acc@5  99.22 ( 99.65)
Epoch: [21][380/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.001)	Loss 4.2655e-01 (3.2415e-01)	Acc@1  85.94 ( 88.74)	Acc@5 100.00 ( 99.65)
Epoch: [21][390/391]	Time  0.029 ( 0.041)	Data  0.001 ( 0.001)	Loss 4.8608e-01 (3.2383e-01)	Acc@1  83.75 ( 88.74)	Acc@5 100.00 ( 99.65)
## e[21] optimizer.zero_grad (sum) time: 0.2707538604736328
## e[21]       loss.backward (sum) time: 4.0121190547943115
## e[21]      optimizer.step (sum) time: 1.8229179382324219
## epoch[21] training(only) time: 16.158466339111328
# Switched to evaluate mode...
Test: [  0/100]	Time  0.170 ( 0.170)	Loss 4.5169e-01 (4.5169e-01)	Acc@1  86.00 ( 86.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.018 ( 0.033)	Loss 6.7113e-01 (5.1241e-01)	Acc@1  80.00 ( 82.64)	Acc@5 100.00 ( 99.82)
Test: [ 20/100]	Time  0.019 ( 0.026)	Loss 5.4777e-01 (5.1592e-01)	Acc@1  81.00 ( 82.57)	Acc@5 100.00 ( 99.67)
Test: [ 30/100]	Time  0.018 ( 0.025)	Loss 7.5057e-01 (5.3471e-01)	Acc@1  78.00 ( 82.84)	Acc@5  99.00 ( 99.55)
Test: [ 40/100]	Time  0.018 ( 0.023)	Loss 6.0258e-01 (5.3590e-01)	Acc@1  83.00 ( 82.93)	Acc@5  98.00 ( 99.37)
Test: [ 50/100]	Time  0.021 ( 0.023)	Loss 3.7294e-01 (5.1931e-01)	Acc@1  87.00 ( 83.27)	Acc@5 100.00 ( 99.41)
Test: [ 60/100]	Time  0.023 ( 0.022)	Loss 4.3390e-01 (5.1337e-01)	Acc@1  86.00 ( 83.36)	Acc@5 100.00 ( 99.43)
Test: [ 70/100]	Time  0.020 ( 0.022)	Loss 4.6143e-01 (5.0624e-01)	Acc@1  85.00 ( 83.46)	Acc@5 100.00 ( 99.48)
Test: [ 80/100]	Time  0.021 ( 0.022)	Loss 4.6911e-01 (5.0755e-01)	Acc@1  82.00 ( 83.57)	Acc@5 100.00 ( 99.51)
Test: [ 90/100]	Time  0.021 ( 0.022)	Loss 3.0161e-01 (5.0606e-01)	Acc@1  88.00 ( 83.57)	Acc@5 100.00 ( 99.49)
 * Acc@1 83.570 Acc@5 99.480
### epoch[21] execution time: 18.466623783111572
EPOCH 22
i:   0, name:           module.stem.0.weight  changing lr from: 0.057931648642011363   to: 0.054542230279991735
i:   1, name:             module.stem.0.bias  changing lr from: 0.058449997167167284   to: 0.055089366100652508
i:   2, name:           module.stem.1.weight  changing lr from: 0.058962495448909392   to: 0.055630691860597214
i:   3, name:             module.stem.1.bias  changing lr from: 0.059469173748153650   to: 0.056166223261340020
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.059970064062653289   to: 0.056695978405225736
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.060465200016599330   to: 0.057219977661529302
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.060954616754964087   to: 0.057738243537986761
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.061438350842414127   to: 0.058250800557571918
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.061916440166625036   to: 0.058757675140337598
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.062388923845834957   to: 0.059258895490145215
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.062855842140479415   to: 0.059754491486111463
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.063317236368754234   to: 0.060244494578605291
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.063773148825958678   to: 0.060728937689633146
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.064223622707475503   to: 0.061207855117455558
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.064668702035249201   to: 0.061681282445281864
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.065108431587628288   to: 0.062149256453895643
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.065542856832441973   to: 0.062611815038066385
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.065972023863185722   to: 0.063068997126608878
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.066395979338194813   to: 0.063520842605954725
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.066814770422688283   to: 0.063967392247105667
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.067228444733570800   to: 0.064408687635841830
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.067637050286882994   to: 0.064844771106062613
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.068040635447794817   to: 0.065275685676141226
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.068439248883040524   to: 0.065701474988178563
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.068832939515696925   to: 0.066122183250045222
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.069221756482210434   to: 0.066537855180104619
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.069605749091581598   to: 0.066948535954513069
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.069984966786619376   to: 0.067354271156997478
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.070359459107180083   to: 0.067755106731013093
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.070729275655309440   to: 0.068151088934188406
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.071094466062209136   to: 0.068542264294966682
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.071455079956952022   to: 0.068928679571357496
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.071811166936872908   to: 0.069310381711713651
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.072162776539564669   to: 0.069687417817453010
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.072509958216412027   to: 0.070059835107646823
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.072852761307597935   to: 0.070427680885398969
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.073191235018519860   to: 0.070791002505943834
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.073525428397555548   to: 0.071149847346392500
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.073855390315120534   to: 0.071504262777059777
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.074181169443961290   to: 0.071854296134307036
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.074502814240630724   to: 0.072199994694838149
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.074820372928094181   to: 0.072541405651388294
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.075133893479416361   to: 0.072878576089747224
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.075443423602481838   to: 0.073211552967061361
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.075749010725702920   to: 0.073540383091360503
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.076050701984671218   to: 0.073865113102257532
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.076348544209710378   to: 0.074185789452771086
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.076642583914289658   to: 0.074502458392223261
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.076932867284259090   to: 0.074815165950165935
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.077219440167868927   to: 0.075123957921291604
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.077502348066537385   to: 0.075428879851285657
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.077781636126332099   to: 0.075729977023579254
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.078057349130132320   to: 0.076027294446963031
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.078329531490439933   to: 0.076320876844024027
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.078598227242808891   to: 0.076610768640368934
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.078863480039863543   to: 0.076897013954598720
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.079125333145878177   to: 0.077179656589001097
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.079383829431890610   to: 0.077458740020928118
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.079639011371323898   to: 0.077734307394828173
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.079890921036091689   to: 0.078006401514901999
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.080139600093163302   to: 0.078275064838354655
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.080385089801565779   to: 0.078540339469215292
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.080627431009801187   to: 0.078802267152698655
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.080866664153658119   to: 0.079060889270082729
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.081102829254397615   to: 0.079316246834078341
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.081335965917294140   to: 0.079568380484667134
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.081566113330513140   to: 0.079817330485385599
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.081793310264308028   to: 0.080063136720033665
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.082017595070519186   to: 0.080305838689786982
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.082239005682359270   to: 0.080545475510693493
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.082457579614469256   to: 0.080782085911534782
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.082673353963230306   to: 0.081015708232034550
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.082886365407317641   to: 0.081246380421396300
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.083096650208482614   to: 0.081474140037153725
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.083304244212550019   to: 0.081699024244317839
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.083509182850618688   to: 0.081921069814805236
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.083711501140452949   to: 0.082140313127132991
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.083911233688054088   to: 0.082356790166365948
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.084108414689400918   to: 0.082570536524303101
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.084303077932348841   to: 0.082781587399889778
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.084495256798677976   to: 0.082989977599843667
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.084684984266280613   to: 0.083195741539482518
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.084872292911479130   to: 0.083398913243742379
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.085057214911465714   to: 0.083599526348375364
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.085239782046855658   to: 0.083797614101316586
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.085420025704346605   to: 0.083993209364210578
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.085597976879475957   to: 0.084186344614087236
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.085773666179469576   to: 0.084377051945178624
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.085947123826174920   to: 0.084565363070867844
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.086118379659071986   to: 0.084751309325761387
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.086287463138356210   to: 0.084934921667877555
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.086454403348087031   to: 0.085116230680942928
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.086619228999396947   to: 0.085295266576789763
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.086781968433755352   to: 0.085472059197847727
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.086942649626282245   to: 0.085646638019722707
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.087101300189107181   to: 0.085819032153857111
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.087257947374768358   to: 0.085989270350265157
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.087412618079648022   to: 0.086157381000337777
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.087565338847439653   to: 0.086323392139711144
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.087716135872643153   to: 0.086487331451194388
i: 100, name:           module.conv10.weight  changing lr from: 0.087865035004084324   to: 0.086649226267750679
i: 101, name:             module.conv10.bias  changing lr from: 0.088012061748454828   to: 0.086809103575527735



# Switched to train mode...
Epoch: [22][  0/391]	Time  0.211 ( 0.211)	Data  0.170 ( 0.170)	Loss 2.5424e-01 (2.5424e-01)	Acc@1  90.62 ( 90.62)	Acc@5 100.00 (100.00)
Epoch: [22][ 10/391]	Time  0.040 ( 0.056)	Data  0.001 ( 0.016)	Loss 2.3313e-01 (2.8220e-01)	Acc@1  92.19 ( 90.20)	Acc@5 100.00 ( 99.79)
Epoch: [22][ 20/391]	Time  0.040 ( 0.049)	Data  0.001 ( 0.009)	Loss 3.7951e-01 (2.9924e-01)	Acc@1  85.94 ( 90.07)	Acc@5 100.00 ( 99.70)
Epoch: [22][ 30/391]	Time  0.038 ( 0.046)	Data  0.001 ( 0.006)	Loss 2.8185e-01 (2.9893e-01)	Acc@1  92.19 ( 90.07)	Acc@5  99.22 ( 99.72)
Epoch: [22][ 40/391]	Time  0.039 ( 0.045)	Data  0.001 ( 0.005)	Loss 2.5461e-01 (2.9944e-01)	Acc@1  89.84 ( 89.92)	Acc@5 100.00 ( 99.77)
Epoch: [22][ 50/391]	Time  0.041 ( 0.044)	Data  0.001 ( 0.004)	Loss 3.0813e-01 (2.9812e-01)	Acc@1  89.06 ( 89.72)	Acc@5 100.00 ( 99.79)
Epoch: [22][ 60/391]	Time  0.042 ( 0.044)	Data  0.001 ( 0.004)	Loss 2.4803e-01 (2.9088e-01)	Acc@1  89.84 ( 90.07)	Acc@5 100.00 ( 99.74)
Epoch: [22][ 70/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.003)	Loss 3.8327e-01 (2.9654e-01)	Acc@1  87.50 ( 89.80)	Acc@5 100.00 ( 99.74)
Epoch: [22][ 80/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.003)	Loss 3.5338e-01 (2.9747e-01)	Acc@1  88.28 ( 89.79)	Acc@5 100.00 ( 99.74)
Epoch: [22][ 90/391]	Time  0.038 ( 0.043)	Data  0.001 ( 0.003)	Loss 2.0107e-01 (2.9773e-01)	Acc@1  90.62 ( 89.72)	Acc@5 100.00 ( 99.76)
Epoch: [22][100/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.003)	Loss 2.4374e-01 (2.9717e-01)	Acc@1  92.97 ( 89.71)	Acc@5  99.22 ( 99.76)
Epoch: [22][110/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.6644e-01 (2.9714e-01)	Acc@1  89.84 ( 89.68)	Acc@5  99.22 ( 99.75)
Epoch: [22][120/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 3.2685e-01 (2.9572e-01)	Acc@1  85.94 ( 89.73)	Acc@5 100.00 ( 99.75)
Epoch: [22][130/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.1335e-01 (2.9581e-01)	Acc@1  92.19 ( 89.65)	Acc@5 100.00 ( 99.76)
Epoch: [22][140/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.3945e-01 (2.9565e-01)	Acc@1  92.97 ( 89.65)	Acc@5 100.00 ( 99.76)
Epoch: [22][150/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.002)	Loss 4.1283e-01 (2.9621e-01)	Acc@1  88.28 ( 89.60)	Acc@5  99.22 ( 99.77)
Epoch: [22][160/391]	Time  0.041 ( 0.042)	Data  0.002 ( 0.002)	Loss 3.2460e-01 (2.9912e-01)	Acc@1  91.41 ( 89.52)	Acc@5 100.00 ( 99.78)
Epoch: [22][170/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 3.9336e-01 (2.9900e-01)	Acc@1  84.38 ( 89.50)	Acc@5 100.00 ( 99.79)
Epoch: [22][180/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 3.1735e-01 (3.0081e-01)	Acc@1  85.94 ( 89.44)	Acc@5 100.00 ( 99.79)
Epoch: [22][190/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 3.5544e-01 (3.0078e-01)	Acc@1  89.06 ( 89.45)	Acc@5  99.22 ( 99.79)
Epoch: [22][200/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.5337e-01 (3.0027e-01)	Acc@1  91.41 ( 89.48)	Acc@5 100.00 ( 99.79)
Epoch: [22][210/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.8107e-01 (3.0084e-01)	Acc@1  86.72 ( 89.44)	Acc@5 100.00 ( 99.79)
Epoch: [22][220/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 3.5249e-01 (3.0302e-01)	Acc@1  91.41 ( 89.39)	Acc@5  99.22 ( 99.78)
Epoch: [22][230/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 3.2693e-01 (3.0519e-01)	Acc@1  89.06 ( 89.30)	Acc@5 100.00 ( 99.77)
Epoch: [22][240/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.9022e-01 (3.0585e-01)	Acc@1  89.84 ( 89.30)	Acc@5 100.00 ( 99.76)
Epoch: [22][250/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.1465e-01 (3.0564e-01)	Acc@1  86.72 ( 89.32)	Acc@5 100.00 ( 99.74)
Epoch: [22][260/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.6939e-01 (3.0530e-01)	Acc@1  90.62 ( 89.33)	Acc@5 100.00 ( 99.75)
Epoch: [22][270/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.4645e-01 (3.0526e-01)	Acc@1  92.19 ( 89.36)	Acc@5 100.00 ( 99.75)
Epoch: [22][280/391]	Time  0.044 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.4372e-01 (3.0578e-01)	Acc@1  87.50 ( 89.39)	Acc@5 100.00 ( 99.75)
Epoch: [22][290/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.8682e-01 (3.0618e-01)	Acc@1  87.50 ( 89.37)	Acc@5  99.22 ( 99.75)
Epoch: [22][300/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.7501e-01 (3.0722e-01)	Acc@1  93.75 ( 89.34)	Acc@5  99.22 ( 99.75)
Epoch: [22][310/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.5451e-01 (3.0739e-01)	Acc@1  91.41 ( 89.33)	Acc@5  99.22 ( 99.74)
Epoch: [22][320/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.7553e-01 (3.0856e-01)	Acc@1  88.28 ( 89.30)	Acc@5  99.22 ( 99.74)
Epoch: [22][330/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.8490e-01 (3.0875e-01)	Acc@1  89.84 ( 89.28)	Acc@5 100.00 ( 99.74)
Epoch: [22][340/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.001)	Loss 3.4719e-01 (3.0909e-01)	Acc@1  89.06 ( 89.27)	Acc@5 100.00 ( 99.74)
Epoch: [22][350/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.001)	Loss 4.6299e-01 (3.0927e-01)	Acc@1  84.38 ( 89.26)	Acc@5  99.22 ( 99.74)
Epoch: [22][360/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.001)	Loss 5.0841e-01 (3.0929e-01)	Acc@1  82.81 ( 89.27)	Acc@5  99.22 ( 99.74)
Epoch: [22][370/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.001)	Loss 3.9651e-01 (3.0984e-01)	Acc@1  86.72 ( 89.25)	Acc@5 100.00 ( 99.74)
Epoch: [22][380/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.001)	Loss 2.8513e-01 (3.1033e-01)	Acc@1  91.41 ( 89.21)	Acc@5  99.22 ( 99.74)
Epoch: [22][390/391]	Time  0.028 ( 0.041)	Data  0.001 ( 0.001)	Loss 3.4637e-01 (3.1020e-01)	Acc@1  88.75 ( 89.22)	Acc@5 100.00 ( 99.74)
## e[22] optimizer.zero_grad (sum) time: 0.2713625431060791
## e[22]       loss.backward (sum) time: 4.044296741485596
## e[22]      optimizer.step (sum) time: 1.809433937072754
## epoch[22] training(only) time: 16.220682382583618
# Switched to evaluate mode...
Test: [  0/100]	Time  0.176 ( 0.176)	Loss 3.9270e-01 (3.9270e-01)	Acc@1  87.00 ( 87.00)	Acc@5  99.00 ( 99.00)
Test: [ 10/100]	Time  0.017 ( 0.036)	Loss 5.8401e-01 (4.2025e-01)	Acc@1  82.00 ( 86.27)	Acc@5 100.00 ( 99.64)
Test: [ 20/100]	Time  0.022 ( 0.029)	Loss 4.7831e-01 (4.3743e-01)	Acc@1  82.00 ( 85.62)	Acc@5 100.00 ( 99.52)
Test: [ 30/100]	Time  0.022 ( 0.027)	Loss 5.5859e-01 (4.6134e-01)	Acc@1  82.00 ( 85.55)	Acc@5 100.00 ( 99.52)
Test: [ 40/100]	Time  0.021 ( 0.025)	Loss 4.1292e-01 (4.6802e-01)	Acc@1  84.00 ( 85.22)	Acc@5  98.00 ( 99.44)
Test: [ 50/100]	Time  0.021 ( 0.024)	Loss 2.7180e-01 (4.6069e-01)	Acc@1  88.00 ( 85.61)	Acc@5 100.00 ( 99.41)
Test: [ 60/100]	Time  0.019 ( 0.023)	Loss 4.3600e-01 (4.6104e-01)	Acc@1  86.00 ( 85.52)	Acc@5 100.00 ( 99.38)
Test: [ 70/100]	Time  0.024 ( 0.023)	Loss 4.4040e-01 (4.5592e-01)	Acc@1  84.00 ( 85.58)	Acc@5 100.00 ( 99.34)
Test: [ 80/100]	Time  0.017 ( 0.022)	Loss 4.6746e-01 (4.5687e-01)	Acc@1  83.00 ( 85.44)	Acc@5 100.00 ( 99.36)
Test: [ 90/100]	Time  0.021 ( 0.022)	Loss 2.9441e-01 (4.5674e-01)	Acc@1  90.00 ( 85.36)	Acc@5 100.00 ( 99.37)
 * Acc@1 85.420 Acc@5 99.390
### epoch[22] execution time: 18.513715028762817
EPOCH 23
i:   0, name:           module.stem.0.weight  changing lr from: 0.054542230279991735   to: 0.051136353678802732
i:   1, name:             module.stem.0.bias  changing lr from: 0.055089366100652508   to: 0.051710011572125542
i:   2, name:           module.stem.1.weight  changing lr from: 0.055630691860597214   to: 0.052277994581496824
i:   3, name:             module.stem.1.bias  changing lr from: 0.056166223261340020   to: 0.052840300868527638
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.056695978405225736   to: 0.053396931737493561
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.057219977661529302   to: 0.053947891476622378
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.057738243537986761   to: 0.054493187205473276
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.058250800557571918   to: 0.055032828728213690
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.058757675140337598   to: 0.055566828392604434
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.059258895490145215   to: 0.056095200954507533
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.059754491486111463   to: 0.056617963447736112
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.060244494578605291   to: 0.057135135059069045
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.060728937689633146   to: 0.057646737008258148
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.061207855117455558   to: 0.058152792432859750
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.061681282445281864   to: 0.058653326277726472
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.062149256453895643   to: 0.059148365189000011
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.062611815038066385   to: 0.059637937412449174
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.063068997126608878   to: 0.060122072696002532
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.063520842605954725   to: 0.060600802196328421
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.063967392247105667   to: 0.061074158389319767
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.064408687635841830   to: 0.061542174984345027
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.064844771106062613   to: 0.062004886842130694
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.065275685676141226   to: 0.062462329896144711
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.065701474988178563   to: 0.062914541077354225
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.066122183250045222   to: 0.063361558242234661
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.066537855180104619   to: 0.063803420103911115
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.066948535954513069   to: 0.064240166166316823
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.067354271156997478   to: 0.064671836661256879
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.067755106731013093   to: 0.065098472488268902
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.068151088934188406   to: 0.065520115157176137
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.068542264294966682   to: 0.065936806733231434
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.068928679571357496   to: 0.066348589784754400
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.069310381711713651   to: 0.066755507333166514
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.069687417817453010   to: 0.067157602805332881
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.070059835107646823   to: 0.067554919988121964
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.070427680885398969   to: 0.067947502985097594
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.070791002505943834   to: 0.068335396175260618
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.071149847346392500   to: 0.068718644173760446
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.071504262777059777   to: 0.069097291794499124
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.071854296134307036   to: 0.069471384014553800
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.072199994694838149   to: 0.069840965940345306
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.072541405651388294   to: 0.070206082775484166
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.072878576089747224   to: 0.070566779790226283
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.073211552967061361   to: 0.070923102292474588
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.073540383091360503   to: 0.071275095600263932
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.073865113102257532   to: 0.071622805015669450
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.074185789452771086   to: 0.071966275800080359
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.074502458392223261   to: 0.072305553150783797
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.074815165950165935   to: 0.072640682178804525
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.075123957921291604   to: 0.072971707887949197
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.075428879851285657   to: 0.073298675155004947
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.075729977023579254   to: 0.073621628711044537
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.076027294446963031   to: 0.073940613123791729
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.076320876844024027   to: 0.074255672781002327
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.076610768640368934   to: 0.074566851874818138
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.076897013954598720   to: 0.074874194387052256
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.077179656589001097   to: 0.075177744075366634
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.077458740020928118   to: 0.075477544460302859
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.077734307394828173   to: 0.075773638813130234
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.078006401514901999   to: 0.076066070144474945
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.078275064838354655   to: 0.076354881193697210
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.078540339469215292   to: 0.076640114418982941
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.078802267152698655   to: 0.076921811988118760
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.079060889270082729   to: 0.077200015769920305
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.079316246834078341   to: 0.077474767326284388
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.079568380484667134   to: 0.077746107904837353
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.079817330485385599   to: 0.078014078432152759
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.080063136720033665   to: 0.078278719507512307
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.080305838689786982   to: 0.078540071397185662
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.080545475510693493   to: 0.078798174029204998
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.080782085911534782   to: 0.079053066988611545
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.081015708232034550   to: 0.079304789513152271
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.081246380421396300   to: 0.079553380489405301
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.081474140037153725   to: 0.079798878449314214
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.081699024244317839   to: 0.080041321567111523
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.081921069814805236   to: 0.080280747656612750
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.082140313127132991   to: 0.080517194168863215
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.082356790166365948   to: 0.080750698190120263
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.082570536524303101   to: 0.080981296440154726
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.082781587399889778   to: 0.081209025270855481
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.082989977599843667   to: 0.081433920665121950
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.083195741539482518   to: 0.081656018236030484
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.083398913243742379   to: 0.081875353226259995
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.083599526348375364   to: 0.082091960507764017
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.083797614101316586   to: 0.082305874581676056
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.083993209364210578   to: 0.082517129578436113
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.084186344614087236   to: 0.082725759258126697
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.084377051945178624   to: 0.082931797011006669
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.084565363070867844   to: 0.083135275858232660
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.084751309325761387   to: 0.083336228452757358
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.084934921667877555   to: 0.083534687080394687
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.085116230680942928   to: 0.083730683661042860
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.085295266576789763   to: 0.083924249750055663
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.085472059197847727   to: 0.084115416539753796
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.085646638019722707   to: 0.084304214861067428
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.085819032153857111   to: 0.084490675185302677
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.085989270350265157   to: 0.084674827626023658
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.086157381000337777   to: 0.084856701941043555
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.086323392139711144   to: 0.085036327534517162
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.086487331451194388   to: 0.085213733459128596
i: 100, name:           module.conv10.weight  changing lr from: 0.086649226267750679   to: 0.085388948418367805
i: 101, name:             module.conv10.bias  changing lr from: 0.086809103575527735   to: 0.085562000768889646



# Switched to train mode...
Epoch: [23][  0/391]	Time  0.210 ( 0.210)	Data  0.170 ( 0.170)	Loss 3.1163e-01 (3.1163e-01)	Acc@1  87.50 ( 87.50)	Acc@5 100.00 (100.00)
Epoch: [23][ 10/391]	Time  0.041 ( 0.056)	Data  0.001 ( 0.016)	Loss 2.2837e-01 (2.7972e-01)	Acc@1  91.41 ( 90.48)	Acc@5 100.00 ( 99.86)
Epoch: [23][ 20/391]	Time  0.040 ( 0.049)	Data  0.001 ( 0.009)	Loss 3.3375e-01 (2.9585e-01)	Acc@1  88.28 ( 89.77)	Acc@5 100.00 ( 99.89)
Epoch: [23][ 30/391]	Time  0.039 ( 0.046)	Data  0.001 ( 0.006)	Loss 3.1738e-01 (3.0095e-01)	Acc@1  87.50 ( 89.69)	Acc@5 100.00 ( 99.82)
Epoch: [23][ 40/391]	Time  0.040 ( 0.045)	Data  0.001 ( 0.005)	Loss 2.8292e-01 (2.9861e-01)	Acc@1  90.62 ( 89.96)	Acc@5  98.44 ( 99.73)
Epoch: [23][ 50/391]	Time  0.042 ( 0.044)	Data  0.001 ( 0.004)	Loss 4.2180e-01 (3.0079e-01)	Acc@1  86.72 ( 89.83)	Acc@5  99.22 ( 99.71)
Epoch: [23][ 60/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.004)	Loss 3.5615e-01 (2.9646e-01)	Acc@1  85.16 ( 90.02)	Acc@5 100.00 ( 99.69)
Epoch: [23][ 70/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.003)	Loss 2.5490e-01 (3.0000e-01)	Acc@1  89.84 ( 89.84)	Acc@5 100.00 ( 99.69)
Epoch: [23][ 80/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.003)	Loss 2.7002e-01 (2.9957e-01)	Acc@1  90.62 ( 89.88)	Acc@5 100.00 ( 99.68)
Epoch: [23][ 90/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.003)	Loss 3.5664e-01 (3.0121e-01)	Acc@1  86.72 ( 89.82)	Acc@5 100.00 ( 99.68)
Epoch: [23][100/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.003)	Loss 3.1618e-01 (3.0049e-01)	Acc@1  87.50 ( 89.76)	Acc@5 100.00 ( 99.69)
Epoch: [23][110/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.1151e-01 (2.9985e-01)	Acc@1  94.53 ( 89.79)	Acc@5 100.00 ( 99.69)
Epoch: [23][120/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.9988e-01 (3.0106e-01)	Acc@1  89.84 ( 89.75)	Acc@5  99.22 ( 99.69)
Epoch: [23][130/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.6675e-01 (3.0419e-01)	Acc@1  89.84 ( 89.65)	Acc@5  99.22 ( 99.66)
Epoch: [23][140/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.2057e-01 (3.0390e-01)	Acc@1  91.41 ( 89.66)	Acc@5 100.00 ( 99.67)
Epoch: [23][150/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.1146e-01 (3.0295e-01)	Acc@1  88.28 ( 89.61)	Acc@5 100.00 ( 99.68)
Epoch: [23][160/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.7172e-01 (3.0451e-01)	Acc@1  90.62 ( 89.52)	Acc@5 100.00 ( 99.69)
Epoch: [23][170/391]	Time  0.037 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.0429e-01 (3.0359e-01)	Acc@1  85.94 ( 89.54)	Acc@5 100.00 ( 99.69)
Epoch: [23][180/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.2695e-01 (3.0455e-01)	Acc@1  80.47 ( 89.51)	Acc@5 100.00 ( 99.69)
Epoch: [23][190/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.6988e-01 (3.0523e-01)	Acc@1  88.28 ( 89.45)	Acc@5 100.00 ( 99.69)
Epoch: [23][200/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.7732e-01 (3.0545e-01)	Acc@1  91.41 ( 89.42)	Acc@5 100.00 ( 99.69)
Epoch: [23][210/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.4314e-01 (3.0576e-01)	Acc@1  90.62 ( 89.45)	Acc@5 100.00 ( 99.69)
Epoch: [23][220/391]	Time  0.045 ( 0.041)	Data  0.002 ( 0.002)	Loss 3.4221e-01 (3.0588e-01)	Acc@1  88.28 ( 89.48)	Acc@5 100.00 ( 99.70)
Epoch: [23][230/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.4050e-01 (3.0643e-01)	Acc@1  87.50 ( 89.44)	Acc@5 100.00 ( 99.71)
Epoch: [23][240/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.8890e-01 (3.0535e-01)	Acc@1  92.97 ( 89.44)	Acc@5 100.00 ( 99.71)
Epoch: [23][250/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.2283e-01 (3.0722e-01)	Acc@1  85.94 ( 89.36)	Acc@5 100.00 ( 99.70)
Epoch: [23][260/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.8517e-01 (3.0835e-01)	Acc@1  87.50 ( 89.27)	Acc@5  99.22 ( 99.71)
Epoch: [23][270/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.5553e-01 (3.1007e-01)	Acc@1  87.50 ( 89.21)	Acc@5 100.00 ( 99.71)
Epoch: [23][280/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.7585e-01 (3.1037e-01)	Acc@1  88.28 ( 89.19)	Acc@5 100.00 ( 99.71)
Epoch: [23][290/391]	Time  0.043 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.4488e-01 (3.1049e-01)	Acc@1  92.19 ( 89.16)	Acc@5 100.00 ( 99.72)
Epoch: [23][300/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.0378e-01 (3.0918e-01)	Acc@1  93.75 ( 89.20)	Acc@5 100.00 ( 99.72)
Epoch: [23][310/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.8093e-01 (3.0940e-01)	Acc@1  89.06 ( 89.19)	Acc@5 100.00 ( 99.72)
Epoch: [23][320/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.8526e-01 (3.1066e-01)	Acc@1  92.19 ( 89.14)	Acc@5 100.00 ( 99.72)
Epoch: [23][330/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.5818e-01 (3.1054e-01)	Acc@1  92.97 ( 89.19)	Acc@5  99.22 ( 99.72)
Epoch: [23][340/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.8569e-01 (3.1019e-01)	Acc@1  92.97 ( 89.21)	Acc@5 100.00 ( 99.72)
Epoch: [23][350/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.2108e-01 (3.1004e-01)	Acc@1  87.50 ( 89.19)	Acc@5 100.00 ( 99.72)
Epoch: [23][360/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.001)	Loss 4.3117e-01 (3.1051e-01)	Acc@1  85.94 ( 89.17)	Acc@5  99.22 ( 99.72)
Epoch: [23][370/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.001)	Loss 2.9073e-01 (3.1050e-01)	Acc@1  90.62 ( 89.17)	Acc@5 100.00 ( 99.71)
Epoch: [23][380/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.001)	Loss 3.8227e-01 (3.0992e-01)	Acc@1  85.16 ( 89.20)	Acc@5  99.22 ( 99.71)
Epoch: [23][390/391]	Time  0.028 ( 0.041)	Data  0.001 ( 0.001)	Loss 4.0275e-01 (3.1003e-01)	Acc@1  85.00 ( 89.18)	Acc@5  98.75 ( 99.71)
## e[23] optimizer.zero_grad (sum) time: 0.27115488052368164
## e[23]       loss.backward (sum) time: 3.9818599224090576
## e[23]      optimizer.step (sum) time: 1.851515531539917
## epoch[23] training(only) time: 15.99834394454956
# Switched to evaluate mode...
Test: [  0/100]	Time  0.172 ( 0.172)	Loss 3.1083e-01 (3.1083e-01)	Acc@1  90.00 ( 90.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.022 ( 0.033)	Loss 4.4211e-01 (4.6231e-01)	Acc@1  87.00 ( 85.82)	Acc@5  99.00 ( 99.55)
Test: [ 20/100]	Time  0.022 ( 0.027)	Loss 5.6267e-01 (4.5429e-01)	Acc@1  79.00 ( 85.05)	Acc@5 100.00 ( 99.33)
Test: [ 30/100]	Time  0.018 ( 0.025)	Loss 4.7027e-01 (4.6547e-01)	Acc@1  87.00 ( 85.45)	Acc@5  98.00 ( 99.35)
Test: [ 40/100]	Time  0.018 ( 0.024)	Loss 4.0131e-01 (4.5886e-01)	Acc@1  86.00 ( 85.61)	Acc@5  99.00 ( 99.39)
Test: [ 50/100]	Time  0.018 ( 0.023)	Loss 3.7452e-01 (4.4632e-01)	Acc@1  88.00 ( 85.94)	Acc@5  99.00 ( 99.39)
Test: [ 60/100]	Time  0.024 ( 0.023)	Loss 5.2414e-01 (4.4462e-01)	Acc@1  85.00 ( 85.95)	Acc@5 100.00 ( 99.43)
Test: [ 70/100]	Time  0.018 ( 0.023)	Loss 4.1012e-01 (4.3683e-01)	Acc@1  86.00 ( 86.13)	Acc@5  99.00 ( 99.41)
Test: [ 80/100]	Time  0.022 ( 0.023)	Loss 3.6031e-01 (4.3076e-01)	Acc@1  84.00 ( 85.99)	Acc@5 100.00 ( 99.42)
Test: [ 90/100]	Time  0.023 ( 0.023)	Loss 1.8332e-01 (4.2629e-01)	Acc@1  95.00 ( 86.07)	Acc@5 100.00 ( 99.44)
 * Acc@1 86.060 Acc@5 99.430
### epoch[23] execution time: 18.348973274230957
EPOCH 24
i:   0, name:           module.stem.0.weight  changing lr from: 0.051136353678802732   to: 0.047729843538492883
i:   1, name:             module.stem.0.bias  changing lr from: 0.051710011572125542   to: 0.048327406203646464
i:   2, name:           module.stem.1.weight  changing lr from: 0.052277994581496824   to: 0.048919530988329608
i:   3, name:             module.stem.1.bias  changing lr from: 0.052840300868527638   to: 0.049506195473080113
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.053396931737493561   to: 0.050087381196055658
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.053947891476622378   to: 0.050663073468658393
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.054493187205473276   to: 0.051233261197852466
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.055032828728213690   to: 0.051797936714979675
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.055566828392604434   to: 0.052357095610881504
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.056095200954507533   to: 0.052910736577138621
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.056617963447736112   to: 0.053458861253242840
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.057135135059069045   to: 0.054001474079519232
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.057646737008258148   to: 0.054538582155619776
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.058152792432859750   to: 0.055070195104414049
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.058653326277726472   to: 0.055596324941105203
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.059148365189000011   to: 0.056116985947404441
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.059637937412449174   to: 0.056632194550599514
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.060122072696002532   to: 0.057141969207358229
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.060600802196328421   to: 0.057646330292110248
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.061074158389319767   to: 0.058145299989855584
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.061542174984345027   to: 0.058638902193250887
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.062004886842130694   to: 0.059127162403829703
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.062462329896144711   to: 0.059610107637215463
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.062914541077354225   to: 0.060087766332190651
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.063361558242234661   to: 0.060560168263488957
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.063803420103911115   to: 0.061027344458180754
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.064240166166316823   to: 0.061489327115526515
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.064671836661256879   to: 0.061946149530175777
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.065098472488268902   to: 0.062397846018593106
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.065520115157176137   to: 0.062844451848595911
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.065936806733231434   to: 0.063286003171892688
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.066348589784754400   to: 0.063722536959513160
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.066755507333166514   to: 0.064154090940025443
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.067157602805332881   to: 0.064580703540438808
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.067554919988121964   to: 0.065002413829692990
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.067947502985097594   to: 0.065419261464639014
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.068335396175260618   to: 0.065831286638419140
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.068718644173760446   to: 0.066238530031156428
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.069097291794499124   to: 0.066641032762867286
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.069471384014553800   to: 0.067038836348513556
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.069840965940345306   to: 0.067431982655113229
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.070206082775484166   to: 0.067820513860831266
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.070566779790226283   to: 0.068204472415975034
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.070923102292474588   to: 0.068583901005821485
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.071275095600263932   to: 0.068958842515205163
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.071622805015669450   to: 0.069329339994798983
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.071966275800080359   to: 0.069695436629021751
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.072305553150783797   to: 0.070057175705509289
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.072640682178804525   to: 0.070414600586087131
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.072971707887949197   to: 0.070767754679186029
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.073298675155004947   to: 0.071116681413642913
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.073621628711044537   to: 0.071461424213832198
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.073940613123791729   to: 0.071802026476074074
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.074255672781002327   to: 0.072138531546268855
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.074566851874818138   to: 0.072470982698707470
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.074874194387052256   to: 0.072799423116010620
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.075177744075366634   to: 0.073123895870150779
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.075477544460302859   to: 0.073444443904512324
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.075773638813130234   to: 0.073761110016947504
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.076066070144474945   to: 0.074073936843786867
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.076354881193697210   to: 0.074382966844764697
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.076640114418982941   to: 0.074688242288821080
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.076921811988118760   to: 0.074989805240744084
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.077200015769920305   to: 0.075287697548616403
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.077474767326284388   to: 0.075581960832032821
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.077746107904837353   to: 0.075872636471055119
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.078014078432152759   to: 0.076159765595873410
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.078278719507512307   to: 0.076443389077143140
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.078540071397185662   to: 0.076723547516968874
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.078798174029204998   to: 0.077000281240506396
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.079053066988611545   to: 0.077273630288156397
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.079304789513152271   to: 0.077543634408323445
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.079553380489405301   to: 0.077810333050715608
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.079798878449314214   to: 0.078073765360160280
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.080041321567111523   to: 0.078333970170913370
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.080280747656612750   to: 0.078590986001439461
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.080517194168863215   to: 0.078844851049641743
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.080750698190120263   to: 0.079095603188521046
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.080981296440154726   to: 0.079343279962244315
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.081209025270855481   to: 0.079587918582603556
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.081433920665121950   to: 0.079829555925847132
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.081656018236030484   to: 0.080068228529865823
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.081875353226259995   to: 0.080303972591716871
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.082091960507764017   to: 0.080536823965469961
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.082305874581676056   to: 0.080766818160359605
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.082517129578436113   to: 0.080993990339229105
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.082725759258126697   to: 0.081218375317251734
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.082931797011006669   to: 0.081440007560915656
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.083135275858232660   to: 0.081658921187259259
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.083336228452757358   to: 0.081875149963344371
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.083534687080394687   to: 0.082088727305955234
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.083730683661042860   to: 0.082299686281511852
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.083924249750055663   to: 0.082508059606186221
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.084115416539753796   to: 0.082713879646211186
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.084304214861067428   to: 0.082917178418371387
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.084490675185302677   to: 0.083117987590666728
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.084674827626023658   to: 0.083316338483138852
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.084856701941043555   to: 0.083512262068851692
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.085036327534517162   to: 0.083705788975017473
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.085213733459128596   to: 0.083896949484259881
i: 100, name:           module.conv10.weight  changing lr from: 0.085388948418367805   to: 0.084085773536006575
i: 101, name:             module.conv10.bias  changing lr from: 0.085562000768889646   to: 0.084272290728003352



# Switched to train mode...
Epoch: [24][  0/391]	Time  0.217 ( 0.217)	Data  0.174 ( 0.174)	Loss 3.0022e-01 (3.0022e-01)	Acc@1  89.84 ( 89.84)	Acc@5 100.00 (100.00)
Epoch: [24][ 10/391]	Time  0.039 ( 0.057)	Data  0.001 ( 0.017)	Loss 3.1143e-01 (2.9473e-01)	Acc@1  86.72 ( 88.85)	Acc@5 100.00 ( 99.79)
Epoch: [24][ 20/391]	Time  0.041 ( 0.049)	Data  0.001 ( 0.009)	Loss 2.8608e-01 (3.0535e-01)	Acc@1  92.97 ( 88.73)	Acc@5 100.00 ( 99.70)
Epoch: [24][ 30/391]	Time  0.038 ( 0.046)	Data  0.001 ( 0.006)	Loss 2.6543e-01 (3.0591e-01)	Acc@1  87.50 ( 88.79)	Acc@5 100.00 ( 99.77)
Epoch: [24][ 40/391]	Time  0.045 ( 0.044)	Data  0.001 ( 0.005)	Loss 2.5902e-01 (3.0215e-01)	Acc@1  89.06 ( 89.04)	Acc@5 100.00 ( 99.81)
Epoch: [24][ 50/391]	Time  0.041 ( 0.044)	Data  0.001 ( 0.004)	Loss 2.3515e-01 (2.9845e-01)	Acc@1  92.97 ( 89.25)	Acc@5 100.00 ( 99.83)
Epoch: [24][ 60/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.004)	Loss 2.9127e-01 (3.0088e-01)	Acc@1  89.06 ( 89.10)	Acc@5  99.22 ( 99.78)
Epoch: [24][ 70/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.003)	Loss 3.0401e-01 (2.9891e-01)	Acc@1  90.62 ( 89.13)	Acc@5  99.22 ( 99.78)
Epoch: [24][ 80/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.003)	Loss 2.9495e-01 (2.9905e-01)	Acc@1  89.06 ( 89.22)	Acc@5 100.00 ( 99.77)
Epoch: [24][ 90/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.003)	Loss 3.0305e-01 (2.9550e-01)	Acc@1  89.84 ( 89.43)	Acc@5 100.00 ( 99.76)
Epoch: [24][100/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.003)	Loss 2.7714e-01 (2.9570e-01)	Acc@1  92.19 ( 89.46)	Acc@5 100.00 ( 99.75)
Epoch: [24][110/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.003)	Loss 3.0620e-01 (2.9590e-01)	Acc@1  90.62 ( 89.51)	Acc@5  99.22 ( 99.72)
Epoch: [24][120/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.002)	Loss 3.4282e-01 (2.9676e-01)	Acc@1  89.84 ( 89.50)	Acc@5  99.22 ( 99.72)
Epoch: [24][130/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.0495e-01 (2.9498e-01)	Acc@1  92.97 ( 89.57)	Acc@5 100.00 ( 99.74)
Epoch: [24][140/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.3078e-01 (2.9325e-01)	Acc@1  91.41 ( 89.64)	Acc@5  99.22 ( 99.74)
Epoch: [24][150/391]	Time  0.042 ( 0.041)	Data  0.002 ( 0.002)	Loss 3.1383e-01 (2.9191e-01)	Acc@1  89.06 ( 89.72)	Acc@5  99.22 ( 99.73)
Epoch: [24][160/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.3444e-01 (2.9139e-01)	Acc@1  91.41 ( 89.79)	Acc@5 100.00 ( 99.72)
Epoch: [24][170/391]	Time  0.041 ( 0.041)	Data  0.002 ( 0.002)	Loss 2.1863e-01 (2.9069e-01)	Acc@1  93.75 ( 89.81)	Acc@5  99.22 ( 99.73)
Epoch: [24][180/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.2571e-01 (2.9058e-01)	Acc@1  92.19 ( 89.80)	Acc@5 100.00 ( 99.72)
Epoch: [24][190/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.1891e-01 (2.9147e-01)	Acc@1  89.84 ( 89.77)	Acc@5 100.00 ( 99.73)
Epoch: [24][200/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.6796e-01 (2.9087e-01)	Acc@1  92.97 ( 89.84)	Acc@5 100.00 ( 99.73)
Epoch: [24][210/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.4108e-01 (2.9068e-01)	Acc@1  89.84 ( 89.86)	Acc@5 100.00 ( 99.73)
Epoch: [24][220/391]	Time  0.043 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.7244e-01 (2.9093e-01)	Acc@1  92.19 ( 89.85)	Acc@5 100.00 ( 99.73)
Epoch: [24][230/391]	Time  0.041 ( 0.041)	Data  0.002 ( 0.002)	Loss 3.2425e-01 (2.9134e-01)	Acc@1  90.62 ( 89.84)	Acc@5  99.22 ( 99.73)
Epoch: [24][240/391]	Time  0.044 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.3760e-01 (2.9274e-01)	Acc@1  85.94 ( 89.77)	Acc@5 100.00 ( 99.73)
Epoch: [24][250/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.9508e-01 (2.9261e-01)	Acc@1  85.16 ( 89.76)	Acc@5  99.22 ( 99.74)
Epoch: [24][260/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.8913e-01 (2.9403e-01)	Acc@1  85.94 ( 89.72)	Acc@5 100.00 ( 99.73)
Epoch: [24][270/391]	Time  0.044 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.8892e-01 (2.9533e-01)	Acc@1  88.28 ( 89.67)	Acc@5 100.00 ( 99.73)
Epoch: [24][280/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.8817e-01 (2.9539e-01)	Acc@1  83.59 ( 89.65)	Acc@5 100.00 ( 99.73)
Epoch: [24][290/391]	Time  0.043 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.2360e-01 (2.9462e-01)	Acc@1  90.62 ( 89.66)	Acc@5  98.44 ( 99.73)
Epoch: [24][300/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.3684e-01 (2.9431e-01)	Acc@1  92.19 ( 89.66)	Acc@5 100.00 ( 99.74)
Epoch: [24][310/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.8475e-01 (2.9429e-01)	Acc@1  89.06 ( 89.67)	Acc@5 100.00 ( 99.74)
Epoch: [24][320/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.4399e-01 (2.9481e-01)	Acc@1  87.50 ( 89.64)	Acc@5  99.22 ( 99.74)
Epoch: [24][330/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.5143e-01 (2.9616e-01)	Acc@1  89.84 ( 89.59)	Acc@5 100.00 ( 99.73)
Epoch: [24][340/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.0131e-01 (2.9686e-01)	Acc@1  90.62 ( 89.58)	Acc@5  99.22 ( 99.73)
Epoch: [24][350/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.2045e-01 (2.9604e-01)	Acc@1  92.19 ( 89.61)	Acc@5  98.44 ( 99.74)
Epoch: [24][360/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.8342e-01 (2.9658e-01)	Acc@1  82.03 ( 89.62)	Acc@5 100.00 ( 99.73)
Epoch: [24][370/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.3719e-01 (2.9641e-01)	Acc@1  89.06 ( 89.65)	Acc@5 100.00 ( 99.72)
Epoch: [24][380/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.8148e-01 (2.9810e-01)	Acc@1  88.28 ( 89.60)	Acc@5 100.00 ( 99.72)
Epoch: [24][390/391]	Time  0.031 ( 0.041)	Data  0.001 ( 0.001)	Loss 2.3574e-01 (2.9780e-01)	Acc@1  93.75 ( 89.61)	Acc@5 100.00 ( 99.72)
## e[24] optimizer.zero_grad (sum) time: 0.27138686180114746
## e[24]       loss.backward (sum) time: 3.948118209838867
## e[24]      optimizer.step (sum) time: 1.8330423831939697
## epoch[24] training(only) time: 15.98095965385437
# Switched to evaluate mode...
Test: [  0/100]	Time  0.174 ( 0.174)	Loss 4.9187e-01 (4.9187e-01)	Acc@1  85.00 ( 85.00)	Acc@5  99.00 ( 99.00)
Test: [ 10/100]	Time  0.023 ( 0.035)	Loss 6.5816e-01 (4.9277e-01)	Acc@1  82.00 ( 83.64)	Acc@5 100.00 ( 99.64)
Test: [ 20/100]	Time  0.019 ( 0.028)	Loss 4.0075e-01 (4.7511e-01)	Acc@1  84.00 ( 84.71)	Acc@5 100.00 ( 99.33)
Test: [ 30/100]	Time  0.020 ( 0.025)	Loss 5.2312e-01 (4.7619e-01)	Acc@1  84.00 ( 85.00)	Acc@5  99.00 ( 99.39)
Test: [ 40/100]	Time  0.018 ( 0.024)	Loss 5.2386e-01 (4.7428e-01)	Acc@1  85.00 ( 84.85)	Acc@5  99.00 ( 99.41)
Test: [ 50/100]	Time  0.021 ( 0.024)	Loss 4.0182e-01 (4.6597e-01)	Acc@1  90.00 ( 85.08)	Acc@5 100.00 ( 99.41)
Test: [ 60/100]	Time  0.021 ( 0.023)	Loss 3.9654e-01 (4.6565e-01)	Acc@1  87.00 ( 85.08)	Acc@5 100.00 ( 99.44)
Test: [ 70/100]	Time  0.022 ( 0.023)	Loss 4.4751e-01 (4.5953e-01)	Acc@1  85.00 ( 85.17)	Acc@5 100.00 ( 99.48)
Test: [ 80/100]	Time  0.022 ( 0.022)	Loss 2.4211e-01 (4.5611e-01)	Acc@1  92.00 ( 85.37)	Acc@5 100.00 ( 99.53)
Test: [ 90/100]	Time  0.019 ( 0.022)	Loss 2.4559e-01 (4.5537e-01)	Acc@1  90.00 ( 85.31)	Acc@5 100.00 ( 99.54)
 * Acc@1 85.270 Acc@5 99.540
### epoch[24] execution time: 18.272887706756592
EPOCH 25
i:   0, name:           module.stem.0.weight  changing lr from: 0.047729843538492883   to: 0.044338527502719036
i:   1, name:             module.stem.0.bias  changing lr from: 0.048327406203646464   to: 0.044957037501483943
i:   2, name:           module.stem.1.weight  changing lr from: 0.048919530988329608   to: 0.045570454475437429
i:   3, name:             module.stem.1.bias  changing lr from: 0.049506195473080113   to: 0.046178732364548405
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.050087381196055658   to: 0.046781829947759125
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.050663073468658393   to: 0.047379710632641632
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.051233261197852466   to: 0.047972342252257473
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.051797936714979675   to: 0.048559696869033553
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.052357095610881504   to: 0.049141750585467533
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.052910736577138621   to: 0.049718483361478209
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.053458861253242840   to: 0.050289878838217797
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.054001474079519232   to: 0.050855924168165485
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.054538582155619776   to: 0.051416609851323208
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.055070195104414049   to: 0.051971929577338011
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.055596324941105203   to: 0.052521880073377138
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.056116985947404441   to: 0.053066460957585798
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.056632194550599514   to: 0.053605674597959264
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.057141969207358229   to: 0.054139525976465687
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.057646330292110248   to: 0.054668022558257361
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.058145299989855584   to: 0.055191174165813053
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.058638902193250887   to: 0.055708992857856243
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.059127162403829703   to: 0.056221492812898066
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.059610107637215463   to: 0.056728690217256787
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.060087766332190651   to: 0.057230603157409535
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.060560168263488957   to: 0.057727251516534961
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.061027344458180754   to: 0.058218656875109270
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.061489327115526515   to: 0.058704842415421211
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.061946149530175777   to: 0.059185832829875731
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.062397846018593106   to: 0.059661654232958529
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.062844451848595911   to: 0.060132334076737494
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.063286003171892688   to: 0.060597901069780746
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.063722536959513160   to: 0.061058385099373828
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.064154090940025443   to: 0.061513817156921960
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.064580703540438808   to: 0.061964229266426765
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.065002413829692990   to: 0.062409654415929716
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.065419261464639014   to: 0.062850126491817926
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.065831286638419140   to: 0.063285680215891121
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.066238530031156428   to: 0.063716351085091077
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.066641032762867286   to: 0.064142175313798455
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.067038836348513556   to: 0.064563189778604577
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.067431982655113229   to: 0.064979431965468321
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.067820513860831266   to: 0.065390939919171776
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.068204472415975034   to: 0.065797752194989872
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.068583901005821485   to: 0.066199907812493450
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.068958842515205163   to: 0.066597446211406203
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.069329339994798983   to: 0.066990407209439565
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.069695436629021751   to: 0.067378830962031830
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.070057175705509289   to: 0.067762757923920017
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.070414600586087131   to: 0.068142228812475142
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.070767754679186029   to: 0.068517284572734927
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.071116681413642913   to: 0.068887966344068560
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.071461424213832198   to: 0.069254315428411761
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.071802026476074074   to: 0.069616373260011646
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.072138531546268855   to: 0.069974181376623368
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.072470982698707470   to: 0.070327781392102162
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.072799423116010620   to: 0.070677214970336563
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.073123895870150779   to: 0.071022523800470611
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.073444443904512324   to: 0.071363749573364069
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.073761110016947504   to: 0.071700933959242361
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.074073936843786867   to: 0.072034118586488546
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.074382966844764697   to: 0.072363345021532494
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.074688242288821080   to: 0.072688654749792955
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.074989805240744084   to: 0.073010089157630589
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.075287697548616403   to: 0.073327689515270827
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.075581960832032821   to: 0.073641496960657735
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.075872636471055119   to: 0.073951552484200697
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.076159765595873410   to: 0.074257896914377328
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.076443389077143140   to: 0.074560570904157797
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.076723547516968874   to: 0.074859614918216272
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.077000281240506396   to: 0.075155069220896986
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.077273630288156397   to: 0.075446973864903621
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.077543634408323445   to: 0.075735368680681411
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.077810333050715608   to: 0.076020293266462924
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.078073765360160280   to: 0.076301786978949446
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.078333970170913370   to: 0.076579888924601061
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.078590986001439461   to: 0.076854637951508958
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.078844851049641743   to: 0.077126072641825361
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.079095603188521046   to: 0.077394231304726627
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.079343279962244315   to: 0.077659151969886653
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.079587918582603556   to: 0.077920872381437897
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.079829555925847132   to: 0.078179429992398783
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.080068228529865823   to: 0.078434861959546742
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.080303972591716871   to: 0.078687205138717020
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.080536823965469961   to: 0.078936496080508206
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.080766818160359605   to: 0.079182771026375998
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.080993990339229105   to: 0.079426065905097737
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.081218375317251734   to: 0.079666416329590498
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.081440007560915656   to: 0.079903857594066666
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.081658921187259259   to: 0.080138424671511138
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.081875149963344371   to: 0.080370152211465207
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.082088727305955234   to: 0.080599074538102500
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.082299686281511852   to: 0.080825225648583410
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.082508059606186221   to: 0.081048639211674323
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.082713879646211186   to: 0.081269348566618757
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.082917178418371387   to: 0.081487386722248742
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.083117987590666728   to: 0.081702786356323762
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.083316338483138852   to: 0.081915579815086570
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.083512262068851692   to: 0.082125799113024769
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.083705788975017473   to: 0.082333475932827499
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.083896949484259881   to: 0.082538641625527598
i: 100, name:           module.conv10.weight  changing lr from: 0.084085773536006575   to: 0.082741327210819518
i: 101, name:             module.conv10.bias  changing lr from: 0.084272290728003352   to: 0.082941563377543381



# Switched to train mode...
Epoch: [25][  0/391]	Time  0.215 ( 0.215)	Data  0.172 ( 0.172)	Loss 2.4485e-01 (2.4485e-01)	Acc@1  91.41 ( 91.41)	Acc@5 100.00 (100.00)
Epoch: [25][ 10/391]	Time  0.039 ( 0.056)	Data  0.001 ( 0.017)	Loss 2.6357e-01 (2.6324e-01)	Acc@1  92.97 ( 90.70)	Acc@5  99.22 ( 99.64)
Epoch: [25][ 20/391]	Time  0.040 ( 0.049)	Data  0.001 ( 0.009)	Loss 2.6556e-01 (2.7330e-01)	Acc@1  92.19 ( 90.33)	Acc@5 100.00 ( 99.78)
Epoch: [25][ 30/391]	Time  0.041 ( 0.046)	Data  0.001 ( 0.007)	Loss 3.2518e-01 (2.6380e-01)	Acc@1  89.06 ( 90.55)	Acc@5  99.22 ( 99.82)
Epoch: [25][ 40/391]	Time  0.039 ( 0.045)	Data  0.001 ( 0.005)	Loss 1.4448e-01 (2.6229e-01)	Acc@1  95.31 ( 90.74)	Acc@5 100.00 ( 99.73)
Epoch: [25][ 50/391]	Time  0.039 ( 0.044)	Data  0.001 ( 0.004)	Loss 3.2142e-01 (2.6577e-01)	Acc@1  85.94 ( 90.55)	Acc@5  99.22 ( 99.74)
Epoch: [25][ 60/391]	Time  0.038 ( 0.043)	Data  0.001 ( 0.004)	Loss 2.4377e-01 (2.6232e-01)	Acc@1  92.19 ( 90.77)	Acc@5  99.22 ( 99.76)
Epoch: [25][ 70/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.003)	Loss 1.9796e-01 (2.6137e-01)	Acc@1  94.53 ( 90.82)	Acc@5 100.00 ( 99.78)
Epoch: [25][ 80/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.003)	Loss 2.2207e-01 (2.6357e-01)	Acc@1  91.41 ( 90.79)	Acc@5 100.00 ( 99.79)
Epoch: [25][ 90/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.003)	Loss 2.4412e-01 (2.6608e-01)	Acc@1  91.41 ( 90.68)	Acc@5 100.00 ( 99.79)
Epoch: [25][100/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.003)	Loss 2.2637e-01 (2.7111e-01)	Acc@1  91.41 ( 90.52)	Acc@5 100.00 ( 99.78)
Epoch: [25][110/391]	Time  0.045 ( 0.042)	Data  0.001 ( 0.002)	Loss 3.0571e-01 (2.7230e-01)	Acc@1  87.50 ( 90.48)	Acc@5  99.22 ( 99.76)
Epoch: [25][120/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.4722e-01 (2.7394e-01)	Acc@1  92.97 ( 90.42)	Acc@5 100.00 ( 99.77)
Epoch: [25][130/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 4.6824e-01 (2.7565e-01)	Acc@1  83.59 ( 90.34)	Acc@5 100.00 ( 99.77)
Epoch: [25][140/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.5005e-01 (2.7526e-01)	Acc@1  94.53 ( 90.29)	Acc@5  99.22 ( 99.78)
Epoch: [25][150/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 3.3563e-01 (2.7431e-01)	Acc@1  88.28 ( 90.30)	Acc@5 100.00 ( 99.79)
Epoch: [25][160/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.5763e-01 (2.7514e-01)	Acc@1  93.75 ( 90.31)	Acc@5  99.22 ( 99.79)
Epoch: [25][170/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.9488e-01 (2.7607e-01)	Acc@1  89.84 ( 90.29)	Acc@5  99.22 ( 99.78)
Epoch: [25][180/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.3864e-01 (2.7609e-01)	Acc@1  91.41 ( 90.30)	Acc@5 100.00 ( 99.77)
Epoch: [25][190/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.2624e-01 (2.7785e-01)	Acc@1  89.84 ( 90.27)	Acc@5 100.00 ( 99.76)
Epoch: [25][200/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.2137e-01 (2.7879e-01)	Acc@1  85.16 ( 90.17)	Acc@5  99.22 ( 99.76)
Epoch: [25][210/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.1156e-01 (2.7896e-01)	Acc@1  90.62 ( 90.18)	Acc@5  99.22 ( 99.75)
Epoch: [25][220/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.8605e-01 (2.7995e-01)	Acc@1  85.16 ( 90.15)	Acc@5 100.00 ( 99.75)
Epoch: [25][230/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.8390e-01 (2.7975e-01)	Acc@1  95.31 ( 90.15)	Acc@5  99.22 ( 99.75)
Epoch: [25][240/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.9763e-01 (2.8115e-01)	Acc@1  90.62 ( 90.13)	Acc@5 100.00 ( 99.74)
Epoch: [25][250/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.2984e-01 (2.8095e-01)	Acc@1  89.84 ( 90.15)	Acc@5  99.22 ( 99.74)
Epoch: [25][260/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.8411e-01 (2.8199e-01)	Acc@1  90.62 ( 90.14)	Acc@5 100.00 ( 99.74)
Epoch: [25][270/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.7459e-01 (2.8302e-01)	Acc@1  92.19 ( 90.11)	Acc@5 100.00 ( 99.73)
Epoch: [25][280/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.8351e-01 (2.8380e-01)	Acc@1  90.62 ( 90.07)	Acc@5 100.00 ( 99.73)
Epoch: [25][290/391]	Time  0.039 ( 0.041)	Data  0.002 ( 0.002)	Loss 3.1877e-01 (2.8452e-01)	Acc@1  91.41 ( 90.04)	Acc@5 100.00 ( 99.73)
Epoch: [25][300/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.0674e-01 (2.8438e-01)	Acc@1  93.75 ( 90.07)	Acc@5 100.00 ( 99.73)
Epoch: [25][310/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.6439e-01 (2.8378e-01)	Acc@1  88.28 ( 90.07)	Acc@5 100.00 ( 99.73)
Epoch: [25][320/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.0153e-01 (2.8430e-01)	Acc@1  86.72 ( 90.03)	Acc@5 100.00 ( 99.73)
Epoch: [25][330/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.8312e-01 (2.8518e-01)	Acc@1  89.06 ( 90.04)	Acc@5 100.00 ( 99.73)
Epoch: [25][340/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.4367e-01 (2.8550e-01)	Acc@1  88.28 ( 90.04)	Acc@5 100.00 ( 99.73)
Epoch: [25][350/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.0596e-01 (2.8509e-01)	Acc@1  88.28 ( 90.06)	Acc@5 100.00 ( 99.74)
Epoch: [25][360/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.001)	Loss 1.9454e-01 (2.8589e-01)	Acc@1  92.19 ( 90.05)	Acc@5 100.00 ( 99.74)
Epoch: [25][370/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.001)	Loss 3.9880e-01 (2.8595e-01)	Acc@1  87.50 ( 90.06)	Acc@5  98.44 ( 99.74)
Epoch: [25][380/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.001)	Loss 3.6428e-01 (2.8597e-01)	Acc@1  86.72 ( 90.06)	Acc@5  99.22 ( 99.74)
Epoch: [25][390/391]	Time  0.028 ( 0.041)	Data  0.001 ( 0.001)	Loss 2.0021e-01 (2.8622e-01)	Acc@1  92.50 ( 90.06)	Acc@5 100.00 ( 99.74)
## e[25] optimizer.zero_grad (sum) time: 0.2734341621398926
## e[25]       loss.backward (sum) time: 4.004125595092773
## e[25]      optimizer.step (sum) time: 1.7657232284545898
## epoch[25] training(only) time: 16.10108733177185
# Switched to evaluate mode...
Test: [  0/100]	Time  0.175 ( 0.175)	Loss 3.8517e-01 (3.8517e-01)	Acc@1  88.00 ( 88.00)	Acc@5  99.00 ( 99.00)
Test: [ 10/100]	Time  0.020 ( 0.035)	Loss 6.1511e-01 (4.6204e-01)	Acc@1  81.00 ( 85.18)	Acc@5 100.00 ( 99.73)
Test: [ 20/100]	Time  0.022 ( 0.028)	Loss 4.9733e-01 (4.5855e-01)	Acc@1  81.00 ( 85.05)	Acc@5 100.00 ( 99.43)
Test: [ 30/100]	Time  0.026 ( 0.026)	Loss 6.2514e-01 (4.7263e-01)	Acc@1  82.00 ( 84.97)	Acc@5  98.00 ( 99.26)
Test: [ 40/100]	Time  0.020 ( 0.025)	Loss 5.1180e-01 (4.7682e-01)	Acc@1  84.00 ( 84.80)	Acc@5  98.00 ( 99.20)
Test: [ 50/100]	Time  0.019 ( 0.024)	Loss 2.8001e-01 (4.6680e-01)	Acc@1  87.00 ( 85.00)	Acc@5 100.00 ( 99.29)
Test: [ 60/100]	Time  0.020 ( 0.024)	Loss 4.8820e-01 (4.6503e-01)	Acc@1  87.00 ( 85.25)	Acc@5  99.00 ( 99.36)
Test: [ 70/100]	Time  0.020 ( 0.023)	Loss 3.1971e-01 (4.5732e-01)	Acc@1  87.00 ( 85.34)	Acc@5 100.00 ( 99.38)
Test: [ 80/100]	Time  0.021 ( 0.023)	Loss 3.5103e-01 (4.5184e-01)	Acc@1  88.00 ( 85.49)	Acc@5 100.00 ( 99.43)
Test: [ 90/100]	Time  0.023 ( 0.023)	Loss 2.9202e-01 (4.5297e-01)	Acc@1  94.00 ( 85.47)	Acc@5  99.00 ( 99.43)
 * Acc@1 85.520 Acc@5 99.450
### epoch[25] execution time: 18.47741985321045
EPOCH 26
i:   0, name:           module.stem.0.weight  changing lr from: 0.044338527502719036   to: 0.040978162618878995
i:   1, name:             module.stem.0.bias  changing lr from: 0.044957037501483943   to: 0.041614336945434281
i:   2, name:           module.stem.1.weight  changing lr from: 0.045570454475437429   to: 0.042245876082637419
i:   3, name:             module.stem.1.bias  changing lr from: 0.046178732364548405   to: 0.042872707297176293
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.046781829947759125   to: 0.043494763633682855
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.047379710632641632   to: 0.044111983678748128
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.047972342252257473   to: 0.044724311332524525
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.048559696869033553   to: 0.045331695587745455
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.049141750585467533   to: 0.045934090315990786
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.049718483361478209   to: 0.046531454061026573
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.050289878838217797   to: 0.047123749839046707
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.050855924168165485   to: 0.047710944945644596
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.051416609851323208   to: 0.048293010769343440
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.051971929577338011   to: 0.048869922611514752
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.052521880073377138   to: 0.049441659512515765
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.053066460957585798   to: 0.050008204083878176
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.053605674597959264   to: 0.050569542346381863
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.054139525976465687   to: 0.051125663573850205
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.054668022558257361   to: 0.051676560142504463
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.055191174165813053   to: 0.052222227385718314
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.055708992857856243   to: 0.052762663454015146
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.056221492812898066   to: 0.053297869180153813
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.056728690217256787   to: 0.053827847949151297
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.057230603157409535   to: 0.054352605573093328
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.057727251516534961   to: 0.054872150170586997
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.058218656875109270   to: 0.055386492050712333
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.058704842415421211   to: 0.055895643601333013
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.059185832829875731   to: 0.056399619181629251
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.059661654232958529   to: 0.056898435018718732
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.060132334076737494   to: 0.057392109108235417
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.060597901069780746   to: 0.057880661118737790
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.061058385099373828   to: 0.058364112299822912
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.061513817156921960   to: 0.058842485393824077
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.061964229266426765   to: 0.059315804550974176
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.062409654415929716   to: 0.059784095247919312
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.062850126491817926   to: 0.060247384209470567
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.063285680215891121   to: 0.060705699333484520
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.063716351085091077   to: 0.061159069618766472
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.064142175313798455   to: 0.061607525095893047
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.064563189778604577   to: 0.062051096760853623
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.064979431965468321   to: 0.062489816511413387
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.065390939919171776   to: 0.062923717086103087
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.065797752194989872   to: 0.063352832005743459
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.066199907812493450   to: 0.063777195517415550
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.066597446211406203   to: 0.064196842540789806
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.066990407209439565   to: 0.064611808616730451
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.067378830962031830   to: 0.065022129858093469
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.067762757923920017   to: 0.065427842902639685
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.068142228812475142   to: 0.065828984867986037
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.068517284572734927   to: 0.066225593308521388
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.068887966344068560   to: 0.066617706174215127
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.069254315428411761   to: 0.067005361771248856
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.069616373260011646   to: 0.067388598724404586
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.069974181376623368   to: 0.067767455941143667
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.070327781392102162   to: 0.068141972577314289
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.070677214970336563   to: 0.068512188004426045
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.071022523800470611   to: 0.068878141778433391
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.071363749573364069   to: 0.069239873609970512
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.071700933959242361   to: 0.069597423335983094
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.072034118586488546   to: 0.069950830892703403
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.072363345021532494   to: 0.070300136289917908
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.072688654749792955   to: 0.070645379586477319
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.073010089157630589   to: 0.070986600867001273
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.073327689515270827   to: 0.071323840219731607
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.073641496960657735   to: 0.071657137715489302
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.073951552484200697   to: 0.071986533387692106
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.074257896914377328   to: 0.072312067213391160
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.074560570904157797   to: 0.072633779095286385
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.074859614918216272   to: 0.072951708844682064
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.075155069220896986   to: 0.073265896165344999
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.075446973864903621   to: 0.073576380638229341
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.075735368680681411   to: 0.073883201707033094
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.076020293266462924   to: 0.074186398664553108
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.076301786978949446   to: 0.074486010639805672
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.076579888924601061   to: 0.074782076585882179
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.076854637951508958   to: 0.075074635268509174
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.077126072641825361   to: 0.075363725255284231
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.077394231304726627   to: 0.075649384905559572
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.077659151969886653   to: 0.075931652360946553
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.077920872381437897   to: 0.076210565536415198
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.078179429992398783   to: 0.076486162111963560
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.078434861959546742   to: 0.076758479524833279
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.078687205138717020   to: 0.077027554962247807
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.078936496080508206   to: 0.077293425354651141
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.079182771026375998   to: 0.077556127369425729
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.079426065905097737   to: 0.077815697405068718
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.079666416329590498   to: 0.078072171585806691
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.079903857594066666   to: 0.078325585756629901
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.080138424671511138   to: 0.078575975478727411
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.080370152211465207   to: 0.078823376025305425
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.080599074538102500   to: 0.079067822377772046
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.080825225648583410   to: 0.079309349222271619
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.081048639211674323   to: 0.079547990946553376
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.081269348566618757   to: 0.079783781637158754
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.081487386722248742   to: 0.080016755076913221
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.081702786356323762   to: 0.080246944742708284
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.081915579815086570   to: 0.080474383803560479
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.082125799113024769   to: 0.080699105118934078
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.082333475932827499   to: 0.080921141237315447
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.082538641625527598   to: 0.081140524395026697
i: 100, name:           module.conv10.weight  changing lr from: 0.082741327210819518   to: 0.081357286515267482
i: 101, name:             module.conv10.bias  changing lr from: 0.082941563377543381   to: 0.081571459207373770



# Switched to train mode...
Epoch: [26][  0/391]	Time  0.215 ( 0.215)	Data  0.173 ( 0.173)	Loss 2.4738e-01 (2.4738e-01)	Acc@1  92.97 ( 92.97)	Acc@5  98.44 ( 98.44)
Epoch: [26][ 10/391]	Time  0.043 ( 0.056)	Data  0.001 ( 0.017)	Loss 3.4059e-01 (2.7011e-01)	Acc@1  90.62 ( 90.70)	Acc@5  99.22 ( 99.72)
Epoch: [26][ 20/391]	Time  0.041 ( 0.049)	Data  0.001 ( 0.009)	Loss 2.1088e-01 (2.6743e-01)	Acc@1  92.19 ( 90.48)	Acc@5 100.00 ( 99.81)
Epoch: [26][ 30/391]	Time  0.038 ( 0.046)	Data  0.001 ( 0.007)	Loss 3.0404e-01 (2.8021e-01)	Acc@1  90.62 ( 90.12)	Acc@5 100.00 ( 99.80)
Epoch: [26][ 40/391]	Time  0.039 ( 0.045)	Data  0.001 ( 0.005)	Loss 1.9993e-01 (2.7733e-01)	Acc@1  91.41 ( 90.13)	Acc@5 100.00 ( 99.79)
Epoch: [26][ 50/391]	Time  0.039 ( 0.044)	Data  0.001 ( 0.004)	Loss 2.6262e-01 (2.7081e-01)	Acc@1  89.84 ( 90.38)	Acc@5  99.22 ( 99.79)
Epoch: [26][ 60/391]	Time  0.046 ( 0.044)	Data  0.001 ( 0.004)	Loss 2.3395e-01 (2.6960e-01)	Acc@1  89.84 ( 90.50)	Acc@5 100.00 ( 99.80)
Epoch: [26][ 70/391]	Time  0.044 ( 0.043)	Data  0.001 ( 0.003)	Loss 2.3793e-01 (2.7233e-01)	Acc@1  90.62 ( 90.39)	Acc@5  99.22 ( 99.79)
Epoch: [26][ 80/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.003)	Loss 2.3762e-01 (2.7104e-01)	Acc@1  91.41 ( 90.44)	Acc@5 100.00 ( 99.78)
Epoch: [26][ 90/391]	Time  0.038 ( 0.043)	Data  0.001 ( 0.003)	Loss 5.3552e-01 (2.7129e-01)	Acc@1  82.03 ( 90.50)	Acc@5  98.44 ( 99.77)
Epoch: [26][100/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.003)	Loss 3.8870e-01 (2.7318e-01)	Acc@1  84.38 ( 90.38)	Acc@5 100.00 ( 99.78)
Epoch: [26][110/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.003)	Loss 3.7093e-01 (2.7218e-01)	Acc@1  86.72 ( 90.42)	Acc@5 100.00 ( 99.78)
Epoch: [26][120/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.4550e-01 (2.7151e-01)	Acc@1  90.62 ( 90.41)	Acc@5 100.00 ( 99.76)
Epoch: [26][130/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 3.1833e-01 (2.7106e-01)	Acc@1  88.28 ( 90.42)	Acc@5 100.00 ( 99.77)
Epoch: [26][140/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 3.0793e-01 (2.7267e-01)	Acc@1  90.62 ( 90.40)	Acc@5  98.44 ( 99.76)
Epoch: [26][150/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.2750e-01 (2.7227e-01)	Acc@1  91.41 ( 90.38)	Acc@5  99.22 ( 99.76)
Epoch: [26][160/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 3.1701e-01 (2.7266e-01)	Acc@1  87.50 ( 90.41)	Acc@5 100.00 ( 99.76)
Epoch: [26][170/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.6535e-01 (2.7140e-01)	Acc@1  92.19 ( 90.45)	Acc@5 100.00 ( 99.77)
Epoch: [26][180/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 3.1935e-01 (2.7099e-01)	Acc@1  89.84 ( 90.47)	Acc@5 100.00 ( 99.78)
Epoch: [26][190/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.6766e-01 (2.7120e-01)	Acc@1  92.19 ( 90.47)	Acc@5 100.00 ( 99.78)
Epoch: [26][200/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 3.5682e-01 (2.7186e-01)	Acc@1  85.16 ( 90.43)	Acc@5 100.00 ( 99.78)
Epoch: [26][210/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.9859e-01 (2.7456e-01)	Acc@1  89.84 ( 90.34)	Acc@5 100.00 ( 99.77)
Epoch: [26][220/391]	Time  0.049 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.5261e-01 (2.7458e-01)	Acc@1  92.19 ( 90.34)	Acc@5  99.22 ( 99.76)
Epoch: [26][230/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.3767e-01 (2.7458e-01)	Acc@1  92.97 ( 90.38)	Acc@5 100.00 ( 99.76)
Epoch: [26][240/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.8447e-01 (2.7547e-01)	Acc@1  90.62 ( 90.31)	Acc@5 100.00 ( 99.76)
Epoch: [26][250/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.6255e-01 (2.7643e-01)	Acc@1  92.19 ( 90.26)	Acc@5 100.00 ( 99.76)
Epoch: [26][260/391]	Time  0.044 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.0663e-01 (2.7692e-01)	Acc@1  92.19 ( 90.24)	Acc@5  99.22 ( 99.76)
Epoch: [26][270/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.2120e-01 (2.7778e-01)	Acc@1  93.75 ( 90.22)	Acc@5 100.00 ( 99.76)
Epoch: [26][280/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.1350e-01 (2.7734e-01)	Acc@1  92.97 ( 90.25)	Acc@5 100.00 ( 99.76)
Epoch: [26][290/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.9469e-01 (2.7869e-01)	Acc@1  89.84 ( 90.21)	Acc@5  99.22 ( 99.76)
Epoch: [26][300/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.5337e-01 (2.7994e-01)	Acc@1  89.84 ( 90.17)	Acc@5 100.00 ( 99.76)
Epoch: [26][310/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.6901e-01 (2.8031e-01)	Acc@1  89.06 ( 90.16)	Acc@5 100.00 ( 99.75)
Epoch: [26][320/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.5382e-01 (2.8146e-01)	Acc@1  92.19 ( 90.16)	Acc@5 100.00 ( 99.75)
Epoch: [26][330/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.3510e-01 (2.8068e-01)	Acc@1  92.97 ( 90.20)	Acc@5 100.00 ( 99.75)
Epoch: [26][340/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.0018e-01 (2.8076e-01)	Acc@1  90.62 ( 90.19)	Acc@5 100.00 ( 99.75)
Epoch: [26][350/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.001)	Loss 2.4827e-01 (2.8103e-01)	Acc@1  90.62 ( 90.16)	Acc@5 100.00 ( 99.75)
Epoch: [26][360/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.001)	Loss 2.4961e-01 (2.8091e-01)	Acc@1  91.41 ( 90.17)	Acc@5 100.00 ( 99.75)
Epoch: [26][370/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.001)	Loss 2.8396e-01 (2.8074e-01)	Acc@1  88.28 ( 90.20)	Acc@5 100.00 ( 99.76)
Epoch: [26][380/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.001)	Loss 1.9865e-01 (2.8040e-01)	Acc@1  92.19 ( 90.21)	Acc@5 100.00 ( 99.76)
Epoch: [26][390/391]	Time  0.028 ( 0.041)	Data  0.001 ( 0.001)	Loss 2.5561e-01 (2.7973e-01)	Acc@1  88.75 ( 90.23)	Acc@5 100.00 ( 99.75)
## e[26] optimizer.zero_grad (sum) time: 0.27066707611083984
## e[26]       loss.backward (sum) time: 4.010394811630249
## e[26]      optimizer.step (sum) time: 1.7848241329193115
## epoch[26] training(only) time: 16.173510313034058
# Switched to evaluate mode...
Test: [  0/100]	Time  0.171 ( 0.171)	Loss 4.5071e-01 (4.5071e-01)	Acc@1  84.00 ( 84.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.023 ( 0.034)	Loss 5.6713e-01 (4.4213e-01)	Acc@1  85.00 ( 86.18)	Acc@5  99.00 ( 99.82)
Test: [ 20/100]	Time  0.024 ( 0.028)	Loss 4.0102e-01 (4.6174e-01)	Acc@1  84.00 ( 85.86)	Acc@5 100.00 ( 99.62)
Test: [ 30/100]	Time  0.024 ( 0.026)	Loss 4.7636e-01 (4.6928e-01)	Acc@1  88.00 ( 86.10)	Acc@5  98.00 ( 99.45)
Test: [ 40/100]	Time  0.023 ( 0.025)	Loss 4.2602e-01 (4.7472e-01)	Acc@1  87.00 ( 85.59)	Acc@5  98.00 ( 99.39)
Test: [ 50/100]	Time  0.018 ( 0.024)	Loss 3.8207e-01 (4.6346e-01)	Acc@1  90.00 ( 85.84)	Acc@5  99.00 ( 99.37)
Test: [ 60/100]	Time  0.019 ( 0.023)	Loss 4.8842e-01 (4.7076e-01)	Acc@1  87.00 ( 85.57)	Acc@5 100.00 ( 99.38)
Test: [ 70/100]	Time  0.017 ( 0.023)	Loss 4.2472e-01 (4.6621e-01)	Acc@1  85.00 ( 85.68)	Acc@5 100.00 ( 99.46)
Test: [ 80/100]	Time  0.017 ( 0.023)	Loss 3.0853e-01 (4.5938e-01)	Acc@1  88.00 ( 85.70)	Acc@5 100.00 ( 99.51)
Test: [ 90/100]	Time  0.023 ( 0.023)	Loss 3.1577e-01 (4.5873e-01)	Acc@1  92.00 ( 85.74)	Acc@5 100.00 ( 99.51)
 * Acc@1 85.740 Acc@5 99.500
### epoch[26] execution time: 18.524719715118408
EPOCH 27
i:   0, name:           module.stem.0.weight  changing lr from: 0.040978162618878995   to: 0.037664362126255110
i:   1, name:             module.stem.0.bias  changing lr from: 0.041614336945434281   to: 0.038314609334661631
i:   2, name:           module.stem.1.weight  changing lr from: 0.042245876082637419   to: 0.038960796314180687
i:   3, name:             module.stem.1.bias  changing lr from: 0.042872707297176293   to: 0.039602820699736502
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.043494763633682855   to: 0.040240586889922769
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.044111983678748128   to: 0.040874005786416721
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.044724311332524525   to: 0.041502994541199580
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.045331695587745455   to: 0.042127476311442681
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.045934090315990786   to: 0.042747380021914083
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.046531454061026573   to: 0.043362640134757449
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.047123749839046707   to: 0.043973196426491591
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.047710944945644596   to: 0.044578993772077219
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.048293010769343440   to: 0.045179981935895119
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.048869922611514752   to: 0.045776115369479814
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.049441659512515765   to: 0.046367353015850626
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.050008204083878176   to: 0.046953658120283265
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.050569542346381863   to: 0.047534998047363719
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.051125663573850205   to: 0.048111344104167952
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.051676560142504463   to: 0.048682671369410659
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.052222227385718314   to: 0.049248958528407799
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.052762663454015146   to: 0.049810187713699001
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.053297869180153813   to: 0.050366344351177240
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.053827847949151297   to: 0.050917417011574928
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.054352605573093328   to: 0.051463397267157644
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.054872150170586997   to: 0.052004279553478611
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.055386492050712333   to: 0.052540061036049204
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.055895643601333013   to: 0.053070741481783257
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.056399619181629251   to: 0.053596323135075424
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.056898435018718732   to: 0.054116810598375899
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.057392109108235417   to: 0.054632210717127122
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.057880661118737790   to: 0.055142532468929806
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.058364112299822912   to: 0.055647786856809690
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.058842485393824077   to: 0.056147986806457474
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.059315804550974176   to: 0.056643147067318655
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.059784095247919312   to: 0.057133284117411913
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.060247384209470567   to: 0.057618416071757828
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.060705699333484520   to: 0.058098562594302419
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.061159069618766472   to: 0.058573744813222840
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.061607525095893047   to: 0.059043985239505430
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.062051096760853623   to: 0.059509307688688839
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.062489816511413387   to: 0.059969737205668221
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.062923717086103087   to: 0.060425299992458652
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.063352832005743459   to: 0.060876023338818946
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.063777195517415550   to: 0.061321935555639931
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.064196842540789806   to: 0.061763065911003334
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.064611808616730451   to: 0.062199444568820567
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.065022129858093469   to: 0.062631102529962929
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.065427842902639685   to: 0.063058071575797681
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.065828984867986037   to: 0.063480384214046323
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.066225593308521388   to: 0.063898073626884419
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.066617706174215127   to: 0.064311173621204351
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.067005361771248856   to: 0.064719718580965105
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.067388598724404586   to: 0.065123743421554761
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.067767455941143667   to: 0.065523283546094782
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.068141972577314289   to: 0.065918374803616148
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.068512188004426045   to: 0.066309053449040145
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.068878141778433391   to: 0.066695356104899239
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.069239873609970512   to: 0.067077319724734102
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.069597423335983094   to: 0.067454981558106461
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.069950830892703403   to: 0.067828379117168144
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.070300136289917908   to: 0.068197550144729405
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.070645379586477319   to: 0.068562532583770971
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.070986600867001273   to: 0.068923364548346230
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.071323840219731607   to: 0.069280084295822039
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.071657137715489302   to: 0.069632730200407542
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.071986533387692106   to: 0.069981340727923128
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.072312067213391160   to: 0.070325954411762176
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.072633779095286385   to: 0.070666609830000768
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.072951708844682064   to: 0.071003345583611391
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.073265896165344999   to: 0.071336200275738351
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.073576380638229341   to: 0.071665212491994340
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.073883201707033094   to: 0.071990420781738437
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.074186398664553108   to: 0.072311863640297749
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.074486010639805672   to: 0.072629579492095614
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.074782076585882179   to: 0.072943606674651426
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.075074635268509174   to: 0.073253983423417268
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.075363725255284231   to: 0.073560747857418604
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.075649384905559572   to: 0.073863937965667190
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.075931652360946553   to: 0.074163591594315251
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.076210565536415198   to: 0.074459746434521606
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.076486162111963560   to: 0.074752440011000496
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.076758479524833279   to: 0.075041709671226323
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.077027554962247807   to: 0.075327592575266986
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.077293425354651141   to: 0.075610125686220608
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.077556127369425729   to: 0.075889345761230742
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.077815697405068718   to: 0.076165289343056261
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.078072171585806691   to: 0.076437992752172793
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.078325585756629901   to: 0.076707492079384057
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.078575975478727411   to: 0.076973823178921152
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.078823376025305425   to: 0.077237021662009631
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.079067822377772046   to: 0.077497122890884673
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.079309349222271619   to: 0.077754161973234731
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.079547990946553376   to: 0.078008173757056168
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.079783781637158754   to: 0.078259192825900284
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.080016755076913221   to: 0.078507253494496526
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.080246944742708284   to: 0.078752389804734868
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.080474383803560479   to: 0.078994635521992096
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.080699105118934078   to: 0.079234024131786582
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.080921141237315447   to: 0.079470588836746792
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.081140524395026697   to: 0.079704362553879901
i: 100, name:           module.conv10.weight  changing lr from: 0.081357286515267482   to: 0.079935377912126751
i: 101, name:             module.conv10.bias  changing lr from: 0.081571459207373770   to: 0.080163667250190085



# Switched to train mode...
Epoch: [27][  0/391]	Time  0.215 ( 0.215)	Data  0.173 ( 0.173)	Loss 3.3039e-01 (3.3039e-01)	Acc@1  88.28 ( 88.28)	Acc@5 100.00 (100.00)
Epoch: [27][ 10/391]	Time  0.040 ( 0.056)	Data  0.001 ( 0.017)	Loss 3.0162e-01 (2.8201e-01)	Acc@1  92.97 ( 89.99)	Acc@5 100.00 (100.00)
Epoch: [27][ 20/391]	Time  0.041 ( 0.048)	Data  0.001 ( 0.009)	Loss 3.5954e-01 (2.8153e-01)	Acc@1  88.28 ( 89.96)	Acc@5 100.00 ( 99.96)
Epoch: [27][ 30/391]	Time  0.039 ( 0.046)	Data  0.001 ( 0.007)	Loss 2.9659e-01 (2.7456e-01)	Acc@1  90.62 ( 90.10)	Acc@5 100.00 ( 99.92)
Epoch: [27][ 40/391]	Time  0.040 ( 0.044)	Data  0.001 ( 0.005)	Loss 2.6126e-01 (2.7401e-01)	Acc@1  90.62 ( 90.09)	Acc@5 100.00 ( 99.87)
Epoch: [27][ 50/391]	Time  0.036 ( 0.043)	Data  0.001 ( 0.004)	Loss 2.6255e-01 (2.7067e-01)	Acc@1  89.84 ( 90.32)	Acc@5 100.00 ( 99.82)
Epoch: [27][ 60/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.004)	Loss 2.5071e-01 (2.6348e-01)	Acc@1  91.41 ( 90.54)	Acc@5  99.22 ( 99.82)
Epoch: [27][ 70/391]	Time  0.043 ( 0.042)	Data  0.002 ( 0.003)	Loss 2.5887e-01 (2.6716e-01)	Acc@1  90.62 ( 90.45)	Acc@5 100.00 ( 99.82)
Epoch: [27][ 80/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.003)	Loss 2.9123e-01 (2.6362e-01)	Acc@1  90.62 ( 90.62)	Acc@5 100.00 ( 99.81)
Epoch: [27][ 90/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.003)	Loss 2.0761e-01 (2.6267e-01)	Acc@1  92.97 ( 90.66)	Acc@5 100.00 ( 99.81)
Epoch: [27][100/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.003)	Loss 3.4606e-01 (2.6168e-01)	Acc@1  85.94 ( 90.66)	Acc@5 100.00 ( 99.82)
Epoch: [27][110/391]	Time  0.053 ( 0.042)	Data  0.001 ( 0.003)	Loss 2.5041e-01 (2.6610e-01)	Acc@1  92.19 ( 90.55)	Acc@5 100.00 ( 99.80)
Epoch: [27][120/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.0397e-01 (2.6486e-01)	Acc@1  94.53 ( 90.59)	Acc@5 100.00 ( 99.81)
Epoch: [27][130/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.6183e-01 (2.6361e-01)	Acc@1  92.19 ( 90.61)	Acc@5 100.00 ( 99.80)
Epoch: [27][140/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.1941e-01 (2.6206e-01)	Acc@1  92.97 ( 90.64)	Acc@5 100.00 ( 99.81)
Epoch: [27][150/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.8753e-01 (2.6306e-01)	Acc@1  89.06 ( 90.65)	Acc@5 100.00 ( 99.80)
Epoch: [27][160/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.6332e-01 (2.6168e-01)	Acc@1  96.09 ( 90.70)	Acc@5 100.00 ( 99.80)
Epoch: [27][170/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.0939e-01 (2.6332e-01)	Acc@1  92.97 ( 90.63)	Acc@5 100.00 ( 99.81)
Epoch: [27][180/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.9096e-01 (2.6264e-01)	Acc@1  89.84 ( 90.65)	Acc@5 100.00 ( 99.81)
Epoch: [27][190/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.9003e-01 (2.6265e-01)	Acc@1  86.72 ( 90.67)	Acc@5 100.00 ( 99.82)
Epoch: [27][200/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.9056e-01 (2.6253e-01)	Acc@1  89.84 ( 90.63)	Acc@5  99.22 ( 99.83)
Epoch: [27][210/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.7387e-01 (2.6338e-01)	Acc@1  90.62 ( 90.60)	Acc@5 100.00 ( 99.83)
Epoch: [27][220/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.5523e-01 (2.6338e-01)	Acc@1  87.50 ( 90.58)	Acc@5 100.00 ( 99.83)
Epoch: [27][230/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.8800e-01 (2.6394e-01)	Acc@1  88.28 ( 90.56)	Acc@5  99.22 ( 99.82)
Epoch: [27][240/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.1561e-01 (2.6431e-01)	Acc@1  92.97 ( 90.56)	Acc@5 100.00 ( 99.82)
Epoch: [27][250/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.5764e-01 (2.6462e-01)	Acc@1  89.06 ( 90.55)	Acc@5 100.00 ( 99.83)
Epoch: [27][260/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.0996e-01 (2.6382e-01)	Acc@1  87.50 ( 90.58)	Acc@5 100.00 ( 99.84)
Epoch: [27][270/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.7787e-01 (2.6456e-01)	Acc@1  89.84 ( 90.59)	Acc@5 100.00 ( 99.83)
Epoch: [27][280/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.8812e-01 (2.6519e-01)	Acc@1  89.84 ( 90.57)	Acc@5 100.00 ( 99.84)
Epoch: [27][290/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.8592e-01 (2.6568e-01)	Acc@1  89.06 ( 90.58)	Acc@5 100.00 ( 99.83)
Epoch: [27][300/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.4418e-01 (2.6518e-01)	Acc@1  91.41 ( 90.61)	Acc@5 100.00 ( 99.83)
Epoch: [27][310/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.3655e-01 (2.6454e-01)	Acc@1  96.09 ( 90.64)	Acc@5 100.00 ( 99.82)
Epoch: [27][320/391]	Time  0.048 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.6119e-01 (2.6605e-01)	Acc@1  92.19 ( 90.58)	Acc@5 100.00 ( 99.81)
Epoch: [27][330/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.001)	Loss 2.3724e-01 (2.6620e-01)	Acc@1  92.19 ( 90.58)	Acc@5 100.00 ( 99.81)
Epoch: [27][340/391]	Time  0.047 ( 0.041)	Data  0.001 ( 0.001)	Loss 2.8847e-01 (2.6621e-01)	Acc@1  89.06 ( 90.57)	Acc@5 100.00 ( 99.82)
Epoch: [27][350/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.001)	Loss 3.1463e-01 (2.6712e-01)	Acc@1  86.72 ( 90.55)	Acc@5 100.00 ( 99.82)
Epoch: [27][360/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.001)	Loss 3.6128e-01 (2.6686e-01)	Acc@1  89.06 ( 90.56)	Acc@5  99.22 ( 99.82)
Epoch: [27][370/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.001)	Loss 2.3911e-01 (2.6814e-01)	Acc@1  92.97 ( 90.53)	Acc@5 100.00 ( 99.82)
Epoch: [27][380/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.001)	Loss 2.5218e-01 (2.6773e-01)	Acc@1  89.06 ( 90.54)	Acc@5 100.00 ( 99.82)
Epoch: [27][390/391]	Time  0.028 ( 0.041)	Data  0.001 ( 0.001)	Loss 2.0892e-01 (2.6809e-01)	Acc@1  91.25 ( 90.52)	Acc@5 100.00 ( 99.81)
## e[27] optimizer.zero_grad (sum) time: 0.2723832130432129
## e[27]       loss.backward (sum) time: 4.0504536628723145
## e[27]      optimizer.step (sum) time: 1.7882046699523926
## epoch[27] training(only) time: 16.143857717514038
# Switched to evaluate mode...
Test: [  0/100]	Time  0.175 ( 0.175)	Loss 3.6779e-01 (3.6779e-01)	Acc@1  85.00 ( 85.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.022 ( 0.033)	Loss 5.1209e-01 (4.1427e-01)	Acc@1  84.00 ( 86.27)	Acc@5 100.00 ( 99.82)
Test: [ 20/100]	Time  0.022 ( 0.027)	Loss 4.8600e-01 (4.4785e-01)	Acc@1  85.00 ( 85.33)	Acc@5 100.00 ( 99.38)
Test: [ 30/100]	Time  0.021 ( 0.025)	Loss 4.2154e-01 (4.4995e-01)	Acc@1  84.00 ( 85.45)	Acc@5 100.00 ( 99.35)
Test: [ 40/100]	Time  0.018 ( 0.024)	Loss 4.0335e-01 (4.5300e-01)	Acc@1  87.00 ( 85.44)	Acc@5  99.00 ( 99.32)
Test: [ 50/100]	Time  0.018 ( 0.022)	Loss 3.3139e-01 (4.4946e-01)	Acc@1  90.00 ( 85.57)	Acc@5 100.00 ( 99.37)
Test: [ 60/100]	Time  0.019 ( 0.022)	Loss 3.3421e-01 (4.4750e-01)	Acc@1  90.00 ( 85.61)	Acc@5 100.00 ( 99.46)
Test: [ 70/100]	Time  0.024 ( 0.022)	Loss 4.6545e-01 (4.4658e-01)	Acc@1  85.00 ( 85.41)	Acc@5 100.00 ( 99.51)
Test: [ 80/100]	Time  0.017 ( 0.022)	Loss 3.2683e-01 (4.4159e-01)	Acc@1  91.00 ( 85.53)	Acc@5 100.00 ( 99.54)
Test: [ 90/100]	Time  0.017 ( 0.022)	Loss 2.6392e-01 (4.4379e-01)	Acc@1  91.00 ( 85.30)	Acc@5 100.00 ( 99.56)
 * Acc@1 85.310 Acc@5 99.540
### epoch[27] execution time: 18.40728187561035
EPOCH 28
i:   0, name:           module.stem.0.weight  changing lr from: 0.037664362126255110   to: 0.034412522912332426
i:   1, name:             module.stem.0.bias  changing lr from: 0.038314609334661631   to: 0.035072962713554805
i:   2, name:           module.stem.1.weight  changing lr from: 0.038960796314180687   to: 0.035730037456447504
i:   3, name:             module.stem.1.bias  changing lr from: 0.039602820699736502   to: 0.036383612309236701
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.040240586889922769   to: 0.037033560223358498
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.040874005786416721   to: 0.037679761650102686
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.041502994541199580   to: 0.038322104265076463
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.042127476311442681   to: 0.038960482700391284
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.042747380021914083   to: 0.039594798284466097
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.043362640134757449   to: 0.040224958789334866
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.043973196426491591   to: 0.040850878185338703
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.044578993772077219   to: 0.041472476403078468
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.045179981935895119   to: 0.042089679102498230
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.045776115369479814   to: 0.042702417448967127
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.046367353015850626   to: 0.043310627896222649
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.046953658120283265   to: 0.043914251976037065
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.047534998047363719   to: 0.044513236094465301
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.048111344104167952   to: 0.045107531334532235
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.048682671369410659   to: 0.045697093265215143
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.049248958528407799   to: 0.046281881756577214
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.049810187713699001   to: 0.046861860800906957
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.050366344351177240   to: 0.047436998339719205
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.050917417011574928   to: 0.048007266096472934
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.051463397267157644   to: 0.048572639414862222
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.052004279553478611   to: 0.049133097102537771
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.052540061036049204   to: 0.049688621280116758
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.053070741481783257   to: 0.050239197235340996
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.053596323135075424   to: 0.050784813282244490
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.054116810598375899   to: 0.051325460625193157
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.054632210717127122   to: 0.051861133227661296
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.055142532468929806   to: 0.052391827685611604
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.055647786856809690   to: 0.052917543105347464
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.056147986806457474   to: 0.053438280985708346
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.056643147067318655   to: 0.053954045104481443
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.057133284117411913   to: 0.054464841408905257
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.057618416071757828   to: 0.054970677910142707
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.058098562594302419   to: 0.055471564581604654
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.058573744813222840   to: 0.055967513261005908
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.059043985239505430   to: 0.056458537556039870
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.059509307688688839   to: 0.056944652753558971
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.059969737205668221   to: 0.057425875732151910
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.060425299992458652   to: 0.057902224878010271
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.060876023338818946   to: 0.058373720003980036
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.061321935555639931   to: 0.058840382271696516
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.061763065911003334   to: 0.059302234116702546
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.062199444568820567   to: 0.059759299176453839
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.062631102529962929   to: 0.060211602221116448
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.063058071575797681   to: 0.060659169087064937
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.063480384214046323   to: 0.061102026612991446
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.063898073626884419   to: 0.061540202578538844
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.064311173621204351   to: 0.061973725645373103
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.064719718580965105   to: 0.062402625300612781
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.065123743421554761   to: 0.062826931802535457
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.065523283546094782   to: 0.063246676128483614
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.065918374803616148   to: 0.063661889924894355
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.066309053449040145   to: 0.064072605459379470
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.066695356104899239   to: 0.064478855574785277
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.067077319724734102   to: 0.064880673645162687
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.067454981558106461   to: 0.065278093533580966
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.067828379117168144   to: 0.065671149551719710
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.068197550144729405   to: 0.066059876421176930
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.068562532583770971   to: 0.066444309236431465
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.068923364548346230   to: 0.066824483429401033
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.069280084295822039   to: 0.067200434735538370
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.069632730200407542   to: 0.067572199161410440
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.069981340727923128   to: 0.067939812953706505
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.070325954411762176   to: 0.068303312569623284
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.070666609830000768   to: 0.068662734648576848
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.071003345583611391   to: 0.069018115985192682
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.071336200275738351   to: 0.069369493503526405
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.071665212491994340   to: 0.069716904232469956
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.071990420781738437   to: 0.070060385282298937
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.072311863640297749   to: 0.070399973822318551
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.072629579492095614   to: 0.070735707059566819
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.072943606674651426   to: 0.071067622218535395
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.073253983423417268   to: 0.071395756521869275
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.073560747857418604   to: 0.071720147172008392
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.073863937965667190   to: 0.072040831333734845
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.074163591594315251   to: 0.072357846117591329
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.074459746434521606   to: 0.072671228564137144
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.074752440011000496   to: 0.072981015629009091
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.075041709671226323   to: 0.073287244168756538
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.075327592575266986   to: 0.073589950927419823
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.075610125686220608   to: 0.073889172523823307
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.075889345761230742   to: 0.074184945439554714
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.076165289343056261   to: 0.074477306007603702
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.076437992752172793   to: 0.074766290401633281
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.076707492079384057   to: 0.075051934625859199
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.076973823178921152   to: 0.075334274505512319
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.077237021662009631   to: 0.075613345677861044
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.077497122890884673   to: 0.075889183583770836
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.077754161973234731   to: 0.076161823459778774
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.078008173757056168   to: 0.076431300330662547
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.078259192825900284   to: 0.076697649002483131
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.078507253494496526   to: 0.076960904056081691
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.078752389804734868   to: 0.077221099841011873
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.078994635521992096   to: 0.077478270469889296
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.079234024131786582   to: 0.077732449813140606
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.079470588836746792   to: 0.077983671494135209
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.079704362553879901   to: 0.078231968884683645
i: 100, name:           module.conv10.weight  changing lr from: 0.079935377912126751   to: 0.078477375100886468
i: 101, name:             module.conv10.bias  changing lr from: 0.080163667250190085   to: 0.078719922999319014



# Switched to train mode...
Epoch: [28][  0/391]	Time  0.220 ( 0.220)	Data  0.175 ( 0.175)	Loss 2.6636e-01 (2.6636e-01)	Acc@1  92.19 ( 92.19)	Acc@5 100.00 (100.00)
Epoch: [28][ 10/391]	Time  0.039 ( 0.057)	Data  0.001 ( 0.017)	Loss 2.8634e-01 (2.5591e-01)	Acc@1  89.84 ( 91.48)	Acc@5 100.00 ( 99.93)
Epoch: [28][ 20/391]	Time  0.040 ( 0.049)	Data  0.001 ( 0.009)	Loss 2.5863e-01 (2.5344e-01)	Acc@1  89.84 ( 91.33)	Acc@5 100.00 ( 99.93)
Epoch: [28][ 30/391]	Time  0.041 ( 0.046)	Data  0.001 ( 0.007)	Loss 2.4417e-01 (2.5043e-01)	Acc@1  92.19 ( 91.51)	Acc@5 100.00 ( 99.90)
Epoch: [28][ 40/391]	Time  0.042 ( 0.045)	Data  0.001 ( 0.005)	Loss 2.6029e-01 (2.4912e-01)	Acc@1  90.62 ( 91.52)	Acc@5 100.00 ( 99.89)
Epoch: [28][ 50/391]	Time  0.042 ( 0.044)	Data  0.001 ( 0.004)	Loss 2.7651e-01 (2.5667e-01)	Acc@1  88.28 ( 91.15)	Acc@5 100.00 ( 99.88)
Epoch: [28][ 60/391]	Time  0.039 ( 0.043)	Data  0.001 ( 0.004)	Loss 3.2533e-01 (2.5938e-01)	Acc@1  89.06 ( 90.91)	Acc@5  99.22 ( 99.85)
Epoch: [28][ 70/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.003)	Loss 2.1574e-01 (2.6226e-01)	Acc@1  92.97 ( 90.87)	Acc@5 100.00 ( 99.85)
Epoch: [28][ 80/391]	Time  0.045 ( 0.043)	Data  0.001 ( 0.003)	Loss 3.2375e-01 (2.6345e-01)	Acc@1  88.28 ( 90.75)	Acc@5 100.00 ( 99.86)
Epoch: [28][ 90/391]	Time  0.036 ( 0.043)	Data  0.001 ( 0.003)	Loss 2.4014e-01 (2.6065e-01)	Acc@1  92.19 ( 90.87)	Acc@5 100.00 ( 99.86)
Epoch: [28][100/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.003)	Loss 2.2107e-01 (2.5815e-01)	Acc@1  92.19 ( 90.97)	Acc@5 100.00 ( 99.85)
Epoch: [28][110/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.003)	Loss 2.4014e-01 (2.5728e-01)	Acc@1  90.62 ( 91.05)	Acc@5  99.22 ( 99.84)
Epoch: [28][120/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.6588e-01 (2.5964e-01)	Acc@1  95.31 ( 90.95)	Acc@5 100.00 ( 99.82)
Epoch: [28][130/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 3.2821e-01 (2.6254e-01)	Acc@1  85.16 ( 90.83)	Acc@5 100.00 ( 99.82)
Epoch: [28][140/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 3.0078e-01 (2.6311e-01)	Acc@1  92.19 ( 90.87)	Acc@5  99.22 ( 99.81)
Epoch: [28][150/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.5300e-01 (2.6416e-01)	Acc@1  90.62 ( 90.82)	Acc@5 100.00 ( 99.82)
Epoch: [28][160/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.6551e-01 (2.6431e-01)	Acc@1  92.19 ( 90.84)	Acc@5 100.00 ( 99.83)
Epoch: [28][170/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 3.6681e-01 (2.6392e-01)	Acc@1  89.06 ( 90.91)	Acc@5  99.22 ( 99.83)
Epoch: [28][180/391]	Time  0.046 ( 0.042)	Data  0.001 ( 0.002)	Loss 3.0980e-01 (2.6336e-01)	Acc@1  85.94 ( 90.95)	Acc@5 100.00 ( 99.84)
Epoch: [28][190/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.3346e-01 (2.6338e-01)	Acc@1  90.62 ( 90.96)	Acc@5  98.44 ( 99.83)
Epoch: [28][200/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.3410e-01 (2.6288e-01)	Acc@1  92.97 ( 90.96)	Acc@5 100.00 ( 99.84)
Epoch: [28][210/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.8580e-01 (2.6294e-01)	Acc@1  92.19 ( 90.96)	Acc@5  98.44 ( 99.82)
Epoch: [28][220/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.8754e-01 (2.6273e-01)	Acc@1  91.41 ( 90.97)	Acc@5  99.22 ( 99.82)
Epoch: [28][230/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.4818e-01 (2.6236e-01)	Acc@1  94.53 ( 90.98)	Acc@5 100.00 ( 99.82)
Epoch: [28][240/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.5439e-01 (2.6150e-01)	Acc@1  89.84 ( 90.98)	Acc@5 100.00 ( 99.82)
Epoch: [28][250/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.0217e-01 (2.6152e-01)	Acc@1  89.06 ( 90.98)	Acc@5 100.00 ( 99.82)
Epoch: [28][260/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.3829e-01 (2.6124e-01)	Acc@1  94.53 ( 90.98)	Acc@5 100.00 ( 99.82)
Epoch: [28][270/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.1392e-01 (2.6129e-01)	Acc@1  89.06 ( 90.98)	Acc@5  99.22 ( 99.82)
Epoch: [28][280/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.8227e-01 (2.6211e-01)	Acc@1  89.84 ( 90.99)	Acc@5 100.00 ( 99.81)
Epoch: [28][290/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.6475e-01 (2.6177e-01)	Acc@1  90.62 ( 91.00)	Acc@5 100.00 ( 99.81)
Epoch: [28][300/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.4377e-01 (2.6182e-01)	Acc@1  92.97 ( 90.99)	Acc@5  99.22 ( 99.80)
Epoch: [28][310/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.001)	Loss 2.6280e-01 (2.6084e-01)	Acc@1  92.19 ( 91.03)	Acc@5 100.00 ( 99.80)
Epoch: [28][320/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.001)	Loss 2.7431e-01 (2.6138e-01)	Acc@1  89.84 ( 91.00)	Acc@5 100.00 ( 99.80)
Epoch: [28][330/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.001)	Loss 2.3245e-01 (2.6149e-01)	Acc@1  92.97 ( 90.98)	Acc@5 100.00 ( 99.80)
Epoch: [28][340/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.001)	Loss 1.7926e-01 (2.6156e-01)	Acc@1  96.88 ( 90.98)	Acc@5 100.00 ( 99.80)
Epoch: [28][350/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.001)	Loss 3.0536e-01 (2.6199e-01)	Acc@1  91.41 ( 90.98)	Acc@5  99.22 ( 99.79)
Epoch: [28][360/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.001)	Loss 2.8403e-01 (2.6164e-01)	Acc@1  89.06 ( 90.96)	Acc@5  99.22 ( 99.79)
Epoch: [28][370/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.001)	Loss 2.8341e-01 (2.6188e-01)	Acc@1  90.62 ( 90.95)	Acc@5 100.00 ( 99.80)
Epoch: [28][380/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.001)	Loss 3.0312e-01 (2.6244e-01)	Acc@1  90.62 ( 90.93)	Acc@5 100.00 ( 99.80)
Epoch: [28][390/391]	Time  0.028 ( 0.041)	Data  0.001 ( 0.001)	Loss 5.4585e-01 (2.6336e-01)	Acc@1  80.00 ( 90.88)	Acc@5 100.00 ( 99.80)
## e[28] optimizer.zero_grad (sum) time: 0.2714221477508545
## e[28]       loss.backward (sum) time: 4.022079944610596
## e[28]      optimizer.step (sum) time: 1.7832036018371582
## epoch[28] training(only) time: 16.143136978149414
# Switched to evaluate mode...
Test: [  0/100]	Time  0.179 ( 0.179)	Loss 4.9154e-01 (4.9154e-01)	Acc@1  83.00 ( 83.00)	Acc@5  98.00 ( 98.00)
Test: [ 10/100]	Time  0.017 ( 0.033)	Loss 6.4989e-01 (5.1038e-01)	Acc@1  81.00 ( 84.18)	Acc@5 100.00 ( 99.18)
Test: [ 20/100]	Time  0.022 ( 0.027)	Loss 3.2900e-01 (5.1756e-01)	Acc@1  86.00 ( 84.05)	Acc@5 100.00 ( 99.05)
Test: [ 30/100]	Time  0.017 ( 0.024)	Loss 5.3126e-01 (5.1862e-01)	Acc@1  85.00 ( 84.39)	Acc@5  99.00 ( 99.06)
Test: [ 40/100]	Time  0.022 ( 0.024)	Loss 4.7610e-01 (5.1717e-01)	Acc@1  84.00 ( 84.37)	Acc@5  98.00 ( 99.07)
Test: [ 50/100]	Time  0.020 ( 0.023)	Loss 3.5617e-01 (5.0718e-01)	Acc@1  88.00 ( 84.69)	Acc@5 100.00 ( 99.14)
Test: [ 60/100]	Time  0.022 ( 0.023)	Loss 3.7890e-01 (5.0454e-01)	Acc@1  88.00 ( 84.69)	Acc@5 100.00 ( 99.20)
Test: [ 70/100]	Time  0.018 ( 0.022)	Loss 4.7827e-01 (4.9816e-01)	Acc@1  82.00 ( 84.63)	Acc@5 100.00 ( 99.28)
Test: [ 80/100]	Time  0.020 ( 0.022)	Loss 3.6776e-01 (4.9574e-01)	Acc@1  89.00 ( 84.78)	Acc@5 100.00 ( 99.32)
Test: [ 90/100]	Time  0.020 ( 0.022)	Loss 3.8149e-01 (4.9804e-01)	Acc@1  88.00 ( 84.66)	Acc@5  99.00 ( 99.32)
 * Acc@1 84.680 Acc@5 99.310
### epoch[28] execution time: 18.381953954696655
EPOCH 29
i:   0, name:           module.stem.0.weight  changing lr from: 0.034412522912332426   to: 0.031237753974350746
i:   1, name:             module.stem.0.bias  changing lr from: 0.035072962713554805   to: 0.031904239198440175
i:   2, name:           module.stem.1.weight  changing lr from: 0.035730037456447504   to: 0.032568176699762141
i:   3, name:             module.stem.1.bias  changing lr from: 0.036383612309236701   to: 0.033229396519150793
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.037033560223358498   to: 0.033887737519025476
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.037679761650102686   to: 0.034543047079952725
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.038322104265076463   to: 0.035195180804796368
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.038960482700391284   to: 0.035844002230416248
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.039594798284466097   to: 0.036489382546863534
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.040224958789334866   to: 0.037131200324008941
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.040850878185338703   to: 0.037769341245530226
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.041472476403078468   to: 0.038403697850175791
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.042089679102498230   to: 0.039034169280213089
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.042702417448967127   to: 0.039660661036963508
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.043310627896222649   to: 0.040283084743318667
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.043914251976037065   to: 0.040901357913128086
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.044513236094465301   to: 0.041515403727342304
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.045107531334532235   to: 0.042125150816792946
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.045697093265215143   to: 0.042730533051486080
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.046281881756577214   to: 0.043331489336283530
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.046861860800906957   to: 0.043927963412843690
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.047436998339719205   to: 0.044519903667692137
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.048007266096472934   to: 0.045107262946290166
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.048572639414862222   to: 0.045689998372968992
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.049133097102537771   to: 0.046268071176596648
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.049688621280116758   to: 0.046841446521843633
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.050239197235340996   to: 0.047410093345914554
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.050784813282244490   to: 0.047973984200612330
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.051325460625193157   to: 0.048533095099602686
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.051861133227661296   to: 0.049087405370746934
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.052391827685611604   to: 0.049636897513372781
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.052917543105347464   to: 0.050181557060353557
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.053438280985708346   to: 0.050721372444867678
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.053954045104481443   to: 0.051256334871712085
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.054464841408905257   to: 0.051786438193044508
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.054970677910142707   to: 0.052311678788431737
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.055471564581604654   to: 0.052832055449082517
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.055967513261005908   to: 0.053347569266145978
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.056458537556039870   to: 0.053858223522958340
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.056944652753558971   to: 0.054364023591122856
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.057425875732151910   to: 0.054864976830310302
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.057902224878010271   to: 0.055361092491669053
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.058373720003980036   to: 0.055852381624736561
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.058840382271696516   to: 0.056338856987746190
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.059302234116702546   to: 0.056820532961225190
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.059759299176453839   to: 0.057297425464782864
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.060211602221116448   to: 0.057769551876989213
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.060659169087064937   to: 0.058236930958247737
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.061102026612991446   to: 0.058699582776567276
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.061540202578538844   to: 0.059157528636141168
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.061973725645373103   to: 0.059610791008643506
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.062402625300612781   to: 0.060059393467154880
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.062826931802535457   to: 0.060503360622632341
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.063246676128483614   to: 0.060942718062840330
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.063661889924894355   to: 0.061377492293661733
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.064072605459379470   to: 0.061807710682709988
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.064478855574785277   to: 0.062233401405166311
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.064880673645162687   to: 0.062654593391766711
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.065278093533580966   to: 0.063071316278867237
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.065671149551719710   to: 0.063483600360516340
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.066059876421176930   to: 0.063891476542466741
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.066444309236431465   to: 0.064294976298059942
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.066824483429401033   to: 0.064694131625919207
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.067200434735538370   to: 0.065088975009388414
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.067572199161410440   to: 0.065479539377656229
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.067939812953706505   to: 0.065865858068506686
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.068303312569623284   to: 0.066247964792639238
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.068662734648576848   to: 0.066625893599502745
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.069018115985192682   to: 0.066999678844590141
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.069369493503526405   to: 0.067369355158141547
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.069716904232469956   to: 0.067734957415205618
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.070060385282298937   to: 0.068096520707010375
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.070399973822318551   to: 0.068454080313596441
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.070735707059566819   to: 0.068807671677666479
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.071067622218535395   to: 0.069157330379607557
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.071395756521869275   to: 0.069503092113642473
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.071720147172008392   to: 0.069844992665069522
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.072040831333734845   to: 0.070183067888550013
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.072357846117591329   to: 0.070517353687405235
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.072671228564137144   to: 0.070847885993885071
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.072981015629009091   to: 0.071174700750371897
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.073287244168756538   to: 0.071497833891485230
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.073589950927419823   to: 0.071817321327052583
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.073889172523823307   to: 0.072133198925914285
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.074184945439554714   to: 0.072445502500530209
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.074477306007603702   to: 0.072754267792358315
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.074766290401633281   to: 0.073059530457974822
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.075051934625859199   to: 0.073361326055908144
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.075334274505512319   to: 0.073659690034158509
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.075613345677861044   to: 0.073954657718376962
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.075889183583770836   to: 0.074246264300677753
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.076161823459778774   to: 0.074534544829059746
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.076431300330662547   to: 0.074819534197412371
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.076697649002483131   to: 0.075101267136083491
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.076960904056081691   to: 0.075379778202986580
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.077221099841011873   to: 0.075655101775225650
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.077478270469889296   to: 0.075927272041217506
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.077732449813140606   to: 0.076196322993290988
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.077983671494135209   to: 0.076462288420743929
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.078231968884683645   to: 0.076725201903339271
i: 100, name:           module.conv10.weight  changing lr from: 0.078477375100886468   to: 0.076985096805222461
i: 101, name:             module.conv10.bias  changing lr from: 0.078719922999319014   to: 0.077242006269242477



# Switched to train mode...
Epoch: [29][  0/391]	Time  0.216 ( 0.216)	Data  0.174 ( 0.174)	Loss 2.9114e-01 (2.9114e-01)	Acc@1  90.62 ( 90.62)	Acc@5  99.22 ( 99.22)
Epoch: [29][ 10/391]	Time  0.041 ( 0.056)	Data  0.001 ( 0.017)	Loss 3.4111e-01 (2.7625e-01)	Acc@1  88.28 ( 90.48)	Acc@5 100.00 ( 99.64)
Epoch: [29][ 20/391]	Time  0.041 ( 0.049)	Data  0.001 ( 0.009)	Loss 2.4785e-01 (2.5589e-01)	Acc@1  91.41 ( 91.18)	Acc@5 100.00 ( 99.81)
Epoch: [29][ 30/391]	Time  0.040 ( 0.046)	Data  0.001 ( 0.007)	Loss 2.8790e-01 (2.5039e-01)	Acc@1  88.28 ( 91.26)	Acc@5 100.00 ( 99.80)
Epoch: [29][ 40/391]	Time  0.042 ( 0.045)	Data  0.001 ( 0.005)	Loss 2.5100e-01 (2.5167e-01)	Acc@1  92.97 ( 91.20)	Acc@5 100.00 ( 99.83)
Epoch: [29][ 50/391]	Time  0.041 ( 0.044)	Data  0.001 ( 0.004)	Loss 3.0372e-01 (2.5537e-01)	Acc@1  92.19 ( 91.08)	Acc@5 100.00 ( 99.82)
Epoch: [29][ 60/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.004)	Loss 2.3195e-01 (2.5208e-01)	Acc@1  92.19 ( 91.19)	Acc@5  99.22 ( 99.82)
Epoch: [29][ 70/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.003)	Loss 2.5032e-01 (2.5419e-01)	Acc@1  89.84 ( 91.20)	Acc@5  99.22 ( 99.79)
Epoch: [29][ 80/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.003)	Loss 2.0916e-01 (2.5546e-01)	Acc@1  94.53 ( 91.17)	Acc@5 100.00 ( 99.78)
Epoch: [29][ 90/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.003)	Loss 2.7140e-01 (2.5273e-01)	Acc@1  89.06 ( 91.19)	Acc@5  99.22 ( 99.78)
Epoch: [29][100/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.003)	Loss 2.4972e-01 (2.5154e-01)	Acc@1  91.41 ( 91.24)	Acc@5  99.22 ( 99.76)
Epoch: [29][110/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.5269e-01 (2.5031e-01)	Acc@1  90.62 ( 91.31)	Acc@5 100.00 ( 99.77)
Epoch: [29][120/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.002)	Loss 3.7456e-01 (2.4998e-01)	Acc@1  86.72 ( 91.32)	Acc@5  99.22 ( 99.77)
Epoch: [29][130/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.0093e-01 (2.5135e-01)	Acc@1  92.19 ( 91.25)	Acc@5 100.00 ( 99.78)
Epoch: [29][140/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.3294e-01 (2.4974e-01)	Acc@1  90.62 ( 91.32)	Acc@5 100.00 ( 99.77)
Epoch: [29][150/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.1471e-01 (2.4830e-01)	Acc@1  92.19 ( 91.36)	Acc@5 100.00 ( 99.77)
Epoch: [29][160/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.9036e-01 (2.4893e-01)	Acc@1  85.94 ( 91.32)	Acc@5 100.00 ( 99.77)
Epoch: [29][170/391]	Time  0.043 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.9985e-01 (2.4867e-01)	Acc@1  92.19 ( 91.28)	Acc@5 100.00 ( 99.77)
Epoch: [29][180/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.9070e-01 (2.4945e-01)	Acc@1  87.50 ( 91.24)	Acc@5  99.22 ( 99.77)
Epoch: [29][190/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.6114e-01 (2.4924e-01)	Acc@1  92.19 ( 91.24)	Acc@5  99.22 ( 99.76)
Epoch: [29][200/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.0328e-01 (2.4897e-01)	Acc@1  85.16 ( 91.22)	Acc@5 100.00 ( 99.77)
Epoch: [29][210/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.4740e-01 (2.4882e-01)	Acc@1  89.06 ( 91.22)	Acc@5 100.00 ( 99.77)
Epoch: [29][220/391]	Time  0.044 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.9340e-01 (2.4964e-01)	Acc@1  89.84 ( 91.18)	Acc@5 100.00 ( 99.77)
Epoch: [29][230/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.6624e-01 (2.5056e-01)	Acc@1  93.75 ( 91.17)	Acc@5 100.00 ( 99.77)
Epoch: [29][240/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.8334e-01 (2.4976e-01)	Acc@1  90.62 ( 91.20)	Acc@5 100.00 ( 99.78)
Epoch: [29][250/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.0278e-01 (2.4897e-01)	Acc@1  93.75 ( 91.24)	Acc@5 100.00 ( 99.77)
Epoch: [29][260/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.9577e-01 (2.4930e-01)	Acc@1  89.84 ( 91.23)	Acc@5 100.00 ( 99.77)
Epoch: [29][270/391]	Time  0.040 ( 0.041)	Data  0.002 ( 0.002)	Loss 2.5464e-01 (2.5057e-01)	Acc@1  88.28 ( 91.21)	Acc@5 100.00 ( 99.78)
Epoch: [29][280/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.9392e-01 (2.4955e-01)	Acc@1  92.97 ( 91.27)	Acc@5 100.00 ( 99.77)
Epoch: [29][290/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.7496e-01 (2.4904e-01)	Acc@1  91.41 ( 91.29)	Acc@5 100.00 ( 99.78)
Epoch: [29][300/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.4766e-01 (2.4813e-01)	Acc@1  89.84 ( 91.31)	Acc@5 100.00 ( 99.78)
Epoch: [29][310/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.8245e-01 (2.4855e-01)	Acc@1  89.06 ( 91.33)	Acc@5  99.22 ( 99.78)
Epoch: [29][320/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.8991e-01 (2.4936e-01)	Acc@1  92.19 ( 91.27)	Acc@5 100.00 ( 99.78)
Epoch: [29][330/391]	Time  0.039 ( 0.041)	Data  0.002 ( 0.001)	Loss 1.7848e-01 (2.5010e-01)	Acc@1  94.53 ( 91.24)	Acc@5 100.00 ( 99.78)
Epoch: [29][340/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.001)	Loss 4.0261e-01 (2.5088e-01)	Acc@1  88.28 ( 91.24)	Acc@5  99.22 ( 99.78)
Epoch: [29][350/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.001)	Loss 2.7793e-01 (2.5178e-01)	Acc@1  90.62 ( 91.23)	Acc@5 100.00 ( 99.78)
Epoch: [29][360/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.001)	Loss 1.7436e-01 (2.5181e-01)	Acc@1  94.53 ( 91.23)	Acc@5 100.00 ( 99.78)
Epoch: [29][370/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.001)	Loss 3.3469e-01 (2.5244e-01)	Acc@1  85.16 ( 91.19)	Acc@5 100.00 ( 99.79)
Epoch: [29][380/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.001)	Loss 3.1608e-01 (2.5318e-01)	Acc@1  90.62 ( 91.16)	Acc@5 100.00 ( 99.78)
Epoch: [29][390/391]	Time  0.028 ( 0.041)	Data  0.001 ( 0.001)	Loss 3.3532e-01 (2.5296e-01)	Acc@1  85.00 ( 91.17)	Acc@5  98.75 ( 99.78)
## e[29] optimizer.zero_grad (sum) time: 0.2729825973510742
## e[29]       loss.backward (sum) time: 4.025461196899414
## e[29]      optimizer.step (sum) time: 1.817901611328125
## epoch[29] training(only) time: 16.011701107025146
# Switched to evaluate mode...
Test: [  0/100]	Time  0.172 ( 0.172)	Loss 3.6745e-01 (3.6745e-01)	Acc@1  86.00 ( 86.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.020 ( 0.035)	Loss 5.3802e-01 (3.9997e-01)	Acc@1  84.00 ( 86.55)	Acc@5 100.00 ( 99.73)
Test: [ 20/100]	Time  0.020 ( 0.028)	Loss 4.0828e-01 (4.1709e-01)	Acc@1  86.00 ( 86.43)	Acc@5  99.00 ( 99.48)
Test: [ 30/100]	Time  0.018 ( 0.025)	Loss 4.2637e-01 (4.2404e-01)	Acc@1  85.00 ( 87.03)	Acc@5 100.00 ( 99.32)
Test: [ 40/100]	Time  0.015 ( 0.024)	Loss 3.9222e-01 (4.2194e-01)	Acc@1  88.00 ( 86.80)	Acc@5  99.00 ( 99.29)
Test: [ 50/100]	Time  0.024 ( 0.023)	Loss 2.3856e-01 (4.2004e-01)	Acc@1  91.00 ( 86.69)	Acc@5  99.00 ( 99.25)
Test: [ 60/100]	Time  0.018 ( 0.022)	Loss 3.8745e-01 (4.1735e-01)	Acc@1  86.00 ( 86.57)	Acc@5  99.00 ( 99.28)
Test: [ 70/100]	Time  0.022 ( 0.022)	Loss 3.4765e-01 (4.1603e-01)	Acc@1  88.00 ( 86.59)	Acc@5 100.00 ( 99.35)
Test: [ 80/100]	Time  0.024 ( 0.022)	Loss 3.2722e-01 (4.1641e-01)	Acc@1  89.00 ( 86.60)	Acc@5 100.00 ( 99.38)
Test: [ 90/100]	Time  0.016 ( 0.022)	Loss 3.4093e-01 (4.1728e-01)	Acc@1  86.00 ( 86.49)	Acc@5 100.00 ( 99.40)
 * Acc@1 86.620 Acc@5 99.410
### epoch[29] execution time: 18.313522338867188
EPOCH 30
i:   0, name:           module.stem.0.weight  changing lr from: 0.031237753974350746   to: 0.028154806218479014
i:   1, name:             module.stem.0.bias  changing lr from: 0.031904239198440175   to: 0.028822947021865816
i:   2, name:           module.stem.1.weight  changing lr from: 0.032568176699762141   to: 0.029489480366081306
i:   3, name:             module.stem.1.bias  changing lr from: 0.033229396519150793   to: 0.030154198729653026
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.033887737519025476   to: 0.030816904452948591
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.034543047079952725   to: 0.031477409418263692
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.035195180804796368   to: 0.032135534736977403
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.035844002230416248   to: 0.032791110443810882
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.036489382546863534   to: 0.033443975198206841
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.037131200324008941   to: 0.034093975992830955
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.037769341245530226   to: 0.034740967869181162
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.038403697850175791   to: 0.035384813640277075
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.039034169280213089   to: 0.036025383620389005
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.039660661036963508   to: 0.036662555361755521
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.040283084743318667   to: 0.037296213398227335
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.040901357913128086   to: 0.037926248995767242
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.041515403727342304   to: 0.038552559909726759
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.042125150816792946   to: 0.039175050148813791
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.042730533051486080   to: 0.039793629745658365
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.043331489336283530   to: 0.040408214533878384
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.043927963412843690   to: 0.041018725931542308
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.044519903667692137   to: 0.041625090730921466
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.045107262946290166   to: 0.042227240894420683
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.045689998372968992   to: 0.042825113356573553
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.046268071176596648   to: 0.043418649831985269
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.046841446521843633   to: 0.044007796629104458
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.047410093345914554   to: 0.044592504469703614
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.047973984200612330   to: 0.045172728313946475
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.048533095099602686   to: 0.045748427190919816
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.049087405370746934   to: 0.046319564034506516
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.049636897513372781   to: 0.046886105524476779
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.050181557060353557   to: 0.047448021932674250
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.050721372444867678   to: 0.048005286974174055
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.051256334871712085   to: 0.048557877663290457
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.051786438193044508   to: 0.049105774174312625
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.052311678788431737   to: 0.049648959706847566
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.052832055449082517   to: 0.050187420355651179
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.053347569266145978   to: 0.050721144984828617
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.053858223522958340   to: 0.051250125106287507
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.054364023591122856   to: 0.051774354762328445
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.054864976830310302   to: 0.052293830412259192
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.055361092491669053   to: 0.052808550822920547
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.055852381624736561   to: 0.053318516963013575
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.056338856987746190   to: 0.053823731901120324
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.056820532961225190   to: 0.054324200707310921
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.057297425464782864   to: 0.054819930358233494
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.057769551876989213   to: 0.055310929645583685
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.058236930958247737   to: 0.055797209087854516
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.058699582776567276   to: 0.056278780845267079
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.059157528636141168   to: 0.056755658637787136
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.059610791008643506   to: 0.057227857666132878
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.060059393467154880   to: 0.057695394535682065
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.060503360622632341   to: 0.058158287183189064
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.060942718062840330   to: 0.058616554806223888
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.061377492293661733   to: 0.059070217795247786
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.061807710682709988   to: 0.059519297668241711
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.062233401405166311   to: 0.059963817007806924
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.062654593391766711   to: 0.060403799400657633
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.063071316278867237   to: 0.060839269379429239
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.063483600360516340   to: 0.061270252366726279
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.063891476542466741   to: 0.061696774621337470
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.064294976298059942   to: 0.062118863186546205
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.064694131625919207   to: 0.062536545840467306
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.065088975009388414   to: 0.062949851048342900
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.065479539377656229   to: 0.063358807916731458
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.065865858068506686   to: 0.063763446149527031
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.066247964792639238   to: 0.064163796005746135
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.066625893599502745   to: 0.064559888259022702
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.066999678844590141   to: 0.064951754158752803
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.067369355158141547   to: 0.065339425392832259
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.067734957415205618   to: 0.065722934051932663
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.068096520707010375   to: 0.066102312595261989
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.068454080313596441   to: 0.066477593817758890
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.068807671677666479   to: 0.066848810818669585
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.069157330379607557   to: 0.067215996971459954
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.069503092113642473   to: 0.067579185895014646
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.069844992665069522   to: 0.067938411426078413
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.070183067888550013   to: 0.068293707592894867
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.070517353687405235   to: 0.068645108590000420
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.070847885993885071   to: 0.068992648754131553
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.071174700750371897   to: 0.069336362541205260
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.071497833891485230   to: 0.069676284504334149
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.071817321327052583   to: 0.070012449272838229
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.072133198925914285   to: 0.070344891532217277
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.072445502500530209   to: 0.070673646005048107
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.072754267792358315   to: 0.070998747432773401
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.073059530457974822   to: 0.071320230558348380
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.073361326055908144   to: 0.071638130109713871
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.073659690034158509   to: 0.071952480784065062
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.073954657718376962   to: 0.072263317232885663
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.074246264300677753   to: 0.072570674047719094
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.074534544829059746   to: 0.072874585746648693
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.074819534197412371   to: 0.073175086761460242
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.075101267136083491   to: 0.073472211425460315
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.075379778202986580   to: 0.073765993961925930
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.075655101775225650   to: 0.074056468473160914
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.075927272041217506   to: 0.074343668930135554
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.076196322993290988   to: 0.074627629162687087
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.076462288420743929   to: 0.074908382850258901
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.076725201903339271   to: 0.075185963513157678
i: 100, name:           module.conv10.weight  changing lr from: 0.076985096805222461   to: 0.075460404504307729
i: 101, name:             module.conv10.bias  changing lr from: 0.077242006269242477   to: 0.075731739001483431



# Switched to train mode...
Epoch: [30][  0/391]	Time  0.210 ( 0.210)	Data  0.157 ( 0.157)	Loss 2.0738e-01 (2.0738e-01)	Acc@1  90.62 ( 90.62)	Acc@5 100.00 (100.00)
Epoch: [30][ 10/391]	Time  0.042 ( 0.057)	Data  0.001 ( 0.015)	Loss 1.9241e-01 (2.2277e-01)	Acc@1  93.75 ( 91.83)	Acc@5 100.00 ( 99.93)
Epoch: [30][ 20/391]	Time  0.040 ( 0.049)	Data  0.001 ( 0.008)	Loss 3.4763e-01 (2.2447e-01)	Acc@1  87.50 ( 92.00)	Acc@5  99.22 ( 99.85)
Epoch: [30][ 30/391]	Time  0.039 ( 0.046)	Data  0.001 ( 0.006)	Loss 1.6139e-01 (2.1841e-01)	Acc@1  95.31 ( 92.44)	Acc@5 100.00 ( 99.87)
Epoch: [30][ 40/391]	Time  0.041 ( 0.045)	Data  0.001 ( 0.005)	Loss 1.9418e-01 (2.1721e-01)	Acc@1  92.97 ( 92.23)	Acc@5 100.00 ( 99.85)
Epoch: [30][ 50/391]	Time  0.039 ( 0.044)	Data  0.001 ( 0.004)	Loss 1.8961e-01 (2.1417e-01)	Acc@1  92.97 ( 92.34)	Acc@5 100.00 ( 99.86)
Epoch: [30][ 60/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.004)	Loss 3.3321e-01 (2.1836e-01)	Acc@1  90.62 ( 92.23)	Acc@5 100.00 ( 99.86)
Epoch: [30][ 70/391]	Time  0.039 ( 0.043)	Data  0.001 ( 0.003)	Loss 2.8419e-01 (2.2526e-01)	Acc@1  90.62 ( 91.91)	Acc@5 100.00 ( 99.86)
Epoch: [30][ 80/391]	Time  0.039 ( 0.043)	Data  0.001 ( 0.003)	Loss 2.8506e-01 (2.2565e-01)	Acc@1  90.62 ( 92.04)	Acc@5 100.00 ( 99.86)
Epoch: [30][ 90/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.003)	Loss 2.7561e-01 (2.2315e-01)	Acc@1  89.06 ( 92.11)	Acc@5 100.00 ( 99.88)
Epoch: [30][100/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.003)	Loss 2.6468e-01 (2.2692e-01)	Acc@1  91.41 ( 92.05)	Acc@5 100.00 ( 99.87)
Epoch: [30][110/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.3408e-01 (2.2761e-01)	Acc@1  93.75 ( 92.03)	Acc@5 100.00 ( 99.87)
Epoch: [30][120/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.9984e-01 (2.2559e-01)	Acc@1  93.75 ( 92.13)	Acc@5 100.00 ( 99.87)
Epoch: [30][130/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.7611e-01 (2.2395e-01)	Acc@1  93.75 ( 92.18)	Acc@5 100.00 ( 99.87)
Epoch: [30][140/391]	Time  0.046 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.1985e-01 (2.2339e-01)	Acc@1  96.88 ( 92.18)	Acc@5 100.00 ( 99.87)
Epoch: [30][150/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.7377e-01 (2.2354e-01)	Acc@1  93.75 ( 92.20)	Acc@5 100.00 ( 99.86)
Epoch: [30][160/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.0578e-01 (2.2577e-01)	Acc@1  88.28 ( 92.14)	Acc@5 100.00 ( 99.86)
Epoch: [30][170/391]	Time  0.037 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.4279e-01 (2.2673e-01)	Acc@1  92.97 ( 92.11)	Acc@5 100.00 ( 99.84)
Epoch: [30][180/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.7092e-01 (2.2712e-01)	Acc@1  94.53 ( 92.08)	Acc@5 100.00 ( 99.85)
Epoch: [30][190/391]	Time  0.045 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.4861e-01 (2.2691e-01)	Acc@1  87.50 ( 92.06)	Acc@5 100.00 ( 99.85)
Epoch: [30][200/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 4.5124e-01 (2.2943e-01)	Acc@1  85.94 ( 91.96)	Acc@5  98.44 ( 99.85)
Epoch: [30][210/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.9748e-01 (2.3130e-01)	Acc@1  91.41 ( 91.82)	Acc@5 100.00 ( 99.85)
Epoch: [30][220/391]	Time  0.044 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.4027e-01 (2.3125e-01)	Acc@1  92.19 ( 91.84)	Acc@5 100.00 ( 99.86)
Epoch: [30][230/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.6240e-01 (2.3211e-01)	Acc@1  88.28 ( 91.79)	Acc@5  99.22 ( 99.85)
Epoch: [30][240/391]	Time  0.037 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.9720e-01 (2.3291e-01)	Acc@1  88.28 ( 91.76)	Acc@5 100.00 ( 99.86)
Epoch: [30][250/391]	Time  0.037 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.0250e-01 (2.3389e-01)	Acc@1  91.41 ( 91.72)	Acc@5 100.00 ( 99.86)
Epoch: [30][260/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.7395e-01 (2.3476e-01)	Acc@1  91.41 ( 91.70)	Acc@5 100.00 ( 99.87)
Epoch: [30][270/391]	Time  0.043 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.1047e-01 (2.3541e-01)	Acc@1  89.84 ( 91.68)	Acc@5 100.00 ( 99.87)
Epoch: [30][280/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.6187e-01 (2.3594e-01)	Acc@1  92.19 ( 91.66)	Acc@5 100.00 ( 99.87)
Epoch: [30][290/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.1468e-01 (2.3846e-01)	Acc@1  89.06 ( 91.59)	Acc@5  99.22 ( 99.86)
Epoch: [30][300/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.3289e-01 (2.3916e-01)	Acc@1  92.97 ( 91.60)	Acc@5  99.22 ( 99.86)
Epoch: [30][310/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.7933e-01 (2.4024e-01)	Acc@1  93.75 ( 91.57)	Acc@5 100.00 ( 99.86)
Epoch: [30][320/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.001)	Loss 3.1374e-01 (2.4098e-01)	Acc@1  87.50 ( 91.53)	Acc@5 100.00 ( 99.86)
Epoch: [30][330/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.001)	Loss 2.3079e-01 (2.4005e-01)	Acc@1  90.62 ( 91.55)	Acc@5 100.00 ( 99.86)
Epoch: [30][340/391]	Time  0.040 ( 0.041)	Data  0.004 ( 0.001)	Loss 3.3182e-01 (2.4104e-01)	Acc@1  89.06 ( 91.51)	Acc@5 100.00 ( 99.86)
Epoch: [30][350/391]	Time  0.044 ( 0.041)	Data  0.002 ( 0.001)	Loss 3.7353e-01 (2.4215e-01)	Acc@1  87.50 ( 91.48)	Acc@5 100.00 ( 99.87)
Epoch: [30][360/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.001)	Loss 2.4468e-01 (2.4264e-01)	Acc@1  90.62 ( 91.48)	Acc@5 100.00 ( 99.87)
Epoch: [30][370/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.001)	Loss 3.4424e-01 (2.4380e-01)	Acc@1  85.94 ( 91.44)	Acc@5 100.00 ( 99.87)
Epoch: [30][380/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.001)	Loss 2.6291e-01 (2.4517e-01)	Acc@1  89.06 ( 91.40)	Acc@5 100.00 ( 99.86)
Epoch: [30][390/391]	Time  0.028 ( 0.040)	Data  0.001 ( 0.001)	Loss 1.5976e-01 (2.4450e-01)	Acc@1  93.75 ( 91.42)	Acc@5 100.00 ( 99.87)
## e[30] optimizer.zero_grad (sum) time: 0.27305150032043457
## e[30]       loss.backward (sum) time: 3.97757625579834
## e[30]      optimizer.step (sum) time: 1.8236947059631348
## epoch[30] training(only) time: 15.947604894638062
# Switched to evaluate mode...
Test: [  0/100]	Time  0.172 ( 0.172)	Loss 3.1487e-01 (3.1487e-01)	Acc@1  87.00 ( 87.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.024 ( 0.035)	Loss 5.7658e-01 (4.1718e-01)	Acc@1  87.00 ( 86.73)	Acc@5 100.00 ( 99.55)
Test: [ 20/100]	Time  0.022 ( 0.029)	Loss 3.9593e-01 (4.1292e-01)	Acc@1  84.00 ( 86.57)	Acc@5 100.00 ( 99.48)
Test: [ 30/100]	Time  0.022 ( 0.027)	Loss 4.7915e-01 (4.3700e-01)	Acc@1  83.00 ( 86.26)	Acc@5  99.00 ( 99.39)
Test: [ 40/100]	Time  0.019 ( 0.025)	Loss 4.6488e-01 (4.4613e-01)	Acc@1  82.00 ( 85.85)	Acc@5 100.00 ( 99.27)
Test: [ 50/100]	Time  0.023 ( 0.024)	Loss 3.6914e-01 (4.3499e-01)	Acc@1  86.00 ( 86.14)	Acc@5 100.00 ( 99.39)
Test: [ 60/100]	Time  0.023 ( 0.024)	Loss 4.2323e-01 (4.3755e-01)	Acc@1  91.00 ( 86.23)	Acc@5 100.00 ( 99.41)
Test: [ 70/100]	Time  0.022 ( 0.023)	Loss 2.6072e-01 (4.2923e-01)	Acc@1  93.00 ( 86.48)	Acc@5  99.00 ( 99.45)
Test: [ 80/100]	Time  0.020 ( 0.023)	Loss 3.1055e-01 (4.2320e-01)	Acc@1  89.00 ( 86.62)	Acc@5 100.00 ( 99.51)
Test: [ 90/100]	Time  0.019 ( 0.023)	Loss 2.6487e-01 (4.2249e-01)	Acc@1  88.00 ( 86.53)	Acc@5 100.00 ( 99.51)
 * Acc@1 86.470 Acc@5 99.500
### epoch[30] execution time: 18.331867694854736
EPOCH 31
i:   0, name:           module.stem.0.weight  changing lr from: 0.028154806218479014   to: 0.025178003922785554
i:   1, name:             module.stem.0.bias  changing lr from: 0.028822947021865816   to: 0.025843194105596646
i:   2, name:           module.stem.1.weight  changing lr from: 0.029489480366081306   to: 0.026507839539321398
i:   3, name:             module.stem.1.bias  changing lr from: 0.030154198729653026   to: 0.027171692982877083
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.030816904452948591   to: 0.027834518080325905
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.031477409418263692   to: 0.028496089029063643
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.032135534736977403   to: 0.029156190254225268
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.032791110443810882   to: 0.029814616089436904
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.033443975198206841   to: 0.030471170464018562
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.034093975992830955   to: 0.031125666596720031
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.034740967869181162   to: 0.031777926696051631
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.035384813640277075   to: 0.032427781667251923
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.036025383620389005   to: 0.033075070825917714
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.036662555361755521   to: 0.033719641618305270
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.037296213398227335   to: 0.034361349348297231
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.037926248995767242   to: 0.035000056911016673
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.038552559909726759   to: 0.035635634533056841
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.039175050148813791   to: 0.036267959519285700
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.039793629745658365   to: 0.036896916006172745
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.040408214533878384   to: 0.037522394721577944
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.041018725931542308   to: 0.038144292750934131
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.041625090730921466   to: 0.038762513309747143
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.042227240894420683   to: 0.039376965522331685
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.042825113356573553   to: 0.039987564206695185
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.043418649831985269   to: 0.040594229665477155
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.044007796629104458   to: 0.041196887482846965
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.044592504469703614   to: 0.041795468327259618
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.045172728313946475   to: 0.042389907759965720
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.045748427190919816   to: 0.042980146049169103
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.046319564034506516   to: 0.043566127989723313
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.046886105524476779   to: 0.044147802728256781
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.047448021932674250   to: 0.044725123593614607
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.048005286974174055   to: 0.045298047932503950
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.048557877663290457   to: 0.045866536950229679
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.049105774174312625   to: 0.046430555556405878
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.049648959706847566   to: 0.046990072215529179
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.050187420355651179   to: 0.047545058802299978
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.050721144984828617   to: 0.048095490461577371
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.051250125106287507   to: 0.048641345472854931
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.051774354762328445   to: 0.049182605119144712
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.052293830412259192   to: 0.049719253560157869
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.052808550822920547   to: 0.050251277709671333
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.053318516963013575   to: 0.050778667116971134
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.053823731901120324   to: 0.051301413852264499
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.054324200707310921   to: 0.051819512395953671
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.054819930358233494   to: 0.052332959531666813
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.055310929645583685   to: 0.052841754242941789
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.055797209087854516   to: 0.053345897613461694
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.056278780845267079   to: 0.053845392730741154
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.056755658637787136   to: 0.054340244593165533
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.057227857666132878   to: 0.054830460020286298
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.057695394535682065   to: 0.055316047566277608
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.058158287183189064   to: 0.055797017436461628
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.058616554806223888   to: 0.056273381406811387
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.059070217795247786   to: 0.056745152746342280
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.059519297668241711   to: 0.057212346142304853
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.059963817007806924   to: 0.057674977628094405
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.060403799400657633   to: 0.058133064513793312
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.060839269379429239   to: 0.058586625319265666
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.061270252366726279   to: 0.059035679709724224
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.061696774621337470   to: 0.059480248433692963
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.062118863186546205   to: 0.059920353263289074
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.062536545840467306   to: 0.060356016936751404
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.062949851048342900   to: 0.060787263103143196
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.063358807916731458   to: 0.061214116269159673
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.063763446149527031   to: 0.061636601747972170
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.064163796005746135   to: 0.062054745610042789
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.064559888259022702   to: 0.062468574635845091
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.064951754158752803   to: 0.062878116270428233
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.065339425392832259   to: 0.063283398579763533
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.065722934051932663   to: 0.063684450208814511
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.066102312595261989   to: 0.064081300341272282
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.066477593817758890   to: 0.064473978660901252
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.066848810818669585   to: 0.064862515314439900
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.067215996971459954   to: 0.065246940876004592
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.067579185895014646   to: 0.065627286312944941
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.067938411426078413   to: 0.066003582953101117
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.068293707592894867   to: 0.066375862453414688
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.068645108590000420   to: 0.066744156769846685
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.068992648754131553   to: 0.067108498128557223
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.069336362541205260   to: 0.067468918998302527
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.069676284504334149   to: 0.067825452064007349
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.070012449272838229   to: 0.068178130201470719
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.070344891532217277   to: 0.068526986453165725
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.070673646005048107   to: 0.068872054005093872
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.070998747432773401   to: 0.069213366164656828
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.071320230558348380   to: 0.069550956339509293
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.071638130109713871   to: 0.069884858017357249
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.071952480784065062   to: 0.070215104746667978
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.072263317232885663   to: 0.070541730118258580
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.072570674047719094   to: 0.070864767747731136
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.072874585746648693   to: 0.071184251258723394
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.073175086761460242   to: 0.071500214266945403
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.073472211425460315   to: 0.071812690364972787
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.073765993961925930   to: 0.072121713107768978
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.074056468473160914   to: 0.072427315998909031
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.074343668930135554   to: 0.072729532477479111
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.074627629162687087   to: 0.073028395905626223
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.074908382850258901   to: 0.073323939556733678
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.075185963513157678   to: 0.073616196604198686
i: 100, name:           module.conv10.weight  changing lr from: 0.075460404504307729   to: 0.073905200110789313
i: 101, name:             module.conv10.bias  changing lr from: 0.075731739001483431   to: 0.074190983018558629



# Switched to train mode...
Epoch: [31][  0/391]	Time  0.218 ( 0.218)	Data  0.175 ( 0.175)	Loss 1.6519e-01 (1.6519e-01)	Acc@1  93.75 ( 93.75)	Acc@5 100.00 (100.00)
Epoch: [31][ 10/391]	Time  0.039 ( 0.057)	Data  0.001 ( 0.017)	Loss 2.0211e-01 (2.3289e-01)	Acc@1  94.53 ( 91.55)	Acc@5 100.00 ( 99.93)
Epoch: [31][ 20/391]	Time  0.040 ( 0.049)	Data  0.001 ( 0.009)	Loss 2.2327e-01 (2.3358e-01)	Acc@1  90.62 ( 91.82)	Acc@5 100.00 ( 99.85)
Epoch: [31][ 30/391]	Time  0.040 ( 0.046)	Data  0.001 ( 0.007)	Loss 2.2467e-01 (2.2576e-01)	Acc@1  92.19 ( 92.26)	Acc@5 100.00 ( 99.80)
Epoch: [31][ 40/391]	Time  0.039 ( 0.045)	Data  0.001 ( 0.005)	Loss 2.1935e-01 (2.2418e-01)	Acc@1  92.97 ( 92.45)	Acc@5 100.00 ( 99.83)
Epoch: [31][ 50/391]	Time  0.039 ( 0.044)	Data  0.001 ( 0.005)	Loss 3.2127e-01 (2.2216e-01)	Acc@1  86.72 ( 92.34)	Acc@5  99.22 ( 99.85)
Epoch: [31][ 60/391]	Time  0.039 ( 0.043)	Data  0.001 ( 0.004)	Loss 2.1026e-01 (2.1960e-01)	Acc@1  89.06 ( 92.29)	Acc@5 100.00 ( 99.86)
Epoch: [31][ 70/391]	Time  0.037 ( 0.043)	Data  0.001 ( 0.004)	Loss 2.9172e-01 (2.2270e-01)	Acc@1  87.50 ( 92.22)	Acc@5 100.00 ( 99.85)
Epoch: [31][ 80/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.003)	Loss 1.7228e-01 (2.2490e-01)	Acc@1  93.75 ( 92.19)	Acc@5 100.00 ( 99.86)
Epoch: [31][ 90/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.003)	Loss 2.0845e-01 (2.2372e-01)	Acc@1  92.19 ( 92.25)	Acc@5 100.00 ( 99.85)
Epoch: [31][100/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.003)	Loss 3.0192e-01 (2.2335e-01)	Acc@1  89.84 ( 92.34)	Acc@5 100.00 ( 99.85)
Epoch: [31][110/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.003)	Loss 1.6967e-01 (2.2242e-01)	Acc@1  92.19 ( 92.36)	Acc@5 100.00 ( 99.85)
Epoch: [31][120/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.4622e-01 (2.2246e-01)	Acc@1  94.53 ( 92.36)	Acc@5  98.44 ( 99.84)
Epoch: [31][130/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.3441e-01 (2.2600e-01)	Acc@1  92.19 ( 92.25)	Acc@5  99.22 ( 99.83)
Epoch: [31][140/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.7711e-01 (2.2652e-01)	Acc@1  93.75 ( 92.19)	Acc@5 100.00 ( 99.83)
Epoch: [31][150/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.4914e-01 (2.2760e-01)	Acc@1  90.62 ( 92.17)	Acc@5 100.00 ( 99.83)
Epoch: [31][160/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.4052e-01 (2.2696e-01)	Acc@1  96.09 ( 92.22)	Acc@5 100.00 ( 99.84)
Epoch: [31][170/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 3.0570e-01 (2.2577e-01)	Acc@1  89.06 ( 92.24)	Acc@5  99.22 ( 99.84)
Epoch: [31][180/391]	Time  0.045 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.3504e-01 (2.2639e-01)	Acc@1  91.41 ( 92.18)	Acc@5 100.00 ( 99.84)
Epoch: [31][190/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.4672e-01 (2.2741e-01)	Acc@1  93.75 ( 92.14)	Acc@5  99.22 ( 99.83)
Epoch: [31][200/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.0494e-01 (2.2801e-01)	Acc@1  92.19 ( 92.08)	Acc@5 100.00 ( 99.83)
Epoch: [31][210/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.2254e-01 (2.2870e-01)	Acc@1  91.41 ( 92.07)	Acc@5  99.22 ( 99.82)
Epoch: [31][220/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.1866e-01 (2.2834e-01)	Acc@1  95.31 ( 92.08)	Acc@5 100.00 ( 99.82)
Epoch: [31][230/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.9671e-01 (2.2978e-01)	Acc@1  88.28 ( 92.02)	Acc@5 100.00 ( 99.82)
Epoch: [31][240/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.2129e-01 (2.2957e-01)	Acc@1  94.53 ( 92.04)	Acc@5 100.00 ( 99.82)
Epoch: [31][250/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.8909e-01 (2.2914e-01)	Acc@1  93.75 ( 92.02)	Acc@5 100.00 ( 99.82)
Epoch: [31][260/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.0335e-01 (2.2925e-01)	Acc@1  93.75 ( 92.03)	Acc@5 100.00 ( 99.81)
Epoch: [31][270/391]	Time  0.040 ( 0.041)	Data  0.002 ( 0.002)	Loss 2.6875e-01 (2.3090e-01)	Acc@1  91.41 ( 91.98)	Acc@5 100.00 ( 99.81)
Epoch: [31][280/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.1393e-01 (2.3200e-01)	Acc@1  92.19 ( 91.96)	Acc@5 100.00 ( 99.81)
Epoch: [31][290/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.0470e-01 (2.3240e-01)	Acc@1  90.62 ( 91.96)	Acc@5 100.00 ( 99.81)
Epoch: [31][300/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.5254e-01 (2.3286e-01)	Acc@1  93.75 ( 91.97)	Acc@5 100.00 ( 99.81)
Epoch: [31][310/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.9394e-01 (2.3391e-01)	Acc@1  89.84 ( 91.91)	Acc@5 100.00 ( 99.81)
Epoch: [31][320/391]	Time  0.043 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.3732e-01 (2.3452e-01)	Acc@1  95.31 ( 91.91)	Acc@5  99.22 ( 99.81)
Epoch: [31][330/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.1382e-01 (2.3490e-01)	Acc@1  89.84 ( 91.89)	Acc@5 100.00 ( 99.81)
Epoch: [31][340/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.001)	Loss 1.2611e-01 (2.3502e-01)	Acc@1  96.88 ( 91.88)	Acc@5 100.00 ( 99.81)
Epoch: [31][350/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.001)	Loss 2.2967e-01 (2.3456e-01)	Acc@1  90.62 ( 91.88)	Acc@5 100.00 ( 99.82)
Epoch: [31][360/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.001)	Loss 3.3348e-01 (2.3578e-01)	Acc@1  88.28 ( 91.86)	Acc@5 100.00 ( 99.82)
Epoch: [31][370/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.001)	Loss 2.5975e-01 (2.3493e-01)	Acc@1  89.06 ( 91.89)	Acc@5 100.00 ( 99.82)
Epoch: [31][380/391]	Time  0.046 ( 0.041)	Data  0.001 ( 0.001)	Loss 2.3048e-01 (2.3587e-01)	Acc@1  90.62 ( 91.85)	Acc@5 100.00 ( 99.82)
Epoch: [31][390/391]	Time  0.029 ( 0.041)	Data  0.001 ( 0.001)	Loss 3.3015e-01 (2.3551e-01)	Acc@1  91.25 ( 91.89)	Acc@5 100.00 ( 99.82)
## e[31] optimizer.zero_grad (sum) time: 0.2703418731689453
## e[31]       loss.backward (sum) time: 3.986487627029419
## e[31]      optimizer.step (sum) time: 1.821357250213623
## epoch[31] training(only) time: 16.103894472122192
# Switched to evaluate mode...
Test: [  0/100]	Time  0.192 ( 0.192)	Loss 2.4820e-01 (2.4820e-01)	Acc@1  92.00 ( 92.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.024 ( 0.038)	Loss 5.4820e-01 (3.8341e-01)	Acc@1  81.00 ( 87.64)	Acc@5 100.00 ( 99.64)
Test: [ 20/100]	Time  0.017 ( 0.030)	Loss 4.0183e-01 (4.0785e-01)	Acc@1  86.00 ( 86.38)	Acc@5  98.00 ( 99.48)
Test: [ 30/100]	Time  0.018 ( 0.027)	Loss 4.0925e-01 (4.1288e-01)	Acc@1  87.00 ( 86.61)	Acc@5  98.00 ( 99.32)
Test: [ 40/100]	Time  0.023 ( 0.025)	Loss 4.1938e-01 (4.1317e-01)	Acc@1  85.00 ( 86.71)	Acc@5 100.00 ( 99.32)
Test: [ 50/100]	Time  0.023 ( 0.025)	Loss 3.2792e-01 (4.1324e-01)	Acc@1  86.00 ( 86.61)	Acc@5 100.00 ( 99.27)
Test: [ 60/100]	Time  0.017 ( 0.024)	Loss 4.3686e-01 (4.1970e-01)	Acc@1  84.00 ( 86.30)	Acc@5  98.00 ( 99.33)
Test: [ 70/100]	Time  0.019 ( 0.023)	Loss 3.8190e-01 (4.1528e-01)	Acc@1  87.00 ( 86.48)	Acc@5  99.00 ( 99.37)
Test: [ 80/100]	Time  0.016 ( 0.023)	Loss 2.5273e-01 (4.1299e-01)	Acc@1  92.00 ( 86.62)	Acc@5 100.00 ( 99.42)
Test: [ 90/100]	Time  0.022 ( 0.023)	Loss 2.5690e-01 (4.1506e-01)	Acc@1  92.00 ( 86.49)	Acc@5 100.00 ( 99.44)
 * Acc@1 86.530 Acc@5 99.440
### epoch[31] execution time: 18.442887783050537
EPOCH 32
i:   0, name:           module.stem.0.weight  changing lr from: 0.025178003922785554   to: 0.022321178182447728
i:   1, name:             module.stem.0.bias  changing lr from: 0.025843194105596646   to: 0.022978623466462275
i:   2, name:           module.stem.1.weight  changing lr from: 0.026507839539321398   to: 0.023636707388760666
i:   3, name:             module.stem.1.bias  changing lr from: 0.027171692982877083   to: 0.024295141160509067
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.027834518080325905   to: 0.024953647863799878
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.028496089029063643   to: 0.025611962113519661
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.029156190254225268   to: 0.026269829724213246
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.029814616089436904   to: 0.026927007382186521
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.030471170464018562   to: 0.027583262323057731
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.031125666596720031   to: 0.028238372014938468
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.031777926696051631   to: 0.028892123847398612
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.032427781667251923   to: 0.029544314826343832
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.033075070825917714   to: 0.030194751274911537
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.033719641618305270   to: 0.030843248540469839
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.034361349348297231   to: 0.031489630707783843
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.035000056911016673   to: 0.032133730318396440
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.035635634533056841   to: 0.032775388096252821
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.036267959519285700   to: 0.033414452679584393
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.036896916006172745   to: 0.034050780359051923
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.037522394721577944   to: 0.034684234822136714
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.038144292750934131   to: 0.035314686903755686
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.038762513309747143   to: 0.035942014343066798
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.039376965522331685   to: 0.036566101546420753
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.039987564206695185   to: 0.037186839356407049
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.040594229665477155   to: 0.037804124826934342
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.041196887482846965   to: 0.038417861004277874
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.041795468327259618   to: 0.039027956714021268
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.042389907759965720   to: 0.039634326353813698
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.042980146049169103   to: 0.040236889691859165
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.043566127989723313   to: 0.040835571671049654
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.044147802728256781   to: 0.041430302218651113
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.044725123593614607   to: 0.042021016061447369
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.045298047932503950   to: 0.042607652546244462
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.045866536950229679   to: 0.043190155465635711
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.046430555556405878   to: 0.043768472888926019
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.046990072215529179   to: 0.044342556998112168
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.047545058802299978   to: 0.044912363928814800
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.048095490461577371   to: 0.045477853616057211
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.048641345472854931   to: 0.046038989644784832
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.049182605119144712   to: 0.046595739105019823
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.049719253560157869   to: 0.047148072451544475
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.050251277709671333   to: 0.047695963368007764
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.050778667116971134   to: 0.048239388635349149
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.051301413852264499   to: 0.048778328004435240
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.051819512395953671   to: 0.049312764072804487
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.052332959531666813   to: 0.049842682165416985
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.052841754242941789   to: 0.050368070219306504
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.053345897613461694   to: 0.050888918672034281
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.053845392730741154   to: 0.051405220353843296
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.054340244593165533   to: 0.051916970383415695
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.054830460020286298   to: 0.052424166067134750
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.055316047566277608   to: 0.052926806801756425
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.055797017436461628   to: 0.053424893980395655
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.056273381406811387   to: 0.053918430901734975
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.056745152746342280   to: 0.054407422682364204
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.057212346142304853   to: 0.054891876172161583
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.057674977628094405   to: 0.055371799872629184
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.058133064513793312   to: 0.055847203858096155
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.058586625319265666   to: 0.056318099699705818
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.059035679709724224   to: 0.056784500392103900
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.059480248433692963   to: 0.057246420282747915
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.059920353263289074   to: 0.057703875003757787
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.060356016936751404   to: 0.058156881406231570
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.060787263103143196   to: 0.058605457496950446
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.061214116269159673   to: 0.059049622377399594
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.061636601747972170   to: 0.059489396185033266
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.062054745610042789   to: 0.059924800036713959
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.062468574635845091   to: 0.060355855974257300
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.062878116270428233   to: 0.060782586912016615
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.063283398579763533   to: 0.061205016586441612
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.063684450208814511   to: 0.061623169507548814
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.064081300341272282   to: 0.062037070912241511
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.064473978660901252   to: 0.062446746719420188
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.064862515314439900   to: 0.062852223486824371
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.065246940876004592   to: 0.063253528369550102
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.065627286312944941   to: 0.063650689080187242
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.066003582953101117   to: 0.064043733850523643
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.066375862453414688   to: 0.064432691394763736
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.066744156769846685   to: 0.064817590874211226
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.067108498128557223   to: 0.065198461863367002
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.067468918998302527   to: 0.065575334317393805
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.067825452064007349   to: 0.065948238540902468
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.068178130201470719   to: 0.066317205158013925
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.068526986453165725   to: 0.066682265083653755
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.068872054005093872   to: 0.067043449496036897
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.069213366164656828   to: 0.067400789810301731
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.069550956339509293   to: 0.067754317653253224
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.069884858017357249   to: 0.068104064839177150
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.070215104746667978   to: 0.068450063346687615
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.070541730118258580   to: 0.068792345296571744
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.070864767747731136   to: 0.069130942930596559
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.071184251258723394   to: 0.069465888591243669
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.071500214266945403   to: 0.069797214702339239
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.071812690364972787   to: 0.070124953750546989
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.072121713107768978   to: 0.070449138267693556
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.072427315998909031   to: 0.070769800813895944
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.072729532477479111   to: 0.071086973961462588
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.073028395905626223   to: 0.071400690279539561
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.073323939556733678   to: 0.071710982319474981
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.073616196604198686   to: 0.072017882600875271
i: 100, name:           module.conv10.weight  changing lr from: 0.073905200110789313   to: 0.072321423598328063
i: 101, name:             module.conv10.bias  changing lr from: 0.074190983018558629   to: 0.072621637728766827



# Switched to train mode...
Epoch: [32][  0/391]	Time  0.208 ( 0.208)	Data  0.165 ( 0.165)	Loss 2.3739e-01 (2.3739e-01)	Acc@1  91.41 ( 91.41)	Acc@5 100.00 (100.00)
Epoch: [32][ 10/391]	Time  0.039 ( 0.055)	Data  0.001 ( 0.016)	Loss 2.7365e-01 (2.2693e-01)	Acc@1  92.19 ( 92.05)	Acc@5 100.00 ( 99.86)
Epoch: [32][ 20/391]	Time  0.040 ( 0.049)	Data  0.001 ( 0.009)	Loss 2.2952e-01 (2.2695e-01)	Acc@1  89.84 ( 92.04)	Acc@5 100.00 ( 99.85)
Epoch: [32][ 30/391]	Time  0.038 ( 0.046)	Data  0.001 ( 0.006)	Loss 2.5938e-01 (2.2695e-01)	Acc@1  92.19 ( 91.86)	Acc@5 100.00 ( 99.90)
Epoch: [32][ 40/391]	Time  0.041 ( 0.045)	Data  0.001 ( 0.005)	Loss 2.4116e-01 (2.2278e-01)	Acc@1  92.19 ( 92.11)	Acc@5 100.00 ( 99.89)
Epoch: [32][ 50/391]	Time  0.039 ( 0.044)	Data  0.001 ( 0.004)	Loss 1.7613e-01 (2.1954e-01)	Acc@1  94.53 ( 92.23)	Acc@5 100.00 ( 99.89)
Epoch: [32][ 60/391]	Time  0.038 ( 0.043)	Data  0.001 ( 0.004)	Loss 1.4488e-01 (2.2190e-01)	Acc@1  93.75 ( 92.19)	Acc@5 100.00 ( 99.91)
Epoch: [32][ 70/391]	Time  0.038 ( 0.043)	Data  0.001 ( 0.003)	Loss 1.8382e-01 (2.2157e-01)	Acc@1  93.75 ( 92.12)	Acc@5  99.22 ( 99.89)
Epoch: [32][ 80/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.003)	Loss 2.6994e-01 (2.2032e-01)	Acc@1  89.84 ( 92.15)	Acc@5  99.22 ( 99.89)
Epoch: [32][ 90/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.003)	Loss 3.7657e-01 (2.2244e-01)	Acc@1  86.72 ( 92.02)	Acc@5  99.22 ( 99.90)
Epoch: [32][100/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.003)	Loss 2.7777e-01 (2.2170e-01)	Acc@1  89.06 ( 92.07)	Acc@5 100.00 ( 99.91)
Epoch: [32][110/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.2339e-01 (2.2167e-01)	Acc@1  89.84 ( 92.07)	Acc@5 100.00 ( 99.89)
Epoch: [32][120/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.2422e-01 (2.2238e-01)	Acc@1  92.19 ( 92.06)	Acc@5 100.00 ( 99.88)
Epoch: [32][130/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.1700e-01 (2.2269e-01)	Acc@1  90.62 ( 92.06)	Acc@5 100.00 ( 99.87)
Epoch: [32][140/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.6747e-01 (2.2206e-01)	Acc@1  94.53 ( 92.14)	Acc@5 100.00 ( 99.87)
Epoch: [32][150/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.0899e-01 (2.2301e-01)	Acc@1  91.41 ( 92.12)	Acc@5 100.00 ( 99.87)
Epoch: [32][160/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.5146e-01 (2.2347e-01)	Acc@1  92.19 ( 92.12)	Acc@5 100.00 ( 99.87)
Epoch: [32][170/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.3455e-01 (2.2441e-01)	Acc@1  91.41 ( 92.11)	Acc@5  99.22 ( 99.87)
Epoch: [32][180/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.7527e-01 (2.2365e-01)	Acc@1  94.53 ( 92.13)	Acc@5 100.00 ( 99.87)
Epoch: [32][190/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.8682e-01 (2.2214e-01)	Acc@1  93.75 ( 92.16)	Acc@5 100.00 ( 99.88)
Epoch: [32][200/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.6540e-01 (2.2262e-01)	Acc@1  93.75 ( 92.18)	Acc@5 100.00 ( 99.88)
Epoch: [32][210/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.8543e-01 (2.2192e-01)	Acc@1  92.19 ( 92.18)	Acc@5 100.00 ( 99.88)
Epoch: [32][220/391]	Time  0.046 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.6754e-01 (2.2373e-01)	Acc@1  90.62 ( 92.13)	Acc@5 100.00 ( 99.87)
Epoch: [32][230/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.9018e-01 (2.2553e-01)	Acc@1  88.28 ( 92.05)	Acc@5 100.00 ( 99.87)
Epoch: [32][240/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.6171e-01 (2.2669e-01)	Acc@1  89.84 ( 91.99)	Acc@5 100.00 ( 99.87)
Epoch: [32][250/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.5062e-01 (2.2795e-01)	Acc@1  86.72 ( 91.94)	Acc@5 100.00 ( 99.87)
Epoch: [32][260/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.8608e-01 (2.2763e-01)	Acc@1  89.06 ( 91.94)	Acc@5 100.00 ( 99.87)
Epoch: [32][270/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.9608e-01 (2.2738e-01)	Acc@1  92.19 ( 91.97)	Acc@5 100.00 ( 99.87)
Epoch: [32][280/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.9632e-01 (2.2743e-01)	Acc@1  89.06 ( 91.97)	Acc@5  99.22 ( 99.87)
Epoch: [32][290/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.4859e-01 (2.2774e-01)	Acc@1  91.41 ( 92.00)	Acc@5 100.00 ( 99.86)
Epoch: [32][300/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.001)	Loss 2.3050e-01 (2.2707e-01)	Acc@1  93.75 ( 92.03)	Acc@5 100.00 ( 99.87)
Epoch: [32][310/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.001)	Loss 1.6033e-01 (2.2695e-01)	Acc@1  94.53 ( 92.04)	Acc@5 100.00 ( 99.86)
Epoch: [32][320/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.001)	Loss 2.3530e-01 (2.2815e-01)	Acc@1  89.84 ( 92.00)	Acc@5 100.00 ( 99.86)
Epoch: [32][330/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.001)	Loss 1.6477e-01 (2.2714e-01)	Acc@1  95.31 ( 92.04)	Acc@5 100.00 ( 99.86)
Epoch: [32][340/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.001)	Loss 1.8818e-01 (2.2720e-01)	Acc@1  93.75 ( 92.06)	Acc@5 100.00 ( 99.86)
Epoch: [32][350/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.001)	Loss 3.1866e-01 (2.2766e-01)	Acc@1  89.06 ( 92.05)	Acc@5  99.22 ( 99.86)
Epoch: [32][360/391]	Time  0.043 ( 0.041)	Data  0.002 ( 0.001)	Loss 1.7662e-01 (2.2817e-01)	Acc@1  93.75 ( 92.02)	Acc@5 100.00 ( 99.86)
Epoch: [32][370/391]	Time  0.045 ( 0.041)	Data  0.001 ( 0.001)	Loss 3.4808e-01 (2.2876e-01)	Acc@1  89.84 ( 92.01)	Acc@5 100.00 ( 99.86)
Epoch: [32][380/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.001)	Loss 1.9558e-01 (2.2814e-01)	Acc@1  92.97 ( 92.02)	Acc@5  99.22 ( 99.86)
Epoch: [32][390/391]	Time  0.026 ( 0.041)	Data  0.001 ( 0.001)	Loss 2.5673e-01 (2.2747e-01)	Acc@1  91.25 ( 92.05)	Acc@5 100.00 ( 99.86)
## e[32] optimizer.zero_grad (sum) time: 0.2727692127227783
## e[32]       loss.backward (sum) time: 4.035410165786743
## e[32]      optimizer.step (sum) time: 1.7917602062225342
## epoch[32] training(only) time: 16.065451860427856
# Switched to evaluate mode...
Test: [  0/100]	Time  0.174 ( 0.174)	Loss 2.3964e-01 (2.3964e-01)	Acc@1  93.00 ( 93.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.022 ( 0.036)	Loss 5.2737e-01 (3.5883e-01)	Acc@1  87.00 ( 89.64)	Acc@5 100.00 ( 99.55)
Test: [ 20/100]	Time  0.017 ( 0.028)	Loss 3.8410e-01 (3.6560e-01)	Acc@1  85.00 ( 88.76)	Acc@5 100.00 ( 99.52)
Test: [ 30/100]	Time  0.018 ( 0.025)	Loss 3.5405e-01 (3.8149e-01)	Acc@1  87.00 ( 88.48)	Acc@5  99.00 ( 99.52)
Test: [ 40/100]	Time  0.022 ( 0.024)	Loss 3.1833e-01 (3.7925e-01)	Acc@1  88.00 ( 88.41)	Acc@5 100.00 ( 99.51)
Test: [ 50/100]	Time  0.017 ( 0.023)	Loss 2.1087e-01 (3.6978e-01)	Acc@1  94.00 ( 88.69)	Acc@5 100.00 ( 99.55)
Test: [ 60/100]	Time  0.018 ( 0.022)	Loss 3.1783e-01 (3.6552e-01)	Acc@1  93.00 ( 88.79)	Acc@5 100.00 ( 99.59)
Test: [ 70/100]	Time  0.021 ( 0.022)	Loss 3.2124e-01 (3.6201e-01)	Acc@1  86.00 ( 88.76)	Acc@5 100.00 ( 99.63)
Test: [ 80/100]	Time  0.016 ( 0.022)	Loss 3.2218e-01 (3.5789e-01)	Acc@1  90.00 ( 88.83)	Acc@5 100.00 ( 99.67)
Test: [ 90/100]	Time  0.021 ( 0.022)	Loss 2.0075e-01 (3.5795e-01)	Acc@1  92.00 ( 88.77)	Acc@5 100.00 ( 99.66)
 * Acc@1 88.850 Acc@5 99.660
### epoch[32] execution time: 18.30744767189026
EPOCH 33
i:   0, name:           module.stem.0.weight  changing lr from: 0.022321178182447728   to: 0.019597602646433312
i:   1, name:             module.stem.0.bias  changing lr from: 0.022978623466462275   to: 0.020242350750805591
i:   2, name:           module.stem.1.weight  changing lr from: 0.023636707388760666   to: 0.020889038468312839
i:   3, name:             module.stem.1.bias  changing lr from: 0.024295141160509067   to: 0.021537334014075010
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.024953647863799878   to: 0.022186918400243116
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.025611962113519661   to: 0.022837485098150173
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.026269829724213246   to: 0.023488739703830298
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.026927007382186521   to: 0.024140399607280295
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.027583262323057731   to: 0.024792193665799035
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.028238372014938468   to: 0.025443861881702973
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.028892123847398612   to: 0.026095155084682138
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.029544314826343832   to: 0.026745834619029119
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.030194751274911537   to: 0.027395672035943675
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.030843248540469839   to: 0.028044448791088805
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.031489630707783843   to: 0.028691955947547615
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.032133730318396440   to: 0.029337993884308133
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.032775388096252821   to: 0.029982372010379645
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.033414452679584393   to: 0.030624908484625981
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.034050780359051923   to: 0.031265429941380651
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.034684234822136714   to: 0.031903771221892856
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.035314686903755686   to: 0.032539775111637213
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.035942014343066798   to: 0.033173292083505654
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.036566101546420753   to: 0.033804180046886442
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.037186839356407049   to: 0.034432304102623726
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.037804124826934342   to: 0.035057536303839190
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.038417861004277874   to: 0.035679755422588035
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.039027956714021268   to: 0.036298846722311907
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.039634326353813698   to: 0.036914701736043352
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.040236889691859165   to: 0.037527218050309015
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.040835571671049654   to: 0.038136299094671401
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.041430302218651113   to: 0.038741853936844109
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.042021016061447369   to: 0.039343797083309331
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.042607652546244462   to: 0.039942048285361666
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.043190155465635711   to: 0.040536532350498596
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.043768472888926019   to: 0.041127178959073800
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.044342556998112168   to: 0.041713922486126639
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.044912363928814800   to: 0.042296701828298401
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.045477853616057211   to: 0.042875460235743366
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.046038989644784832   to: 0.043450145148940966
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.046595739105019823   to: 0.044020708040314001
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.047148072451544475   to: 0.044587104260556107
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.047695963368007764   to: 0.045149292889571237
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.048239388635349149   to: 0.045707236591926825
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.048778328004435240   to: 0.046260901476722426
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.049312764072804487   to: 0.046810256961774800
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.049842682165416985   to: 0.047355275642021084
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.050368070219306504   to: 0.047895933162041208
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.050888918672034281   to: 0.048432208092602187
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.051405220353843296   to: 0.048964081811126173
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.051916970383415695   to: 0.049491538385985842
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.052424166067134750   to: 0.050014564464531334
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.052926806801756425   to: 0.050533149164753301
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.053424893980395655   to: 0.051047283970488938
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.053918430901734975   to: 0.051556962630077488
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.054407422682364204   to: 0.052062181058374429
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.054891876172161583   to: 0.052562937242033383
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.055371799872629184   to: 0.053059231147967970
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.055847203858096155   to: 0.053551064634905110
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.056318099699705818   to: 0.054038441367944945
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.056784500392103900   to: 0.054521366736042048
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.057246420282747915   to: 0.054999847772326055
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.057703875003757787   to: 0.055473893077179662
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.058156881406231570   to: 0.055943512743994894
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.058605457496950446   to: 0.056408718287529351
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.059049622377399594   to: 0.056869522574786308
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.059489396185033266   to: 0.057325939758343714
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.059924800036713959   to: 0.057777985212059284
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.060355855974257300   to: 0.058225675469079724
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.060782586912016615   to: 0.058669028162085114
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.061205016586441612   to: 0.059108061965699399
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.061623169507548814   to: 0.059542796541001287
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.062037070912241511   to: 0.059973252482069819
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.062446746719420188   to: 0.060399451264502205
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.062852223486824371   to: 0.060821415195841291
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.063253528369550102   to: 0.061239167367853321
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.063650689080187242   to: 0.061652731610596770
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.064043733850523643   to: 0.062062132448225685
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.064432691394763736   to: 0.062467395056471364
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.064817590874211226   to: 0.062868545221749089
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.065198461863367002   to: 0.063265609301836695
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.065575334317393805   to: 0.063658614188073809
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.065948238540902468   to: 0.064047587269032619
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.066317205158013925   to: 0.064432556395611004
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.066682265083653755   to: 0.064813549847501623
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.067043449496036897   to: 0.065190596300990819
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.067400789810301731   to: 0.065563724798043496
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.067754317653253224   to: 0.065932964716630460
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.068104064839177150   to: 0.066298345742256418
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.068450063346687615   to: 0.066659897840648394
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.068792345296571744   to: 0.067017651231564737
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.069130942930596559   to: 0.067371636363686663
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.069465888591243669   to: 0.067721883890555321
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.069797214702339239   to: 0.068068424647518236
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.070124953750546989   to: 0.068411289629650290
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.070449138267693556   to: 0.068750509970615645
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.070769800813895944   to: 0.069086116922437310
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.071086973961462588   to: 0.069418141836143296
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.071400690279539561   to: 0.069746616143257764
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.071710982319474981   to: 0.070071571338108027
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.072017882600875271   to: 0.070393038960918114
i: 100, name:           module.conv10.weight  changing lr from: 0.072321423598328063   to: 0.070711050581660981
i: 101, name:             module.conv10.bias  changing lr from: 0.072621637728766827   to: 0.071025637784642381



# Switched to train mode...
Epoch: [33][  0/391]	Time  0.207 ( 0.207)	Data  0.162 ( 0.162)	Loss 1.3602e-01 (1.3602e-01)	Acc@1  94.53 ( 94.53)	Acc@5 100.00 (100.00)
Epoch: [33][ 10/391]	Time  0.039 ( 0.055)	Data  0.002 ( 0.016)	Loss 2.4716e-01 (1.8600e-01)	Acc@1  92.19 ( 93.25)	Acc@5 100.00 ( 99.93)
Epoch: [33][ 20/391]	Time  0.039 ( 0.049)	Data  0.001 ( 0.009)	Loss 1.4463e-01 (1.8539e-01)	Acc@1  92.97 ( 93.75)	Acc@5 100.00 ( 99.96)
Epoch: [33][ 30/391]	Time  0.038 ( 0.046)	Data  0.001 ( 0.006)	Loss 3.1977e-01 (1.9426e-01)	Acc@1  88.28 ( 93.37)	Acc@5 100.00 ( 99.92)
Epoch: [33][ 40/391]	Time  0.039 ( 0.045)	Data  0.001 ( 0.005)	Loss 1.8846e-01 (1.9808e-01)	Acc@1  95.31 ( 93.20)	Acc@5 100.00 ( 99.89)
Epoch: [33][ 50/391]	Time  0.037 ( 0.043)	Data  0.001 ( 0.004)	Loss 1.6967e-01 (1.9991e-01)	Acc@1  95.31 ( 93.12)	Acc@5 100.00 ( 99.85)
Epoch: [33][ 60/391]	Time  0.039 ( 0.043)	Data  0.001 ( 0.004)	Loss 1.5259e-01 (2.0094e-01)	Acc@1  93.75 ( 92.97)	Acc@5 100.00 ( 99.86)
Epoch: [33][ 70/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.003)	Loss 2.3984e-01 (2.0393e-01)	Acc@1  89.06 ( 92.87)	Acc@5 100.00 ( 99.87)
Epoch: [33][ 80/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.003)	Loss 1.4104e-01 (2.0521e-01)	Acc@1  96.09 ( 92.80)	Acc@5 100.00 ( 99.87)
Epoch: [33][ 90/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.003)	Loss 2.4883e-01 (2.0440e-01)	Acc@1  90.62 ( 92.87)	Acc@5 100.00 ( 99.89)
Epoch: [33][100/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.003)	Loss 2.0083e-01 (2.0445e-01)	Acc@1  93.75 ( 92.88)	Acc@5 100.00 ( 99.90)
Epoch: [33][110/391]	Time  0.054 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.6519e-01 (2.0282e-01)	Acc@1  93.75 ( 92.93)	Acc@5 100.00 ( 99.91)
Epoch: [33][120/391]	Time  0.036 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.1353e-01 (2.0347e-01)	Acc@1  96.09 ( 92.88)	Acc@5 100.00 ( 99.90)
Epoch: [33][130/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.4181e-01 (2.0215e-01)	Acc@1  94.53 ( 92.92)	Acc@5 100.00 ( 99.90)
Epoch: [33][140/391]	Time  0.037 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.4991e-01 (2.0346e-01)	Acc@1  96.88 ( 92.90)	Acc@5 100.00 ( 99.90)
Epoch: [33][150/391]	Time  0.038 ( 0.041)	Data  0.002 ( 0.002)	Loss 1.7297e-01 (2.0571e-01)	Acc@1  96.88 ( 92.82)	Acc@5  99.22 ( 99.89)
Epoch: [33][160/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.1949e-01 (2.0520e-01)	Acc@1  96.09 ( 92.82)	Acc@5 100.00 ( 99.89)
Epoch: [33][170/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.1668e-01 (2.0528e-01)	Acc@1  91.41 ( 92.82)	Acc@5 100.00 ( 99.88)
Epoch: [33][180/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.1517e-01 (2.0518e-01)	Acc@1  92.97 ( 92.83)	Acc@5 100.00 ( 99.87)
Epoch: [33][190/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.3777e-01 (2.0570e-01)	Acc@1  88.28 ( 92.79)	Acc@5  99.22 ( 99.87)
Epoch: [33][200/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.5350e-01 (2.0571e-01)	Acc@1  90.62 ( 92.81)	Acc@5 100.00 ( 99.86)
Epoch: [33][210/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.5042e-01 (2.0554e-01)	Acc@1  90.62 ( 92.81)	Acc@5 100.00 ( 99.85)
Epoch: [33][220/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.9736e-01 (2.0505e-01)	Acc@1  93.75 ( 92.86)	Acc@5 100.00 ( 99.86)
Epoch: [33][230/391]	Time  0.043 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.1619e-01 (2.0596e-01)	Acc@1  93.75 ( 92.81)	Acc@5  99.22 ( 99.85)
Epoch: [33][240/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.9203e-01 (2.0667e-01)	Acc@1  90.62 ( 92.80)	Acc@5 100.00 ( 99.86)
Epoch: [33][250/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.0496e-01 (2.0733e-01)	Acc@1  94.53 ( 92.79)	Acc@5 100.00 ( 99.86)
Epoch: [33][260/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.0654e-01 (2.0842e-01)	Acc@1  92.19 ( 92.76)	Acc@5 100.00 ( 99.87)
Epoch: [33][270/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.4657e-01 (2.0891e-01)	Acc@1  92.97 ( 92.74)	Acc@5  99.22 ( 99.87)
Epoch: [33][280/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.8010e-01 (2.1003e-01)	Acc@1  89.84 ( 92.69)	Acc@5  98.44 ( 99.86)
Epoch: [33][290/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.7507e-01 (2.1136e-01)	Acc@1  89.84 ( 92.62)	Acc@5 100.00 ( 99.86)
Epoch: [33][300/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.1956e-01 (2.1169e-01)	Acc@1  90.62 ( 92.62)	Acc@5 100.00 ( 99.86)
Epoch: [33][310/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.5026e-01 (2.1267e-01)	Acc@1  88.28 ( 92.59)	Acc@5 100.00 ( 99.86)
Epoch: [33][320/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.9592e-01 (2.1324e-01)	Acc@1  90.62 ( 92.57)	Acc@5 100.00 ( 99.86)
Epoch: [33][330/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.9650e-01 (2.1317e-01)	Acc@1  92.97 ( 92.57)	Acc@5  99.22 ( 99.86)
Epoch: [33][340/391]	Time  0.045 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.2717e-01 (2.1370e-01)	Acc@1  95.31 ( 92.55)	Acc@5  97.66 ( 99.86)
Epoch: [33][350/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.8717e-01 (2.1419e-01)	Acc@1  96.88 ( 92.53)	Acc@5 100.00 ( 99.86)
Epoch: [33][360/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.6766e-01 (2.1462e-01)	Acc@1  89.06 ( 92.53)	Acc@5 100.00 ( 99.86)
Epoch: [33][370/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.001)	Loss 1.2098e-01 (2.1420e-01)	Acc@1  96.09 ( 92.55)	Acc@5 100.00 ( 99.86)
Epoch: [33][380/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.001)	Loss 3.0547e-01 (2.1513e-01)	Acc@1  90.62 ( 92.51)	Acc@5 100.00 ( 99.86)
Epoch: [33][390/391]	Time  0.028 ( 0.041)	Data  0.001 ( 0.001)	Loss 1.9533e-01 (2.1545e-01)	Acc@1  93.75 ( 92.50)	Acc@5  98.75 ( 99.86)
## e[33] optimizer.zero_grad (sum) time: 0.2723374366760254
## e[33]       loss.backward (sum) time: 3.985502004623413
## e[33]      optimizer.step (sum) time: 1.825474739074707
## epoch[33] training(only) time: 16.01327157020569
# Switched to evaluate mode...
Test: [  0/100]	Time  0.174 ( 0.174)	Loss 3.2613e-01 (3.2613e-01)	Acc@1  93.00 ( 93.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.024 ( 0.035)	Loss 6.1485e-01 (3.7737e-01)	Acc@1  83.00 ( 89.09)	Acc@5 100.00 ( 99.82)
Test: [ 20/100]	Time  0.023 ( 0.029)	Loss 3.2806e-01 (3.8374e-01)	Acc@1  85.00 ( 88.19)	Acc@5 100.00 ( 99.62)
Test: [ 30/100]	Time  0.021 ( 0.027)	Loss 4.5208e-01 (4.0022e-01)	Acc@1  81.00 ( 87.74)	Acc@5  99.00 ( 99.55)
Test: [ 40/100]	Time  0.018 ( 0.025)	Loss 4.0875e-01 (4.0741e-01)	Acc@1  87.00 ( 87.68)	Acc@5  99.00 ( 99.49)
Test: [ 50/100]	Time  0.024 ( 0.024)	Loss 3.0549e-01 (3.9612e-01)	Acc@1  87.00 ( 87.92)	Acc@5 100.00 ( 99.55)
Test: [ 60/100]	Time  0.017 ( 0.023)	Loss 3.1500e-01 (3.9433e-01)	Acc@1  93.00 ( 87.82)	Acc@5  99.00 ( 99.59)
Test: [ 70/100]	Time  0.019 ( 0.023)	Loss 3.4422e-01 (3.8716e-01)	Acc@1  87.00 ( 88.03)	Acc@5 100.00 ( 99.62)
Test: [ 80/100]	Time  0.021 ( 0.023)	Loss 2.6894e-01 (3.8453e-01)	Acc@1  91.00 ( 88.01)	Acc@5 100.00 ( 99.64)
Test: [ 90/100]	Time  0.022 ( 0.023)	Loss 1.4282e-01 (3.8277e-01)	Acc@1  95.00 ( 87.89)	Acc@5 100.00 ( 99.66)
 * Acc@1 88.010 Acc@5 99.640
### epoch[33] execution time: 18.360828399658203
EPOCH 34
i:   0, name:           module.stem.0.weight  changing lr from: 0.019597602646433312   to: 0.017019931844240544
i:   1, name:             module.stem.0.bias  changing lr from: 0.020242350750805591   to: 0.017646904183536174
i:   2, name:           module.stem.1.weight  changing lr from: 0.020889038468312839   to: 0.018277230265554358
i:   3, name:             module.stem.1.bias  changing lr from: 0.021537334014075010   to: 0.018910534290135752
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.022186918400243116   to: 0.019546454097042126
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.022837485098150173   to: 0.020184640836026863
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.023488739703830298   to: 0.020824758638202597
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.024140399607280295   to: 0.021466484289233319
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.024792193665799035   to: 0.022109506904831069
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.025443861881702973   to: 0.022753527608991572
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.026095155084682138   to: 0.023398259215362201
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.026745834619029119   to: 0.024043425912095896
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.027395672035943675   to: 0.024688762950507450
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.028044448791088805   to: 0.025334016337816054
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.028691955947547615   to: 0.025978942534223805
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.029337993884308133   to: 0.026623308154552595
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.029982372010379645   to: 0.027266889674631752
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.030624908484625981   to: 0.027909473142605543
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.031265429941380651   to: 0.028550853895303666
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.031903771221892856   to: 0.029190836279797284
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.032539775111637213   to: 0.029829233380241682
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.033173292083505654   to: 0.030465866750088590
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.033804180046886442   to: 0.031100566149732656
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.034432304102623726   to: 0.031733169289641677
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.035057536303839190   to: 0.032363521579004184
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.035679755422588035   to: 0.032991475879915112
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.036298846722311907   to: 0.033616892267107359
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.036914701736043352   to: 0.034239637793226023
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.037527218050309015   to: 0.034859586259630940
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.038136299094671401   to: 0.035476617992704088
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.038741853936844109   to: 0.036090619625629809
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.039343797083309331   to: 0.036701483885607622
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.039942048285361666   to: 0.037309109386450316
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.040536532350498596   to: 0.037913400426513824
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.041127178959073800   to: 0.038514266791899343
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.041713922486126639   to: 0.039111623564863238
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.042296701828298401   to: 0.039705390937365637
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.042875460235743366   to: 0.040295494029684423
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.043450145148940966   to: 0.040881862714017864
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.044020708040314001   to: 0.041464431442996372
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.044587104260556107   to: 0.042043139083020334
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.045149292889571237   to: 0.042617928752339995
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.045707236591926825   to: 0.043188747663789745
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.046260901476722426   to: 0.043755546972089554
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.046810256961774800   to: 0.044318281625623124
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.047355275642021084   to: 0.044876910222602900
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.047895933162041208   to: 0.045431394871529987
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.048432208092602187   to: 0.045981701055858165
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.048964081811126173   to: 0.046527797502768968
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.049491538385985842   to: 0.047069656055966594
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.050014564464531334   to: 0.047607251552400157
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.050533149164753301   to: 0.048140561702821959
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.051047283970488938   to: 0.048669566976090532
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.051556962630077488   to: 0.049194250487127694
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.052062181058374429   to: 0.049714597888440071
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.052562937242033383   to: 0.050230597265115376
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.053059231147967970   to: 0.050742239033206238
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.053551064634905110   to: 0.051249515841413587
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.054038441367944945   to: 0.051752422475984189
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.054521366736042048   to: 0.052250955768737034
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.054999847772326055   to: 0.052745114508135515
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.055473893077179662   to: 0.053234899353322596
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.055943512743994894   to: 0.053720312751038141
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.056408718287529351   to: 0.054201358855339013
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.056869522574786308   to: 0.054678043450043526
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.057325939758343714   to: 0.055150373873823814
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.057777985212059284   to: 0.055618358947870400
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.058225675469079724   to: 0.056082008906055705
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.058669028162085114   to: 0.056541335327523951
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.059108061965699399   to: 0.056996351071636711
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.059542796541001287   to: 0.057447070215205023
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.059973252482069819   to: 0.057893507991940124
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.060399451264502205   to: 0.058335680734056865
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.060821415195841291   to: 0.058773605815964872
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.061239167367853321   to: 0.059207301599984552
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.061652731610596770   to: 0.059636787384026058
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.062062132448225685   to: 0.060062083351171053
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.062467395056471364   to: 0.060483210521098708
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.062868545221749089   to: 0.060900190703298634
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.063265609301836695   to: 0.061313046452014880
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.063658614188073809   to: 0.061721801022866653
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.064047587269032619   to: 0.062126478331092985
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.064432556395611004   to: 0.062527102911369467
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.064813549847501623   to: 0.062923699879147227
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.065190596300990819   to: 0.063316294893464825
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.065563724798043496   to: 0.063704914121186201
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.065932964716630460   to: 0.064089584202617664
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.066298345742256418   to: 0.064470332218459769
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.066659897840648394   to: 0.064847185658049769
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.067017651231564737   to: 0.065220172388852471
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.067371636363686663   to: 0.065589320627158373
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.067721883890555321   to: 0.065954658909948505
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.068068424647518236   to: 0.066316216067887818
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.068411289629650290   to: 0.066674021199408420
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.068750509970615645   to: 0.067028103645846882
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.069086116922437310   to: 0.067378492967599304
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.069418141836143296   to: 0.067725218921259878
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.069746616143257764   to: 0.068068311437709708
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.070071571338108027   to: 0.068407800601122615
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.070393038960918114   to: 0.068743716628857296
i: 100, name:           module.conv10.weight  changing lr from: 0.070711050581660981   to: 0.069076089852204522
i: 101, name:             module.conv10.bias  changing lr from: 0.071025637784642381   to: 0.069404950697960252



# Switched to train mode...
Epoch: [34][  0/391]	Time  0.208 ( 0.208)	Data  0.166 ( 0.166)	Loss 2.1510e-01 (2.1510e-01)	Acc@1  91.41 ( 91.41)	Acc@5 100.00 (100.00)
Epoch: [34][ 10/391]	Time  0.039 ( 0.056)	Data  0.001 ( 0.016)	Loss 1.9939e-01 (2.0188e-01)	Acc@1  95.31 ( 92.90)	Acc@5  99.22 ( 99.79)
Epoch: [34][ 20/391]	Time  0.038 ( 0.048)	Data  0.001 ( 0.009)	Loss 2.0888e-01 (1.9814e-01)	Acc@1  92.97 ( 92.97)	Acc@5 100.00 ( 99.78)
Epoch: [34][ 30/391]	Time  0.039 ( 0.046)	Data  0.001 ( 0.006)	Loss 2.2649e-01 (2.0419e-01)	Acc@1  91.41 ( 92.67)	Acc@5 100.00 ( 99.82)
Epoch: [34][ 40/391]	Time  0.041 ( 0.044)	Data  0.001 ( 0.005)	Loss 2.0916e-01 (2.0322e-01)	Acc@1  89.06 ( 92.74)	Acc@5 100.00 ( 99.85)
Epoch: [34][ 50/391]	Time  0.043 ( 0.044)	Data  0.001 ( 0.004)	Loss 1.8545e-01 (2.0277e-01)	Acc@1  93.75 ( 92.75)	Acc@5 100.00 ( 99.85)
Epoch: [34][ 60/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.004)	Loss 2.2368e-01 (2.0003e-01)	Acc@1  92.97 ( 92.93)	Acc@5 100.00 ( 99.86)
Epoch: [34][ 70/391]	Time  0.039 ( 0.043)	Data  0.001 ( 0.003)	Loss 1.9748e-01 (2.0051e-01)	Acc@1  93.75 ( 92.95)	Acc@5 100.00 ( 99.86)
Epoch: [34][ 80/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.003)	Loss 1.9117e-01 (2.0052e-01)	Acc@1  94.53 ( 92.94)	Acc@5 100.00 ( 99.85)
Epoch: [34][ 90/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.003)	Loss 3.4807e-01 (2.0007e-01)	Acc@1  87.50 ( 93.01)	Acc@5  99.22 ( 99.85)
Epoch: [34][100/391]	Time  0.037 ( 0.042)	Data  0.001 ( 0.003)	Loss 2.3120e-01 (1.9862e-01)	Acc@1  92.97 ( 93.11)	Acc@5 100.00 ( 99.86)
Epoch: [34][110/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.003)	Loss 2.3974e-01 (2.0200e-01)	Acc@1  92.19 ( 93.02)	Acc@5 100.00 ( 99.86)
Epoch: [34][120/391]	Time  0.037 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.7707e-01 (2.0093e-01)	Acc@1  95.31 ( 93.07)	Acc@5  99.22 ( 99.86)
Epoch: [34][130/391]	Time  0.037 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.8909e-01 (2.0161e-01)	Acc@1  93.75 ( 93.01)	Acc@5 100.00 ( 99.87)
Epoch: [34][140/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.4274e-01 (2.0236e-01)	Acc@1  90.62 ( 93.00)	Acc@5 100.00 ( 99.88)
Epoch: [34][150/391]	Time  0.044 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.6556e-01 (2.0137e-01)	Acc@1  95.31 ( 93.04)	Acc@5 100.00 ( 99.89)
Epoch: [34][160/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.5424e-01 (2.0228e-01)	Acc@1  88.28 ( 93.00)	Acc@5  99.22 ( 99.88)
Epoch: [34][170/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.6767e-01 (2.0391e-01)	Acc@1  94.53 ( 92.99)	Acc@5 100.00 ( 99.88)
Epoch: [34][180/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.3355e-01 (2.0399e-01)	Acc@1  91.41 ( 92.96)	Acc@5 100.00 ( 99.88)
Epoch: [34][190/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.6519e-01 (2.0451e-01)	Acc@1  92.19 ( 92.94)	Acc@5 100.00 ( 99.88)
Epoch: [34][200/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.6548e-01 (2.0310e-01)	Acc@1  96.09 ( 92.99)	Acc@5  99.22 ( 99.87)
Epoch: [34][210/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.6168e-01 (2.0299e-01)	Acc@1  89.84 ( 92.99)	Acc@5 100.00 ( 99.88)
Epoch: [34][220/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.8554e-01 (2.0373e-01)	Acc@1  92.19 ( 92.93)	Acc@5 100.00 ( 99.88)
Epoch: [34][230/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.7133e-01 (2.0545e-01)	Acc@1  89.06 ( 92.86)	Acc@5 100.00 ( 99.89)
Epoch: [34][240/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.5217e-01 (2.0585e-01)	Acc@1  92.19 ( 92.85)	Acc@5 100.00 ( 99.89)
Epoch: [34][250/391]	Time  0.037 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.6926e-01 (2.0660e-01)	Acc@1  90.62 ( 92.84)	Acc@5 100.00 ( 99.88)
Epoch: [34][260/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.3957e-01 (2.0809e-01)	Acc@1  93.75 ( 92.81)	Acc@5 100.00 ( 99.88)
Epoch: [34][270/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.0347e-01 (2.0869e-01)	Acc@1  93.75 ( 92.78)	Acc@5 100.00 ( 99.88)
Epoch: [34][280/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.3573e-01 (2.0924e-01)	Acc@1  91.41 ( 92.76)	Acc@5 100.00 ( 99.88)
Epoch: [34][290/391]	Time  0.037 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.6357e-01 (2.0910e-01)	Acc@1  93.75 ( 92.76)	Acc@5  99.22 ( 99.88)
Epoch: [34][300/391]	Time  0.035 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.5142e-01 (2.0905e-01)	Acc@1  90.62 ( 92.77)	Acc@5 100.00 ( 99.88)
Epoch: [34][310/391]	Time  0.036 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.6711e-01 (2.0883e-01)	Acc@1  93.75 ( 92.78)	Acc@5  99.22 ( 99.87)
Epoch: [34][320/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.5510e-01 (2.0860e-01)	Acc@1  92.97 ( 92.77)	Acc@5 100.00 ( 99.87)
Epoch: [34][330/391]	Time  0.041 ( 0.040)	Data  0.001 ( 0.002)	Loss 1.7413e-01 (2.0903e-01)	Acc@1  94.53 ( 92.76)	Acc@5 100.00 ( 99.87)
Epoch: [34][340/391]	Time  0.042 ( 0.040)	Data  0.001 ( 0.002)	Loss 3.3141e-01 (2.0959e-01)	Acc@1  90.62 ( 92.76)	Acc@5  99.22 ( 99.87)
Epoch: [34][350/391]	Time  0.040 ( 0.040)	Data  0.001 ( 0.002)	Loss 2.0617e-01 (2.0957e-01)	Acc@1  91.41 ( 92.74)	Acc@5 100.00 ( 99.87)
Epoch: [34][360/391]	Time  0.041 ( 0.040)	Data  0.001 ( 0.002)	Loss 3.0375e-01 (2.1027e-01)	Acc@1  91.41 ( 92.71)	Acc@5 100.00 ( 99.87)
Epoch: [34][370/391]	Time  0.036 ( 0.040)	Data  0.001 ( 0.002)	Loss 2.6176e-01 (2.1063e-01)	Acc@1  92.19 ( 92.69)	Acc@5 100.00 ( 99.86)
Epoch: [34][380/391]	Time  0.045 ( 0.040)	Data  0.001 ( 0.002)	Loss 1.5004e-01 (2.1138e-01)	Acc@1  96.09 ( 92.67)	Acc@5 100.00 ( 99.86)
Epoch: [34][390/391]	Time  0.027 ( 0.040)	Data  0.001 ( 0.002)	Loss 2.0065e-01 (2.1094e-01)	Acc@1  93.75 ( 92.68)	Acc@5 100.00 ( 99.86)
## e[34] optimizer.zero_grad (sum) time: 0.27118849754333496
## e[34]       loss.backward (sum) time: 3.8942220211029053
## e[34]      optimizer.step (sum) time: 1.8552258014678955
## epoch[34] training(only) time: 15.899867296218872
# Switched to evaluate mode...
Test: [  0/100]	Time  0.165 ( 0.165)	Loss 2.8782e-01 (2.8782e-01)	Acc@1  91.00 ( 91.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.017 ( 0.033)	Loss 5.0309e-01 (4.0924e-01)	Acc@1  85.00 ( 87.82)	Acc@5 100.00 ( 99.64)
Test: [ 20/100]	Time  0.022 ( 0.027)	Loss 3.4276e-01 (4.1583e-01)	Acc@1  85.00 ( 87.57)	Acc@5 100.00 ( 99.38)
Test: [ 30/100]	Time  0.018 ( 0.025)	Loss 3.7677e-01 (4.1725e-01)	Acc@1  87.00 ( 88.10)	Acc@5 100.00 ( 99.35)
Test: [ 40/100]	Time  0.022 ( 0.024)	Loss 3.8349e-01 (4.2124e-01)	Acc@1  85.00 ( 88.10)	Acc@5 100.00 ( 99.41)
Test: [ 50/100]	Time  0.019 ( 0.023)	Loss 1.9294e-01 (4.2071e-01)	Acc@1  93.00 ( 88.08)	Acc@5 100.00 ( 99.41)
Test: [ 60/100]	Time  0.022 ( 0.023)	Loss 3.6133e-01 (4.1751e-01)	Acc@1  88.00 ( 88.07)	Acc@5  99.00 ( 99.43)
Test: [ 70/100]	Time  0.023 ( 0.022)	Loss 3.5118e-01 (4.0989e-01)	Acc@1  85.00 ( 87.97)	Acc@5 100.00 ( 99.48)
Test: [ 80/100]	Time  0.020 ( 0.022)	Loss 2.4028e-01 (4.0903e-01)	Acc@1  94.00 ( 87.99)	Acc@5 100.00 ( 99.46)
Test: [ 90/100]	Time  0.021 ( 0.022)	Loss 3.0152e-01 (4.0883e-01)	Acc@1  91.00 ( 88.04)	Acc@5 100.00 ( 99.46)
 * Acc@1 88.170 Acc@5 99.480
### epoch[34] execution time: 18.202359914779663
EPOCH 35
i:   0, name:           module.stem.0.weight  changing lr from: 0.017019931844240544   to: 0.014600142389248290
i:   1, name:             module.stem.0.bias  changing lr from: 0.017646904183536174   to: 0.015204167206735463
i:   2, name:           module.stem.1.weight  changing lr from: 0.018277230265554358   to: 0.015813067264236137
i:   3, name:             module.stem.1.bias  changing lr from: 0.018910534290135752   to: 0.016426422203285863
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.019546454097042126   to: 0.017043826040319843
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.020184640836026863   to: 0.017664886853320967
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.020824758638202597   to: 0.018289226467221094
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.021466484289233319   to: 0.018916480138756808
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.022109506904831069   to: 0.019546296241423473
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.022753527608991572   to: 0.020178335951118221
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.023398259215362201   to: 0.020812272933011924
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.024043425912095896   to: 0.021447793030143304
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.024688762950507450   to: 0.022084593954183336
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.025334016337816054   to: 0.022722384978777328
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.025978942534223805   to: 0.023360886635832492
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.026623308154552595   to: 0.023999830415083148
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.027266889674631752   to: 0.024638958467230618
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.027909473142605543   to: 0.025278023310924699
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.028550853895303666   to: 0.025916787543821929
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.029190836279797284   to: 0.026555023557930338
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.029829233380241682   to: 0.027192513259422759
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.030465866750088590   to: 0.027829047793078709
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.031100566149732656   to: 0.028464427271490601
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.031733169289641677   to: 0.029098460509151394
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.032363521579004184   to: 0.029730964761520186
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.032991475879915112   to: 0.030361765469145426
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.033616892267107359   to: 0.030990696006908514
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.034239637793226023   to: 0.031617597438436097
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.034859586259630940   to: 0.032242318275714700
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.035476617992704088   to: 0.032864714243929005
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.036090619625629809   to: 0.033484648051533221
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.036701483885607622   to: 0.034101989165554396
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.037309109386450316   to: 0.034716613592116030
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.037913400426513824   to: 0.035328403662162132
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.038514266791899343   to: 0.035937247822353129
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.039111623564863238   to: 0.036543040431097677
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.039705390937365637   to: 0.037145681559678012
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.040295494029684423   to: 0.037745076798419736
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.040881862714017864   to: 0.038341137067852117
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.041464431442996372   to: 0.038933778434799671
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.042043139083020334   to: 0.039522921933341594
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.042617928752339995   to: 0.040108493390571633
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.043188747663789745   to: 0.040690423257087556
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.043755546972089554   to: 0.041268646442136681
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.044318281625623124   to: 0.041843102153340736
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.044876910222602900   to: 0.042413733740921833
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.045431394871529987   to: 0.042980488546348727
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.045981701055858165   to: 0.043543317755321789
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.046527797502768968   to: 0.044102176255012795
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.047069656055966594   to: 0.044657022495475804
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.047607251552400157   to: 0.045207818355143564
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.048140561702821959   to: 0.045754529010324202
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.048669566976090532   to: 0.046297122808612097
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.049194250487127694   to: 0.046835571146127013
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.049714597888440071   to: 0.047369848348495391
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.050230597265115376   to: 0.047899931555487947
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.050742239033206238   to: 0.048425800609228548
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.051249515841413587   to: 0.048947437945888850
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.051752422475984189   to: 0.049464828490784936
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.052250955768737034   to: 0.049977959556791830
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.052745114508135515   to: 0.050486820745993671
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.053234899353322596   to: 0.050991403854487111
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.053720312751038141   to: 0.051491702780257421
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.054201358855339013   to: 0.051987713434047261
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.054678043450043526   to: 0.052479433653139465
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.055150373873823814   to: 0.052966863117976472
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.055618358947870400   to: 0.053450003271539641
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.056082008906055705   to: 0.053928857241413664
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.056541335327523951   to: 0.054403429764462524
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.056996351071636711   to: 0.054873727114043806
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.057447070215205023   to: 0.055339757029691274
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.057893507991940124   to: 0.055801528649194847
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.058335680734056865   to: 0.056259052443010708
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.058773605815964872   to: 0.056712340150933661
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.059207301599984552   to: 0.057161404720966917
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.059636787384026058   to: 0.057606260250324538
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.060062083351171053   to: 0.058046921928504316
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.060483210521098708   to: 0.058483405982369223
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.060900190703298634   to: 0.058915729623178051
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.061313046452014880   to: 0.059343910995506337
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.061721801022866653   to: 0.059767969128000302
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.062126478331092985   to: 0.060187923885908490
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.062527102911369467   to: 0.060603795925336240
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.062923699879147227   to: 0.061015606649170141
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.063316294893464825   to: 0.061423378164620637
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.063704914121186201   to: 0.061827133242332445
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.064089584202617664   to: 0.062226895277013632
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.064470332218459769   to: 0.062622688249535402
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.064847185658049769   to: 0.063014536690456299
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.065220172388852471   to: 0.063402465644925118
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.065589320627158373   to: 0.063786500638918706
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.065954658909948505   to: 0.064166667646771675
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.066316216067887818   to: 0.064542993059956061
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.066674021199408420   to: 0.064915503657070703
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.067028103645846882   to: 0.065284226575000812
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.067378492967599304   to: 0.065649189281208900
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.067725218921259878   to: 0.066010419547120683
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.068068311437709708   to: 0.066367945422569088
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.068407800601122615   to: 0.066721795211261453
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.068743716628857296   to: 0.067071997447235784
i: 100, name:           module.conv10.weight  changing lr from: 0.069076089852204522   to: 0.067418580872273051
i: 101, name:             module.conv10.bias  changing lr from: 0.069404950697960252   to: 0.067761574414233139



# Switched to train mode...
Epoch: [35][  0/391]	Time  0.220 ( 0.220)	Data  0.176 ( 0.176)	Loss 1.8287e-01 (1.8287e-01)	Acc@1  94.53 ( 94.53)	Acc@5 100.00 (100.00)
Epoch: [35][ 10/391]	Time  0.039 ( 0.057)	Data  0.001 ( 0.017)	Loss 1.5120e-01 (1.7157e-01)	Acc@1  96.09 ( 93.68)	Acc@5 100.00 (100.00)
Epoch: [35][ 20/391]	Time  0.040 ( 0.049)	Data  0.001 ( 0.009)	Loss 1.4022e-01 (1.7441e-01)	Acc@1  96.88 ( 93.90)	Acc@5 100.00 ( 99.93)
Epoch: [35][ 30/391]	Time  0.038 ( 0.046)	Data  0.001 ( 0.007)	Loss 1.9252e-01 (1.8379e-01)	Acc@1  93.75 ( 93.55)	Acc@5 100.00 ( 99.90)
Epoch: [35][ 40/391]	Time  0.042 ( 0.045)	Data  0.001 ( 0.005)	Loss 2.2667e-01 (1.7787e-01)	Acc@1  93.75 ( 93.83)	Acc@5  99.22 ( 99.89)
Epoch: [35][ 50/391]	Time  0.040 ( 0.044)	Data  0.001 ( 0.004)	Loss 2.0186e-01 (1.7862e-01)	Acc@1  92.97 ( 93.78)	Acc@5 100.00 ( 99.88)
Epoch: [35][ 60/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.004)	Loss 1.6236e-01 (1.8112e-01)	Acc@1  93.75 ( 93.75)	Acc@5 100.00 ( 99.90)
Epoch: [35][ 70/391]	Time  0.043 ( 0.043)	Data  0.001 ( 0.003)	Loss 2.6581e-01 (1.8635e-01)	Acc@1  92.19 ( 93.54)	Acc@5 100.00 ( 99.90)
Epoch: [35][ 80/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.003)	Loss 2.2718e-01 (1.8633e-01)	Acc@1  89.84 ( 93.45)	Acc@5 100.00 ( 99.91)
Epoch: [35][ 90/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.003)	Loss 1.4976e-01 (1.8798e-01)	Acc@1  95.31 ( 93.40)	Acc@5 100.00 ( 99.91)
Epoch: [35][100/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.003)	Loss 1.5877e-01 (1.8982e-01)	Acc@1  95.31 ( 93.39)	Acc@5 100.00 ( 99.90)
Epoch: [35][110/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.003)	Loss 1.0959e-01 (1.8879e-01)	Acc@1  95.31 ( 93.44)	Acc@5 100.00 ( 99.89)
Epoch: [35][120/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.4399e-01 (1.8926e-01)	Acc@1  95.31 ( 93.45)	Acc@5 100.00 ( 99.88)
Epoch: [35][130/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.7857e-01 (1.9029e-01)	Acc@1  92.19 ( 93.45)	Acc@5 100.00 ( 99.89)
Epoch: [35][140/391]	Time  0.035 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.1474e-01 (1.9015e-01)	Acc@1  89.06 ( 93.47)	Acc@5 100.00 ( 99.88)
Epoch: [35][150/391]	Time  0.037 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.6754e-01 (1.9217e-01)	Acc@1  89.84 ( 93.38)	Acc@5  99.22 ( 99.88)
Epoch: [35][160/391]	Time  0.043 ( 0.041)	Data  0.002 ( 0.002)	Loss 1.3820e-01 (1.9108e-01)	Acc@1  95.31 ( 93.44)	Acc@5 100.00 ( 99.89)
Epoch: [35][170/391]	Time  0.043 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.9786e-01 (1.9236e-01)	Acc@1  91.41 ( 93.36)	Acc@5  99.22 ( 99.88)
Epoch: [35][180/391]	Time  0.048 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.3295e-01 (1.9420e-01)	Acc@1  89.84 ( 93.30)	Acc@5 100.00 ( 99.87)
Epoch: [35][190/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.2012e-01 (1.9463e-01)	Acc@1  94.53 ( 93.29)	Acc@5 100.00 ( 99.87)
Epoch: [35][200/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.0158e-01 (1.9560e-01)	Acc@1  92.19 ( 93.23)	Acc@5 100.00 ( 99.88)
Epoch: [35][210/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.9001e-01 (1.9612e-01)	Acc@1  93.75 ( 93.19)	Acc@5 100.00 ( 99.87)
Epoch: [35][220/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.7565e-01 (1.9681e-01)	Acc@1  95.31 ( 93.17)	Acc@5  99.22 ( 99.86)
Epoch: [35][230/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.2244e-01 (1.9723e-01)	Acc@1  92.97 ( 93.15)	Acc@5 100.00 ( 99.86)
Epoch: [35][240/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.7654e-01 (1.9830e-01)	Acc@1  95.31 ( 93.12)	Acc@5 100.00 ( 99.86)
Epoch: [35][250/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.0180e-01 (1.9774e-01)	Acc@1  91.41 ( 93.12)	Acc@5 100.00 ( 99.86)
Epoch: [35][260/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.4779e-01 (1.9878e-01)	Acc@1  93.75 ( 93.06)	Acc@5 100.00 ( 99.87)
Epoch: [35][270/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.1379e-01 (1.9861e-01)	Acc@1  95.31 ( 93.05)	Acc@5 100.00 ( 99.87)
Epoch: [35][280/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.3921e-01 (1.9971e-01)	Acc@1  92.19 ( 93.02)	Acc@5 100.00 ( 99.87)
Epoch: [35][290/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.9455e-01 (2.0031e-01)	Acc@1  89.84 ( 93.00)	Acc@5  99.22 ( 99.87)
Epoch: [35][300/391]	Time  0.036 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.7258e-01 (2.0067e-01)	Acc@1  95.31 ( 92.99)	Acc@5 100.00 ( 99.87)
Epoch: [35][310/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.7824e-01 (2.0248e-01)	Acc@1  89.84 ( 92.94)	Acc@5 100.00 ( 99.87)
Epoch: [35][320/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.6276e-01 (2.0230e-01)	Acc@1  94.53 ( 92.94)	Acc@5 100.00 ( 99.86)
Epoch: [35][330/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.7157e-01 (2.0311e-01)	Acc@1  91.41 ( 92.91)	Acc@5 100.00 ( 99.86)
Epoch: [35][340/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.7156e-01 (2.0282e-01)	Acc@1  92.97 ( 92.92)	Acc@5 100.00 ( 99.86)
Epoch: [35][350/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.7518e-01 (2.0247e-01)	Acc@1  92.19 ( 92.92)	Acc@5 100.00 ( 99.87)
Epoch: [35][360/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.9007e-01 (2.0199e-01)	Acc@1  96.09 ( 92.93)	Acc@5 100.00 ( 99.87)
Epoch: [35][370/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.001)	Loss 2.2038e-01 (2.0241e-01)	Acc@1  91.41 ( 92.92)	Acc@5 100.00 ( 99.87)
Epoch: [35][380/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.001)	Loss 1.9683e-01 (2.0241e-01)	Acc@1  92.97 ( 92.91)	Acc@5 100.00 ( 99.87)
Epoch: [35][390/391]	Time  0.028 ( 0.040)	Data  0.001 ( 0.001)	Loss 2.8264e-01 (2.0217e-01)	Acc@1  83.75 ( 92.91)	Acc@5 100.00 ( 99.87)
## e[35] optimizer.zero_grad (sum) time: 0.2725203037261963
## e[35]       loss.backward (sum) time: 3.9756040573120117
## e[35]      optimizer.step (sum) time: 1.8190901279449463
## epoch[35] training(only) time: 15.982783317565918
# Switched to evaluate mode...
Test: [  0/100]	Time  0.175 ( 0.175)	Loss 3.2515e-01 (3.2515e-01)	Acc@1  89.00 ( 89.00)	Acc@5  99.00 ( 99.00)
Test: [ 10/100]	Time  0.018 ( 0.033)	Loss 5.3561e-01 (4.0887e-01)	Acc@1  86.00 ( 88.18)	Acc@5  99.00 ( 99.27)
Test: [ 20/100]	Time  0.026 ( 0.027)	Loss 3.6829e-01 (4.2732e-01)	Acc@1  83.00 ( 87.43)	Acc@5 100.00 ( 99.24)
Test: [ 30/100]	Time  0.022 ( 0.026)	Loss 4.3813e-01 (4.4855e-01)	Acc@1  87.00 ( 87.65)	Acc@5  99.00 ( 99.19)
Test: [ 40/100]	Time  0.020 ( 0.024)	Loss 3.3385e-01 (4.4296e-01)	Acc@1  88.00 ( 87.41)	Acc@5  99.00 ( 99.27)
Test: [ 50/100]	Time  0.021 ( 0.024)	Loss 2.5668e-01 (4.3257e-01)	Acc@1  91.00 ( 87.57)	Acc@5 100.00 ( 99.33)
Test: [ 60/100]	Time  0.019 ( 0.023)	Loss 4.3945e-01 (4.2572e-01)	Acc@1  90.00 ( 87.59)	Acc@5  99.00 ( 99.41)
Test: [ 70/100]	Time  0.023 ( 0.023)	Loss 3.3393e-01 (4.2084e-01)	Acc@1  88.00 ( 87.59)	Acc@5  99.00 ( 99.44)
Test: [ 80/100]	Time  0.024 ( 0.022)	Loss 2.5105e-01 (4.2100e-01)	Acc@1  90.00 ( 87.68)	Acc@5 100.00 ( 99.43)
Test: [ 90/100]	Time  0.022 ( 0.022)	Loss 3.5340e-01 (4.1893e-01)	Acc@1  90.00 ( 87.80)	Acc@5  99.00 ( 99.40)
 * Acc@1 87.900 Acc@5 99.380
### epoch[35] execution time: 18.27626061439514
EPOCH 36
i:   0, name:           module.stem.0.weight  changing lr from: 0.014600142389248290   to: 0.012349477331863180
i:   1, name:             module.stem.0.bias  changing lr from: 0.015204167206735463   to: 0.012925324070447330
i:   2, name:           module.stem.1.weight  changing lr from: 0.015813067264236137   to: 0.013507667772669579
i:   3, name:             module.stem.1.bias  changing lr from: 0.016426422203285863   to: 0.014096043499414113
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.017043826040319843   to: 0.014690001287931537
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.017664886853320967   to: 0.015289105864714974
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.018289226467221094   to: 0.015892936354088595
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.018916480138756808   to: 0.016501085983402775
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.019546296241423473   to: 0.017113161785663689
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.020178335951118221   to: 0.017728784300362295
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.020812272933011924   to: 0.018347587273208388
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.021447793030143304   to: 0.018969217355420193
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.022084593954183336   to: 0.019593333803166340
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.022722384978777328   to: 0.020219608177709132
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.023360886635832492   to: 0.020847724046750268
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.023999830415083148   to: 0.021477376687437599
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.024638958467230618   to: 0.022108272791449599
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.025278023310924699   to: 0.022740130172537027
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.025916787543821929   to: 0.023372677476864192
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.026555023557930338   to: 0.024005653896459228
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.027192513259422759   to: 0.024638808886051067
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.027829047793078709   to: 0.025271901883541684
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.028464427271490601   to: 0.025904702034334218
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.029098460509151394   to: 0.026536987919712363
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.029730964761520186   to: 0.027168547289442686
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.030361765469145426   to: 0.027799176798748639
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.030990696006908514   to: 0.028428681749785190
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.031617597438436097   to: 0.029056875837723567
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.032242318275714700   to: 0.029683580901537360
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.032864714243929005   to: 0.030308626679565437
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.033484648051533221   to: 0.030931850569911365
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.034101989165554396   to: 0.031553097395725496
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.034716613592116030   to: 0.032172219175402174
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.035328403662162132   to: 0.032789074897713121
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.035937247822353129   to: 0.033403530301886919
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.036543040431097677   to: 0.034015457662634245
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.037145681559678012   to: 0.034624735580109436
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.037745076798419736   to: 0.035231248774790523
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.038341137067852117   to: 0.035834887887252038
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.038933778434799671   to: 0.036435549282797866
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.039522921933341594   to: 0.037033134860915397
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.040108493390571633   to: 0.037627551869506094
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.040690423257087556   to: 0.038218712723842418
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.041268646442136681   to: 0.038806534830196943
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.041843102153340736   to: 0.039390940414084467
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.042413733740921833   to: 0.039971856353055259
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.042980488546348727   to: 0.040549214013973239
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.043543317755321789   to: 0.041122949094711203
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.044102176255012795   to: 0.041693001470191497
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.044657022495475804   to: 0.042259315042699475
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.045207818355143564   to: 0.042821837596394602
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.045754529010324202   to: 0.043380520655942667
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.046297122808612097   to: 0.043935319349191607
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.046835571146127013   to: 0.044486192273812036
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.047369848348495391   to: 0.045033101367823153
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.047899931555487947   to: 0.045576011783923717
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.048425800609228548   to: 0.046114891767548162
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.048947437945888850   to: 0.046649712538566833
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.049464828490784936   to: 0.047180448176550177
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.049977959556791830   to: 0.047707075509516146
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.050486820745993671   to: 0.048229574006081022
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.050991403854487111   to: 0.048747925670933723
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.051491702780257421   to: 0.049262114943554418
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.051987713434047261   to: 0.049772128600099080
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.052479433653139465   to: 0.050277955658371974
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.052966863117976472   to: 0.050779587285809231
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.053450003271539641   to: 0.051277016710397243
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.053928857241413664   to: 0.051770239134450668
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.054403429764462524   to: 0.052259251651176286
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.054873727114043806   to: 0.052744053163948923
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.055339757029691274   to: 0.053224644308228208
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.055801528649194847   to: 0.053701027376044722
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.056259052443010708   to: 0.054173206242986362
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.056712340150933661   to: 0.054641186297616086
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.057161404720966917   to: 0.055104974373254345
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.057606260250324538   to: 0.055564578682059711
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.058046921928504316   to: 0.056020008751343636
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.058483405982369223   to: 0.056471275362055297
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.058915729623178051   to: 0.056918390489375408
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.059343910995506337   to: 0.057361367245357189
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.059767969128000302   to: 0.057800219823555869
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.060187923885908490   to: 0.058234963445588130
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.060603795925336240   to: 0.058665614309564851
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.061015606649170141   to: 0.059092189540341469
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.061423378164620637   to: 0.059514707141531779
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.061827133242332445   to: 0.059933185949232207
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.062226895277013632   to: 0.060347645587404797
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.062622688249535402   to: 0.060758106424868563
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.063014536690456299   to: 0.061164589533849879
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.063402465644925118   to: 0.061567116650044024
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.063786500638918706   to: 0.061965710134141129
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.064166667646771675   to: 0.062360392934770963
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.064542993059956061   to: 0.062751188552822218
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.064915503657070703   to: 0.063138121007092957
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.065284226575000812   to: 0.063521214801230449
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.065649189281208900   to: 0.063900494891918971
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.066010419547120683   to: 0.064275986658276454
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.066367945422569088   to: 0.064647715872420547
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.066721795211261453   to: 0.065015708671166753
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.067071997447235784   to: 0.065379991528822040
i: 100, name:           module.conv10.weight  changing lr from: 0.067418580872273051   to: 0.065740591231038190
i: 101, name:             module.conv10.bias  changing lr from: 0.067761574414233139   to: 0.066097534849690415



# Switched to train mode...
Epoch: [36][  0/391]	Time  0.229 ( 0.229)	Data  0.186 ( 0.186)	Loss 3.0213e-01 (3.0213e-01)	Acc@1  89.06 ( 89.06)	Acc@5 100.00 (100.00)
Epoch: [36][ 10/391]	Time  0.041 ( 0.057)	Data  0.001 ( 0.018)	Loss 1.9570e-01 (1.9751e-01)	Acc@1  94.53 ( 93.39)	Acc@5  99.22 ( 99.79)
Epoch: [36][ 20/391]	Time  0.041 ( 0.049)	Data  0.001 ( 0.010)	Loss 1.5305e-01 (2.0079e-01)	Acc@1  96.09 ( 92.93)	Acc@5 100.00 ( 99.89)
Epoch: [36][ 30/391]	Time  0.039 ( 0.046)	Data  0.001 ( 0.007)	Loss 1.8544e-01 (1.9170e-01)	Acc@1  93.75 ( 93.04)	Acc@5 100.00 ( 99.92)
Epoch: [36][ 40/391]	Time  0.038 ( 0.044)	Data  0.002 ( 0.006)	Loss 1.8522e-01 (1.9339e-01)	Acc@1  92.19 ( 93.01)	Acc@5 100.00 ( 99.92)
Epoch: [36][ 50/391]	Time  0.038 ( 0.043)	Data  0.001 ( 0.005)	Loss 1.9405e-01 (1.9154e-01)	Acc@1  95.31 ( 93.29)	Acc@5 100.00 ( 99.92)
Epoch: [36][ 60/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.004)	Loss 1.5421e-01 (1.8763e-01)	Acc@1  94.53 ( 93.40)	Acc@5 100.00 ( 99.94)
Epoch: [36][ 70/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.004)	Loss 1.5673e-01 (1.8468e-01)	Acc@1  95.31 ( 93.51)	Acc@5 100.00 ( 99.92)
Epoch: [36][ 80/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.003)	Loss 1.7665e-01 (1.8800e-01)	Acc@1  93.75 ( 93.48)	Acc@5 100.00 ( 99.92)
Epoch: [36][ 90/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.003)	Loss 1.2763e-01 (1.8537e-01)	Acc@1  94.53 ( 93.57)	Acc@5 100.00 ( 99.92)
Epoch: [36][100/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.003)	Loss 1.6049e-01 (1.8290e-01)	Acc@1  95.31 ( 93.64)	Acc@5 100.00 ( 99.93)
Epoch: [36][110/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.003)	Loss 1.1665e-01 (1.8493e-01)	Acc@1  96.88 ( 93.55)	Acc@5 100.00 ( 99.92)
Epoch: [36][120/391]	Time  0.035 ( 0.041)	Data  0.001 ( 0.003)	Loss 2.1508e-01 (1.8717e-01)	Acc@1  91.41 ( 93.42)	Acc@5  99.22 ( 99.90)
Epoch: [36][130/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.3016e-01 (1.8807e-01)	Acc@1  96.09 ( 93.31)	Acc@5 100.00 ( 99.91)
Epoch: [36][140/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.5970e-01 (1.8703e-01)	Acc@1  96.09 ( 93.37)	Acc@5 100.00 ( 99.91)
Epoch: [36][150/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.1357e-01 (1.8687e-01)	Acc@1  95.31 ( 93.35)	Acc@5 100.00 ( 99.92)
Epoch: [36][160/391]	Time  0.049 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.1397e-01 (1.8856e-01)	Acc@1  91.41 ( 93.31)	Acc@5 100.00 ( 99.91)
Epoch: [36][170/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.5410e-01 (1.8850e-01)	Acc@1  94.53 ( 93.30)	Acc@5 100.00 ( 99.91)
Epoch: [36][180/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.2840e-01 (1.8877e-01)	Acc@1  92.19 ( 93.27)	Acc@5 100.00 ( 99.91)
Epoch: [36][190/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.0581e-01 (1.8725e-01)	Acc@1  97.66 ( 93.34)	Acc@5 100.00 ( 99.91)
Epoch: [36][200/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.2515e-01 (1.8756e-01)	Acc@1  96.88 ( 93.28)	Acc@5 100.00 ( 99.91)
Epoch: [36][210/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.4086e-01 (1.8872e-01)	Acc@1  90.62 ( 93.21)	Acc@5 100.00 ( 99.91)
Epoch: [36][220/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.3050e-01 (1.8882e-01)	Acc@1  96.09 ( 93.21)	Acc@5 100.00 ( 99.91)
Epoch: [36][230/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.8870e-01 (1.8914e-01)	Acc@1  90.62 ( 93.21)	Acc@5 100.00 ( 99.91)
Epoch: [36][240/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 9.0698e-02 (1.8866e-01)	Acc@1  98.44 ( 93.24)	Acc@5 100.00 ( 99.92)
Epoch: [36][250/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.9236e-01 (1.8869e-01)	Acc@1  91.41 ( 93.23)	Acc@5 100.00 ( 99.91)
Epoch: [36][260/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.0639e-01 (1.8904e-01)	Acc@1  93.75 ( 93.22)	Acc@5 100.00 ( 99.91)
Epoch: [36][270/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.8529e-01 (1.8902e-01)	Acc@1  94.53 ( 93.23)	Acc@5 100.00 ( 99.91)
Epoch: [36][280/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 8.0347e-02 (1.8862e-01)	Acc@1  96.09 ( 93.26)	Acc@5 100.00 ( 99.92)
Epoch: [36][290/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.2136e-01 (1.8871e-01)	Acc@1  92.97 ( 93.26)	Acc@5 100.00 ( 99.92)
Epoch: [36][300/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.4445e-01 (1.8892e-01)	Acc@1  95.31 ( 93.29)	Acc@5 100.00 ( 99.92)
Epoch: [36][310/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.8766e-01 (1.8878e-01)	Acc@1  91.41 ( 93.27)	Acc@5 100.00 ( 99.91)
Epoch: [36][320/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.2411e-01 (1.8951e-01)	Acc@1  95.31 ( 93.25)	Acc@5 100.00 ( 99.91)
Epoch: [36][330/391]	Time  0.039 ( 0.040)	Data  0.001 ( 0.002)	Loss 1.3935e-01 (1.8985e-01)	Acc@1  96.09 ( 93.26)	Acc@5 100.00 ( 99.92)
Epoch: [36][340/391]	Time  0.042 ( 0.040)	Data  0.001 ( 0.002)	Loss 2.0710e-01 (1.9030e-01)	Acc@1  92.97 ( 93.24)	Acc@5 100.00 ( 99.92)
Epoch: [36][350/391]	Time  0.040 ( 0.040)	Data  0.001 ( 0.002)	Loss 1.2068e-01 (1.9090e-01)	Acc@1  96.09 ( 93.24)	Acc@5 100.00 ( 99.91)
Epoch: [36][360/391]	Time  0.042 ( 0.040)	Data  0.001 ( 0.002)	Loss 2.4028e-01 (1.9124e-01)	Acc@1  93.75 ( 93.25)	Acc@5  99.22 ( 99.91)
Epoch: [36][370/391]	Time  0.042 ( 0.040)	Data  0.001 ( 0.002)	Loss 2.9748e-01 (1.9271e-01)	Acc@1  89.84 ( 93.19)	Acc@5  99.22 ( 99.91)
Epoch: [36][380/391]	Time  0.040 ( 0.040)	Data  0.001 ( 0.002)	Loss 2.0936e-01 (1.9284e-01)	Acc@1  91.41 ( 93.19)	Acc@5 100.00 ( 99.91)
Epoch: [36][390/391]	Time  0.038 ( 0.040)	Data  0.001 ( 0.002)	Loss 2.5999e-01 (1.9288e-01)	Acc@1  92.50 ( 93.20)	Acc@5 100.00 ( 99.91)
## e[36] optimizer.zero_grad (sum) time: 0.27176499366760254
## e[36]       loss.backward (sum) time: 3.8649609088897705
## e[36]      optimizer.step (sum) time: 1.9229457378387451
## epoch[36] training(only) time: 15.929214715957642
# Switched to evaluate mode...
Test: [  0/100]	Time  0.173 ( 0.173)	Loss 2.7528e-01 (2.7528e-01)	Acc@1  93.00 ( 93.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.023 ( 0.036)	Loss 4.0370e-01 (3.4567e-01)	Acc@1  89.00 ( 89.55)	Acc@5 100.00 ( 99.64)
Test: [ 20/100]	Time  0.021 ( 0.029)	Loss 4.4268e-01 (3.7511e-01)	Acc@1  85.00 ( 88.38)	Acc@5 100.00 ( 99.67)
Test: [ 30/100]	Time  0.019 ( 0.026)	Loss 4.9555e-01 (3.9608e-01)	Acc@1  86.00 ( 88.39)	Acc@5  99.00 ( 99.55)
Test: [ 40/100]	Time  0.021 ( 0.025)	Loss 3.2645e-01 (3.9763e-01)	Acc@1  88.00 ( 88.24)	Acc@5  99.00 ( 99.49)
Test: [ 50/100]	Time  0.020 ( 0.024)	Loss 1.6784e-01 (3.9105e-01)	Acc@1  91.00 ( 88.18)	Acc@5 100.00 ( 99.55)
Test: [ 60/100]	Time  0.023 ( 0.024)	Loss 4.0815e-01 (3.9378e-01)	Acc@1  90.00 ( 88.05)	Acc@5  99.00 ( 99.57)
Test: [ 70/100]	Time  0.017 ( 0.023)	Loss 2.6741e-01 (3.8832e-01)	Acc@1  92.00 ( 88.14)	Acc@5 100.00 ( 99.59)
Test: [ 80/100]	Time  0.017 ( 0.023)	Loss 2.1237e-01 (3.8430e-01)	Acc@1  93.00 ( 88.22)	Acc@5 100.00 ( 99.59)
Test: [ 90/100]	Time  0.018 ( 0.022)	Loss 2.8502e-01 (3.8382e-01)	Acc@1  91.00 ( 88.22)	Acc@5 100.00 ( 99.58)
 * Acc@1 88.320 Acc@5 99.600
### epoch[36] execution time: 18.235196828842163
EPOCH 37
i:   0, name:           module.stem.0.weight  changing lr from: 0.012349477331863180   to: 0.010278393921015021
i:   1, name:             module.stem.0.bias  changing lr from: 0.012925324070447330   to: 0.010820808624770743
i:   2, name:           module.stem.1.weight  changing lr from: 0.013507667772669579   to: 0.011371433757897682
i:   3, name:             module.stem.1.bias  changing lr from: 0.014096043499414113   to: 0.011929760340165234
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.014690001287931537   to: 0.012495294809443381
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.015289105864714974   to: 0.013067558771401911
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.015892936354088595   to: 0.013646088741366386
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.016501085983402775   to: 0.014230435879436794
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.017113161785663689   to: 0.014820165719898561
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.017728784300362295   to: 0.015414857895883722
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.018347587273208388   to: 0.016014105860171275
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.018969217355420193   to: 0.016617516602951569
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.019593333803166340   to: 0.017224710367318107
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.020219608177709132   to: 0.017835320363193016
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.020847724046750268   to: 0.018448992480337469
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.021477376687437599   to: 0.019065385001047847
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.022108272791449599   to: 0.019684168313089251
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.022740130172537027   to: 0.020305024623373635
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.023372677476864192   to: 0.020927647672846023
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.024005653896459228   to: 0.021551742453002978
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.024638808886051067   to: 0.022177024924429252
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.025271901883541684   to: 0.022803221737703695
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.025904702034334218   to: 0.023430069956991789
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.026536987919712363   to: 0.024057316786611618
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.027168547289442686   to: 0.024684719300830840
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.027799176798748639   to: 0.025312044177125011
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.028428681749785190   to: 0.025939067433102286
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.029056875837723567   to: 0.026565574167276271
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.029683580901537360   to: 0.027191358303845836
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.030308626679565437   to: 0.027816222341621084
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.030931850569911365   to: 0.028439977107214832
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.031553097395725496   to: 0.029062441512602011
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.032172219175402174   to: 0.029683442317131825
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.032789074897713121   to: 0.030302813894063380
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.033403530301886919   to: 0.030920398001680269
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.034015457662634245   to: 0.031536043559027532
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.034624735580109436   to: 0.032149606426301526
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.035231248774790523   to: 0.032760949189912500
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.035834887887252038   to: 0.033369940952229428
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.036435549282797866   to: 0.033976457126007054
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.037033134860915397   to: 0.034580379233486780
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.037627551869506094   to: 0.035181594710154793
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.038218712723842418   to: 0.035779996713133810
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.038806534830196943   to: 0.036375483934178464
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.039390940414084467   to: 0.036967960417237877
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.039971856353055259   to: 0.037557335380544156
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.040549214013973239   to: 0.038143523043180132
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.041122949094711203   to: 0.038726442456076211
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.041693001470191497   to: 0.039306017337380768
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.042259315042699475   to: 0.039882175912146878
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.042821837596394602   to: 0.040454850756273475
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.043380520655942667   to: 0.041023978644637492
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.043935319349191607   to: 0.041589500403350500
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.044486192273812036   to: 0.042151360766071636
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.045033101367823153   to: 0.042709508234306859
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.045576011783923717   to: 0.043263894941622548
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.046114891767548162   to: 0.043814476521701673
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.046649712538566833   to: 0.044361211980167847
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.047180448176550177   to: 0.044904063570103611
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.047707075509516146   to: 0.045442996671187369
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.048229574006081022   to: 0.045977979672374221
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.048747925670933723   to: 0.046508983858044667
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.049262114943554418   to: 0.047035983297545818
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.049772128600099080   to: 0.047558954738049559
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.050277955658371974   to: 0.048077877500652642
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.050779587285809231   to: 0.048592733379643455
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.051277016710397243   to: 0.049103506544861467
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.051770239134450668   to: 0.049610183447074983
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.052259251651176286   to: 0.050112752726304610
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.052744053163948923   to: 0.050611205123019316
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.053224644308228208   to: 0.051105533392134056
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.053701027376044722   to: 0.051595732219737400
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.054173206242986362   to: 0.052081798142480179
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.054641186297616086   to: 0.052563729469555204
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.055104974373254345   to: 0.053041526207201255
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.055564578682059711   to: 0.053515189985663569
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.056020008751343636   to: 0.053984723988545716
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.056471275362055297   to: 0.054450132884487835
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.056918390489375408   to: 0.054911422761108067
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.057361367245357189   to: 0.055368601061144766
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.057800219823555869   to: 0.055821676520738051
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.058234963445588130   to: 0.056270659109791545
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.058665614309564851   to: 0.056715559974354526
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.059092189540341469   to: 0.057156391380968001
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.059514707141531779   to: 0.057593166662917444
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.059933185949232207   to: 0.058025900168338002
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.060347645587404797   to: 0.058454607210117505
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.060758106424868563   to: 0.058879304017545153
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.061164589533849879   to: 0.059300007689654113
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.061567116650044024   to: 0.059716736150207811
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.061965710134141129   to: 0.060129508104280888
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.062360392934770963   to: 0.060538342996386899
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.062751188552822218   to: 0.060943260970105974
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.063138121007092957   to: 0.061344282829166701
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.063521214801230449   to: 0.061741429999938084
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.063900494891918971   to: 0.062134724495288007
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.064275986658276454   to: 0.062524188879766046
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.064647715872420547   to: 0.062909846236069461
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.065015708671166753   to: 0.063291720132752333
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.065379991528822040   to: 0.063669834593138797
i: 100, name:           module.conv10.weight  changing lr from: 0.065740591231038190   to: 0.064044214065402616
i: 101, name:             module.conv10.bias  changing lr from: 0.066097534849690415   to: 0.064414883393775643



# Switched to train mode...
Epoch: [37][  0/391]	Time  0.213 ( 0.213)	Data  0.171 ( 0.171)	Loss 1.2413e-01 (1.2413e-01)	Acc@1  95.31 ( 95.31)	Acc@5 100.00 (100.00)
Epoch: [37][ 10/391]	Time  0.042 ( 0.056)	Data  0.001 ( 0.016)	Loss 1.4193e-01 (1.8228e-01)	Acc@1  92.97 ( 93.47)	Acc@5 100.00 ( 99.93)
Epoch: [37][ 20/391]	Time  0.042 ( 0.050)	Data  0.001 ( 0.009)	Loss 1.6473e-01 (1.8464e-01)	Acc@1  95.31 ( 93.75)	Acc@5 100.00 ( 99.93)
Epoch: [37][ 30/391]	Time  0.041 ( 0.047)	Data  0.001 ( 0.006)	Loss 2.1709e-01 (1.8289e-01)	Acc@1  91.41 ( 93.65)	Acc@5 100.00 ( 99.95)
Epoch: [37][ 40/391]	Time  0.043 ( 0.045)	Data  0.001 ( 0.005)	Loss 1.8163e-01 (1.7260e-01)	Acc@1  93.75 ( 94.11)	Acc@5 100.00 ( 99.96)
Epoch: [37][ 50/391]	Time  0.041 ( 0.044)	Data  0.001 ( 0.004)	Loss 1.9764e-01 (1.7341e-01)	Acc@1  92.97 ( 94.07)	Acc@5 100.00 ( 99.95)
Epoch: [37][ 60/391]	Time  0.040 ( 0.044)	Data  0.001 ( 0.004)	Loss 1.8572e-01 (1.7576e-01)	Acc@1  92.97 ( 94.11)	Acc@5 100.00 ( 99.95)
Epoch: [37][ 70/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.003)	Loss 8.0972e-02 (1.7546e-01)	Acc@1  98.44 ( 93.98)	Acc@5 100.00 ( 99.94)
Epoch: [37][ 80/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.003)	Loss 2.1881e-01 (1.7516e-01)	Acc@1  92.19 ( 93.92)	Acc@5 100.00 ( 99.94)
Epoch: [37][ 90/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.003)	Loss 1.3542e-01 (1.7680e-01)	Acc@1  94.53 ( 93.80)	Acc@5 100.00 ( 99.94)
Epoch: [37][100/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.003)	Loss 1.4625e-01 (1.7795e-01)	Acc@1  92.97 ( 93.68)	Acc@5 100.00 ( 99.94)
Epoch: [37][110/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.003)	Loss 1.5801e-01 (1.7759e-01)	Acc@1  94.53 ( 93.74)	Acc@5 100.00 ( 99.94)
Epoch: [37][120/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.2485e-01 (1.7821e-01)	Acc@1  95.31 ( 93.74)	Acc@5 100.00 ( 99.94)
Epoch: [37][130/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.1282e-01 (1.7811e-01)	Acc@1  92.97 ( 93.73)	Acc@5 100.00 ( 99.95)
Epoch: [37][140/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.7137e-01 (1.7810e-01)	Acc@1  92.19 ( 93.76)	Acc@5 100.00 ( 99.94)
Epoch: [37][150/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.0809e-01 (1.7698e-01)	Acc@1  92.97 ( 93.80)	Acc@5 100.00 ( 99.95)
Epoch: [37][160/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 2.1320e-01 (1.7798e-01)	Acc@1  92.19 ( 93.76)	Acc@5 100.00 ( 99.94)
Epoch: [37][170/391]	Time  0.037 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.9003e-01 (1.7761e-01)	Acc@1  91.41 ( 93.76)	Acc@5 100.00 ( 99.95)
Epoch: [37][180/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.7981e-01 (1.7728e-01)	Acc@1  95.31 ( 93.79)	Acc@5 100.00 ( 99.94)
Epoch: [37][190/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.5320e-01 (1.7795e-01)	Acc@1  95.31 ( 93.77)	Acc@5 100.00 ( 99.94)
Epoch: [37][200/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.2845e-01 (1.7729e-01)	Acc@1  95.31 ( 93.79)	Acc@5 100.00 ( 99.94)
Epoch: [37][210/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.1945e-01 (1.7824e-01)	Acc@1  95.31 ( 93.76)	Acc@5 100.00 ( 99.94)
Epoch: [37][220/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.4350e-01 (1.7716e-01)	Acc@1  93.75 ( 93.79)	Acc@5 100.00 ( 99.94)
Epoch: [37][230/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.9728e-01 (1.7775e-01)	Acc@1  91.41 ( 93.77)	Acc@5 100.00 ( 99.94)
Epoch: [37][240/391]	Time  0.048 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.8567e-01 (1.7848e-01)	Acc@1  93.75 ( 93.74)	Acc@5 100.00 ( 99.94)
Epoch: [37][250/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.5825e-01 (1.7808e-01)	Acc@1  95.31 ( 93.78)	Acc@5 100.00 ( 99.94)
Epoch: [37][260/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.6348e-01 (1.7831e-01)	Acc@1  92.97 ( 93.74)	Acc@5 100.00 ( 99.94)
Epoch: [37][270/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.3533e-01 (1.8030e-01)	Acc@1  90.62 ( 93.66)	Acc@5  99.22 ( 99.93)
Epoch: [37][280/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.5402e-01 (1.8074e-01)	Acc@1  93.75 ( 93.64)	Acc@5 100.00 ( 99.92)
Epoch: [37][290/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.1137e-01 (1.8110e-01)	Acc@1  96.09 ( 93.63)	Acc@5 100.00 ( 99.92)
Epoch: [37][300/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.2411e-01 (1.8150e-01)	Acc@1  97.66 ( 93.63)	Acc@5 100.00 ( 99.92)
Epoch: [37][310/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.3486e-01 (1.8228e-01)	Acc@1  91.41 ( 93.61)	Acc@5  99.22 ( 99.91)
Epoch: [37][320/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.5647e-01 (1.8198e-01)	Acc@1  94.53 ( 93.65)	Acc@5 100.00 ( 99.91)
Epoch: [37][330/391]	Time  0.046 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.3855e-01 (1.8239e-01)	Acc@1  92.19 ( 93.63)	Acc@5 100.00 ( 99.91)
Epoch: [37][340/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.001)	Loss 1.5830e-01 (1.8200e-01)	Acc@1  96.09 ( 93.65)	Acc@5 100.00 ( 99.92)
Epoch: [37][350/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.001)	Loss 1.5214e-01 (1.8196e-01)	Acc@1  92.97 ( 93.66)	Acc@5 100.00 ( 99.92)
Epoch: [37][360/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.001)	Loss 1.4148e-01 (1.8301e-01)	Acc@1  94.53 ( 93.60)	Acc@5 100.00 ( 99.92)
Epoch: [37][370/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.001)	Loss 1.8519e-01 (1.8304e-01)	Acc@1  93.75 ( 93.60)	Acc@5 100.00 ( 99.92)
Epoch: [37][380/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.001)	Loss 1.7327e-01 (1.8448e-01)	Acc@1  95.31 ( 93.54)	Acc@5 100.00 ( 99.92)
Epoch: [37][390/391]	Time  0.028 ( 0.041)	Data  0.001 ( 0.001)	Loss 1.0212e-01 (1.8452e-01)	Acc@1  96.25 ( 93.54)	Acc@5 100.00 ( 99.92)
## e[37] optimizer.zero_grad (sum) time: 0.2700998783111572
## e[37]       loss.backward (sum) time: 4.022585153579712
## e[37]      optimizer.step (sum) time: 1.791133165359497
## epoch[37] training(only) time: 16.065832376480103
# Switched to evaluate mode...
Test: [  0/100]	Time  0.170 ( 0.170)	Loss 1.7541e-01 (1.7541e-01)	Acc@1  97.00 ( 97.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.017 ( 0.034)	Loss 3.3708e-01 (2.8547e-01)	Acc@1  92.00 ( 91.18)	Acc@5 100.00 ( 99.91)
Test: [ 20/100]	Time  0.020 ( 0.027)	Loss 4.2007e-01 (3.2683e-01)	Acc@1  88.00 ( 89.81)	Acc@5 100.00 ( 99.67)
Test: [ 30/100]	Time  0.021 ( 0.026)	Loss 4.1082e-01 (3.5213e-01)	Acc@1  88.00 ( 89.42)	Acc@5 100.00 ( 99.61)
Test: [ 40/100]	Time  0.021 ( 0.025)	Loss 3.9004e-01 (3.6228e-01)	Acc@1  88.00 ( 89.05)	Acc@5  99.00 ( 99.59)
Test: [ 50/100]	Time  0.023 ( 0.024)	Loss 2.2356e-01 (3.6110e-01)	Acc@1  91.00 ( 89.16)	Acc@5 100.00 ( 99.49)
Test: [ 60/100]	Time  0.021 ( 0.023)	Loss 4.4403e-01 (3.6325e-01)	Acc@1  90.00 ( 89.08)	Acc@5  99.00 ( 99.49)
Test: [ 70/100]	Time  0.021 ( 0.023)	Loss 4.2495e-01 (3.6256e-01)	Acc@1  87.00 ( 89.11)	Acc@5 100.00 ( 99.54)
Test: [ 80/100]	Time  0.020 ( 0.023)	Loss 2.6111e-01 (3.5608e-01)	Acc@1  91.00 ( 89.12)	Acc@5 100.00 ( 99.57)
Test: [ 90/100]	Time  0.022 ( 0.023)	Loss 1.0901e-01 (3.5975e-01)	Acc@1  96.00 ( 89.05)	Acc@5 100.00 ( 99.58)
 * Acc@1 89.040 Acc@5 99.570
### epoch[37] execution time: 18.40636420249939
EPOCH 38
i:   0, name:           module.stem.0.weight  changing lr from: 0.010278393921015021   to: 0.008396515016716099
i:   1, name:             module.stem.0.bias  changing lr from: 0.010820808624770743   to: 0.008900256547713335
i:   2, name:           module.stem.1.weight  changing lr from: 0.011371433757897682   to: 0.009414003911999192
i:   3, name:             module.stem.1.bias  changing lr from: 0.011929760340165234   to: 0.009937205226997942
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.012495294809443381   to: 0.010469324283703119
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.013067558771401911   to: 0.011009840344671468
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.013646088741366386   to: 0.011558247930092962
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.014230435879436794   to: 0.012114056593271711
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.014820165719898561   to: 0.012676790686766148
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.015414857895883722   to: 0.013245989120355552
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.016014105860171275   to: 0.013821205111922197
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.016617516602951569   to: 0.014402005932265278
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.017224710367318107   to: 0.014987972644791604
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.017835320363193016   to: 0.015578699840964098
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.018448992480337469   to: 0.016173795372324100
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.019065385001047847   to: 0.016772880079846758
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.019684168313089251   to: 0.017375587521330366
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.020305024623373635   to: 0.017981563697470178
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.020927647672846023   to: 0.018590466777215237
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.021551742453002978   to: 0.019201966822961027
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.022177024924429252   to: 0.019815745516086211
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.022803221737703695   to: 0.020431495883299761
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.023430069956991789   to: 0.021048922024225772
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.024057316786611618   to: 0.021667738840616499
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.024684719300830840   to: 0.022287671767549179
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.025312044177125011   to: 0.022908456506930054
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.025939067433102286   to: 0.023529838763598300
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.026565574167276271   to: 0.024151573984294225
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.027191358303845836   to: 0.024773427099729180
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.027816222341621084   to: 0.025395172269969613
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.028439977107214832   to: 0.026016592633324388
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.029062441512602011   to: 0.026637480058903231
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.029683442317131825   to: 0.027257634902992312
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.030302813894063380   to: 0.027876865769376070
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.030920398001680269   to: 0.028494989273714799
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.031536043559027532   to: 0.029111829812072682
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.032149606426301526   to: 0.029727219333674462
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.032760949189912500   to: 0.030340997117955945
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.033369940952229428   to: 0.030953009555959365
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.033976457126007054   to: 0.031563109936113429
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.034580379233486780   to: 0.032171158234426192
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.035181594710154793   to: 0.032777020909108716
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.035779996713133810   to: 0.033380570699637846
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.036375483934178464   to: 0.033981686430258222
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.036967960417237877   to: 0.034580252817914679
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.037557335380544156   to: 0.035176160284600071
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.038143523043180132   to: 0.035769304774095519
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.038726442456076211   to: 0.036359587573075586
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.039306017337380768   to: 0.036946915136543385
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.039882175912146878   to: 0.037531198917557622
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.040454850756273475   to: 0.038112355201207447
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.041023978644637492   to: 0.038690304942787808
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.041589500403350500   to: 0.039264973610124126
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.042151360766071636   to: 0.039836291029991699
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.042709508234306859   to: 0.040404191238572654
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.043263894941622548   to: 0.040968612335890150
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.043814476521701673   to: 0.041529496344158347
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.044361211980167847   to: 0.042086789069983616
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.044904063570103611   to: 0.042640439970351496
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.045442996671187369   to: 0.043190402022332264
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.045977979672374221   to: 0.043736631596437162
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.046508983858044667   to: 0.044279088333555816
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.047035983297545818   to: 0.044817735025405141
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.047558954738049559   to: 0.045352537498419311
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.048077877500652642   to: 0.045883464501010163
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.048592733379643455   to: 0.046410487594126831
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.049103506544861467   to: 0.046933581045043818
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.049610183447074983   to: 0.047452721724306340
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.050112752726304610   to: 0.047967889005762453
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.050611205123019316   to: 0.048479064669611188
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.051105533392134056   to: 0.048986232808397166
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.051595732219737400   to: 0.049489379735881418
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.052081798142480179   to: 0.049988493898720399
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.052563729469555204   to: 0.050483565790884005
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.053041526207201255   to: 0.050974587870745908
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.053515189985663569   to: 0.051461554480778750
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.053984723988545716   to: 0.051944461769788820
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.054450132884487835   to: 0.052423307617624773
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.054911422761108067   to: 0.052898091562296828
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.055368601061144766   to: 0.053368814729442986
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.055821676520738051   to: 0.053835479764080221
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.056270659109791545   to: 0.054298090764579865
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.056715559974354526   to: 0.054756653218806933
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.057156391380968001   to: 0.055211173942364682
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.057593166662917444   to: 0.055661661018886366
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.058025900168338002   to: 0.056108123742317918
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.058454607210117505   to: 0.056550572561135416
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.058879304017545153   to: 0.056989019024443421
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.059300007689654113   to: 0.057423475729900544
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.059716736150207811   to: 0.057853956273420097
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.060129508104280888   to: 0.058280475200594865
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.060538342996386899   to: 0.058703047959795987
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.060943260970105974   to: 0.059121690856897113
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.061344282829166701   to: 0.059536421011576329
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.061741429999938084   to: 0.059947256315148835
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.062134724495288007   to: 0.060354215389885439
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.062524188879766046   to: 0.060757317549772032
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.062909846236069461   to: 0.061156582762667049
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.063291720132752333   to: 0.061552031613814229
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.063669834593138797   to: 0.061943685270670068
i: 100, name:           module.conv10.weight  changing lr from: 0.064044214065402616   to: 0.062331565449005213
i: 101, name:             module.conv10.bias  changing lr from: 0.064414883393775643   to: 0.062715694380241077



# Switched to train mode...
Epoch: [38][  0/391]	Time  0.215 ( 0.215)	Data  0.173 ( 0.173)	Loss 1.5516e-01 (1.5516e-01)	Acc@1  92.19 ( 92.19)	Acc@5 100.00 (100.00)
Epoch: [38][ 10/391]	Time  0.038 ( 0.057)	Data  0.001 ( 0.017)	Loss 1.6755e-01 (1.7901e-01)	Acc@1  95.31 ( 93.32)	Acc@5 100.00 ( 99.86)
Epoch: [38][ 20/391]	Time  0.039 ( 0.049)	Data  0.001 ( 0.009)	Loss 1.7301e-01 (1.7204e-01)	Acc@1  94.53 ( 93.68)	Acc@5 100.00 ( 99.93)
Epoch: [38][ 30/391]	Time  0.039 ( 0.046)	Data  0.001 ( 0.007)	Loss 1.5043e-01 (1.6669e-01)	Acc@1  96.09 ( 93.98)	Acc@5 100.00 ( 99.92)
Epoch: [38][ 40/391]	Time  0.042 ( 0.045)	Data  0.001 ( 0.005)	Loss 1.7089e-01 (1.6345e-01)	Acc@1  92.97 ( 94.09)	Acc@5 100.00 ( 99.94)
Epoch: [38][ 50/391]	Time  0.041 ( 0.044)	Data  0.001 ( 0.004)	Loss 1.3178e-01 (1.6164e-01)	Acc@1  96.09 ( 94.06)	Acc@5 100.00 ( 99.94)
Epoch: [38][ 60/391]	Time  0.043 ( 0.044)	Data  0.001 ( 0.004)	Loss 8.9685e-02 (1.6237e-01)	Acc@1  97.66 ( 94.03)	Acc@5 100.00 ( 99.95)
Epoch: [38][ 70/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.003)	Loss 2.6484e-01 (1.6210e-01)	Acc@1  89.84 ( 94.04)	Acc@5 100.00 ( 99.96)
Epoch: [38][ 80/391]	Time  0.046 ( 0.043)	Data  0.002 ( 0.003)	Loss 1.1072e-01 (1.6018e-01)	Acc@1  97.66 ( 94.15)	Acc@5 100.00 ( 99.95)
Epoch: [38][ 90/391]	Time  0.039 ( 0.043)	Data  0.001 ( 0.003)	Loss 1.8998e-01 (1.6136e-01)	Acc@1  94.53 ( 94.14)	Acc@5 100.00 ( 99.96)
Epoch: [38][100/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.003)	Loss 1.1160e-01 (1.6220e-01)	Acc@1  96.09 ( 94.14)	Acc@5 100.00 ( 99.96)
Epoch: [38][110/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.003)	Loss 2.7388e-01 (1.6559e-01)	Acc@1  90.62 ( 94.05)	Acc@5  99.22 ( 99.94)
Epoch: [38][120/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.4046e-01 (1.6627e-01)	Acc@1  95.31 ( 94.02)	Acc@5 100.00 ( 99.94)
Epoch: [38][130/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.3182e-01 (1.6672e-01)	Acc@1  96.09 ( 93.96)	Acc@5 100.00 ( 99.95)
Epoch: [38][140/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.6290e-01 (1.6708e-01)	Acc@1  95.31 ( 93.91)	Acc@5 100.00 ( 99.95)
Epoch: [38][150/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.4385e-01 (1.6640e-01)	Acc@1  93.75 ( 93.93)	Acc@5 100.00 ( 99.95)
Epoch: [38][160/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.7973e-01 (1.6652e-01)	Acc@1  92.19 ( 93.91)	Acc@5 100.00 ( 99.95)
Epoch: [38][170/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.2911e-01 (1.6643e-01)	Acc@1  96.09 ( 93.91)	Acc@5 100.00 ( 99.95)
Epoch: [38][180/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.7195e-01 (1.6747e-01)	Acc@1  95.31 ( 93.90)	Acc@5  99.22 ( 99.94)
Epoch: [38][190/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.6064e-01 (1.6726e-01)	Acc@1  95.31 ( 93.90)	Acc@5 100.00 ( 99.94)
Epoch: [38][200/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.8317e-01 (1.6910e-01)	Acc@1  89.06 ( 93.84)	Acc@5 100.00 ( 99.94)
Epoch: [38][210/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.5218e-01 (1.7064e-01)	Acc@1  90.62 ( 93.83)	Acc@5 100.00 ( 99.94)
Epoch: [38][220/391]	Time  0.056 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.5244e-01 (1.7024e-01)	Acc@1  92.97 ( 93.86)	Acc@5 100.00 ( 99.94)
Epoch: [38][230/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.2804e-01 (1.6990e-01)	Acc@1  90.62 ( 93.87)	Acc@5 100.00 ( 99.95)
Epoch: [38][240/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.1079e-01 (1.7058e-01)	Acc@1  94.53 ( 93.84)	Acc@5  99.22 ( 99.94)
Epoch: [38][250/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.3701e-01 (1.6991e-01)	Acc@1  96.88 ( 93.87)	Acc@5 100.00 ( 99.94)
Epoch: [38][260/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.7953e-01 (1.6943e-01)	Acc@1  96.09 ( 93.91)	Acc@5 100.00 ( 99.95)
Epoch: [38][270/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.7522e-01 (1.7046e-01)	Acc@1  92.97 ( 93.86)	Acc@5 100.00 ( 99.95)
Epoch: [38][280/391]	Time  0.043 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.1947e-01 (1.7132e-01)	Acc@1  92.19 ( 93.83)	Acc@5  99.22 ( 99.94)
Epoch: [38][290/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.5460e-01 (1.7214e-01)	Acc@1  94.53 ( 93.81)	Acc@5 100.00 ( 99.94)
Epoch: [38][300/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.8563e-01 (1.7214e-01)	Acc@1  91.41 ( 93.80)	Acc@5 100.00 ( 99.94)
Epoch: [38][310/391]	Time  0.040 ( 0.041)	Data  0.002 ( 0.002)	Loss 1.8698e-01 (1.7226e-01)	Acc@1  92.19 ( 93.82)	Acc@5 100.00 ( 99.94)
Epoch: [38][320/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.6935e-01 (1.7237e-01)	Acc@1  91.41 ( 93.80)	Acc@5 100.00 ( 99.94)
Epoch: [38][330/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.001)	Loss 1.3068e-01 (1.7307e-01)	Acc@1  93.75 ( 93.77)	Acc@5 100.00 ( 99.94)
Epoch: [38][340/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.001)	Loss 1.5265e-01 (1.7330e-01)	Acc@1  92.19 ( 93.74)	Acc@5 100.00 ( 99.94)
Epoch: [38][350/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.001)	Loss 3.0013e-01 (1.7325e-01)	Acc@1  85.94 ( 93.73)	Acc@5 100.00 ( 99.94)
Epoch: [38][360/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.001)	Loss 1.4097e-01 (1.7368e-01)	Acc@1  96.09 ( 93.74)	Acc@5 100.00 ( 99.94)
Epoch: [38][370/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.001)	Loss 2.5070e-01 (1.7509e-01)	Acc@1  89.84 ( 93.68)	Acc@5 100.00 ( 99.93)
Epoch: [38][380/391]	Time  0.043 ( 0.041)	Data  0.001 ( 0.001)	Loss 2.5291e-01 (1.7605e-01)	Acc@1  91.41 ( 93.67)	Acc@5 100.00 ( 99.93)
Epoch: [38][390/391]	Time  0.028 ( 0.041)	Data  0.001 ( 0.001)	Loss 2.0442e-01 (1.7618e-01)	Acc@1  93.75 ( 93.65)	Acc@5 100.00 ( 99.93)
## e[38] optimizer.zero_grad (sum) time: 0.27236151695251465
## e[38]       loss.backward (sum) time: 4.050767421722412
## e[38]      optimizer.step (sum) time: 1.7976484298706055
## epoch[38] training(only) time: 16.15946364402771
# Switched to evaluate mode...
Test: [  0/100]	Time  0.161 ( 0.161)	Loss 3.4400e-01 (3.4400e-01)	Acc@1  90.00 ( 90.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.021 ( 0.035)	Loss 6.6915e-01 (3.5006e-01)	Acc@1  85.00 ( 89.73)	Acc@5  98.00 ( 99.73)
Test: [ 20/100]	Time  0.023 ( 0.029)	Loss 2.8313e-01 (3.9121e-01)	Acc@1  86.00 ( 88.48)	Acc@5  99.00 ( 99.38)
Test: [ 30/100]	Time  0.018 ( 0.026)	Loss 4.3771e-01 (4.0793e-01)	Acc@1  85.00 ( 88.39)	Acc@5  98.00 ( 99.39)
Test: [ 40/100]	Time  0.021 ( 0.025)	Loss 4.2611e-01 (4.0457e-01)	Acc@1  86.00 ( 88.32)	Acc@5  99.00 ( 99.37)
Test: [ 50/100]	Time  0.016 ( 0.024)	Loss 1.7443e-01 (3.9900e-01)	Acc@1  94.00 ( 88.37)	Acc@5 100.00 ( 99.47)
Test: [ 60/100]	Time  0.019 ( 0.023)	Loss 4.5216e-01 (3.9078e-01)	Acc@1  90.00 ( 88.41)	Acc@5  98.00 ( 99.51)
Test: [ 70/100]	Time  0.023 ( 0.022)	Loss 3.8239e-01 (3.8513e-01)	Acc@1  90.00 ( 88.52)	Acc@5 100.00 ( 99.54)
Test: [ 80/100]	Time  0.017 ( 0.022)	Loss 3.1047e-01 (3.8318e-01)	Acc@1  89.00 ( 88.68)	Acc@5 100.00 ( 99.56)
Test: [ 90/100]	Time  0.022 ( 0.022)	Loss 2.3833e-01 (3.8585e-01)	Acc@1  90.00 ( 88.63)	Acc@5 100.00 ( 99.55)
 * Acc@1 88.650 Acc@5 99.550
### epoch[38] execution time: 18.463797330856323
EPOCH 39
i:   0, name:           module.stem.0.weight  changing lr from: 0.008396515016716099   to: 0.006712584379435493
i:   1, name:             module.stem.0.bias  changing lr from: 0.008900256547713335   to: 0.007172461227534282
i:   2, name:           module.stem.1.weight  changing lr from: 0.009414003911999192   to: 0.007644210162291009
i:   3, name:             module.stem.1.bias  changing lr from: 0.009937205226997942   to: 0.008127238169718536
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.010469324283703119   to: 0.008620967952089536
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.011009840344671468   to: 0.009124837786484128
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.011558247930092962   to: 0.009638301366807298
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.012114056593271711   to: 0.010160827630853880
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.012676790686766148   to: 0.010691900573903245
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.013245989120355552   to: 0.011231019050234915
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.013821205111922197   to: 0.011777696563869417
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.014402005932265278   to: 0.012331461049756482
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.014987972644791604   to: 0.012891854646553329
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.015578699840964098   to: 0.013458433462062287
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.016173795372324100   to: 0.014030767332324657
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.016772880079846758   to: 0.014608439575301935
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.017375587521330366   to: 0.015191046740010261
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.017981563697470178   to: 0.015778198351914869
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.018590466777215237   to: 0.016369516655332882
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.019201966822961027   to: 0.016964636353539536
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.019815745516086211   to: 0.017563204347221178
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.020431495883299761   to: 0.018164879471870572
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.021048922024225772   to: 0.018769332234673679
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.021667738840616499   to: 0.019376244551395000
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.022287671767549179   to: 0.019985309483727134
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.022908456506930054   to: 0.020596230977532434
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.023529838763598300   to: 0.021208723602368702
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.024151573984294225   to: 0.021822512292657272
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.024773427099729180   to: 0.022437332090819263
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.025395172269969613   to: 0.023052927892677041
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.026016592633324388   to: 0.023669054195389012
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.026637480058903231   to: 0.024285474848160876
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.027257634902992312   to: 0.024901962805950001
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.027876865769376070   to: 0.025518299886358942
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.028494989273714799   to: 0.026134276529890667
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.029111829812072682   to: 0.026749691563719254
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.029727219333674462   to: 0.027364351969110540
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.030340997117955945   to: 0.027978072652609966
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.030953009555959365   to: 0.028590676221098468
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.031563109936113429   to: 0.029201992760802410
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.032171158234426192   to: 0.029811859620329336
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.032777020909108716   to: 0.030420121197788419
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.033380570699637846   to: 0.031026628732042000
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.033981686430258222   to: 0.031631240098124465
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.034580252817914679   to: 0.032233819606852961
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.035176160284600071   to: 0.032834237808646353
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.035769304774095519   to: 0.033432371301558787
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.036359587573075586   to: 0.034028102543527471
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.036946915136543385   to: 0.034621319668825326
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.037531198917557622   to: 0.035211916308704072
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.038112355201207447   to: 0.035799791416205637
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.038690304942787808   to: 0.036384849095115003
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.039264973610124126   to: 0.036966998433022362
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.039836291029991699   to: 0.037546153338457421
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.040404191238572654   to: 0.038122232382054984
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.040968612335890150   to: 0.038695158641706418
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.041529496344158347   to: 0.039264859551649503
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.042086789069983616   to: 0.039831266755444517
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.042640439970351496   to: 0.040394315962783083
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.043190402022332264   to: 0.040953946810073069
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.043736631596437162   to: 0.041510102724741489
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.044279088333555816   to: 0.042062730793194628
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.044817735025405141   to: 0.042611781632374113
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.045352537498419311   to: 0.043157209264845481
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.045883464501010163   to: 0.043698970997355313
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.046410487594126831   to: 0.044237027302791901
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.046933581045043818   to: 0.044771341705483553
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.047452721724306340   to: 0.045301880669768368
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.047967889005762453   to: 0.045828613491769171
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.048479064669611188   to: 0.046351512194306325
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.048986232808397166   to: 0.046870551424882084
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.049489379735881418   to: 0.047385708356669283
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.049988493898720399   to: 0.047896962592438141
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.050483565790884005   to: 0.048404296071354297
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.050974587870745908   to: 0.048907692978582912
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.051461554480778750   to: 0.049407139657632444
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.051944461769788820   to: 0.049902624525373897
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.052423307617624773   to: 0.050394137989670518
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.052898091562296828   to: 0.050881672369554959
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.053368814729442986   to: 0.051365221817890383
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.053835479764080221   to: 0.051844782246453558
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.054298090764579865   to: 0.052320351253378750
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.054756653218806933   to: 0.052791928052901706
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.055211173942364682   to: 0.053259513407344319
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.055661661018886366   to: 0.053723109561281172
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.056108123742317918   to: 0.054182720177830761
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.056550572561135416   to: 0.054638350277013914
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.056989019024443421   to: 0.055090006176124633
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.057423475729900544   to: 0.055537695432057992
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.057853956273420097   to: 0.055981426785541868
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.058280475200594865   to: 0.056421210107219823
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.058703047959795987   to: 0.056857056345533369
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.059121690856897113   to: 0.057288977476353732
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.059536421011576329   to: 0.057716986454312807
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.059947256315148835   to: 0.058141097165785853
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.060354215389885439   to: 0.058561324383477845
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.060757317549772032   to: 0.058977683722567759
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.061156582762667049   to: 0.059390191598365165
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.061552031613814229   to: 0.059798865185435229
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.061943685270670068   to: 0.060203722378148694
i: 100, name:           module.conv10.weight  changing lr from: 0.062331565449005213   to: 0.060604781752614995
i: 101, name:             module.conv10.bias  changing lr from: 0.062715694380241077   to: 0.061002062529957046



# Switched to train mode...
Epoch: [39][  0/391]	Time  0.205 ( 0.205)	Data  0.162 ( 0.162)	Loss 1.3673e-01 (1.3673e-01)	Acc@1  95.31 ( 95.31)	Acc@5 100.00 (100.00)
Epoch: [39][ 10/391]	Time  0.039 ( 0.055)	Data  0.001 ( 0.016)	Loss 1.1382e-01 (1.5496e-01)	Acc@1  96.09 ( 95.10)	Acc@5 100.00 ( 99.93)
Epoch: [39][ 20/391]	Time  0.042 ( 0.049)	Data  0.001 ( 0.009)	Loss 1.8396e-01 (1.6672e-01)	Acc@1  93.75 ( 94.46)	Acc@5 100.00 ( 99.89)
Epoch: [39][ 30/391]	Time  0.039 ( 0.046)	Data  0.001 ( 0.006)	Loss 1.7807e-01 (1.6164e-01)	Acc@1  93.75 ( 94.56)	Acc@5 100.00 ( 99.87)
Epoch: [39][ 40/391]	Time  0.041 ( 0.045)	Data  0.001 ( 0.005)	Loss 1.5936e-01 (1.5934e-01)	Acc@1  95.31 ( 94.59)	Acc@5 100.00 ( 99.89)
Epoch: [39][ 50/391]	Time  0.041 ( 0.044)	Data  0.001 ( 0.004)	Loss 1.5120e-01 (1.5718e-01)	Acc@1  95.31 ( 94.67)	Acc@5 100.00 ( 99.91)
Epoch: [39][ 60/391]	Time  0.037 ( 0.043)	Data  0.001 ( 0.004)	Loss 1.9104e-01 (1.5594e-01)	Acc@1  93.75 ( 94.85)	Acc@5 100.00 ( 99.90)
Epoch: [39][ 70/391]	Time  0.039 ( 0.043)	Data  0.001 ( 0.003)	Loss 1.4183e-01 (1.5624e-01)	Acc@1  96.09 ( 94.81)	Acc@5  99.22 ( 99.90)
Epoch: [39][ 80/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.003)	Loss 1.8142e-01 (1.5895e-01)	Acc@1  92.97 ( 94.65)	Acc@5 100.00 ( 99.91)
Epoch: [39][ 90/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.003)	Loss 1.3787e-01 (1.5781e-01)	Acc@1  94.53 ( 94.63)	Acc@5 100.00 ( 99.91)
Epoch: [39][100/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.003)	Loss 1.1845e-01 (1.5702e-01)	Acc@1  93.75 ( 94.63)	Acc@5 100.00 ( 99.92)
Epoch: [39][110/391]	Time  0.047 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.8847e-01 (1.5752e-01)	Acc@1  92.19 ( 94.62)	Acc@5 100.00 ( 99.92)
Epoch: [39][120/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 9.6135e-02 (1.5830e-01)	Acc@1  96.88 ( 94.59)	Acc@5 100.00 ( 99.91)
Epoch: [39][130/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.1094e-01 (1.5863e-01)	Acc@1  96.09 ( 94.51)	Acc@5 100.00 ( 99.91)
Epoch: [39][140/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 8.2564e-02 (1.5964e-01)	Acc@1  96.88 ( 94.47)	Acc@5 100.00 ( 99.91)
Epoch: [39][150/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.8346e-01 (1.6100e-01)	Acc@1  95.31 ( 94.41)	Acc@5 100.00 ( 99.92)
Epoch: [39][160/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.2908e-01 (1.6024e-01)	Acc@1  96.09 ( 94.44)	Acc@5 100.00 ( 99.92)
Epoch: [39][170/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.3729e-01 (1.6097e-01)	Acc@1  94.53 ( 94.36)	Acc@5 100.00 ( 99.92)
Epoch: [39][180/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.2743e-01 (1.6267e-01)	Acc@1  96.88 ( 94.30)	Acc@5 100.00 ( 99.92)
Epoch: [39][190/391]	Time  0.043 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.8706e-01 (1.6331e-01)	Acc@1  92.97 ( 94.28)	Acc@5 100.00 ( 99.92)
Epoch: [39][200/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.8842e-01 (1.6286e-01)	Acc@1  93.75 ( 94.28)	Acc@5 100.00 ( 99.92)
Epoch: [39][210/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 9.2497e-02 (1.6263e-01)	Acc@1  96.88 ( 94.28)	Acc@5 100.00 ( 99.92)
Epoch: [39][220/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.7961e-01 (1.6285e-01)	Acc@1  88.28 ( 94.24)	Acc@5 100.00 ( 99.92)
Epoch: [39][230/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.7948e-01 (1.6251e-01)	Acc@1  94.53 ( 94.28)	Acc@5  99.22 ( 99.92)
Epoch: [39][240/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.1959e-01 (1.6187e-01)	Acc@1  96.88 ( 94.31)	Acc@5 100.00 ( 99.92)
Epoch: [39][250/391]	Time  0.040 ( 0.041)	Data  0.002 ( 0.002)	Loss 1.6220e-01 (1.6289e-01)	Acc@1  93.75 ( 94.26)	Acc@5 100.00 ( 99.92)
Epoch: [39][260/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.6043e-01 (1.6340e-01)	Acc@1  90.62 ( 94.24)	Acc@5 100.00 ( 99.92)
Epoch: [39][270/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.5292e-01 (1.6392e-01)	Acc@1  92.97 ( 94.22)	Acc@5 100.00 ( 99.92)
Epoch: [39][280/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.6064e-01 (1.6396e-01)	Acc@1  92.19 ( 94.20)	Acc@5 100.00 ( 99.92)
Epoch: [39][290/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.8914e-01 (1.6421e-01)	Acc@1  94.53 ( 94.19)	Acc@5 100.00 ( 99.92)
Epoch: [39][300/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.4281e-01 (1.6446e-01)	Acc@1  96.09 ( 94.20)	Acc@5 100.00 ( 99.93)
Epoch: [39][310/391]	Time  0.040 ( 0.041)	Data  0.002 ( 0.002)	Loss 1.3598e-01 (1.6515e-01)	Acc@1  96.88 ( 94.16)	Acc@5 100.00 ( 99.93)
Epoch: [39][320/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.1607e-01 (1.6651e-01)	Acc@1  91.41 ( 94.11)	Acc@5 100.00 ( 99.93)
Epoch: [39][330/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.001)	Loss 2.1070e-01 (1.6682e-01)	Acc@1  92.19 ( 94.11)	Acc@5 100.00 ( 99.93)
Epoch: [39][340/391]	Time  0.050 ( 0.041)	Data  0.001 ( 0.001)	Loss 1.1746e-01 (1.6738e-01)	Acc@1  96.09 ( 94.09)	Acc@5 100.00 ( 99.93)
Epoch: [39][350/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.001)	Loss 1.4074e-01 (1.6689e-01)	Acc@1  95.31 ( 94.10)	Acc@5 100.00 ( 99.93)
Epoch: [39][360/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.001)	Loss 1.6838e-01 (1.6711e-01)	Acc@1  92.97 ( 94.09)	Acc@5 100.00 ( 99.93)
Epoch: [39][370/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.001)	Loss 1.7388e-01 (1.6673e-01)	Acc@1  92.19 ( 94.10)	Acc@5 100.00 ( 99.93)
Epoch: [39][380/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.001)	Loss 1.5373e-01 (1.6612e-01)	Acc@1  96.88 ( 94.13)	Acc@5 100.00 ( 99.93)
Epoch: [39][390/391]	Time  0.027 ( 0.041)	Data  0.001 ( 0.001)	Loss 1.9769e-01 (1.6615e-01)	Acc@1  93.75 ( 94.12)	Acc@5 100.00 ( 99.93)
## e[39] optimizer.zero_grad (sum) time: 0.27332210540771484
## e[39]       loss.backward (sum) time: 4.022790431976318
## e[39]      optimizer.step (sum) time: 1.790282964706421
## epoch[39] training(only) time: 16.098180532455444
# Switched to evaluate mode...
Test: [  0/100]	Time  0.174 ( 0.174)	Loss 1.6341e-01 (1.6341e-01)	Acc@1  93.00 ( 93.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.021 ( 0.036)	Loss 4.0982e-01 (3.5538e-01)	Acc@1  86.00 ( 89.27)	Acc@5 100.00 ( 99.64)
Test: [ 20/100]	Time  0.024 ( 0.029)	Loss 3.8352e-01 (3.6565e-01)	Acc@1  86.00 ( 89.19)	Acc@5 100.00 ( 99.52)
Test: [ 30/100]	Time  0.021 ( 0.027)	Loss 3.4111e-01 (3.6956e-01)	Acc@1  89.00 ( 89.03)	Acc@5  99.00 ( 99.48)
Test: [ 40/100]	Time  0.021 ( 0.026)	Loss 3.8524e-01 (3.7763e-01)	Acc@1  87.00 ( 88.90)	Acc@5  99.00 ( 99.46)
Test: [ 50/100]	Time  0.017 ( 0.025)	Loss 2.8082e-01 (3.7849e-01)	Acc@1  90.00 ( 88.88)	Acc@5 100.00 ( 99.49)
Test: [ 60/100]	Time  0.018 ( 0.024)	Loss 4.1083e-01 (3.7387e-01)	Acc@1  91.00 ( 88.82)	Acc@5 100.00 ( 99.56)
Test: [ 70/100]	Time  0.017 ( 0.023)	Loss 2.5936e-01 (3.6905e-01)	Acc@1  93.00 ( 88.82)	Acc@5 100.00 ( 99.59)
Test: [ 80/100]	Time  0.022 ( 0.023)	Loss 1.6006e-01 (3.6369e-01)	Acc@1  94.00 ( 88.89)	Acc@5 100.00 ( 99.64)
Test: [ 90/100]	Time  0.022 ( 0.022)	Loss 1.0836e-01 (3.6538e-01)	Acc@1  94.00 ( 88.78)	Acc@5 100.00 ( 99.65)
 * Acc@1 88.820 Acc@5 99.660
### epoch[39] execution time: 18.433449506759644
EPOCH 40
i:   0, name:           module.stem.0.weight  changing lr from: 0.006712584379435493   to: 0.005234426044027662
i:   1, name:             module.stem.0.bias  changing lr from: 0.007172461227534282   to: 0.005645333501572674
i:   2, name:           module.stem.1.weight  changing lr from: 0.007644210162291009   to: 0.006070037821654799
i:   3, name:             module.stem.1.bias  changing lr from: 0.008127238169718536   to: 0.006507907289942610
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.008620967952089536   to: 0.006958325712136919
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.009124837786484128   to: 0.007420692346008445
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.009638301366807298   to: 0.007894421811782553
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.010160827630853880   to: 0.008378943982703085
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.010691900573903245   to: 0.008873703857502691
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.011231019050234915   to: 0.009378161416407699
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.011777696563869417   to: 0.009891791462209393
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.012331461049756482   to: 0.010414083447842899
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.012891854646553329   to: 0.010944541291827085
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.013458433462062287   to: 0.011482683182836545
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.014030767332324657   to: 0.012028041374596714
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.014608439575301935   to: 0.012580161972218680
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.015191046740010261   to: 0.013138604711017486
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.015778198351914869   to: 0.013702942728790912
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.016369516655332882   to: 0.014272762332469453
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.016964636353539536   to: 0.014847662759988160
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.017563204347221178   to: 0.015427255938171715
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.018164879471870572   to: 0.016011166237369673
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.018769332234673679   to: 0.016599030223526053
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.019376244551395000   to: 0.017190496408318195
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.019985309483727134   to: 0.017785224997953087
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.020596230977532434   to: 0.018382887641165063
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.021208723602368702   to: 0.018983167176917067
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.021822512292657272   to: 0.019585757382268931
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.022437332090819263   to: 0.020190362720837837
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.023052927892677041   to: 0.020796698092242313
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.023669054195389012   to: 0.021404488582887717
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.024285474848160876   to: 0.022013469218420664
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.024901962805950001   to: 0.022623384718149866
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.025518299886358942   to: 0.023233989251704758
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.026134276529890667   to: 0.023845046198176890
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.026749691563719254   to: 0.024456327907965189
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.027364351969110540   to: 0.025067615467524104
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.027978072652609966   to: 0.025678698467191858
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.028590676221098468   to: 0.026289374772257269
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.029201992760802410   to: 0.026899450297404294
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.029811859620329336   to: 0.027508738784657163
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.030420121197788419   to: 0.028117061584932202
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.031026628732042000   to: 0.028724247443287960
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.031631240098124465   to: 0.029330132287951585
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.032233819606852961   to: 0.029934559023185727
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.032834237808646353   to: 0.030537377326049355
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.033432371301558787   to: 0.031138443447093673
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.034028102543527471   to: 0.031737620015025177
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.034621319668825326   to: 0.032334775845357294
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.035211916308704072   to: 0.032929785753064211
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.035799791416205637   to: 0.033522530369241819
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.036384849095115003   to: 0.034112895961773519
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.036966998433022362   to: 0.034700774259991983
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.037546153338457421   to: 0.035286062283321276
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.038122232382054984   to: 0.035868662173878442
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.038695158641706418   to: 0.036448481033008011
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.039264859551649503   to: 0.037025430761718971
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.039831266755444517   to: 0.037599427904988228
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.040394315962783083   to: 0.038170393499891930
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.040953946810073069   to: 0.038738252927521484
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.041510102724741489   to: 0.039302935768638983
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.042062730793194628   to: 0.039864375663022901
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.042611781632374113   to: 0.040422510172453227
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.043157209264845481   to: 0.040977280647282704
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.043698970997355313   to: 0.041528632096538953
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.044237027302791901   to: 0.042076513061500620
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.044771341705483553   to: 0.042620875492689239
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.045301880669768368   to: 0.043161674630217195
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.045828613491769171   to: 0.043698868887431616
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.046351512194306325   to: 0.044232419737792371
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.046870551424882084   to: 0.044762291604922753
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.047385708356669283   to: 0.045288451755769968
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.047896962592438141   to: 0.045810870196813014
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.048404296071354297   to: 0.046329519573254666
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.048907692978582912   to: 0.046844375071134987
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.049407139657632444   to: 0.047355414322302884
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.049902624525373897   to: 0.047862617312183428
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.050394137989670518   to: 0.048365966290277923
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.050881672369554959   to: 0.048865445683334841
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.051365221817890383   to: 0.049361042011129903
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.051844782246453558   to: 0.049852743804793459
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.052320351253378750   to: 0.050340541527625376
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.052791928052901706   to: 0.050824427498336475
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.053259513407344319   to: 0.051304395816657668
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.053723109561281172   to: 0.051780442291257847
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.054182720177830761   to: 0.052252564369912768
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.054638350277013914   to: 0.052720761071867697
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.055090006176124633   to: 0.053185032922337699
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.055537695432057992   to: 0.053645381889090016
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.055981426785541868   to: 0.054101811321054294
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.056421210107219823   to: 0.054554325888906789
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.056857056345533369   to: 0.055002931527576029
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.057288977476353732   to: 0.055447635380618546
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.057716986454312807   to: 0.055888445746413266
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.058141097165785853   to: 0.056325372026125579
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.058561324383477845   to: 0.056758424673391698
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.058977683722567759   to: 0.057187615145675955
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.059390191598365165   to: 0.057612955857253928
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.059798865185435229   to: 0.058034460133775667
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.060203722378148694   to: 0.058452142168364342
i: 100, name:           module.conv10.weight  changing lr from: 0.060604781752614995   to: 0.058866016979206084
i: 101, name:             module.conv10.bias  changing lr from: 0.061002062529957046   to: 0.059276100368588651



# Switched to train mode...
Epoch: [40][  0/391]	Time  0.215 ( 0.215)	Data  0.174 ( 0.174)	Loss 1.5423e-01 (1.5423e-01)	Acc@1  94.53 ( 94.53)	Acc@5 100.00 (100.00)
Epoch: [40][ 10/391]	Time  0.039 ( 0.057)	Data  0.001 ( 0.017)	Loss 7.5605e-02 (1.4060e-01)	Acc@1  96.88 ( 95.03)	Acc@5 100.00 (100.00)
Epoch: [40][ 20/391]	Time  0.039 ( 0.049)	Data  0.001 ( 0.009)	Loss 1.3508e-01 (1.4100e-01)	Acc@1  96.09 ( 95.09)	Acc@5 100.00 ( 99.96)
Epoch: [40][ 30/391]	Time  0.038 ( 0.046)	Data  0.001 ( 0.007)	Loss 2.0540e-01 (1.4386e-01)	Acc@1  91.41 ( 94.88)	Acc@5 100.00 ( 99.92)
Epoch: [40][ 40/391]	Time  0.038 ( 0.045)	Data  0.001 ( 0.005)	Loss 1.0190e-01 (1.4905e-01)	Acc@1  96.09 ( 94.93)	Acc@5 100.00 ( 99.92)
Epoch: [40][ 50/391]	Time  0.043 ( 0.044)	Data  0.001 ( 0.004)	Loss 7.8688e-02 (1.4723e-01)	Acc@1  96.88 ( 94.88)	Acc@5 100.00 ( 99.92)
Epoch: [40][ 60/391]	Time  0.041 ( 0.044)	Data  0.001 ( 0.004)	Loss 1.0255e-01 (1.4545e-01)	Acc@1  95.31 ( 94.93)	Acc@5 100.00 ( 99.92)
Epoch: [40][ 70/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.003)	Loss 1.3750e-01 (1.4934e-01)	Acc@1  94.53 ( 94.77)	Acc@5 100.00 ( 99.92)
Epoch: [40][ 80/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.003)	Loss 8.4946e-02 (1.5123e-01)	Acc@1  96.88 ( 94.67)	Acc@5 100.00 ( 99.92)
Epoch: [40][ 90/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.003)	Loss 1.0120e-01 (1.5186e-01)	Acc@1  96.88 ( 94.63)	Acc@5 100.00 ( 99.92)
Epoch: [40][100/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.003)	Loss 1.2893e-01 (1.5400e-01)	Acc@1  94.53 ( 94.55)	Acc@5 100.00 ( 99.92)
Epoch: [40][110/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.003)	Loss 2.3309e-01 (1.5608e-01)	Acc@1  90.62 ( 94.48)	Acc@5 100.00 ( 99.93)
Epoch: [40][120/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.2041e-01 (1.5589e-01)	Acc@1  94.53 ( 94.54)	Acc@5 100.00 ( 99.94)
Epoch: [40][130/391]	Time  0.041 ( 0.042)	Data  0.002 ( 0.002)	Loss 1.4782e-01 (1.5648e-01)	Acc@1  92.19 ( 94.52)	Acc@5 100.00 ( 99.93)
Epoch: [40][140/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 9.4415e-02 (1.5698e-01)	Acc@1  97.66 ( 94.45)	Acc@5 100.00 ( 99.94)
Epoch: [40][150/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.0952e-01 (1.5424e-01)	Acc@1  94.53 ( 94.58)	Acc@5 100.00 ( 99.94)
Epoch: [40][160/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.5553e-01 (1.5307e-01)	Acc@1  93.75 ( 94.62)	Acc@5 100.00 ( 99.94)
Epoch: [40][170/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.0123e-01 (1.5298e-01)	Acc@1  96.88 ( 94.60)	Acc@5 100.00 ( 99.95)
Epoch: [40][180/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.2494e-01 (1.5233e-01)	Acc@1  94.53 ( 94.59)	Acc@5 100.00 ( 99.95)
Epoch: [40][190/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.0503e-01 (1.5149e-01)	Acc@1  97.66 ( 94.62)	Acc@5 100.00 ( 99.95)
Epoch: [40][200/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.0263e-01 (1.5283e-01)	Acc@1  96.09 ( 94.55)	Acc@5 100.00 ( 99.95)
Epoch: [40][210/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.5449e-01 (1.5315e-01)	Acc@1  95.31 ( 94.54)	Acc@5 100.00 ( 99.95)
Epoch: [40][220/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.9094e-01 (1.5341e-01)	Acc@1  90.62 ( 94.49)	Acc@5 100.00 ( 99.95)
Epoch: [40][230/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.7631e-01 (1.5439e-01)	Acc@1  94.53 ( 94.47)	Acc@5 100.00 ( 99.95)
Epoch: [40][240/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.7426e-01 (1.5535e-01)	Acc@1  90.62 ( 94.45)	Acc@5 100.00 ( 99.95)
Epoch: [40][250/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.0002e-01 (1.5540e-01)	Acc@1  96.09 ( 94.45)	Acc@5 100.00 ( 99.95)
Epoch: [40][260/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.1539e-01 (1.5508e-01)	Acc@1  96.88 ( 94.45)	Acc@5 100.00 ( 99.95)
Epoch: [40][270/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.5501e-01 (1.5548e-01)	Acc@1  95.31 ( 94.44)	Acc@5 100.00 ( 99.95)
Epoch: [40][280/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.4417e-01 (1.5490e-01)	Acc@1  95.31 ( 94.46)	Acc@5 100.00 ( 99.95)
Epoch: [40][290/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.1621e-01 (1.5522e-01)	Acc@1  91.41 ( 94.45)	Acc@5  99.22 ( 99.95)
Epoch: [40][300/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.3750e-01 (1.5552e-01)	Acc@1  96.09 ( 94.45)	Acc@5  99.22 ( 99.95)
Epoch: [40][310/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.4846e-01 (1.5704e-01)	Acc@1  93.75 ( 94.39)	Acc@5 100.00 ( 99.94)
Epoch: [40][320/391]	Time  0.041 ( 0.041)	Data  0.002 ( 0.002)	Loss 1.3273e-01 (1.5670e-01)	Acc@1  94.53 ( 94.40)	Acc@5 100.00 ( 99.94)
Epoch: [40][330/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.5782e-01 (1.5740e-01)	Acc@1  94.53 ( 94.39)	Acc@5 100.00 ( 99.95)
Epoch: [40][340/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.001)	Loss 8.5468e-02 (1.5836e-01)	Acc@1  97.66 ( 94.37)	Acc@5 100.00 ( 99.95)
Epoch: [40][350/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.001)	Loss 1.1398e-01 (1.5836e-01)	Acc@1  96.88 ( 94.36)	Acc@5 100.00 ( 99.94)
Epoch: [40][360/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.001)	Loss 3.1187e-01 (1.5936e-01)	Acc@1  88.28 ( 94.33)	Acc@5 100.00 ( 99.94)
Epoch: [40][370/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.001)	Loss 2.5262e-01 (1.5975e-01)	Acc@1  89.84 ( 94.30)	Acc@5 100.00 ( 99.94)
Epoch: [40][380/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.001)	Loss 2.7464e-01 (1.6064e-01)	Acc@1  90.62 ( 94.28)	Acc@5  98.44 ( 99.94)
Epoch: [40][390/391]	Time  0.028 ( 0.041)	Data  0.001 ( 0.001)	Loss 2.6824e-01 (1.6072e-01)	Acc@1  90.00 ( 94.28)	Acc@5 100.00 ( 99.94)
## e[40] optimizer.zero_grad (sum) time: 0.2711606025695801
## e[40]       loss.backward (sum) time: 4.029371976852417
## e[40]      optimizer.step (sum) time: 1.7894504070281982
## epoch[40] training(only) time: 16.116525888442993
# Switched to evaluate mode...
Test: [  0/100]	Time  0.164 ( 0.164)	Loss 3.0482e-01 (3.0482e-01)	Acc@1  92.00 ( 92.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.024 ( 0.033)	Loss 5.4256e-01 (3.9722e-01)	Acc@1  88.00 ( 87.73)	Acc@5  99.00 ( 99.73)
Test: [ 20/100]	Time  0.020 ( 0.028)	Loss 3.0415e-01 (3.8591e-01)	Acc@1  88.00 ( 87.81)	Acc@5 100.00 ( 99.67)
Test: [ 30/100]	Time  0.018 ( 0.025)	Loss 3.9425e-01 (4.0419e-01)	Acc@1  88.00 ( 87.84)	Acc@5 100.00 ( 99.61)
Test: [ 40/100]	Time  0.021 ( 0.023)	Loss 3.1926e-01 (4.0977e-01)	Acc@1  88.00 ( 87.98)	Acc@5 100.00 ( 99.56)
Test: [ 50/100]	Time  0.023 ( 0.023)	Loss 3.1497e-01 (4.1101e-01)	Acc@1  93.00 ( 87.98)	Acc@5 100.00 ( 99.59)
Test: [ 60/100]	Time  0.021 ( 0.023)	Loss 3.9956e-01 (4.0588e-01)	Acc@1  92.00 ( 88.05)	Acc@5  99.00 ( 99.62)
Test: [ 70/100]	Time  0.017 ( 0.023)	Loss 2.6226e-01 (3.9962e-01)	Acc@1  91.00 ( 88.01)	Acc@5 100.00 ( 99.66)
Test: [ 80/100]	Time  0.023 ( 0.022)	Loss 3.6637e-01 (3.9019e-01)	Acc@1  87.00 ( 88.23)	Acc@5  99.00 ( 99.65)
Test: [ 90/100]	Time  0.021 ( 0.022)	Loss 2.6886e-01 (3.9269e-01)	Acc@1  89.00 ( 88.21)	Acc@5 100.00 ( 99.67)
 * Acc@1 88.320 Acc@5 99.690
### epoch[40] execution time: 18.471930742263794
EPOCH 41
i:   0, name:           module.stem.0.weight  changing lr from: 0.005234426044027662   to: 0.003968907966975204
i:   1, name:             module.stem.0.bias  changing lr from: 0.005645333501572674   to: 0.004325865435899644
i:   2, name:           module.stem.1.weight  changing lr from: 0.006070037821654799   to: 0.004698589558789484
i:   3, name:             module.stem.1.bias  changing lr from: 0.006507907289942610   to: 0.005086413034663916
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.006958325712136919   to: 0.005488683622030876
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.007420692346008445   to: 0.005904764157897851
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.007894421811782553   to: 0.006334032549510598
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.008378943982703085   to: 0.006775881740913463
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.008873703857502691   to: 0.007229719656312549
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.009378161416407699   to: 0.007694969122115341
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.009891791462209393   to: 0.008171067769416340
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.010414083447842899   to: 0.008657467918599226
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.010944541291827085   to: 0.009153636447630502
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.011482683182836545   to: 0.009659054645528745
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.012028041374596714   to: 0.010173218052406129
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.012580161972218680   to: 0.010695636287395994
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.013138604711017486   to: 0.011225832865700103
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.013702942728790912   to: 0.011763345005914676
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.014272762332469453   to: 0.012307723428720430
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.014847662759988160   to: 0.012858532147954738
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.015427255938171715   to: 0.013415348255017466
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.016011166237369673   to: 0.013977761697500580
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.016599030223526053   to: 0.014545375052872234
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.017190496408318195   to: 0.015117803297990319
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.017785224997953087   to: 0.015694673575166972
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.018382887641165063   to: 0.016275624955455609
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.018983167176917067   to: 0.016860308199783947
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.019585757382268931   to: 0.017448385518512018
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.020190362720837837   to: 0.018039530329950648
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.020796698092242313   to: 0.018633427018336386
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.021404488582887717   to: 0.019229770691720289
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.022013469218420664   to: 0.019828266940192490
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.022623384718149866   to: 0.020428631594830195
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.023233989251704758   to: 0.021030590487725178
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.023845046198176890   to: 0.021633879213416758
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.024456327907965189   to: 0.022238242892027971
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.025067615467524104   to: 0.022843435934376002
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.025678698467191858   to: 0.023449221809303311
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.026289374772257269   to: 0.024055372813452214
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.026899450297404294   to: 0.024661669843683572
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.027508738784657163   to: 0.025267902172320514
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.028117061584932202   to: 0.025873867225377795
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.028724247443287960   to: 0.026479370363919896
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.029330132287951585   to: 0.027084224668674595
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.029934559023185727   to: 0.027688250728012034
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.030537377326049355   to: 0.028291276429385594
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.031138443447093673   to: 0.028893136754316564
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.031737620015025177   to: 0.029493673576992743
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.032334775845357294   to: 0.030092735466537818
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.032929785753064211   to: 0.030690177492999418
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.033522530369241819   to: 0.031285861037091647
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.034112895961773519   to: 0.031879653603719783
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.034700774259991983   to: 0.032471428639305605
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.035286062283321276   to: 0.033061065352923850
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.035868662173878442   to: 0.033648448541252950
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.036448481033008011   to: 0.034233468417336044
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.037025430761718971   to: 0.034816020443142914
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.037599427904988228   to: 0.035396005165916476
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.038170393499891930   to: 0.035973328058283363
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.038738252927521484   to: 0.036547899362102412
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.039302935768638983   to: 0.037119633936021648
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.039864375663022901   to: 0.037688451106708952
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.040422510172453227   to: 0.038254274523719316
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.040977280647282704   to: 0.038817032017957664
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.041528632096538953   to: 0.039376655463693636
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.042076513061500620   to: 0.039933080644082047
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.042620875492689239   to: 0.040486247120140408
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.043161674630217195   to: 0.041036098103132836
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.043698868887431616   to: 0.041582580330308420
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.044232419737792371   to: 0.042125643943939584
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.044762291604922753   to: 0.042665242373606020
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.045288451755769968   to: 0.043201332221666937
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.045810870196813014   to: 0.043733873151865624
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.046329519573254666   to: 0.044262827781007145
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.046844375071134987   to: 0.044788161573651751
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.047355414322302884   to: 0.045309842739764128
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.047862617312183428   to: 0.045827842135259984
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.048365966290277923   to: 0.046342133165389848
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.048865445683334841   to: 0.046852691690901144
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.049361042011129903   to: 0.047359495936918974
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.049852743804793459   to: 0.047862526404485892
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.050340541527625376   to: 0.048361765784702443
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.050824427498336475   to: 0.048857198875408965
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.051304395816657668   to: 0.049348812500350933
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.051780442291257847   to: 0.049836595430769397
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.052252564369912768   to: 0.050320538309359938
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.052720761071867697   to: 0.050800633576542728
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.053185032922337699   to: 0.051276875398987953
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.053645381889090016   to: 0.051749259600341185
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.054101811321054294   to: 0.052217783594093785
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.054554325888906789   to: 0.052682446318544622
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.055002931527576029   to: 0.053143248173799812
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.055447635380618546   to: 0.053600190960758257
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.055888445746413266   to: 0.054053277822031211
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.056325372026125579   to: 0.054502513184745707
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.056758424673391698   to: 0.054947902705181385
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.057187615145675955   to: 0.055389453215192654
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.057612955857253928   to: 0.055827172670367436
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.058034460133775667   to: 0.056261070099875882
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.058452142168364342   to: 0.056691155557962752
i: 100, name:           module.conv10.weight  changing lr from: 0.058866016979206084   to: 0.057117440077038256
i: 101, name:             module.conv10.bias  changing lr from: 0.059276100368588651   to: 0.057539935622322916



# Switched to train mode...
Epoch: [41][  0/391]	Time  0.225 ( 0.225)	Data  0.181 ( 0.181)	Loss 8.3418e-02 (8.3418e-02)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [41][ 10/391]	Time  0.042 ( 0.057)	Data  0.001 ( 0.017)	Loss 2.3998e-01 (1.5615e-01)	Acc@1  92.97 ( 94.67)	Acc@5 100.00 (100.00)
Epoch: [41][ 20/391]	Time  0.039 ( 0.050)	Data  0.001 ( 0.010)	Loss 1.1092e-01 (1.4490e-01)	Acc@1  96.09 ( 94.79)	Acc@5 100.00 (100.00)
Epoch: [41][ 30/391]	Time  0.040 ( 0.047)	Data  0.001 ( 0.007)	Loss 2.4012e-01 (1.4458e-01)	Acc@1  91.41 ( 95.01)	Acc@5 100.00 (100.00)
Epoch: [41][ 40/391]	Time  0.038 ( 0.045)	Data  0.001 ( 0.005)	Loss 2.2532e-01 (1.4485e-01)	Acc@1  94.53 ( 95.03)	Acc@5  99.22 ( 99.98)
Epoch: [41][ 50/391]	Time  0.040 ( 0.044)	Data  0.001 ( 0.005)	Loss 1.5579e-01 (1.4330e-01)	Acc@1  94.53 ( 95.14)	Acc@5 100.00 ( 99.98)
Epoch: [41][ 60/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.004)	Loss 1.2311e-01 (1.4402e-01)	Acc@1  95.31 ( 95.08)	Acc@5 100.00 ( 99.97)
Epoch: [41][ 70/391]	Time  0.039 ( 0.043)	Data  0.001 ( 0.004)	Loss 1.7389e-01 (1.4567e-01)	Acc@1  93.75 ( 95.05)	Acc@5 100.00 ( 99.98)
Epoch: [41][ 80/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.003)	Loss 2.0829e-01 (1.4731e-01)	Acc@1  92.19 ( 95.04)	Acc@5 100.00 ( 99.96)
Epoch: [41][ 90/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.003)	Loss 5.4679e-02 (1.4615e-01)	Acc@1  97.66 ( 95.08)	Acc@5 100.00 ( 99.97)
Epoch: [41][100/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.003)	Loss 8.7817e-02 (1.4471e-01)	Acc@1  97.66 ( 95.16)	Acc@5 100.00 ( 99.97)
Epoch: [41][110/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.003)	Loss 1.3439e-01 (1.4388e-01)	Acc@1  95.31 ( 95.13)	Acc@5 100.00 ( 99.96)
Epoch: [41][120/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.5954e-01 (1.4475e-01)	Acc@1  93.75 ( 95.05)	Acc@5 100.00 ( 99.95)
Epoch: [41][130/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 7.4040e-02 (1.4308e-01)	Acc@1  96.88 ( 95.07)	Acc@5 100.00 ( 99.96)
Epoch: [41][140/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.1970e-01 (1.4284e-01)	Acc@1  96.09 ( 95.02)	Acc@5 100.00 ( 99.96)
Epoch: [41][150/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.3280e-01 (1.4290e-01)	Acc@1  92.97 ( 95.03)	Acc@5 100.00 ( 99.96)
Epoch: [41][160/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.6654e-01 (1.4425e-01)	Acc@1  94.53 ( 94.95)	Acc@5 100.00 ( 99.97)
Epoch: [41][170/391]	Time  0.043 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.5111e-01 (1.4435e-01)	Acc@1  94.53 ( 94.94)	Acc@5 100.00 ( 99.97)
Epoch: [41][180/391]	Time  0.043 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.6172e-01 (1.4553e-01)	Acc@1  92.19 ( 94.96)	Acc@5 100.00 ( 99.97)
Epoch: [41][190/391]	Time  0.043 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.5222e-01 (1.4623e-01)	Acc@1  95.31 ( 94.90)	Acc@5 100.00 ( 99.97)
Epoch: [41][200/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.6208e-01 (1.4670e-01)	Acc@1  95.31 ( 94.91)	Acc@5  99.22 ( 99.96)
Epoch: [41][210/391]	Time  0.043 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.8366e-01 (1.4757e-01)	Acc@1  93.75 ( 94.92)	Acc@5 100.00 ( 99.96)
Epoch: [41][220/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 7.5668e-02 (1.4730e-01)	Acc@1  97.66 ( 94.95)	Acc@5 100.00 ( 99.96)
Epoch: [41][230/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.2899e-01 (1.4716e-01)	Acc@1  93.75 ( 94.96)	Acc@5 100.00 ( 99.96)
Epoch: [41][240/391]	Time  0.045 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.0211e-01 (1.4791e-01)	Acc@1  96.09 ( 94.95)	Acc@5 100.00 ( 99.96)
Epoch: [41][250/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 3.1705e-01 (1.4882e-01)	Acc@1  90.62 ( 94.92)	Acc@5 100.00 ( 99.96)
Epoch: [41][260/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.0996e-01 (1.4922e-01)	Acc@1  96.88 ( 94.91)	Acc@5 100.00 ( 99.96)
Epoch: [41][270/391]	Time  0.037 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.1158e-01 (1.4949e-01)	Acc@1  91.41 ( 94.90)	Acc@5 100.00 ( 99.96)
Epoch: [41][280/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.7235e-01 (1.4935e-01)	Acc@1  92.97 ( 94.92)	Acc@5 100.00 ( 99.96)
Epoch: [41][290/391]	Time  0.046 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.4833e-01 (1.5010e-01)	Acc@1  89.84 ( 94.88)	Acc@5 100.00 ( 99.96)
Epoch: [41][300/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.5536e-01 (1.5046e-01)	Acc@1  95.31 ( 94.86)	Acc@5  99.22 ( 99.96)
Epoch: [41][310/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 9.6636e-02 (1.5088e-01)	Acc@1  96.88 ( 94.86)	Acc@5 100.00 ( 99.95)
Epoch: [41][320/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.3972e-01 (1.5125e-01)	Acc@1  96.09 ( 94.84)	Acc@5 100.00 ( 99.95)
Epoch: [41][330/391]	Time  0.043 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.2104e-01 (1.5185e-01)	Acc@1  92.97 ( 94.80)	Acc@5 100.00 ( 99.95)
Epoch: [41][340/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 9.8300e-02 (1.5214e-01)	Acc@1  97.66 ( 94.78)	Acc@5 100.00 ( 99.95)
Epoch: [41][350/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.8586e-01 (1.5316e-01)	Acc@1  92.97 ( 94.75)	Acc@5 100.00 ( 99.95)
Epoch: [41][360/391]	Time  0.044 ( 0.041)	Data  0.001 ( 0.001)	Loss 1.7593e-01 (1.5322e-01)	Acc@1  92.97 ( 94.75)	Acc@5 100.00 ( 99.95)
Epoch: [41][370/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.001)	Loss 1.9295e-01 (1.5324e-01)	Acc@1  93.75 ( 94.75)	Acc@5 100.00 ( 99.95)
Epoch: [41][380/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.001)	Loss 1.8010e-01 (1.5293e-01)	Acc@1  94.53 ( 94.76)	Acc@5 100.00 ( 99.95)
Epoch: [41][390/391]	Time  0.028 ( 0.041)	Data  0.001 ( 0.001)	Loss 1.6273e-01 (1.5311e-01)	Acc@1  95.00 ( 94.74)	Acc@5 100.00 ( 99.95)
## e[41] optimizer.zero_grad (sum) time: 0.2712233066558838
## e[41]       loss.backward (sum) time: 3.9624149799346924
## e[41]      optimizer.step (sum) time: 1.8330776691436768
## epoch[41] training(only) time: 16.063984632492065
# Switched to evaluate mode...
Test: [  0/100]	Time  0.175 ( 0.175)	Loss 2.0630e-01 (2.0630e-01)	Acc@1  93.00 ( 93.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.024 ( 0.036)	Loss 3.7462e-01 (3.2073e-01)	Acc@1  89.00 ( 90.36)	Acc@5 100.00 ( 99.82)
Test: [ 20/100]	Time  0.021 ( 0.029)	Loss 3.8137e-01 (3.3414e-01)	Acc@1  85.00 ( 89.67)	Acc@5 100.00 ( 99.76)
Test: [ 30/100]	Time  0.022 ( 0.026)	Loss 3.5372e-01 (3.5174e-01)	Acc@1  89.00 ( 89.58)	Acc@5  99.00 ( 99.65)
Test: [ 40/100]	Time  0.020 ( 0.024)	Loss 3.6474e-01 (3.6303e-01)	Acc@1  90.00 ( 89.61)	Acc@5  99.00 ( 99.54)
Test: [ 50/100]	Time  0.020 ( 0.024)	Loss 2.8933e-01 (3.5552e-01)	Acc@1  91.00 ( 89.88)	Acc@5 100.00 ( 99.57)
Test: [ 60/100]	Time  0.021 ( 0.023)	Loss 4.5146e-01 (3.6021e-01)	Acc@1  91.00 ( 89.62)	Acc@5 100.00 ( 99.62)
Test: [ 70/100]	Time  0.018 ( 0.023)	Loss 4.3743e-01 (3.5817e-01)	Acc@1  86.00 ( 89.61)	Acc@5 100.00 ( 99.68)
Test: [ 80/100]	Time  0.020 ( 0.022)	Loss 2.0212e-01 (3.5271e-01)	Acc@1  90.00 ( 89.54)	Acc@5 100.00 ( 99.70)
Test: [ 90/100]	Time  0.016 ( 0.022)	Loss 1.6642e-01 (3.5782e-01)	Acc@1  93.00 ( 89.43)	Acc@5 100.00 ( 99.70)
 * Acc@1 89.460 Acc@5 99.710
### epoch[41] execution time: 18.385573148727417
EPOCH 42
i:   0, name:           module.stem.0.weight  changing lr from: 0.003968907966975204   to: 0.002921910115851916
i:   1, name:             module.stem.0.bias  changing lr from: 0.004325865435899644   to: 0.003220098311632024
i:   2, name:           module.stem.1.weight  changing lr from: 0.004698589558789484   to: 0.003536053350956108
i:   3, name:             module.stem.1.bias  changing lr from: 0.005086413034663916   to: 0.003869076159056599
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.005488683622030876   to: 0.004218481971524157
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.005904764157897851   to: 0.004583600454169278
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.006334032549510598   to: 0.004963775789528468
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.006775881740913463   to: 0.005358366732373109
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.007229719656312549   to: 0.005766746636460168
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.007694969122115341   to: 0.006188303454649119
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.008171067769416340   to: 0.006622439714398692
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.008657467918599226   to: 0.007068572470550482
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.009153636447630502   to: 0.007526133237203580
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.009659054645528745   to: 0.007994567900386478
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.010173218052406129   to: 0.008473336613137029
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.010695636287395994   to: 0.008961913674511511
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.011225832865700103   to: 0.009459787393956153
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.011763345005914676   to: 0.009966459942392120
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.012307723428720430   to: 0.010481447191284861
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.012858532147954738   to: 0.011004278540893440
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.013415348255017466   to: 0.011534496738822481
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.013977761697500580   to: 0.012071657689930942
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.014545375052872234   to: 0.012615330258585661
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.015117803297990319   to: 0.013165096064185200
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.015694673575166972   to: 0.013720549270820191
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.016275624955455609   to: 0.014281296371879103
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.016860308199783947   to: 0.014846955970355576
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.017448385518512018   to: 0.015417158555561632
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.018039530329950648   to: 0.015991546276903107
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.018633427018336386   to: 0.016569772715327429
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.019229770691720289   to: 0.017151502653010971
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.019828266940192490   to: 0.017736411841812016
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.020428631594830195   to: 0.018324186770975692
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.021030590487725178   to: 0.018914524434541953
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.021633879213416758   to: 0.019507132098871650
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.022238242892027971   to: 0.020101727070673980
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.022843435934376002   to: 0.020698036465887276
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.023449221809303311   to: 0.021295796979736076
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.024055372813452214   to: 0.021894754658260209
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.024661669843683572   to: 0.022494664671585785
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.025267902172320514   to: 0.023095291089183775
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.025873867225377795   to: 0.023696406657339276
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.026479370363919896   to: 0.024297792579032619
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.027084224668674595   to: 0.024899238296414650
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.027688250728012034   to: 0.025500541276038326
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.028291276429385594   to: 0.026101506796992420
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.028893136754316564   to: 0.026701947742065649
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.029493673576992743   to: 0.027301684392055461
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.030092735466537818   to: 0.027900544223319806
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.030690177492999418   to: 0.028498361708658351
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.031285861037091647   to: 0.029094978121595907
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.031879653603719783   to: 0.029690241344130230
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.032471428639305605   to: 0.030284005677994857
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.033061065352923850   to: 0.030876131659477904
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.033648448541252950   to: 0.031466485877828729
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.034233468417336044   to: 0.032054940797274931
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.034816020443142914   to: 0.032641374582665354
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.035396005165916476   to: 0.033225670928746377
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.035973328058283363   to: 0.033807718893072783
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.036547899362102412   to: 0.034387412732547397
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.037119633936021648   to: 0.034964651743579288
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.037688451106708952   to: 0.035539340105843399
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.038254274523719316   to: 0.036111386729621130
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.038817032017957664   to: 0.036680705106696243
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.039376655463693636   to: 0.037247213164776673
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.039933080644082047   to: 0.037810833125409227
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.040486247120140408   to: 0.038371491365350910
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.041036098103132836   to: 0.038929118281357512
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.041582580330308420   to: 0.039483648158347845
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.042125643943939584   to: 0.040035019040898984
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.042665242373606020   to: 0.040583172608026845
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.043201332221666937   to: 0.041128054051203046
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.043733873151865624   to: 0.041669611955559342
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.044262827781007145   to: 0.042207798184227457
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.044788161573651751   to: 0.042742567765762851
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.045309842739764128   to: 0.043273878784598374
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.045827842135259984   to: 0.043801692274474141
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.046342133165389848   to: 0.044325972114788260
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.046852691690901144   to: 0.044846684929813523
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.047359495936918974   to: 0.045363799990723999
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.047862526404485892   to: 0.045877289120375302
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.048361765784702443   to: 0.046387126600782876
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.048857198875408965   to: 0.046893289083241557
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.049348812500350933   to: 0.047395755501030479
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.049836595430769397   to: 0.047894506984647145
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.050320538309359938   to: 0.048389526779515225
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.050800633576542728   to: 0.048880800166110107
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.051276875398987953   to: 0.049368314382447459
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.051749259600341185   to: 0.049852058548880092
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.052217783594093785   to: 0.050332023595148837
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.052682446318544622   to: 0.050808202189633916
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.053143248173799812   to: 0.051280588670753795
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.053600190960758257   to: 0.051749178980459221
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.054053277822031211   to: 0.052213970599770537
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.054502513184745707   to: 0.052674962486307486
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.054947902705181385   to: 0.053132155013761208
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.055389453215192654   to: 0.053585549913258861
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.055827172670367436   to: 0.054035150216572396
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.056261070099875882   to: 0.054480960201123169
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.056691155557962752   to: 0.054922985336735730
i: 100, name:           module.conv10.weight  changing lr from: 0.057117440077038256   to: 0.055361232234094448
i: 101, name:             module.conv10.bias  changing lr from: 0.057539935622322916   to: 0.055795708594857302



# Switched to train mode...
Epoch: [42][  0/391]	Time  0.217 ( 0.217)	Data  0.173 ( 0.173)	Loss 1.8374e-01 (1.8374e-01)	Acc@1  92.19 ( 92.19)	Acc@5 100.00 (100.00)
Epoch: [42][ 10/391]	Time  0.041 ( 0.057)	Data  0.001 ( 0.017)	Loss 1.4233e-01 (1.2291e-01)	Acc@1  95.31 ( 95.45)	Acc@5 100.00 (100.00)
Epoch: [42][ 20/391]	Time  0.041 ( 0.049)	Data  0.001 ( 0.009)	Loss 2.1701e-01 (1.2173e-01)	Acc@1  91.41 ( 95.57)	Acc@5 100.00 (100.00)
Epoch: [42][ 30/391]	Time  0.038 ( 0.046)	Data  0.001 ( 0.007)	Loss 1.5526e-01 (1.1878e-01)	Acc@1  94.53 ( 95.74)	Acc@5 100.00 (100.00)
Epoch: [42][ 40/391]	Time  0.044 ( 0.045)	Data  0.001 ( 0.005)	Loss 1.0524e-01 (1.1684e-01)	Acc@1  94.53 ( 95.81)	Acc@5 100.00 (100.00)
Epoch: [42][ 50/391]	Time  0.040 ( 0.044)	Data  0.001 ( 0.004)	Loss 1.6232e-01 (1.1928e-01)	Acc@1  95.31 ( 95.83)	Acc@5 100.00 ( 99.98)
Epoch: [42][ 60/391]	Time  0.037 ( 0.044)	Data  0.001 ( 0.004)	Loss 7.8295e-02 (1.2067e-01)	Acc@1  98.44 ( 95.76)	Acc@5 100.00 ( 99.99)
Epoch: [42][ 70/391]	Time  0.037 ( 0.043)	Data  0.001 ( 0.003)	Loss 1.4942e-01 (1.2274e-01)	Acc@1  94.53 ( 95.75)	Acc@5 100.00 ( 99.98)
Epoch: [42][ 80/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.003)	Loss 9.6776e-02 (1.2293e-01)	Acc@1  95.31 ( 95.72)	Acc@5 100.00 ( 99.97)
Epoch: [42][ 90/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.003)	Loss 1.1773e-01 (1.2322e-01)	Acc@1  96.09 ( 95.64)	Acc@5 100.00 ( 99.97)
Epoch: [42][100/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.003)	Loss 7.9188e-02 (1.2071e-01)	Acc@1  96.88 ( 95.75)	Acc@5 100.00 ( 99.97)
Epoch: [42][110/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.003)	Loss 2.3437e-01 (1.2460e-01)	Acc@1  91.41 ( 95.60)	Acc@5  99.22 ( 99.96)
Epoch: [42][120/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.7388e-01 (1.2745e-01)	Acc@1  93.75 ( 95.45)	Acc@5 100.00 ( 99.96)
Epoch: [42][130/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.9949e-01 (1.2899e-01)	Acc@1  91.41 ( 95.43)	Acc@5 100.00 ( 99.95)
Epoch: [42][140/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 8.6405e-02 (1.2924e-01)	Acc@1  96.09 ( 95.41)	Acc@5 100.00 ( 99.96)
Epoch: [42][150/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.0821e-01 (1.2845e-01)	Acc@1  95.31 ( 95.46)	Acc@5 100.00 ( 99.95)
Epoch: [42][160/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.5008e-01 (1.2876e-01)	Acc@1  93.75 ( 95.42)	Acc@5 100.00 ( 99.96)
Epoch: [42][170/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 8.7939e-02 (1.2990e-01)	Acc@1  97.66 ( 95.38)	Acc@5 100.00 ( 99.96)
Epoch: [42][180/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.6857e-01 (1.3210e-01)	Acc@1  94.53 ( 95.33)	Acc@5 100.00 ( 99.95)
Epoch: [42][190/391]	Time  0.040 ( 0.041)	Data  0.002 ( 0.002)	Loss 1.1762e-01 (1.3229e-01)	Acc@1  96.09 ( 95.31)	Acc@5 100.00 ( 99.96)
Epoch: [42][200/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.2549e-01 (1.3173e-01)	Acc@1  96.88 ( 95.34)	Acc@5 100.00 ( 99.95)
Epoch: [42][210/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.4885e-01 (1.3319e-01)	Acc@1  92.97 ( 95.29)	Acc@5 100.00 ( 99.96)
Epoch: [42][220/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 8.8803e-02 (1.3257e-01)	Acc@1  96.88 ( 95.30)	Acc@5 100.00 ( 99.96)
Epoch: [42][230/391]	Time  0.043 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.0143e-01 (1.3323e-01)	Acc@1  95.31 ( 95.28)	Acc@5 100.00 ( 99.95)
Epoch: [42][240/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.5882e-01 (1.3382e-01)	Acc@1  94.53 ( 95.25)	Acc@5 100.00 ( 99.95)
Epoch: [42][250/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 9.1219e-02 (1.3317e-01)	Acc@1  96.88 ( 95.29)	Acc@5 100.00 ( 99.96)
Epoch: [42][260/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.6100e-01 (1.3432e-01)	Acc@1  94.53 ( 95.24)	Acc@5 100.00 ( 99.96)
Epoch: [42][270/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.9969e-01 (1.3397e-01)	Acc@1  92.97 ( 95.27)	Acc@5 100.00 ( 99.96)
Epoch: [42][280/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.4986e-01 (1.3446e-01)	Acc@1  94.53 ( 95.24)	Acc@5 100.00 ( 99.96)
Epoch: [42][290/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.7450e-01 (1.3554e-01)	Acc@1  93.75 ( 95.19)	Acc@5 100.00 ( 99.95)
Epoch: [42][300/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 8.6610e-02 (1.3563e-01)	Acc@1  96.88 ( 95.20)	Acc@5 100.00 ( 99.95)
Epoch: [42][310/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.7508e-01 (1.3689e-01)	Acc@1  92.97 ( 95.17)	Acc@5 100.00 ( 99.95)
Epoch: [42][320/391]	Time  0.043 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.9160e-01 (1.3736e-01)	Acc@1  95.31 ( 95.18)	Acc@5 100.00 ( 99.95)
Epoch: [42][330/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.3221e-01 (1.3743e-01)	Acc@1  96.09 ( 95.16)	Acc@5 100.00 ( 99.96)
Epoch: [42][340/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.4773e-01 (1.3744e-01)	Acc@1  93.75 ( 95.15)	Acc@5 100.00 ( 99.96)
Epoch: [42][350/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.001)	Loss 1.5500e-01 (1.3807e-01)	Acc@1  92.97 ( 95.12)	Acc@5 100.00 ( 99.96)
Epoch: [42][360/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.001)	Loss 1.6222e-01 (1.3798e-01)	Acc@1  91.41 ( 95.13)	Acc@5 100.00 ( 99.96)
Epoch: [42][370/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.001)	Loss 2.3233e-01 (1.3804e-01)	Acc@1  89.84 ( 95.12)	Acc@5  99.22 ( 99.96)
Epoch: [42][380/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.001)	Loss 1.7494e-01 (1.3802e-01)	Acc@1  94.53 ( 95.14)	Acc@5 100.00 ( 99.95)
Epoch: [42][390/391]	Time  0.028 ( 0.041)	Data  0.001 ( 0.001)	Loss 3.7574e-01 (1.3904e-01)	Acc@1  90.00 ( 95.13)	Acc@5 100.00 ( 99.95)
## e[42] optimizer.zero_grad (sum) time: 0.27015209197998047
## e[42]       loss.backward (sum) time: 3.9830567836761475
## e[42]      optimizer.step (sum) time: 1.7709863185882568
## epoch[42] training(only) time: 16.09749126434326
# Switched to evaluate mode...
Test: [  0/100]	Time  0.171 ( 0.171)	Loss 2.4700e-01 (2.4700e-01)	Acc@1  93.00 ( 93.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.022 ( 0.034)	Loss 4.9996e-01 (3.3149e-01)	Acc@1  89.00 ( 91.00)	Acc@5 100.00 ( 99.91)
Test: [ 20/100]	Time  0.023 ( 0.028)	Loss 2.8512e-01 (3.6014e-01)	Acc@1  87.00 ( 89.95)	Acc@5 100.00 ( 99.62)
Test: [ 30/100]	Time  0.021 ( 0.026)	Loss 3.1513e-01 (3.7673e-01)	Acc@1  88.00 ( 89.61)	Acc@5  97.00 ( 99.48)
Test: [ 40/100]	Time  0.022 ( 0.025)	Loss 3.2037e-01 (3.8214e-01)	Acc@1  90.00 ( 89.59)	Acc@5  99.00 ( 99.46)
Test: [ 50/100]	Time  0.023 ( 0.024)	Loss 2.8966e-01 (3.7641e-01)	Acc@1  93.00 ( 89.78)	Acc@5 100.00 ( 99.51)
Test: [ 60/100]	Time  0.020 ( 0.024)	Loss 4.1125e-01 (3.7391e-01)	Acc@1  88.00 ( 89.62)	Acc@5  98.00 ( 99.54)
Test: [ 70/100]	Time  0.024 ( 0.024)	Loss 3.4506e-01 (3.6849e-01)	Acc@1  84.00 ( 89.55)	Acc@5 100.00 ( 99.61)
Test: [ 80/100]	Time  0.020 ( 0.023)	Loss 2.7251e-01 (3.6679e-01)	Acc@1  89.00 ( 89.49)	Acc@5 100.00 ( 99.63)
Test: [ 90/100]	Time  0.018 ( 0.023)	Loss 2.9481e-01 (3.6741e-01)	Acc@1  92.00 ( 89.57)	Acc@5 100.00 ( 99.62)
 * Acc@1 89.460 Acc@5 99.620
### epoch[42] execution time: 18.453096389770508
EPOCH 43
i:   0, name:           module.stem.0.weight  changing lr from: 0.002921910115851916   to: 0.002098297149271610
i:   1, name:             module.stem.0.bias  changing lr from: 0.003220098311632024   to: 0.002333094964484710
i:   2, name:           module.stem.1.weight  changing lr from: 0.003536053350956108   to: 0.002587674563812297
i:   3, name:             module.stem.1.bias  changing lr from: 0.003869076159056599   to: 0.002861309620877366
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.004218481971524157   to: 0.003153287059193027
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.004583600454169278   to: 0.003462907286975191
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.004963775789528468   to: 0.003789484392097053
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.005358366732373109   to: 0.004132346299805383
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.005766746636460168   to: 0.004490834895694761
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.006188303454649119   to: 0.004864306116315714
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.006622439714398692   to: 0.005252130009676380
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.007068572470550482   to: 0.005653690767784696
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.007526133237203580   to: 0.006068386733268882
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.007994567900386478   to: 0.006495630382009681
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.008473336613137029   to: 0.006934848283615996
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.008961913674511511   to: 0.007385481041478670
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.009459787393956153   to: 0.007846983214043025
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.009966459942392120   to: 0.008318823218851679
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.010481447191284861   to: 0.008800483220821852
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.011004278540893440   to: 0.009291459006139775
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.011534496738822481   to: 0.009791259843074777
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.012071657689930942   to: 0.010299408330940840
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.012615330258585661   to: 0.010815440238360025
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.013165096064185200   to: 0.011338904331914063
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.013720549270820191   to: 0.011869362196203936
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.014281296371879103   to: 0.012406388046274371
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.014846955970355576   to: 0.012949568533300863
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.015417158555561632   to: 0.013498502544379315
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.015991546276903107   to: 0.014052800997204427
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.016569772715327429   to: 0.014612086630371425
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.017151502653010971   to: 0.015175993789986804
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.017736411841812016   to: 0.015744168213227765
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.018324186770975692   to: 0.016316266809444903
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.018914524434541953   to: 0.016891957439362382
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.019507132098871650   to: 0.017470918692889359
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.020101727070673980   to: 0.018052839666019227
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.020698036465887276   to: 0.018637419737258489
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.021295796979736076   to: 0.019224368343992555
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.021894754658260209   to: 0.019813404759165477
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.022494664671585785   to: 0.020404257868619671
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.023095291089183775   to: 0.020996665949414746
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.023696406657339276   to: 0.021590376449417088
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.024297792579032619   to: 0.022185145768427506
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.024899238296414650   to: 0.022780739041091048
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.025500541276038326   to: 0.023376929921809959
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.026101506796992420   to: 0.023973500371861772
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.026701947742065649   to: 0.024570240448903054
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.027301684392055461   to: 0.025166948099023246
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.027900544223319806   to: 0.025763428951493941
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.028498361708658351   to: 0.026359496116344461
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.029094978121595907   to: 0.026954969984878809
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.029690241344130230   to: 0.027549678033235315
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.030284005677994857   to: 0.028143454629077282
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.030876131659477904   to: 0.028736140841490756
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.031466485877828729   to: 0.029327584254154028
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.032054940797274931   to: 0.029917638781832859
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.032641374582665354   to: 0.030506164490246259
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.033225670928746377   to: 0.031093027419337241
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.033807718893072783   to: 0.031678099409976082
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.034387412732547397   to: 0.032261257934114065
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.034964651743579288   to: 0.032842385928400324
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.035539340105843399   to: 0.033421371631265684
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.036111386729621130   to: 0.033998108423473082
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.036680705106696243   to: 0.034572494672126995
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.037247213164776673   to: 0.035144433578130109
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.037810833125409227   to: 0.035713833027070228
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.038371491365350910   to: 0.036280605443515912
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.038929118281357512   to: 0.036844667648695616
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.039483648158347845   to: 0.037405940721531618
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.040035019040898984   to: 0.037964349862996030
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.040583172608026845   to: 0.038519824263754318
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.041128054051203046   to: 0.039072296975057742
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.041669611955559342   to: 0.039621704782845095
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.042207798184227457   to: 0.040167988085010757
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.042742567765762851   to: 0.040711090771795272
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.043273878784598374   to: 0.041250960109252055
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.043801692274474141   to: 0.041787546625742952
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.044325972114788260   to: 0.042320804001413886
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.044846684929813523   to: 0.042850688960600930
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.045363799990723999   to: 0.043377161167116075
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.045877289120375302   to: 0.043900183122360853
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.046387126600782876   to: 0.044419720066216625
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.046893289083241557   to: 0.044935739880658049
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.047395755501030479   to: 0.045448212996037581
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.047894506984647145   to: 0.045957112299987453
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.048389526779515225   to: 0.046462413048886382
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.048880800166110107   to: 0.046964092781837198
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.049368314382447459   to: 0.047462131237102856
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.049852058548880092   to: 0.047956510270947363
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.050332023595148837   to: 0.048447213778829122
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.050808202189633916   to: 0.048934227618894016
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.051280588670753795   to: 0.049417539537716368
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.051749178980459221   to: 0.049897139098235892
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.052213970599770537   to: 0.050373017609839456
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.052674962486307486   to: 0.050845168060537162
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.053132155013761208   to: 0.051313585051182289
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.053585549913258861   to: 0.051778264731685876
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.054035150216572396   to: 0.052239204739177064
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.054480960201123169   to: 0.052696404138060586
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.054922985336735730   to: 0.053149863361924447
i: 100, name:           module.conv10.weight  changing lr from: 0.055361232234094448   to: 0.053599584157250635
i: 101, name:             module.conv10.bias  changing lr from: 0.055795708594857302   to: 0.054045569528882891



# Switched to train mode...
Epoch: [43][  0/391]	Time  0.214 ( 0.214)	Data  0.170 ( 0.170)	Loss 1.0623e-01 (1.0623e-01)	Acc@1  97.66 ( 97.66)	Acc@5 100.00 (100.00)
Epoch: [43][ 10/391]	Time  0.040 ( 0.056)	Data  0.001 ( 0.016)	Loss 1.4791e-01 (1.4805e-01)	Acc@1  95.31 ( 94.82)	Acc@5 100.00 ( 99.93)
Epoch: [43][ 20/391]	Time  0.039 ( 0.049)	Data  0.001 ( 0.009)	Loss 1.2233e-01 (1.4890e-01)	Acc@1  96.09 ( 94.75)	Acc@5 100.00 ( 99.96)
Epoch: [43][ 30/391]	Time  0.039 ( 0.046)	Data  0.001 ( 0.006)	Loss 1.1289e-01 (1.4745e-01)	Acc@1  95.31 ( 94.68)	Acc@5 100.00 ( 99.97)
Epoch: [43][ 40/391]	Time  0.039 ( 0.045)	Data  0.001 ( 0.005)	Loss 1.1924e-01 (1.3982e-01)	Acc@1  95.31 ( 95.01)	Acc@5 100.00 ( 99.98)
Epoch: [43][ 50/391]	Time  0.038 ( 0.043)	Data  0.001 ( 0.004)	Loss 1.5562e-01 (1.3800e-01)	Acc@1  95.31 ( 95.13)	Acc@5 100.00 ( 99.98)
Epoch: [43][ 60/391]	Time  0.039 ( 0.043)	Data  0.001 ( 0.004)	Loss 1.7705e-01 (1.3907e-01)	Acc@1  92.97 ( 94.98)	Acc@5 100.00 ( 99.99)
Epoch: [43][ 70/391]	Time  0.039 ( 0.042)	Data  0.002 ( 0.003)	Loss 1.4327e-01 (1.3822e-01)	Acc@1  95.31 ( 95.06)	Acc@5 100.00 ( 99.99)
Epoch: [43][ 80/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.003)	Loss 2.1889e-01 (1.3711e-01)	Acc@1  92.97 ( 95.10)	Acc@5 100.00 ( 99.99)
Epoch: [43][ 90/391]	Time  0.035 ( 0.042)	Data  0.001 ( 0.003)	Loss 1.6658e-01 (1.3657e-01)	Acc@1  92.97 ( 95.12)	Acc@5 100.00 ( 99.98)
Epoch: [43][100/391]	Time  0.036 ( 0.042)	Data  0.001 ( 0.003)	Loss 1.2074e-01 (1.3727e-01)	Acc@1  94.53 ( 95.09)	Acc@5 100.00 ( 99.96)
Epoch: [43][110/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.003)	Loss 8.3507e-02 (1.3682e-01)	Acc@1  96.88 ( 95.08)	Acc@5 100.00 ( 99.96)
Epoch: [43][120/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.2838e-01 (1.3600e-01)	Acc@1  95.31 ( 95.14)	Acc@5 100.00 ( 99.96)
Epoch: [43][130/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.002)	Loss 6.8015e-02 (1.3537e-01)	Acc@1  97.66 ( 95.18)	Acc@5 100.00 ( 99.95)
Epoch: [43][140/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.9684e-01 (1.3559e-01)	Acc@1  93.75 ( 95.17)	Acc@5 100.00 ( 99.96)
Epoch: [43][150/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 7.5143e-02 (1.3518e-01)	Acc@1  96.88 ( 95.20)	Acc@5 100.00 ( 99.95)
Epoch: [43][160/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.0828e-01 (1.3511e-01)	Acc@1  96.09 ( 95.21)	Acc@5 100.00 ( 99.96)
Epoch: [43][170/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 9.4244e-02 (1.3664e-01)	Acc@1  96.88 ( 95.15)	Acc@5 100.00 ( 99.96)
Epoch: [43][180/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.2909e-01 (1.3705e-01)	Acc@1  95.31 ( 95.19)	Acc@5 100.00 ( 99.94)
Epoch: [43][190/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.1079e-01 (1.3676e-01)	Acc@1  94.53 ( 95.20)	Acc@5 100.00 ( 99.95)
Epoch: [43][200/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.5072e-01 (1.3584e-01)	Acc@1  94.53 ( 95.26)	Acc@5 100.00 ( 99.95)
Epoch: [43][210/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.1850e-01 (1.3689e-01)	Acc@1  92.97 ( 95.23)	Acc@5 100.00 ( 99.94)
Epoch: [43][220/391]	Time  0.045 ( 0.041)	Data  0.001 ( 0.002)	Loss 7.9829e-02 (1.3663e-01)	Acc@1  97.66 ( 95.23)	Acc@5 100.00 ( 99.95)
Epoch: [43][230/391]	Time  0.044 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.8353e-01 (1.3719e-01)	Acc@1  92.19 ( 95.20)	Acc@5 100.00 ( 99.95)
Epoch: [43][240/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.2492e-01 (1.3687e-01)	Acc@1  95.31 ( 95.24)	Acc@5 100.00 ( 99.94)
Epoch: [43][250/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.0736e-01 (1.3690e-01)	Acc@1  96.09 ( 95.23)	Acc@5 100.00 ( 99.94)
Epoch: [43][260/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.3513e-01 (1.3630e-01)	Acc@1  95.31 ( 95.26)	Acc@5 100.00 ( 99.94)
Epoch: [43][270/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.3357e-01 (1.3645e-01)	Acc@1  96.09 ( 95.26)	Acc@5 100.00 ( 99.95)
Epoch: [43][280/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.0192e-01 (1.3704e-01)	Acc@1  92.97 ( 95.24)	Acc@5 100.00 ( 99.95)
Epoch: [43][290/391]	Time  0.042 ( 0.041)	Data  0.002 ( 0.002)	Loss 1.4415e-01 (1.3685e-01)	Acc@1  96.09 ( 95.23)	Acc@5 100.00 ( 99.95)
Epoch: [43][300/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.0144e-01 (1.3705e-01)	Acc@1  96.09 ( 95.20)	Acc@5 100.00 ( 99.95)
Epoch: [43][310/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.0806e-01 (1.3688e-01)	Acc@1  96.88 ( 95.21)	Acc@5 100.00 ( 99.95)
Epoch: [43][320/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.3315e-01 (1.3739e-01)	Acc@1  96.09 ( 95.20)	Acc@5 100.00 ( 99.95)
Epoch: [43][330/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.7895e-01 (1.3751e-01)	Acc@1  95.31 ( 95.19)	Acc@5 100.00 ( 99.94)
Epoch: [43][340/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.1538e-01 (1.3714e-01)	Acc@1  96.09 ( 95.21)	Acc@5 100.00 ( 99.95)
Epoch: [43][350/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.6448e-01 (1.3713e-01)	Acc@1  92.97 ( 95.20)	Acc@5 100.00 ( 99.95)
Epoch: [43][360/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 9.4889e-02 (1.3696e-01)	Acc@1  96.88 ( 95.20)	Acc@5 100.00 ( 99.95)
Epoch: [43][370/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.6929e-01 (1.3754e-01)	Acc@1  90.62 ( 95.19)	Acc@5 100.00 ( 99.95)
Epoch: [43][380/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.001)	Loss 1.2723e-01 (1.3708e-01)	Acc@1  94.53 ( 95.20)	Acc@5 100.00 ( 99.95)
Epoch: [43][390/391]	Time  0.028 ( 0.041)	Data  0.001 ( 0.001)	Loss 2.8722e-01 (1.3717e-01)	Acc@1  92.50 ( 95.20)	Acc@5 100.00 ( 99.95)
## e[43] optimizer.zero_grad (sum) time: 0.2704794406890869
## e[43]       loss.backward (sum) time: 3.9991302490234375
## e[43]      optimizer.step (sum) time: 1.789609432220459
## epoch[43] training(only) time: 16.11518621444702
# Switched to evaluate mode...
Test: [  0/100]	Time  0.164 ( 0.164)	Loss 1.8830e-01 (1.8830e-01)	Acc@1  94.00 ( 94.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.019 ( 0.033)	Loss 4.0342e-01 (3.6670e-01)	Acc@1  90.00 ( 90.18)	Acc@5 100.00 ( 99.73)
Test: [ 20/100]	Time  0.021 ( 0.027)	Loss 3.8666e-01 (3.7679e-01)	Acc@1  86.00 ( 89.57)	Acc@5 100.00 ( 99.62)
Test: [ 30/100]	Time  0.018 ( 0.025)	Loss 4.8870e-01 (3.9379e-01)	Acc@1  85.00 ( 89.35)	Acc@5  98.00 ( 99.52)
Test: [ 40/100]	Time  0.024 ( 0.024)	Loss 3.8956e-01 (3.9908e-01)	Acc@1  89.00 ( 89.46)	Acc@5 100.00 ( 99.44)
Test: [ 50/100]	Time  0.019 ( 0.023)	Loss 2.4811e-01 (3.9389e-01)	Acc@1  92.00 ( 89.49)	Acc@5 100.00 ( 99.49)
Test: [ 60/100]	Time  0.018 ( 0.023)	Loss 4.5430e-01 (3.9357e-01)	Acc@1  90.00 ( 89.41)	Acc@5  98.00 ( 99.51)
Test: [ 70/100]	Time  0.021 ( 0.022)	Loss 3.8011e-01 (3.8843e-01)	Acc@1  90.00 ( 89.35)	Acc@5  99.00 ( 99.52)
Test: [ 80/100]	Time  0.021 ( 0.022)	Loss 2.5846e-01 (3.8278e-01)	Acc@1  92.00 ( 89.41)	Acc@5 100.00 ( 99.53)
Test: [ 90/100]	Time  0.022 ( 0.022)	Loss 1.3650e-01 (3.8518e-01)	Acc@1  95.00 ( 89.35)	Acc@5 100.00 ( 99.55)
 * Acc@1 89.450 Acc@5 99.570
### epoch[43] execution time: 18.456583738327026
EPOCH 44
i:   0, name:           module.stem.0.weight  changing lr from: 0.002098297149271610   to: 0.001501895814259612
i:   1, name:             module.stem.0.bias  changing lr from: 0.002333094964484710   to: 0.001668916604206632
i:   2, name:           module.stem.1.weight  changing lr from: 0.002587674563812297   to: 0.001857732284312052
i:   3, name:             module.stem.1.bias  changing lr from: 0.002861309620877366   to: 0.002067594511440428
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.003153287059193027   to: 0.002297766799711914
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.003462907286975191   to: 0.002547524884396939
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.003789484392097053   to: 0.002816157039088812
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.004132346299805383   to: 0.003102964349027409
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.004490834895694761   to: 0.003407260943320477
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.004864306116315714   to: 0.003728374188685634
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.005252130009676380   to: 0.004065644847215921
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.005653690767784696   to: 0.004418427200554508
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.006068386733268882   to: 0.004786089142750576
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.006495630382009681   to: 0.005168012243958541
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.006934848283615996   to: 0.005563591787035454
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.007385481041478670   to: 0.005972236778989342
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.007846983214043025   to: 0.006393369939130588
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.008318823218851679   to: 0.006826427665683737
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.008800483220821852   to: 0.007270859982523630
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.009291459006139775   to: 0.007726130467611835
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.009791259843074777   to: 0.008191716164623108
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.010299408330940840   to: 0.008667107479170655
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.010815440238360025   to: 0.009151808060959353
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.011338904331914063   to: 0.009645334673121581
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.011869362196203936   to: 0.010147217049917934
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.012406388046274371   to: 0.010656997743916152
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.012949568533300863   to: 0.011174231963695835
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.013498502544379315   to: 0.011698487403063972
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.014052800997204427   to: 0.012229344062705604
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.014612086630371425   to: 0.012766394065137597
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.015175993789986804   to: 0.013309241463778522
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.015744168213227765   to: 0.013857502046896446
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.016316266809444903   to: 0.014410803137146287
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.016891957439362382   to: 0.014968783387362416
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.017470918692889359   to: 0.015531092573227451
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.018052839666019227   to: 0.016097391383395859
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.018637419737258489   to: 0.016667351207610991
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.019224368343992555   to: 0.017240653923316841
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.019813404759165477   to: 0.017816991681228769
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.020404257868619671   to: 0.018396066690294928
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.020996665949414746   to: 0.018977591002446611
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.021590376449417088   to: 0.019561286297506537
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.022185145768427506   to: 0.020146883668594351
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.022780739041091048   to: 0.020734123408342887
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.023376929921809959   to: 0.021322754796211596
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.023973500371861772   to: 0.021912535887161150
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.024570240448903054   to: 0.022503233301929229
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.025166948099023246   to: 0.023094622019127410
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.025763428951493941   to: 0.023686485169357716
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.026359496116344461   to: 0.024278613831529919
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.026954969984878809   to: 0.024870806831542025
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.027549678033235315   to: 0.025462870543470312
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.028143454629077282   to: 0.026054618693399447
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.028736140841490756   to: 0.026645872166009291
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.029327584254154028   to: 0.027236458814020193
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.029917638781832859   to: 0.027826213270587232
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.030506164490246259   to: 0.028414976764721125
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.031093027419337241   to: 0.029002596939802519
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.031678099409976082   to: 0.029588927675246547
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.032261257934114065   to: 0.030173828911364012
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.032842385928400324   to: 0.030757166477457992
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.033421371631265684   to: 0.031338811923184690
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.033998108423473082   to: 0.031918642353201035
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.034572494672126995   to: 0.032496540265113748
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.035144433578130109   to: 0.033072393390738045
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.035713833027070228   to: 0.033646094540668359
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.036280605443515912   to: 0.034217541452157364
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.036844667648695616   to: 0.034786636640294744
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.037405940721531618   to: 0.035353287252472630
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.037964349862996030   to: 0.035917404926119521
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.038519824263754318   to: 0.036478905649681530
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.039072296975057742   to: 0.037037709626825045
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.039621704782845095   to: 0.037593741143832980
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.040167988085010757   to: 0.038146928440162202
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.040711090771795272   to: 0.038697203582128567
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.041250960109252055   to: 0.039244502339682352
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.041787546625742952   to: 0.039788764066235632
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.042320804001413886   to: 0.040329931581500174
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.042850688960600930   to: 0.040867951057294225
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.043377161167116075   to: 0.041402771906273284
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.043900183122360853   to: 0.041934346673539950
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.044419720066216625   to: 0.042462630931086397
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.044935739880658049   to: 0.042987583175021805
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.045448212996037581   to: 0.043509164725536759
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.045957112299987453   to: 0.044027339629555219
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.046462413048886382   to: 0.044542074566025283
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.046964092781837198   to: 0.045053338753798237
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.047462131237102856   to: 0.045561103862046086
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.047956510270947363   to: 0.046065343923167128
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.048447213778829122   to: 0.046566035248129092
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.048934227618894016   to: 0.047063156344199428
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.049417539537716368   to: 0.047556687835012428
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.049897139098235892   to: 0.048046612382922946
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.050373017609839456   to: 0.048532914613596718
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.050845168060537162   to: 0.049015581042787790
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.051313585051182289   to: 0.049494600005253395
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.051778264731685876   to: 0.049969961585757797
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.052239204739177064   to: 0.050441657552116465
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.052696404138060586   to: 0.050909681290232295
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.053149863361924447   to: 0.051374027741077188
i: 100, name:           module.conv10.weight  changing lr from: 0.053599584157250635   to: 0.051834693339571386
i: 101, name:             module.conv10.bias  changing lr from: 0.054045569528882891   to: 0.052291675955314913



# Switched to train mode...
Epoch: [44][  0/391]	Time  0.213 ( 0.213)	Data  0.171 ( 0.171)	Loss 1.0438e-01 (1.0438e-01)	Acc@1  96.09 ( 96.09)	Acc@5 100.00 (100.00)
Epoch: [44][ 10/391]	Time  0.042 ( 0.057)	Data  0.001 ( 0.016)	Loss 9.9070e-02 (1.1642e-01)	Acc@1  96.88 ( 95.60)	Acc@5 100.00 (100.00)
Epoch: [44][ 20/391]	Time  0.038 ( 0.049)	Data  0.001 ( 0.009)	Loss 1.7925e-01 (1.2505e-01)	Acc@1  93.75 ( 95.42)	Acc@5 100.00 (100.00)
Epoch: [44][ 30/391]	Time  0.039 ( 0.046)	Data  0.001 ( 0.006)	Loss 1.4733e-01 (1.2546e-01)	Acc@1  96.09 ( 95.56)	Acc@5 100.00 (100.00)
Epoch: [44][ 40/391]	Time  0.043 ( 0.045)	Data  0.001 ( 0.005)	Loss 1.5893e-01 (1.2264e-01)	Acc@1  94.53 ( 95.66)	Acc@5 100.00 (100.00)
Epoch: [44][ 50/391]	Time  0.042 ( 0.044)	Data  0.001 ( 0.004)	Loss 1.6785e-01 (1.2571e-01)	Acc@1  94.53 ( 95.60)	Acc@5 100.00 (100.00)
Epoch: [44][ 60/391]	Time  0.039 ( 0.044)	Data  0.001 ( 0.004)	Loss 1.3608e-01 (1.2464e-01)	Acc@1  94.53 ( 95.62)	Acc@5 100.00 (100.00)
Epoch: [44][ 70/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.003)	Loss 1.2830e-01 (1.2499e-01)	Acc@1  93.75 ( 95.66)	Acc@5 100.00 (100.00)
Epoch: [44][ 80/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.003)	Loss 6.5551e-02 (1.2491e-01)	Acc@1  97.66 ( 95.68)	Acc@5 100.00 (100.00)
Epoch: [44][ 90/391]	Time  0.043 ( 0.042)	Data  0.001 ( 0.003)	Loss 1.4678e-01 (1.2541e-01)	Acc@1  95.31 ( 95.72)	Acc@5 100.00 ( 99.99)
Epoch: [44][100/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.003)	Loss 1.5860e-01 (1.2604e-01)	Acc@1  93.75 ( 95.68)	Acc@5 100.00 ( 99.99)
Epoch: [44][110/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.003)	Loss 1.0642e-01 (1.2490e-01)	Acc@1  96.09 ( 95.71)	Acc@5 100.00 ( 99.99)
Epoch: [44][120/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.1841e-01 (1.2422e-01)	Acc@1  94.53 ( 95.74)	Acc@5 100.00 ( 99.99)
Epoch: [44][130/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.2700e-01 (1.2458e-01)	Acc@1  96.09 ( 95.69)	Acc@5 100.00 ( 99.99)
Epoch: [44][140/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.0672e-01 (1.2433e-01)	Acc@1  95.31 ( 95.68)	Acc@5 100.00 ( 99.99)
Epoch: [44][150/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.0243e-01 (1.2521e-01)	Acc@1  96.88 ( 95.65)	Acc@5 100.00 ( 99.99)
Epoch: [44][160/391]	Time  0.044 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.4897e-01 (1.2550e-01)	Acc@1  94.53 ( 95.62)	Acc@5 100.00 ( 99.99)
Epoch: [44][170/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.0897e-01 (1.2494e-01)	Acc@1  96.09 ( 95.66)	Acc@5 100.00 ( 99.99)
Epoch: [44][180/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.2620e-01 (1.2519e-01)	Acc@1  94.53 ( 95.60)	Acc@5 100.00 ( 99.99)
Epoch: [44][190/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.2981e-01 (1.2523e-01)	Acc@1  95.31 ( 95.61)	Acc@5 100.00 ( 99.99)
Epoch: [44][200/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.3748e-01 (1.2577e-01)	Acc@1  96.09 ( 95.60)	Acc@5 100.00 ( 99.98)
Epoch: [44][210/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.1550e-01 (1.2597e-01)	Acc@1  96.09 ( 95.59)	Acc@5 100.00 ( 99.98)
Epoch: [44][220/391]	Time  0.045 ( 0.041)	Data  0.001 ( 0.002)	Loss 9.5750e-02 (1.2687e-01)	Acc@1  96.88 ( 95.58)	Acc@5 100.00 ( 99.98)
Epoch: [44][230/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.3043e-01 (1.2672e-01)	Acc@1  95.31 ( 95.60)	Acc@5 100.00 ( 99.98)
Epoch: [44][240/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.4159e-01 (1.2798e-01)	Acc@1  95.31 ( 95.59)	Acc@5 100.00 ( 99.98)
Epoch: [44][250/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 7.5817e-02 (1.2748e-01)	Acc@1  96.88 ( 95.61)	Acc@5 100.00 ( 99.98)
Epoch: [44][260/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.4093e-01 (1.2712e-01)	Acc@1  95.31 ( 95.62)	Acc@5 100.00 ( 99.98)
Epoch: [44][270/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.5304e-01 (1.2819e-01)	Acc@1  94.53 ( 95.60)	Acc@5 100.00 ( 99.98)
Epoch: [44][280/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.0418e-01 (1.2814e-01)	Acc@1  96.09 ( 95.61)	Acc@5 100.00 ( 99.98)
Epoch: [44][290/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 7.1101e-02 (1.2830e-01)	Acc@1  96.88 ( 95.60)	Acc@5 100.00 ( 99.98)
Epoch: [44][300/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.5632e-01 (1.2810e-01)	Acc@1  92.97 ( 95.60)	Acc@5 100.00 ( 99.97)
Epoch: [44][310/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.2494e-01 (1.2773e-01)	Acc@1  96.88 ( 95.62)	Acc@5 100.00 ( 99.97)
Epoch: [44][320/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.4172e-01 (1.2810e-01)	Acc@1  96.88 ( 95.59)	Acc@5 100.00 ( 99.97)
Epoch: [44][330/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.2061e-01 (1.2819e-01)	Acc@1  95.31 ( 95.59)	Acc@5 100.00 ( 99.97)
Epoch: [44][340/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.0907e-01 (1.2814e-01)	Acc@1  96.88 ( 95.59)	Acc@5 100.00 ( 99.97)
Epoch: [44][350/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 9.5975e-02 (1.2812e-01)	Acc@1  95.31 ( 95.60)	Acc@5 100.00 ( 99.97)
Epoch: [44][360/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.3385e-01 (1.2769e-01)	Acc@1  95.31 ( 95.63)	Acc@5 100.00 ( 99.97)
Epoch: [44][370/391]	Time  0.037 ( 0.041)	Data  0.001 ( 0.001)	Loss 1.0501e-01 (1.2765e-01)	Acc@1  95.31 ( 95.62)	Acc@5 100.00 ( 99.97)
Epoch: [44][380/391]	Time  0.045 ( 0.041)	Data  0.001 ( 0.001)	Loss 1.2166e-01 (1.2773e-01)	Acc@1  93.75 ( 95.60)	Acc@5 100.00 ( 99.97)
Epoch: [44][390/391]	Time  0.028 ( 0.041)	Data  0.001 ( 0.001)	Loss 1.6320e-01 (1.2793e-01)	Acc@1  91.25 ( 95.58)	Acc@5 100.00 ( 99.97)
## e[44] optimizer.zero_grad (sum) time: 0.27028799057006836
## e[44]       loss.backward (sum) time: 3.9973268508911133
## e[44]      optimizer.step (sum) time: 1.7821376323699951
## epoch[44] training(only) time: 16.137905597686768
# Switched to evaluate mode...
Test: [  0/100]	Time  0.167 ( 0.167)	Loss 1.9782e-01 (1.9782e-01)	Acc@1  91.00 ( 91.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.019 ( 0.034)	Loss 4.7312e-01 (3.5225e-01)	Acc@1  87.00 ( 89.91)	Acc@5 100.00 ( 99.82)
Test: [ 20/100]	Time  0.024 ( 0.028)	Loss 4.9250e-01 (3.5837e-01)	Acc@1  83.00 ( 89.67)	Acc@5 100.00 ( 99.62)
Test: [ 30/100]	Time  0.022 ( 0.027)	Loss 4.2496e-01 (3.8070e-01)	Acc@1  88.00 ( 89.48)	Acc@5  99.00 ( 99.55)
Test: [ 40/100]	Time  0.021 ( 0.025)	Loss 4.5218e-01 (3.9382e-01)	Acc@1  87.00 ( 89.44)	Acc@5  98.00 ( 99.49)
Test: [ 50/100]	Time  0.023 ( 0.024)	Loss 1.7258e-01 (3.8477e-01)	Acc@1  94.00 ( 89.57)	Acc@5 100.00 ( 99.47)
Test: [ 60/100]	Time  0.022 ( 0.024)	Loss 3.8183e-01 (3.7983e-01)	Acc@1  93.00 ( 89.49)	Acc@5  99.00 ( 99.51)
Test: [ 70/100]	Time  0.024 ( 0.023)	Loss 4.3426e-01 (3.7562e-01)	Acc@1  86.00 ( 89.41)	Acc@5 100.00 ( 99.58)
Test: [ 80/100]	Time  0.024 ( 0.023)	Loss 2.4930e-01 (3.7437e-01)	Acc@1  90.00 ( 89.28)	Acc@5 100.00 ( 99.60)
Test: [ 90/100]	Time  0.023 ( 0.023)	Loss 2.0672e-01 (3.7650e-01)	Acc@1  96.00 ( 89.30)	Acc@5 100.00 ( 99.59)
 * Acc@1 89.320 Acc@5 99.600
### epoch[44] execution time: 18.52062463760376
EPOCH 45
i:   0, name:           module.stem.0.weight  changing lr from: 0.001501895814259612   to: 0.001135477166065490
i:   1, name:             module.stem.0.bias  changing lr from: 0.001668916604206632   to: 0.001230604220034714
i:   2, name:           module.stem.1.weight  changing lr from: 0.001857732284312052   to: 0.001349520013457000
i:   3, name:             module.stem.1.bias  changing lr from: 0.002067594511440428   to: 0.001491460130189769
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.002297766799711914   to: 0.001655670268040987
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.002547524884396939   to: 0.001841406745697160
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.002816157039088812   to: 0.002047936955776529
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.003102964349027409   to: 0.002274539767118033
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.003407260943320477   to: 0.002520505879290179
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.003728374188685634   to: 0.002785138132179398
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.004065644847215921   to: 0.003067751773395682
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.004418427200554508   to: 0.003367674686113752
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.004786089142750576   to: 0.003684247579851251
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.005168012243958541   to: 0.004016824146572056
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.005563591787035454   to: 0.004364771184391930
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.005972236778989342   to: 0.004727468691056552
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.006393369939130588   to: 0.005104309929257327
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.006826427665683737   to: 0.005494701465750229
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.007270859982523630   to: 0.005898063186144425
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.007726130467611835   to: 0.006313828287133993
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.008191716164623108   to: 0.006741443247854566
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.008667107479170655   to: 0.007180367781959678
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.009151808060959353   to: 0.007630074771926792
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.009645334673121581   to: 0.008090050187022378
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.010147217049917934   to: 0.008559792986277437
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.010656997743916152   to: 0.009038815007750074
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.011174231963695835   to: 0.009526640845280602
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.011698487403063972   to: 0.010022807713875696
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.012229344062705604   to: 0.010526865304792882
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.012766394065137597   to: 0.011038375631333596
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.013309241463778522   to: 0.011556912866293713
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.013857502046896446   to: 0.012082063171963059
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.014410803137146287   to: 0.012613424523510674
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.014968783387362416   to: 0.013150606526541136
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.015531092573227451   to: 0.013693230229557547
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.016097391383395859   to: 0.014240927932019865
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.016667351207610991   to: 0.014793342988642367
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.017240653923316841   to: 0.015350129610531782
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.017816991681228769   to: 0.015910952663727041
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.018396066690294928   to: 0.016475487465663331
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.018977591002446611   to: 0.017043419580047094
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.019561286297506537   to: 0.017614444610593940
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.020146883668594351   to: 0.018188267994048664
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.020734123408342887   to: 0.018764604792876539
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.021322754796211596   to: 0.019343179487984891
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.021912535887161150   to: 0.019923725771807028
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.022503233301929229   to: 0.020505986342054607
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.023094622019127410   to: 0.021089712696419707
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.023686485169357716   to: 0.021674664928484695
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.024278613831529919   to: 0.022260611525076621
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.024870806831542025   to: 0.022847329165281607
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.025462870543470312   to: 0.023434602521316079
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.026054618693399447   to: 0.024022224061433273
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.026645872166009291   to: 0.024609993855025793
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.027236458814020193   to: 0.025197719380070274
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.027826213270587232   to: 0.025785215333043489
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.028414976764721125   to: 0.026372303441426784
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.029002596939802519   to: 0.026958812278901297
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.029588927675246547   to: 0.027544577083324764
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.030173828911364012   to: 0.028129439577568749
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.030757166477457992   to: 0.028713247793284949
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.031338811923184690   to: 0.029295855897658235
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.031918642353201035   to: 0.029877124023195624
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.032496540265113748   to: 0.030456918100591208
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.033072393390738045   to: 0.031035109694699026
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.033646094540668359   to: 0.031611575843638370
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.034217541452157364   to: 0.032186198901048929
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.034786636640294744   to: 0.032758866381506782
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.035353287252472630   to: 0.033329470809106490
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.035917404926119521   to: 0.033897909569208462
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.036478905649681530   to: 0.034464084763346357
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.037037709626825045   to: 0.035027903067283893
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.037593741143832980   to: 0.035589275592206961
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.038146928440162202   to: 0.036148117749032004
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.038697203582128567   to: 0.036704349115809276
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.039244502339682352   to: 0.037257893308194796
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.039788764066235632   to: 0.037808677852963428
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.040329931581500174   to: 0.038356634064531395
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.040867951057294225   to: 0.038901696924455276
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.041402771906273284   to: 0.039443804963871537
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.041934346673539950   to: 0.039982900148838880
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.042462630931086397   to: 0.040518927768544405
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.042987583175021805   to: 0.041051836326332303
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.043509164725536759   to: 0.041581577433513206
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.044027339629555219   to: 0.042108105705910157
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.044542074566025283   to: 0.042631378663097554
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.045053338753798237   to: 0.043151356630287172
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.045561103862046086   to: 0.043668002642815298
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.046065343923167128   to: 0.044181282353184810
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.046566035248129092   to: 0.044691163940614502
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.047063156344199428   to: 0.045197618023048697
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.047556687835012428   to: 0.045700617571579366
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.048046612382922946   to: 0.046200137827232833
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.048532914613596718   to: 0.046696156220073254
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.049015581042787790   to: 0.047188652290575166
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.049494600005253395   to: 0.047677607613216981
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.049969961585757797   to: 0.048163005722248381
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.050441657552116465   to: 0.048644832039583891
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.050909681290232295   to: 0.049123073804775493
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.051374027741077188   to: 0.049597720007018037
i: 100, name:           module.conv10.weight  changing lr from: 0.051834693339571386   to: 0.050068761319140627
i: 101, name:             module.conv10.bias  changing lr from: 0.052291675955314913   to: 0.050536190033538549



# Switched to train mode...
Epoch: [45][  0/391]	Time  0.209 ( 0.209)	Data  0.164 ( 0.164)	Loss 1.3928e-01 (1.3928e-01)	Acc@1  96.09 ( 96.09)	Acc@5 100.00 (100.00)
Epoch: [45][ 10/391]	Time  0.041 ( 0.056)	Data  0.001 ( 0.016)	Loss 6.3871e-02 (1.1261e-01)	Acc@1  96.88 ( 95.88)	Acc@5 100.00 (100.00)
Epoch: [45][ 20/391]	Time  0.039 ( 0.049)	Data  0.001 ( 0.009)	Loss 7.6319e-02 (1.1155e-01)	Acc@1  96.09 ( 96.17)	Acc@5 100.00 ( 99.96)
Epoch: [45][ 30/391]	Time  0.044 ( 0.047)	Data  0.001 ( 0.006)	Loss 1.5278e-01 (1.1033e-01)	Acc@1  94.53 ( 96.12)	Acc@5 100.00 ( 99.97)
Epoch: [45][ 40/391]	Time  0.037 ( 0.045)	Data  0.001 ( 0.005)	Loss 1.3021e-01 (1.1412e-01)	Acc@1  96.88 ( 96.02)	Acc@5 100.00 ( 99.98)
Epoch: [45][ 50/391]	Time  0.037 ( 0.043)	Data  0.001 ( 0.004)	Loss 1.1529e-01 (1.1293e-01)	Acc@1  95.31 ( 95.99)	Acc@5 100.00 ( 99.98)
Epoch: [45][ 60/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.004)	Loss 5.9981e-02 (1.1278e-01)	Acc@1  96.88 ( 95.94)	Acc@5 100.00 ( 99.99)
Epoch: [45][ 70/391]	Time  0.036 ( 0.042)	Data  0.001 ( 0.003)	Loss 1.6966e-01 (1.1261e-01)	Acc@1  95.31 ( 96.03)	Acc@5 100.00 ( 99.99)
Epoch: [45][ 80/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.003)	Loss 1.1590e-01 (1.1183e-01)	Acc@1  96.09 ( 96.03)	Acc@5 100.00 ( 99.97)
Epoch: [45][ 90/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.003)	Loss 9.4470e-02 (1.1148e-01)	Acc@1  95.31 ( 96.03)	Acc@5 100.00 ( 99.97)
Epoch: [45][100/391]	Time  0.037 ( 0.041)	Data  0.001 ( 0.003)	Loss 1.0451e-01 (1.1310e-01)	Acc@1  97.66 ( 95.99)	Acc@5 100.00 ( 99.97)
Epoch: [45][110/391]	Time  0.046 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.2034e-01 (1.1382e-01)	Acc@1  97.66 ( 96.03)	Acc@5 100.00 ( 99.97)
Epoch: [45][120/391]	Time  0.044 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.2868e-01 (1.1447e-01)	Acc@1  93.75 ( 95.99)	Acc@5 100.00 ( 99.97)
Epoch: [45][130/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.7452e-01 (1.1511e-01)	Acc@1  93.75 ( 95.94)	Acc@5 100.00 ( 99.98)
Epoch: [45][140/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 9.6206e-02 (1.1488e-01)	Acc@1  97.66 ( 95.97)	Acc@5 100.00 ( 99.98)
Epoch: [45][150/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.1600e-01 (1.1556e-01)	Acc@1  95.31 ( 95.95)	Acc@5 100.00 ( 99.97)
Epoch: [45][160/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.3184e-01 (1.1584e-01)	Acc@1  90.62 ( 95.94)	Acc@5 100.00 ( 99.97)
Epoch: [45][170/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.6514e-01 (1.1765e-01)	Acc@1  93.75 ( 95.89)	Acc@5 100.00 ( 99.97)
Epoch: [45][180/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 9.5267e-02 (1.1907e-01)	Acc@1  96.88 ( 95.87)	Acc@5 100.00 ( 99.96)
Epoch: [45][190/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.5827e-01 (1.2053e-01)	Acc@1  93.75 ( 95.81)	Acc@5 100.00 ( 99.96)
Epoch: [45][200/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 7.2372e-02 (1.2199e-01)	Acc@1  98.44 ( 95.78)	Acc@5 100.00 ( 99.96)
Epoch: [45][210/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.9138e-01 (1.2360e-01)	Acc@1  95.31 ( 95.73)	Acc@5 100.00 ( 99.96)
Epoch: [45][220/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.5346e-01 (1.2355e-01)	Acc@1  95.31 ( 95.72)	Acc@5 100.00 ( 99.96)
Epoch: [45][230/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.2490e-01 (1.2378e-01)	Acc@1  95.31 ( 95.71)	Acc@5 100.00 ( 99.96)
Epoch: [45][240/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.2093e-01 (1.2437e-01)	Acc@1  96.09 ( 95.69)	Acc@5 100.00 ( 99.96)
Epoch: [45][250/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 7.2371e-02 (1.2503e-01)	Acc@1  96.88 ( 95.64)	Acc@5 100.00 ( 99.96)
Epoch: [45][260/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.0364e-01 (1.2497e-01)	Acc@1  96.88 ( 95.63)	Acc@5 100.00 ( 99.96)
Epoch: [45][270/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.2875e-01 (1.2567e-01)	Acc@1  95.31 ( 95.60)	Acc@5 100.00 ( 99.96)
Epoch: [45][280/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.1423e-01 (1.2576e-01)	Acc@1  96.09 ( 95.59)	Acc@5 100.00 ( 99.96)
Epoch: [45][290/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.5400e-01 (1.2540e-01)	Acc@1  93.75 ( 95.61)	Acc@5 100.00 ( 99.96)
Epoch: [45][300/391]	Time  0.037 ( 0.041)	Data  0.001 ( 0.002)	Loss 7.2184e-02 (1.2606e-01)	Acc@1  96.09 ( 95.60)	Acc@5 100.00 ( 99.96)
Epoch: [45][310/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.001)	Loss 1.0694e-01 (1.2595e-01)	Acc@1  96.09 ( 95.60)	Acc@5 100.00 ( 99.96)
Epoch: [45][320/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.001)	Loss 7.1740e-02 (1.2570e-01)	Acc@1  97.66 ( 95.60)	Acc@5 100.00 ( 99.96)
Epoch: [45][330/391]	Time  0.043 ( 0.041)	Data  0.001 ( 0.001)	Loss 9.1043e-02 (1.2558e-01)	Acc@1  98.44 ( 95.61)	Acc@5 100.00 ( 99.96)
Epoch: [45][340/391]	Time  0.045 ( 0.041)	Data  0.001 ( 0.001)	Loss 1.8228e-01 (1.2591e-01)	Acc@1  93.75 ( 95.59)	Acc@5 100.00 ( 99.96)
Epoch: [45][350/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.001)	Loss 1.3572e-01 (1.2563e-01)	Acc@1  95.31 ( 95.61)	Acc@5 100.00 ( 99.96)
Epoch: [45][360/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.001)	Loss 7.1758e-02 (1.2547e-01)	Acc@1  98.44 ( 95.62)	Acc@5 100.00 ( 99.96)
Epoch: [45][370/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.001)	Loss 1.1735e-01 (1.2515e-01)	Acc@1  95.31 ( 95.63)	Acc@5 100.00 ( 99.96)
Epoch: [45][380/391]	Time  0.044 ( 0.041)	Data  0.001 ( 0.001)	Loss 1.1415e-01 (1.2542e-01)	Acc@1  96.09 ( 95.63)	Acc@5 100.00 ( 99.96)
Epoch: [45][390/391]	Time  0.026 ( 0.041)	Data  0.001 ( 0.001)	Loss 1.8751e-01 (1.2587e-01)	Acc@1  95.00 ( 95.62)	Acc@5 100.00 ( 99.96)
## e[45] optimizer.zero_grad (sum) time: 0.2728085517883301
## e[45]       loss.backward (sum) time: 3.9967947006225586
## e[45]      optimizer.step (sum) time: 1.839620590209961
## epoch[45] training(only) time: 15.990691423416138
# Switched to evaluate mode...
Test: [  0/100]	Time  0.168 ( 0.168)	Loss 2.3863e-01 (2.3863e-01)	Acc@1  91.00 ( 91.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.024 ( 0.036)	Loss 6.0057e-01 (3.7173e-01)	Acc@1  88.00 ( 89.91)	Acc@5 100.00 ( 99.73)
Test: [ 20/100]	Time  0.023 ( 0.029)	Loss 3.9013e-01 (3.6353e-01)	Acc@1  84.00 ( 89.33)	Acc@5 100.00 ( 99.62)
Test: [ 30/100]	Time  0.021 ( 0.026)	Loss 5.4855e-01 (4.0052e-01)	Acc@1  84.00 ( 89.16)	Acc@5  99.00 ( 99.61)
Test: [ 40/100]	Time  0.023 ( 0.024)	Loss 2.5817e-01 (4.0071e-01)	Acc@1  91.00 ( 89.34)	Acc@5  99.00 ( 99.54)
Test: [ 50/100]	Time  0.018 ( 0.024)	Loss 1.8176e-01 (3.9382e-01)	Acc@1  94.00 ( 89.63)	Acc@5 100.00 ( 99.59)
Test: [ 60/100]	Time  0.021 ( 0.023)	Loss 3.9721e-01 (3.8722e-01)	Acc@1  88.00 ( 89.61)	Acc@5 100.00 ( 99.61)
Test: [ 70/100]	Time  0.023 ( 0.023)	Loss 3.3730e-01 (3.7921e-01)	Acc@1  89.00 ( 89.61)	Acc@5 100.00 ( 99.65)
Test: [ 80/100]	Time  0.017 ( 0.022)	Loss 2.9054e-01 (3.7729e-01)	Acc@1  91.00 ( 89.59)	Acc@5 100.00 ( 99.67)
Test: [ 90/100]	Time  0.024 ( 0.022)	Loss 2.7498e-01 (3.7981e-01)	Acc@1  94.00 ( 89.59)	Acc@5 100.00 ( 99.65)
 * Acc@1 89.620 Acc@5 99.660
### epoch[45] execution time: 18.295020818710327
EPOCH 46
i:   0, name:           module.stem.0.weight  changing lr from: 0.001135477166065490   to: 0.001000743693028921
i:   1, name:             module.stem.0.bias  changing lr from: 0.001230604220034714   to: 0.001020164657302085
i:   2, name:           module.stem.1.weight  changing lr from: 0.001349520013457000   to: 0.001065330806013408
i:   3, name:             module.stem.1.bias  changing lr from: 0.001491460130189769   to: 0.001135468291468144
i:   4, name:  module.fire2.squeeze.0.weight  changing lr from: 0.001655670268040987   to: 0.001229811270168156
i:   5, name:    module.fire2.squeeze.0.bias  changing lr from: 0.001841406745697160   to: 0.001347602566317717
i:   6, name:  module.fire2.squeeze.1.weight  changing lr from: 0.002047936955776529   to: 0.001488094274099288
i:   7, name:    module.fire2.squeeze.1.bias  changing lr from: 0.002274539767118033   to: 0.001650548302044229
i:   8, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.002520505879290179   to: 0.001834236862699916
i:   9, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.002785138132179398   to: 0.002038442910672577
i:  10, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.003067751773395682   to: 0.002262460532003957
i:  11, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.003367674686113752   to: 0.002505595287720723
i:  12, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.003684247579851251   to: 0.002767164514277936
i:  13, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.004016824146572056   to: 0.003046497583503026
i:  14, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.004364771184391930   to: 0.003342936124533540
i:  15, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.004727468691056552   to: 0.003655834210132285
i:  16, name:  module.fire3.squeeze.0.weight  changing lr from: 0.005104309929257327   to: 0.003984558509655566
i:  17, name:    module.fire3.squeeze.0.bias  changing lr from: 0.005494701465750229   to: 0.004328488410846192
i:  18, name:  module.fire3.squeeze.1.weight  changing lr from: 0.005898063186144425   to: 0.004687016112520986
i:  19, name:    module.fire3.squeeze.1.bias  changing lr from: 0.006313828287133993   to: 0.005059546690124072
i:  20, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.006741443247854566   to: 0.005445498136021997
i:  21, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.007180367781959678   to: 0.005844301376324045
i:  22, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.007630074771926792   to: 0.006255400265922111
i:  23, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.008090050187022378   to: 0.006678251563358450
i:  24, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.008559792986277437   to: 0.007112324887046383
i:  25, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.009038815007750074   to: 0.007557102654289410
i:  26, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.009526640845280602   to: 0.008012080004467226
i:  27, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.010022807713875696   to: 0.008476764707683498
i:  28, name:  module.fire4.squeeze.0.weight  changing lr from: 0.010526865304792882   to: 0.008950677060098999
i:  29, name:    module.fire4.squeeze.0.bias  changing lr from: 0.011038375631333596   to: 0.009433349767106247
i:  30, name:  module.fire4.squeeze.1.weight  changing lr from: 0.011556912866293713   to: 0.009924327815436312
i:  31, name:    module.fire4.squeeze.1.bias  changing lr from: 0.012082063171963059   to: 0.010423168335226680
i:  32, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.012613424523510674   to: 0.010929440453018534
i:  33, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.013150606526541136   to: 0.011442725136596027
i:  34, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.013693230229557547   to: 0.011962615032524809
i:  35, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.014240927932019865   to: 0.012488714297195676
i:  36, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.014793342988642367   to: 0.013020638422129620
i:  37, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.015350129610531782   to: 0.013558014054253397
i:  38, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.015910952663727041   to: 0.014100478811809813
i:  39, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.016475487465663331   to: 0.014647681096524527
i:  40, name:  module.fire5.squeeze.0.weight  changing lr from: 0.017043419580047094   to: 0.015199279902610070
i:  41, name:    module.fire5.squeeze.0.bias  changing lr from: 0.017614444610593940   to: 0.015754944623149990
i:  42, name:  module.fire5.squeeze.1.weight  changing lr from: 0.018188267994048664   to: 0.016314354854368295
i:  43, name:    module.fire5.squeeze.1.bias  changing lr from: 0.018764604792876539   to: 0.016877200198256233
i:  44, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.019343179487984891   to: 0.017443180063993674
i:  45, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.019923725771807028   to: 0.018012003468572842
i:  46, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.020505986342054607   to: 0.018583388837001415
i:  47, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.021089712696419707   to: 0.019157063802434936
i:  48, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.021674664928484695   to: 0.019732765006561105
i:  49, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.022260611525076621   to: 0.020310237900534746
i:  50, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.022847329165281607   to: 0.020889236546737390
i:  51, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.023434602521316079   to: 0.021469523421614175
i:  52, name:  module.fire6.squeeze.0.weight  changing lr from: 0.024022224061433273   to: 0.022050869219819413
i:  53, name:    module.fire6.squeeze.0.bias  changing lr from: 0.024609993855025793   to: 0.022633052659882094
i:  54, name:  module.fire6.squeeze.1.weight  changing lr from: 0.025197719380070274   to: 0.023215860291584751
i:  55, name:    module.fire6.squeeze.1.bias  changing lr from: 0.025785215333043489   to: 0.023799086305230283
i:  56, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.026372303441426784   to: 0.024382532342957036
i:  57, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.026958812278901297   to: 0.024966007312244139
i:  58, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.027544577083324764   to: 0.025549327201737301
i:  59, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.028129439577568749   to: 0.026132314899509512
i:  60, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.028713247793284949   to: 0.026714800013860021
i:  61, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.029295855897658235   to: 0.027296618696741437
i:  62, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.029877124023195624   to: 0.027877613469895077
i:  63, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.030456918100591208   to: 0.028457633053762879
i:  64, name:  module.fire7.squeeze.0.weight  changing lr from: 0.031035109694699026   to: 0.029036532199235777
i:  65, name:    module.fire7.squeeze.0.bias  changing lr from: 0.031611575843638370   to: 0.029614171522288114
i:  66, name:  module.fire7.squeeze.1.weight  changing lr from: 0.032186198901048929   to: 0.030190417341540012
i:  67, name:    module.fire7.squeeze.1.bias  changing lr from: 0.032758866381506782   to: 0.030765141518781288
i:  68, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.033329470809106490   to: 0.031338221302483350
i:  69, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.033897909569208462   to: 0.031909539174318664
i:  70, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.034464084763346357   to: 0.032478982698701073
i:  71, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.035027903067283893   to: 0.033046444375354173
i:  72, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.035589275592206961   to: 0.033611821494910037
i:  73, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.036148117749032004   to: 0.034175015997534974
i:  74, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.036704349115809276   to: 0.034735934334575079
i:  75, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.037257893308194796   to: 0.035294487333209341
i:  76, name:  module.fire8.squeeze.0.weight  changing lr from: 0.037808677852963428   to: 0.035850590064094884
i:  77, name:    module.fire8.squeeze.0.bias  changing lr from: 0.038356634064531395   to: 0.036404161711984996
i:  78, name:  module.fire8.squeeze.1.weight  changing lr from: 0.038901696924455276   to: 0.036955125449297389
i:  79, name:    module.fire8.squeeze.1.bias  changing lr from: 0.039443804963871537   to: 0.037503408312607379
i:  80, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.039982900148838880   to: 0.038048941082037449
i:  81, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.040518927768544405   to: 0.038591658163513336
i:  82, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.041051836326332303   to: 0.039131497473852944
i:  83, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.041581577433513206   to: 0.039668400328654312
i:  84, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.042108105705910157   to: 0.040202311332945224
i:  85, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.042631378663097554   to: 0.040733178274557316
i:  86, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.043151356630287172   to: 0.041260952020184455
i:  87, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.043668002642815298   to: 0.041785586414085342
i:  88, name:  module.fire9.squeeze.0.weight  changing lr from: 0.044181282353184810   to: 0.042307038179388440
i:  89, name:    module.fire9.squeeze.0.bias  changing lr from: 0.044691163940614502   to: 0.042825266821956566
i:  90, name:  module.fire9.squeeze.1.weight  changing lr from: 0.045197618023048697   to: 0.043340234536768045
i:  91, name:    module.fire9.squeeze.1.bias  changing lr from: 0.045700617571579366   to: 0.043851906116770298
i:  92, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.046200137827232833   to: 0.044360248864161622
i:  93, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.046696156220073254   to: 0.044865232504055941
i:  94, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.047188652290575166   to: 0.045366829100485784
i:  95, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.047677607613216981   to: 0.045865012974697923
i:  96, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.048163005722248381   to: 0.046359760625696245
i:  97, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.048644832039583891   to: 0.046851050652986524
i:  98, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.049123073804775493   to: 0.047338863681477238
i:  99, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.049597720007018037   to: 0.047823182288491806
i: 100, name:           module.conv10.weight  changing lr from: 0.050068761319140627   to: 0.048303990932846451
i: 101, name:             module.conv10.bias  changing lr from: 0.050536190033538549   to: 0.048781275885949139



# Switched to train mode...
Epoch: [46][  0/391]	Time  0.210 ( 0.210)	Data  0.168 ( 0.168)	Loss 9.2939e-02 (9.2939e-02)	Acc@1  95.31 ( 95.31)	Acc@5 100.00 (100.00)
Epoch: [46][ 10/391]	Time  0.040 ( 0.056)	Data  0.001 ( 0.016)	Loss 1.0110e-01 (1.0310e-01)	Acc@1  96.09 ( 96.16)	Acc@5 100.00 (100.00)
Epoch: [46][ 20/391]	Time  0.041 ( 0.048)	Data  0.001 ( 0.009)	Loss 1.2401e-01 (1.0817e-01)	Acc@1  94.53 ( 95.94)	Acc@5 100.00 (100.00)
Epoch: [46][ 30/391]	Time  0.042 ( 0.046)	Data  0.001 ( 0.006)	Loss 1.0222e-01 (1.0424e-01)	Acc@1  95.31 ( 96.19)	Acc@5 100.00 (100.00)
Epoch: [46][ 40/391]	Time  0.040 ( 0.044)	Data  0.001 ( 0.005)	Loss 1.0963e-01 (1.0184e-01)	Acc@1  94.53 ( 96.27)	Acc@5 100.00 (100.00)
Epoch: [46][ 50/391]	Time  0.042 ( 0.044)	Data  0.001 ( 0.004)	Loss 1.2099e-01 (1.0281e-01)	Acc@1  95.31 ( 96.19)	Acc@5 100.00 (100.00)
Epoch: [46][ 60/391]	Time  0.038 ( 0.043)	Data  0.001 ( 0.004)	Loss 1.2707e-01 (1.0670e-01)	Acc@1  96.88 ( 96.14)	Acc@5 100.00 ( 99.99)
Epoch: [46][ 70/391]	Time  0.044 ( 0.043)	Data  0.001 ( 0.003)	Loss 1.0962e-01 (1.0614e-01)	Acc@1  94.53 ( 96.20)	Acc@5 100.00 ( 99.99)
Epoch: [46][ 80/391]	Time  0.042 ( 0.043)	Data  0.001 ( 0.003)	Loss 9.4910e-02 (1.0494e-01)	Acc@1  96.09 ( 96.20)	Acc@5 100.00 ( 99.99)
Epoch: [46][ 90/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.003)	Loss 9.3629e-02 (1.0518e-01)	Acc@1  97.66 ( 96.26)	Acc@5 100.00 ( 99.98)
Epoch: [46][100/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.003)	Loss 6.9321e-02 (1.0546e-01)	Acc@1  98.44 ( 96.23)	Acc@5 100.00 ( 99.98)
Epoch: [46][110/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.003)	Loss 1.4506e-01 (1.0551e-01)	Acc@1  95.31 ( 96.25)	Acc@5 100.00 ( 99.98)
Epoch: [46][120/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.002)	Loss 8.0950e-02 (1.0695e-01)	Acc@1  98.44 ( 96.22)	Acc@5 100.00 ( 99.97)
Epoch: [46][130/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.6794e-01 (1.0762e-01)	Acc@1  92.97 ( 96.21)	Acc@5 100.00 ( 99.97)
Epoch: [46][140/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.6469e-01 (1.0811e-01)	Acc@1  94.53 ( 96.22)	Acc@5 100.00 ( 99.97)
Epoch: [46][150/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 8.8019e-02 (1.0800e-01)	Acc@1  97.66 ( 96.26)	Acc@5 100.00 ( 99.97)
Epoch: [46][160/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.2932e-01 (1.0802e-01)	Acc@1  92.97 ( 96.24)	Acc@5 100.00 ( 99.97)
Epoch: [46][170/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.1360e-01 (1.0924e-01)	Acc@1  95.31 ( 96.19)	Acc@5 100.00 ( 99.97)
Epoch: [46][180/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.7187e-01 (1.0903e-01)	Acc@1  96.09 ( 96.25)	Acc@5  99.22 ( 99.97)
Epoch: [46][190/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 7.0690e-02 (1.0991e-01)	Acc@1  97.66 ( 96.22)	Acc@5 100.00 ( 99.97)
Epoch: [46][200/391]	Time  0.043 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.5241e-01 (1.0977e-01)	Acc@1  96.09 ( 96.23)	Acc@5 100.00 ( 99.97)
Epoch: [46][210/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 7.1371e-02 (1.1046e-01)	Acc@1  96.09 ( 96.22)	Acc@5 100.00 ( 99.97)
Epoch: [46][220/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 6.6250e-02 (1.1156e-01)	Acc@1  98.44 ( 96.18)	Acc@5 100.00 ( 99.97)
Epoch: [46][230/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.8938e-02 (1.1161e-01)	Acc@1  99.22 ( 96.17)	Acc@5 100.00 ( 99.96)
Epoch: [46][240/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 8.2928e-02 (1.1175e-01)	Acc@1  96.88 ( 96.16)	Acc@5 100.00 ( 99.96)
Epoch: [46][250/391]	Time  0.045 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.3705e-01 (1.1220e-01)	Acc@1  93.75 ( 96.11)	Acc@5 100.00 ( 99.96)
Epoch: [46][260/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 8.0861e-02 (1.1235e-01)	Acc@1  96.88 ( 96.11)	Acc@5 100.00 ( 99.96)
Epoch: [46][270/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.0552e-01 (1.1307e-01)	Acc@1  96.88 ( 96.06)	Acc@5 100.00 ( 99.96)
Epoch: [46][280/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.3145e-01 (1.1328e-01)	Acc@1  94.53 ( 96.04)	Acc@5 100.00 ( 99.96)
Epoch: [46][290/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.3672e-01 (1.1380e-01)	Acc@1  94.53 ( 96.01)	Acc@5 100.00 ( 99.96)
Epoch: [46][300/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.5057e-01 (1.1433e-01)	Acc@1  96.88 ( 95.99)	Acc@5 100.00 ( 99.96)
Epoch: [46][310/391]	Time  0.037 ( 0.041)	Data  0.002 ( 0.002)	Loss 1.2264e-01 (1.1464e-01)	Acc@1  94.53 ( 95.96)	Acc@5 100.00 ( 99.96)
Epoch: [46][320/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 6.5370e-02 (1.1541e-01)	Acc@1  98.44 ( 95.94)	Acc@5 100.00 ( 99.96)
Epoch: [46][330/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.3591e-01 (1.1676e-01)	Acc@1  92.97 ( 95.91)	Acc@5 100.00 ( 99.96)
Epoch: [46][340/391]	Time  0.043 ( 0.041)	Data  0.001 ( 0.002)	Loss 7.6232e-02 (1.1651e-01)	Acc@1  96.88 ( 95.90)	Acc@5 100.00 ( 99.96)
Epoch: [46][350/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.001)	Loss 1.8330e-01 (1.1654e-01)	Acc@1  91.41 ( 95.90)	Acc@5 100.00 ( 99.96)
Epoch: [46][360/391]	Time  0.038 ( 0.041)	Data  0.002 ( 0.001)	Loss 1.1584e-01 (1.1688e-01)	Acc@1  96.09 ( 95.89)	Acc@5 100.00 ( 99.96)
Epoch: [46][370/391]	Time  0.044 ( 0.041)	Data  0.001 ( 0.001)	Loss 1.4416e-01 (1.1685e-01)	Acc@1  96.09 ( 95.88)	Acc@5 100.00 ( 99.96)
Epoch: [46][380/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.001)	Loss 1.0273e-01 (1.1713e-01)	Acc@1  93.75 ( 95.87)	Acc@5 100.00 ( 99.96)
Epoch: [46][390/391]	Time  0.028 ( 0.041)	Data  0.001 ( 0.001)	Loss 2.0915e-01 (1.1684e-01)	Acc@1  92.50 ( 95.88)	Acc@5 100.00 ( 99.96)
## e[46] optimizer.zero_grad (sum) time: 0.27117085456848145
## e[46]       loss.backward (sum) time: 4.0103371143341064
## e[46]      optimizer.step (sum) time: 1.8024728298187256
## epoch[46] training(only) time: 16.073368787765503
# Switched to evaluate mode...
Test: [  0/100]	Time  0.177 ( 0.177)	Loss 2.1724e-01 (2.1724e-01)	Acc@1  93.00 ( 93.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.025 ( 0.036)	Loss 5.4958e-01 (3.3095e-01)	Acc@1  87.00 ( 90.27)	Acc@5 100.00 ( 99.73)
Test: [ 20/100]	Time  0.020 ( 0.030)	Loss 4.0878e-01 (3.5039e-01)	Acc@1  82.00 ( 90.00)	Acc@5 100.00 ( 99.76)
Test: [ 30/100]	Time  0.017 ( 0.026)	Loss 4.6482e-01 (3.7907e-01)	Acc@1  87.00 ( 90.03)	Acc@5  98.00 ( 99.61)
Test: [ 40/100]	Time  0.020 ( 0.025)	Loss 3.6434e-01 (3.7500e-01)	Acc@1  89.00 ( 89.98)	Acc@5  99.00 ( 99.56)
Test: [ 50/100]	Time  0.018 ( 0.024)	Loss 1.7982e-01 (3.7399e-01)	Acc@1  94.00 ( 89.98)	Acc@5 100.00 ( 99.55)
Test: [ 60/100]	Time  0.018 ( 0.023)	Loss 3.4177e-01 (3.7184e-01)	Acc@1  91.00 ( 89.85)	Acc@5 100.00 ( 99.62)
Test: [ 70/100]	Time  0.018 ( 0.023)	Loss 3.6004e-01 (3.6428e-01)	Acc@1  88.00 ( 89.97)	Acc@5 100.00 ( 99.65)
Test: [ 80/100]	Time  0.021 ( 0.023)	Loss 1.7766e-01 (3.5724e-01)	Acc@1  94.00 ( 90.10)	Acc@5 100.00 ( 99.64)
Test: [ 90/100]	Time  0.022 ( 0.023)	Loss 2.6370e-01 (3.6316e-01)	Acc@1  92.00 ( 90.02)	Acc@5 100.00 ( 99.64)
 * Acc@1 89.990 Acc@5 99.650
### epoch[46] execution time: 18.402877807617188
EPOCH 47
REMOVING: module.stem.0.weight
REMOVING: module.stem.0.bias
REMOVING: module.stem.1.weight
i:   0, name:             module.stem.1.bias  changing lr from: 0.001135468291468144   to: 0.001001201933263656
i:   1, name:  module.fire2.squeeze.0.weight  changing lr from: 0.001229811270168156   to: 0.001022056012402144
i:   2, name:    module.fire2.squeeze.0.bias  changing lr from: 0.001347602566317717   to: 0.001068245066369416
i:   3, name:  module.fire2.squeeze.1.weight  changing lr from: 0.001488094274099288   to: 0.001139012112481057
i:   4, name:    module.fire2.squeeze.1.bias  changing lr from: 0.001650548302044229   to: 0.001233607979771744
i:   5, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.001834236862699916   to: 0.001351291946320476
i:   6, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.002038442910672577   to: 0.001491332318062732
i:   7, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.002262460532003957   to: 0.001653006952246948
i:   8, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.002505595287720723   to: 0.001835603728576573
i:   9, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.002767164514277936   to: 0.002038420970963161
i:  10, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.003046497583503026   to: 0.002260767822702092
i:  11, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.003342936124533540   to: 0.002501964577769371
i:  12, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.003655834210132285   to: 0.002761342970827579
i:  13, name:  module.fire3.squeeze.0.weight  changing lr from: 0.003984558509655566   to: 0.003038246428419821
i:  14, name:    module.fire3.squeeze.0.bias  changing lr from: 0.004328488410846192   to: 0.003332030283724584
i:  15, name:  module.fire3.squeeze.1.weight  changing lr from: 0.004687016112520986   to: 0.003642061957139780
i:  16, name:    module.fire3.squeeze.1.bias  changing lr from: 0.005059546690124072   to: 0.003967721104863219
i:  17, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.005445498136021997   to: 0.004308399737537749
i:  18, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.005844301376324045   to: 0.004663502310933481
i:  19, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.006255400265922111   to: 0.005032445790546002
i:  20, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.006678251563358450   to: 0.005414659691899714
i:  21, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.007112324887046383   to: 0.005809586098257535
i:  22, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.007557102654289410   to: 0.006216679657354168
i:  23, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.008012080004467226   to: 0.006635407558688299
i:  24, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.008476764707683498   to: 0.007065249492831021
i:  25, name:  module.fire4.squeeze.0.weight  changing lr from: 0.008950677060098999   to: 0.007505697594131405
i:  26, name:    module.fire4.squeeze.0.bias  changing lr from: 0.009433349767106247   to: 0.007956256368127822
i:  27, name:  module.fire4.squeeze.1.weight  changing lr from: 0.009924327815436312   to: 0.008416442604903540
i:  28, name:    module.fire4.squeeze.1.bias  changing lr from: 0.010423168335226680   to: 0.008885785279557915
i:  29, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.010929440453018534   to: 0.009363825440899785
i:  30, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.011442725136596027   to: 0.009850116089408407
i:  31, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.011962615032524809   to: 0.010344222045447497
i:  32, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.012488714297195676   to: 0.010845719808661846
i:  33, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.013020638422129620   to: 0.011354197409431686
i:  34, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.013558014054253397   to: 0.011869254253207930
i:  35, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.014100478811809813   to: 0.012390500958502720
i:  36, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.014647681096524527   to: 0.012917559189262035
i:  37, name:  module.fire5.squeeze.0.weight  changing lr from: 0.015199279902610070   to: 0.013450061482302555
i:  38, name:    module.fire5.squeeze.0.bias  changing lr from: 0.015754944623149990   to: 0.013987651070452262
i:  39, name:  module.fire5.squeeze.1.weight  changing lr from: 0.016314354854368295   to: 0.014529981701993121
i:  40, name:    module.fire5.squeeze.1.bias  changing lr from: 0.016877200198256233   to: 0.015076717456966437
i:  41, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.017443180063993674   to: 0.015627532560863383
i:  42, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.018012003468572842   to: 0.016182111196189630
i:  43, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.018583388837001415   to: 0.016740147312358677
i:  44, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.019157063802434936   to: 0.017301344434337975
i:  45, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.019732765006561105   to: 0.017865415470441317
i:  46, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.020310237900534746   to: 0.018432082519633370
i:  47, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.020889236546737390   to: 0.019001076678684982
i:  48, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.021469523421614175   to: 0.019572137849492743
i:  49, name:  module.fire6.squeeze.0.weight  changing lr from: 0.022050869219819413   to: 0.020145014546852791
i:  50, name:    module.fire6.squeeze.0.bias  changing lr from: 0.022633052659882094   to: 0.020719463706955456
i:  51, name:  module.fire6.squeeze.1.weight  changing lr from: 0.023215860291584751   to: 0.021295250496846663
i:  52, name:    module.fire6.squeeze.1.bias  changing lr from: 0.023799086305230283   to: 0.021872148125081217
i:  53, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.024382532342957036   to: 0.022449937653775277
i:  54, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.024966007312244139   to: 0.023028407812245733
i:  55, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.025549327201737301   to: 0.023607354812409099
i:  56, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.026132314899509512   to: 0.024186582166095101
i:  57, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.026714800013860021   to: 0.024765900504416946
i:  58, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.027296618696741437   to: 0.025345127399324281
i:  59, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.027877613469895077   to: 0.025924087187453610
i:  60, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.028457633053762879   to: 0.026502610796377203
i:  61, name:  module.fire7.squeeze.0.weight  changing lr from: 0.029036532199235777   to: 0.027080535573340815
i:  62, name:    module.fire7.squeeze.0.bias  changing lr from: 0.029614171522288114   to: 0.027657705116569453
i:  63, name:  module.fire7.squeeze.1.weight  changing lr from: 0.030190417341540012   to: 0.028233969109210111
i:  64, name:    module.fire7.squeeze.1.bias  changing lr from: 0.030765141518781288   to: 0.028809183155971214
i:  65, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.031338221302483350   to: 0.029383208622509739
i:  66, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.031909539174318664   to: 0.029955912477608423
i:  67, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.032478982698701073   to: 0.030527167138178157
i:  68, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.033046444375354173   to: 0.031096850317113147
i:  69, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.033611821494910037   to: 0.031664844874020305
i:  70, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.034175015997534974   to: 0.032231038668837600
i:  71, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.034735934334575079   to: 0.032795324418350959
i:  72, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.035294487333209341   to: 0.033357599555613432
i:  73, name:  module.fire8.squeeze.0.weight  changing lr from: 0.035850590064094884   to: 0.033917766092266058
i:  74, name:    module.fire8.squeeze.0.bias  changing lr from: 0.036404161711984996   to: 0.034475730483754831
i:  75, name:  module.fire8.squeeze.1.weight  changing lr from: 0.036955125449297389   to: 0.035031403497434499
i:  76, name:    module.fire8.squeeze.1.bias  changing lr from: 0.037503408312607379   to: 0.035584700083545841
i:  77, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.038048941082037449   to: 0.036135539249049185
i:  78, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.038591658163513336   to: 0.036683843934295128
i:  79, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.039131497473852944   to: 0.037229540892508343
i:  80, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.039668400328654312   to: 0.037772560572060042
i:  81, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.040202311332945224   to: 0.038312837001500066
i:  82, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.040733178274557316   to: 0.038850307677319486
i:  83, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.041260952020184455   to: 0.039384913454410579
i:  84, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.041785586414085342   to: 0.039916598439191202
i:  85, name:  module.fire9.squeeze.0.weight  changing lr from: 0.042307038179388440   to: 0.040445309885357501
i:  86, name:    module.fire9.squeeze.0.bias  changing lr from: 0.042825266821956566   to: 0.040970998092228351
i:  87, name:  module.fire9.squeeze.1.weight  changing lr from: 0.043340234536768045   to: 0.041493616305643632
i:  88, name:    module.fire9.squeeze.1.bias  changing lr from: 0.043851906116770298   to: 0.042013120621376951
i:  89, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.044360248864161622   to: 0.042529469891022936
i:  90, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.044865232504055941   to: 0.043042625630318236
i:  91, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.045366829100485784   to: 0.043552551929854841
i:  92, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.045865012974697923   to: 0.044059215368143501
i:  93, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.046359760625696245   to: 0.044562584926984998
i:  94, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.046851050652986524   to: 0.045062631909106449
i:  95, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.047338863681477238   to: 0.045559329858019387
i:  96, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.047823182288491806   to: 0.046052654480056826
i:  97, name:           module.conv10.weight  changing lr from: 0.048303990932846451   to: 0.046542583568545737
i:  98, name:             module.conv10.bias  changing lr from: 0.048781275885949139   to: 0.047029096930071894



# Switched to train mode...
Epoch: [47][  0/391]	Time  0.214 ( 0.214)	Data  0.170 ( 0.170)	Loss 8.0807e-02 (8.0807e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [47][ 10/391]	Time  0.040 ( 0.056)	Data  0.001 ( 0.016)	Loss 1.0046e-01 (1.0782e-01)	Acc@1  97.66 ( 96.95)	Acc@5 100.00 (100.00)
Epoch: [47][ 20/391]	Time  0.041 ( 0.049)	Data  0.001 ( 0.009)	Loss 1.7425e-01 (1.1280e-01)	Acc@1  93.75 ( 96.50)	Acc@5 100.00 (100.00)
Epoch: [47][ 30/391]	Time  0.042 ( 0.046)	Data  0.001 ( 0.006)	Loss 8.8593e-02 (1.0875e-01)	Acc@1  96.09 ( 96.57)	Acc@5 100.00 (100.00)
Epoch: [47][ 40/391]	Time  0.038 ( 0.045)	Data  0.001 ( 0.005)	Loss 7.5044e-02 (1.1064e-01)	Acc@1  97.66 ( 96.40)	Acc@5 100.00 (100.00)
Epoch: [47][ 50/391]	Time  0.039 ( 0.043)	Data  0.002 ( 0.004)	Loss 9.0180e-02 (1.0787e-01)	Acc@1  96.88 ( 96.42)	Acc@5 100.00 (100.00)
Epoch: [47][ 60/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.004)	Loss 7.7190e-02 (1.0777e-01)	Acc@1  98.44 ( 96.41)	Acc@5 100.00 (100.00)
Epoch: [47][ 70/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.003)	Loss 7.9754e-02 (1.0489e-01)	Acc@1  96.88 ( 96.47)	Acc@5 100.00 (100.00)
Epoch: [47][ 80/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.003)	Loss 1.4206e-01 (1.0367e-01)	Acc@1  93.75 ( 96.43)	Acc@5 100.00 (100.00)
Epoch: [47][ 90/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.003)	Loss 7.1541e-02 (1.0265e-01)	Acc@1  96.88 ( 96.43)	Acc@5 100.00 ( 99.99)
Epoch: [47][100/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.003)	Loss 1.0837e-01 (1.0302e-01)	Acc@1  96.09 ( 96.41)	Acc@5 100.00 ( 99.99)
Epoch: [47][110/391]	Time  0.042 ( 0.042)	Data  0.001 ( 0.003)	Loss 1.4030e-01 (1.0322e-01)	Acc@1  94.53 ( 96.38)	Acc@5 100.00 ( 99.99)
Epoch: [47][120/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.1587e-01 (1.0223e-01)	Acc@1  95.31 ( 96.40)	Acc@5 100.00 ( 99.99)
Epoch: [47][130/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.002)	Loss 9.2906e-02 (1.0274e-01)	Acc@1  96.09 ( 96.40)	Acc@5 100.00 ( 99.99)
Epoch: [47][140/391]	Time  0.038 ( 0.042)	Data  0.001 ( 0.002)	Loss 1.5912e-01 (1.0261e-01)	Acc@1  92.97 ( 96.38)	Acc@5 100.00 ( 99.99)
Epoch: [47][150/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.5513e-01 (1.0246e-01)	Acc@1  94.53 ( 96.40)	Acc@5 100.00 ( 99.99)
Epoch: [47][160/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.2276e-01 (1.0371e-01)	Acc@1  96.88 ( 96.39)	Acc@5 100.00 (100.00)
Epoch: [47][170/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.8895e-02 (1.0412e-01)	Acc@1  99.22 ( 96.39)	Acc@5 100.00 (100.00)
Epoch: [47][180/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 9.6855e-02 (1.0355e-01)	Acc@1  96.88 ( 96.39)	Acc@5 100.00 (100.00)
Epoch: [47][190/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.6610e-01 (1.0282e-01)	Acc@1  93.75 ( 96.42)	Acc@5 100.00 (100.00)
Epoch: [47][200/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.2775e-01 (1.0348e-01)	Acc@1  95.31 ( 96.39)	Acc@5 100.00 ( 99.99)
Epoch: [47][210/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.1393e-01 (1.0364e-01)	Acc@1  95.31 ( 96.37)	Acc@5 100.00 ( 99.99)
Epoch: [47][220/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.1099e-01 (1.0340e-01)	Acc@1  95.31 ( 96.40)	Acc@5 100.00 ( 99.99)
Epoch: [47][230/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 9.7318e-02 (1.0383e-01)	Acc@1  96.88 ( 96.39)	Acc@5 100.00 ( 99.99)
Epoch: [47][240/391]	Time  0.044 ( 0.041)	Data  0.001 ( 0.002)	Loss 7.3931e-02 (1.0384e-01)	Acc@1  96.88 ( 96.37)	Acc@5 100.00 ( 99.99)
Epoch: [47][250/391]	Time  0.036 ( 0.041)	Data  0.001 ( 0.002)	Loss 7.8617e-02 (1.0361e-01)	Acc@1  97.66 ( 96.36)	Acc@5 100.00 ( 99.99)
Epoch: [47][260/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 7.1587e-02 (1.0423e-01)	Acc@1  98.44 ( 96.34)	Acc@5 100.00 ( 99.99)
Epoch: [47][270/391]	Time  0.040 ( 0.041)	Data  0.002 ( 0.002)	Loss 1.3929e-01 (1.0486e-01)	Acc@1  94.53 ( 96.31)	Acc@5 100.00 ( 99.99)
Epoch: [47][280/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.4930e-01 (1.0440e-01)	Acc@1  96.09 ( 96.33)	Acc@5 100.00 ( 99.99)
Epoch: [47][290/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.3346e-01 (1.0458e-01)	Acc@1  95.31 ( 96.32)	Acc@5 100.00 ( 99.99)
Epoch: [47][300/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.1678e-01 (1.0422e-01)	Acc@1  96.09 ( 96.35)	Acc@5 100.00 ( 99.99)
Epoch: [47][310/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.4065e-01 (1.0500e-01)	Acc@1  95.31 ( 96.31)	Acc@5 100.00 ( 99.99)
Epoch: [47][320/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.0451e-01 (1.0449e-01)	Acc@1  95.31 ( 96.33)	Acc@5 100.00 ( 99.99)
Epoch: [47][330/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 9.2926e-02 (1.0413e-01)	Acc@1  94.53 ( 96.33)	Acc@5 100.00 ( 99.99)
Epoch: [47][340/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.1541e-01 (1.0457e-01)	Acc@1  95.31 ( 96.32)	Acc@5 100.00 ( 99.99)
Epoch: [47][350/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.0660e-01 (1.0472e-01)	Acc@1  94.53 ( 96.31)	Acc@5 100.00 ( 99.99)
Epoch: [47][360/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.0764e-02 (1.0476e-01)	Acc@1  98.44 ( 96.32)	Acc@5 100.00 ( 99.99)
Epoch: [47][370/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.001)	Loss 9.0240e-02 (1.0474e-01)	Acc@1  97.66 ( 96.33)	Acc@5 100.00 ( 99.99)
Epoch: [47][380/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.001)	Loss 1.1740e-01 (1.0524e-01)	Acc@1  96.09 ( 96.31)	Acc@5 100.00 ( 99.99)
Epoch: [47][390/391]	Time  0.028 ( 0.041)	Data  0.001 ( 0.001)	Loss 1.3191e-01 (1.0557e-01)	Acc@1  93.75 ( 96.30)	Acc@5 100.00 ( 99.99)
## e[47] optimizer.zero_grad (sum) time: 0.26209163665771484
## e[47]       loss.backward (sum) time: 3.942592144012451
## e[47]      optimizer.step (sum) time: 1.807969570159912
## epoch[47] training(only) time: 15.984795808792114
# Switched to evaluate mode...
Test: [  0/100]	Time  0.165 ( 0.165)	Loss 1.4994e-01 (1.4994e-01)	Acc@1  95.00 ( 95.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.020 ( 0.033)	Loss 4.5455e-01 (3.4730e-01)	Acc@1  90.00 ( 90.36)	Acc@5 100.00 ( 99.64)
Test: [ 20/100]	Time  0.020 ( 0.027)	Loss 3.3028e-01 (3.5727e-01)	Acc@1  91.00 ( 90.38)	Acc@5 100.00 ( 99.71)
Test: [ 30/100]	Time  0.021 ( 0.025)	Loss 4.2398e-01 (3.7312e-01)	Acc@1  87.00 ( 90.19)	Acc@5 100.00 ( 99.68)
Test: [ 40/100]	Time  0.021 ( 0.024)	Loss 3.1742e-01 (3.8135e-01)	Acc@1  90.00 ( 90.05)	Acc@5  99.00 ( 99.59)
Test: [ 50/100]	Time  0.021 ( 0.023)	Loss 1.9290e-01 (3.7242e-01)	Acc@1  95.00 ( 90.25)	Acc@5 100.00 ( 99.57)
Test: [ 60/100]	Time  0.022 ( 0.023)	Loss 3.4558e-01 (3.6641e-01)	Acc@1  94.00 ( 90.21)	Acc@5 100.00 ( 99.61)
Test: [ 70/100]	Time  0.018 ( 0.023)	Loss 4.0445e-01 (3.6259e-01)	Acc@1  86.00 ( 90.24)	Acc@5 100.00 ( 99.65)
Test: [ 80/100]	Time  0.023 ( 0.023)	Loss 2.7433e-01 (3.5586e-01)	Acc@1  92.00 ( 90.30)	Acc@5 100.00 ( 99.64)
Test: [ 90/100]	Time  0.022 ( 0.022)	Loss 1.9126e-01 (3.6643e-01)	Acc@1  95.00 ( 90.19)	Acc@5 100.00 ( 99.63)
 * Acc@1 90.190 Acc@5 99.630
### epoch[47] execution time: 18.35192036628723
EPOCH 48
REMOVING: module.stem.1.bias
REMOVING: module.fire2.squeeze.0.weight
REMOVING: module.fire2.squeeze.0.bias
i:   0, name:  module.fire2.squeeze.1.weight  changing lr from: 0.001139012112481057   to: 0.001002176431456941
i:   1, name:    module.fire2.squeeze.1.bias  changing lr from: 0.001233607979771744   to: 0.001025468120044503
i:   2, name: module.fire2.expand_1x1.0.weight  changing lr from: 0.001351291946320476   to: 0.001073668339882954
i:   3, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.001491332318062732   to: 0.001146036570688618
i:   4, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.001653006952246948   to: 0.001241839946507955
i:   5, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.001835603728576573   to: 0.001360353866001034
i:   6, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.002038420970963161   to: 0.001500862546882830
i:   7, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.002260767822702092   to: 0.001662659527519843
i:   8, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.002501964577769371   to: 0.001845048118569031
i:   9, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.002761342970827579   to: 0.002047341807437380
i:  10, name:  module.fire3.squeeze.0.weight  changing lr from: 0.003038246428419821   to: 0.002268864618232113
i:  11, name:    module.fire3.squeeze.0.bias  changing lr from: 0.003332030283724584   to: 0.002508951429765465
i:  12, name:  module.fire3.squeeze.1.weight  changing lr from: 0.003642061957139780   to: 0.002766948254072892
i:  13, name:    module.fire3.squeeze.1.bias  changing lr from: 0.003967721104863219   to: 0.003042212477801209
i:  14, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.004308399737537749   to: 0.003334113068722127
i:  15, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.004663502310933481   to: 0.003642030749528923
i:  16, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.005032445790546002   to: 0.003965358140977437
i:  17, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.005414659691899714   to: 0.004303499876339916
i:  18, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.005809586098257535   to: 0.004655872689048850
i:  19, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.006216679657354168   to: 0.005021905475320331
i:  20, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.006635407558688299   to: 0.005401039333460794
i:  21, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.007065249492831021   to: 0.005792727581478695
i:  22, name:  module.fire4.squeeze.0.weight  changing lr from: 0.007505697594131405   to: 0.006196435754542345
i:  23, name:    module.fire4.squeeze.0.bias  changing lr from: 0.007956256368127822   to: 0.006611641583748290
i:  24, name:  module.fire4.squeeze.1.weight  changing lr from: 0.008416442604903540   to: 0.007037834957590294
i:  25, name:    module.fire4.squeeze.1.bias  changing lr from: 0.008885785279557915   to: 0.007474517867447122
i:  26, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.009363825440899785   to: 0.007921204338338372
i:  27, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.009850116089408407   to: 0.008377420346131492
i:  28, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.010344222045447497   to: 0.008842703722319094
i:  29, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.010845719808661846   to: 0.009316604047424935
i:  30, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.011354197409431686   to: 0.009798682534038001
i:  31, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.011869254253207930   to: 0.010288511900418257
i:  32, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.012390500958502720   to: 0.010785676235563497
i:  33, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.012917559189262035   to: 0.011289770856575974
i:  34, name:  module.fire5.squeeze.0.weight  changing lr from: 0.013450061482302555   to: 0.011800402159117689
i:  35, name:    module.fire5.squeeze.0.bias  changing lr from: 0.013987651070452262   to: 0.012317187461696667
i:  36, name:  module.fire5.squeeze.1.weight  changing lr from: 0.014529981701993121   to: 0.012839754844481816
i:  37, name:    module.fire5.squeeze.1.bias  changing lr from: 0.015076717456966437   to: 0.013367742983301185
i:  38, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.015627532560863383   to: 0.013900800979437623
i:  39, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.016182111196189630   to: 0.014438588185797498
i:  40, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.016740147312358677   to: 0.014980774029990714
i:  41, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.017301344434337975   to: 0.015527037834826136
i:  42, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.017865415470441317   to: 0.016077068636691783
i:  43, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.018432082519633370   to: 0.016630565002259234
i:  44, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.019001076678684982   to: 0.017187234843920259
i:  45, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.019572137849492743   to: 0.017746795234335932
i:  46, name:  module.fire6.squeeze.0.weight  changing lr from: 0.020145014546852791   to: 0.018308972220451480
i:  47, name:    module.fire6.squeeze.0.bias  changing lr from: 0.020719463706955456   to: 0.018873500637304131
i:  48, name:  module.fire6.squeeze.1.weight  changing lr from: 0.021295250496846663   to: 0.019440123921927798
i:  49, name:    module.fire6.squeeze.1.bias  changing lr from: 0.021872148125081217   to: 0.020008593927634318
i:  50, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.022449937653775277   to: 0.020578670738930990
i:  51, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.023028407812245733   to: 0.021150122487312007
i:  52, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.023607354812409099   to: 0.021722725168143511
i:  53, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.024186582166095101   to: 0.022296262458842600
i:  54, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.024765900504416946   to: 0.022870525538534598
i:  55, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.025345127399324281   to: 0.023445312909355649
i:  56, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.025924087187453610   to: 0.024020430219553270
i:  57, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.026502610796377203   to: 0.024595690088522693
i:  58, name:  module.fire7.squeeze.0.weight  changing lr from: 0.027080535573340815   to: 0.025170911933903840
i:  59, name:    module.fire7.squeeze.0.bias  changing lr from: 0.027657705116569453   to: 0.025745921800850453
i:  60, name:  module.fire7.squeeze.1.weight  changing lr from: 0.028233969109210111   to: 0.026320552193571791
i:  61, name:    module.fire7.squeeze.1.bias  changing lr from: 0.028809183155971214   to: 0.026894641909235451
i:  62, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.029383208622509739   to: 0.027468035874310209
i:  63, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.029955912477608423   to: 0.028040584983417150
i:  64, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.030527167138178157   to: 0.028612145940749147
i:  65, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.031096850317113147   to: 0.029182581104109262
i:  66, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.031664844874020305   to: 0.029751758331611724
i:  67, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.032231038668837600   to: 0.030319550831080580
i:  68, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.032795324418350959   to: 0.030885837012175257
i:  69, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.033357599555613432   to: 0.031450500341265106
i:  70, name:  module.fire8.squeeze.0.weight  changing lr from: 0.033917766092266058   to: 0.032013429199069389
i:  71, name:    module.fire8.squeeze.0.bias  changing lr from: 0.034475730483754831   to: 0.032574516741073360
i:  72, name:  module.fire8.squeeze.1.weight  changing lr from: 0.035031403497434499   to: 0.033133660760726373
i:  73, name:    module.fire8.squeeze.1.bias  changing lr from: 0.035584700083545841   to: 0.033690763555422769
i:  74, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.036135539249049185   to: 0.034245731795261893
i:  75, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.036683843934295128   to: 0.034798476394580218
i:  76, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.037229540892508343   to: 0.035348912386243735
i:  77, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.037772560572060042   to: 0.035896958798686429
i:  78, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.038312837001500066   to: 0.036442538535676576
i:  79, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.038850307677319486   to: 0.036985578258790723
i:  80, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.039384913454410579   to: 0.037526008272571527
i:  81, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.039916598439191202   to: 0.038063762412344070
i:  82, name:  module.fire9.squeeze.0.weight  changing lr from: 0.040445309885357501   to: 0.038598777934662987
i:  83, name:    module.fire9.squeeze.0.bias  changing lr from: 0.040970998092228351   to: 0.039130995410360137
i:  84, name:  module.fire9.squeeze.1.weight  changing lr from: 0.041493616305643632   to: 0.039660358620161859
i:  85, name:    module.fire9.squeeze.1.bias  changing lr from: 0.042013120621376951   to: 0.040186814452842418
i:  86, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.042529469891022936   to: 0.040710312805879334
i:  87, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.043042625630318236   to: 0.041230806488574696
i:  88, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.043552551929854841   to: 0.041748251127606072
i:  89, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.044059215368143501   to: 0.042262605074968866
i:  90, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.044562584926984998   to: 0.042773829318272012
i:  91, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.045062631909106449   to: 0.043281887393347679
i:  92, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.045559329858019387   to: 0.043786745299134969
i:  93, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.046052654480056826   to: 0.044288371414797856
i:  94, name:           module.conv10.weight  changing lr from: 0.046542583568545737   to: 0.044786736419036501
i:  95, name:             module.conv10.bias  changing lr from: 0.047029096930071894   to: 0.045281813211551100



# Switched to train mode...
Epoch: [48][  0/391]	Time  0.209 ( 0.209)	Data  0.164 ( 0.164)	Loss 6.0277e-02 (6.0277e-02)	Acc@1  97.66 ( 97.66)	Acc@5 100.00 (100.00)
Epoch: [48][ 10/391]	Time  0.041 ( 0.056)	Data  0.001 ( 0.016)	Loss 1.8098e-01 (9.7508e-02)	Acc@1  92.97 ( 96.80)	Acc@5 100.00 (100.00)
Epoch: [48][ 20/391]	Time  0.041 ( 0.048)	Data  0.001 ( 0.009)	Loss 4.0697e-02 (9.3602e-02)	Acc@1  97.66 ( 96.65)	Acc@5 100.00 ( 99.96)
Epoch: [48][ 30/391]	Time  0.039 ( 0.045)	Data  0.001 ( 0.006)	Loss 1.1119e-01 (9.8574e-02)	Acc@1  96.09 ( 96.47)	Acc@5 100.00 ( 99.97)
Epoch: [48][ 40/391]	Time  0.038 ( 0.044)	Data  0.001 ( 0.005)	Loss 1.4166e-01 (1.0471e-01)	Acc@1  92.97 ( 96.17)	Acc@5 100.00 ( 99.96)
Epoch: [48][ 50/391]	Time  0.039 ( 0.043)	Data  0.001 ( 0.004)	Loss 8.7717e-02 (1.0163e-01)	Acc@1  97.66 ( 96.34)	Acc@5 100.00 ( 99.97)
Epoch: [48][ 60/391]	Time  0.039 ( 0.043)	Data  0.001 ( 0.004)	Loss 1.0813e-01 (1.0200e-01)	Acc@1  96.09 ( 96.32)	Acc@5 100.00 ( 99.97)
Epoch: [48][ 70/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.003)	Loss 5.1223e-02 (9.8989e-02)	Acc@1  99.22 ( 96.48)	Acc@5 100.00 ( 99.98)
Epoch: [48][ 80/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.003)	Loss 8.6751e-02 (9.7686e-02)	Acc@1  97.66 ( 96.54)	Acc@5 100.00 ( 99.97)
Epoch: [48][ 90/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.003)	Loss 7.7219e-02 (9.7730e-02)	Acc@1  96.88 ( 96.58)	Acc@5 100.00 ( 99.97)
Epoch: [48][100/391]	Time  0.035 ( 0.041)	Data  0.001 ( 0.003)	Loss 6.0071e-02 (9.6970e-02)	Acc@1  97.66 ( 96.62)	Acc@5 100.00 ( 99.97)
Epoch: [48][110/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.4680e-01 (9.7213e-02)	Acc@1  93.75 ( 96.54)	Acc@5 100.00 ( 99.96)
Epoch: [48][120/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.2219e-01 (9.7640e-02)	Acc@1  94.53 ( 96.48)	Acc@5 100.00 ( 99.96)
Epoch: [48][130/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.1345e-01 (9.8847e-02)	Acc@1  96.88 ( 96.39)	Acc@5 100.00 ( 99.96)
Epoch: [48][140/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 8.6237e-02 (9.8831e-02)	Acc@1  96.09 ( 96.41)	Acc@5 100.00 ( 99.97)
Epoch: [48][150/391]	Time  0.036 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.0262e-02 (9.9045e-02)	Acc@1  98.44 ( 96.45)	Acc@5 100.00 ( 99.97)
Epoch: [48][160/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.4549e-01 (9.9052e-02)	Acc@1  96.09 ( 96.45)	Acc@5  99.22 ( 99.97)
Epoch: [48][170/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.6130e-02 (9.8706e-02)	Acc@1  99.22 ( 96.47)	Acc@5 100.00 ( 99.97)
Epoch: [48][180/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.0745e-01 (9.8580e-02)	Acc@1  96.88 ( 96.49)	Acc@5  99.22 ( 99.97)
Epoch: [48][190/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.0061e-01 (9.8604e-02)	Acc@1  96.09 ( 96.50)	Acc@5 100.00 ( 99.96)
Epoch: [48][200/391]	Time  0.037 ( 0.040)	Data  0.001 ( 0.002)	Loss 6.4050e-02 (9.7771e-02)	Acc@1  98.44 ( 96.53)	Acc@5 100.00 ( 99.97)
Epoch: [48][210/391]	Time  0.041 ( 0.040)	Data  0.001 ( 0.002)	Loss 1.0366e-01 (9.8170e-02)	Acc@1  97.66 ( 96.54)	Acc@5 100.00 ( 99.96)
Epoch: [48][220/391]	Time  0.039 ( 0.040)	Data  0.001 ( 0.002)	Loss 1.4461e-01 (9.7617e-02)	Acc@1  93.75 ( 96.56)	Acc@5 100.00 ( 99.96)
Epoch: [48][230/391]	Time  0.035 ( 0.040)	Data  0.001 ( 0.002)	Loss 6.3003e-02 (9.7137e-02)	Acc@1  97.66 ( 96.60)	Acc@5 100.00 ( 99.97)
Epoch: [48][240/391]	Time  0.043 ( 0.040)	Data  0.001 ( 0.002)	Loss 1.0334e-01 (9.7346e-02)	Acc@1  96.09 ( 96.61)	Acc@5 100.00 ( 99.97)
Epoch: [48][250/391]	Time  0.040 ( 0.040)	Data  0.001 ( 0.002)	Loss 1.1503e-01 (9.7846e-02)	Acc@1  95.31 ( 96.59)	Acc@5 100.00 ( 99.97)
Epoch: [48][260/391]	Time  0.041 ( 0.040)	Data  0.001 ( 0.002)	Loss 1.0185e-01 (9.7889e-02)	Acc@1  96.09 ( 96.60)	Acc@5 100.00 ( 99.97)
Epoch: [48][270/391]	Time  0.038 ( 0.040)	Data  0.001 ( 0.002)	Loss 2.0081e-01 (9.8054e-02)	Acc@1  92.97 ( 96.61)	Acc@5 100.00 ( 99.97)
Epoch: [48][280/391]	Time  0.041 ( 0.040)	Data  0.001 ( 0.002)	Loss 9.0957e-02 (9.8160e-02)	Acc@1  96.88 ( 96.61)	Acc@5 100.00 ( 99.97)
Epoch: [48][290/391]	Time  0.041 ( 0.040)	Data  0.001 ( 0.002)	Loss 1.0952e-01 (9.9006e-02)	Acc@1  96.88 ( 96.58)	Acc@5 100.00 ( 99.97)
Epoch: [48][300/391]	Time  0.039 ( 0.040)	Data  0.001 ( 0.002)	Loss 9.6179e-02 (9.9149e-02)	Acc@1  95.31 ( 96.56)	Acc@5 100.00 ( 99.97)
Epoch: [48][310/391]	Time  0.041 ( 0.040)	Data  0.001 ( 0.002)	Loss 1.5072e-01 (9.9954e-02)	Acc@1  97.66 ( 96.54)	Acc@5 100.00 ( 99.97)
Epoch: [48][320/391]	Time  0.039 ( 0.040)	Data  0.001 ( 0.002)	Loss 1.0763e-01 (1.0050e-01)	Acc@1  96.09 ( 96.51)	Acc@5 100.00 ( 99.98)
Epoch: [48][330/391]	Time  0.042 ( 0.040)	Data  0.001 ( 0.001)	Loss 1.0477e-01 (1.0095e-01)	Acc@1  95.31 ( 96.49)	Acc@5 100.00 ( 99.98)
Epoch: [48][340/391]	Time  0.041 ( 0.040)	Data  0.001 ( 0.001)	Loss 8.8654e-02 (1.0090e-01)	Acc@1  97.66 ( 96.49)	Acc@5 100.00 ( 99.98)
Epoch: [48][350/391]	Time  0.042 ( 0.040)	Data  0.001 ( 0.001)	Loss 7.1122e-02 (1.0149e-01)	Acc@1  97.66 ( 96.47)	Acc@5 100.00 ( 99.98)
Epoch: [48][360/391]	Time  0.038 ( 0.040)	Data  0.001 ( 0.001)	Loss 8.0060e-02 (1.0183e-01)	Acc@1  98.44 ( 96.47)	Acc@5 100.00 ( 99.97)
Epoch: [48][370/391]	Time  0.041 ( 0.040)	Data  0.001 ( 0.001)	Loss 1.0845e-01 (1.0256e-01)	Acc@1  94.53 ( 96.43)	Acc@5 100.00 ( 99.97)
Epoch: [48][380/391]	Time  0.041 ( 0.040)	Data  0.001 ( 0.001)	Loss 1.3480e-01 (1.0218e-01)	Acc@1  97.66 ( 96.45)	Acc@5 100.00 ( 99.97)
Epoch: [48][390/391]	Time  0.027 ( 0.040)	Data  0.001 ( 0.001)	Loss 1.7805e-01 (1.0250e-01)	Acc@1  95.00 ( 96.44)	Acc@5 100.00 ( 99.97)
## e[48] optimizer.zero_grad (sum) time: 0.2550647258758545
## e[48]       loss.backward (sum) time: 3.894984006881714
## e[48]      optimizer.step (sum) time: 1.7701032161712646
## epoch[48] training(only) time: 15.791494607925415
# Switched to evaluate mode...
Test: [  0/100]	Time  0.180 ( 0.180)	Loss 1.9114e-01 (1.9114e-01)	Acc@1  93.00 ( 93.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.021 ( 0.035)	Loss 5.1604e-01 (3.6113e-01)	Acc@1  87.00 ( 89.82)	Acc@5 100.00 ( 99.73)
Test: [ 20/100]	Time  0.021 ( 0.029)	Loss 3.8307e-01 (3.5978e-01)	Acc@1  85.00 ( 89.90)	Acc@5 100.00 ( 99.67)
Test: [ 30/100]	Time  0.018 ( 0.027)	Loss 4.3317e-01 (3.8189e-01)	Acc@1  88.00 ( 89.68)	Acc@5  99.00 ( 99.61)
Test: [ 40/100]	Time  0.016 ( 0.025)	Loss 3.4728e-01 (3.8259e-01)	Acc@1  88.00 ( 89.59)	Acc@5 100.00 ( 99.56)
Test: [ 50/100]	Time  0.020 ( 0.024)	Loss 1.6802e-01 (3.7410e-01)	Acc@1  94.00 ( 89.92)	Acc@5 100.00 ( 99.53)
Test: [ 60/100]	Time  0.018 ( 0.023)	Loss 4.0922e-01 (3.6711e-01)	Acc@1  91.00 ( 90.08)	Acc@5  98.00 ( 99.56)
Test: [ 70/100]	Time  0.017 ( 0.023)	Loss 3.3111e-01 (3.6223e-01)	Acc@1  91.00 ( 90.06)	Acc@5 100.00 ( 99.61)
Test: [ 80/100]	Time  0.021 ( 0.023)	Loss 2.1909e-01 (3.5602e-01)	Acc@1  92.00 ( 90.15)	Acc@5 100.00 ( 99.62)
Test: [ 90/100]	Time  0.017 ( 0.023)	Loss 1.9169e-01 (3.6095e-01)	Acc@1  93.00 ( 90.19)	Acc@5 100.00 ( 99.64)
 * Acc@1 90.180 Acc@5 99.660
### epoch[48] execution time: 18.115784168243408
EPOCH 49
REMOVING: module.fire2.squeeze.1.weight
REMOVING: module.fire2.squeeze.1.bias
REMOVING: module.fire2.expand_1x1.0.weight
i:   0, name: module.fire2.expand_1x1.0.bias  changing lr from: 0.001146036570688618   to: 0.001003963216179354
i:   1, name: module.fire2.expand_1x1.1.weight  changing lr from: 0.001241839946507955   to: 0.001030611670103475
i:   2, name: module.fire2.expand_1x1.1.bias  changing lr from: 0.001360353866001034   to: 0.001081728179421303
i:   3, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.001500862546882830   to: 0.001156588299572280
i:   4, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.001662659527519843   to: 0.001254475113278130
i:   5, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.001845048118569031   to: 0.001374679813205553
i:   6, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.002047341807437380   to: 0.001516502231403337
i:   7, name:  module.fire3.squeeze.0.weight  changing lr from: 0.002268864618232113   to: 0.001679251318357660
i:   8, name:    module.fire3.squeeze.0.bias  changing lr from: 0.002508951429765465   to: 0.001862245574405501
i:   9, name:  module.fire3.squeeze.1.weight  changing lr from: 0.002766948254072892   to: 0.002064813436142726
i:  10, name:    module.fire3.squeeze.1.bias  changing lr from: 0.003042212477801209   to: 0.002286293620361501
i:  11, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.003334113068722127   to: 0.002526035427951078
i:  12, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.003642030749528923   to: 0.002783399010096986
i:  13, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.003965358140977437   to: 0.003057755599016631
i:  14, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.004303499876339916   to: 0.003348487705374308
i:  15, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.004655872689048850   to: 0.003654989284425691
i:  16, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.005021905475320331   to: 0.003976665872851065
i:  17, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.005401039333460794   to: 0.004312934698148817
i:  18, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.005792727581478695   to: 0.004663224762374429
i:  19, name:  module.fire4.squeeze.0.weight  changing lr from: 0.006196435754542345   to: 0.005026976901927277
i:  20, name:    module.fire4.squeeze.0.bias  changing lr from: 0.006611641583748290   to: 0.005403643825006576
i:  21, name:  module.fire4.squeeze.1.weight  changing lr from: 0.007037834957590294   to: 0.005792690128279914
i:  22, name:    module.fire4.squeeze.1.bias  changing lr from: 0.007474517867447122   to: 0.006193592294232163
i:  23, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.007921204338338372   to: 0.006605838670589464
i:  24, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.008377420346131492   to: 0.007028929433142694
i:  25, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.008842703722319094   to: 0.007462376533227188
i:  26, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.009316604047424935   to: 0.007905703631049692
i:  27, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.009798682534038001   to: 0.008358446015991349
i:  28, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.010288511900418257   to: 0.008820150514954567
i:  29, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.010785676235563497   to: 0.009290375389764231
i:  30, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.011289770856575974   to: 0.009768690224577770
i:  31, name:  module.fire5.squeeze.0.weight  changing lr from: 0.011800402159117689   to: 0.010254675804205683
i:  32, name:    module.fire5.squeeze.0.bias  changing lr from: 0.012317187461696667   to: 0.010747923984192866
i:  33, name:  module.fire5.squeeze.1.weight  changing lr from: 0.012839754844481816   to: 0.011248037553462393
i:  34, name:    module.fire5.squeeze.1.bias  changing lr from: 0.013367742983301185   to: 0.011754630090277229
i:  35, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.013900800979437623   to: 0.012267325812229730
i:  36, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.014438588185797498   to: 0.012785759420927717
i:  37, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.014980774029990714   to: 0.013309575942003927
i:  38, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.015527037834826136   to: 0.013838430561038294
i:  39, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.016077068636691783   to: 0.014371988455944361
i:  40, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.016630565002259234   to: 0.014909924626337313
i:  41, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.017187234843920259   to: 0.015451923720366800
i:  42, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.017746795234335932   to: 0.015997679859466624
i:  43, name:  module.fire6.squeeze.0.weight  changing lr from: 0.018308972220451480   to: 0.016546896461442872
i:  44, name:    module.fire6.squeeze.0.bias  changing lr from: 0.018873500637304131   to: 0.017099286062293727
i:  45, name:  module.fire6.squeeze.1.weight  changing lr from: 0.019440123921927798   to: 0.017654570137126825
i:  46, name:    module.fire6.squeeze.1.bias  changing lr from: 0.020008593927634318   to: 0.018212478920514318
i:  47, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.020578670738930990   to: 0.018772751226601738
i:  48, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.021150122487312007   to: 0.019335134269263050
i:  49, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.021722725168143511   to: 0.019899383482573203
i:  50, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.022296262458842600   to: 0.020465262341847670
i:  51, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.022870525538534598   to: 0.021032542185480681
i:  52, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.023445312909355649   to: 0.021601002037793235
i:  53, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.024020430219553270   to: 0.022170428433086295
i:  54, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.024595690088522693   to: 0.022740615241077490
i:  55, name:  module.fire7.squeeze.0.weight  changing lr from: 0.025170911933903840   to: 0.023311363493883776
i:  56, name:    module.fire7.squeeze.0.bias  changing lr from: 0.025745921800850453   to: 0.023882481214698784
i:  57, name:  module.fire7.squeeze.1.weight  changing lr from: 0.026320552193571791   to: 0.024453783248298874
i:  58, name:    module.fire7.squeeze.1.bias  changing lr from: 0.026894641909235451   to: 0.025025091093499843
i:  59, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.027468035874310209   to: 0.025596232737673558
i:  60, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.028040584983417150   to: 0.026167042493422478
i:  61, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.028612145940749147   to: 0.026737360837499582
i:  62, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.029182581104109262   to: 0.027307034252050767
i:  63, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.029751758331611724   to: 0.027875915068247784
i:  64, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.030319550831080580   to: 0.028443861312370658
i:  65, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.030885837012175257   to: 0.029010736554390706
i:  66, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.031450500341265106   to: 0.029576409759096867
i:  67, name:  module.fire8.squeeze.0.weight  changing lr from: 0.032013429199069389   to: 0.030140755139801956
i:  68, name:    module.fire8.squeeze.0.bias  changing lr from: 0.032574516741073360   to: 0.030703652014657603
i:  69, name:  module.fire8.squeeze.1.weight  changing lr from: 0.033133660760726373   to: 0.031264984665601306
i:  70, name:    module.fire8.squeeze.1.bias  changing lr from: 0.033690763555422769   to: 0.031824642199952957
i:  71, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.034245731795261893   to: 0.032382518414672400
i:  72, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.034798476394580218   to: 0.032938511663285507
i:  73, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.035348912386243735   to: 0.033492524725480602
i:  74, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.035896958798686429   to: 0.034044464679373741
i:  75, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.036442538535676576   to: 0.034594242776436517
i:  76, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.036985578258790723   to: 0.035141774319077348
i:  77, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.037526008272571527   to: 0.035686978540863133
i:  78, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.038063762412344070   to: 0.036229778489365309
i:  79, name:  module.fire9.squeeze.0.weight  changing lr from: 0.038598777934662987   to: 0.036770100911611939
i:  80, name:    module.fire9.squeeze.0.bias  changing lr from: 0.039130995410360137   to: 0.037307876142124025
i:  81, name:  module.fire9.squeeze.1.weight  changing lr from: 0.039660358620161859   to: 0.037843037993513087
i:  82, name:    module.fire9.squeeze.1.bias  changing lr from: 0.040186814452842418   to: 0.038375523649613552
i:  83, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.040710312805879334   to: 0.038905273561123062
i:  84, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.041230806488574696   to: 0.039432231343720620
i:  85, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.041748251127606072   to: 0.039956343678632246
i:  86, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.042262605074968866   to: 0.040477560215611393
i:  87, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.042773829318272012   to: 0.040995833478300908
i:  88, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.043281887393347679   to: 0.041511118771941857
i:  89, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.043786745299134969   to: 0.042023374093393379
i:  90, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.044288371414797856   to: 0.042532560043427731
i:  91, name:           module.conv10.weight  changing lr from: 0.044786736419036501   to: 0.043038639741262923
i:  92, name:             module.conv10.bias  changing lr from: 0.045281813211551100   to: 0.043541578741295751



# Switched to train mode...
Epoch: [49][  0/391]	Time  0.204 ( 0.204)	Data  0.163 ( 0.163)	Loss 8.2072e-02 (8.2072e-02)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [49][ 10/391]	Time  0.041 ( 0.055)	Data  0.001 ( 0.016)	Loss 1.2226e-01 (1.1020e-01)	Acc@1  96.09 ( 96.24)	Acc@5 100.00 ( 99.93)
Epoch: [49][ 20/391]	Time  0.037 ( 0.048)	Data  0.001 ( 0.009)	Loss 4.7692e-02 (9.6736e-02)	Acc@1  98.44 ( 96.65)	Acc@5 100.00 ( 99.93)
Epoch: [49][ 30/391]	Time  0.040 ( 0.045)	Data  0.001 ( 0.006)	Loss 1.5508e-01 (9.4110e-02)	Acc@1  93.75 ( 96.75)	Acc@5 100.00 ( 99.95)
Epoch: [49][ 40/391]	Time  0.038 ( 0.044)	Data  0.001 ( 0.005)	Loss 6.4480e-02 (9.4658e-02)	Acc@1  97.66 ( 96.80)	Acc@5 100.00 ( 99.94)
Epoch: [49][ 50/391]	Time  0.038 ( 0.043)	Data  0.001 ( 0.004)	Loss 1.0368e-01 (9.4927e-02)	Acc@1  95.31 ( 96.69)	Acc@5 100.00 ( 99.95)
Epoch: [49][ 60/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.004)	Loss 1.6368e-01 (9.5845e-02)	Acc@1  94.53 ( 96.66)	Acc@5 100.00 ( 99.96)
Epoch: [49][ 70/391]	Time  0.041 ( 0.042)	Data  0.001 ( 0.003)	Loss 9.1052e-02 (9.6031e-02)	Acc@1  96.88 ( 96.63)	Acc@5 100.00 ( 99.97)
Epoch: [49][ 80/391]	Time  0.037 ( 0.041)	Data  0.001 ( 0.003)	Loss 6.8361e-02 (9.5251e-02)	Acc@1  96.09 ( 96.64)	Acc@5 100.00 ( 99.95)
Epoch: [49][ 90/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.003)	Loss 1.4202e-01 (9.5779e-02)	Acc@1  93.75 ( 96.64)	Acc@5 100.00 ( 99.96)
Epoch: [49][100/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.003)	Loss 1.2998e-01 (9.3758e-02)	Acc@1  95.31 ( 96.72)	Acc@5 100.00 ( 99.96)
Epoch: [49][110/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 5.3932e-02 (9.2688e-02)	Acc@1  99.22 ( 96.76)	Acc@5 100.00 ( 99.96)
Epoch: [49][120/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.002)	Loss 7.5525e-02 (9.3316e-02)	Acc@1  96.88 ( 96.73)	Acc@5 100.00 ( 99.97)
Epoch: [49][130/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 9.8529e-02 (9.4462e-02)	Acc@1  95.31 ( 96.64)	Acc@5 100.00 ( 99.97)
Epoch: [49][140/391]	Time  0.037 ( 0.040)	Data  0.001 ( 0.002)	Loss 3.9909e-02 (9.4085e-02)	Acc@1  98.44 ( 96.66)	Acc@5 100.00 ( 99.97)
Epoch: [49][150/391]	Time  0.037 ( 0.040)	Data  0.001 ( 0.002)	Loss 7.6964e-02 (9.3938e-02)	Acc@1  97.66 ( 96.65)	Acc@5 100.00 ( 99.97)
Epoch: [49][160/391]	Time  0.038 ( 0.040)	Data  0.001 ( 0.002)	Loss 1.0787e-01 (9.4356e-02)	Acc@1  96.88 ( 96.64)	Acc@5 100.00 ( 99.97)
Epoch: [49][170/391]	Time  0.039 ( 0.040)	Data  0.001 ( 0.002)	Loss 1.3294e-01 (9.5420e-02)	Acc@1  94.53 ( 96.58)	Acc@5 100.00 ( 99.97)
Epoch: [49][180/391]	Time  0.038 ( 0.040)	Data  0.001 ( 0.002)	Loss 6.0550e-02 (9.6011e-02)	Acc@1  97.66 ( 96.57)	Acc@5 100.00 ( 99.97)
Epoch: [49][190/391]	Time  0.041 ( 0.040)	Data  0.001 ( 0.002)	Loss 1.4310e-01 (9.5597e-02)	Acc@1  95.31 ( 96.58)	Acc@5 100.00 ( 99.97)
Epoch: [49][200/391]	Time  0.044 ( 0.040)	Data  0.001 ( 0.002)	Loss 9.2692e-02 (9.5629e-02)	Acc@1  96.09 ( 96.61)	Acc@5 100.00 ( 99.97)
Epoch: [49][210/391]	Time  0.040 ( 0.040)	Data  0.001 ( 0.002)	Loss 5.2174e-02 (9.5567e-02)	Acc@1  98.44 ( 96.60)	Acc@5 100.00 ( 99.97)
Epoch: [49][220/391]	Time  0.040 ( 0.040)	Data  0.001 ( 0.002)	Loss 1.1991e-01 (9.5643e-02)	Acc@1  96.09 ( 96.59)	Acc@5 100.00 ( 99.98)
Epoch: [49][230/391]	Time  0.042 ( 0.040)	Data  0.001 ( 0.002)	Loss 8.7469e-02 (9.6434e-02)	Acc@1  96.09 ( 96.56)	Acc@5 100.00 ( 99.98)
Epoch: [49][240/391]	Time  0.039 ( 0.040)	Data  0.001 ( 0.002)	Loss 1.7414e-01 (9.7200e-02)	Acc@1  92.19 ( 96.53)	Acc@5 100.00 ( 99.98)
Epoch: [49][250/391]	Time  0.039 ( 0.040)	Data  0.001 ( 0.002)	Loss 1.0580e-01 (9.7037e-02)	Acc@1  96.88 ( 96.55)	Acc@5 100.00 ( 99.98)
Epoch: [49][260/391]	Time  0.038 ( 0.040)	Data  0.001 ( 0.002)	Loss 8.2387e-02 (9.6933e-02)	Acc@1  96.09 ( 96.53)	Acc@5 100.00 ( 99.98)
Epoch: [49][270/391]	Time  0.037 ( 0.040)	Data  0.001 ( 0.002)	Loss 8.0112e-02 (9.7072e-02)	Acc@1  96.88 ( 96.52)	Acc@5 100.00 ( 99.98)
Epoch: [49][280/391]	Time  0.037 ( 0.040)	Data  0.001 ( 0.002)	Loss 5.1038e-02 (9.6886e-02)	Acc@1  99.22 ( 96.54)	Acc@5 100.00 ( 99.98)
Epoch: [49][290/391]	Time  0.040 ( 0.040)	Data  0.001 ( 0.002)	Loss 9.0369e-02 (9.7450e-02)	Acc@1  96.09 ( 96.51)	Acc@5 100.00 ( 99.98)
Epoch: [49][300/391]	Time  0.039 ( 0.040)	Data  0.001 ( 0.001)	Loss 7.2830e-02 (9.7350e-02)	Acc@1  98.44 ( 96.52)	Acc@5 100.00 ( 99.98)
Epoch: [49][310/391]	Time  0.038 ( 0.040)	Data  0.001 ( 0.001)	Loss 8.2324e-02 (9.7572e-02)	Acc@1  97.66 ( 96.50)	Acc@5 100.00 ( 99.98)
Epoch: [49][320/391]	Time  0.038 ( 0.040)	Data  0.001 ( 0.001)	Loss 9.7310e-02 (9.7407e-02)	Acc@1  95.31 ( 96.49)	Acc@5 100.00 ( 99.98)
Epoch: [49][330/391]	Time  0.041 ( 0.040)	Data  0.001 ( 0.001)	Loss 1.1494e-01 (9.7423e-02)	Acc@1  97.66 ( 96.50)	Acc@5 100.00 ( 99.98)
Epoch: [49][340/391]	Time  0.039 ( 0.040)	Data  0.001 ( 0.001)	Loss 7.1599e-02 (9.7231e-02)	Acc@1  96.88 ( 96.52)	Acc@5 100.00 ( 99.98)
Epoch: [49][350/391]	Time  0.037 ( 0.040)	Data  0.001 ( 0.001)	Loss 1.9532e-01 (9.7089e-02)	Acc@1  93.75 ( 96.54)	Acc@5 100.00 ( 99.98)
Epoch: [49][360/391]	Time  0.038 ( 0.040)	Data  0.001 ( 0.001)	Loss 6.4312e-02 (9.7070e-02)	Acc@1  99.22 ( 96.55)	Acc@5 100.00 ( 99.98)
Epoch: [49][370/391]	Time  0.041 ( 0.040)	Data  0.001 ( 0.001)	Loss 7.8768e-02 (9.7470e-02)	Acc@1  95.31 ( 96.54)	Acc@5 100.00 ( 99.98)
Epoch: [49][380/391]	Time  0.040 ( 0.040)	Data  0.001 ( 0.001)	Loss 6.0181e-02 (9.7437e-02)	Acc@1  97.66 ( 96.53)	Acc@5 100.00 ( 99.98)
Epoch: [49][390/391]	Time  0.028 ( 0.040)	Data  0.001 ( 0.001)	Loss 8.1627e-02 (9.7552e-02)	Acc@1  97.50 ( 96.53)	Acc@5 100.00 ( 99.98)
## e[49] optimizer.zero_grad (sum) time: 0.24650788307189941
## e[49]       loss.backward (sum) time: 3.8673717975616455
## e[49]      optimizer.step (sum) time: 1.6676068305969238
## epoch[49] training(only) time: 15.64337682723999
# Switched to evaluate mode...
Test: [  0/100]	Time  0.180 ( 0.180)	Loss 2.4989e-01 (2.4989e-01)	Acc@1  92.00 ( 92.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.018 ( 0.034)	Loss 5.1214e-01 (3.3182e-01)	Acc@1  88.00 ( 90.64)	Acc@5 100.00 ( 99.91)
Test: [ 20/100]	Time  0.023 ( 0.029)	Loss 4.2214e-01 (3.5897e-01)	Acc@1  87.00 ( 90.10)	Acc@5 100.00 ( 99.81)
Test: [ 30/100]	Time  0.018 ( 0.026)	Loss 3.9075e-01 (3.7364e-01)	Acc@1  89.00 ( 90.03)	Acc@5 100.00 ( 99.74)
Test: [ 40/100]	Time  0.021 ( 0.025)	Loss 3.6955e-01 (3.7984e-01)	Acc@1  88.00 ( 89.98)	Acc@5  98.00 ( 99.63)
Test: [ 50/100]	Time  0.017 ( 0.024)	Loss 1.0445e-01 (3.7944e-01)	Acc@1  99.00 ( 90.10)	Acc@5 100.00 ( 99.59)
Test: [ 60/100]	Time  0.018 ( 0.023)	Loss 3.8345e-01 (3.7387e-01)	Acc@1  92.00 ( 90.15)	Acc@5  99.00 ( 99.62)
Test: [ 70/100]	Time  0.017 ( 0.022)	Loss 3.6601e-01 (3.6740e-01)	Acc@1  85.00 ( 90.17)	Acc@5 100.00 ( 99.61)
Test: [ 80/100]	Time  0.022 ( 0.022)	Loss 2.6610e-01 (3.6306e-01)	Acc@1  93.00 ( 90.30)	Acc@5 100.00 ( 99.62)
Test: [ 90/100]	Time  0.019 ( 0.022)	Loss 2.5537e-01 (3.6753e-01)	Acc@1  93.00 ( 90.29)	Acc@5 100.00 ( 99.63)
 * Acc@1 90.270 Acc@5 99.640
### epoch[49] execution time: 17.925415992736816
EPOCH 50
REMOVING: module.fire2.expand_1x1.0.bias
REMOVING: module.fire2.expand_1x1.1.weight
REMOVING: module.fire2.expand_1x1.1.bias
i:   0, name: module.fire2.expand_3x3.0.weight  changing lr from: 0.001156588299572280   to: 0.001006942550728784
i:   1, name: module.fire2.expand_3x3.0.bias  changing lr from: 0.001254475113278130   to: 0.001037785884132180
i:   2, name: module.fire2.expand_3x3.1.weight  changing lr from: 0.001374679813205553   to: 0.001092644758309696
i:   3, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.001516502231403337   to: 0.001170810435569058
i:   4, name:  module.fire3.squeeze.0.weight  changing lr from: 0.001679251318357660   to: 0.001271581604418009
i:   5, name:    module.fire3.squeeze.0.bias  changing lr from: 0.001862245574405501   to: 0.001394264934276112
i:   6, name:  module.fire3.squeeze.1.weight  changing lr from: 0.002064813436142726   to: 0.001538175579515393
i:   7, name:    module.fire3.squeeze.1.bias  changing lr from: 0.002286293620361501   to: 0.001702637635527148
i:   8, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.002526035427951078   to: 0.001886984549413644
i:   9, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.002783399010096986   to: 0.002090559487805848
i:  10, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.003057755599016631   to: 0.002312715664211745
i:  11, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.003348487705374308   to: 0.002552816628204862
i:  12, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.003654989284425691   to: 0.002810236518668878
i:  13, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.003976665872851065   to: 0.003084360283222492
i:  14, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.004312934698148817   to: 0.003374583865858948
i:  15, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.004663224762374429   to: 0.003680314364746856
i:  16, name:  module.fire4.squeeze.0.weight  changing lr from: 0.005026976901927277   to: 0.004000970162053129
i:  17, name:    module.fire4.squeeze.0.bias  changing lr from: 0.005403643825006576   to: 0.004335981027565632
i:  18, name:  module.fire4.squeeze.1.weight  changing lr from: 0.005792690128279914   to: 0.004684788197811934
i:  19, name:    module.fire4.squeeze.1.bias  changing lr from: 0.006193592294232163   to: 0.005046844432292212
i:  20, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.006605838670589464   to: 0.005421614048367462
i:  21, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.007028929433142694   to: 0.005808572936270766
i:  22, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.007462376533227188   to: 0.006207208555637777
i:  23, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.007905703631049692   to: 0.006617019914883398
i:  24, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.008358446015991349   to: 0.007037517534685549
i:  25, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.008820150514954567   to: 0.007468223396771872
i:  26, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.009290375389764231   to: 0.007908670879144541
i:  27, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.009768690224577770   to: 0.008358404678817738
i:  28, name:  module.fire5.squeeze.0.weight  changing lr from: 0.010254675804205683   to: 0.008816980723086298
i:  29, name:    module.fire5.squeeze.0.bias  changing lr from: 0.010747923984192866   to: 0.009283966070288464
i:  30, name:  module.fire5.squeeze.1.weight  changing lr from: 0.011248037553462393   to: 0.009758938800973099
i:  31, name:    module.fire5.squeeze.1.bias  changing lr from: 0.011754630090277229   to: 0.010241487900331987
i:  32, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.012267325812229730   to: 0.010731213132708379
i:  33, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.012785759420927717   to: 0.011227724908947866
i:  34, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.013309575942003927   to: 0.011730644147312508
i:  35, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.013838430561038294   to: 0.012239602128637728
i:  36, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.014371988455944361   to: 0.012754240346370110
i:  37, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.014909924626337313   to: 0.013274210352087083
i:  38, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.015451923720366800   to: 0.013799173597061183
i:  39, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.015997679859466624   to: 0.014328801270398060
i:  40, name:  module.fire6.squeeze.0.weight  changing lr from: 0.016546896461442872   to: 0.014862774134243056
i:  41, name:    module.fire6.squeeze.0.bias  changing lr from: 0.017099286062293727   to: 0.015400782356520031
i:  42, name:  module.fire6.squeeze.1.weight  changing lr from: 0.017654570137126825   to: 0.015942525341635615
i:  43, name:    module.fire6.squeeze.1.bias  changing lr from: 0.018212478920514318   to: 0.016487711559553486
i:  44, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.018772751226601738   to: 0.017036058373616474
i:  45, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.019335134269263050   to: 0.017587291867467415
i:  46, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.019899383482573203   to: 0.018141146671396553
i:  47, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.020465262341847670   to: 0.018697365788418515
i:  48, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.021032542185480681   to: 0.019255700420361472
i:  49, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.021601002037793235   to: 0.019815909794228665
i:  50, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.022170428433086295   to: 0.020377760989073901
i:  51, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.022740615241077490   to: 0.020941028763613374
i:  52, name:  module.fire7.squeeze.0.weight  changing lr from: 0.023311363493883776   to: 0.021505495384778934
i:  53, name:    module.fire7.squeeze.0.bias  changing lr from: 0.023882481214698784   to: 0.022070950457400748
i:  54, name:  module.fire7.squeeze.1.weight  changing lr from: 0.024453783248298874   to: 0.022637190755192105
i:  55, name:    module.fire7.squeeze.1.bias  changing lr from: 0.025025091093499843   to: 0.023204020053193886
i:  56, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.025596232737673558   to: 0.023771248961822727
i:  57, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.026167042493422478   to: 0.024338694762652990
i:  58, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.026737360837499582   to: 0.024906181246051234
i:  59, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.027307034252050767   to: 0.025473538550769389
i:  60, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.027875915068247784   to: 0.026040603005592355
i:  61, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.028443861312370658   to: 0.026607216973125403
i:  62, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.029010736554390706   to: 0.027173228695797108
i:  63, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.029576409759096867   to: 0.027738492144144290
i:  64, name:  module.fire8.squeeze.0.weight  changing lr from: 0.030140755139801956   to: 0.028302866867437406
i:  65, name:    module.fire8.squeeze.0.bias  changing lr from: 0.030703652014657603   to: 0.028866217846696421
i:  66, name:  module.fire8.squeeze.1.weight  changing lr from: 0.031264984665601306   to: 0.029428415350140416
i:  67, name:    module.fire8.squeeze.1.bias  changing lr from: 0.031824642199952957   to: 0.029989334791106617
i:  68, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.032382518414672400   to: 0.030548856588468249
i:  69, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.032938511663285507   to: 0.031106866029575398
i:  70, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.033492524725480602   to: 0.031663253135735918
i:  71, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.034044464679373741   to: 0.032217912530250005
i:  72, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.034594242776436517   to: 0.032770743309005528
i:  73, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.035141774319077348   to: 0.033321648913638383
i:  74, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.035686978540863133   to: 0.033870537007256500
i:  75, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.036229778489365309   to: 0.034417319352723408
i:  76, name:  module.fire9.squeeze.0.weight  changing lr from: 0.036770100911611939   to: 0.034961911693493164
i:  77, name:    module.fire9.squeeze.0.bias  changing lr from: 0.037307876142124025   to: 0.035504233636985343
i:  78, name:  module.fire9.squeeze.1.weight  changing lr from: 0.037843037993513087   to: 0.036044208540485866
i:  79, name:    module.fire9.squeeze.1.bias  changing lr from: 0.038375523649613552   to: 0.036581763399556724
i:  80, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.038905273561123062   to: 0.037116828738934828
i:  81, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.039432231343720620   to: 0.037649338505898577
i:  82, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.039956343678632246   to: 0.038179229966077935
i:  83, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.040477560215611393   to: 0.038706443601682398
i:  84, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.040995833478300908   to: 0.039230923012119542
i:  85, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.041511118771941857   to: 0.039752614816974945
i:  86, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.042023374093393379   to: 0.040271468561323180
i:  87, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.042532560043427731   to: 0.040787436623338502
i:  88, name:           module.conv10.weight  changing lr from: 0.043038639741262923   to: 0.041300474124172454
i:  89, name:             module.conv10.bias  changing lr from: 0.043541578741295751   to: 0.041810538840064818



# Switched to train mode...
Epoch: [50][  0/391]	Time  0.215 ( 0.215)	Data  0.174 ( 0.174)	Loss 8.3450e-02 (8.3450e-02)	Acc@1  97.66 ( 97.66)	Acc@5 100.00 (100.00)
Epoch: [50][ 10/391]	Time  0.037 ( 0.055)	Data  0.001 ( 0.017)	Loss 8.7440e-02 (6.6000e-02)	Acc@1  97.66 ( 98.08)	Acc@5 100.00 (100.00)
Epoch: [50][ 20/391]	Time  0.041 ( 0.047)	Data  0.001 ( 0.009)	Loss 1.4934e-01 (7.6981e-02)	Acc@1  93.75 ( 97.51)	Acc@5 100.00 ( 99.96)
Epoch: [50][ 30/391]	Time  0.038 ( 0.045)	Data  0.001 ( 0.007)	Loss 6.4811e-02 (7.8886e-02)	Acc@1  98.44 ( 97.43)	Acc@5 100.00 ( 99.97)
Epoch: [50][ 40/391]	Time  0.037 ( 0.043)	Data  0.001 ( 0.005)	Loss 7.1811e-02 (8.2136e-02)	Acc@1  96.88 ( 97.28)	Acc@5 100.00 ( 99.98)
Epoch: [50][ 50/391]	Time  0.041 ( 0.043)	Data  0.001 ( 0.004)	Loss 1.1679e-01 (8.3195e-02)	Acc@1  96.09 ( 97.21)	Acc@5 100.00 ( 99.98)
Epoch: [50][ 60/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.004)	Loss 8.2087e-02 (8.3536e-02)	Acc@1  96.09 ( 97.22)	Acc@5 100.00 ( 99.99)
Epoch: [50][ 70/391]	Time  0.037 ( 0.042)	Data  0.001 ( 0.003)	Loss 5.0885e-02 (8.5107e-02)	Acc@1  97.66 ( 97.22)	Acc@5 100.00 ( 99.99)
Epoch: [50][ 80/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.003)	Loss 1.1046e-01 (8.5333e-02)	Acc@1  96.09 ( 97.16)	Acc@5 100.00 ( 99.99)
Epoch: [50][ 90/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.003)	Loss 9.1482e-02 (8.7554e-02)	Acc@1  97.66 ( 97.03)	Acc@5 100.00 ( 99.99)
Epoch: [50][100/391]	Time  0.041 ( 0.041)	Data  0.001 ( 0.003)	Loss 7.3909e-02 (8.6717e-02)	Acc@1  97.66 ( 97.06)	Acc@5 100.00 ( 99.99)
Epoch: [50][110/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.002)	Loss 2.8711e-02 (8.6890e-02)	Acc@1  99.22 ( 97.05)	Acc@5 100.00 ( 99.99)
Epoch: [50][120/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.002)	Loss 1.3288e-01 (8.7446e-02)	Acc@1  96.09 ( 97.04)	Acc@5 100.00 ( 99.99)
Epoch: [50][130/391]	Time  0.038 ( 0.040)	Data  0.001 ( 0.002)	Loss 6.3411e-02 (8.8345e-02)	Acc@1  97.66 ( 97.01)	Acc@5 100.00 ( 99.98)
Epoch: [50][140/391]	Time  0.041 ( 0.040)	Data  0.001 ( 0.002)	Loss 6.0546e-02 (8.8567e-02)	Acc@1  98.44 ( 97.02)	Acc@5 100.00 ( 99.98)
Epoch: [50][150/391]	Time  0.038 ( 0.040)	Data  0.001 ( 0.002)	Loss 8.7465e-02 (8.7351e-02)	Acc@1  96.09 ( 97.05)	Acc@5 100.00 ( 99.97)
Epoch: [50][160/391]	Time  0.038 ( 0.040)	Data  0.001 ( 0.002)	Loss 1.3718e-01 (8.7475e-02)	Acc@1  95.31 ( 97.03)	Acc@5 100.00 ( 99.98)
Epoch: [50][170/391]	Time  0.038 ( 0.040)	Data  0.001 ( 0.002)	Loss 6.6071e-02 (8.6310e-02)	Acc@1  96.88 ( 97.03)	Acc@5 100.00 ( 99.98)
Epoch: [50][180/391]	Time  0.038 ( 0.040)	Data  0.001 ( 0.002)	Loss 1.3040e-01 (8.7668e-02)	Acc@1  95.31 ( 96.97)	Acc@5 100.00 ( 99.98)
Epoch: [50][190/391]	Time  0.040 ( 0.040)	Data  0.001 ( 0.002)	Loss 2.1577e-02 (8.8014e-02)	Acc@1 100.00 ( 96.95)	Acc@5 100.00 ( 99.98)
Epoch: [50][200/391]	Time  0.037 ( 0.040)	Data  0.001 ( 0.002)	Loss 1.0811e-01 (8.8074e-02)	Acc@1  97.66 ( 96.98)	Acc@5 100.00 ( 99.98)
Epoch: [50][210/391]	Time  0.039 ( 0.040)	Data  0.001 ( 0.002)	Loss 7.2140e-02 (8.7686e-02)	Acc@1  96.88 ( 96.99)	Acc@5 100.00 ( 99.98)
Epoch: [50][220/391]	Time  0.045 ( 0.040)	Data  0.001 ( 0.002)	Loss 1.2728e-01 (8.8554e-02)	Acc@1  96.09 ( 96.95)	Acc@5 100.00 ( 99.98)
Epoch: [50][230/391]	Time  0.037 ( 0.040)	Data  0.001 ( 0.002)	Loss 1.1960e-01 (8.9446e-02)	Acc@1  96.88 ( 96.91)	Acc@5 100.00 ( 99.98)
Epoch: [50][240/391]	Time  0.040 ( 0.040)	Data  0.001 ( 0.002)	Loss 1.4634e-01 (9.0353e-02)	Acc@1  95.31 ( 96.86)	Acc@5 100.00 ( 99.98)
Epoch: [50][250/391]	Time  0.040 ( 0.040)	Data  0.001 ( 0.002)	Loss 8.4360e-02 (9.0311e-02)	Acc@1  97.66 ( 96.88)	Acc@5 100.00 ( 99.98)
Epoch: [50][260/391]	Time  0.040 ( 0.040)	Data  0.001 ( 0.002)	Loss 6.9831e-02 (9.0014e-02)	Acc@1  97.66 ( 96.88)	Acc@5 100.00 ( 99.98)
Epoch: [50][270/391]	Time  0.038 ( 0.040)	Data  0.001 ( 0.002)	Loss 7.5641e-02 (8.9948e-02)	Acc@1  96.88 ( 96.87)	Acc@5 100.00 ( 99.98)
Epoch: [50][280/391]	Time  0.038 ( 0.040)	Data  0.001 ( 0.002)	Loss 1.2104e-01 (9.0607e-02)	Acc@1  95.31 ( 96.84)	Acc@5 100.00 ( 99.98)
Epoch: [50][290/391]	Time  0.037 ( 0.040)	Data  0.001 ( 0.002)	Loss 4.1050e-02 (9.0171e-02)	Acc@1  99.22 ( 96.85)	Acc@5 100.00 ( 99.98)
Epoch: [50][300/391]	Time  0.041 ( 0.040)	Data  0.001 ( 0.002)	Loss 1.3513e-01 (8.9887e-02)	Acc@1  94.53 ( 96.86)	Acc@5 100.00 ( 99.98)
Epoch: [50][310/391]	Time  0.035 ( 0.040)	Data  0.001 ( 0.002)	Loss 9.2772e-02 (8.9793e-02)	Acc@1  96.09 ( 96.88)	Acc@5 100.00 ( 99.98)
Epoch: [50][320/391]	Time  0.041 ( 0.040)	Data  0.001 ( 0.002)	Loss 4.9725e-02 (9.0030e-02)	Acc@1  98.44 ( 96.87)	Acc@5 100.00 ( 99.98)
Epoch: [50][330/391]	Time  0.037 ( 0.040)	Data  0.001 ( 0.001)	Loss 3.1309e-02 (8.9819e-02)	Acc@1 100.00 ( 96.87)	Acc@5 100.00 ( 99.98)
Epoch: [50][340/391]	Time  0.040 ( 0.039)	Data  0.001 ( 0.001)	Loss 1.1756e-01 (8.9911e-02)	Acc@1  95.31 ( 96.87)	Acc@5 100.00 ( 99.98)
Epoch: [50][350/391]	Time  0.040 ( 0.039)	Data  0.001 ( 0.001)	Loss 6.4138e-02 (8.9937e-02)	Acc@1  96.88 ( 96.87)	Acc@5 100.00 ( 99.98)
Epoch: [50][360/391]	Time  0.041 ( 0.039)	Data  0.001 ( 0.001)	Loss 1.2196e-01 (9.0270e-02)	Acc@1  94.53 ( 96.86)	Acc@5 100.00 ( 99.98)
Epoch: [50][370/391]	Time  0.039 ( 0.039)	Data  0.001 ( 0.001)	Loss 1.1369e-01 (9.0445e-02)	Acc@1  93.75 ( 96.85)	Acc@5 100.00 ( 99.98)
Epoch: [50][380/391]	Time  0.038 ( 0.039)	Data  0.001 ( 0.001)	Loss 6.3572e-02 (9.0537e-02)	Acc@1  98.44 ( 96.84)	Acc@5 100.00 ( 99.98)
Epoch: [50][390/391]	Time  0.027 ( 0.039)	Data  0.001 ( 0.001)	Loss 1.4704e-01 (9.0728e-02)	Acc@1  95.00 ( 96.83)	Acc@5 100.00 ( 99.98)
## e[50] optimizer.zero_grad (sum) time: 0.24170565605163574
## e[50]       loss.backward (sum) time: 3.806922674179077
## e[50]      optimizer.step (sum) time: 1.665764570236206
## epoch[50] training(only) time: 15.519484519958496
# Switched to evaluate mode...
Test: [  0/100]	Time  0.164 ( 0.164)	Loss 2.5519e-01 (2.5519e-01)	Acc@1  94.00 ( 94.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.021 ( 0.032)	Loss 5.2281e-01 (3.3479e-01)	Acc@1  89.00 ( 90.64)	Acc@5 100.00 ( 99.73)
Test: [ 20/100]	Time  0.017 ( 0.027)	Loss 3.7580e-01 (3.6099e-01)	Acc@1  89.00 ( 90.38)	Acc@5 100.00 ( 99.57)
Test: [ 30/100]	Time  0.023 ( 0.024)	Loss 4.0213e-01 (3.8592e-01)	Acc@1  89.00 ( 90.23)	Acc@5  99.00 ( 99.58)
Test: [ 40/100]	Time  0.020 ( 0.023)	Loss 3.5201e-01 (3.9798e-01)	Acc@1  87.00 ( 89.95)	Acc@5  99.00 ( 99.49)
Test: [ 50/100]	Time  0.023 ( 0.022)	Loss 1.6015e-01 (3.9209e-01)	Acc@1  94.00 ( 89.88)	Acc@5 100.00 ( 99.51)
Test: [ 60/100]	Time  0.021 ( 0.022)	Loss 4.1430e-01 (3.8252e-01)	Acc@1  90.00 ( 89.93)	Acc@5  99.00 ( 99.54)
Test: [ 70/100]	Time  0.023 ( 0.022)	Loss 3.5944e-01 (3.7159e-01)	Acc@1  89.00 ( 90.10)	Acc@5 100.00 ( 99.59)
Test: [ 80/100]	Time  0.022 ( 0.022)	Loss 1.9578e-01 (3.6613e-01)	Acc@1  94.00 ( 90.16)	Acc@5 100.00 ( 99.62)
Test: [ 90/100]	Time  0.020 ( 0.022)	Loss 2.3477e-01 (3.7044e-01)	Acc@1  94.00 ( 90.22)	Acc@5 100.00 ( 99.62)
 * Acc@1 90.230 Acc@5 99.630
### epoch[50] execution time: 17.78074812889099
EPOCH 51
REMOVING: module.fire2.expand_3x3.0.weight
REMOVING: module.fire2.expand_3x3.0.bias
REMOVING: module.fire2.expand_3x3.1.weight
i:   0, name: module.fire2.expand_3x3.1.bias  changing lr from: 0.001170810435569058   to: 0.001011559862627930
i:   1, name:  module.fire3.squeeze.0.weight  changing lr from: 0.001271581604418009   to: 0.001047359364565991
i:   2, name:    module.fire3.squeeze.0.bias  changing lr from: 0.001394264934276112   to: 0.001106711661655290
i:   3, name:  module.fire3.squeeze.1.weight  changing lr from: 0.001538175579515393   to: 0.001188923373088107
i:   4, name:    module.fire3.squeeze.1.bias  changing lr from: 0.001702637635527148   to: 0.001293308465133696
i:   5, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.001886984549413644   to: 0.001419188777786306
i:   6, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.002090559487805848   to: 0.001565894503229025
i:   7, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.002312715664211745   to: 0.001732764618670573
i:   8, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.002552816628204862   to: 0.001919147276018989
i:   9, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.002810236518668878   to: 0.002124400150763566
i:  10, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.003084360283222492   to: 0.002347890752345121
i:  11, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.003374583865858948   to: 0.002588996698204804
i:  12, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.003680314364746856   to: 0.002847105953613054
i:  13, name:  module.fire4.squeeze.0.weight  changing lr from: 0.004000970162053129   to: 0.003121617039293655
i:  14, name:    module.fire4.squeeze.0.bias  changing lr from: 0.004335981027565632   to: 0.003411939208772712
i:  15, name:  module.fire4.squeeze.1.weight  changing lr from: 0.004684788197811934   to: 0.003717492597299659
i:  16, name:    module.fire4.squeeze.1.bias  changing lr from: 0.005046844432292212   to: 0.004037708344106349
i:  17, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.005421614048367462   to: 0.004372028689691309
i:  18, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.005808572936270766   to: 0.004719907049739935
i:  19, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.006207208555637777   to: 0.005080808067216702
i:  20, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.006617019914883398   to: 0.005454207644093616
i:  21, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.007037517534685549   to: 0.005839592954109029
i:  22, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.007468223396771872   to: 0.006236462437883682
i:  23, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.007908670879144541   to: 0.006644325781655269
i:  24, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.008358404678817738   to: 0.007062703880830145
i:  25, name:  module.fire5.squeeze.0.weight  changing lr from: 0.008816980723086298   to: 0.007491128789489964
i:  26, name:    module.fire5.squeeze.0.bias  changing lr from: 0.009283966070288464   to: 0.007929143656932569
i:  27, name:  module.fire5.squeeze.1.weight  changing lr from: 0.009758938800973099   to: 0.008376302652270174
i:  28, name:    module.fire5.squeeze.1.bias  changing lr from: 0.010241487900331987   to: 0.008832170878054161
i:  29, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.010731213132708379   to: 0.009296324273843276
i:  30, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.011227724908947866   to: 0.009768349510582728
i:  31, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.011730644147312508   to: 0.010247843876613798
i:  32, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.012239602128637728   to: 0.010734415156087695
i:  33, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.012754240346370110   to: 0.011227681500513502
i:  34, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.013274210352087083   to: 0.011727271294128667
i:  35, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.013799173597061183   to: 0.012232823013739496
i:  36, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.014328801270398060   to: 0.012743985083642016
i:  37, name:  module.fire6.squeeze.0.weight  changing lr from: 0.014862774134243056   to: 0.013260415726195941
i:  38, name:    module.fire6.squeeze.0.bias  changing lr from: 0.015400782356520031   to: 0.013781782808590558
i:  39, name:  module.fire6.squeeze.1.weight  changing lr from: 0.015942525341635615   to: 0.014307763686307439
i:  40, name:    module.fire6.squeeze.1.bias  changing lr from: 0.016487711559553486   to: 0.014838045043753339
i:  41, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.017036058373616474   to: 0.015372322732507465
i:  42, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.017587291867467415   to: 0.015910301607596867
i:  43, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.018141146671396553   to: 0.016451695362188341
i:  44, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.018697365788418515   to: 0.016996226361057822
i:  45, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.019255700420361472   to: 0.017543625473174812
i:  46, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.019815909794228665   to: 0.018093631903715265
i:  47, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.020377760989073901   to: 0.018645993025794477
i:  48, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.020941028763613374   to: 0.019200464212190679
i:  49, name:  module.fire7.squeeze.0.weight  changing lr from: 0.021505495384778934   to: 0.019756808667310208
i:  50, name:    module.fire7.squeeze.0.bias  changing lr from: 0.022070950457400748   to: 0.020314797259625962
i:  51, name:  module.fire7.squeeze.1.weight  changing lr from: 0.022637190755192105   to: 0.020874208354803320
i:  52, name:    module.fire7.squeeze.1.bias  changing lr from: 0.023204020053193886   to: 0.021434827649710886
i:  53, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.023771248961822727   to: 0.021996448007497574
i:  54, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.024338694762652990   to: 0.022558869293902148
i:  55, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.024906181246051234   to: 0.023121898214947964
i:  56, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.025473538550769389   to: 0.023685348156161214
i:  57, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.026040603005592355   to: 0.024249039023439580
i:  58, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.026607216973125403   to: 0.024812797085685352
i:  59, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.027173228695797108   to: 0.025376454819306678
i:  60, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.027738492144144290   to: 0.025939850754679444
i:  61, name:  module.fire8.squeeze.0.weight  changing lr from: 0.028302866867437406   to: 0.026502829324653310
i:  62, name:    module.fire8.squeeze.0.bias  changing lr from: 0.028866217846696421   to: 0.027065240715175101
i:  63, name:  module.fire8.squeeze.1.weight  changing lr from: 0.029428415350140416   to: 0.027626940718095051
i:  64, name:    module.fire8.squeeze.1.bias  changing lr from: 0.029989334791106617   to: 0.028187790586213068
i:  65, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.030548856588468249   to: 0.028747656890613694
i:  66, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.031106866029575398   to: 0.029306411380332908
i:  67, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.031663253135735918   to: 0.029863930844391842
i:  68, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.032217912530250005   to: 0.030420096976227107
i:  69, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.032770743309005528   to: 0.030974796240541159
i:  70, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.033321648913638383   to: 0.031527919742591365
i:  71, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.033870537007256500   to: 0.032079363099930550
i:  72, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.034417319352723408   to: 0.032629026316608058
i:  73, name:  module.fire9.squeeze.0.weight  changing lr from: 0.034961911693493164   to: 0.033176813659835373
i:  74, name:    module.fire9.squeeze.0.bias  changing lr from: 0.035504233636985343   to: 0.033722633539116580
i:  75, name:  module.fire9.squeeze.1.weight  changing lr from: 0.036044208540485866   to: 0.034266398387840458
i:  76, name:    module.fire9.squeeze.1.bias  changing lr from: 0.036581763399556724   to: 0.034808024547327114
i:  77, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.037116828738934828   to: 0.035347432153319404
i:  78, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.037649338505898577   to: 0.035884545024906074
i:  79, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.038179229966077935   to: 0.036419290555861371
i:  80, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.038706443601682398   to: 0.036951599608382624
i:  81, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.039230923012119542   to: 0.037481406409206351
i:  82, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.039752614816974945   to: 0.038008648448080058
i:  83, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.040271468561323180   to: 0.038533266378565835
i:  84, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.040787436623338502   to: 0.039055203921150181
i:  85, name:           module.conv10.weight  changing lr from: 0.041300474124172454   to: 0.039574407768632781
i:  86, name:             module.conv10.bias  changing lr from: 0.041810538840064818   to: 0.040090827493765489



# Switched to train mode...
Epoch: [51][  0/391]	Time  0.214 ( 0.214)	Data  0.169 ( 0.169)	Loss 7.9398e-02 (7.9398e-02)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [51][ 10/391]	Time  0.037 ( 0.054)	Data  0.001 ( 0.016)	Loss 5.6858e-02 (7.1069e-02)	Acc@1  97.66 ( 97.73)	Acc@5 100.00 (100.00)
Epoch: [51][ 20/391]	Time  0.038 ( 0.048)	Data  0.001 ( 0.009)	Loss 7.4201e-02 (8.2545e-02)	Acc@1  98.44 ( 97.40)	Acc@5 100.00 (100.00)
Epoch: [51][ 30/391]	Time  0.037 ( 0.045)	Data  0.001 ( 0.006)	Loss 2.3244e-01 (8.6205e-02)	Acc@1  94.53 ( 97.33)	Acc@5 100.00 (100.00)
Epoch: [51][ 40/391]	Time  0.039 ( 0.043)	Data  0.001 ( 0.005)	Loss 4.5867e-02 (8.4631e-02)	Acc@1  97.66 ( 97.22)	Acc@5 100.00 (100.00)
Epoch: [51][ 50/391]	Time  0.037 ( 0.042)	Data  0.001 ( 0.004)	Loss 8.4463e-02 (8.4311e-02)	Acc@1  96.88 ( 97.18)	Acc@5 100.00 (100.00)
Epoch: [51][ 60/391]	Time  0.037 ( 0.042)	Data  0.001 ( 0.004)	Loss 1.0171e-01 (8.2567e-02)	Acc@1  96.09 ( 97.27)	Acc@5 100.00 (100.00)
Epoch: [51][ 70/391]	Time  0.037 ( 0.041)	Data  0.001 ( 0.003)	Loss 1.0911e-01 (8.2298e-02)	Acc@1  95.31 ( 97.28)	Acc@5 100.00 (100.00)
Epoch: [51][ 80/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.003)	Loss 1.1133e-01 (8.2154e-02)	Acc@1  96.09 ( 97.26)	Acc@5 100.00 (100.00)
Epoch: [51][ 90/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.003)	Loss 1.2832e-01 (8.2761e-02)	Acc@1  97.66 ( 97.28)	Acc@5 100.00 (100.00)
Epoch: [51][100/391]	Time  0.037 ( 0.041)	Data  0.001 ( 0.003)	Loss 1.3093e-01 (8.3216e-02)	Acc@1  96.88 ( 97.25)	Acc@5  99.22 ( 99.99)
Epoch: [51][110/391]	Time  0.045 ( 0.040)	Data  0.001 ( 0.002)	Loss 8.7880e-02 (8.2149e-02)	Acc@1  97.66 ( 97.28)	Acc@5 100.00 ( 99.99)
Epoch: [51][120/391]	Time  0.037 ( 0.040)	Data  0.001 ( 0.002)	Loss 1.0970e-01 (8.3422e-02)	Acc@1  96.09 ( 97.28)	Acc@5 100.00 ( 99.99)
Epoch: [51][130/391]	Time  0.039 ( 0.040)	Data  0.001 ( 0.002)	Loss 4.5776e-02 (8.1809e-02)	Acc@1  98.44 ( 97.32)	Acc@5 100.00 ( 99.99)
Epoch: [51][140/391]	Time  0.037 ( 0.040)	Data  0.001 ( 0.002)	Loss 6.9569e-02 (8.1811e-02)	Acc@1  96.88 ( 97.32)	Acc@5 100.00 ( 99.99)
Epoch: [51][150/391]	Time  0.035 ( 0.040)	Data  0.001 ( 0.002)	Loss 6.0624e-02 (8.2230e-02)	Acc@1  97.66 ( 97.30)	Acc@5 100.00 ( 99.99)
Epoch: [51][160/391]	Time  0.038 ( 0.040)	Data  0.000 ( 0.002)	Loss 7.6631e-02 (8.2013e-02)	Acc@1  97.66 ( 97.31)	Acc@5 100.00 ( 99.99)
Epoch: [51][170/391]	Time  0.037 ( 0.040)	Data  0.001 ( 0.002)	Loss 1.1437e-01 (8.2177e-02)	Acc@1  96.09 ( 97.32)	Acc@5 100.00 ( 99.99)
Epoch: [51][180/391]	Time  0.040 ( 0.040)	Data  0.001 ( 0.002)	Loss 6.2675e-02 (8.0872e-02)	Acc@1  97.66 ( 97.38)	Acc@5 100.00 ( 99.98)
Epoch: [51][190/391]	Time  0.038 ( 0.040)	Data  0.001 ( 0.002)	Loss 7.8367e-02 (8.1590e-02)	Acc@1  98.44 ( 97.35)	Acc@5 100.00 ( 99.98)
Epoch: [51][200/391]	Time  0.042 ( 0.040)	Data  0.001 ( 0.002)	Loss 1.3958e-01 (8.1867e-02)	Acc@1  94.53 ( 97.33)	Acc@5 100.00 ( 99.98)
Epoch: [51][210/391]	Time  0.037 ( 0.040)	Data  0.001 ( 0.002)	Loss 4.2107e-02 (8.2325e-02)	Acc@1  99.22 ( 97.30)	Acc@5 100.00 ( 99.98)
Epoch: [51][220/391]	Time  0.038 ( 0.040)	Data  0.001 ( 0.002)	Loss 9.6520e-02 (8.2519e-02)	Acc@1  96.09 ( 97.29)	Acc@5 100.00 ( 99.98)
Epoch: [51][230/391]	Time  0.037 ( 0.040)	Data  0.001 ( 0.002)	Loss 1.2486e-01 (8.3223e-02)	Acc@1  96.09 ( 97.26)	Acc@5 100.00 ( 99.98)
Epoch: [51][240/391]	Time  0.038 ( 0.039)	Data  0.001 ( 0.002)	Loss 1.8004e-01 (8.3772e-02)	Acc@1  94.53 ( 97.24)	Acc@5 100.00 ( 99.98)
Epoch: [51][250/391]	Time  0.038 ( 0.039)	Data  0.001 ( 0.002)	Loss 6.1936e-02 (8.3349e-02)	Acc@1  99.22 ( 97.27)	Acc@5 100.00 ( 99.98)
Epoch: [51][260/391]	Time  0.038 ( 0.039)	Data  0.001 ( 0.002)	Loss 4.1597e-02 (8.3270e-02)	Acc@1 100.00 ( 97.26)	Acc@5 100.00 ( 99.99)
Epoch: [51][270/391]	Time  0.037 ( 0.039)	Data  0.001 ( 0.002)	Loss 7.4863e-02 (8.4025e-02)	Acc@1  97.66 ( 97.25)	Acc@5 100.00 ( 99.98)
Epoch: [51][280/391]	Time  0.039 ( 0.039)	Data  0.001 ( 0.002)	Loss 1.9366e-01 (8.3980e-02)	Acc@1  93.75 ( 97.24)	Acc@5 100.00 ( 99.98)
Epoch: [51][290/391]	Time  0.043 ( 0.039)	Data  0.001 ( 0.002)	Loss 1.0393e-01 (8.4781e-02)	Acc@1  95.31 ( 97.22)	Acc@5 100.00 ( 99.98)
Epoch: [51][300/391]	Time  0.037 ( 0.039)	Data  0.001 ( 0.002)	Loss 9.1535e-02 (8.4402e-02)	Acc@1  96.09 ( 97.23)	Acc@5 100.00 ( 99.98)
Epoch: [51][310/391]	Time  0.038 ( 0.039)	Data  0.001 ( 0.001)	Loss 5.6733e-02 (8.4611e-02)	Acc@1  99.22 ( 97.21)	Acc@5 100.00 ( 99.98)
Epoch: [51][320/391]	Time  0.039 ( 0.039)	Data  0.001 ( 0.001)	Loss 5.9883e-02 (8.4148e-02)	Acc@1  98.44 ( 97.23)	Acc@5 100.00 ( 99.98)
Epoch: [51][330/391]	Time  0.038 ( 0.039)	Data  0.001 ( 0.001)	Loss 5.7713e-02 (8.3580e-02)	Acc@1  98.44 ( 97.25)	Acc@5 100.00 ( 99.98)
Epoch: [51][340/391]	Time  0.052 ( 0.039)	Data  0.001 ( 0.001)	Loss 5.9113e-02 (8.3544e-02)	Acc@1  98.44 ( 97.24)	Acc@5 100.00 ( 99.98)
Epoch: [51][350/391]	Time  0.037 ( 0.039)	Data  0.001 ( 0.001)	Loss 8.1962e-02 (8.4235e-02)	Acc@1  96.09 ( 97.22)	Acc@5 100.00 ( 99.98)
Epoch: [51][360/391]	Time  0.039 ( 0.039)	Data  0.001 ( 0.001)	Loss 8.5110e-02 (8.4329e-02)	Acc@1  97.66 ( 97.22)	Acc@5 100.00 ( 99.98)
Epoch: [51][370/391]	Time  0.043 ( 0.039)	Data  0.001 ( 0.001)	Loss 4.8789e-02 (8.4187e-02)	Acc@1  98.44 ( 97.22)	Acc@5 100.00 ( 99.97)
Epoch: [51][380/391]	Time  0.041 ( 0.039)	Data  0.001 ( 0.001)	Loss 5.6757e-02 (8.4101e-02)	Acc@1  99.22 ( 97.21)	Acc@5 100.00 ( 99.98)
Epoch: [51][390/391]	Time  0.026 ( 0.039)	Data  0.001 ( 0.001)	Loss 3.7107e-02 (8.4496e-02)	Acc@1 100.00 ( 97.18)	Acc@5 100.00 ( 99.98)
## e[51] optimizer.zero_grad (sum) time: 0.23268556594848633
## e[51]       loss.backward (sum) time: 3.830204725265503
## e[51]      optimizer.step (sum) time: 1.5993847846984863
## epoch[51] training(only) time: 15.42130970954895
# Switched to evaluate mode...
Test: [  0/100]	Time  0.182 ( 0.182)	Loss 2.6638e-01 (2.6638e-01)	Acc@1  92.00 ( 92.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.022 ( 0.037)	Loss 5.7462e-01 (3.7598e-01)	Acc@1  88.00 ( 90.91)	Acc@5 100.00 (100.00)
Test: [ 20/100]	Time  0.021 ( 0.029)	Loss 3.9708e-01 (3.9142e-01)	Acc@1  87.00 ( 90.14)	Acc@5  99.00 ( 99.71)
Test: [ 30/100]	Time  0.016 ( 0.026)	Loss 4.7776e-01 (4.0313e-01)	Acc@1  88.00 ( 90.00)	Acc@5  99.00 ( 99.58)
Test: [ 40/100]	Time  0.017 ( 0.024)	Loss 3.9090e-01 (4.1224e-01)	Acc@1  87.00 ( 89.93)	Acc@5  99.00 ( 99.51)
Test: [ 50/100]	Time  0.018 ( 0.024)	Loss 1.3849e-01 (4.1158e-01)	Acc@1  96.00 ( 90.02)	Acc@5 100.00 ( 99.53)
Test: [ 60/100]	Time  0.018 ( 0.023)	Loss 4.6893e-01 (4.0282e-01)	Acc@1  90.00 ( 90.02)	Acc@5  99.00 ( 99.56)
Test: [ 70/100]	Time  0.021 ( 0.023)	Loss 4.3909e-01 (3.9380e-01)	Acc@1  87.00 ( 90.04)	Acc@5 100.00 ( 99.55)
Test: [ 80/100]	Time  0.021 ( 0.022)	Loss 2.0190e-01 (3.8782e-01)	Acc@1  93.00 ( 90.14)	Acc@5 100.00 ( 99.57)
Test: [ 90/100]	Time  0.020 ( 0.022)	Loss 2.0686e-01 (3.9218e-01)	Acc@1  94.00 ( 90.10)	Acc@5 100.00 ( 99.59)
 * Acc@1 90.070 Acc@5 99.610
### epoch[51] execution time: 17.75625205039978
EPOCH 52
REMOVING: module.fire2.expand_3x3.1.bias
REMOVING: module.fire3.squeeze.0.weight
i:   0, name:    module.fire3.squeeze.0.bias  changing lr from: 0.001106711661655290   to: 0.001000631653351713
i:   1, name:  module.fire3.squeeze.1.weight  changing lr from: 0.001188923373088107   to: 0.001018309345057027
i:   2, name:    module.fire3.squeeze.1.bias  changing lr from: 0.001293308465133696   to: 0.001059753591295991
i:   3, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.001419188777786306   to: 0.001124279298084823
i:   4, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.001565894503229025   to: 0.001211208110764027
i:   5, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.001732764618670573   to: 0.001319868960940767
i:   6, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.001919147276018989   to: 0.001449598565149456
i:   7, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.002124400150763566   to: 0.001599741877743076
i:   8, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.002347890752345121   to: 0.001769652500438500
i:   9, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.002588996698204804   to: 0.001958693050850917
i:  10, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.002847105953613054   to: 0.002166235492264739
i:  11, name:  module.fire4.squeeze.0.weight  changing lr from: 0.003121617039293655   to: 0.002391661426801899
i:  12, name:    module.fire4.squeeze.0.bias  changing lr from: 0.003411939208772712   to: 0.002634362354063446
i:  13, name:  module.fire4.squeeze.1.weight  changing lr from: 0.003717492597299659   to: 0.002893739897236396
i:  14, name:    module.fire4.squeeze.1.bias  changing lr from: 0.004037708344106349   to: 0.003169205998576124
i:  15, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.004372028689691309   to: 0.003460183086093754
i:  16, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.004719907049739935   to: 0.003766104213200105
i:  17, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.005080808067216702   to: 0.004086413172980746
i:  18, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.005454207644093616   to: 0.004420564588702624
i:  19, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.005839592954109029   to: 0.004768023982080077
i:  20, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.006236462437883682   to: 0.005128267820757758
i:  21, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.006644325781655269   to: 0.005500783546400028
i:  22, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.007062703880830145   to: 0.005885069584709973
i:  23, name:  module.fire5.squeeze.0.weight  changing lr from: 0.007491128789489964   to: 0.006280635338637907
i:  24, name:    module.fire5.squeeze.0.bias  changing lr from: 0.007929143656932569   to: 0.006687001165977063
i:  25, name:  module.fire5.squeeze.1.weight  changing lr from: 0.008376302652270174   to: 0.007103698342484787
i:  26, name:    module.fire5.squeeze.1.bias  changing lr from: 0.008832170878054161   to: 0.007530269011610562
i:  27, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.009296324273843276   to: 0.007966266121855975
i:  28, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.009768349510582728   to: 0.008411253352739890
i:  29, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.010247843876613798   to: 0.008864805030289451
i:  30, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.010734415156087695   to: 0.009326506032930008
i:  31, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.011227681500513502   to: 0.009795951688598342
i:  32, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.011727271294128667   to: 0.010272747663859650
i:  33, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.012232823013739496   to: 0.010756509845764678
i:  34, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.012743985083642016   to: 0.011246864217142171
i:  35, name:  module.fire6.squeeze.0.weight  changing lr from: 0.013260415726195941   to: 0.011743446725982216
i:  36, name:    module.fire6.squeeze.0.bias  changing lr from: 0.013781782808590558   to: 0.012245903149527761
i:  37, name:  module.fire6.squeeze.1.weight  changing lr from: 0.014307763686307439   to: 0.012753888953655795
i:  38, name:    module.fire6.squeeze.1.bias  changing lr from: 0.014838045043753339   to: 0.013267069148094536
i:  39, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.015372322732507465   to: 0.013785118137990621
i:  40, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.015910301607596867   to: 0.014307719572307948
i:  41, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.016451695362188341   to: 0.014834566189510741
i:  42, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.016996226361057822   to: 0.015365359660953655
i:  43, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.017543625473174812   to: 0.015899810432376243
i:  44, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.018093631903715265   to: 0.016437637563871187
i:  45, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.018645993025794477   to: 0.016978568568672636
i:  46, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.019200464212190679   to: 0.017522339251087204
i:  47, name:  module.fire7.squeeze.0.weight  changing lr from: 0.019756808667310208   to: 0.018068693543867625
i:  48, name:    module.fire7.squeeze.0.bias  changing lr from: 0.020314797259625962   to: 0.018617383345308613
i:  49, name:  module.fire7.squeeze.1.weight  changing lr from: 0.020874208354803320   to: 0.019168168356324077
i:  50, name:    module.fire7.squeeze.1.bias  changing lr from: 0.021434827649710886   to: 0.019720815917745993
i:  51, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.021996448007497574   to: 0.020275100848067714
i:  52, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.022558869293902148   to: 0.020830805281837006
i:  53, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.023121898214947964   to: 0.021387718508888667
i:  54, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.023685348156161214   to: 0.021945636814590504
i:  55, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.024249039023439580   to: 0.022504363321263595
i:  56, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.024812797085685352   to: 0.023063707830922597
i:  57, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.025376454819306678   to: 0.023623486669470607
i:  58, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.025939850754679444   to: 0.024183522532469817
i:  59, name:  module.fire8.squeeze.0.weight  changing lr from: 0.026502829324653310   to: 0.024743644332598992
i:  60, name:    module.fire8.squeeze.0.bias  changing lr from: 0.027065240715175101   to: 0.025303687048897124
i:  61, name:  module.fire8.squeeze.1.weight  changing lr from: 0.027626940718095051   to: 0.025863491577883681
i:  62, name:    module.fire8.squeeze.1.bias  changing lr from: 0.028187790586213068   to: 0.026422904586635421
i:  63, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.028747656890613694   to: 0.026981778367891465
i:  64, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.029306411380332908   to: 0.027539970697250199
i:  65, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.029863930844391842   to: 0.028097344692513196
i:  66, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.030420096976227107   to: 0.028653768675224435
i:  67, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.030974796240541159   to: 0.029209116034446477
i:  68, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.031527919742591365   to: 0.029763265092808334
i:  69, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.032079363099930550   to: 0.030316098974854357
i:  70, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.032629026316608058   to: 0.030867505477717400
i:  71, name:  module.fire9.squeeze.0.weight  changing lr from: 0.033176813659835373   to: 0.031417376944134996
i:  72, name:    module.fire9.squeeze.0.bias  changing lr from: 0.033722633539116580   to: 0.031965610137821607
i:  73, name:  module.fire9.squeeze.1.weight  changing lr from: 0.034266398387840458   to: 0.032512106121206419
i:  74, name:    module.fire9.squeeze.1.bias  changing lr from: 0.034808024547327114   to: 0.033056770135541223
i:  75, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.035347432153319404   to: 0.033599511483379731
i:  76, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.035884545024906074   to: 0.034140243413425482
i:  77, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.036419290555861371   to: 0.034678883007742745
i:  78, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.036951599608382624   to: 0.035215351071321267
i:  79, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.037481406409206351   to: 0.035749572023983510
i:  80, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.038008648448080058   to: 0.036281473794619865
i:  81, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.038533266378565835   to: 0.036810987717735159
i:  82, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.039055203921150181   to: 0.037338048432287961
i:  83, name:           module.conv10.weight  changing lr from: 0.039574407768632781   to: 0.037862593782801622
i:  84, name:             module.conv10.bias  changing lr from: 0.040090827493765489   to: 0.038384564722724716



# Switched to train mode...
Epoch: [52][  0/391]	Time  0.201 ( 0.201)	Data  0.161 ( 0.161)	Loss 1.3581e-01 (1.3581e-01)	Acc@1  95.31 ( 95.31)	Acc@5 100.00 (100.00)
Epoch: [52][ 10/391]	Time  0.039 ( 0.053)	Data  0.001 ( 0.015)	Loss 1.3476e-01 (1.0208e-01)	Acc@1  95.31 ( 96.38)	Acc@5 100.00 (100.00)
Epoch: [52][ 20/391]	Time  0.038 ( 0.046)	Data  0.001 ( 0.009)	Loss 3.0354e-02 (8.7895e-02)	Acc@1  99.22 ( 96.69)	Acc@5 100.00 (100.00)
Epoch: [52][ 30/391]	Time  0.036 ( 0.043)	Data  0.001 ( 0.006)	Loss 1.2968e-01 (8.4244e-02)	Acc@1  95.31 ( 97.00)	Acc@5 100.00 (100.00)
Epoch: [52][ 40/391]	Time  0.037 ( 0.042)	Data  0.001 ( 0.005)	Loss 4.4426e-02 (7.8317e-02)	Acc@1  98.44 ( 97.18)	Acc@5 100.00 (100.00)
Epoch: [52][ 50/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.004)	Loss 1.0955e-01 (7.6671e-02)	Acc@1  96.09 ( 97.32)	Acc@5 100.00 (100.00)
Epoch: [52][ 60/391]	Time  0.042 ( 0.041)	Data  0.001 ( 0.004)	Loss 6.7579e-02 (7.6071e-02)	Acc@1  98.44 ( 97.37)	Acc@5 100.00 (100.00)
Epoch: [52][ 70/391]	Time  0.036 ( 0.041)	Data  0.001 ( 0.003)	Loss 4.0283e-02 (7.5203e-02)	Acc@1  98.44 ( 97.47)	Acc@5 100.00 (100.00)
Epoch: [52][ 80/391]	Time  0.037 ( 0.040)	Data  0.001 ( 0.003)	Loss 8.2652e-02 (7.4524e-02)	Acc@1  96.88 ( 97.41)	Acc@5 100.00 (100.00)
Epoch: [52][ 90/391]	Time  0.037 ( 0.040)	Data  0.001 ( 0.003)	Loss 4.5657e-02 (7.3962e-02)	Acc@1  99.22 ( 97.45)	Acc@5 100.00 (100.00)
Epoch: [52][100/391]	Time  0.037 ( 0.040)	Data  0.001 ( 0.003)	Loss 5.7860e-02 (7.2822e-02)	Acc@1  97.66 ( 97.48)	Acc@5 100.00 (100.00)
Epoch: [52][110/391]	Time  0.039 ( 0.040)	Data  0.001 ( 0.002)	Loss 4.0107e-02 (7.1405e-02)	Acc@1  99.22 ( 97.53)	Acc@5 100.00 (100.00)
Epoch: [52][120/391]	Time  0.039 ( 0.040)	Data  0.001 ( 0.002)	Loss 5.0017e-02 (7.2612e-02)	Acc@1  97.66 ( 97.48)	Acc@5 100.00 (100.00)
Epoch: [52][130/391]	Time  0.036 ( 0.039)	Data  0.001 ( 0.002)	Loss 6.5048e-02 (7.2097e-02)	Acc@1  98.44 ( 97.50)	Acc@5 100.00 (100.00)
Epoch: [52][140/391]	Time  0.040 ( 0.039)	Data  0.001 ( 0.002)	Loss 3.2973e-02 (7.1848e-02)	Acc@1  99.22 ( 97.51)	Acc@5 100.00 (100.00)
Epoch: [52][150/391]	Time  0.038 ( 0.039)	Data  0.001 ( 0.002)	Loss 1.2827e-01 (7.2445e-02)	Acc@1  94.53 ( 97.46)	Acc@5 100.00 (100.00)
Epoch: [52][160/391]	Time  0.039 ( 0.039)	Data  0.002 ( 0.002)	Loss 3.6781e-02 (7.1845e-02)	Acc@1  99.22 ( 97.49)	Acc@5 100.00 (100.00)
Epoch: [52][170/391]	Time  0.038 ( 0.039)	Data  0.001 ( 0.002)	Loss 8.3731e-02 (7.1770e-02)	Acc@1  96.09 ( 97.49)	Acc@5 100.00 (100.00)
Epoch: [52][180/391]	Time  0.036 ( 0.039)	Data  0.001 ( 0.002)	Loss 3.8393e-02 (7.1361e-02)	Acc@1  99.22 ( 97.52)	Acc@5 100.00 (100.00)
Epoch: [52][190/391]	Time  0.039 ( 0.039)	Data  0.001 ( 0.002)	Loss 4.2993e-02 (7.1202e-02)	Acc@1 100.00 ( 97.55)	Acc@5 100.00 (100.00)
Epoch: [52][200/391]	Time  0.038 ( 0.039)	Data  0.001 ( 0.002)	Loss 1.0310e-01 (7.1658e-02)	Acc@1  96.09 ( 97.53)	Acc@5 100.00 (100.00)
Epoch: [52][210/391]	Time  0.040 ( 0.039)	Data  0.001 ( 0.002)	Loss 8.2586e-02 (7.2031e-02)	Acc@1  98.44 ( 97.52)	Acc@5 100.00 (100.00)
Epoch: [52][220/391]	Time  0.038 ( 0.039)	Data  0.001 ( 0.002)	Loss 9.1702e-02 (7.3228e-02)	Acc@1  97.66 ( 97.48)	Acc@5 100.00 (100.00)
Epoch: [52][230/391]	Time  0.036 ( 0.039)	Data  0.001 ( 0.002)	Loss 9.7130e-02 (7.3907e-02)	Acc@1  96.88 ( 97.46)	Acc@5 100.00 (100.00)
Epoch: [52][240/391]	Time  0.039 ( 0.039)	Data  0.001 ( 0.002)	Loss 1.6942e-01 (7.4370e-02)	Acc@1  94.53 ( 97.46)	Acc@5  99.22 ( 99.99)
Epoch: [52][250/391]	Time  0.040 ( 0.039)	Data  0.001 ( 0.002)	Loss 5.2639e-02 (7.5486e-02)	Acc@1  98.44 ( 97.40)	Acc@5 100.00 ( 99.99)
Epoch: [52][260/391]	Time  0.037 ( 0.039)	Data  0.001 ( 0.002)	Loss 6.7742e-02 (7.6121e-02)	Acc@1  97.66 ( 97.38)	Acc@5 100.00 ( 99.99)
Epoch: [52][270/391]	Time  0.039 ( 0.039)	Data  0.001 ( 0.002)	Loss 6.2839e-02 (7.5993e-02)	Acc@1  96.88 ( 97.38)	Acc@5 100.00 ( 99.99)
Epoch: [52][280/391]	Time  0.037 ( 0.039)	Data  0.001 ( 0.002)	Loss 2.4625e-02 (7.6186e-02)	Acc@1  99.22 ( 97.37)	Acc@5 100.00 ( 99.99)
Epoch: [52][290/391]	Time  0.043 ( 0.039)	Data  0.001 ( 0.002)	Loss 7.6022e-02 (7.5719e-02)	Acc@1  97.66 ( 97.38)	Acc@5 100.00 ( 99.99)
Epoch: [52][300/391]	Time  0.043 ( 0.039)	Data  0.001 ( 0.002)	Loss 8.3954e-02 (7.5512e-02)	Acc@1  98.44 ( 97.39)	Acc@5 100.00 ( 99.99)
Epoch: [52][310/391]	Time  0.037 ( 0.039)	Data  0.001 ( 0.002)	Loss 6.0265e-02 (7.5675e-02)	Acc@1  97.66 ( 97.38)	Acc@5 100.00 ( 99.99)
Epoch: [52][320/391]	Time  0.037 ( 0.039)	Data  0.001 ( 0.002)	Loss 8.8874e-02 (7.5670e-02)	Acc@1  97.66 ( 97.39)	Acc@5 100.00 (100.00)
Epoch: [52][330/391]	Time  0.039 ( 0.039)	Data  0.001 ( 0.002)	Loss 8.6272e-02 (7.5968e-02)	Acc@1  96.88 ( 97.38)	Acc@5 100.00 (100.00)
Epoch: [52][340/391]	Time  0.037 ( 0.039)	Data  0.001 ( 0.001)	Loss 1.0704e-01 (7.6497e-02)	Acc@1  98.44 ( 97.37)	Acc@5 100.00 (100.00)
Epoch: [52][350/391]	Time  0.042 ( 0.039)	Data  0.001 ( 0.001)	Loss 1.0072e-01 (7.6793e-02)	Acc@1  97.66 ( 97.36)	Acc@5 100.00 (100.00)
Epoch: [52][360/391]	Time  0.037 ( 0.039)	Data  0.001 ( 0.001)	Loss 6.7334e-02 (7.6686e-02)	Acc@1  97.66 ( 97.37)	Acc@5 100.00 (100.00)
Epoch: [52][370/391]	Time  0.037 ( 0.039)	Data  0.001 ( 0.001)	Loss 6.5187e-02 (7.7323e-02)	Acc@1  96.88 ( 97.34)	Acc@5 100.00 (100.00)
Epoch: [52][380/391]	Time  0.037 ( 0.039)	Data  0.001 ( 0.001)	Loss 8.7706e-02 (7.7631e-02)	Acc@1  96.09 ( 97.33)	Acc@5 100.00 (100.00)
Epoch: [52][390/391]	Time  0.025 ( 0.039)	Data  0.001 ( 0.001)	Loss 8.3134e-02 (7.7707e-02)	Acc@1  97.50 ( 97.33)	Acc@5 100.00 (100.00)
## e[52] optimizer.zero_grad (sum) time: 0.2269740104675293
## e[52]       loss.backward (sum) time: 3.7406575679779053
## e[52]      optimizer.step (sum) time: 1.548386573791504
## epoch[52] training(only) time: 15.202664613723755
# Switched to evaluate mode...
Test: [  0/100]	Time  0.161 ( 0.161)	Loss 2.7581e-01 (2.7581e-01)	Acc@1  91.00 ( 91.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.018 ( 0.033)	Loss 5.4288e-01 (3.4612e-01)	Acc@1  89.00 ( 90.73)	Acc@5 100.00 ( 99.91)
Test: [ 20/100]	Time  0.021 ( 0.028)	Loss 3.4972e-01 (3.7468e-01)	Acc@1  90.00 ( 90.38)	Acc@5 100.00 ( 99.76)
Test: [ 30/100]	Time  0.026 ( 0.026)	Loss 4.0416e-01 (4.0284e-01)	Acc@1  87.00 ( 90.16)	Acc@5  99.00 ( 99.61)
Test: [ 40/100]	Time  0.021 ( 0.025)	Loss 4.0019e-01 (4.1336e-01)	Acc@1  90.00 ( 90.07)	Acc@5  99.00 ( 99.54)
Test: [ 50/100]	Time  0.018 ( 0.024)	Loss 1.5885e-01 (4.0132e-01)	Acc@1  93.00 ( 90.29)	Acc@5 100.00 ( 99.55)
Test: [ 60/100]	Time  0.021 ( 0.023)	Loss 3.7617e-01 (3.8890e-01)	Acc@1  93.00 ( 90.38)	Acc@5 100.00 ( 99.59)
Test: [ 70/100]	Time  0.024 ( 0.023)	Loss 3.4611e-01 (3.7457e-01)	Acc@1  87.00 ( 90.54)	Acc@5 100.00 ( 99.63)
Test: [ 80/100]	Time  0.019 ( 0.023)	Loss 3.1441e-01 (3.6905e-01)	Acc@1  91.00 ( 90.63)	Acc@5 100.00 ( 99.67)
Test: [ 90/100]	Time  0.023 ( 0.023)	Loss 3.1651e-01 (3.7048e-01)	Acc@1  93.00 ( 90.57)	Acc@5 100.00 ( 99.69)
 * Acc@1 90.620 Acc@5 99.710
### epoch[52] execution time: 17.595993041992188
EPOCH 53
REMOVING: module.fire3.squeeze.0.bias
REMOVING: module.fire3.squeeze.1.weight
REMOVING: module.fire3.squeeze.1.bias
i:   0, name: module.fire3.expand_1x1.0.weight  changing lr from: 0.001124279298084823   to: 0.001003284447787805
i:   1, name: module.fire3.expand_1x1.0.bias  changing lr from: 0.001211208110764027   to: 0.001027719895412492
i:   2, name: module.fire3.expand_1x1.1.weight  changing lr from: 0.001319868960940767   to: 0.001075428738004757
i:   3, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.001449598565149456   to: 0.001145740611665579
i:   4, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.001599741877743076   to: 0.001237991876243032
i:   5, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.001769652500438500   to: 0.001351526132055319
i:   6, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.001958693050850917   to: 0.001485694690803640
i:   7, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.002166235492264739   to: 0.001639857003055194
i:   8, name:  module.fire4.squeeze.0.weight  changing lr from: 0.002391661426801899   to: 0.001813381044591977
i:   9, name:    module.fire4.squeeze.0.bias  changing lr from: 0.002634362354063446   to: 0.002005643663837352
i:  10, name:  module.fire4.squeeze.1.weight  changing lr from: 0.002893739897236396   to: 0.002216030892489334
i:  11, name:    module.fire4.squeeze.1.bias  changing lr from: 0.003169205998576124   to: 0.002443938221407676
i:  12, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.003460183086093754   to: 0.002688770843721077
i:  13, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.003766104213200105   to: 0.002949943867041887
i:  14, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.004086413172980746   to: 0.003226882496597782
i:  15, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.004420564588702624   to: 0.003519022191014148
i:  16, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.004768023982080077   to: 0.003825808792406642
i:  17, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.005128267820757758   to: 0.004146698632371098
i:  18, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.005500783546400028   to: 0.004481158615387414
i:  19, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.005885069584709973   to: 0.004828666281085991
i:  20, name:  module.fire5.squeeze.0.weight  changing lr from: 0.006280635338637907   to: 0.005188709846758266
i:  21, name:    module.fire5.squeeze.0.bias  changing lr from: 0.006687001165977063   to: 0.005560788231429164
i:  22, name:  module.fire5.squeeze.1.weight  changing lr from: 0.007103698342484787   to: 0.005944411062746185
i:  23, name:    module.fire5.squeeze.1.bias  changing lr from: 0.007530269011610562   to: 0.006339098667880311
i:  24, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.007966266121855975   to: 0.006744382049574759
i:  25, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.008411253352739890   to: 0.007159802848422275
i:  26, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.008864805030289451   to: 0.007584913292396472
i:  27, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.009326506032930008   to: 0.008019276134611574
i:  28, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.009795951688598342   to: 0.008462464580233369
i:  29, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.010272747663859650   to: 0.008914062203417034
i:  30, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.010756509845764678   to: 0.009373662855100332
i:  31, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.011246864217142171   to: 0.009840870562436072
i:  32, name:  module.fire6.squeeze.0.weight  changing lr from: 0.011743446725982216   to: 0.010315299420605665
i:  33, name:    module.fire6.squeeze.0.bias  changing lr from: 0.012245903149527761   to: 0.010796573477713761
i:  34, name:  module.fire6.squeeze.1.weight  changing lr from: 0.012753888953655795   to: 0.011284326613425173
i:  35, name:    module.fire6.squeeze.1.bias  changing lr from: 0.013267069148094536   to: 0.011778202411967632
i:  36, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.013785118137990621   to: 0.012277854030088187
i:  37, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.014307719572307948   to: 0.012782944060516221
i:  38, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.014834566189510741   to: 0.013293144391454004
i:  39, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.015365359660953655   to: 0.013808136062583454
i:  40, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.015899810432376243   to: 0.014327609118049162
i:  41, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.016437637563871187   to: 0.014851262456848046
i:  42, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.016978568568672636   to: 0.015378803681029739
i:  43, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.017522339251087204   to: 0.015909948942085510
i:  44, name:  module.fire7.squeeze.0.weight  changing lr from: 0.018068693543867625   to: 0.016444422785879632
i:  45, name:    module.fire7.squeeze.0.bias  changing lr from: 0.018617383345308613   to: 0.016981957996452881
i:  46, name:  module.fire7.squeeze.1.weight  changing lr from: 0.019168168356324077   to: 0.017522295439006363
i:  47, name:    module.fire7.squeeze.1.bias  changing lr from: 0.019720815917745993   to: 0.018065183902352584
i:  48, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.020275100848067714   to: 0.018610379941100676
i:  49, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.020830805281837006   to: 0.019157647717823630
i:  50, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.021387718508888667   to: 0.019706758845437846
i:  51, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.021945636814590504   to: 0.020257492230007543
i:  52, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.022504363321263595   to: 0.020809633914171368
i:  53, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.023063707830922597   to: 0.021362976921372425
i:  54, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.023623486669470607   to: 0.021917321101059230
i:  55, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.024183522532469817   to: 0.022472472975010895
i:  56, name:  module.fire8.squeeze.0.weight  changing lr from: 0.024743644332598992   to: 0.023028245584927654
i:  57, name:    module.fire8.squeeze.0.bias  changing lr from: 0.025303687048897124   to: 0.023584458341414712
i:  58, name:  module.fire8.squeeze.1.weight  changing lr from: 0.025863491577883681   to: 0.024140936874477228
i:  59, name:    module.fire8.squeeze.1.bias  changing lr from: 0.026422904586635421   to: 0.024697512885632263
i:  60, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.026981778367891465   to: 0.025254024001734030
i:  61, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.027539970697250199   to: 0.025810313630599185
i:  62, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.028097344692513196   to: 0.026366230818509664
i:  63, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.028653768675224435   to: 0.026921630109662212
i:  64, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.029209116034446477   to: 0.027476371407625891
i:  65, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.029763265092808334   to: 0.028030319838861575
i:  66, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.030316098974854357   to: 0.028583345618349906
i:  67, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.030867505477717400   to: 0.029135323917368280
i:  68, name:  module.fire9.squeeze.0.weight  changing lr from: 0.031417376944134996   to: 0.029686134733451122
i:  69, name:    module.fire9.squeeze.0.bias  changing lr from: 0.031965610137821607   to: 0.030235662762561621
i:  70, name:  module.fire9.squeeze.1.weight  changing lr from: 0.032512106121206419   to: 0.030783797273498555
i:  71, name:    module.fire9.squeeze.1.bias  changing lr from: 0.033056770135541223   to: 0.031330431984555943
i:  72, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.033599511483379731   to: 0.031875464942449500
i:  73, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.034140243413425482   to: 0.032418798403518870
i:  74, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.034678883007742745   to: 0.032960338717211081
i:  75, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.035215351071321267   to: 0.033499996211846704
i:  76, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.035749572023983510   to: 0.034037685082666892
i:  77, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.036281473794619865   to: 0.034573323282156183
i:  78, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.036810987717735159   to: 0.035106832412633071
i:  79, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.037338048432287961   to: 0.035638137621097722
i:  80, name:           module.conv10.weight  changing lr from: 0.037862593782801622   to: 0.036167167496323559
i:  81, name:             module.conv10.bias  changing lr from: 0.038384564722724716   to: 0.036693853968177349



# Switched to train mode...
Epoch: [53][  0/391]	Time  0.206 ( 0.206)	Data  0.166 ( 0.166)	Loss 9.3134e-02 (9.3134e-02)	Acc@1  96.09 ( 96.09)	Acc@5 100.00 (100.00)
Epoch: [53][ 10/391]	Time  0.040 ( 0.053)	Data  0.001 ( 0.016)	Loss 7.6096e-02 (7.7079e-02)	Acc@1  96.88 ( 97.59)	Acc@5 100.00 (100.00)
Epoch: [53][ 20/391]	Time  0.039 ( 0.047)	Data  0.001 ( 0.009)	Loss 1.1509e-01 (7.7865e-02)	Acc@1  94.53 ( 97.28)	Acc@5 100.00 (100.00)
Epoch: [53][ 30/391]	Time  0.039 ( 0.044)	Data  0.001 ( 0.006)	Loss 5.4746e-02 (7.7257e-02)	Acc@1  99.22 ( 97.35)	Acc@5 100.00 (100.00)
Epoch: [53][ 40/391]	Time  0.036 ( 0.042)	Data  0.001 ( 0.005)	Loss 9.2062e-02 (7.5544e-02)	Acc@1  97.66 ( 97.39)	Acc@5 100.00 (100.00)
Epoch: [53][ 50/391]	Time  0.036 ( 0.042)	Data  0.001 ( 0.004)	Loss 1.0208e-01 (7.6233e-02)	Acc@1  96.09 ( 97.37)	Acc@5 100.00 (100.00)
Epoch: [53][ 60/391]	Time  0.037 ( 0.041)	Data  0.001 ( 0.004)	Loss 6.7124e-02 (7.7411e-02)	Acc@1  97.66 ( 97.39)	Acc@5 100.00 (100.00)
Epoch: [53][ 70/391]	Time  0.037 ( 0.041)	Data  0.001 ( 0.003)	Loss 1.2561e-01 (7.8583e-02)	Acc@1  95.31 ( 97.30)	Acc@5 100.00 (100.00)
Epoch: [53][ 80/391]	Time  0.038 ( 0.040)	Data  0.001 ( 0.003)	Loss 7.5234e-02 (7.7461e-02)	Acc@1  96.88 ( 97.36)	Acc@5 100.00 (100.00)
Epoch: [53][ 90/391]	Time  0.039 ( 0.040)	Data  0.001 ( 0.003)	Loss 8.5737e-02 (7.7896e-02)	Acc@1  97.66 ( 97.36)	Acc@5 100.00 (100.00)
Epoch: [53][100/391]	Time  0.037 ( 0.040)	Data  0.001 ( 0.003)	Loss 6.0828e-02 (7.7918e-02)	Acc@1  97.66 ( 97.30)	Acc@5 100.00 (100.00)
Epoch: [53][110/391]	Time  0.037 ( 0.040)	Data  0.001 ( 0.002)	Loss 4.3631e-02 (7.6877e-02)	Acc@1  99.22 ( 97.35)	Acc@5 100.00 ( 99.99)
Epoch: [53][120/391]	Time  0.037 ( 0.040)	Data  0.001 ( 0.002)	Loss 6.6758e-02 (7.5787e-02)	Acc@1  97.66 ( 97.39)	Acc@5 100.00 ( 99.99)
Epoch: [53][130/391]	Time  0.039 ( 0.039)	Data  0.001 ( 0.002)	Loss 7.2856e-02 (7.6294e-02)	Acc@1  97.66 ( 97.38)	Acc@5 100.00 ( 99.99)
Epoch: [53][140/391]	Time  0.036 ( 0.039)	Data  0.001 ( 0.002)	Loss 4.2260e-02 (7.5975e-02)	Acc@1  98.44 ( 97.40)	Acc@5 100.00 ( 99.99)
Epoch: [53][150/391]	Time  0.037 ( 0.039)	Data  0.001 ( 0.002)	Loss 4.0894e-02 (7.5124e-02)	Acc@1  97.66 ( 97.42)	Acc@5 100.00 ( 99.99)
Epoch: [53][160/391]	Time  0.039 ( 0.039)	Data  0.001 ( 0.002)	Loss 4.0412e-02 (7.4427e-02)	Acc@1  97.66 ( 97.42)	Acc@5 100.00 (100.00)
Epoch: [53][170/391]	Time  0.039 ( 0.039)	Data  0.001 ( 0.002)	Loss 1.4179e-01 (7.5041e-02)	Acc@1  92.19 ( 97.36)	Acc@5 100.00 (100.00)
Epoch: [53][180/391]	Time  0.039 ( 0.039)	Data  0.001 ( 0.002)	Loss 3.7431e-02 (7.5001e-02)	Acc@1  99.22 ( 97.38)	Acc@5 100.00 (100.00)
Epoch: [53][190/391]	Time  0.037 ( 0.039)	Data  0.001 ( 0.002)	Loss 5.9510e-02 (7.4860e-02)	Acc@1  98.44 ( 97.37)	Acc@5 100.00 (100.00)
Epoch: [53][200/391]	Time  0.037 ( 0.039)	Data  0.001 ( 0.002)	Loss 9.7707e-02 (7.4773e-02)	Acc@1  95.31 ( 97.37)	Acc@5 100.00 (100.00)
Epoch: [53][210/391]	Time  0.037 ( 0.039)	Data  0.001 ( 0.002)	Loss 1.3223e-01 (7.4380e-02)	Acc@1  93.75 ( 97.39)	Acc@5 100.00 (100.00)
Epoch: [53][220/391]	Time  0.039 ( 0.039)	Data  0.001 ( 0.002)	Loss 8.0899e-02 (7.4461e-02)	Acc@1  96.88 ( 97.40)	Acc@5 100.00 (100.00)
Epoch: [53][230/391]	Time  0.040 ( 0.039)	Data  0.001 ( 0.002)	Loss 8.3393e-02 (7.5357e-02)	Acc@1  96.88 ( 97.36)	Acc@5 100.00 (100.00)
Epoch: [53][240/391]	Time  0.042 ( 0.039)	Data  0.001 ( 0.002)	Loss 7.6130e-02 (7.4957e-02)	Acc@1  97.66 ( 97.36)	Acc@5 100.00 (100.00)
Epoch: [53][250/391]	Time  0.036 ( 0.039)	Data  0.001 ( 0.002)	Loss 1.3857e-01 (7.5717e-02)	Acc@1  94.53 ( 97.34)	Acc@5 100.00 (100.00)
Epoch: [53][260/391]	Time  0.040 ( 0.039)	Data  0.001 ( 0.002)	Loss 4.4054e-02 (7.5689e-02)	Acc@1 100.00 ( 97.34)	Acc@5 100.00 (100.00)
Epoch: [53][270/391]	Time  0.037 ( 0.039)	Data  0.001 ( 0.002)	Loss 6.0106e-02 (7.5552e-02)	Acc@1  99.22 ( 97.36)	Acc@5 100.00 (100.00)
Epoch: [53][280/391]	Time  0.037 ( 0.039)	Data  0.002 ( 0.002)	Loss 6.1961e-02 (7.6044e-02)	Acc@1  99.22 ( 97.35)	Acc@5 100.00 ( 99.99)
Epoch: [53][290/391]	Time  0.035 ( 0.039)	Data  0.001 ( 0.002)	Loss 5.0885e-02 (7.5926e-02)	Acc@1  97.66 ( 97.36)	Acc@5 100.00 ( 99.99)
Epoch: [53][300/391]	Time  0.036 ( 0.039)	Data  0.001 ( 0.002)	Loss 8.9069e-02 (7.5841e-02)	Acc@1  97.66 ( 97.37)	Acc@5 100.00 ( 99.99)
Epoch: [53][310/391]	Time  0.038 ( 0.039)	Data  0.001 ( 0.001)	Loss 7.7693e-02 (7.5674e-02)	Acc@1  97.66 ( 97.38)	Acc@5 100.00 ( 99.99)
Epoch: [53][320/391]	Time  0.035 ( 0.039)	Data  0.001 ( 0.001)	Loss 8.7922e-02 (7.5792e-02)	Acc@1  96.88 ( 97.38)	Acc@5 100.00 ( 99.99)
Epoch: [53][330/391]	Time  0.036 ( 0.038)	Data  0.001 ( 0.001)	Loss 1.5514e-01 (7.5968e-02)	Acc@1  93.75 ( 97.37)	Acc@5 100.00 ( 99.99)
Epoch: [53][340/391]	Time  0.041 ( 0.038)	Data  0.001 ( 0.001)	Loss 3.6111e-02 (7.6214e-02)	Acc@1 100.00 ( 97.37)	Acc@5 100.00 ( 99.99)
Epoch: [53][350/391]	Time  0.040 ( 0.038)	Data  0.001 ( 0.001)	Loss 8.7295e-02 (7.6484e-02)	Acc@1  98.44 ( 97.35)	Acc@5 100.00 ( 99.99)
Epoch: [53][360/391]	Time  0.038 ( 0.038)	Data  0.001 ( 0.001)	Loss 7.1735e-02 (7.6411e-02)	Acc@1  97.66 ( 97.36)	Acc@5 100.00 ( 99.99)
Epoch: [53][370/391]	Time  0.038 ( 0.038)	Data  0.001 ( 0.001)	Loss 3.8527e-02 (7.6315e-02)	Acc@1  99.22 ( 97.37)	Acc@5 100.00 ( 99.99)
Epoch: [53][380/391]	Time  0.036 ( 0.038)	Data  0.001 ( 0.001)	Loss 7.3415e-02 (7.7006e-02)	Acc@1  98.44 ( 97.35)	Acc@5 100.00 ( 99.99)
Epoch: [53][390/391]	Time  0.025 ( 0.038)	Data  0.001 ( 0.001)	Loss 1.1418e-01 (7.7144e-02)	Acc@1  96.25 ( 97.34)	Acc@5 100.00 ( 99.99)
## e[53] optimizer.zero_grad (sum) time: 0.22054672241210938
## e[53]       loss.backward (sum) time: 3.6037161350250244
## e[53]      optimizer.step (sum) time: 1.5079152584075928
## epoch[53] training(only) time: 15.088748216629028
# Switched to evaluate mode...
Test: [  0/100]	Time  0.172 ( 0.172)	Loss 2.5469e-01 (2.5469e-01)	Acc@1  92.00 ( 92.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.018 ( 0.033)	Loss 5.2246e-01 (3.4232e-01)	Acc@1  88.00 ( 90.09)	Acc@5 100.00 ( 99.91)
Test: [ 20/100]	Time  0.020 ( 0.027)	Loss 3.5446e-01 (3.7050e-01)	Acc@1  87.00 ( 89.76)	Acc@5 100.00 ( 99.76)
Test: [ 30/100]	Time  0.024 ( 0.025)	Loss 4.5595e-01 (3.9764e-01)	Acc@1  86.00 ( 89.81)	Acc@5  99.00 ( 99.65)
Test: [ 40/100]	Time  0.018 ( 0.024)	Loss 3.4038e-01 (4.0099e-01)	Acc@1  88.00 ( 89.73)	Acc@5  99.00 ( 99.63)
Test: [ 50/100]	Time  0.023 ( 0.023)	Loss 1.9830e-01 (3.9091e-01)	Acc@1  95.00 ( 90.00)	Acc@5 100.00 ( 99.65)
Test: [ 60/100]	Time  0.018 ( 0.023)	Loss 3.8165e-01 (3.8007e-01)	Acc@1  91.00 ( 90.11)	Acc@5  99.00 ( 99.66)
Test: [ 70/100]	Time  0.018 ( 0.022)	Loss 3.8118e-01 (3.6920e-01)	Acc@1  91.00 ( 90.28)	Acc@5 100.00 ( 99.66)
Test: [ 80/100]	Time  0.024 ( 0.022)	Loss 1.6863e-01 (3.6444e-01)	Acc@1  94.00 ( 90.37)	Acc@5 100.00 ( 99.69)
Test: [ 90/100]	Time  0.022 ( 0.022)	Loss 2.1091e-01 (3.6592e-01)	Acc@1  96.00 ( 90.40)	Acc@5 100.00 ( 99.73)
 * Acc@1 90.410 Acc@5 99.730
### epoch[53] execution time: 17.412477016448975
EPOCH 54
REMOVING: module.fire3.expand_1x1.0.weight
REMOVING: module.fire3.expand_1x1.0.bias
REMOVING: module.fire3.expand_1x1.1.weight
i:   0, name: module.fire3.expand_1x1.1.bias  changing lr from: 0.001145740611665579   to: 0.001008589481088367
i:   1, name: module.fire3.expand_3x3.0.weight  changing lr from: 0.001237991876243032   to: 0.001040343096861406
i:   2, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.001351526132055319   to: 0.001094871519790279
i:   3, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.001485694690803640   to: 0.001171518811375115
i:   4, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.001639857003055194   to: 0.001269635752869113
i:   5, name:  module.fire4.squeeze.0.weight  changing lr from: 0.001813381044591977   to: 0.001388580332245936
i:   6, name:    module.fire4.squeeze.0.bias  changing lr from: 0.002005643663837352   to: 0.001527718187744525
i:   7, name:  module.fire4.squeeze.1.weight  changing lr from: 0.002216030892489334   to: 0.001686423010245507
i:   8, name:    module.fire4.squeeze.1.bias  changing lr from: 0.002443938221407676   to: 0.001864076906653316
i:   9, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.002688770843721077   to: 0.002060070726378409
i:  10, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.002949943867041887   to: 0.002273804352935482
i:  11, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.003226882496597782   to: 0.002504686962595886
i:  12, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.003519022191014148   to: 0.002752137251956093
i:  13, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.003825808792406642   to: 0.003015583636209173
i:  14, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.004146698632371098   to: 0.003294464419832793
i:  15, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.004481158615387414   to: 0.003588227941335242
i:  16, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.004828666281085991   to: 0.003896332693631160
i:  17, name:  module.fire5.squeeze.0.weight  changing lr from: 0.005188709846758266   to: 0.004218247421549947
i:  18, name:    module.fire5.squeeze.0.bias  changing lr from: 0.005560788231429164   to: 0.004553451197913643
i:  19, name:  module.fire5.squeeze.1.weight  changing lr from: 0.005944411062746185   to: 0.004901433479555855
i:  20, name:    module.fire5.squeeze.1.bias  changing lr from: 0.006339098667880311   to: 0.005261694144591349
i:  21, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.006744382049574759   to: 0.005633743512184075
i:  22, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.007159802848422275   to: 0.006017102346003378
i:  23, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.007584913292396472   to: 0.006411301842500394
i:  24, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.008019276134611574   to: 0.006815883605082395
i:  25, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.008462464580233369   to: 0.007230399605208665
i:  26, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.008914062203417034   to: 0.007654412131381244
i:  27, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.009373662855100332   to: 0.008087493726953865
i:  28, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.009840870562436072   to: 0.008529227117635157
i:  29, name:  module.fire6.squeeze.0.weight  changing lr from: 0.010315299420605665   to: 0.008979205129516447
i:  30, name:    module.fire6.squeeze.0.bias  changing lr from: 0.010796573477713761   to: 0.009437030598410695
i:  31, name:  module.fire6.squeeze.1.weight  changing lr from: 0.011284326613425173   to: 0.009902316271246752
i:  32, name:    module.fire6.squeeze.1.bias  changing lr from: 0.011778202411967632   to: 0.010374684700222712
i:  33, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.012277854030088187   to: 0.010853768130383912
i:  34, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.012782944060516221   to: 0.011339208381252956
i:  35, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.013293144391454004   to: 0.011830656723104949
i:  36, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.013808136062583454   to: 0.012327773748445636
i:  37, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.014327609118049162   to: 0.012830229239219299
i:  38, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.014851262456848046   to: 0.013337702030240661
i:  39, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.015378803681029739   to: 0.013849879869316573
i:  40, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.015909948942085510   to: 0.014366459274494377
i:  41, name:  module.fire7.squeeze.0.weight  changing lr from: 0.016444422785879632   to: 0.014887145388847178
i:  42, name:    module.fire7.squeeze.0.bias  changing lr from: 0.016981957996452881   to: 0.015411651833180523
i:  43, name:  module.fire7.squeeze.1.weight  changing lr from: 0.017522295439006363   to: 0.015939700557020375
i:  44, name:    module.fire7.squeeze.1.bias  changing lr from: 0.018065183902352584   to: 0.016471021688219307
i:  45, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.018610379941100676   to: 0.017005353381495402
i:  46, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.019157647717823630   to: 0.017542441666197606
i:  47, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.019706758845437846   to: 0.018082040293571161
i:  48, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.020257492230007543   to: 0.018623910583777475
i:  49, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.020809633914171368   to: 0.019167821272905800
i:  50, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.021362976921372425   to: 0.019713548360195315
i:  51, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.021917321101059230   to: 0.020260874955672276
i:  52, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.022472472975010895   to: 0.020809591128389218
i:  53, name:  module.fire8.squeeze.0.weight  changing lr from: 0.023028245584927654   to: 0.021359493755440724
i:  54, name:    module.fire8.squeeze.0.bias  changing lr from: 0.023584458341414712   to: 0.021910386371915086
i:  55, name:  module.fire8.squeeze.1.weight  changing lr from: 0.024140936874477228   to: 0.022462079021929284
i:  56, name:    module.fire8.squeeze.1.bias  changing lr from: 0.024697512885632263   to: 0.023014388110881967
i:  57, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.025254024001734030   to: 0.023567136259047092
i:  58, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.025810313630599185   to: 0.024120152156621479
i:  59, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.026366230818509664   to: 0.024673270420327388
i:  60, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.026921630109662212   to: 0.025226331451663003
i:  61, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.027476371407625891   to: 0.025779181296883804
i:  62, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.028030319838861575   to: 0.026331671508789622
i:  63, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.028583345618349906   to: 0.026883659010383816
i:  64, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.029135323917368280   to: 0.027435005960463738
i:  65, name:  module.fire9.squeeze.0.weight  changing lr from: 0.029686134733451122   to: 0.027985579621194429
i:  66, name:    module.fire9.squeeze.0.bias  changing lr from: 0.030235662762561621   to: 0.028535252227710497
i:  67, name:  module.fire9.squeeze.1.weight  changing lr from: 0.030783797273498555   to: 0.029083900859785752
i:  68, name:    module.fire9.squeeze.1.bias  changing lr from: 0.031330431984555943   to: 0.029631407315603178
i:  69, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.031875464942449500   to: 0.030177657987653497
i:  70, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.032418798403518870   to: 0.030722543740784536
i:  71, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.032960338717211081   to: 0.031265959792419626
i:  72, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.033499996211846704   to: 0.031807805594958050
i:  73, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.034037685082666892   to: 0.032347984720367269
i:  74, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.034573323282156183   to: 0.032886404746972263
i:  75, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.035106832412633071   to: 0.033422977148443604
i:  76, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.035638137621097722   to: 0.033957617184983295
i:  77, name:           module.conv10.weight  changing lr from: 0.036167167496323559   to: 0.034490243796703700
i:  78, name:             module.conv10.bias  changing lr from: 0.036693853968177349   to: 0.035020779499192356



# Switched to train mode...
Epoch: [54][  0/391]	Time  0.208 ( 0.208)	Data  0.170 ( 0.170)	Loss 7.6054e-02 (7.6054e-02)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [54][ 10/391]	Time  0.038 ( 0.053)	Data  0.001 ( 0.016)	Loss 7.7195e-02 (6.7968e-02)	Acc@1  96.09 ( 97.30)	Acc@5 100.00 (100.00)
Epoch: [54][ 20/391]	Time  0.037 ( 0.046)	Data  0.001 ( 0.009)	Loss 4.8711e-02 (6.7719e-02)	Acc@1  98.44 ( 97.32)	Acc@5 100.00 (100.00)
Epoch: [54][ 30/391]	Time  0.036 ( 0.043)	Data  0.001 ( 0.006)	Loss 1.2140e-01 (7.1009e-02)	Acc@1  96.88 ( 97.43)	Acc@5 100.00 (100.00)
Epoch: [54][ 40/391]	Time  0.036 ( 0.042)	Data  0.001 ( 0.005)	Loss 1.0015e-01 (6.9834e-02)	Acc@1  96.09 ( 97.48)	Acc@5 100.00 (100.00)
Epoch: [54][ 50/391]	Time  0.040 ( 0.041)	Data  0.001 ( 0.004)	Loss 5.2078e-02 (7.0393e-02)	Acc@1  97.66 ( 97.37)	Acc@5 100.00 (100.00)
Epoch: [54][ 60/391]	Time  0.037 ( 0.041)	Data  0.001 ( 0.004)	Loss 3.8753e-02 (7.0933e-02)	Acc@1  99.22 ( 97.40)	Acc@5 100.00 ( 99.99)
Epoch: [54][ 70/391]	Time  0.037 ( 0.040)	Data  0.001 ( 0.003)	Loss 1.0543e-01 (6.9613e-02)	Acc@1  95.31 ( 97.48)	Acc@5 100.00 ( 99.99)
Epoch: [54][ 80/391]	Time  0.034 ( 0.040)	Data  0.001 ( 0.003)	Loss 4.6109e-02 (6.9029e-02)	Acc@1  98.44 ( 97.42)	Acc@5 100.00 ( 99.99)
Epoch: [54][ 90/391]	Time  0.038 ( 0.040)	Data  0.001 ( 0.003)	Loss 4.7266e-02 (6.8765e-02)	Acc@1  99.22 ( 97.42)	Acc@5 100.00 ( 99.99)
Epoch: [54][100/391]	Time  0.039 ( 0.039)	Data  0.001 ( 0.003)	Loss 5.1588e-02 (6.8236e-02)	Acc@1  99.22 ( 97.46)	Acc@5 100.00 ( 99.99)
Epoch: [54][110/391]	Time  0.036 ( 0.039)	Data  0.001 ( 0.002)	Loss 5.1257e-02 (6.8344e-02)	Acc@1  98.44 ( 97.53)	Acc@5 100.00 ( 99.99)
Epoch: [54][120/391]	Time  0.036 ( 0.039)	Data  0.001 ( 0.002)	Loss 6.7698e-02 (6.8192e-02)	Acc@1  96.88 ( 97.53)	Acc@5  99.22 ( 99.99)
Epoch: [54][130/391]	Time  0.037 ( 0.039)	Data  0.001 ( 0.002)	Loss 3.9627e-02 (6.8823e-02)	Acc@1  99.22 ( 97.54)	Acc@5 100.00 ( 99.98)
Epoch: [54][140/391]	Time  0.036 ( 0.039)	Data  0.001 ( 0.002)	Loss 1.1327e-01 (7.0256e-02)	Acc@1  96.09 ( 97.46)	Acc@5 100.00 ( 99.98)
Epoch: [54][150/391]	Time  0.039 ( 0.039)	Data  0.001 ( 0.002)	Loss 5.0245e-02 (7.0370e-02)	Acc@1  98.44 ( 97.45)	Acc@5 100.00 ( 99.98)
Epoch: [54][160/391]	Time  0.037 ( 0.039)	Data  0.001 ( 0.002)	Loss 7.2226e-02 (6.9094e-02)	Acc@1  96.88 ( 97.53)	Acc@5 100.00 ( 99.99)
Epoch: [54][170/391]	Time  0.036 ( 0.039)	Data  0.001 ( 0.002)	Loss 6.0738e-02 (6.8643e-02)	Acc@1  96.88 ( 97.53)	Acc@5 100.00 ( 99.99)
Epoch: [54][180/391]	Time  0.038 ( 0.039)	Data  0.001 ( 0.002)	Loss 4.5292e-02 (6.8544e-02)	Acc@1  99.22 ( 97.51)	Acc@5 100.00 ( 99.99)
Epoch: [54][190/391]	Time  0.036 ( 0.039)	Data  0.001 ( 0.002)	Loss 4.9252e-02 (6.9389e-02)	Acc@1  97.66 ( 97.50)	Acc@5 100.00 ( 99.99)
Epoch: [54][200/391]	Time  0.039 ( 0.039)	Data  0.001 ( 0.002)	Loss 6.2298e-02 (6.9249e-02)	Acc@1  97.66 ( 97.49)	Acc@5 100.00 ( 99.99)
Epoch: [54][210/391]	Time  0.035 ( 0.039)	Data  0.001 ( 0.002)	Loss 7.3879e-02 (6.9302e-02)	Acc@1  98.44 ( 97.50)	Acc@5 100.00 ( 99.99)
Epoch: [54][220/391]	Time  0.038 ( 0.039)	Data  0.001 ( 0.002)	Loss 8.8350e-02 (6.9547e-02)	Acc@1  98.44 ( 97.50)	Acc@5 100.00 ( 99.99)
Epoch: [54][230/391]	Time  0.037 ( 0.038)	Data  0.001 ( 0.002)	Loss 6.3112e-02 (6.9438e-02)	Acc@1  96.88 ( 97.51)	Acc@5 100.00 ( 99.99)
Epoch: [54][240/391]	Time  0.039 ( 0.038)	Data  0.001 ( 0.002)	Loss 3.0647e-02 (6.9397e-02)	Acc@1 100.00 ( 97.52)	Acc@5 100.00 ( 99.99)
Epoch: [54][250/391]	Time  0.036 ( 0.038)	Data  0.001 ( 0.002)	Loss 7.5573e-02 (6.9625e-02)	Acc@1  98.44 ( 97.52)	Acc@5 100.00 ( 99.99)
Epoch: [54][260/391]	Time  0.039 ( 0.038)	Data  0.001 ( 0.002)	Loss 5.4031e-02 (6.9476e-02)	Acc@1  98.44 ( 97.52)	Acc@5 100.00 ( 99.99)
Epoch: [54][270/391]	Time  0.037 ( 0.038)	Data  0.001 ( 0.002)	Loss 6.5853e-02 (6.9256e-02)	Acc@1  96.88 ( 97.51)	Acc@5 100.00 ( 99.99)
Epoch: [54][280/391]	Time  0.038 ( 0.038)	Data  0.001 ( 0.002)	Loss 1.2631e-01 (6.9346e-02)	Acc@1  94.53 ( 97.52)	Acc@5 100.00 ( 99.99)
Epoch: [54][290/391]	Time  0.036 ( 0.038)	Data  0.001 ( 0.002)	Loss 7.3874e-02 (6.9279e-02)	Acc@1  96.88 ( 97.52)	Acc@5 100.00 ( 99.99)
Epoch: [54][300/391]	Time  0.037 ( 0.038)	Data  0.001 ( 0.002)	Loss 6.8709e-02 (6.9533e-02)	Acc@1  97.66 ( 97.52)	Acc@5 100.00 ( 99.99)
Epoch: [54][310/391]	Time  0.038 ( 0.038)	Data  0.001 ( 0.002)	Loss 6.7634e-02 (6.9494e-02)	Acc@1  97.66 ( 97.51)	Acc@5 100.00 ( 99.99)
Epoch: [54][320/391]	Time  0.040 ( 0.038)	Data  0.001 ( 0.002)	Loss 5.3714e-02 (6.9306e-02)	Acc@1  96.88 ( 97.52)	Acc@5 100.00 ( 99.99)
Epoch: [54][330/391]	Time  0.037 ( 0.038)	Data  0.001 ( 0.001)	Loss 8.4387e-02 (6.9094e-02)	Acc@1  96.09 ( 97.52)	Acc@5 100.00 ( 99.99)
Epoch: [54][340/391]	Time  0.040 ( 0.038)	Data  0.001 ( 0.001)	Loss 5.6732e-02 (6.9591e-02)	Acc@1  97.66 ( 97.51)	Acc@5 100.00 ( 99.99)
Epoch: [54][350/391]	Time  0.039 ( 0.038)	Data  0.001 ( 0.001)	Loss 7.0731e-02 (6.9720e-02)	Acc@1  96.88 ( 97.51)	Acc@5 100.00 ( 99.99)
Epoch: [54][360/391]	Time  0.043 ( 0.038)	Data  0.001 ( 0.001)	Loss 7.5281e-02 (6.9931e-02)	Acc@1  96.88 ( 97.50)	Acc@5 100.00 ( 99.99)
Epoch: [54][370/391]	Time  0.036 ( 0.038)	Data  0.001 ( 0.001)	Loss 9.1374e-02 (7.0354e-02)	Acc@1  96.88 ( 97.50)	Acc@5 100.00 ( 99.99)
Epoch: [54][380/391]	Time  0.037 ( 0.038)	Data  0.001 ( 0.001)	Loss 4.9940e-02 (7.0492e-02)	Acc@1  98.44 ( 97.51)	Acc@5 100.00 ( 99.99)
Epoch: [54][390/391]	Time  0.026 ( 0.038)	Data  0.001 ( 0.001)	Loss 1.9248e-01 (7.0717e-02)	Acc@1  96.25 ( 97.50)	Acc@5 100.00 ( 99.99)
## e[54] optimizer.zero_grad (sum) time: 0.21347522735595703
## e[54]       loss.backward (sum) time: 3.5584003925323486
## e[54]      optimizer.step (sum) time: 1.436142921447754
## epoch[54] training(only) time: 15.088343858718872
# Switched to evaluate mode...
Test: [  0/100]	Time  0.174 ( 0.174)	Loss 1.8951e-01 (1.8951e-01)	Acc@1  94.00 ( 94.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.021 ( 0.033)	Loss 4.1985e-01 (3.3846e-01)	Acc@1  90.00 ( 91.18)	Acc@5 100.00 (100.00)
Test: [ 20/100]	Time  0.018 ( 0.026)	Loss 5.3634e-01 (3.7247e-01)	Acc@1  83.00 ( 90.43)	Acc@5 100.00 ( 99.71)
Test: [ 30/100]	Time  0.021 ( 0.024)	Loss 4.7670e-01 (4.0121e-01)	Acc@1  87.00 ( 90.29)	Acc@5  99.00 ( 99.65)
Test: [ 40/100]	Time  0.018 ( 0.024)	Loss 3.4092e-01 (4.1186e-01)	Acc@1  86.00 ( 89.90)	Acc@5  99.00 ( 99.56)
Test: [ 50/100]	Time  0.021 ( 0.023)	Loss 1.6527e-01 (4.0444e-01)	Acc@1  96.00 ( 90.10)	Acc@5 100.00 ( 99.55)
Test: [ 60/100]	Time  0.023 ( 0.023)	Loss 4.2273e-01 (3.9867e-01)	Acc@1  92.00 ( 90.03)	Acc@5  99.00 ( 99.59)
Test: [ 70/100]	Time  0.018 ( 0.023)	Loss 3.7839e-01 (3.8592e-01)	Acc@1  91.00 ( 90.15)	Acc@5 100.00 ( 99.65)
Test: [ 80/100]	Time  0.017 ( 0.022)	Loss 1.6727e-01 (3.8017e-01)	Acc@1  95.00 ( 90.15)	Acc@5 100.00 ( 99.68)
Test: [ 90/100]	Time  0.021 ( 0.022)	Loss 2.0477e-01 (3.8435e-01)	Acc@1  96.00 ( 90.09)	Acc@5 100.00 ( 99.70)
 * Acc@1 90.060 Acc@5 99.700
### epoch[54] execution time: 17.389233827590942
EPOCH 55
REMOVING: module.fire3.expand_1x1.1.bias
REMOVING: module.fire3.expand_3x3.0.weight
i:   0, name: module.fire3.expand_3x3.0.bias  changing lr from: 0.001094871519790279   to: 0.001000523381565803
i:   1, name: module.fire3.expand_3x3.1.weight  changing lr from: 0.001171518811375115   to: 0.001017173165621964
i:   2, name: module.fire3.expand_3x3.1.bias  changing lr from: 0.001269635752869113   to: 0.001056742984833974
i:   3, name:  module.fire4.squeeze.0.weight  changing lr from: 0.001388580332245936   to: 0.001118584818423256
i:   4, name:    module.fire4.squeeze.0.bias  changing lr from: 0.001527718187744525   to: 0.001202056869053641
i:   5, name:  module.fire4.squeeze.1.weight  changing lr from: 0.001686423010245507   to: 0.001306524063958424
i:   6, name:    module.fire4.squeeze.1.bias  changing lr from: 0.001864076906653316   to: 0.001431358512736174
i:   7, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.002060070726378409   to: 0.001575939924025915
i:   8, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.002273804352935482   to: 0.001739655983196153
i:   9, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.002504686962595886   to: 0.001921902693105492
i:  10, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.002752137251956093   to: 0.002122084679917457
i:  11, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.003015583636209173   to: 0.002339615465877331
i:  12, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.003294464419832793   to: 0.002573917710885370
i:  13, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.003588227941335242   to: 0.002824423424628363
i:  14, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.003896332693631160   to: 0.003090574150960734
i:  15, name:  module.fire5.squeeze.0.weight  changing lr from: 0.004218247421549947   to: 0.003371821126156576
i:  16, name:    module.fire5.squeeze.0.bias  changing lr from: 0.004553451197913643   to: 0.003667625412586428
i:  17, name:  module.fire5.squeeze.1.weight  changing lr from: 0.004901433479555855   to: 0.003977458009305822
i:  18, name:    module.fire5.squeeze.1.bias  changing lr from: 0.005261694144591349   to: 0.004300799940978644
i:  19, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.005633743512184075   to: 0.004637142326494619
i:  20, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.006017102346003378   to: 0.004985986428580013
i:  21, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.006411301842500394   to: 0.005346843685640467
i:  22, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.006815883605082395   to: 0.005719235727018267
i:  23, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.007230399605208665   to: 0.006102694372789741
i:  24, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.007654412131381244   to: 0.006496761619175572
i:  25, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.008087493726953865   to: 0.006900989610583990
i:  26, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.008529227117635157   to: 0.007314940599257202
i:  27, name:  module.fire6.squeeze.0.weight  changing lr from: 0.008979205129516447   to: 0.007738186893442750
i:  28, name:    module.fire6.squeeze.0.bias  changing lr from: 0.009437030598410695   to: 0.008170310794964830
i:  29, name:  module.fire6.squeeze.1.weight  changing lr from: 0.009902316271246752   to: 0.008610904527026009
i:  30, name:    module.fire6.squeeze.1.bias  changing lr from: 0.010374684700222712   to: 0.009059570153025876
i:  31, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.010853768130383912   to: 0.009515919487143077
i:  32, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.011339208381252956   to: 0.009979573997385610
i:  33, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.011830656723104949   to: 0.010450164701777731
i:  34, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.012327773748445636   to: 0.010927332058313682
i:  35, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.012830229239219299   to: 0.011410725849274883
i:  36, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.013337702030240661   to: 0.011900005060472278
i:  37, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.013849879869316573   to: 0.012394837755944209
i:  38, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.014366459274494377   to: 0.012894900948609223
i:  39, name:  module.fire7.squeeze.0.weight  changing lr from: 0.014887145388847178   to: 0.013399880467343868
i:  40, name:    module.fire7.squeeze.0.bias  changing lr from: 0.015411651833180523   to: 0.013909470820927687
i:  41, name:  module.fire7.squeeze.1.weight  changing lr from: 0.015939700557020375   to: 0.014423375059270445
i:  42, name:    module.fire7.squeeze.1.bias  changing lr from: 0.016471021688219307   to: 0.014941304632311476
i:  43, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.017005353381495402   to: 0.015462979246956981
i:  44, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.017542441666197606   to: 0.015988126722397099
i:  45, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.018082040293571161   to: 0.016516482844123586
i:  46, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.018623910583777475   to: 0.017047791216947078
i:  47, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.019167821272905800   to: 0.017581803117293821
i:  48, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.019713548360195315   to: 0.018118277345041751
i:  49, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.020260874955672276   to: 0.018656980075139242
i:  50, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.020809591128389218   to: 0.019197684709231427
i:  51, name:  module.fire8.squeeze.0.weight  changing lr from: 0.021359493755440724   to: 0.019740171727503530
i:  52, name:    module.fire8.squeeze.0.bias  changing lr from: 0.021910386371915086   to: 0.020284228540935197
i:  53, name:  module.fire8.squeeze.1.weight  changing lr from: 0.022462079021929284   to: 0.020829649344145426
i:  54, name:    module.fire8.squeeze.1.bias  changing lr from: 0.023014388110881967   to: 0.021376234968993435
i:  55, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.023567136259047092   to: 0.021923792739088201
i:  56, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.024120152156621479   to: 0.022472136325347471
i:  57, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.024673270420327388   to: 0.023021085602734109
i:  58, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.025226331451663003   to: 0.023570466508288410
i:  59, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.025779181296883804   to: 0.024120110900562972
i:  60, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.026331671508789622   to: 0.024669856420558491
i:  61, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.026883659010383816   to: 0.025219546354248001
i:  62, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.027435005960463738   to: 0.025769029496770086
i:  63, name:  module.fire9.squeeze.0.weight  changing lr from: 0.027985579621194429   to: 0.026318160018362097
i:  64, name:    module.fire9.squeeze.0.bias  changing lr from: 0.028535252227710497   to: 0.026866797332097372
i:  65, name:  module.fire9.squeeze.1.weight  changing lr from: 0.029083900859785752   to: 0.027414805963483224
i:  66, name:    module.fire9.squeeze.1.bias  changing lr from: 0.029631407315603178   to: 0.027962055421969424
i:  67, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.030177657987653497   to: 0.028508420074410862
i:  68, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.030722543740784536   to: 0.029053779020521798
i:  69, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.031265959792419626   to: 0.029598015970353914
i:  70, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.031807805594958050   to: 0.030141019123824764
i:  71, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.032347984720367269   to: 0.030682681052318667
i:  72, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.032886404746972263   to: 0.031222898582377534
i:  73, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.033422977148443604   to: 0.031761572681494335
i:  74, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.033957617184983295   to: 0.032298608346018845
i:  75, name:           module.conv10.weight  changing lr from: 0.034490243796703700   to: 0.032833914491181067
i:  76, name:             module.conv10.bias  changing lr from: 0.035020779499192356   to: 0.033367403843234243



# Switched to train mode...
Epoch: [55][  0/391]	Time  0.206 ( 0.206)	Data  0.165 ( 0.165)	Loss 4.1891e-02 (4.1891e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [55][ 10/391]	Time  0.036 ( 0.053)	Data  0.001 ( 0.016)	Loss 8.8721e-02 (6.7755e-02)	Acc@1  96.09 ( 97.44)	Acc@5 100.00 (100.00)
Epoch: [55][ 20/391]	Time  0.036 ( 0.046)	Data  0.001 ( 0.009)	Loss 4.1002e-02 (6.6555e-02)	Acc@1  98.44 ( 97.47)	Acc@5 100.00 (100.00)
Epoch: [55][ 30/391]	Time  0.040 ( 0.043)	Data  0.001 ( 0.006)	Loss 6.9628e-02 (7.0983e-02)	Acc@1  97.66 ( 97.38)	Acc@5 100.00 (100.00)
Epoch: [55][ 40/391]	Time  0.040 ( 0.042)	Data  0.001 ( 0.005)	Loss 7.8700e-02 (6.9482e-02)	Acc@1  96.88 ( 97.45)	Acc@5 100.00 (100.00)
Epoch: [55][ 50/391]	Time  0.037 ( 0.041)	Data  0.002 ( 0.004)	Loss 8.2364e-02 (6.7385e-02)	Acc@1  96.88 ( 97.55)	Acc@5 100.00 (100.00)
Epoch: [55][ 60/391]	Time  0.036 ( 0.040)	Data  0.001 ( 0.004)	Loss 4.6809e-02 (6.6856e-02)	Acc@1  97.66 ( 97.54)	Acc@5 100.00 (100.00)
Epoch: [55][ 70/391]	Time  0.039 ( 0.040)	Data  0.001 ( 0.003)	Loss 6.7777e-02 (6.3989e-02)	Acc@1  96.88 ( 97.68)	Acc@5 100.00 (100.00)
Epoch: [55][ 80/391]	Time  0.038 ( 0.039)	Data  0.001 ( 0.003)	Loss 4.3622e-02 (6.2105e-02)	Acc@1  98.44 ( 97.75)	Acc@5 100.00 (100.00)
Epoch: [55][ 90/391]	Time  0.037 ( 0.039)	Data  0.001 ( 0.003)	Loss 7.9267e-02 (6.1901e-02)	Acc@1  96.88 ( 97.72)	Acc@5 100.00 (100.00)
Epoch: [55][100/391]	Time  0.039 ( 0.039)	Data  0.001 ( 0.003)	Loss 7.9751e-02 (6.1966e-02)	Acc@1  96.88 ( 97.73)	Acc@5 100.00 (100.00)
Epoch: [55][110/391]	Time  0.037 ( 0.039)	Data  0.001 ( 0.002)	Loss 4.2990e-02 (6.1446e-02)	Acc@1  99.22 ( 97.74)	Acc@5 100.00 (100.00)
Epoch: [55][120/391]	Time  0.039 ( 0.039)	Data  0.001 ( 0.002)	Loss 8.2066e-02 (6.0607e-02)	Acc@1  96.09 ( 97.80)	Acc@5 100.00 (100.00)
Epoch: [55][130/391]	Time  0.036 ( 0.039)	Data  0.001 ( 0.002)	Loss 5.8346e-02 (6.0444e-02)	Acc@1  97.66 ( 97.82)	Acc@5 100.00 (100.00)
Epoch: [55][140/391]	Time  0.036 ( 0.039)	Data  0.001 ( 0.002)	Loss 4.7152e-02 (6.0561e-02)	Acc@1  98.44 ( 97.80)	Acc@5 100.00 (100.00)
Epoch: [55][150/391]	Time  0.036 ( 0.039)	Data  0.001 ( 0.002)	Loss 3.3889e-02 (6.0744e-02)	Acc@1  99.22 ( 97.82)	Acc@5 100.00 (100.00)
Epoch: [55][160/391]	Time  0.038 ( 0.039)	Data  0.001 ( 0.002)	Loss 6.3341e-02 (6.1686e-02)	Acc@1  98.44 ( 97.80)	Acc@5 100.00 (100.00)
Epoch: [55][170/391]	Time  0.037 ( 0.038)	Data  0.001 ( 0.002)	Loss 3.9619e-02 (6.1965e-02)	Acc@1  99.22 ( 97.81)	Acc@5 100.00 (100.00)
Epoch: [55][180/391]	Time  0.039 ( 0.038)	Data  0.001 ( 0.002)	Loss 7.1556e-02 (6.2599e-02)	Acc@1  98.44 ( 97.78)	Acc@5 100.00 (100.00)
Epoch: [55][190/391]	Time  0.039 ( 0.038)	Data  0.001 ( 0.002)	Loss 3.2154e-02 (6.2663e-02)	Acc@1  98.44 ( 97.78)	Acc@5 100.00 (100.00)
Epoch: [55][200/391]	Time  0.036 ( 0.038)	Data  0.001 ( 0.002)	Loss 1.2830e-01 (6.3699e-02)	Acc@1  96.09 ( 97.77)	Acc@5 100.00 (100.00)
Epoch: [55][210/391]	Time  0.039 ( 0.038)	Data  0.001 ( 0.002)	Loss 2.9774e-02 (6.3397e-02)	Acc@1  99.22 ( 97.77)	Acc@5 100.00 (100.00)
Epoch: [55][220/391]	Time  0.036 ( 0.038)	Data  0.001 ( 0.002)	Loss 5.6178e-02 (6.3600e-02)	Acc@1  98.44 ( 97.77)	Acc@5 100.00 (100.00)
Epoch: [55][230/391]	Time  0.036 ( 0.038)	Data  0.001 ( 0.002)	Loss 9.5311e-02 (6.4004e-02)	Acc@1  95.31 ( 97.76)	Acc@5 100.00 (100.00)
Epoch: [55][240/391]	Time  0.040 ( 0.038)	Data  0.001 ( 0.002)	Loss 3.2606e-02 (6.4211e-02)	Acc@1  98.44 ( 97.76)	Acc@5 100.00 (100.00)
Epoch: [55][250/391]	Time  0.038 ( 0.038)	Data  0.001 ( 0.002)	Loss 1.0500e-01 (6.5130e-02)	Acc@1  96.88 ( 97.72)	Acc@5 100.00 (100.00)
Epoch: [55][260/391]	Time  0.039 ( 0.038)	Data  0.001 ( 0.002)	Loss 5.7982e-02 (6.5030e-02)	Acc@1  97.66 ( 97.73)	Acc@5 100.00 (100.00)
Epoch: [55][270/391]	Time  0.039 ( 0.038)	Data  0.001 ( 0.002)	Loss 6.5542e-02 (6.5242e-02)	Acc@1  96.88 ( 97.72)	Acc@5 100.00 (100.00)
Epoch: [55][280/391]	Time  0.039 ( 0.038)	Data  0.001 ( 0.002)	Loss 9.6111e-02 (6.5659e-02)	Acc@1  96.09 ( 97.71)	Acc@5 100.00 (100.00)
Epoch: [55][290/391]	Time  0.038 ( 0.038)	Data  0.001 ( 0.002)	Loss 1.3675e-01 (6.5916e-02)	Acc@1  97.66 ( 97.72)	Acc@5 100.00 (100.00)
Epoch: [55][300/391]	Time  0.039 ( 0.038)	Data  0.001 ( 0.002)	Loss 4.6565e-02 (6.5769e-02)	Acc@1  97.66 ( 97.71)	Acc@5 100.00 (100.00)
Epoch: [55][310/391]	Time  0.039 ( 0.038)	Data  0.001 ( 0.002)	Loss 1.3757e-01 (6.5931e-02)	Acc@1  92.97 ( 97.70)	Acc@5 100.00 (100.00)
Epoch: [55][320/391]	Time  0.036 ( 0.038)	Data  0.001 ( 0.001)	Loss 6.1505e-02 (6.6376e-02)	Acc@1  98.44 ( 97.67)	Acc@5 100.00 (100.00)
Epoch: [55][330/391]	Time  0.036 ( 0.038)	Data  0.001 ( 0.001)	Loss 3.0201e-02 (6.6555e-02)	Acc@1  99.22 ( 97.66)	Acc@5 100.00 (100.00)
Epoch: [55][340/391]	Time  0.036 ( 0.038)	Data  0.001 ( 0.001)	Loss 2.4076e-02 (6.6393e-02)	Acc@1  99.22 ( 97.67)	Acc@5 100.00 (100.00)
Epoch: [55][350/391]	Time  0.038 ( 0.038)	Data  0.001 ( 0.001)	Loss 6.6515e-02 (6.6113e-02)	Acc@1  98.44 ( 97.68)	Acc@5 100.00 (100.00)
Epoch: [55][360/391]	Time  0.036 ( 0.038)	Data  0.001 ( 0.001)	Loss 6.3228e-02 (6.6132e-02)	Acc@1  97.66 ( 97.68)	Acc@5 100.00 (100.00)
Epoch: [55][370/391]	Time  0.036 ( 0.038)	Data  0.001 ( 0.001)	Loss 4.6613e-02 (6.6065e-02)	Acc@1  98.44 ( 97.69)	Acc@5 100.00 (100.00)
Epoch: [55][380/391]	Time  0.036 ( 0.038)	Data  0.001 ( 0.001)	Loss 4.3330e-02 (6.6213e-02)	Acc@1  97.66 ( 97.68)	Acc@5 100.00 (100.00)
Epoch: [55][390/391]	Time  0.026 ( 0.038)	Data  0.001 ( 0.001)	Loss 6.1535e-02 (6.6149e-02)	Acc@1  96.25 ( 97.68)	Acc@5 100.00 (100.00)
## e[55] optimizer.zero_grad (sum) time: 0.20679926872253418
## e[55]       loss.backward (sum) time: 3.4541001319885254
## e[55]      optimizer.step (sum) time: 1.4088575839996338
## epoch[55] training(only) time: 14.929490566253662
# Switched to evaluate mode...
Test: [  0/100]	Time  0.164 ( 0.164)	Loss 1.5959e-01 (1.5959e-01)	Acc@1  94.00 ( 94.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.022 ( 0.035)	Loss 4.6464e-01 (3.4197e-01)	Acc@1  89.00 ( 91.27)	Acc@5  99.00 ( 99.73)
Test: [ 20/100]	Time  0.023 ( 0.028)	Loss 4.1210e-01 (3.7703e-01)	Acc@1  88.00 ( 90.48)	Acc@5 100.00 ( 99.52)
Test: [ 30/100]	Time  0.022 ( 0.026)	Loss 4.9217e-01 (4.0494e-01)	Acc@1  89.00 ( 90.29)	Acc@5  98.00 ( 99.45)
Test: [ 40/100]	Time  0.023 ( 0.025)	Loss 4.2098e-01 (4.0787e-01)	Acc@1  88.00 ( 90.39)	Acc@5 100.00 ( 99.44)
Test: [ 50/100]	Time  0.022 ( 0.024)	Loss 1.8521e-01 (4.0078e-01)	Acc@1  94.00 ( 90.65)	Acc@5 100.00 ( 99.49)
Test: [ 60/100]	Time  0.016 ( 0.023)	Loss 4.0172e-01 (3.9286e-01)	Acc@1  90.00 ( 90.57)	Acc@5  99.00 ( 99.52)
Test: [ 70/100]	Time  0.018 ( 0.023)	Loss 4.5681e-01 (3.8785e-01)	Acc@1  90.00 ( 90.56)	Acc@5 100.00 ( 99.56)
Test: [ 80/100]	Time  0.023 ( 0.023)	Loss 1.8426e-01 (3.8151e-01)	Acc@1  94.00 ( 90.54)	Acc@5 100.00 ( 99.59)
Test: [ 90/100]	Time  0.023 ( 0.023)	Loss 1.6716e-01 (3.8550e-01)	Acc@1  96.00 ( 90.41)	Acc@5 100.00 ( 99.62)
 * Acc@1 90.500 Acc@5 99.640
### epoch[55] execution time: 17.297507286071777
EPOCH 56
REMOVING: module.fire3.expand_3x3.0.bias
REMOVING: module.fire3.expand_3x3.1.weight
REMOVING: module.fire3.expand_3x3.1.bias
i:   0, name:  module.fire4.squeeze.0.weight  changing lr from: 0.001118584818423256   to: 0.001004236984742045
i:   1, name:    module.fire4.squeeze.0.bias  changing lr from: 0.001202056869053641   to: 0.001029662017431292
i:   2, name:  module.fire4.squeeze.1.weight  changing lr from: 0.001306524063958424   to: 0.001077487372257396
i:   3, name:    module.fire4.squeeze.1.bias  changing lr from: 0.001431358512736174   to: 0.001147078862434624
i:   4, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.001575939924025915   to: 0.001237808566610675
i:   5, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.001739655983196153   to: 0.001349055299172429
i:   6, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.001921902693105492   to: 0.001480205039554582
i:   7, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.002122084679917457   to: 0.001630651322643810
i:   8, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.002339615465877331   to: 0.001799795592298447
i:   9, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.002573917710885370   to: 0.001987047519930779
i:  10, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.002824423424628363   to: 0.002191825290027904
i:  11, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.003090574150960734   to: 0.002413555854415849
i:  12, name:  module.fire5.squeeze.0.weight  changing lr from: 0.003371821126156576   to: 0.002651675157002353
i:  13, name:    module.fire5.squeeze.0.bias  changing lr from: 0.003667625412586428   to: 0.002905628330664955
i:  14, name:  module.fire5.squeeze.1.weight  changing lr from: 0.003977458009305822   to: 0.003174869867883811
i:  15, name:    module.fire5.squeeze.1.bias  changing lr from: 0.004300799940978644   to: 0.003458863766653319
i:  16, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.004637142326494619   to: 0.003757083653141585
i:  17, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.004985986428580013   to: 0.004069012882504996
i:  18, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.005346843685640467   to: 0.004394144619203093
i:  19, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.005719235727018267   to: 0.004731981898100434
i:  20, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.006102694372789741   to: 0.005082037667583494
i:  21, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.006496761619175572   to: 0.005443834815865472
i:  22, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.006900989610583990   to: 0.005816906181596775
i:  23, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.007314940599257202   to: 0.006200794549846982
i:  24, name:  module.fire6.squeeze.0.weight  changing lr from: 0.007738186893442750   to: 0.006595052634472981
i:  25, name:    module.fire6.squeeze.0.bias  changing lr from: 0.008170310794964830   to: 0.006999243047838821
i:  26, name:  module.fire6.squeeze.1.weight  changing lr from: 0.008610904527026009   to: 0.007412938258805645
i:  27, name:    module.fire6.squeeze.1.bias  changing lr from: 0.009059570153025876   to: 0.007835720539863904
i:  28, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.009515919487143077   to: 0.008267181904236798
i:  29, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.009979573997385610   to: 0.008706924033740564
i:  30, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.010450164701777731   to: 0.009154558198147460
i:  31, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.010927332058313682   to: 0.009609705166757011
i:  32, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.011410725849274883   to: 0.010071995112844827
i:  33, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.011900005060472278   to: 0.010541067511620893
i:  34, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.012394837755944209   to: 0.011016571032295509
i:  35, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.012894900948609223   to: 0.011498163424817527
i:  36, name:  module.fire7.squeeze.0.weight  changing lr from: 0.013399880467343868   to: 0.011985511401818111
i:  37, name:    module.fire7.squeeze.0.bias  changing lr from: 0.013909470820927687   to: 0.012478290516262508
i:  38, name:  module.fire7.squeeze.1.weight  changing lr from: 0.014423375059270445   to: 0.012976185035283305
i:  39, name:    module.fire7.squeeze.1.bias  changing lr from: 0.014941304632311476   to: 0.013478887810641483
i:  40, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.015462979246956981   to: 0.013986100146234248
i:  41, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.015988126722397099   to: 0.014497531663043944
i:  42, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.016516482844123586   to: 0.015012900161898074
i:  43, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.017047791216947078   to: 0.015531931484387106
i:  44, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.017581803117293821   to: 0.016054359372265802
i:  45, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.018118277345041751   to: 0.016579925325641415
i:  46, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.018656980075139242   to: 0.017108378460234209
i:  47, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.019197684709231427   to: 0.017639475363974911
i:  48, name:  module.fire8.squeeze.0.weight  changing lr from: 0.019740171727503530   to: 0.018172979953187490
i:  49, name:    module.fire8.squeeze.0.bias  changing lr from: 0.020284228540935197   to: 0.018708663328587113
i:  50, name:  module.fire8.squeeze.1.weight  changing lr from: 0.020829649344145426   to: 0.019246303631308432
i:  51, name:    module.fire8.squeeze.1.bias  changing lr from: 0.021376234968993435   to: 0.019785685899162936
i:  52, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.021923792739088201   to: 0.020326601923309685
i:  53, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.022472136325347471   to: 0.020868850105510900
i:  54, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.023021085602734109   to: 0.021412235316129419
i:  55, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.023570466508288410   to: 0.021956568753013925
i:  56, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.024120110900562972   to: 0.022501667801405167
i:  57, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.024669856420558491   to: 0.023047355894986576
i:  58, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.025219546354248001   to: 0.023593462378190655
i:  59, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.025769029496770086   to: 0.024139822369864186
i:  60, name:  module.fire9.squeeze.0.weight  changing lr from: 0.026318160018362097   to: 0.024686276628385052
i:  61, name:    module.fire9.squeeze.0.bias  changing lr from: 0.026866797332097372   to: 0.025232671418315252
i:  62, name:  module.fire9.squeeze.1.weight  changing lr from: 0.027414805963483224   to: 0.025778858378665906
i:  63, name:    module.fire9.squeeze.1.bias  changing lr from: 0.027962055421969424   to: 0.026324694392842924
i:  64, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.028508420074410862   to: 0.026870041460334289
i:  65, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.029053779020521798   to: 0.027414766570192879
i:  66, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.029598015970353914   to: 0.027958741576363133
i:  67, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.030141019123824764   to: 0.028501843074892497
i:  68, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.030682681052318667   to: 0.029043952283064434
i:  69, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.031222898582377534   to: 0.029584954920483231
i:  70, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.031761572681494335   to: 0.030124741092136222
i:  71, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.032298608346018845   to: 0.030663205173455128
i:  72, name:           module.conv10.weight  changing lr from: 0.032833914491181067   to: 0.031200245697392600
i:  73, name:             module.conv10.bias  changing lr from: 0.033367403843234243   to: 0.031735765243527003



# Switched to train mode...
Epoch: [56][  0/391]	Time  0.230 ( 0.230)	Data  0.185 ( 0.185)	Loss 3.5490e-02 (3.5490e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [56][ 10/391]	Time  0.036 ( 0.054)	Data  0.001 ( 0.018)	Loss 2.3889e-02 (5.1910e-02)	Acc@1  99.22 ( 98.08)	Acc@5 100.00 (100.00)
Epoch: [56][ 20/391]	Time  0.037 ( 0.046)	Data  0.001 ( 0.010)	Loss 3.0700e-02 (5.3746e-02)	Acc@1  98.44 ( 98.03)	Acc@5 100.00 (100.00)
Epoch: [56][ 30/391]	Time  0.039 ( 0.043)	Data  0.001 ( 0.007)	Loss 7.5535e-02 (5.6024e-02)	Acc@1  96.88 ( 98.08)	Acc@5 100.00 (100.00)
Epoch: [56][ 40/391]	Time  0.037 ( 0.042)	Data  0.001 ( 0.005)	Loss 1.0518e-01 (5.8635e-02)	Acc@1  96.09 ( 97.98)	Acc@5 100.00 ( 99.98)
Epoch: [56][ 50/391]	Time  0.038 ( 0.041)	Data  0.001 ( 0.004)	Loss 5.0905e-02 (6.0050e-02)	Acc@1  96.88 ( 97.81)	Acc@5 100.00 ( 99.98)
Epoch: [56][ 60/391]	Time  0.035 ( 0.041)	Data  0.001 ( 0.004)	Loss 4.0941e-02 (5.9114e-02)	Acc@1  97.66 ( 97.80)	Acc@5 100.00 ( 99.99)
Epoch: [56][ 70/391]	Time  0.035 ( 0.040)	Data  0.001 ( 0.003)	Loss 1.0296e-01 (6.0395e-02)	Acc@1  95.31 ( 97.76)	Acc@5 100.00 ( 99.99)
Epoch: [56][ 80/391]	Time  0.040 ( 0.040)	Data  0.001 ( 0.003)	Loss 5.8737e-02 (6.2553e-02)	Acc@1  97.66 ( 97.67)	Acc@5 100.00 ( 99.99)
Epoch: [56][ 90/391]	Time  0.035 ( 0.040)	Data  0.001 ( 0.003)	Loss 4.9549e-02 (6.3344e-02)	Acc@1  97.66 ( 97.64)	Acc@5 100.00 ( 99.99)
Epoch: [56][100/391]	Time  0.035 ( 0.039)	Data  0.001 ( 0.003)	Loss 4.4635e-02 (6.3187e-02)	Acc@1  98.44 ( 97.61)	Acc@5 100.00 ( 99.99)
Epoch: [56][110/391]	Time  0.037 ( 0.039)	Data  0.001 ( 0.003)	Loss 4.2171e-02 (6.3002e-02)	Acc@1  97.66 ( 97.63)	Acc@5 100.00 ( 99.99)
Epoch: [56][120/391]	Time  0.037 ( 0.039)	Data  0.001 ( 0.002)	Loss 7.4035e-02 (6.3281e-02)	Acc@1  97.66 ( 97.64)	Acc@5 100.00 ( 99.99)
Epoch: [56][130/391]	Time  0.035 ( 0.039)	Data  0.001 ( 0.002)	Loss 7.3341e-02 (6.3935e-02)	Acc@1  97.66 ( 97.64)	Acc@5 100.00 ( 99.99)
Epoch: [56][140/391]	Time  0.037 ( 0.039)	Data  0.001 ( 0.002)	Loss 5.9083e-02 (6.3608e-02)	Acc@1  98.44 ( 97.68)	Acc@5 100.00 ( 99.99)
Epoch: [56][150/391]	Time  0.035 ( 0.038)	Data  0.001 ( 0.002)	Loss 3.6602e-02 (6.2867e-02)	Acc@1  97.66 ( 97.70)	Acc@5 100.00 ( 99.99)
Epoch: [56][160/391]	Time  0.036 ( 0.038)	Data  0.001 ( 0.002)	Loss 5.4356e-02 (6.2033e-02)	Acc@1  98.44 ( 97.74)	Acc@5 100.00 (100.00)
Epoch: [56][170/391]	Time  0.037 ( 0.038)	Data  0.001 ( 0.002)	Loss 1.1539e-01 (6.2054e-02)	Acc@1  95.31 ( 97.75)	Acc@5 100.00 (100.00)
Epoch: [56][180/391]	Time  0.036 ( 0.038)	Data  0.001 ( 0.002)	Loss 3.6715e-02 (6.1907e-02)	Acc@1  98.44 ( 97.77)	Acc@5 100.00 (100.00)
Epoch: [56][190/391]	Time  0.038 ( 0.038)	Data  0.001 ( 0.002)	Loss 6.2608e-02 (6.1566e-02)	Acc@1  98.44 ( 97.79)	Acc@5 100.00 (100.00)
Epoch: [56][200/391]	Time  0.040 ( 0.038)	Data  0.001 ( 0.002)	Loss 6.0561e-02 (6.0526e-02)	Acc@1  97.66 ( 97.84)	Acc@5 100.00 (100.00)
Epoch: [56][210/391]	Time  0.036 ( 0.038)	Data  0.001 ( 0.002)	Loss 3.0448e-02 (6.0078e-02)	Acc@1  99.22 ( 97.86)	Acc@5 100.00 (100.00)
Epoch: [56][220/391]	Time  0.049 ( 0.038)	Data  0.001 ( 0.002)	Loss 5.5228e-02 (6.0054e-02)	Acc@1  97.66 ( 97.85)	Acc@5 100.00 (100.00)
Epoch: [56][230/391]	Time  0.036 ( 0.038)	Data  0.001 ( 0.002)	Loss 1.3639e-01 (6.1193e-02)	Acc@1  93.75 ( 97.82)	Acc@5 100.00 (100.00)
Epoch: [56][240/391]	Time  0.046 ( 0.038)	Data  0.001 ( 0.002)	Loss 3.2360e-02 (6.1193e-02)	Acc@1  99.22 ( 97.82)	Acc@5 100.00 (100.00)
Epoch: [56][250/391]	Time  0.035 ( 0.038)	Data  0.001 ( 0.002)	Loss 9.3124e-02 (6.1356e-02)	Acc@1  98.44 ( 97.82)	Acc@5 100.00 (100.00)
Epoch: [56][260/391]	Time  0.038 ( 0.038)	Data  0.001 ( 0.002)	Loss 7.6833e-02 (6.1885e-02)	Acc@1  96.88 ( 97.79)	Acc@5 100.00 (100.00)
Epoch: [56][270/391]	Time  0.036 ( 0.038)	Data  0.001 ( 0.002)	Loss 6.7556e-02 (6.2049e-02)	Acc@1  96.09 ( 97.78)	Acc@5 100.00 ( 99.99)
Epoch: [56][280/391]	Time  0.035 ( 0.038)	Data  0.001 ( 0.002)	Loss 8.2786e-02 (6.2396e-02)	Acc@1  99.22 ( 97.78)	Acc@5 100.00 ( 99.99)
Epoch: [56][290/391]	Time  0.037 ( 0.038)	Data  0.001 ( 0.002)	Loss 7.4848e-02 (6.2385e-02)	Acc@1  97.66 ( 97.79)	Acc@5 100.00 ( 99.99)
Epoch: [56][300/391]	Time  0.037 ( 0.038)	Data  0.001 ( 0.002)	Loss 2.4406e-02 (6.2521e-02)	Acc@1 100.00 ( 97.79)	Acc@5 100.00 ( 99.99)
Epoch: [56][310/391]	Time  0.035 ( 0.038)	Data  0.001 ( 0.002)	Loss 7.1395e-02 (6.2566e-02)	Acc@1  96.88 ( 97.78)	Acc@5 100.00 ( 99.99)
Epoch: [56][320/391]	Time  0.037 ( 0.038)	Data  0.001 ( 0.001)	Loss 2.6348e-02 (6.2614e-02)	Acc@1  99.22 ( 97.79)	Acc@5 100.00 (100.00)
Epoch: [56][330/391]	Time  0.035 ( 0.038)	Data  0.001 ( 0.001)	Loss 1.1132e-01 (6.2779e-02)	Acc@1  96.09 ( 97.78)	Acc@5 100.00 (100.00)
Epoch: [56][340/391]	Time  0.038 ( 0.038)	Data  0.001 ( 0.001)	Loss 5.1818e-02 (6.2854e-02)	Acc@1  96.88 ( 97.78)	Acc@5 100.00 (100.00)
Epoch: [56][350/391]	Time  0.037 ( 0.038)	Data  0.001 ( 0.001)	Loss 6.4032e-02 (6.3124e-02)	Acc@1  96.88 ( 97.77)	Acc@5 100.00 ( 99.99)
Epoch: [56][360/391]	Time  0.036 ( 0.038)	Data  0.001 ( 0.001)	Loss 5.6199e-02 (6.3083e-02)	Acc@1  96.88 ( 97.78)	Acc@5 100.00 ( 99.99)
Epoch: [56][370/391]	Time  0.036 ( 0.038)	Data  0.001 ( 0.001)	Loss 8.4403e-02 (6.3300e-02)	Acc@1  97.66 ( 97.77)	Acc@5 100.00 ( 99.99)
Epoch: [56][380/391]	Time  0.036 ( 0.038)	Data  0.001 ( 0.001)	Loss 4.7729e-02 (6.3034e-02)	Acc@1  98.44 ( 97.78)	Acc@5 100.00 ( 99.99)
Epoch: [56][390/391]	Time  0.026 ( 0.037)	Data  0.001 ( 0.001)	Loss 5.5088e-02 (6.3299e-02)	Acc@1  98.75 ( 97.78)	Acc@5 100.00 ( 99.99)
## e[56] optimizer.zero_grad (sum) time: 0.2002112865447998
## e[56]       loss.backward (sum) time: 3.415792942047119
## e[56]      optimizer.step (sum) time: 1.3005702495574951
## epoch[56] training(only) time: 14.813708066940308
# Switched to evaluate mode...
Test: [  0/100]	Time  0.167 ( 0.167)	Loss 1.8205e-01 (1.8205e-01)	Acc@1  93.00 ( 93.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.023 ( 0.036)	Loss 5.0824e-01 (3.1890e-01)	Acc@1  89.00 ( 91.00)	Acc@5 100.00 (100.00)
Test: [ 20/100]	Time  0.024 ( 0.029)	Loss 3.3838e-01 (3.4392e-01)	Acc@1  88.00 ( 90.86)	Acc@5 100.00 ( 99.81)
Test: [ 30/100]	Time  0.023 ( 0.026)	Loss 4.8418e-01 (3.7250e-01)	Acc@1  87.00 ( 90.90)	Acc@5  99.00 ( 99.77)
Test: [ 40/100]	Time  0.020 ( 0.025)	Loss 3.4308e-01 (3.8034e-01)	Acc@1  88.00 ( 90.61)	Acc@5  99.00 ( 99.66)
Test: [ 50/100]	Time  0.021 ( 0.024)	Loss 1.5636e-01 (3.7065e-01)	Acc@1  96.00 ( 90.92)	Acc@5 100.00 ( 99.63)
Test: [ 60/100]	Time  0.024 ( 0.023)	Loss 3.6116e-01 (3.6525e-01)	Acc@1  94.00 ( 90.80)	Acc@5 100.00 ( 99.64)
Test: [ 70/100]	Time  0.017 ( 0.023)	Loss 4.9365e-01 (3.5618e-01)	Acc@1  88.00 ( 91.00)	Acc@5 100.00 ( 99.66)
Test: [ 80/100]	Time  0.020 ( 0.022)	Loss 1.8258e-01 (3.5192e-01)	Acc@1  95.00 ( 91.06)	Acc@5 100.00 ( 99.69)
Test: [ 90/100]	Time  0.022 ( 0.022)	Loss 2.5718e-01 (3.5769e-01)	Acc@1  97.00 ( 91.03)	Acc@5 100.00 ( 99.73)
 * Acc@1 90.940 Acc@5 99.730
### epoch[56] execution time: 17.093324184417725
EPOCH 57
REMOVING: module.fire4.squeeze.0.weight
REMOVING: module.fire4.squeeze.0.bias
i:   0, name:  module.fire4.squeeze.1.weight  changing lr from: 0.001077487372257396   to: 0.001000008257637818
i:   1, name:    module.fire4.squeeze.1.bias  changing lr from: 0.001147078862434624   to: 0.001012089262398601
i:   2, name: module.fire4.expand_1x1.0.weight  changing lr from: 0.001237808566610675   to: 0.001046675499440468
i:   3, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.001349055299172429   to: 0.001103140535388452
i:   4, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.001480205039554582   to: 0.001180863766474121
i:   5, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.001630651322643810   to: 0.001279230899684119
i:   6, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.001799795592298447   to: 0.001397634393104013
i:   7, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.001987047519930779   to: 0.001535473857507407
i:   8, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.002191825290027904   to: 0.001692156421170526
i:   9, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.002413555854415849   to: 0.001867097059823185
i:  10, name:  module.fire5.squeeze.0.weight  changing lr from: 0.002651675157002353   to: 0.002059718893578049
i:  11, name:    module.fire5.squeeze.0.bias  changing lr from: 0.002905628330664955   to: 0.002269453452612185
i:  12, name:  module.fire5.squeeze.1.weight  changing lr from: 0.003174869867883811   to: 0.002495740913307520
i:  13, name:    module.fire5.squeeze.1.bias  changing lr from: 0.003458863766653319   to: 0.002738030306491256
i:  14, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.003757083653141585   to: 0.002995779699351652
i:  15, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.004069012882504996   to: 0.003268456352541687
i:  16, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.004394144619203093   to: 0.003555536853920365
i:  17, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.004731981898100434   to: 0.003856507230321010
i:  18, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.005082037667583494   to: 0.004170863038676109
i:  19, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.005443834815865472   to: 0.004498109437771135
i:  20, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.005816906181596775   to: 0.004837761241843008
i:  21, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.006200794549846982   to: 0.005189342957184677
i:  22, name:  module.fire6.squeeze.0.weight  changing lr from: 0.006595052634472981   to: 0.005552388802864227
i:  23, name:    module.fire6.squeeze.0.bias  changing lr from: 0.006999243047838821   to: 0.005926442716615714
i:  24, name:  module.fire6.squeeze.1.weight  changing lr from: 0.007412938258805645   to: 0.006311058346909182
i:  25, name:    module.fire6.squeeze.1.bias  changing lr from: 0.007835720539863904   to: 0.006705799032159254
i:  26, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.008267181904236798   to: 0.007110237767985711
i:  27, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.008706924033740564   to: 0.007523957163394140
i:  28, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.009154558198147460   to: 0.007946549386702195
i:  29, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.009609705166757011   to: 0.008377616101994756
i:  30, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.010071995112844827   to: 0.008816768396852182
i:  31, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.010541067511620893   to: 0.009263626702056382
i:  32, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.011016571032295509   to: 0.009717820703943274
i:  33, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.011498163424817527   to: 0.010178989250034159
i:  34, name:  module.fire7.squeeze.0.weight  changing lr from: 0.011985511401818111   to: 0.010646780248544790
i:  35, name:    module.fire7.squeeze.0.bias  changing lr from: 0.012478290516262508   to: 0.011120850562338230
i:  36, name:  module.fire7.squeeze.1.weight  changing lr from: 0.012976185035283305   to: 0.011600865897855937
i:  37, name:    module.fire7.squeeze.1.bias  changing lr from: 0.013478887810641483   to: 0.012086500689532126
i:  38, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.013986100146234248   to: 0.012577437980167288
i:  39, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.014497531663043944   to: 0.013073369297709508
i:  40, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.015012900161898074   to: 0.013573994528866252
i:  41, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.015531931484387106   to: 0.014079021789943517
i:  42, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.016054359372265802   to: 0.014588167295286537
i:  43, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.016579925325641415   to: 0.015101155223672058
i:  44, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.017108378460234209   to: 0.015617717582981812
i:  45, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.017639475363974911   to: 0.016137594073464968
i:  46, name:  module.fire8.squeeze.0.weight  changing lr from: 0.018172979953187490   to: 0.016660531949878443
i:  47, name:    module.fire8.squeeze.0.bias  changing lr from: 0.018708663328587113   to: 0.017186285882774665
i:  48, name:  module.fire8.squeeze.1.weight  changing lr from: 0.019246303631308432   to: 0.017714617819188944
i:  49, name:    module.fire8.squeeze.1.bias  changing lr from: 0.019785685899162936   to: 0.018245296842961455
i:  50, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.020326601923309685   to: 0.018778099034912350
i:  51, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.020868850105510900   to: 0.019312807333074205
i:  52, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.021412235316129419   to: 0.019849211393170293
i:  53, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.021956568753013925   to: 0.020387107449514438
i:  54, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.022501667801405167   to: 0.020926298176494190
i:  55, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.023047355894986576   to: 0.021466592550787846
i:  56, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.023593462378190655   to: 0.022007805714452919
i:  57, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.024139822369864186   to: 0.022549758839013542
i:  58, name:  module.fire9.squeeze.0.weight  changing lr from: 0.024686276628385052   to: 0.023092278990663302
i:  59, name:    module.fire9.squeeze.0.bias  changing lr from: 0.025232671418315252   to: 0.023635198996690268
i:  60, name:  module.fire9.squeeze.1.weight  changing lr from: 0.025778858378665906   to: 0.024178357313221724
i:  61, name:    module.fire9.squeeze.1.bias  changing lr from: 0.026324694392842924   to: 0.024721597894377126
i:  62, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.026870041460334289   to: 0.025264770062909558
i:  63, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.027414766570192879   to: 0.025807728382408381
i:  64, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.027958741576363133   to: 0.026350332531127719
i:  65, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.028501843074892497   to: 0.026892447177499491
i:  66, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.029043952283064434   to: 0.027433941857382238
i:  67, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.029584954920483231   to: 0.027974690853091413
i:  68, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.030124741092136222   to: 0.028514573074250683
i:  69, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.030663205173455128   to: 0.029053471940499006
i:  70, name:           module.conv10.weight  changing lr from: 0.031200245697392600   to: 0.029591275266082375
i:  71, name:             module.conv10.bias  changing lr from: 0.031735765243527003   to: 0.030127875146354961



# Switched to train mode...
Epoch: [57][  0/391]	Time  0.211 ( 0.211)	Data  0.172 ( 0.172)	Loss 4.1057e-02 (4.1057e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [57][ 10/391]	Time  0.036 ( 0.053)	Data  0.001 ( 0.016)	Loss 6.0344e-02 (6.8704e-02)	Acc@1  96.88 ( 97.30)	Acc@5 100.00 (100.00)
Epoch: [57][ 20/391]	Time  0.035 ( 0.046)	Data  0.001 ( 0.009)	Loss 3.1504e-02 (6.9667e-02)	Acc@1  98.44 ( 97.28)	Acc@5 100.00 (100.00)
Epoch: [57][ 30/391]	Time  0.035 ( 0.043)	Data  0.001 ( 0.006)	Loss 9.3693e-02 (6.6069e-02)	Acc@1  96.88 ( 97.51)	Acc@5 100.00 (100.00)
Epoch: [57][ 40/391]	Time  0.039 ( 0.042)	Data  0.001 ( 0.005)	Loss 7.8168e-02 (6.3827e-02)	Acc@1  96.88 ( 97.60)	Acc@5 100.00 (100.00)
Epoch: [57][ 50/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.004)	Loss 4.4924e-02 (6.1625e-02)	Acc@1  96.88 ( 97.66)	Acc@5 100.00 (100.00)
Epoch: [57][ 60/391]	Time  0.039 ( 0.040)	Data  0.001 ( 0.004)	Loss 2.2685e-02 (6.1405e-02)	Acc@1  99.22 ( 97.73)	Acc@5 100.00 ( 99.99)
Epoch: [57][ 70/391]	Time  0.039 ( 0.040)	Data  0.001 ( 0.003)	Loss 4.1659e-02 (5.8661e-02)	Acc@1  99.22 ( 97.89)	Acc@5 100.00 ( 99.99)
Epoch: [57][ 80/391]	Time  0.039 ( 0.039)	Data  0.001 ( 0.003)	Loss 7.2024e-02 (5.6777e-02)	Acc@1  98.44 ( 98.00)	Acc@5 100.00 ( 99.99)
Epoch: [57][ 90/391]	Time  0.035 ( 0.039)	Data  0.001 ( 0.003)	Loss 2.6732e-02 (5.7700e-02)	Acc@1  99.22 ( 97.97)	Acc@5 100.00 ( 99.98)
Epoch: [57][100/391]	Time  0.034 ( 0.039)	Data  0.001 ( 0.003)	Loss 4.4282e-02 (5.7999e-02)	Acc@1  98.44 ( 97.94)	Acc@5 100.00 ( 99.98)
Epoch: [57][110/391]	Time  0.048 ( 0.039)	Data  0.001 ( 0.002)	Loss 4.9243e-02 (5.7254e-02)	Acc@1  96.88 ( 97.99)	Acc@5 100.00 ( 99.99)
Epoch: [57][120/391]	Time  0.040 ( 0.039)	Data  0.001 ( 0.002)	Loss 2.8357e-02 (5.7552e-02)	Acc@1  98.44 ( 97.99)	Acc@5 100.00 ( 99.99)
Epoch: [57][130/391]	Time  0.040 ( 0.038)	Data  0.001 ( 0.002)	Loss 6.0968e-02 (5.8720e-02)	Acc@1  98.44 ( 97.94)	Acc@5 100.00 ( 99.99)
Epoch: [57][140/391]	Time  0.036 ( 0.038)	Data  0.001 ( 0.002)	Loss 2.9471e-02 (5.9314e-02)	Acc@1 100.00 ( 97.93)	Acc@5 100.00 ( 99.99)
Epoch: [57][150/391]	Time  0.038 ( 0.038)	Data  0.001 ( 0.002)	Loss 5.5061e-02 (5.9092e-02)	Acc@1  98.44 ( 97.95)	Acc@5 100.00 ( 99.99)
Epoch: [57][160/391]	Time  0.036 ( 0.038)	Data  0.001 ( 0.002)	Loss 5.2627e-02 (5.9167e-02)	Acc@1  98.44 ( 97.96)	Acc@5 100.00 ( 99.99)
Epoch: [57][170/391]	Time  0.036 ( 0.038)	Data  0.001 ( 0.002)	Loss 4.0122e-02 (5.8993e-02)	Acc@1  99.22 ( 97.98)	Acc@5 100.00 ( 99.99)
Epoch: [57][180/391]	Time  0.035 ( 0.038)	Data  0.001 ( 0.002)	Loss 4.9619e-02 (5.8947e-02)	Acc@1  98.44 ( 97.99)	Acc@5 100.00 ( 99.99)
Epoch: [57][190/391]	Time  0.039 ( 0.038)	Data  0.001 ( 0.002)	Loss 1.9609e-02 (5.8770e-02)	Acc@1  98.44 ( 97.97)	Acc@5 100.00 ( 99.99)
Epoch: [57][200/391]	Time  0.039 ( 0.038)	Data  0.001 ( 0.002)	Loss 6.9021e-02 (5.8629e-02)	Acc@1  97.66 ( 97.97)	Acc@5 100.00 ( 99.99)
Epoch: [57][210/391]	Time  0.040 ( 0.038)	Data  0.001 ( 0.002)	Loss 2.8549e-02 (5.7988e-02)	Acc@1 100.00 ( 97.99)	Acc@5 100.00 ( 99.99)
Epoch: [57][220/391]	Time  0.038 ( 0.038)	Data  0.001 ( 0.002)	Loss 3.2076e-02 (5.8251e-02)	Acc@1  99.22 ( 97.99)	Acc@5 100.00 ( 99.99)
Epoch: [57][230/391]	Time  0.043 ( 0.038)	Data  0.001 ( 0.002)	Loss 3.7231e-02 (5.7796e-02)	Acc@1  98.44 ( 98.00)	Acc@5 100.00 ( 99.99)
Epoch: [57][240/391]	Time  0.035 ( 0.038)	Data  0.001 ( 0.002)	Loss 4.1720e-02 (5.7925e-02)	Acc@1  99.22 ( 98.00)	Acc@5 100.00 ( 99.99)
Epoch: [57][250/391]	Time  0.035 ( 0.038)	Data  0.001 ( 0.002)	Loss 7.0786e-02 (5.8676e-02)	Acc@1  97.66 ( 97.95)	Acc@5 100.00 ( 99.99)
Epoch: [57][260/391]	Time  0.035 ( 0.038)	Data  0.001 ( 0.002)	Loss 7.8833e-02 (5.8659e-02)	Acc@1  97.66 ( 97.96)	Acc@5 100.00 ( 99.99)
Epoch: [57][270/391]	Time  0.039 ( 0.038)	Data  0.001 ( 0.002)	Loss 6.3304e-02 (5.8803e-02)	Acc@1  97.66 ( 97.94)	Acc@5 100.00 ( 99.99)
Epoch: [57][280/391]	Time  0.035 ( 0.038)	Data  0.001 ( 0.002)	Loss 7.1774e-02 (5.8259e-02)	Acc@1  97.66 ( 97.96)	Acc@5 100.00 ( 99.99)
Epoch: [57][290/391]	Time  0.036 ( 0.038)	Data  0.001 ( 0.002)	Loss 8.8268e-02 (5.8482e-02)	Acc@1  97.66 ( 97.96)	Acc@5 100.00 ( 99.99)
Epoch: [57][300/391]	Time  0.038 ( 0.038)	Data  0.001 ( 0.002)	Loss 7.3771e-02 (5.8295e-02)	Acc@1  96.09 ( 97.97)	Acc@5 100.00 ( 99.99)
Epoch: [57][310/391]	Time  0.036 ( 0.038)	Data  0.001 ( 0.001)	Loss 4.4514e-02 (5.7880e-02)	Acc@1  99.22 ( 97.99)	Acc@5 100.00 ( 99.99)
Epoch: [57][320/391]	Time  0.035 ( 0.038)	Data  0.001 ( 0.001)	Loss 4.8246e-02 (5.8109e-02)	Acc@1  99.22 ( 97.98)	Acc@5 100.00 (100.00)
Epoch: [57][330/391]	Time  0.036 ( 0.038)	Data  0.001 ( 0.001)	Loss 5.4483e-02 (5.7690e-02)	Acc@1  97.66 ( 98.00)	Acc@5 100.00 (100.00)
Epoch: [57][340/391]	Time  0.045 ( 0.038)	Data  0.001 ( 0.001)	Loss 1.1895e-01 (5.7550e-02)	Acc@1  96.09 ( 98.00)	Acc@5 100.00 (100.00)
Epoch: [57][350/391]	Time  0.035 ( 0.038)	Data  0.001 ( 0.001)	Loss 2.5309e-02 (5.8014e-02)	Acc@1  99.22 ( 97.98)	Acc@5 100.00 (100.00)
Epoch: [57][360/391]	Time  0.037 ( 0.038)	Data  0.001 ( 0.001)	Loss 8.5804e-02 (5.8010e-02)	Acc@1  96.88 ( 97.97)	Acc@5 100.00 (100.00)
Epoch: [57][370/391]	Time  0.035 ( 0.038)	Data  0.001 ( 0.001)	Loss 3.0724e-02 (5.7799e-02)	Acc@1  99.22 ( 97.98)	Acc@5 100.00 (100.00)
Epoch: [57][380/391]	Time  0.035 ( 0.038)	Data  0.001 ( 0.001)	Loss 6.4036e-02 (5.7406e-02)	Acc@1  98.44 ( 97.99)	Acc@5 100.00 (100.00)
Epoch: [57][390/391]	Time  0.025 ( 0.037)	Data  0.001 ( 0.001)	Loss 1.1590e-01 (5.7649e-02)	Acc@1  92.50 ( 97.99)	Acc@5 100.00 (100.00)
## e[57] optimizer.zero_grad (sum) time: 0.19515395164489746
## e[57]       loss.backward (sum) time: 3.409294605255127
## e[57]      optimizer.step (sum) time: 1.2454664707183838
## epoch[57] training(only) time: 14.767616271972656
# Switched to evaluate mode...
Test: [  0/100]	Time  0.162 ( 0.162)	Loss 1.8787e-01 (1.8787e-01)	Acc@1  94.00 ( 94.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.022 ( 0.033)	Loss 5.3635e-01 (3.5053e-01)	Acc@1  90.00 ( 91.45)	Acc@5 100.00 ( 99.91)
Test: [ 20/100]	Time  0.018 ( 0.027)	Loss 3.7580e-01 (3.7223e-01)	Acc@1  85.00 ( 90.95)	Acc@5 100.00 ( 99.67)
Test: [ 30/100]	Time  0.024 ( 0.026)	Loss 4.9037e-01 (4.0120e-01)	Acc@1  90.00 ( 90.58)	Acc@5  98.00 ( 99.58)
Test: [ 40/100]	Time  0.021 ( 0.024)	Loss 2.7781e-01 (4.0927e-01)	Acc@1  90.00 ( 90.46)	Acc@5 100.00 ( 99.56)
Test: [ 50/100]	Time  0.017 ( 0.023)	Loss 1.6005e-01 (3.9869e-01)	Acc@1  94.00 ( 90.59)	Acc@5 100.00 ( 99.61)
Test: [ 60/100]	Time  0.018 ( 0.022)	Loss 4.1668e-01 (3.8690e-01)	Acc@1  90.00 ( 90.52)	Acc@5 100.00 ( 99.66)
Test: [ 70/100]	Time  0.016 ( 0.022)	Loss 4.3373e-01 (3.7706e-01)	Acc@1  88.00 ( 90.62)	Acc@5 100.00 ( 99.69)
Test: [ 80/100]	Time  0.017 ( 0.022)	Loss 2.2151e-01 (3.6861e-01)	Acc@1  90.00 ( 90.58)	Acc@5 100.00 ( 99.72)
Test: [ 90/100]	Time  0.022 ( 0.022)	Loss 2.9024e-01 (3.7393e-01)	Acc@1  94.00 ( 90.58)	Acc@5 100.00 ( 99.73)
 * Acc@1 90.590 Acc@5 99.730
### epoch[57] execution time: 17.071266174316406
EPOCH 58
REMOVING: module.fire4.squeeze.1.weight
REMOVING: module.fire4.squeeze.1.bias
REMOVING: module.fire4.expand_1x1.0.weight
i:   0, name: module.fire4.expand_1x1.0.bias  changing lr from: 0.001103140535388452   to: 0.001002628302658225
i:   1, name: module.fire4.expand_1x1.1.weight  changing lr from: 0.001180863766474121   to: 0.001024739401259166
i:   2, name: module.fire4.expand_1x1.1.bias  changing lr from: 0.001279230899684119   to: 0.001068820049760870
i:   3, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.001397634393104013   to: 0.001134257086740519
i:   4, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.001535473857507407   to: 0.001220443258374126
i:   5, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.001692156421170526   to: 0.001326777668287692
i:   6, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.001867097059823185   to: 0.001452666188865247
i:   7, name:  module.fire5.squeeze.0.weight  changing lr from: 0.002059718893578049   to: 0.001597521835953419
i:   8, name:    module.fire5.squeeze.0.bias  changing lr from: 0.002269453452612185   to: 0.001760765108835687
i:   9, name:  module.fire5.squeeze.1.weight  changing lr from: 0.002495740913307520   to: 0.001941824297283239
i:  10, name:    module.fire5.squeeze.1.bias  changing lr from: 0.002738030306491256   to: 0.002140135757424254
i:  11, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.002995779699351652   to: 0.002355144158108357
i:  12, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.003268456352541687   to: 0.002586302699379827
i:  13, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.003555536853920365   to: 0.002833073304609928
i:  14, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.003856507230321010   to: 0.003094926787777779
i:  15, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.004170863038676109   to: 0.003371342997328452
i:  16, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.004498109437771135   to: 0.003661810937978526
i:  17, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.004837761241843008   to: 0.003965828871781435
i:  18, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.005189342957184677   to: 0.004282904399709141
i:  19, name:  module.fire6.squeeze.0.weight  changing lr from: 0.005552388802864227   to: 0.004612554524951961
i:  20, name:    module.fire6.squeeze.0.bias  changing lr from: 0.005926442716615714   to: 0.004954305699085253
i:  21, name:  module.fire6.squeeze.1.weight  changing lr from: 0.006311058346909182   to: 0.005307693852200339
i:  22, name:    module.fire6.squeeze.1.bias  changing lr from: 0.006705799032159254   to: 0.005672264408046539
i:  23, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.007110237767985711   to: 0.006047572285183700
i:  24, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.007523957163394140   to: 0.006433181885096495
i:  25, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.007946549386702195   to: 0.006828667068177812
i:  26, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.008377616101994756   to: 0.007233611118443350
i:  27, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.008816768396852182   to: 0.007647606697798809
i:  28, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.009263626702056382   to: 0.008070255790639018
i:  29, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.009717820703943274   to: 0.008501169639520023
i:  30, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.010178989250034159   to: 0.008939968672606852
i:  31, name:  module.fire7.squeeze.0.weight  changing lr from: 0.010646780248544790   to: 0.009386282423563892
i:  32, name:    module.fire7.squeeze.0.bias  changing lr from: 0.011120850562338230   to: 0.009839749444519420
i:  33, name:  module.fire7.squeeze.1.weight  changing lr from: 0.011600865897855937   to: 0.010300017212702631
i:  34, name:    module.fire7.squeeze.1.bias  changing lr from: 0.012086500689532126   to: 0.010766742031319221
i:  35, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.012577437980167288   to: 0.011239588925201011
i:  36, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.013073369297709508   to: 0.011718231531734995
i:  37, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.013573994528866252   to: 0.012202351987549809
i:  38, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.014079021789943517   to: 0.012691640811409388
i:  39, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.014588167295286537   to: 0.013185796783738973
i:  40, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.015101155223672058   to: 0.013684526823182587
i:  41, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.015617717582981812   to: 0.014187545860568772
i:  42, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.016137594073464968   to: 0.014694576710637529
i:  43, name:  module.fire8.squeeze.0.weight  changing lr from: 0.016660531949878443   to: 0.015205349941860964
i:  44, name:    module.fire8.squeeze.0.bias  changing lr from: 0.017186285882774665   to: 0.015719603744668749
i:  45, name:  module.fire8.squeeze.1.weight  changing lr from: 0.017714617819188944   to: 0.016237083798370827
i:  46, name:    module.fire8.squeeze.1.bias  changing lr from: 0.018245296842961455   to: 0.016757543137050357
i:  47, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.018778099034912350   to: 0.017280742014682254
i:  48, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.019312807333074205   to: 0.017806447769716821
i:  49, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.019849211393170293   to: 0.018334434689350337
i:  50, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.020387107449514438   to: 0.018864483873690597
i:  51, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.020926298176494190   to: 0.019396383100009903
i:  52, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.021466592550787846   to: 0.019929926687265516
i:  53, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.022007805714452919   to: 0.020464915361052743
i:  54, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.022549758839013542   to: 0.021001156119145444
i:  55, name:  module.fire9.squeeze.0.weight  changing lr from: 0.023092278990663302   to: 0.021538462097765707
i:  56, name:    module.fire9.squeeze.0.bias  changing lr from: 0.023635198996690268   to: 0.022076652438713720
i:  57, name:  module.fire9.squeeze.1.weight  changing lr from: 0.024178357313221724   to: 0.022615552157478611
i:  58, name:    module.fire9.squeeze.1.bias  changing lr from: 0.024721597894377126   to: 0.023154992012440902
i:  59, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.025264770062909558   to: 0.023694808375267884
i:  60, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.025807728382408381   to: 0.024234843102594335
i:  61, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.026350332531127719   to: 0.024774943409072776
i:  62, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.026892447177499491   to: 0.025314961741869386
i:  63, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.027433941857382238   to: 0.025854755656674541
i:  64, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.027974690853091413   to: 0.026394187695289745
i:  65, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.028514573074250683   to: 0.026933125264845981
i:  66, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.029053471940499006   to: 0.027471440518702806
i:  67, name:           module.conv10.weight  changing lr from: 0.029591275266082375   to: 0.028009010239071288
i:  68, name:             module.conv10.bias  changing lr from: 0.030127875146354961   to: 0.028545715721398458



# Switched to train mode...
Epoch: [58][  0/391]	Time  0.216 ( 0.216)	Data  0.177 ( 0.177)	Loss 3.3094e-02 (3.3094e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [58][ 10/391]	Time  0.035 ( 0.053)	Data  0.001 ( 0.017)	Loss 4.4211e-02 (5.1049e-02)	Acc@1  98.44 ( 98.15)	Acc@5 100.00 (100.00)
Epoch: [58][ 20/391]	Time  0.038 ( 0.045)	Data  0.001 ( 0.009)	Loss 1.0173e-01 (5.3779e-02)	Acc@1  95.31 ( 97.95)	Acc@5 100.00 (100.00)
Epoch: [58][ 30/391]	Time  0.035 ( 0.042)	Data  0.001 ( 0.007)	Loss 6.5481e-02 (5.7283e-02)	Acc@1  97.66 ( 97.88)	Acc@5 100.00 (100.00)
Epoch: [58][ 40/391]	Time  0.037 ( 0.041)	Data  0.001 ( 0.005)	Loss 4.8223e-02 (5.5046e-02)	Acc@1  99.22 ( 98.08)	Acc@5 100.00 (100.00)
Epoch: [58][ 50/391]	Time  0.040 ( 0.040)	Data  0.001 ( 0.004)	Loss 3.6016e-02 (5.4637e-02)	Acc@1  98.44 ( 98.15)	Acc@5 100.00 (100.00)
Epoch: [58][ 60/391]	Time  0.036 ( 0.039)	Data  0.001 ( 0.004)	Loss 2.2603e-02 (5.2890e-02)	Acc@1 100.00 ( 98.21)	Acc@5 100.00 (100.00)
Epoch: [58][ 70/391]	Time  0.039 ( 0.039)	Data  0.001 ( 0.003)	Loss 6.8109e-02 (5.3331e-02)	Acc@1  96.88 ( 98.18)	Acc@5 100.00 (100.00)
Epoch: [58][ 80/391]	Time  0.037 ( 0.039)	Data  0.001 ( 0.003)	Loss 1.9496e-02 (5.2254e-02)	Acc@1 100.00 ( 98.23)	Acc@5 100.00 (100.00)
Epoch: [58][ 90/391]	Time  0.036 ( 0.038)	Data  0.001 ( 0.003)	Loss 3.1914e-02 (5.1607e-02)	Acc@1  98.44 ( 98.26)	Acc@5 100.00 (100.00)
Epoch: [58][100/391]	Time  0.037 ( 0.038)	Data  0.001 ( 0.003)	Loss 6.1522e-02 (5.2480e-02)	Acc@1  96.09 ( 98.22)	Acc@5 100.00 (100.00)
Epoch: [58][110/391]	Time  0.035 ( 0.038)	Data  0.001 ( 0.002)	Loss 4.1082e-02 (5.2381e-02)	Acc@1  98.44 ( 98.22)	Acc@5 100.00 (100.00)
Epoch: [58][120/391]	Time  0.037 ( 0.038)	Data  0.001 ( 0.002)	Loss 5.5754e-02 (5.2319e-02)	Acc@1  99.22 ( 98.24)	Acc@5 100.00 (100.00)
Epoch: [58][130/391]	Time  0.038 ( 0.038)	Data  0.001 ( 0.002)	Loss 1.8258e-02 (5.1698e-02)	Acc@1  99.22 ( 98.25)	Acc@5 100.00 (100.00)
Epoch: [58][140/391]	Time  0.034 ( 0.038)	Data  0.001 ( 0.002)	Loss 5.2782e-02 (5.1787e-02)	Acc@1  98.44 ( 98.25)	Acc@5 100.00 (100.00)
Epoch: [58][150/391]	Time  0.035 ( 0.038)	Data  0.001 ( 0.002)	Loss 3.2062e-02 (5.2066e-02)	Acc@1  99.22 ( 98.23)	Acc@5 100.00 (100.00)
Epoch: [58][160/391]	Time  0.042 ( 0.038)	Data  0.001 ( 0.002)	Loss 3.9496e-02 (5.1980e-02)	Acc@1  99.22 ( 98.24)	Acc@5 100.00 (100.00)
Epoch: [58][170/391]	Time  0.035 ( 0.038)	Data  0.001 ( 0.002)	Loss 6.4145e-02 (5.2795e-02)	Acc@1  97.66 ( 98.20)	Acc@5 100.00 (100.00)
Epoch: [58][180/391]	Time  0.035 ( 0.038)	Data  0.001 ( 0.002)	Loss 1.3758e-02 (5.2157e-02)	Acc@1 100.00 ( 98.20)	Acc@5 100.00 (100.00)
Epoch: [58][190/391]	Time  0.037 ( 0.038)	Data  0.001 ( 0.002)	Loss 2.5173e-02 (5.1354e-02)	Acc@1  99.22 ( 98.22)	Acc@5 100.00 (100.00)
Epoch: [58][200/391]	Time  0.039 ( 0.038)	Data  0.001 ( 0.002)	Loss 8.8653e-02 (5.1608e-02)	Acc@1  96.88 ( 98.23)	Acc@5 100.00 (100.00)
Epoch: [58][210/391]	Time  0.037 ( 0.038)	Data  0.001 ( 0.002)	Loss 3.3343e-02 (5.2018e-02)	Acc@1  99.22 ( 98.23)	Acc@5 100.00 (100.00)
Epoch: [58][220/391]	Time  0.036 ( 0.037)	Data  0.001 ( 0.002)	Loss 1.5245e-02 (5.1603e-02)	Acc@1 100.00 ( 98.25)	Acc@5 100.00 (100.00)
Epoch: [58][230/391]	Time  0.037 ( 0.037)	Data  0.001 ( 0.002)	Loss 2.9839e-02 (5.1335e-02)	Acc@1 100.00 ( 98.28)	Acc@5 100.00 (100.00)
Epoch: [58][240/391]	Time  0.035 ( 0.037)	Data  0.001 ( 0.002)	Loss 3.9823e-02 (5.1054e-02)	Acc@1  99.22 ( 98.30)	Acc@5 100.00 (100.00)
Epoch: [58][250/391]	Time  0.037 ( 0.037)	Data  0.001 ( 0.002)	Loss 8.7962e-02 (5.1299e-02)	Acc@1  97.66 ( 98.30)	Acc@5 100.00 (100.00)
Epoch: [58][260/391]	Time  0.037 ( 0.037)	Data  0.001 ( 0.002)	Loss 1.3601e-01 (5.1581e-02)	Acc@1  95.31 ( 98.28)	Acc@5 100.00 (100.00)
Epoch: [58][270/391]	Time  0.034 ( 0.037)	Data  0.001 ( 0.002)	Loss 4.4362e-02 (5.1683e-02)	Acc@1  99.22 ( 98.28)	Acc@5 100.00 (100.00)
Epoch: [58][280/391]	Time  0.034 ( 0.037)	Data  0.001 ( 0.002)	Loss 7.6059e-02 (5.1682e-02)	Acc@1  97.66 ( 98.29)	Acc@5 100.00 (100.00)
Epoch: [58][290/391]	Time  0.036 ( 0.037)	Data  0.001 ( 0.002)	Loss 3.5420e-02 (5.1987e-02)	Acc@1  97.66 ( 98.28)	Acc@5 100.00 (100.00)
Epoch: [58][300/391]	Time  0.036 ( 0.037)	Data  0.001 ( 0.001)	Loss 3.7239e-02 (5.2144e-02)	Acc@1  98.44 ( 98.27)	Acc@5 100.00 (100.00)
Epoch: [58][310/391]	Time  0.039 ( 0.037)	Data  0.001 ( 0.001)	Loss 4.9484e-02 (5.2130e-02)	Acc@1  98.44 ( 98.27)	Acc@5 100.00 (100.00)
Epoch: [58][320/391]	Time  0.036 ( 0.037)	Data  0.001 ( 0.001)	Loss 1.5389e-01 (5.2540e-02)	Acc@1  96.88 ( 98.27)	Acc@5 100.00 (100.00)
Epoch: [58][330/391]	Time  0.037 ( 0.037)	Data  0.001 ( 0.001)	Loss 3.9119e-02 (5.2655e-02)	Acc@1 100.00 ( 98.26)	Acc@5 100.00 (100.00)
Epoch: [58][340/391]	Time  0.036 ( 0.037)	Data  0.001 ( 0.001)	Loss 2.6755e-02 (5.2894e-02)	Acc@1  99.22 ( 98.25)	Acc@5 100.00 (100.00)
Epoch: [58][350/391]	Time  0.040 ( 0.037)	Data  0.001 ( 0.001)	Loss 2.3825e-02 (5.2667e-02)	Acc@1 100.00 ( 98.25)	Acc@5 100.00 (100.00)
Epoch: [58][360/391]	Time  0.038 ( 0.037)	Data  0.001 ( 0.001)	Loss 5.6814e-02 (5.2517e-02)	Acc@1  98.44 ( 98.26)	Acc@5 100.00 (100.00)
Epoch: [58][370/391]	Time  0.035 ( 0.037)	Data  0.001 ( 0.001)	Loss 3.5063e-02 (5.2687e-02)	Acc@1  98.44 ( 98.25)	Acc@5 100.00 (100.00)
Epoch: [58][380/391]	Time  0.036 ( 0.037)	Data  0.001 ( 0.001)	Loss 3.5260e-02 (5.2599e-02)	Acc@1  98.44 ( 98.25)	Acc@5 100.00 (100.00)
Epoch: [58][390/391]	Time  0.023 ( 0.037)	Data  0.001 ( 0.001)	Loss 9.0191e-02 (5.2755e-02)	Acc@1  96.25 ( 98.24)	Acc@5 100.00 (100.00)
## e[58] optimizer.zero_grad (sum) time: 0.18658113479614258
## e[58]       loss.backward (sum) time: 3.3476908206939697
## e[58]      optimizer.step (sum) time: 1.2102441787719727
## epoch[58] training(only) time: 14.583637714385986
# Switched to evaluate mode...
Test: [  0/100]	Time  0.167 ( 0.167)	Loss 1.8712e-01 (1.8712e-01)	Acc@1  96.00 ( 96.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.022 ( 0.035)	Loss 5.5947e-01 (3.4590e-01)	Acc@1  88.00 ( 91.09)	Acc@5 100.00 ( 99.91)
Test: [ 20/100]	Time  0.018 ( 0.028)	Loss 4.2396e-01 (3.8341e-01)	Acc@1  87.00 ( 90.48)	Acc@5 100.00 ( 99.71)
Test: [ 30/100]	Time  0.023 ( 0.026)	Loss 4.1642e-01 (4.1328e-01)	Acc@1  89.00 ( 90.55)	Acc@5  99.00 ( 99.65)
Test: [ 40/100]	Time  0.018 ( 0.024)	Loss 3.6722e-01 (4.2156e-01)	Acc@1  90.00 ( 90.24)	Acc@5 100.00 ( 99.66)
Test: [ 50/100]	Time  0.021 ( 0.024)	Loss 2.0504e-01 (4.1313e-01)	Acc@1  91.00 ( 90.35)	Acc@5 100.00 ( 99.65)
Test: [ 60/100]	Time  0.017 ( 0.023)	Loss 4.2239e-01 (3.9856e-01)	Acc@1  92.00 ( 90.38)	Acc@5  99.00 ( 99.67)
Test: [ 70/100]	Time  0.019 ( 0.023)	Loss 4.3216e-01 (3.8962e-01)	Acc@1  88.00 ( 90.41)	Acc@5 100.00 ( 99.70)
Test: [ 80/100]	Time  0.022 ( 0.022)	Loss 1.9690e-01 (3.8135e-01)	Acc@1  95.00 ( 90.49)	Acc@5 100.00 ( 99.73)
Test: [ 90/100]	Time  0.017 ( 0.022)	Loss 2.5016e-01 (3.8715e-01)	Acc@1  95.00 ( 90.42)	Acc@5 100.00 ( 99.74)
 * Acc@1 90.500 Acc@5 99.750
### epoch[58] execution time: 16.837140321731567
EPOCH 59
REMOVING: module.fire4.expand_1x1.0.bias
REMOVING: module.fire4.expand_1x1.1.weight
REMOVING: module.fire4.expand_1x1.1.bias
i:   0, name: module.fire4.expand_3x3.0.weight  changing lr from: 0.001134257086740519   to: 0.001010400584188175
i:   1, name: module.fire4.expand_3x3.0.bias  changing lr from: 0.001220443258374126   to: 0.001042825340545921
i:   2, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.001326777668287692   to: 0.001096684141924475
i:   3, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.001452666188865247   to: 0.001171376883197799
i:   4, name:  module.fire5.squeeze.0.weight  changing lr from: 0.001597521835953419   to: 0.001266309443438539
i:   5, name:    module.fire5.squeeze.0.bias  changing lr from: 0.001760765108835687   to: 0.001380894105545732
i:   6, name:  module.fire5.squeeze.1.weight  changing lr from: 0.001941824297283239   to: 0.001514549939495595
i:   7, name:    module.fire5.squeeze.1.bias  changing lr from: 0.002140135757424254   to: 0.001666703151050046
i:   8, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.002355144158108357   to: 0.001836787397693883
i:   9, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.002586302699379827   to: 0.002024244073509073
i:  10, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.002833073304609928   to: 0.002228522564632079
i:  11, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.003094926787777779   to: 0.002449080476879089
i:  12, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.003371342997328452   to: 0.002685383837063242
i:  13, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.003661810937978526   to: 0.002936907269468819
i:  14, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.003965828871781435   to: 0.003203134148888969
i:  15, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.004282904399709141   to: 0.003483556731576519
i:  16, name:  module.fire6.squeeze.0.weight  changing lr from: 0.004612554524951961   to: 0.003777676265401785
i:  17, name:    module.fire6.squeeze.0.bias  changing lr from: 0.004954305699085253   to: 0.004085003080456744
i:  18, name:  module.fire6.squeeze.1.weight  changing lr from: 0.005307693852200339   to: 0.004405056661292033
i:  19, name:    module.fire6.squeeze.1.bias  changing lr from: 0.005672264408046539   to: 0.004737365701921402
i:  20, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.006047572285183700   to: 0.005081468144678707
i:  21, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.006433181885096495   to: 0.005436911203962957
i:  22, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.006828667068177812   to: 0.005803251375860563
i:  23, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.007233611118443350   to: 0.006180054434587578
i:  24, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.007647606697798809   to: 0.006566895416651180
i:  25, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.008070255790639018   to: 0.006963358593585905
i:  26, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.008501169639520023   to: 0.007369037434079867
i:  27, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.008939968672606852   to: 0.007783534556265703
i:  28, name:  module.fire7.squeeze.0.weight  changing lr from: 0.009386282423563892   to: 0.008206461670912740
i:  29, name:    module.fire7.squeeze.0.bias  changing lr from: 0.009839749444519420   to: 0.008637439516220018
i:  30, name:  module.fire7.squeeze.1.weight  changing lr from: 0.010300017212702631   to: 0.009076097784874105
i:  31, name:    module.fire7.squeeze.1.bias  changing lr from: 0.010766742031319221   to: 0.009522075044001037
i:  32, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.011239588925201011   to: 0.009975018648609713
i:  33, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.011718231531734995   to: 0.010434584649091395
i:  34, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.012202351987549809   to: 0.010900437693310540
i:  35, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.012691640811409388   to: 0.011372250923792342
i:  36, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.013185796783738973   to: 0.011849705870485373
i:  37, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.013684526823182587   to: 0.012332492339549896
i:  38, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.014187545860568772   to: 0.012820308298598353
i:  39, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.014694576710637529   to: 0.013312859758788431
i:  40, name:  module.fire8.squeeze.0.weight  changing lr from: 0.015205349941860964   to: 0.013809860654147167
i:  41, name:    module.fire8.squeeze.0.bias  changing lr from: 0.015719603744668749   to: 0.014311032718481421
i:  42, name:  module.fire8.squeeze.1.weight  changing lr from: 0.016237083798370827   to: 0.014816105360209171
i:  43, name:    module.fire8.squeeze.1.bias  changing lr from: 0.016757543137050357   to: 0.015324815535425522
i:  44, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.017280742014682254   to: 0.015836907619497891
i:  45, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.017806447769716821   to: 0.016352133277466846
i:  46, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.018334434689350337   to: 0.016870251333510795
i:  47, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.018864483873690597   to: 0.017391027639716544
i:  48, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.019396383100009903   to: 0.017914234944381303
i:  49, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.019929926687265516   to: 0.018439652760057341
i:  50, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.020464915361052743   to: 0.018967067231535018
i:  51, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.021001156119145444   to: 0.019496271003947237
i:  52, name:  module.fire9.squeeze.0.weight  changing lr from: 0.021538462097765707   to: 0.020027063091164976
i:  53, name:    module.fire9.squeeze.0.bias  changing lr from: 0.022076652438713720   to: 0.020559248744640796
i:  54, name:  module.fire9.squeeze.1.weight  changing lr from: 0.022615552157478611   to: 0.021092639322846569
i:  55, name:    module.fire9.squeeze.1.bias  changing lr from: 0.023154992012440902   to: 0.021627052161439689
i:  56, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.023694808375267884   to: 0.022162310444281866
i:  57, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.024234843102594335   to: 0.022698243075424802
i:  58, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.024774943409072776   to: 0.023234684552167702
i:  59, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.025314961741869386   to: 0.023771474839282006
i:  60, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.025854755656674541   to: 0.024308459244491806
i:  61, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.026394187695289745   to: 0.024845488295288744
i:  62, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.026933125264845981   to: 0.025382417617153992
i:  63, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.027471440518702806   to: 0.025919107813252525
i:  64, name:           module.conv10.weight  changing lr from: 0.028009010239071288   to: 0.026455424345658042
i:  65, name:             module.conv10.bias  changing lr from: 0.028545715721398458   to: 0.026991237418160913



# Switched to train mode...
Epoch: [59][  0/391]	Time  0.217 ( 0.217)	Data  0.174 ( 0.174)	Loss 7.4651e-02 (7.4651e-02)	Acc@1  97.66 ( 97.66)	Acc@5 100.00 (100.00)
Epoch: [59][ 10/391]	Time  0.037 ( 0.053)	Data  0.001 ( 0.017)	Loss 4.3236e-02 (5.2729e-02)	Acc@1  97.66 ( 98.30)	Acc@5 100.00 (100.00)
Epoch: [59][ 20/391]	Time  0.036 ( 0.046)	Data  0.001 ( 0.009)	Loss 4.3840e-02 (5.0292e-02)	Acc@1  99.22 ( 98.33)	Acc@5 100.00 (100.00)
Epoch: [59][ 30/391]	Time  0.038 ( 0.043)	Data  0.001 ( 0.006)	Loss 3.0754e-02 (5.0741e-02)	Acc@1  99.22 ( 98.36)	Acc@5 100.00 (100.00)
Epoch: [59][ 40/391]	Time  0.037 ( 0.041)	Data  0.001 ( 0.005)	Loss 8.9343e-02 (5.1391e-02)	Acc@1  96.88 ( 98.34)	Acc@5 100.00 (100.00)
Epoch: [59][ 50/391]	Time  0.035 ( 0.040)	Data  0.001 ( 0.004)	Loss 6.1169e-02 (5.1788e-02)	Acc@1  98.44 ( 98.35)	Acc@5 100.00 (100.00)
Epoch: [59][ 60/391]	Time  0.037 ( 0.039)	Data  0.001 ( 0.004)	Loss 3.5451e-02 (4.9315e-02)	Acc@1  97.66 ( 98.41)	Acc@5 100.00 (100.00)
Epoch: [59][ 70/391]	Time  0.037 ( 0.039)	Data  0.001 ( 0.003)	Loss 8.7609e-02 (5.2375e-02)	Acc@1  94.53 ( 98.26)	Acc@5 100.00 (100.00)
Epoch: [59][ 80/391]	Time  0.034 ( 0.039)	Data  0.001 ( 0.003)	Loss 1.0091e-02 (5.0095e-02)	Acc@1 100.00 ( 98.37)	Acc@5 100.00 (100.00)
Epoch: [59][ 90/391]	Time  0.039 ( 0.038)	Data  0.001 ( 0.003)	Loss 2.4606e-02 (5.1078e-02)	Acc@1 100.00 ( 98.33)	Acc@5 100.00 (100.00)
Epoch: [59][100/391]	Time  0.040 ( 0.038)	Data  0.001 ( 0.003)	Loss 6.4346e-02 (5.1160e-02)	Acc@1  97.66 ( 98.29)	Acc@5 100.00 (100.00)
Epoch: [59][110/391]	Time  0.034 ( 0.038)	Data  0.001 ( 0.002)	Loss 5.7303e-02 (5.0943e-02)	Acc@1  98.44 ( 98.30)	Acc@5 100.00 (100.00)
Epoch: [59][120/391]	Time  0.037 ( 0.038)	Data  0.001 ( 0.002)	Loss 3.2360e-02 (5.0817e-02)	Acc@1  99.22 ( 98.33)	Acc@5 100.00 (100.00)
Epoch: [59][130/391]	Time  0.034 ( 0.038)	Data  0.001 ( 0.002)	Loss 3.7119e-02 (5.0767e-02)	Acc@1 100.00 ( 98.34)	Acc@5 100.00 (100.00)
Epoch: [59][140/391]	Time  0.035 ( 0.038)	Data  0.001 ( 0.002)	Loss 4.7127e-02 (5.1343e-02)	Acc@1  99.22 ( 98.33)	Acc@5 100.00 (100.00)
Epoch: [59][150/391]	Time  0.039 ( 0.038)	Data  0.001 ( 0.002)	Loss 3.6443e-02 (5.1101e-02)	Acc@1  98.44 ( 98.34)	Acc@5 100.00 (100.00)
Epoch: [59][160/391]	Time  0.034 ( 0.037)	Data  0.001 ( 0.002)	Loss 7.2673e-02 (5.0597e-02)	Acc@1  97.66 ( 98.35)	Acc@5 100.00 (100.00)
Epoch: [59][170/391]	Time  0.037 ( 0.037)	Data  0.001 ( 0.002)	Loss 1.4325e-02 (5.1143e-02)	Acc@1 100.00 ( 98.32)	Acc@5 100.00 (100.00)
Epoch: [59][180/391]	Time  0.036 ( 0.037)	Data  0.001 ( 0.002)	Loss 5.0308e-02 (5.0758e-02)	Acc@1  99.22 ( 98.34)	Acc@5 100.00 (100.00)
Epoch: [59][190/391]	Time  0.034 ( 0.037)	Data  0.001 ( 0.002)	Loss 7.1063e-02 (5.0901e-02)	Acc@1  98.44 ( 98.33)	Acc@5 100.00 (100.00)
Epoch: [59][200/391]	Time  0.035 ( 0.037)	Data  0.001 ( 0.002)	Loss 2.4352e-02 (5.0266e-02)	Acc@1 100.00 ( 98.36)	Acc@5 100.00 (100.00)
Epoch: [59][210/391]	Time  0.034 ( 0.037)	Data  0.001 ( 0.002)	Loss 7.7567e-02 (4.9891e-02)	Acc@1  96.09 ( 98.36)	Acc@5 100.00 (100.00)
Epoch: [59][220/391]	Time  0.034 ( 0.037)	Data  0.001 ( 0.002)	Loss 5.8057e-02 (4.9918e-02)	Acc@1  98.44 ( 98.37)	Acc@5 100.00 (100.00)
Epoch: [59][230/391]	Time  0.039 ( 0.037)	Data  0.001 ( 0.002)	Loss 5.1048e-02 (5.0289e-02)	Acc@1  97.66 ( 98.35)	Acc@5 100.00 (100.00)
Epoch: [59][240/391]	Time  0.034 ( 0.037)	Data  0.001 ( 0.002)	Loss 4.8752e-02 (5.0609e-02)	Acc@1  97.66 ( 98.32)	Acc@5 100.00 (100.00)
Epoch: [59][250/391]	Time  0.038 ( 0.037)	Data  0.001 ( 0.002)	Loss 1.0511e-01 (5.0917e-02)	Acc@1  96.88 ( 98.31)	Acc@5 100.00 (100.00)
Epoch: [59][260/391]	Time  0.038 ( 0.037)	Data  0.001 ( 0.002)	Loss 4.3242e-02 (5.0796e-02)	Acc@1  98.44 ( 98.31)	Acc@5 100.00 (100.00)
Epoch: [59][270/391]	Time  0.034 ( 0.037)	Data  0.001 ( 0.002)	Loss 7.2765e-02 (5.0985e-02)	Acc@1  96.88 ( 98.29)	Acc@5 100.00 (100.00)
Epoch: [59][280/391]	Time  0.040 ( 0.037)	Data  0.001 ( 0.001)	Loss 6.7989e-02 (5.1693e-02)	Acc@1  96.09 ( 98.25)	Acc@5 100.00 (100.00)
Epoch: [59][290/391]	Time  0.034 ( 0.037)	Data  0.001 ( 0.001)	Loss 5.8847e-02 (5.1808e-02)	Acc@1  98.44 ( 98.24)	Acc@5 100.00 (100.00)
Epoch: [59][300/391]	Time  0.034 ( 0.037)	Data  0.001 ( 0.001)	Loss 5.3146e-02 (5.2157e-02)	Acc@1  98.44 ( 98.25)	Acc@5 100.00 (100.00)
Epoch: [59][310/391]	Time  0.037 ( 0.037)	Data  0.001 ( 0.001)	Loss 5.4337e-02 (5.1981e-02)	Acc@1  98.44 ( 98.25)	Acc@5 100.00 (100.00)
Epoch: [59][320/391]	Time  0.037 ( 0.037)	Data  0.001 ( 0.001)	Loss 6.6782e-02 (5.2094e-02)	Acc@1  96.88 ( 98.24)	Acc@5 100.00 (100.00)
Epoch: [59][330/391]	Time  0.034 ( 0.037)	Data  0.001 ( 0.001)	Loss 2.3680e-02 (5.1937e-02)	Acc@1 100.00 ( 98.24)	Acc@5 100.00 (100.00)
Epoch: [59][340/391]	Time  0.035 ( 0.037)	Data  0.001 ( 0.001)	Loss 7.8967e-02 (5.2270e-02)	Acc@1  96.09 ( 98.22)	Acc@5 100.00 (100.00)
Epoch: [59][350/391]	Time  0.036 ( 0.037)	Data  0.001 ( 0.001)	Loss 8.6241e-02 (5.2352e-02)	Acc@1  96.88 ( 98.23)	Acc@5 100.00 (100.00)
Epoch: [59][360/391]	Time  0.034 ( 0.037)	Data  0.001 ( 0.001)	Loss 5.4718e-02 (5.2469e-02)	Acc@1  98.44 ( 98.23)	Acc@5 100.00 (100.00)
Epoch: [59][370/391]	Time  0.034 ( 0.037)	Data  0.001 ( 0.001)	Loss 3.1206e-02 (5.2162e-02)	Acc@1  99.22 ( 98.24)	Acc@5 100.00 (100.00)
Epoch: [59][380/391]	Time  0.037 ( 0.037)	Data  0.001 ( 0.001)	Loss 3.1375e-02 (5.2364e-02)	Acc@1  99.22 ( 98.23)	Acc@5 100.00 (100.00)
Epoch: [59][390/391]	Time  0.025 ( 0.037)	Data  0.001 ( 0.001)	Loss 5.5188e-02 (5.2514e-02)	Acc@1  97.50 ( 98.22)	Acc@5 100.00 (100.00)
## e[59] optimizer.zero_grad (sum) time: 0.18474030494689941
## e[59]       loss.backward (sum) time: 3.315723180770874
## e[59]      optimizer.step (sum) time: 1.178966999053955
## epoch[59] training(only) time: 14.451921701431274
# Switched to evaluate mode...
Test: [  0/100]	Time  0.170 ( 0.170)	Loss 2.2489e-01 (2.2489e-01)	Acc@1  93.00 ( 93.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.018 ( 0.035)	Loss 5.2636e-01 (3.7002e-01)	Acc@1  86.00 ( 90.45)	Acc@5 100.00 ( 99.91)
Test: [ 20/100]	Time  0.023 ( 0.029)	Loss 4.2617e-01 (4.0008e-01)	Acc@1  87.00 ( 90.29)	Acc@5 100.00 ( 99.71)
Test: [ 30/100]	Time  0.021 ( 0.027)	Loss 4.0792e-01 (4.2952e-01)	Acc@1  91.00 ( 90.35)	Acc@5  99.00 ( 99.58)
Test: [ 40/100]	Time  0.026 ( 0.025)	Loss 4.0644e-01 (4.3173e-01)	Acc@1  88.00 ( 90.17)	Acc@5 100.00 ( 99.56)
Test: [ 50/100]	Time  0.021 ( 0.024)	Loss 1.6173e-01 (4.2351e-01)	Acc@1  92.00 ( 90.29)	Acc@5 100.00 ( 99.59)
Test: [ 60/100]	Time  0.017 ( 0.024)	Loss 4.8873e-01 (4.0872e-01)	Acc@1  93.00 ( 90.44)	Acc@5  99.00 ( 99.61)
Test: [ 70/100]	Time  0.023 ( 0.023)	Loss 5.1734e-01 (3.9856e-01)	Acc@1  88.00 ( 90.56)	Acc@5 100.00 ( 99.63)
Test: [ 80/100]	Time  0.021 ( 0.023)	Loss 2.6986e-01 (3.9234e-01)	Acc@1  94.00 ( 90.54)	Acc@5 100.00 ( 99.65)
Test: [ 90/100]	Time  0.024 ( 0.022)	Loss 3.2842e-01 (3.9641e-01)	Acc@1  93.00 ( 90.51)	Acc@5 100.00 ( 99.69)
 * Acc@1 90.590 Acc@5 99.700
### epoch[59] execution time: 16.809606075286865
EPOCH 60
REMOVING: module.fire4.expand_3x3.0.weight
REMOVING: module.fire4.expand_3x3.0.bias
i:   0, name: module.fire4.expand_3x3.1.weight  changing lr from: 0.001096684141924475   to: 0.001002502502751811
i:   1, name: module.fire4.expand_3x3.1.bias  changing lr from: 0.001171376883197799   to: 0.001023985011917632
i:   2, name:  module.fire5.squeeze.0.weight  changing lr from: 0.001266309443438539   to: 0.001066959885427470
i:   3, name:    module.fire5.squeeze.0.bias  changing lr from: 0.001380894105545732   to: 0.001130834243163464
i:   4, name:  module.fire5.squeeze.1.weight  changing lr from: 0.001514549939495595   to: 0.001215020836311269
i:   5, name:    module.fire5.squeeze.1.bias  changing lr from: 0.001666703151050046   to: 0.001318938473976182
i:   6, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.001836787397693883   to: 0.001442012413699461
i:   7, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.002024244073509073   to: 0.001583674717670152
i:   8, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.002228522564632079   to: 0.001743364576366889
i:   9, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.002449080476879089   to: 0.001920528601303755
i:  10, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.002685383837063242   to: 0.002114621088494339
i:  11, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.002936907269468819   to: 0.002325104254189341
i:  12, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.003203134148888969   to: 0.002551448444384401
i:  13, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.003483556731576519   to: 0.002793132319537649
i:  14, name:  module.fire6.squeeze.0.weight  changing lr from: 0.003777676265401785   to: 0.003049643015880348
i:  15, name:    module.fire6.squeeze.0.bias  changing lr from: 0.004085003080456744   to: 0.003320476284648487
i:  16, name:  module.fire6.squeeze.1.weight  changing lr from: 0.004405056661292033   to: 0.003605136610509357
i:  17, name:    module.fire6.squeeze.1.bias  changing lr from: 0.004737365701921402   to: 0.003903137310404347
i:  18, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.005081468144678707   to: 0.004214000613977941
i:  19, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.005436911203962957   to: 0.004537257726712356
i:  20, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.005803251375860563   to: 0.004872448876838952
i:  21, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.006180054434587578   to: 0.005219123347049864
i:  22, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.006566895416651180   to: 0.005576839491987572
i:  23, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.006963358593585905   to: 0.005945164742445291
i:  24, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.007369037434079867   to: 0.006323675597168143
i:  25, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.007783534556265703   to: 0.006711957603103269
i:  26, name:  module.fire7.squeeze.0.weight  changing lr from: 0.008206461670912740   to: 0.007109605324906564
i:  27, name:    module.fire7.squeeze.0.bias  changing lr from: 0.008637439516220018   to: 0.007516222304475056
i:  28, name:  module.fire7.squeeze.1.weight  changing lr from: 0.009076097784874105   to: 0.007931421011235913
i:  29, name:    module.fire7.squeeze.1.bias  changing lr from: 0.009522075044001037   to: 0.008354822783887265
i:  30, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.009975018648609713   to: 0.008786057764251037
i:  31, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.010434584649091395   to: 0.009224764823864102
i:  32, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.010900437693310540   to: 0.009670591483902317
i:  33, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.011372250923792342   to: 0.010123193829000360
i:  34, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.011849705870485373   to: 0.010582236415501118
i:  35, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.012332492339549896   to: 0.011047392174639115
i:  36, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.012820308298598353   to: 0.011518342311135930
i:  37, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.013312859758788431   to: 0.011994776197658107
i:  38, name:  module.fire8.squeeze.0.weight  changing lr from: 0.013809860654147167   to: 0.012476391265564150
i:  39, name:    module.fire8.squeeze.0.bias  changing lr from: 0.014311032718481421   to: 0.012962892892341975
i:  40, name:  module.fire8.squeeze.1.weight  changing lr from: 0.014816105360209171   to: 0.013453994286116266
i:  41, name:    module.fire8.squeeze.1.bias  changing lr from: 0.015324815535425522   to: 0.013949416367582061
i:  42, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.015836907619497891   to: 0.014448887649700599
i:  43, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.016352133277466846   to: 0.014952144115473253
i:  44, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.016870251333510795   to: 0.015458929094089885
i:  45, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.017391027639716544   to: 0.015968993135730060
i:  46, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.017914234944381303   to: 0.016482093885277820
i:  47, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.018439652760057341   to: 0.016997995955194436
i:  48, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.018967067231535018   to: 0.017516470797777395
i:  49, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.019496271003947237   to: 0.018037296577019135
i:  50, name:  module.fire9.squeeze.0.weight  changing lr from: 0.020027063091164976   to: 0.018560258040264638
i:  51, name:    module.fire9.squeeze.0.bias  changing lr from: 0.020559248744640796   to: 0.019085146389853303
i:  52, name:  module.fire9.squeeze.1.weight  changing lr from: 0.021092639322846569   to: 0.019611759154917658
i:  53, name:    module.fire9.squeeze.1.bias  changing lr from: 0.021627052161439689   to: 0.020139900063499451
i:  54, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.022162310444281866   to: 0.020669378915131577
i:  55, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.022698243075424802   to: 0.021200011454023560
i:  56, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.023234684552167702   to: 0.021731619242977913
i:  57, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.023771474839282006   to: 0.022264029538154526
i:  58, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.024308459244491806   to: 0.022797075164791038
i:  59, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.024845488295288744   to: 0.023330594393978450
i:  60, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.025382417617153992   to: 0.023864430820582167
i:  61, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.025919107813252525   to: 0.024398433242391760
i:  62, name:           module.conv10.weight  changing lr from: 0.026455424345658042   to: 0.024932455540574328
i:  63, name:             module.conv10.bias  changing lr from: 0.026991237418160913   to: 0.025466356561499877



# Switched to train mode...
Epoch: [60][  0/391]	Time  0.201 ( 0.201)	Data  0.164 ( 0.164)	Loss 1.0607e-01 (1.0607e-01)	Acc@1  97.66 ( 97.66)	Acc@5 100.00 (100.00)
Epoch: [60][ 10/391]	Time  0.036 ( 0.051)	Data  0.001 ( 0.016)	Loss 3.4416e-02 (4.4834e-02)	Acc@1  99.22 ( 98.58)	Acc@5 100.00 (100.00)
Epoch: [60][ 20/391]	Time  0.039 ( 0.044)	Data  0.001 ( 0.009)	Loss 3.4149e-02 (3.9080e-02)	Acc@1  98.44 ( 98.77)	Acc@5 100.00 (100.00)
Epoch: [60][ 30/391]	Time  0.034 ( 0.042)	Data  0.001 ( 0.006)	Loss 1.2615e-01 (4.2966e-02)	Acc@1  95.31 ( 98.61)	Acc@5 100.00 (100.00)
Epoch: [60][ 40/391]	Time  0.038 ( 0.040)	Data  0.001 ( 0.005)	Loss 4.8310e-02 (4.4192e-02)	Acc@1  96.88 ( 98.48)	Acc@5 100.00 (100.00)
Epoch: [60][ 50/391]	Time  0.034 ( 0.039)	Data  0.001 ( 0.004)	Loss 3.3003e-02 (4.3807e-02)	Acc@1  99.22 ( 98.45)	Acc@5 100.00 (100.00)
Epoch: [60][ 60/391]	Time  0.037 ( 0.039)	Data  0.001 ( 0.004)	Loss 1.1896e-01 (4.6886e-02)	Acc@1  96.88 ( 98.34)	Acc@5 100.00 (100.00)
Epoch: [60][ 70/391]	Time  0.034 ( 0.038)	Data  0.001 ( 0.003)	Loss 8.9608e-02 (4.6243e-02)	Acc@1  96.88 ( 98.34)	Acc@5 100.00 (100.00)
Epoch: [60][ 80/391]	Time  0.034 ( 0.038)	Data  0.001 ( 0.003)	Loss 8.0696e-02 (4.6168e-02)	Acc@1  96.88 ( 98.37)	Acc@5 100.00 (100.00)
Epoch: [60][ 90/391]	Time  0.034 ( 0.038)	Data  0.001 ( 0.003)	Loss 6.1779e-02 (4.6969e-02)	Acc@1  96.88 ( 98.36)	Acc@5 100.00 (100.00)
Epoch: [60][100/391]	Time  0.038 ( 0.038)	Data  0.001 ( 0.003)	Loss 8.0165e-02 (4.6944e-02)	Acc@1  96.88 ( 98.35)	Acc@5 100.00 (100.00)
Epoch: [60][110/391]	Time  0.034 ( 0.038)	Data  0.001 ( 0.002)	Loss 6.3188e-02 (4.7435e-02)	Acc@1  98.44 ( 98.32)	Acc@5 100.00 (100.00)
Epoch: [60][120/391]	Time  0.042 ( 0.037)	Data  0.001 ( 0.002)	Loss 2.6326e-02 (4.7254e-02)	Acc@1  99.22 ( 98.35)	Acc@5 100.00 (100.00)
Epoch: [60][130/391]	Time  0.035 ( 0.037)	Data  0.001 ( 0.002)	Loss 2.7671e-02 (4.8120e-02)	Acc@1 100.00 ( 98.32)	Acc@5 100.00 (100.00)
Epoch: [60][140/391]	Time  0.035 ( 0.037)	Data  0.001 ( 0.002)	Loss 4.9661e-02 (4.8991e-02)	Acc@1  99.22 ( 98.32)	Acc@5 100.00 ( 99.99)
Epoch: [60][150/391]	Time  0.034 ( 0.037)	Data  0.001 ( 0.002)	Loss 3.1870e-02 (4.8886e-02)	Acc@1  98.44 ( 98.31)	Acc@5 100.00 ( 99.99)
Epoch: [60][160/391]	Time  0.034 ( 0.037)	Data  0.001 ( 0.002)	Loss 4.3944e-02 (4.8903e-02)	Acc@1  98.44 ( 98.32)	Acc@5 100.00 (100.00)
Epoch: [60][170/391]	Time  0.038 ( 0.037)	Data  0.001 ( 0.002)	Loss 2.6060e-02 (4.8787e-02)	Acc@1  99.22 ( 98.33)	Acc@5 100.00 (100.00)
Epoch: [60][180/391]	Time  0.034 ( 0.037)	Data  0.001 ( 0.002)	Loss 3.7942e-02 (4.8528e-02)	Acc@1  99.22 ( 98.35)	Acc@5 100.00 (100.00)
Epoch: [60][190/391]	Time  0.039 ( 0.037)	Data  0.001 ( 0.002)	Loss 2.1360e-02 (4.8420e-02)	Acc@1  99.22 ( 98.34)	Acc@5 100.00 (100.00)
Epoch: [60][200/391]	Time  0.037 ( 0.037)	Data  0.001 ( 0.002)	Loss 6.1623e-02 (4.8657e-02)	Acc@1  97.66 ( 98.32)	Acc@5 100.00 (100.00)
Epoch: [60][210/391]	Time  0.034 ( 0.037)	Data  0.001 ( 0.002)	Loss 2.6926e-02 (4.8475e-02)	Acc@1  99.22 ( 98.33)	Acc@5 100.00 (100.00)
Epoch: [60][220/391]	Time  0.036 ( 0.037)	Data  0.001 ( 0.002)	Loss 3.3218e-02 (4.8612e-02)	Acc@1  99.22 ( 98.32)	Acc@5 100.00 (100.00)
Epoch: [60][230/391]	Time  0.038 ( 0.037)	Data  0.001 ( 0.002)	Loss 4.8732e-02 (4.8658e-02)	Acc@1  97.66 ( 98.32)	Acc@5 100.00 (100.00)
Epoch: [60][240/391]	Time  0.035 ( 0.037)	Data  0.001 ( 0.002)	Loss 3.7239e-02 (4.8447e-02)	Acc@1  98.44 ( 98.32)	Acc@5 100.00 (100.00)
Epoch: [60][250/391]	Time  0.034 ( 0.037)	Data  0.001 ( 0.002)	Loss 3.6706e-02 (4.8218e-02)	Acc@1  97.66 ( 98.33)	Acc@5 100.00 (100.00)
Epoch: [60][260/391]	Time  0.034 ( 0.037)	Data  0.001 ( 0.002)	Loss 3.0704e-02 (4.7939e-02)	Acc@1  99.22 ( 98.34)	Acc@5 100.00 (100.00)
Epoch: [60][270/391]	Time  0.037 ( 0.037)	Data  0.001 ( 0.002)	Loss 1.5026e-02 (4.7805e-02)	Acc@1 100.00 ( 98.35)	Acc@5 100.00 (100.00)
Epoch: [60][280/391]	Time  0.034 ( 0.037)	Data  0.001 ( 0.001)	Loss 1.0803e-02 (4.7835e-02)	Acc@1 100.00 ( 98.34)	Acc@5 100.00 (100.00)
Epoch: [60][290/391]	Time  0.036 ( 0.037)	Data  0.001 ( 0.001)	Loss 6.3377e-02 (4.8171e-02)	Acc@1  97.66 ( 98.33)	Acc@5 100.00 (100.00)
Epoch: [60][300/391]	Time  0.039 ( 0.036)	Data  0.001 ( 0.001)	Loss 4.1573e-02 (4.8116e-02)	Acc@1  99.22 ( 98.34)	Acc@5 100.00 (100.00)
Epoch: [60][310/391]	Time  0.037 ( 0.036)	Data  0.001 ( 0.001)	Loss 7.6705e-02 (4.7866e-02)	Acc@1  97.66 ( 98.35)	Acc@5 100.00 (100.00)
Epoch: [60][320/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.001)	Loss 7.6564e-02 (4.8188e-02)	Acc@1  98.44 ( 98.34)	Acc@5 100.00 (100.00)
Epoch: [60][330/391]	Time  0.036 ( 0.036)	Data  0.001 ( 0.001)	Loss 4.7923e-02 (4.8362e-02)	Acc@1  98.44 ( 98.34)	Acc@5 100.00 (100.00)
Epoch: [60][340/391]	Time  0.037 ( 0.036)	Data  0.001 ( 0.001)	Loss 5.9730e-02 (4.8435e-02)	Acc@1  97.66 ( 98.34)	Acc@5 100.00 (100.00)
Epoch: [60][350/391]	Time  0.036 ( 0.036)	Data  0.001 ( 0.001)	Loss 2.7626e-02 (4.8664e-02)	Acc@1  99.22 ( 98.33)	Acc@5 100.00 (100.00)
Epoch: [60][360/391]	Time  0.042 ( 0.036)	Data  0.001 ( 0.001)	Loss 4.2353e-02 (4.8836e-02)	Acc@1  98.44 ( 98.32)	Acc@5 100.00 (100.00)
Epoch: [60][370/391]	Time  0.035 ( 0.036)	Data  0.002 ( 0.001)	Loss 1.6907e-02 (4.8603e-02)	Acc@1 100.00 ( 98.33)	Acc@5 100.00 (100.00)
Epoch: [60][380/391]	Time  0.035 ( 0.036)	Data  0.001 ( 0.001)	Loss 2.3811e-02 (4.8370e-02)	Acc@1 100.00 ( 98.35)	Acc@5 100.00 (100.00)
Epoch: [60][390/391]	Time  0.022 ( 0.036)	Data  0.001 ( 0.001)	Loss 3.1275e-02 (4.8439e-02)	Acc@1  98.75 ( 98.34)	Acc@5 100.00 (100.00)
## e[60] optimizer.zero_grad (sum) time: 0.1747605800628662
## e[60]       loss.backward (sum) time: 3.3184800148010254
## e[60]      optimizer.step (sum) time: 1.1584668159484863
## epoch[60] training(only) time: 14.325454235076904
# Switched to evaluate mode...
Test: [  0/100]	Time  0.171 ( 0.171)	Loss 1.4979e-01 (1.4979e-01)	Acc@1  94.00 ( 94.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.018 ( 0.033)	Loss 4.7756e-01 (3.5141e-01)	Acc@1  90.00 ( 91.55)	Acc@5 100.00 ( 99.91)
Test: [ 20/100]	Time  0.018 ( 0.027)	Loss 3.8792e-01 (3.7441e-01)	Acc@1  85.00 ( 90.81)	Acc@5 100.00 ( 99.67)
Test: [ 30/100]	Time  0.022 ( 0.025)	Loss 5.2000e-01 (4.0471e-01)	Acc@1  89.00 ( 90.42)	Acc@5  96.00 ( 99.52)
Test: [ 40/100]	Time  0.019 ( 0.024)	Loss 2.7338e-01 (4.1610e-01)	Acc@1  89.00 ( 90.17)	Acc@5 100.00 ( 99.51)
Test: [ 50/100]	Time  0.018 ( 0.023)	Loss 2.3958e-01 (4.1426e-01)	Acc@1  95.00 ( 90.31)	Acc@5 100.00 ( 99.53)
Test: [ 60/100]	Time  0.019 ( 0.022)	Loss 4.5128e-01 (4.0173e-01)	Acc@1  93.00 ( 90.39)	Acc@5 100.00 ( 99.57)
Test: [ 70/100]	Time  0.023 ( 0.022)	Loss 5.1270e-01 (3.9579e-01)	Acc@1  88.00 ( 90.37)	Acc@5 100.00 ( 99.59)
Test: [ 80/100]	Time  0.023 ( 0.022)	Loss 2.2054e-01 (3.8832e-01)	Acc@1  95.00 ( 90.49)	Acc@5 100.00 ( 99.62)
Test: [ 90/100]	Time  0.023 ( 0.021)	Loss 3.5285e-01 (3.9548e-01)	Acc@1  93.00 ( 90.42)	Acc@5 100.00 ( 99.64)
 * Acc@1 90.430 Acc@5 99.650
### epoch[60] execution time: 16.57567811012268
EPOCH 61
REMOVING: module.fire4.expand_3x3.1.weight
REMOVING: module.fire4.expand_3x3.1.bias
i:   0, name:  module.fire5.squeeze.0.weight  changing lr from: 0.001066959885427470   to: 0.001000001713038822
i:   1, name:    module.fire5.squeeze.0.bias  changing lr from: 0.001130834243163464   to: 0.001011239716387590
i:   2, name:  module.fire5.squeeze.1.weight  changing lr from: 0.001215020836311269   to: 0.001044010213425905
i:   3, name:    module.fire5.squeeze.1.bias  changing lr from: 0.001318938473976182   to: 0.001097727595780478
i:   4, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.001442012413699461   to: 0.001171811553679801
i:   5, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.001583674717670152   to: 0.001265687508296036
i:   6, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.001743364576366889   to: 0.001378787008309989
i:   7, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.001920528601303755   to: 0.001510548092454805
i:   8, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.002114621088494339   to: 0.001660415619735516
i:   9, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.002325104254189341   to: 0.001827841568963744
i:  10, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.002551448444384401   to: 0.002012285309189248
i:  11, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.002793132319537649   to: 0.002213213842553168
i:  12, name:  module.fire6.squeeze.0.weight  changing lr from: 0.003049643015880348   to: 0.002430102021031587
i:  13, name:    module.fire6.squeeze.0.bias  changing lr from: 0.003320476284648487   to: 0.002662432738482561
i:  14, name:  module.fire6.squeeze.1.weight  changing lr from: 0.003605136610509357   to: 0.002909697099355729
i:  15, name:    module.fire6.squeeze.1.bias  changing lr from: 0.003903137310404347   to: 0.003171394565369639
i:  16, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.004214000613977941   to: 0.003447033081410366
i:  17, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.004537257726712356   to: 0.003736129181853253
i:  18, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.004872448876838952   to: 0.004038208078460120
i:  19, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.005219123347049864   to: 0.004352803730955240
i:  20, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.005576839491987572   to: 0.004679458901336708
i:  21, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.005945164742445291   to: 0.005017725192932664
i:  22, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.006323675597168143   to: 0.005367163075168312
i:  23, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.006711957603103269   to: 0.005727341894965165
i:  24, name:  module.fire7.squeeze.0.weight  changing lr from: 0.007109605324906564   to: 0.006097839875652866
i:  25, name:    module.fire7.squeeze.0.bias  changing lr from: 0.007516222304475056   to: 0.006478244104232444
i:  26, name:  module.fire7.squeeze.1.weight  changing lr from: 0.007931421011235913   to: 0.006868150507790854
i:  27, name:    module.fire7.squeeze.1.bias  changing lr from: 0.008354822783887265   to: 0.007267163819828481
i:  28, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.008786057764251037   to: 0.007674897537224772
i:  29, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.009224764823864102   to: 0.008090973868531248
i:  30, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.009670591483902317   to: 0.008515023674247562
i:  31, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.010123193829000360   to: 0.008946686399702780
i:  32, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.010582236415501118   to: 0.009385610001133093
i:  33, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.011047392174639115   to: 0.009831450865515939
i:  34, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.011518342311135930   to: 0.010283873724692170
i:  35, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.011994776197658107   to: 0.010742551564278807
i:  36, name:  module.fire8.squeeze.0.weight  changing lr from: 0.012476391265564150   to: 0.011207165527848995
i:  37, name:    module.fire8.squeeze.0.bias  changing lr from: 0.012962892892341975   to: 0.011677404816829006
i:  38, name:  module.fire8.squeeze.1.weight  changing lr from: 0.013453994286116266   to: 0.012152966586538149
i:  39, name:    module.fire8.squeeze.1.bias  changing lr from: 0.013949416367582061   to: 0.012633555838773299
i:  40, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.014448887649700599   to: 0.013118885311316809
i:  41, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.014952144115473253   to: 0.013608675364725892
i:  42, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.015458929094089885   to: 0.014102653866739250
i:  43, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.015968993135730060   to: 0.014600556074618548
i:  44, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.016482093885277820   to: 0.015102124515721838
i:  45, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.016997995955194436   to: 0.015607108866589409
i:  46, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.017516470797777395   to: 0.016115265830804075
i:  47, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.018037296577019135   to: 0.016626359015872227
i:  48, name:  module.fire9.squeeze.0.weight  changing lr from: 0.018560258040264638   to: 0.017140158809356210
i:  49, name:    module.fire9.squeeze.0.bias  changing lr from: 0.019085146389853303   to: 0.017656442254473260
i:  50, name:  module.fire9.squeeze.1.weight  changing lr from: 0.019611759154917658   to: 0.018174992925362666
i:  51, name:    module.fire9.squeeze.1.bias  changing lr from: 0.020139900063499451   to: 0.018695600802208952
i:  52, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.020669378915131577   to: 0.019218062146395876
i:  53, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.021200011454023560   to: 0.019742179375854495
i:  54, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.021731619242977913   to: 0.020267760940756271
i:  55, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.022264029538154526   to: 0.020794621199691561
i:  56, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.022797075164791038   to: 0.021322580296463608
i:  57, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.023330594393978450   to: 0.021851464037617764
i:  58, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.023864430820582167   to: 0.022381103770816702
i:  59, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.024398433242391760   to: 0.022911336264163397
i:  60, name:           module.conv10.weight  changing lr from: 0.024932455540574328   to: 0.023442003586565448
i:  61, name:             module.conv10.bias  changing lr from: 0.025466356561499877   to: 0.023972952989226082



# Switched to train mode...
Epoch: [61][  0/391]	Time  0.205 ( 0.205)	Data  0.165 ( 0.165)	Loss 9.2751e-02 (9.2751e-02)	Acc@1  96.09 ( 96.09)	Acc@5 100.00 (100.00)
Epoch: [61][ 10/391]	Time  0.034 ( 0.051)	Data  0.001 ( 0.016)	Loss 3.6714e-02 (4.7281e-02)	Acc@1  98.44 ( 98.51)	Acc@5 100.00 (100.00)
Epoch: [61][ 20/391]	Time  0.035 ( 0.044)	Data  0.001 ( 0.009)	Loss 1.1033e-01 (4.5890e-02)	Acc@1  95.31 ( 98.55)	Acc@5 100.00 (100.00)
Epoch: [61][ 30/391]	Time  0.039 ( 0.041)	Data  0.001 ( 0.006)	Loss 8.9016e-02 (4.9304e-02)	Acc@1  96.09 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [61][ 40/391]	Time  0.037 ( 0.040)	Data  0.001 ( 0.005)	Loss 8.0901e-02 (4.9381e-02)	Acc@1  96.88 ( 98.38)	Acc@5 100.00 (100.00)
Epoch: [61][ 50/391]	Time  0.037 ( 0.039)	Data  0.001 ( 0.004)	Loss 7.3293e-02 (5.0847e-02)	Acc@1  97.66 ( 98.33)	Acc@5 100.00 (100.00)
Epoch: [61][ 60/391]	Time  0.034 ( 0.039)	Data  0.001 ( 0.004)	Loss 5.4396e-02 (5.0458e-02)	Acc@1  97.66 ( 98.36)	Acc@5 100.00 (100.00)
Epoch: [61][ 70/391]	Time  0.034 ( 0.038)	Data  0.001 ( 0.003)	Loss 1.5313e-02 (4.8808e-02)	Acc@1 100.00 ( 98.40)	Acc@5 100.00 (100.00)
Epoch: [61][ 80/391]	Time  0.035 ( 0.038)	Data  0.001 ( 0.003)	Loss 4.7783e-02 (4.8076e-02)	Acc@1  98.44 ( 98.41)	Acc@5 100.00 (100.00)
Epoch: [61][ 90/391]	Time  0.034 ( 0.038)	Data  0.001 ( 0.003)	Loss 4.4483e-02 (4.7613e-02)	Acc@1  99.22 ( 98.45)	Acc@5 100.00 (100.00)
Epoch: [61][100/391]	Time  0.034 ( 0.037)	Data  0.001 ( 0.003)	Loss 2.0878e-02 (4.6783e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [61][110/391]	Time  0.035 ( 0.037)	Data  0.001 ( 0.002)	Loss 2.4754e-02 (4.6845e-02)	Acc@1  99.22 ( 98.43)	Acc@5 100.00 (100.00)
Epoch: [61][120/391]	Time  0.036 ( 0.037)	Data  0.001 ( 0.002)	Loss 7.2997e-02 (4.6541e-02)	Acc@1  97.66 ( 98.43)	Acc@5 100.00 (100.00)
Epoch: [61][130/391]	Time  0.037 ( 0.037)	Data  0.001 ( 0.002)	Loss 1.0194e-02 (4.6162e-02)	Acc@1 100.00 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [61][140/391]	Time  0.034 ( 0.037)	Data  0.001 ( 0.002)	Loss 4.1815e-02 (4.6696e-02)	Acc@1  98.44 ( 98.41)	Acc@5 100.00 (100.00)
Epoch: [61][150/391]	Time  0.033 ( 0.037)	Data  0.001 ( 0.002)	Loss 1.0199e-01 (4.7914e-02)	Acc@1  96.09 ( 98.35)	Acc@5 100.00 (100.00)
Epoch: [61][160/391]	Time  0.036 ( 0.037)	Data  0.002 ( 0.002)	Loss 5.2607e-02 (4.7959e-02)	Acc@1  98.44 ( 98.36)	Acc@5 100.00 (100.00)
Epoch: [61][170/391]	Time  0.034 ( 0.037)	Data  0.001 ( 0.002)	Loss 3.0824e-02 (4.7648e-02)	Acc@1  99.22 ( 98.36)	Acc@5 100.00 (100.00)
Epoch: [61][180/391]	Time  0.034 ( 0.037)	Data  0.001 ( 0.002)	Loss 4.9943e-02 (4.7157e-02)	Acc@1  97.66 ( 98.38)	Acc@5 100.00 (100.00)
Epoch: [61][190/391]	Time  0.036 ( 0.037)	Data  0.001 ( 0.002)	Loss 9.4193e-02 (4.7518e-02)	Acc@1  96.88 ( 98.34)	Acc@5 100.00 (100.00)
Epoch: [61][200/391]	Time  0.035 ( 0.037)	Data  0.001 ( 0.002)	Loss 5.2136e-02 (4.7337e-02)	Acc@1  97.66 ( 98.35)	Acc@5 100.00 (100.00)
Epoch: [61][210/391]	Time  0.034 ( 0.037)	Data  0.001 ( 0.002)	Loss 4.2242e-02 (4.7203e-02)	Acc@1  98.44 ( 98.34)	Acc@5 100.00 (100.00)
Epoch: [61][220/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.002)	Loss 2.9865e-02 (4.7369e-02)	Acc@1  99.22 ( 98.34)	Acc@5 100.00 (100.00)
Epoch: [61][230/391]	Time  0.037 ( 0.036)	Data  0.001 ( 0.002)	Loss 2.9774e-02 (4.7547e-02)	Acc@1  99.22 ( 98.34)	Acc@5 100.00 (100.00)
Epoch: [61][240/391]	Time  0.042 ( 0.036)	Data  0.001 ( 0.002)	Loss 1.0488e-01 (4.8001e-02)	Acc@1  96.09 ( 98.32)	Acc@5 100.00 (100.00)
Epoch: [61][250/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.002)	Loss 7.8593e-02 (4.8189e-02)	Acc@1  97.66 ( 98.31)	Acc@5 100.00 (100.00)
Epoch: [61][260/391]	Time  0.037 ( 0.036)	Data  0.001 ( 0.002)	Loss 1.0197e-01 (4.8509e-02)	Acc@1  97.66 ( 98.31)	Acc@5 100.00 (100.00)
Epoch: [61][270/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.002)	Loss 3.4359e-02 (4.8415e-02)	Acc@1  99.22 ( 98.31)	Acc@5 100.00 (100.00)
Epoch: [61][280/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.002)	Loss 4.2288e-02 (4.7951e-02)	Acc@1  98.44 ( 98.33)	Acc@5 100.00 (100.00)
Epoch: [61][290/391]	Time  0.038 ( 0.036)	Data  0.001 ( 0.002)	Loss 2.5652e-02 (4.8027e-02)	Acc@1 100.00 ( 98.34)	Acc@5 100.00 (100.00)
Epoch: [61][300/391]	Time  0.037 ( 0.036)	Data  0.001 ( 0.002)	Loss 5.4592e-02 (4.8090e-02)	Acc@1  98.44 ( 98.34)	Acc@5 100.00 (100.00)
Epoch: [61][310/391]	Time  0.038 ( 0.036)	Data  0.001 ( 0.001)	Loss 7.1864e-02 (4.8051e-02)	Acc@1  96.88 ( 98.34)	Acc@5 100.00 (100.00)
Epoch: [61][320/391]	Time  0.037 ( 0.036)	Data  0.001 ( 0.001)	Loss 1.9782e-02 (4.8390e-02)	Acc@1 100.00 ( 98.33)	Acc@5 100.00 (100.00)
Epoch: [61][330/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.001)	Loss 5.1165e-02 (4.8655e-02)	Acc@1  96.88 ( 98.32)	Acc@5 100.00 (100.00)
Epoch: [61][340/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.001)	Loss 2.8960e-02 (4.9011e-02)	Acc@1  99.22 ( 98.31)	Acc@5 100.00 (100.00)
Epoch: [61][350/391]	Time  0.037 ( 0.036)	Data  0.001 ( 0.001)	Loss 2.0594e-02 (4.9076e-02)	Acc@1 100.00 ( 98.32)	Acc@5 100.00 (100.00)
Epoch: [61][360/391]	Time  0.035 ( 0.036)	Data  0.001 ( 0.001)	Loss 3.1877e-02 (4.8945e-02)	Acc@1  97.66 ( 98.32)	Acc@5 100.00 (100.00)
Epoch: [61][370/391]	Time  0.037 ( 0.036)	Data  0.001 ( 0.001)	Loss 5.6703e-02 (4.8790e-02)	Acc@1  98.44 ( 98.34)	Acc@5 100.00 (100.00)
Epoch: [61][380/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.001)	Loss 5.7542e-02 (4.8575e-02)	Acc@1  96.88 ( 98.34)	Acc@5 100.00 (100.00)
Epoch: [61][390/391]	Time  0.023 ( 0.036)	Data  0.001 ( 0.001)	Loss 2.2953e-02 (4.8352e-02)	Acc@1 100.00 ( 98.34)	Acc@5 100.00 (100.00)
## e[61] optimizer.zero_grad (sum) time: 0.1701366901397705
## e[61]       loss.backward (sum) time: 3.242326021194458
## e[61]      optimizer.step (sum) time: 1.1213152408599854
## epoch[61] training(only) time: 14.195002794265747
# Switched to evaluate mode...
Test: [  0/100]	Time  0.171 ( 0.171)	Loss 1.0206e-01 (1.0206e-01)	Acc@1  97.00 ( 97.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.022 ( 0.034)	Loss 4.7836e-01 (3.1282e-01)	Acc@1  90.00 ( 92.36)	Acc@5 100.00 ( 99.91)
Test: [ 20/100]	Time  0.018 ( 0.026)	Loss 3.9958e-01 (3.6726e-01)	Acc@1  89.00 ( 91.29)	Acc@5 100.00 ( 99.71)
Test: [ 30/100]	Time  0.017 ( 0.024)	Loss 5.5728e-01 (3.9211e-01)	Acc@1  85.00 ( 91.00)	Acc@5  98.00 ( 99.68)
Test: [ 40/100]	Time  0.017 ( 0.023)	Loss 3.6996e-01 (4.0417e-01)	Acc@1  90.00 ( 90.78)	Acc@5 100.00 ( 99.66)
Test: [ 50/100]	Time  0.017 ( 0.022)	Loss 1.2186e-01 (3.9875e-01)	Acc@1  93.00 ( 90.84)	Acc@5 100.00 ( 99.63)
Test: [ 60/100]	Time  0.021 ( 0.022)	Loss 4.1143e-01 (3.8482e-01)	Acc@1  94.00 ( 90.87)	Acc@5 100.00 ( 99.66)
Test: [ 70/100]	Time  0.020 ( 0.022)	Loss 5.1484e-01 (3.8028e-01)	Acc@1  88.00 ( 90.85)	Acc@5 100.00 ( 99.69)
Test: [ 80/100]	Time  0.021 ( 0.021)	Loss 1.9711e-01 (3.7225e-01)	Acc@1  97.00 ( 90.89)	Acc@5 100.00 ( 99.72)
Test: [ 90/100]	Time  0.023 ( 0.021)	Loss 2.3124e-01 (3.7986e-01)	Acc@1  94.00 ( 90.76)	Acc@5 100.00 ( 99.73)
 * Acc@1 90.750 Acc@5 99.720
### epoch[61] execution time: 16.457475662231445
EPOCH 62
REMOVING: module.fire5.squeeze.0.weight
REMOVING: module.fire5.squeeze.0.bias
REMOVING: module.fire5.squeeze.1.weight
i:   0, name:    module.fire5.squeeze.1.bias  changing lr from: 0.001097727595780478   to: 0.001003634012413478
i:   1, name: module.fire5.expand_1x1.0.weight  changing lr from: 0.001171811553679801   to: 0.001026864022684869
i:   2, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.001265687508296036   to: 0.001071071244522458
i:   3, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.001378787008309989   to: 0.001135682347655763
i:   4, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.001510548092454805   to: 0.001220129424513810
i:   5, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.001660415619735516   to: 0.001323850391686181
i:   6, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.001827841568963744   to: 0.001446289357686863
i:   7, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.002012285309189248   to: 0.001586896958680466
i:   8, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.002213213842553168   to: 0.001745130663774835
i:   9, name:  module.fire6.squeeze.0.weight  changing lr from: 0.002430102021031587   to: 0.001920455051428676
i:  10, name:    module.fire6.squeeze.0.bias  changing lr from: 0.002662432738482561   to: 0.002112342058468163
i:  11, name:  module.fire6.squeeze.1.weight  changing lr from: 0.002909697099355729   to: 0.002320271203152162
i:  12, name:    module.fire6.squeeze.1.bias  changing lr from: 0.003171394565369639   to: 0.002543729783672398
i:  13, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.003447033081410366   to: 0.002782213053422427
i:  14, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.003736129181853253   to: 0.003035224374317496
i:  15, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.004038208078460120   to: 0.003302275349396915
i:  16, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.004352803730955240   to: 0.003582885935890944
i:  17, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.004679458901336708   to: 0.003876584539886074
i:  18, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.005017725192932664   to: 0.004182908093674880
i:  19, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.005367163075168312   to: 0.004501402116831159
i:  20, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.005727341894965165   to: 0.004831620762005927
i:  21, name:  module.fire7.squeeze.0.weight  changing lr from: 0.006097839875652866   to: 0.005173126846396491
i:  22, name:    module.fire7.squeeze.0.bias  changing lr from: 0.006478244104232444   to: 0.005525491869798576
i:  23, name:  module.fire7.squeeze.1.weight  changing lr from: 0.006868150507790854   to: 0.005888296020110411
i:  24, name:    module.fire7.squeeze.1.bias  changing lr from: 0.007267163819828481   to: 0.006261128167117968
i:  25, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.007674897537224772   to: 0.006643585845352473
i:  26, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.008090973868531248   to: 0.007035275226773479
i:  27, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.008515023674247562   to: 0.007435811083995768
i:  28, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.008946686399702780   to: 0.007844816744742810
i:  29, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.009385610001133093   to: 0.008261924038176893
i:  30, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.009831450865515939   to: 0.008686773233723221
i:  31, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.010283873724692170   to: 0.009119012972974821
i:  32, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.010742551564278807   to: 0.009558300195234664
i:  33, name:  module.fire8.squeeze.0.weight  changing lr from: 0.011207165527848995   to: 0.010004300057223459
i:  34, name:    module.fire8.squeeze.0.bias  changing lr from: 0.011677404816829006   to: 0.010456685847453091
i:  35, name:  module.fire8.squeeze.1.weight  changing lr from: 0.012152966586538149   to: 0.010915138895740372
i:  36, name:    module.fire8.squeeze.1.bias  changing lr from: 0.012633555838773299   to: 0.011379348478309258
i:  37, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.013118885311316809   to: 0.011849011718906000
i:  38, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.013608675364725892   to: 0.012323833486328352
i:  39, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.014102653866739250   to: 0.012803526288747220
i:  40, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.014600556074618548   to: 0.013287810165178205
i:  41, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.015102124515721838   to: 0.013776412574439661
i:  42, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.015607108866589409   to: 0.014269068281914644
i:  43, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.016115265830804075   to: 0.014765519244415205
i:  44, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.016626359015872227   to: 0.015265514493429687
i:  45, name:  module.fire9.squeeze.0.weight  changing lr from: 0.017140158809356210   to: 0.015768810017016882
i:  46, name:    module.fire9.squeeze.0.bias  changing lr from: 0.017656442254473260   to: 0.016275168640594185
i:  47, name:  module.fire9.squeeze.1.weight  changing lr from: 0.018174992925362666   to: 0.016784359906851960
i:  48, name:    module.fire9.squeeze.1.bias  changing lr from: 0.018695600802208952   to: 0.017296159955011065
i:  49, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.019218062146395876   to: 0.017810351399626861
i:  50, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.019742179375854495   to: 0.018326723209129241
i:  51, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.020267760940756271   to: 0.018845070584275998
i:  52, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.020794621199691561   to: 0.019365194836684110
i:  53, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.021322580296463608   to: 0.019886903267592765
i:  54, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.021851464037617764   to: 0.020410009047000400
i:  55, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.022381103770816702   to: 0.020934331093307935
i:  56, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.022911336264163397   to: 0.021459693953590715
i:  57, name:           module.conv10.weight  changing lr from: 0.023442003586565448   to: 0.021985927684612112
i:  58, name:             module.conv10.bias  changing lr from: 0.023972952989226082   to: 0.022512867734682970



# Switched to train mode...
Epoch: [62][  0/391]	Time  0.201 ( 0.201)	Data  0.164 ( 0.164)	Loss 8.2663e-02 (8.2663e-02)	Acc@1  97.66 ( 97.66)	Acc@5  99.22 ( 99.22)
Epoch: [62][ 10/391]	Time  0.036 ( 0.051)	Data  0.001 ( 0.016)	Loss 2.1126e-02 (5.7050e-02)	Acc@1  99.22 ( 97.80)	Acc@5 100.00 ( 99.86)
Epoch: [62][ 20/391]	Time  0.034 ( 0.043)	Data  0.001 ( 0.009)	Loss 3.8349e-02 (4.8142e-02)	Acc@1  97.66 ( 98.10)	Acc@5 100.00 ( 99.93)
Epoch: [62][ 30/391]	Time  0.037 ( 0.041)	Data  0.001 ( 0.006)	Loss 1.0243e-01 (4.8803e-02)	Acc@1  96.88 ( 98.08)	Acc@5 100.00 ( 99.95)
Epoch: [62][ 40/391]	Time  0.034 ( 0.040)	Data  0.001 ( 0.005)	Loss 9.4033e-03 (4.7335e-02)	Acc@1 100.00 ( 98.21)	Acc@5 100.00 ( 99.96)
Epoch: [62][ 50/391]	Time  0.040 ( 0.039)	Data  0.001 ( 0.004)	Loss 7.4028e-02 (4.6165e-02)	Acc@1  97.66 ( 98.27)	Acc@5 100.00 ( 99.97)
Epoch: [62][ 60/391]	Time  0.036 ( 0.039)	Data  0.001 ( 0.004)	Loss 3.6703e-02 (4.6097e-02)	Acc@1  98.44 ( 98.35)	Acc@5 100.00 ( 99.97)
Epoch: [62][ 70/391]	Time  0.034 ( 0.038)	Data  0.001 ( 0.003)	Loss 1.6190e-02 (4.4672e-02)	Acc@1 100.00 ( 98.42)	Acc@5 100.00 ( 99.98)
Epoch: [62][ 80/391]	Time  0.037 ( 0.038)	Data  0.001 ( 0.003)	Loss 5.8694e-02 (4.4116e-02)	Acc@1  98.44 ( 98.47)	Acc@5 100.00 ( 99.98)
Epoch: [62][ 90/391]	Time  0.034 ( 0.037)	Data  0.001 ( 0.003)	Loss 4.5363e-02 (4.5472e-02)	Acc@1  98.44 ( 98.43)	Acc@5 100.00 ( 99.98)
Epoch: [62][100/391]	Time  0.035 ( 0.037)	Data  0.001 ( 0.003)	Loss 1.1138e-01 (4.5636e-02)	Acc@1  96.09 ( 98.39)	Acc@5 100.00 ( 99.98)
Epoch: [62][110/391]	Time  0.038 ( 0.037)	Data  0.001 ( 0.002)	Loss 6.4653e-02 (4.5721e-02)	Acc@1  98.44 ( 98.40)	Acc@5 100.00 ( 99.99)
Epoch: [62][120/391]	Time  0.034 ( 0.037)	Data  0.001 ( 0.002)	Loss 2.5914e-02 (4.5504e-02)	Acc@1 100.00 ( 98.45)	Acc@5 100.00 ( 99.99)
Epoch: [62][130/391]	Time  0.040 ( 0.037)	Data  0.001 ( 0.002)	Loss 1.1666e-02 (4.4254e-02)	Acc@1 100.00 ( 98.50)	Acc@5 100.00 ( 99.99)
Epoch: [62][140/391]	Time  0.036 ( 0.037)	Data  0.001 ( 0.002)	Loss 6.1075e-02 (4.4404e-02)	Acc@1  98.44 ( 98.49)	Acc@5 100.00 ( 99.99)
Epoch: [62][150/391]	Time  0.036 ( 0.037)	Data  0.001 ( 0.002)	Loss 5.3762e-02 (4.4840e-02)	Acc@1  97.66 ( 98.47)	Acc@5 100.00 ( 99.99)
Epoch: [62][160/391]	Time  0.033 ( 0.036)	Data  0.001 ( 0.002)	Loss 4.1929e-02 (4.4659e-02)	Acc@1  99.22 ( 98.49)	Acc@5 100.00 ( 99.99)
Epoch: [62][170/391]	Time  0.035 ( 0.036)	Data  0.001 ( 0.002)	Loss 1.7457e-02 (4.3902e-02)	Acc@1 100.00 ( 98.51)	Acc@5 100.00 ( 99.99)
Epoch: [62][180/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.002)	Loss 1.4663e-02 (4.3119e-02)	Acc@1 100.00 ( 98.53)	Acc@5 100.00 ( 99.99)
Epoch: [62][190/391]	Time  0.035 ( 0.036)	Data  0.001 ( 0.002)	Loss 1.5801e-02 (4.2911e-02)	Acc@1 100.00 ( 98.56)	Acc@5 100.00 ( 99.99)
Epoch: [62][200/391]	Time  0.037 ( 0.036)	Data  0.001 ( 0.002)	Loss 4.2976e-02 (4.2741e-02)	Acc@1  98.44 ( 98.57)	Acc@5 100.00 ( 99.99)
Epoch: [62][210/391]	Time  0.035 ( 0.036)	Data  0.001 ( 0.002)	Loss 6.0211e-02 (4.2943e-02)	Acc@1  97.66 ( 98.56)	Acc@5 100.00 ( 99.99)
Epoch: [62][220/391]	Time  0.046 ( 0.036)	Data  0.002 ( 0.002)	Loss 4.9135e-02 (4.3019e-02)	Acc@1  98.44 ( 98.55)	Acc@5 100.00 ( 99.99)
Epoch: [62][230/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.002)	Loss 5.1483e-02 (4.3074e-02)	Acc@1  98.44 ( 98.55)	Acc@5 100.00 ( 99.99)
Epoch: [62][240/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.002)	Loss 3.5519e-02 (4.2991e-02)	Acc@1  98.44 ( 98.55)	Acc@5 100.00 ( 99.99)
Epoch: [62][250/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.002)	Loss 2.7048e-02 (4.2862e-02)	Acc@1  99.22 ( 98.55)	Acc@5 100.00 ( 99.99)
Epoch: [62][260/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.002)	Loss 1.8172e-02 (4.3170e-02)	Acc@1 100.00 ( 98.56)	Acc@5 100.00 ( 99.99)
Epoch: [62][270/391]	Time  0.038 ( 0.036)	Data  0.001 ( 0.002)	Loss 3.2982e-02 (4.3238e-02)	Acc@1  99.22 ( 98.55)	Acc@5 100.00 ( 99.99)
Epoch: [62][280/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.002)	Loss 6.2719e-02 (4.3272e-02)	Acc@1  97.66 ( 98.55)	Acc@5 100.00 ( 99.99)
Epoch: [62][290/391]	Time  0.035 ( 0.036)	Data  0.001 ( 0.002)	Loss 4.6873e-02 (4.3987e-02)	Acc@1  98.44 ( 98.53)	Acc@5 100.00 ( 99.99)
Epoch: [62][300/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.002)	Loss 4.2210e-02 (4.3934e-02)	Acc@1  99.22 ( 98.53)	Acc@5 100.00 ( 99.99)
Epoch: [62][310/391]	Time  0.035 ( 0.036)	Data  0.001 ( 0.001)	Loss 2.9135e-02 (4.4036e-02)	Acc@1  99.22 ( 98.52)	Acc@5 100.00 ( 99.99)
Epoch: [62][320/391]	Time  0.035 ( 0.036)	Data  0.001 ( 0.001)	Loss 5.8988e-02 (4.3969e-02)	Acc@1  98.44 ( 98.52)	Acc@5 100.00 ( 99.99)
Epoch: [62][330/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.001)	Loss 1.4774e-02 (4.3791e-02)	Acc@1 100.00 ( 98.53)	Acc@5 100.00 ( 99.99)
Epoch: [62][340/391]	Time  0.039 ( 0.036)	Data  0.001 ( 0.001)	Loss 2.9167e-02 (4.3918e-02)	Acc@1  99.22 ( 98.52)	Acc@5 100.00 ( 99.99)
Epoch: [62][350/391]	Time  0.033 ( 0.036)	Data  0.001 ( 0.001)	Loss 2.6074e-02 (4.3746e-02)	Acc@1 100.00 ( 98.53)	Acc@5 100.00 ( 99.99)
Epoch: [62][360/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.001)	Loss 5.8094e-02 (4.3880e-02)	Acc@1  97.66 ( 98.52)	Acc@5 100.00 ( 99.99)
Epoch: [62][370/391]	Time  0.035 ( 0.036)	Data  0.001 ( 0.001)	Loss 2.9920e-02 (4.3912e-02)	Acc@1  99.22 ( 98.51)	Acc@5 100.00 ( 99.99)
Epoch: [62][380/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.001)	Loss 4.3705e-02 (4.3841e-02)	Acc@1  98.44 ( 98.51)	Acc@5 100.00 ( 99.99)
Epoch: [62][390/391]	Time  0.024 ( 0.036)	Data  0.001 ( 0.001)	Loss 3.8630e-02 (4.3609e-02)	Acc@1  98.75 ( 98.52)	Acc@5 100.00 ( 99.99)
## e[62] optimizer.zero_grad (sum) time: 0.16161489486694336
## e[62]       loss.backward (sum) time: 3.2400619983673096
## e[62]      optimizer.step (sum) time: 1.0731537342071533
## epoch[62] training(only) time: 14.008240461349487
# Switched to evaluate mode...
Test: [  0/100]	Time  0.174 ( 0.174)	Loss 1.4442e-01 (1.4442e-01)	Acc@1  94.00 ( 94.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.020 ( 0.036)	Loss 5.2383e-01 (3.2950e-01)	Acc@1  89.00 ( 91.45)	Acc@5 100.00 ( 99.82)
Test: [ 20/100]	Time  0.018 ( 0.028)	Loss 2.8896e-01 (3.7061e-01)	Acc@1  92.00 ( 91.38)	Acc@5 100.00 ( 99.71)
Test: [ 30/100]	Time  0.023 ( 0.025)	Loss 5.0548e-01 (4.0318e-01)	Acc@1  88.00 ( 91.10)	Acc@5  98.00 ( 99.58)
Test: [ 40/100]	Time  0.018 ( 0.024)	Loss 3.8253e-01 (4.0929e-01)	Acc@1  88.00 ( 90.80)	Acc@5 100.00 ( 99.59)
Test: [ 50/100]	Time  0.018 ( 0.023)	Loss 1.8626e-01 (4.0948e-01)	Acc@1  93.00 ( 90.78)	Acc@5 100.00 ( 99.61)
Test: [ 60/100]	Time  0.020 ( 0.023)	Loss 4.7724e-01 (3.9644e-01)	Acc@1  93.00 ( 90.82)	Acc@5  99.00 ( 99.62)
Test: [ 70/100]	Time  0.023 ( 0.022)	Loss 4.9001e-01 (3.8683e-01)	Acc@1  89.00 ( 90.90)	Acc@5 100.00 ( 99.63)
Test: [ 80/100]	Time  0.018 ( 0.022)	Loss 1.9486e-01 (3.8116e-01)	Acc@1  96.00 ( 90.96)	Acc@5 100.00 ( 99.67)
Test: [ 90/100]	Time  0.022 ( 0.022)	Loss 2.5715e-01 (3.8819e-01)	Acc@1  95.00 ( 90.95)	Acc@5 100.00 ( 99.69)
 * Acc@1 90.940 Acc@5 99.690
### epoch[62] execution time: 16.24277377128601
EPOCH 63
REMOVING: module.fire5.squeeze.1.bias
REMOVING: module.fire5.expand_1x1.0.weight
i:   0, name: module.fire5.expand_1x1.0.bias  changing lr from: 0.001071071244522458   to: 0.001000308691492590
i:   1, name: module.fire5.expand_1x1.1.weight  changing lr from: 0.001135682347655763   to: 0.001014645715485556
i:   2, name: module.fire5.expand_1x1.1.bias  changing lr from: 0.001220129424513810   to: 0.001049974221548821
i:   3, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.001323850391686181   to: 0.001105727875930539
i:   4, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.001446289357686863   to: 0.001181345477776634
i:   5, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.001586896958680466   to: 0.001276271364399350
i:   6, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.001745130663774835   to: 0.001389955783209533
i:   7, name:  module.fire6.squeeze.0.weight  changing lr from: 0.001920455051428676   to: 0.001521855231934426
i:   8, name:    module.fire6.squeeze.0.bias  changing lr from: 0.002112342058468163   to: 0.001671432768689445
i:   9, name:  module.fire6.squeeze.1.weight  changing lr from: 0.002320271203152162   to: 0.001838158293419156
i:  10, name:    module.fire6.squeeze.1.bias  changing lr from: 0.002543729783672398   to: 0.002021508802169957
i:  11, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.002782213053422427   to: 0.002220968615604867
i:  12, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.003035224374317496   to: 0.002436029583119097
i:  13, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.003302275349396915   to: 0.002666191263864675
i:  14, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.003582885935890944   to: 0.002910961085942103
i:  15, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.003876584539886074   to: 0.003169854484968592
i:  16, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.004182908093674880   to: 0.003442395023183891
i:  17, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.004501402116831159   to: 0.003728114490208417
i:  18, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.004831620762005927   to: 0.004026552986522097
i:  19, name:  module.fire7.squeeze.0.weight  changing lr from: 0.005173126846396491   to: 0.004337258990688186
i:  20, name:    module.fire7.squeeze.0.bias  changing lr from: 0.005525491869798576   to: 0.004659789411302255
i:  21, name:  module.fire7.squeeze.1.weight  changing lr from: 0.005888296020110411   to: 0.004993709624604952
i:  22, name:    module.fire7.squeeze.1.bias  changing lr from: 0.006261128167117968   to: 0.005338593498655108
i:  23, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.006643585845352473   to: 0.005694023404921028
i:  24, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.007035275226773479   to: 0.006059590218108024
i:  25, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.007435811083995768   to: 0.006434893305003564
i:  26, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.007844816744742810   to: 0.006819540503084775
i:  27, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.008261924038176893   to: 0.007213148089598242
i:  28, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.008686773233723221   to: 0.007615340741787912
i:  29, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.009119012972974821   to: 0.008025751488914795
i:  30, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.009558300195234664   to: 0.008444021656679894
i:  31, name:  module.fire8.squeeze.0.weight  changing lr from: 0.010004300057223459   to: 0.008869800804632243
i:  32, name:    module.fire8.squeeze.0.bias  changing lr from: 0.010456685847453091   to: 0.009302746657114187
i:  33, name:  module.fire8.squeeze.1.weight  changing lr from: 0.010915138895740372   to: 0.009742525028268133
i:  34, name:    module.fire8.squeeze.1.bias  changing lr from: 0.011379348478309258   to: 0.010188809741602217
i:  35, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.011849011718906000   to: 0.010641282544585594
i:  36, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.012323833486328352   to: 0.011099633018720474
i:  37, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.012803526288747220   to: 0.011563558485512444
i:  38, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.013287810165178205   to: 0.012032763908739374
i:  39, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.013776412574439661   to: 0.012506961793395766
i:  40, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.014269068281914644   to: 0.012985872081669625
i:  41, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.014765519244415205   to: 0.013469222046287567
i:  42, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.015265514493429687   to: 0.013956746181545861
i:  43, name:  module.fire9.squeeze.0.weight  changing lr from: 0.015768810017016882   to: 0.014448186092325628
i:  44, name:    module.fire9.squeeze.0.bias  changing lr from: 0.016275168640594185   to: 0.014943290381373413
i:  45, name:  module.fire9.squeeze.1.weight  changing lr from: 0.016784359906851960   to: 0.015441814535111353
i:  46, name:    module.fire9.squeeze.1.bias  changing lr from: 0.017296159955011065   to: 0.015943520808225302
i:  47, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.017810351399626861   to: 0.016448178107263522
i:  48, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.018326723209129241   to: 0.016955561873464520
i:  49, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.018845070584275998   to: 0.017465453965018418
i:  50, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.019365194836684110   to: 0.017977642538952950
i:  51, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.019886903267592765   to: 0.018491921932822713
i:  52, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.020410009047000400   to: 0.019008092546368444
i:  53, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.020934331093307935   to: 0.019525960723301160
i:  54, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.021459693953590715   to: 0.020045338633355891
i:  55, name:           module.conv10.weight  changing lr from: 0.021985927684612112   to: 0.020566044154749004
i:  56, name:             module.conv10.bias  changing lr from: 0.022512867734682970   to: 0.021087900757163339



# Switched to train mode...
Epoch: [63][  0/391]	Time  0.202 ( 0.202)	Data  0.158 ( 0.158)	Loss 6.0088e-02 (6.0088e-02)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [63][ 10/391]	Time  0.038 ( 0.051)	Data  0.001 ( 0.015)	Loss 4.0931e-02 (4.2556e-02)	Acc@1  98.44 ( 98.37)	Acc@5 100.00 (100.00)
Epoch: [63][ 20/391]	Time  0.034 ( 0.044)	Data  0.001 ( 0.008)	Loss 1.3932e-02 (4.4126e-02)	Acc@1 100.00 ( 98.51)	Acc@5 100.00 (100.00)
Epoch: [63][ 30/391]	Time  0.033 ( 0.040)	Data  0.001 ( 0.006)	Loss 3.0308e-02 (4.2560e-02)	Acc@1  99.22 ( 98.54)	Acc@5 100.00 (100.00)
Epoch: [63][ 40/391]	Time  0.033 ( 0.039)	Data  0.001 ( 0.005)	Loss 5.7426e-02 (4.3572e-02)	Acc@1  98.44 ( 98.59)	Acc@5 100.00 (100.00)
Epoch: [63][ 50/391]	Time  0.035 ( 0.038)	Data  0.001 ( 0.004)	Loss 3.6410e-02 (4.1256e-02)	Acc@1  98.44 ( 98.67)	Acc@5 100.00 (100.00)
Epoch: [63][ 60/391]	Time  0.035 ( 0.037)	Data  0.001 ( 0.004)	Loss 3.5742e-02 (3.9923e-02)	Acc@1  99.22 ( 98.73)	Acc@5 100.00 (100.00)
Epoch: [63][ 70/391]	Time  0.033 ( 0.037)	Data  0.001 ( 0.003)	Loss 1.7261e-02 (4.1776e-02)	Acc@1 100.00 ( 98.62)	Acc@5 100.00 (100.00)
Epoch: [63][ 80/391]	Time  0.035 ( 0.037)	Data  0.001 ( 0.003)	Loss 2.5858e-02 (4.1894e-02)	Acc@1  98.44 ( 98.61)	Acc@5 100.00 (100.00)
Epoch: [63][ 90/391]	Time  0.038 ( 0.036)	Data  0.001 ( 0.003)	Loss 6.0191e-02 (4.1235e-02)	Acc@1  98.44 ( 98.65)	Acc@5 100.00 (100.00)
Epoch: [63][100/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.003)	Loss 6.7050e-02 (4.0938e-02)	Acc@1  97.66 ( 98.68)	Acc@5 100.00 (100.00)
Epoch: [63][110/391]	Time  0.041 ( 0.036)	Data  0.001 ( 0.002)	Loss 5.1184e-02 (4.1240e-02)	Acc@1  97.66 ( 98.68)	Acc@5 100.00 (100.00)
Epoch: [63][120/391]	Time  0.038 ( 0.036)	Data  0.001 ( 0.002)	Loss 1.7039e-02 (4.0915e-02)	Acc@1 100.00 ( 98.70)	Acc@5 100.00 (100.00)
Epoch: [63][130/391]	Time  0.035 ( 0.036)	Data  0.001 ( 0.002)	Loss 4.7987e-02 (4.0682e-02)	Acc@1  98.44 ( 98.71)	Acc@5 100.00 (100.00)
Epoch: [63][140/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.002)	Loss 1.4151e-02 (4.0069e-02)	Acc@1 100.00 ( 98.71)	Acc@5 100.00 (100.00)
Epoch: [63][150/391]	Time  0.036 ( 0.036)	Data  0.001 ( 0.002)	Loss 3.8588e-02 (4.1203e-02)	Acc@1  98.44 ( 98.66)	Acc@5 100.00 (100.00)
Epoch: [63][160/391]	Time  0.039 ( 0.036)	Data  0.001 ( 0.002)	Loss 5.1794e-02 (4.1090e-02)	Acc@1  97.66 ( 98.67)	Acc@5 100.00 (100.00)
Epoch: [63][170/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.002)	Loss 3.0055e-02 (4.0898e-02)	Acc@1  99.22 ( 98.68)	Acc@5 100.00 (100.00)
Epoch: [63][180/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.002)	Loss 5.9257e-02 (4.0392e-02)	Acc@1  96.88 ( 98.70)	Acc@5 100.00 (100.00)
Epoch: [63][190/391]	Time  0.036 ( 0.036)	Data  0.001 ( 0.002)	Loss 2.7486e-02 (4.0358e-02)	Acc@1 100.00 ( 98.71)	Acc@5 100.00 (100.00)
Epoch: [63][200/391]	Time  0.033 ( 0.036)	Data  0.001 ( 0.002)	Loss 3.9001e-02 (4.0152e-02)	Acc@1  97.66 ( 98.71)	Acc@5 100.00 (100.00)
Epoch: [63][210/391]	Time  0.033 ( 0.036)	Data  0.001 ( 0.002)	Loss 6.2473e-02 (4.0210e-02)	Acc@1  98.44 ( 98.71)	Acc@5 100.00 (100.00)
Epoch: [63][220/391]	Time  0.038 ( 0.036)	Data  0.001 ( 0.002)	Loss 1.0422e-01 (4.0385e-02)	Acc@1  96.88 ( 98.70)	Acc@5 100.00 (100.00)
Epoch: [63][230/391]	Time  0.035 ( 0.035)	Data  0.001 ( 0.002)	Loss 2.6120e-02 (4.0355e-02)	Acc@1  99.22 ( 98.70)	Acc@5 100.00 (100.00)
Epoch: [63][240/391]	Time  0.033 ( 0.035)	Data  0.001 ( 0.002)	Loss 2.4648e-02 (3.9738e-02)	Acc@1  99.22 ( 98.72)	Acc@5 100.00 (100.00)
Epoch: [63][250/391]	Time  0.034 ( 0.035)	Data  0.001 ( 0.002)	Loss 5.1082e-02 (3.9874e-02)	Acc@1  96.88 ( 98.70)	Acc@5 100.00 (100.00)
Epoch: [63][260/391]	Time  0.033 ( 0.035)	Data  0.001 ( 0.002)	Loss 4.2080e-02 (3.9649e-02)	Acc@1  98.44 ( 98.71)	Acc@5 100.00 (100.00)
Epoch: [63][270/391]	Time  0.034 ( 0.035)	Data  0.001 ( 0.002)	Loss 2.9791e-02 (3.9941e-02)	Acc@1  99.22 ( 98.69)	Acc@5 100.00 (100.00)
Epoch: [63][280/391]	Time  0.034 ( 0.035)	Data  0.001 ( 0.002)	Loss 3.9494e-02 (3.9744e-02)	Acc@1  98.44 ( 98.70)	Acc@5 100.00 (100.00)
Epoch: [63][290/391]	Time  0.035 ( 0.035)	Data  0.001 ( 0.002)	Loss 1.9736e-02 (3.9742e-02)	Acc@1 100.00 ( 98.71)	Acc@5 100.00 (100.00)
Epoch: [63][300/391]	Time  0.034 ( 0.035)	Data  0.001 ( 0.001)	Loss 2.9627e-02 (3.9782e-02)	Acc@1  98.44 ( 98.70)	Acc@5 100.00 (100.00)
Epoch: [63][310/391]	Time  0.035 ( 0.035)	Data  0.001 ( 0.001)	Loss 5.8572e-02 (3.9765e-02)	Acc@1  97.66 ( 98.71)	Acc@5 100.00 (100.00)
Epoch: [63][320/391]	Time  0.038 ( 0.035)	Data  0.001 ( 0.001)	Loss 6.5615e-02 (3.9945e-02)	Acc@1  97.66 ( 98.70)	Acc@5 100.00 (100.00)
Epoch: [63][330/391]	Time  0.035 ( 0.035)	Data  0.001 ( 0.001)	Loss 2.6273e-02 (3.9825e-02)	Acc@1  99.22 ( 98.71)	Acc@5 100.00 (100.00)
Epoch: [63][340/391]	Time  0.047 ( 0.035)	Data  0.001 ( 0.001)	Loss 3.4103e-02 (3.9802e-02)	Acc@1  98.44 ( 98.70)	Acc@5 100.00 (100.00)
Epoch: [63][350/391]	Time  0.036 ( 0.035)	Data  0.001 ( 0.001)	Loss 1.0093e-01 (4.0125e-02)	Acc@1  97.66 ( 98.69)	Acc@5 100.00 (100.00)
Epoch: [63][360/391]	Time  0.033 ( 0.035)	Data  0.001 ( 0.001)	Loss 9.7760e-02 (4.0310e-02)	Acc@1  97.66 ( 98.69)	Acc@5 100.00 (100.00)
Epoch: [63][370/391]	Time  0.034 ( 0.035)	Data  0.001 ( 0.001)	Loss 1.8599e-02 (4.0558e-02)	Acc@1 100.00 ( 98.68)	Acc@5 100.00 (100.00)
Epoch: [63][380/391]	Time  0.035 ( 0.035)	Data  0.001 ( 0.001)	Loss 2.5446e-02 (4.0680e-02)	Acc@1  99.22 ( 98.68)	Acc@5 100.00 (100.00)
Epoch: [63][390/391]	Time  0.024 ( 0.035)	Data  0.001 ( 0.001)	Loss 6.4755e-02 (4.0720e-02)	Acc@1  97.50 ( 98.67)	Acc@5 100.00 (100.00)
## e[63] optimizer.zero_grad (sum) time: 0.15558266639709473
## e[63]       loss.backward (sum) time: 3.1189002990722656
## e[63]      optimizer.step (sum) time: 1.0439791679382324
## epoch[63] training(only) time: 13.89093279838562
# Switched to evaluate mode...
Test: [  0/100]	Time  0.174 ( 0.174)	Loss 1.6441e-01 (1.6441e-01)	Acc@1  96.00 ( 96.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.023 ( 0.036)	Loss 5.5022e-01 (3.3123e-01)	Acc@1  89.00 ( 91.82)	Acc@5 100.00 ( 99.82)
Test: [ 20/100]	Time  0.022 ( 0.029)	Loss 3.4551e-01 (3.6863e-01)	Acc@1  90.00 ( 91.43)	Acc@5 100.00 ( 99.62)
Test: [ 30/100]	Time  0.017 ( 0.026)	Loss 4.8937e-01 (4.0099e-01)	Acc@1  89.00 ( 91.23)	Acc@5  97.00 ( 99.48)
Test: [ 40/100]	Time  0.018 ( 0.024)	Loss 3.3626e-01 (4.0764e-01)	Acc@1  91.00 ( 91.07)	Acc@5 100.00 ( 99.54)
Test: [ 50/100]	Time  0.018 ( 0.023)	Loss 1.8471e-01 (4.0124e-01)	Acc@1  94.00 ( 91.22)	Acc@5 100.00 ( 99.57)
Test: [ 60/100]	Time  0.026 ( 0.022)	Loss 4.7810e-01 (3.8975e-01)	Acc@1  93.00 ( 91.26)	Acc@5  99.00 ( 99.59)
Test: [ 70/100]	Time  0.022 ( 0.022)	Loss 4.9973e-01 (3.8073e-01)	Acc@1  89.00 ( 91.27)	Acc@5 100.00 ( 99.62)
Test: [ 80/100]	Time  0.021 ( 0.022)	Loss 1.9119e-01 (3.7572e-01)	Acc@1  94.00 ( 91.23)	Acc@5 100.00 ( 99.64)
Test: [ 90/100]	Time  0.018 ( 0.022)	Loss 2.7703e-01 (3.8139e-01)	Acc@1  95.00 ( 91.19)	Acc@5 100.00 ( 99.67)
 * Acc@1 91.180 Acc@5 99.670
### epoch[63] execution time: 16.186031341552734
EPOCH 64
REMOVING: module.fire5.expand_1x1.0.bias
REMOVING: module.fire5.expand_1x1.1.weight
REMOVING: module.fire5.expand_1x1.1.bias
i:   0, name: module.fire5.expand_3x3.0.weight  changing lr from: 0.001105727875930539   to: 0.001006568141406754
i:   1, name: module.fire5.expand_3x3.0.bias  changing lr from: 0.001181345477776634   to: 0.001033633387362458
i:   2, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.001276271364399350   to: 0.001081129959471121
i:   3, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.001389955783209533   to: 0.001148503378051790
i:   4, name:  module.fire6.squeeze.0.weight  changing lr from: 0.001521855231934426   to: 0.001235204432646363
i:   5, name:    module.fire6.squeeze.0.bias  changing lr from: 0.001671432768689445   to: 0.001340689557128065
i:   6, name:  module.fire6.squeeze.1.weight  changing lr from: 0.001838158293419156   to: 0.001464421173451601
i:   7, name:    module.fire6.squeeze.1.bias  changing lr from: 0.002021508802169957   to: 0.001605868005577559
i:   8, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.002220968615604867   to: 0.001764505365052820
i:   9, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.002436029583119097   to: 0.001939815409677686
i:  10, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.002666191263864675   to: 0.002131287376640438
i:  11, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.002910961085942103   to: 0.002338417791450009
i:  12, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.003169854484968592   to: 0.002560710653948983
i:  13, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.003442395023183891   to: 0.002797677602640335
i:  14, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.003728114490208417   to: 0.003048838058514524
i:  15, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.004026552986522097   to: 0.003313719349516785
i:  16, name:  module.fire7.squeeze.0.weight  changing lr from: 0.004337258990688186   to: 0.003591856816749288
i:  17, name:    module.fire7.squeeze.0.bias  changing lr from: 0.004659789411302255   to: 0.003882793903458298
i:  18, name:  module.fire7.squeeze.1.weight  changing lr from: 0.004993709624604952   to: 0.004186082227813175
i:  19, name:    module.fire7.squeeze.1.bias  changing lr from: 0.005338593498655108   to: 0.004501281640441840
i:  20, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.005694023404921028   to: 0.004827960267646347
i:  21, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.006059590218108024   to: 0.005165694541181936
i:  22, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.006434893305003564   to: 0.005514069215444594
i:  23, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.006819540503084775   to: 0.005872677372873908
i:  24, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.007213148089598242   to: 0.006241120418342272
i:  25, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.007615340741787912   to: 0.006619008063265258
i:  26, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.008025751488914795   to: 0.007005958300134767
i:  27, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.008444021656679894   to: 0.007401597368142742
i:  28, name:  module.fire8.squeeze.0.weight  changing lr from: 0.008869800804632243   to: 0.007805559710531856
i:  29, name:    module.fire8.squeeze.0.bias  changing lr from: 0.009302746657114187   to: 0.008217487924278382
i:  30, name:  module.fire8.squeeze.1.weight  changing lr from: 0.009742525028268133   to: 0.008637032702683418
i:  31, name:    module.fire8.squeeze.1.bias  changing lr from: 0.010188809741602217   to: 0.009063852771419488
i:  32, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.010641282544585594   to: 0.009497614818551901
i:  33, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.011099633018720474   to: 0.009937993419028884
i:  34, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.011563558485512444   to: 0.010384670954107535
i:  35, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.012032763908739374   to: 0.010837337526159424
i:  36, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.012506961793395766   to: 0.011295690869275472
i:  37, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.012985872081669625   to: 0.011759436256067884
i:  38, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.013469222046287567   to: 0.012228286401044508
i:  39, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.013956746181545861   to: 0.012701961360911042
i:  40, name:  module.fire9.squeeze.0.weight  changing lr from: 0.014448186092325628   to: 0.013180188432136409
i:  41, name:    module.fire9.squeeze.0.bias  changing lr from: 0.014943290381373413   to: 0.013662702046097548
i:  42, name:  module.fire9.squeeze.1.weight  changing lr from: 0.015441814535111353   to: 0.014149243662101962
i:  43, name:    module.fire9.squeeze.1.bias  changing lr from: 0.015943520808225302   to: 0.014639561658568917
i:  44, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.016448178107263522   to: 0.015133411222633529
i:  45, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.016955561873464520   to: 0.015630554238422460
i:  46, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.017465453965018418   to: 0.016130759174234476
i:  47, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.017977642538952950   to: 0.016633800968844831
i:  48, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.018491921932822713   to: 0.017139460917139034
i:  49, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.019008092546368444   to: 0.017647526555267991
i:  50, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.019525960723301160   to: 0.018157791545504214
i:  51, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.020045338633355891   to: 0.018670055560967021
i:  52, name:           module.conv10.weight  changing lr from: 0.020566044154749004   to: 0.019184124170373629
i:  53, name:             module.conv10.bias  changing lr from: 0.021087900757163339   to: 0.019699808722961315



# Switched to train mode...
Epoch: [64][  0/391]	Time  0.210 ( 0.210)	Data  0.172 ( 0.172)	Loss 7.0195e-02 (7.0195e-02)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [64][ 10/391]	Time  0.034 ( 0.051)	Data  0.001 ( 0.017)	Loss 4.7772e-02 (3.9764e-02)	Acc@1  97.66 ( 98.65)	Acc@5 100.00 (100.00)
Epoch: [64][ 20/391]	Time  0.033 ( 0.043)	Data  0.001 ( 0.009)	Loss 2.1780e-02 (3.7011e-02)	Acc@1  99.22 ( 98.74)	Acc@5 100.00 (100.00)
Epoch: [64][ 30/391]	Time  0.032 ( 0.040)	Data  0.001 ( 0.006)	Loss 3.1363e-02 (3.4051e-02)	Acc@1  98.44 ( 98.84)	Acc@5 100.00 (100.00)
Epoch: [64][ 40/391]	Time  0.033 ( 0.039)	Data  0.001 ( 0.005)	Loss 2.0128e-02 (3.3091e-02)	Acc@1 100.00 ( 98.93)	Acc@5 100.00 (100.00)
Epoch: [64][ 50/391]	Time  0.035 ( 0.038)	Data  0.001 ( 0.004)	Loss 2.2500e-02 (3.4502e-02)	Acc@1  99.22 ( 98.91)	Acc@5 100.00 (100.00)
Epoch: [64][ 60/391]	Time  0.032 ( 0.037)	Data  0.001 ( 0.004)	Loss 1.3588e-02 (3.4230e-02)	Acc@1 100.00 ( 98.91)	Acc@5 100.00 (100.00)
Epoch: [64][ 70/391]	Time  0.033 ( 0.037)	Data  0.001 ( 0.003)	Loss 4.4859e-02 (3.5999e-02)	Acc@1  97.66 ( 98.82)	Acc@5 100.00 (100.00)
Epoch: [64][ 80/391]	Time  0.033 ( 0.037)	Data  0.001 ( 0.003)	Loss 1.9860e-02 (3.6279e-02)	Acc@1  99.22 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [64][ 90/391]	Time  0.033 ( 0.036)	Data  0.001 ( 0.003)	Loss 3.2800e-02 (3.7169e-02)	Acc@1  99.22 ( 98.82)	Acc@5 100.00 (100.00)
Epoch: [64][100/391]	Time  0.033 ( 0.036)	Data  0.001 ( 0.003)	Loss 6.8136e-02 (3.8624e-02)	Acc@1  97.66 ( 98.77)	Acc@5 100.00 (100.00)
Epoch: [64][110/391]	Time  0.036 ( 0.036)	Data  0.001 ( 0.002)	Loss 1.7911e-02 (3.8417e-02)	Acc@1  99.22 ( 98.78)	Acc@5 100.00 (100.00)
Epoch: [64][120/391]	Time  0.039 ( 0.036)	Data  0.001 ( 0.002)	Loss 1.4071e-02 (3.7454e-02)	Acc@1 100.00 ( 98.79)	Acc@5 100.00 (100.00)
Epoch: [64][130/391]	Time  0.036 ( 0.036)	Data  0.001 ( 0.002)	Loss 1.0661e-01 (3.8073e-02)	Acc@1  96.88 ( 98.77)	Acc@5  99.22 ( 99.99)
Epoch: [64][140/391]	Time  0.033 ( 0.036)	Data  0.001 ( 0.002)	Loss 2.6820e-02 (3.8190e-02)	Acc@1  99.22 ( 98.75)	Acc@5 100.00 ( 99.99)
Epoch: [64][150/391]	Time  0.038 ( 0.036)	Data  0.001 ( 0.002)	Loss 3.9548e-02 (3.8350e-02)	Acc@1  98.44 ( 98.74)	Acc@5 100.00 ( 99.99)
Epoch: [64][160/391]	Time  0.036 ( 0.036)	Data  0.001 ( 0.002)	Loss 5.2877e-02 (3.8005e-02)	Acc@1  97.66 ( 98.75)	Acc@5 100.00 (100.00)
Epoch: [64][170/391]	Time  0.033 ( 0.036)	Data  0.001 ( 0.002)	Loss 2.0306e-02 (3.8223e-02)	Acc@1  99.22 ( 98.74)	Acc@5 100.00 (100.00)
Epoch: [64][180/391]	Time  0.038 ( 0.036)	Data  0.004 ( 0.002)	Loss 6.2828e-02 (3.8127e-02)	Acc@1  96.88 ( 98.74)	Acc@5 100.00 (100.00)
Epoch: [64][190/391]	Time  0.037 ( 0.036)	Data  0.001 ( 0.002)	Loss 3.9302e-02 (3.8801e-02)	Acc@1  98.44 ( 98.73)	Acc@5 100.00 (100.00)
Epoch: [64][200/391]	Time  0.036 ( 0.036)	Data  0.001 ( 0.002)	Loss 4.4380e-02 (3.8602e-02)	Acc@1  99.22 ( 98.72)	Acc@5 100.00 (100.00)
Epoch: [64][210/391]	Time  0.033 ( 0.036)	Data  0.001 ( 0.002)	Loss 2.3286e-02 (3.8526e-02)	Acc@1 100.00 ( 98.73)	Acc@5 100.00 (100.00)
Epoch: [64][220/391]	Time  0.036 ( 0.035)	Data  0.001 ( 0.002)	Loss 4.0557e-02 (3.8401e-02)	Acc@1  98.44 ( 98.72)	Acc@5 100.00 (100.00)
Epoch: [64][230/391]	Time  0.037 ( 0.035)	Data  0.001 ( 0.002)	Loss 4.9505e-02 (3.8336e-02)	Acc@1  99.22 ( 98.73)	Acc@5 100.00 (100.00)
Epoch: [64][240/391]	Time  0.034 ( 0.035)	Data  0.001 ( 0.002)	Loss 6.5486e-02 (3.8319e-02)	Acc@1  97.66 ( 98.74)	Acc@5 100.00 (100.00)
Epoch: [64][250/391]	Time  0.033 ( 0.035)	Data  0.001 ( 0.002)	Loss 3.6578e-02 (3.8709e-02)	Acc@1  98.44 ( 98.72)	Acc@5 100.00 (100.00)
Epoch: [64][260/391]	Time  0.037 ( 0.035)	Data  0.001 ( 0.002)	Loss 5.5010e-02 (3.8553e-02)	Acc@1  98.44 ( 98.73)	Acc@5 100.00 (100.00)
Epoch: [64][270/391]	Time  0.034 ( 0.035)	Data  0.001 ( 0.002)	Loss 1.8374e-02 (3.8620e-02)	Acc@1 100.00 ( 98.73)	Acc@5 100.00 (100.00)
Epoch: [64][280/391]	Time  0.033 ( 0.035)	Data  0.001 ( 0.002)	Loss 6.3167e-02 (3.8789e-02)	Acc@1  97.66 ( 98.71)	Acc@5 100.00 (100.00)
Epoch: [64][290/391]	Time  0.036 ( 0.035)	Data  0.001 ( 0.002)	Loss 5.8809e-02 (3.8766e-02)	Acc@1  97.66 ( 98.71)	Acc@5 100.00 (100.00)
Epoch: [64][300/391]	Time  0.038 ( 0.035)	Data  0.001 ( 0.002)	Loss 5.8350e-02 (3.8992e-02)	Acc@1  96.88 ( 98.70)	Acc@5 100.00 (100.00)
Epoch: [64][310/391]	Time  0.033 ( 0.035)	Data  0.001 ( 0.002)	Loss 5.0787e-02 (3.9114e-02)	Acc@1  97.66 ( 98.70)	Acc@5 100.00 (100.00)
Epoch: [64][320/391]	Time  0.033 ( 0.035)	Data  0.001 ( 0.002)	Loss 2.6769e-02 (3.8825e-02)	Acc@1  98.44 ( 98.71)	Acc@5 100.00 (100.00)
Epoch: [64][330/391]	Time  0.033 ( 0.035)	Data  0.001 ( 0.001)	Loss 5.5136e-02 (3.8898e-02)	Acc@1  97.66 ( 98.70)	Acc@5 100.00 (100.00)
Epoch: [64][340/391]	Time  0.038 ( 0.035)	Data  0.001 ( 0.001)	Loss 5.8849e-02 (3.9032e-02)	Acc@1  98.44 ( 98.70)	Acc@5 100.00 (100.00)
Epoch: [64][350/391]	Time  0.035 ( 0.035)	Data  0.001 ( 0.001)	Loss 2.7752e-02 (3.8624e-02)	Acc@1  99.22 ( 98.72)	Acc@5 100.00 (100.00)
Epoch: [64][360/391]	Time  0.032 ( 0.035)	Data  0.001 ( 0.001)	Loss 7.5240e-03 (3.8447e-02)	Acc@1 100.00 ( 98.73)	Acc@5 100.00 (100.00)
Epoch: [64][370/391]	Time  0.034 ( 0.035)	Data  0.001 ( 0.001)	Loss 2.8917e-02 (3.8285e-02)	Acc@1  99.22 ( 98.73)	Acc@5 100.00 (100.00)
Epoch: [64][380/391]	Time  0.034 ( 0.035)	Data  0.001 ( 0.001)	Loss 1.2250e-02 (3.8204e-02)	Acc@1 100.00 ( 98.73)	Acc@5 100.00 (100.00)
Epoch: [64][390/391]	Time  0.023 ( 0.035)	Data  0.001 ( 0.001)	Loss 1.0643e-01 (3.8054e-02)	Acc@1  95.00 ( 98.73)	Acc@5 100.00 (100.00)
## e[64] optimizer.zero_grad (sum) time: 0.14774298667907715
## e[64]       loss.backward (sum) time: 3.0508174896240234
## e[64]      optimizer.step (sum) time: 0.9869265556335449
## epoch[64] training(only) time: 13.796488523483276
# Switched to evaluate mode...
Test: [  0/100]	Time  0.172 ( 0.172)	Loss 1.9626e-01 (1.9626e-01)	Acc@1  95.00 ( 95.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.024 ( 0.035)	Loss 4.9431e-01 (3.3707e-01)	Acc@1  91.00 ( 91.55)	Acc@5 100.00 (100.00)
Test: [ 20/100]	Time  0.022 ( 0.029)	Loss 3.2441e-01 (3.8000e-01)	Acc@1  87.00 ( 91.00)	Acc@5 100.00 ( 99.76)
Test: [ 30/100]	Time  0.018 ( 0.026)	Loss 5.0327e-01 (4.1845e-01)	Acc@1  89.00 ( 90.71)	Acc@5  96.00 ( 99.48)
Test: [ 40/100]	Time  0.017 ( 0.024)	Loss 3.3924e-01 (4.3026e-01)	Acc@1  89.00 ( 90.37)	Acc@5 100.00 ( 99.51)
Test: [ 50/100]	Time  0.020 ( 0.024)	Loss 1.2343e-01 (4.2486e-01)	Acc@1  96.00 ( 90.59)	Acc@5 100.00 ( 99.55)
Test: [ 60/100]	Time  0.022 ( 0.023)	Loss 4.6647e-01 (4.1115e-01)	Acc@1  94.00 ( 90.75)	Acc@5  99.00 ( 99.59)
Test: [ 70/100]	Time  0.021 ( 0.022)	Loss 4.6336e-01 (4.0061e-01)	Acc@1  90.00 ( 90.85)	Acc@5 100.00 ( 99.63)
Test: [ 80/100]	Time  0.022 ( 0.022)	Loss 2.3153e-01 (3.9281e-01)	Acc@1  95.00 ( 90.95)	Acc@5 100.00 ( 99.65)
Test: [ 90/100]	Time  0.017 ( 0.022)	Loss 2.8910e-01 (3.9911e-01)	Acc@1  94.00 ( 90.80)	Acc@5 100.00 ( 99.68)
 * Acc@1 90.750 Acc@5 99.680
### epoch[64] execution time: 16.095017671585083
EPOCH 65
REMOVING: module.fire5.expand_3x3.0.weight
REMOVING: module.fire5.expand_3x3.0.bias
i:   0, name: module.fire5.expand_3x3.1.weight  changing lr from: 0.001081129959471121   to: 0.001001925963064497
i:   1, name: module.fire5.expand_3x3.1.bias  changing lr from: 0.001148503378051790   to: 0.001021326936322857
i:   2, name:  module.fire6.squeeze.0.weight  changing lr from: 0.001235204432646363   to: 0.001061151228329592
i:   3, name:    module.fire6.squeeze.0.bias  changing lr from: 0.001340689557128065   to: 0.001120851076547718
i:   4, name:  module.fire6.squeeze.1.weight  changing lr from: 0.001464421173451601   to: 0.001199883735401119
i:   5, name:    module.fire6.squeeze.1.bias  changing lr from: 0.001605868005577559   to: 0.001297711853625865
i:   6, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.001764505365052820   to: 0.001413803820648656
i:   7, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.001939815409677686   to: 0.001547634083489379
i:   8, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.002131287376640438   to: 0.001698683435635655
i:   9, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.002338417791450009   to: 0.001866439279288339
i:  10, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.002560710653948983   to: 0.002050395862328623
i:  11, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.002797677602640335   to: 0.002250054491309383
i:  12, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.003048838058514524   to: 0.002464923721726108
i:  13, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.003313719349516785   to: 0.002694519526776356
i:  14, name:  module.fire7.squeeze.0.weight  changing lr from: 0.003591856816749288   to: 0.002938365445770701
i:  15, name:    module.fire7.squeeze.0.bias  changing lr from: 0.003882793903458298   to: 0.003195992713313477
i:  16, name:  module.fire7.squeeze.1.weight  changing lr from: 0.004186082227813175   to: 0.003466940370327359
i:  17, name:    module.fire7.squeeze.1.bias  changing lr from: 0.004501281640441840   to: 0.003750755357952989
i:  18, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.004827960267646347   to: 0.004046992595312947
i:  19, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.005165694541181936   to: 0.004355215042087967
i:  20, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.005514069215444594   to: 0.004674993746813932
i:  21, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.005872677372873908   to: 0.005005907881768806
i:  22, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.006241120418342272   to: 0.005347544765281508
i:  23, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.006619008063265258   to: 0.005699499872257396
i:  24, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.007005958300134767   to: 0.006061376833680287
i:  25, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.007401597368142742   to: 0.006432787425815789
i:  26, name:  module.fire8.squeeze.0.weight  changing lr from: 0.007805559710531856   to: 0.006813351549807977
i:  27, name:    module.fire8.squeeze.0.bias  changing lr from: 0.008217487924278382   to: 0.007202697202328789
i:  28, name:  module.fire8.squeeze.1.weight  changing lr from: 0.008637032702683418   to: 0.007600460437908896
i:  29, name:    module.fire8.squeeze.1.bias  changing lr from: 0.009063852771419488   to: 0.008006285323548183
i:  30, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.009497614818551901   to: 0.008419823886175310
i:  31, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.009937993419028884   to: 0.008840736053498093
i:  32, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.010384670954107535   to: 0.009268689588759000
i:  33, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.010837337526159424   to: 0.009703360019884654
i:  34, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.011295690869275472   to: 0.010144430563492856
i:  35, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.011759436256067884   to: 0.010591592044197334
i:  36, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.012228286401044508   to: 0.011044542809626728
i:  37, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.012701961360911042   to: 0.011502988641552699
i:  38, name:  module.fire9.squeeze.0.weight  changing lr from: 0.013180188432136409   to: 0.011966642663500726
i:  39, name:    module.fire9.squeeze.0.bias  changing lr from: 0.013662702046097548   to: 0.012435225245196808
i:  40, name:  module.fire9.squeeze.1.weight  changing lr from: 0.014149243662101962   to: 0.012908463904183931
i:  41, name:    module.fire9.squeeze.1.bias  changing lr from: 0.014639561658568917   to: 0.013386093204923365
i:  42, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.015133411222633529   to: 0.013867854655678274
i:  43, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.015630554238422460   to: 0.014353496603459769
i:  44, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.016130759174234476   to: 0.014842774127299330
i:  45, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.016633800968844831   to: 0.015335448930096206
i:  46, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.017139460917139034   to: 0.015831289229272995
i:  47, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.017647526555267991   to: 0.016330069646458861
i:  48, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.018157791545504214   to: 0.016831571096406046
i:  49, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.018670055560967021   to: 0.017335580675332508
i:  50, name:           module.conv10.weight  changing lr from: 0.019184124170373629   to: 0.017841891548871208
i:  51, name:             module.conv10.bias  changing lr from: 0.019699808722961315   to: 0.018350302839794726



# Switched to train mode...
Epoch: [65][  0/391]	Time  0.209 ( 0.209)	Data  0.171 ( 0.171)	Loss 6.6798e-02 (6.6798e-02)	Acc@1  97.66 ( 97.66)	Acc@5 100.00 (100.00)
Epoch: [65][ 10/391]	Time  0.035 ( 0.050)	Data  0.001 ( 0.016)	Loss 2.2979e-02 (2.8980e-02)	Acc@1  99.22 ( 98.93)	Acc@5 100.00 (100.00)
Epoch: [65][ 20/391]	Time  0.033 ( 0.043)	Data  0.001 ( 0.009)	Loss 1.8020e-02 (3.6800e-02)	Acc@1 100.00 ( 98.74)	Acc@5 100.00 (100.00)
Epoch: [65][ 30/391]	Time  0.033 ( 0.040)	Data  0.001 ( 0.006)	Loss 4.0639e-02 (3.8078e-02)	Acc@1  98.44 ( 98.66)	Acc@5 100.00 (100.00)
Epoch: [65][ 40/391]	Time  0.037 ( 0.039)	Data  0.001 ( 0.005)	Loss 6.7948e-02 (3.8810e-02)	Acc@1  96.88 ( 98.70)	Acc@5 100.00 (100.00)
Epoch: [65][ 50/391]	Time  0.035 ( 0.038)	Data  0.001 ( 0.004)	Loss 4.7043e-02 (3.7214e-02)	Acc@1  98.44 ( 98.77)	Acc@5 100.00 (100.00)
Epoch: [65][ 60/391]	Time  0.036 ( 0.037)	Data  0.001 ( 0.004)	Loss 2.9041e-02 (3.7878e-02)	Acc@1  99.22 ( 98.74)	Acc@5 100.00 (100.00)
Epoch: [65][ 70/391]	Time  0.037 ( 0.037)	Data  0.001 ( 0.003)	Loss 1.8724e-02 (3.7581e-02)	Acc@1  99.22 ( 98.76)	Acc@5 100.00 (100.00)
Epoch: [65][ 80/391]	Time  0.033 ( 0.037)	Data  0.001 ( 0.003)	Loss 2.2278e-02 (3.7598e-02)	Acc@1  99.22 ( 98.75)	Acc@5 100.00 (100.00)
Epoch: [65][ 90/391]	Time  0.037 ( 0.036)	Data  0.001 ( 0.003)	Loss 8.9003e-03 (3.7023e-02)	Acc@1 100.00 ( 98.77)	Acc@5 100.00 (100.00)
Epoch: [65][100/391]	Time  0.032 ( 0.036)	Data  0.001 ( 0.003)	Loss 4.9437e-02 (3.6534e-02)	Acc@1  97.66 ( 98.76)	Acc@5 100.00 (100.00)
Epoch: [65][110/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.002)	Loss 1.0290e-02 (3.6079e-02)	Acc@1 100.00 ( 98.75)	Acc@5 100.00 (100.00)
Epoch: [65][120/391]	Time  0.033 ( 0.036)	Data  0.001 ( 0.002)	Loss 2.3613e-02 (3.5921e-02)	Acc@1  98.44 ( 98.73)	Acc@5 100.00 (100.00)
Epoch: [65][130/391]	Time  0.035 ( 0.036)	Data  0.001 ( 0.002)	Loss 3.1684e-02 (3.5541e-02)	Acc@1  99.22 ( 98.76)	Acc@5 100.00 (100.00)
Epoch: [65][140/391]	Time  0.036 ( 0.036)	Data  0.001 ( 0.002)	Loss 1.2480e-02 (3.4751e-02)	Acc@1 100.00 ( 98.81)	Acc@5 100.00 (100.00)
Epoch: [65][150/391]	Time  0.033 ( 0.036)	Data  0.001 ( 0.002)	Loss 4.4261e-02 (3.5122e-02)	Acc@1  97.66 ( 98.80)	Acc@5 100.00 (100.00)
Epoch: [65][160/391]	Time  0.036 ( 0.036)	Data  0.001 ( 0.002)	Loss 6.8338e-02 (3.5939e-02)	Acc@1  98.44 ( 98.77)	Acc@5 100.00 (100.00)
Epoch: [65][170/391]	Time  0.035 ( 0.036)	Data  0.001 ( 0.002)	Loss 6.8724e-02 (3.6298e-02)	Acc@1  98.44 ( 98.75)	Acc@5 100.00 (100.00)
Epoch: [65][180/391]	Time  0.036 ( 0.035)	Data  0.001 ( 0.002)	Loss 6.8957e-02 (3.6229e-02)	Acc@1  97.66 ( 98.75)	Acc@5 100.00 (100.00)
Epoch: [65][190/391]	Time  0.034 ( 0.035)	Data  0.001 ( 0.002)	Loss 3.1240e-02 (3.5755e-02)	Acc@1  98.44 ( 98.76)	Acc@5 100.00 (100.00)
Epoch: [65][200/391]	Time  0.035 ( 0.035)	Data  0.001 ( 0.002)	Loss 2.6537e-02 (3.5666e-02)	Acc@1  99.22 ( 98.79)	Acc@5 100.00 (100.00)
Epoch: [65][210/391]	Time  0.033 ( 0.035)	Data  0.001 ( 0.002)	Loss 3.5457e-02 (3.5995e-02)	Acc@1  99.22 ( 98.78)	Acc@5 100.00 (100.00)
Epoch: [65][220/391]	Time  0.033 ( 0.035)	Data  0.001 ( 0.002)	Loss 2.7388e-02 (3.6028e-02)	Acc@1  99.22 ( 98.78)	Acc@5 100.00 (100.00)
Epoch: [65][230/391]	Time  0.036 ( 0.035)	Data  0.001 ( 0.002)	Loss 2.7229e-02 (3.5612e-02)	Acc@1  98.44 ( 98.79)	Acc@5 100.00 (100.00)
Epoch: [65][240/391]	Time  0.033 ( 0.035)	Data  0.001 ( 0.002)	Loss 2.0947e-02 (3.6018e-02)	Acc@1 100.00 ( 98.78)	Acc@5 100.00 (100.00)
Epoch: [65][250/391]	Time  0.033 ( 0.035)	Data  0.001 ( 0.002)	Loss 2.1363e-02 (3.6015e-02)	Acc@1  99.22 ( 98.77)	Acc@5 100.00 (100.00)
Epoch: [65][260/391]	Time  0.034 ( 0.035)	Data  0.001 ( 0.002)	Loss 4.0603e-02 (3.6811e-02)	Acc@1  99.22 ( 98.74)	Acc@5 100.00 (100.00)
Epoch: [65][270/391]	Time  0.037 ( 0.035)	Data  0.001 ( 0.002)	Loss 2.4941e-02 (3.6891e-02)	Acc@1 100.00 ( 98.74)	Acc@5 100.00 (100.00)
Epoch: [65][280/391]	Time  0.032 ( 0.035)	Data  0.001 ( 0.002)	Loss 4.7842e-02 (3.7064e-02)	Acc@1  98.44 ( 98.73)	Acc@5 100.00 (100.00)
Epoch: [65][290/391]	Time  0.035 ( 0.035)	Data  0.001 ( 0.002)	Loss 1.1590e-02 (3.6634e-02)	Acc@1 100.00 ( 98.75)	Acc@5 100.00 (100.00)
Epoch: [65][300/391]	Time  0.033 ( 0.035)	Data  0.001 ( 0.002)	Loss 6.0605e-02 (3.6717e-02)	Acc@1  97.66 ( 98.75)	Acc@5 100.00 (100.00)
Epoch: [65][310/391]	Time  0.038 ( 0.035)	Data  0.001 ( 0.001)	Loss 7.3133e-02 (3.6829e-02)	Acc@1  98.44 ( 98.75)	Acc@5 100.00 (100.00)
Epoch: [65][320/391]	Time  0.036 ( 0.035)	Data  0.001 ( 0.001)	Loss 1.8370e-02 (3.6455e-02)	Acc@1 100.00 ( 98.77)	Acc@5 100.00 (100.00)
Epoch: [65][330/391]	Time  0.032 ( 0.035)	Data  0.001 ( 0.001)	Loss 4.3912e-02 (3.6711e-02)	Acc@1  98.44 ( 98.76)	Acc@5 100.00 (100.00)
Epoch: [65][340/391]	Time  0.033 ( 0.035)	Data  0.001 ( 0.001)	Loss 2.2995e-02 (3.6754e-02)	Acc@1 100.00 ( 98.75)	Acc@5 100.00 (100.00)
Epoch: [65][350/391]	Time  0.034 ( 0.035)	Data  0.001 ( 0.001)	Loss 8.5742e-02 (3.6917e-02)	Acc@1  96.88 ( 98.74)	Acc@5 100.00 (100.00)
Epoch: [65][360/391]	Time  0.035 ( 0.035)	Data  0.001 ( 0.001)	Loss 3.5684e-02 (3.6968e-02)	Acc@1  99.22 ( 98.75)	Acc@5 100.00 (100.00)
Epoch: [65][370/391]	Time  0.034 ( 0.035)	Data  0.001 ( 0.001)	Loss 3.6520e-02 (3.6969e-02)	Acc@1  98.44 ( 98.74)	Acc@5 100.00 (100.00)
Epoch: [65][380/391]	Time  0.036 ( 0.035)	Data  0.001 ( 0.001)	Loss 4.5596e-02 (3.6937e-02)	Acc@1  99.22 ( 98.74)	Acc@5 100.00 (100.00)
Epoch: [65][390/391]	Time  0.023 ( 0.035)	Data  0.001 ( 0.001)	Loss 5.1832e-02 (3.6981e-02)	Acc@1  96.25 ( 98.75)	Acc@5 100.00 (100.00)
## e[65] optimizer.zero_grad (sum) time: 0.14291954040527344
## e[65]       loss.backward (sum) time: 3.0113813877105713
## e[65]      optimizer.step (sum) time: 0.9768033027648926
## epoch[65] training(only) time: 13.732628107070923
# Switched to evaluate mode...
Test: [  0/100]	Time  0.168 ( 0.168)	Loss 1.6875e-01 (1.6875e-01)	Acc@1  94.00 ( 94.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.024 ( 0.034)	Loss 4.6500e-01 (3.4075e-01)	Acc@1  89.00 ( 91.91)	Acc@5 100.00 ( 99.82)
Test: [ 20/100]	Time  0.023 ( 0.029)	Loss 3.6372e-01 (3.8596e-01)	Acc@1  89.00 ( 91.14)	Acc@5 100.00 ( 99.62)
Test: [ 30/100]	Time  0.016 ( 0.026)	Loss 5.2265e-01 (4.2054e-01)	Acc@1  90.00 ( 90.81)	Acc@5  97.00 ( 99.48)
Test: [ 40/100]	Time  0.021 ( 0.025)	Loss 3.7132e-01 (4.2751e-01)	Acc@1  88.00 ( 90.63)	Acc@5 100.00 ( 99.51)
Test: [ 50/100]	Time  0.017 ( 0.023)	Loss 1.1252e-01 (4.1852e-01)	Acc@1  95.00 ( 90.82)	Acc@5 100.00 ( 99.55)
Test: [ 60/100]	Time  0.017 ( 0.023)	Loss 4.4063e-01 (4.0531e-01)	Acc@1  92.00 ( 90.84)	Acc@5 100.00 ( 99.61)
Test: [ 70/100]	Time  0.022 ( 0.022)	Loss 4.8638e-01 (3.9403e-01)	Acc@1  90.00 ( 91.04)	Acc@5 100.00 ( 99.63)
Test: [ 80/100]	Time  0.024 ( 0.022)	Loss 1.9846e-01 (3.8773e-01)	Acc@1  96.00 ( 91.17)	Acc@5 100.00 ( 99.67)
Test: [ 90/100]	Time  0.020 ( 0.022)	Loss 2.8649e-01 (3.9432e-01)	Acc@1  95.00 ( 91.07)	Acc@5 100.00 ( 99.70)
 * Acc@1 91.040 Acc@5 99.710
### epoch[65] execution time: 15.998463869094849
EPOCH 66
REMOVING: module.fire5.expand_3x3.1.weight
REMOVING: module.fire5.expand_3x3.1.bias
i:   0, name:  module.fire6.squeeze.0.weight  changing lr from: 0.001061151228329592   to: 0.001000089430954608
i:   1, name:    module.fire6.squeeze.0.bias  changing lr from: 0.001120851076547718   to: 0.001012408294852112
i:   2, name:  module.fire6.squeeze.1.weight  changing lr from: 0.001199883735401119   to: 0.001045129144030775
i:   3, name:    module.fire6.squeeze.1.bias  changing lr from: 0.001297711853625865   to: 0.001097710912901394
i:   4, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.001413803820648656   to: 0.001169617316830456
i:   5, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.001547634083489379   to: 0.001260317230858542
i:   6, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.001698683435635655   to: 0.001369285037857564
i:   7, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.001866439279288339   to: 0.001496000947588138
i:   8, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.002050395862328623   to: 0.001639951288071267
i:   9, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.002250054491309383   to: 0.001800628770641443
i:  10, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.002464923721726108   to: 0.001977532730001601
i:  11, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.002694519526776356   to: 0.002170169340554178
i:  12, name:  module.fire7.squeeze.0.weight  changing lr from: 0.002938365445770701   to: 0.002378051810237041
i:  13, name:    module.fire7.squeeze.0.bias  changing lr from: 0.003195992713313477   to: 0.002600700553047746
i:  14, name:  module.fire7.squeeze.1.weight  changing lr from: 0.003466940370327359   to: 0.002837643341395767
i:  15, name:    module.fire7.squeeze.1.bias  changing lr from: 0.003750755357952989   to: 0.003088415439378416
i:  16, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.004046992595312947   to: 0.003352559718034181
i:  17, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.004355215042087967   to: 0.003629626753584846
i:  18, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.004674993746813932   to: 0.003919174909637739
i:  19, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.005005907881768806   to: 0.004220770404278883
i:  20, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.005347544765281508   to: 0.004533987362950075
i:  21, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.005699499872257396   to: 0.004858407857964086
i:  22, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.006061376833680287   to: 0.005193621935476489
i:  23, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.006432787425815789   to: 0.005539227630696308
i:  24, name:  module.fire8.squeeze.0.weight  changing lr from: 0.006813351549807977   to: 0.005894830972083497
i:  25, name:    module.fire8.squeeze.0.bias  changing lr from: 0.007202697202328789   to: 0.006260045975247352
i:  26, name:  module.fire8.squeeze.1.weight  changing lr from: 0.007600460437908896   to: 0.006634494627228127
i:  27, name:    module.fire8.squeeze.1.bias  changing lr from: 0.008006285323548183   to: 0.007017806861812103
i:  28, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.008419823886175310   to: 0.007409620526500132
i:  29, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.008840736053498093   to: 0.007809581341720872
i:  30, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.009268689588759000   to: 0.008217342852850799
i:  31, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.009703360019884654   to: 0.008632566375576477
i:  32, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.010144430563492856   to: 0.009054920935107763
i:  33, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.010591592044197334   to: 0.009484083199725882
i:  34, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.011044542809626728   to: 0.009919737409125207
i:  35, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.011502988641552699   to: 0.010361575297984593
i:  36, name:  module.fire9.squeeze.0.weight  changing lr from: 0.011966642663500726   to: 0.010809296015181769
i:  37, name:    module.fire9.squeeze.0.bias  changing lr from: 0.012435225245196808   to: 0.011262606039041889
i:  38, name:  module.fire9.squeeze.1.weight  changing lr from: 0.012908463904183931   to: 0.011721219088991496
i:  39, name:    module.fire9.squeeze.1.bias  changing lr from: 0.013386093204923365   to: 0.012184856033968544
i:  40, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.013867854655678274   to: 0.012653244797920311
i:  41, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.014353496603459769   to: 0.013126120262702705
i:  42, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.014842774127299330   to: 0.013603224168677003
i:  43, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.015335448930096206   to: 0.014084305013282943
i:  44, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.015831289229272995   to: 0.014569117947851672
i:  45, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.016330069646458861   to: 0.015057424672906106
i:  46, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.016831571096406046   to: 0.015548993332181738
i:  47, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.017335580675332508   to: 0.016043598405587507
i:  48, name:           module.conv10.weight  changing lr from: 0.017841891548871208   to: 0.016541020601311913
i:  49, name:             module.conv10.bias  changing lr from: 0.018350302839794726   to: 0.017041046747267870



# Switched to train mode...
Epoch: [66][  0/391]	Time  0.202 ( 0.202)	Data  0.165 ( 0.165)	Loss 6.5561e-03 (6.5561e-03)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [66][ 10/391]	Time  0.037 ( 0.050)	Data  0.001 ( 0.016)	Loss 2.9651e-02 (2.4055e-02)	Acc@1  98.44 ( 99.43)	Acc@5 100.00 (100.00)
Epoch: [66][ 20/391]	Time  0.034 ( 0.042)	Data  0.001 ( 0.009)	Loss 5.4944e-02 (2.7431e-02)	Acc@1  98.44 ( 99.26)	Acc@5 100.00 (100.00)
Epoch: [66][ 30/391]	Time  0.032 ( 0.040)	Data  0.001 ( 0.006)	Loss 4.4837e-02 (2.8420e-02)	Acc@1  98.44 ( 99.24)	Acc@5 100.00 (100.00)
Epoch: [66][ 40/391]	Time  0.033 ( 0.038)	Data  0.001 ( 0.005)	Loss 6.2794e-02 (3.0874e-02)	Acc@1  97.66 ( 99.12)	Acc@5 100.00 (100.00)
Epoch: [66][ 50/391]	Time  0.035 ( 0.037)	Data  0.001 ( 0.004)	Loss 6.2160e-02 (3.2673e-02)	Acc@1  99.22 ( 99.10)	Acc@5 100.00 (100.00)
Epoch: [66][ 60/391]	Time  0.035 ( 0.037)	Data  0.001 ( 0.004)	Loss 1.4002e-02 (3.2349e-02)	Acc@1  99.22 ( 99.12)	Acc@5 100.00 (100.00)
Epoch: [66][ 70/391]	Time  0.035 ( 0.036)	Data  0.001 ( 0.003)	Loss 2.4289e-02 (3.3250e-02)	Acc@1 100.00 ( 99.11)	Acc@5 100.00 (100.00)
Epoch: [66][ 80/391]	Time  0.033 ( 0.036)	Data  0.002 ( 0.003)	Loss 1.9625e-02 (3.3475e-02)	Acc@1 100.00 ( 99.10)	Acc@5 100.00 (100.00)
Epoch: [66][ 90/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.003)	Loss 7.2412e-02 (3.3867e-02)	Acc@1  98.44 ( 99.10)	Acc@5 100.00 (100.00)
Epoch: [66][100/391]	Time  0.035 ( 0.036)	Data  0.001 ( 0.003)	Loss 5.2907e-02 (3.4612e-02)	Acc@1  99.22 ( 99.07)	Acc@5 100.00 (100.00)
Epoch: [66][110/391]	Time  0.034 ( 0.035)	Data  0.001 ( 0.002)	Loss 1.1186e-02 (3.4773e-02)	Acc@1 100.00 ( 99.08)	Acc@5 100.00 (100.00)
Epoch: [66][120/391]	Time  0.032 ( 0.035)	Data  0.001 ( 0.002)	Loss 9.4504e-02 (3.5923e-02)	Acc@1  96.88 ( 99.02)	Acc@5 100.00 (100.00)
Epoch: [66][130/391]	Time  0.037 ( 0.035)	Data  0.001 ( 0.002)	Loss 6.2679e-02 (3.6359e-02)	Acc@1  97.66 ( 98.97)	Acc@5 100.00 (100.00)
Epoch: [66][140/391]	Time  0.032 ( 0.035)	Data  0.001 ( 0.002)	Loss 5.2604e-02 (3.6080e-02)	Acc@1  97.66 ( 98.97)	Acc@5 100.00 (100.00)
Epoch: [66][150/391]	Time  0.032 ( 0.035)	Data  0.001 ( 0.002)	Loss 2.7508e-02 (3.6356e-02)	Acc@1  98.44 ( 98.93)	Acc@5 100.00 (100.00)
Epoch: [66][160/391]	Time  0.035 ( 0.035)	Data  0.001 ( 0.002)	Loss 3.1449e-02 (3.5861e-02)	Acc@1  99.22 ( 98.93)	Acc@5 100.00 (100.00)
Epoch: [66][170/391]	Time  0.034 ( 0.035)	Data  0.001 ( 0.002)	Loss 3.6969e-02 (3.5878e-02)	Acc@1  99.22 ( 98.92)	Acc@5 100.00 (100.00)
Epoch: [66][180/391]	Time  0.035 ( 0.035)	Data  0.001 ( 0.002)	Loss 8.2904e-03 (3.6235e-02)	Acc@1 100.00 ( 98.91)	Acc@5 100.00 (100.00)
Epoch: [66][190/391]	Time  0.032 ( 0.035)	Data  0.001 ( 0.002)	Loss 2.0177e-02 (3.5930e-02)	Acc@1 100.00 ( 98.92)	Acc@5 100.00 (100.00)
Epoch: [66][200/391]	Time  0.033 ( 0.035)	Data  0.001 ( 0.002)	Loss 1.8278e-02 (3.6074e-02)	Acc@1 100.00 ( 98.91)	Acc@5 100.00 (100.00)
Epoch: [66][210/391]	Time  0.035 ( 0.035)	Data  0.001 ( 0.002)	Loss 5.0056e-02 (3.6095e-02)	Acc@1  97.66 ( 98.90)	Acc@5 100.00 (100.00)
Epoch: [66][220/391]	Time  0.036 ( 0.035)	Data  0.001 ( 0.002)	Loss 1.9594e-02 (3.6154e-02)	Acc@1  99.22 ( 98.89)	Acc@5 100.00 (100.00)
Epoch: [66][230/391]	Time  0.034 ( 0.035)	Data  0.001 ( 0.002)	Loss 5.6713e-02 (3.6410e-02)	Acc@1  98.44 ( 98.88)	Acc@5 100.00 (100.00)
Epoch: [66][240/391]	Time  0.034 ( 0.035)	Data  0.001 ( 0.002)	Loss 4.9119e-02 (3.6086e-02)	Acc@1  99.22 ( 98.90)	Acc@5 100.00 (100.00)
Epoch: [66][250/391]	Time  0.036 ( 0.035)	Data  0.001 ( 0.002)	Loss 4.0793e-02 (3.5875e-02)	Acc@1  98.44 ( 98.90)	Acc@5 100.00 (100.00)
Epoch: [66][260/391]	Time  0.032 ( 0.035)	Data  0.001 ( 0.002)	Loss 2.4454e-02 (3.5632e-02)	Acc@1  99.22 ( 98.92)	Acc@5 100.00 (100.00)
Epoch: [66][270/391]	Time  0.033 ( 0.035)	Data  0.001 ( 0.002)	Loss 4.2216e-02 (3.5710e-02)	Acc@1  99.22 ( 98.91)	Acc@5 100.00 (100.00)
Epoch: [66][280/391]	Time  0.036 ( 0.035)	Data  0.001 ( 0.002)	Loss 4.2815e-02 (3.5917e-02)	Acc@1  99.22 ( 98.89)	Acc@5 100.00 (100.00)
Epoch: [66][290/391]	Time  0.036 ( 0.035)	Data  0.001 ( 0.001)	Loss 2.1119e-02 (3.5871e-02)	Acc@1  99.22 ( 98.89)	Acc@5 100.00 (100.00)
Epoch: [66][300/391]	Time  0.035 ( 0.035)	Data  0.001 ( 0.001)	Loss 5.9008e-02 (3.5877e-02)	Acc@1  98.44 ( 98.89)	Acc@5 100.00 (100.00)
Epoch: [66][310/391]	Time  0.037 ( 0.035)	Data  0.001 ( 0.001)	Loss 2.1000e-02 (3.5748e-02)	Acc@1  99.22 ( 98.90)	Acc@5 100.00 (100.00)
Epoch: [66][320/391]	Time  0.032 ( 0.035)	Data  0.001 ( 0.001)	Loss 1.4465e-02 (3.5658e-02)	Acc@1  99.22 ( 98.89)	Acc@5 100.00 (100.00)
Epoch: [66][330/391]	Time  0.034 ( 0.035)	Data  0.001 ( 0.001)	Loss 5.6916e-02 (3.5563e-02)	Acc@1  97.66 ( 98.89)	Acc@5 100.00 (100.00)
Epoch: [66][340/391]	Time  0.036 ( 0.035)	Data  0.001 ( 0.001)	Loss 1.7292e-02 (3.5558e-02)	Acc@1  99.22 ( 98.88)	Acc@5 100.00 (100.00)
Epoch: [66][350/391]	Time  0.032 ( 0.035)	Data  0.001 ( 0.001)	Loss 2.3409e-02 (3.5372e-02)	Acc@1 100.00 ( 98.89)	Acc@5 100.00 (100.00)
Epoch: [66][360/391]	Time  0.039 ( 0.035)	Data  0.001 ( 0.001)	Loss 1.3384e-02 (3.5158e-02)	Acc@1 100.00 ( 98.90)	Acc@5 100.00 (100.00)
Epoch: [66][370/391]	Time  0.032 ( 0.035)	Data  0.001 ( 0.001)	Loss 9.6832e-02 (3.5356e-02)	Acc@1  96.09 ( 98.89)	Acc@5 100.00 (100.00)
Epoch: [66][380/391]	Time  0.033 ( 0.034)	Data  0.001 ( 0.001)	Loss 1.9622e-02 (3.5293e-02)	Acc@1 100.00 ( 98.88)	Acc@5 100.00 (100.00)
Epoch: [66][390/391]	Time  0.025 ( 0.034)	Data  0.001 ( 0.001)	Loss 4.4613e-02 (3.5172e-02)	Acc@1  97.50 ( 98.89)	Acc@5 100.00 (100.00)
## e[66] optimizer.zero_grad (sum) time: 0.13846230506896973
## e[66]       loss.backward (sum) time: 2.99446702003479
## e[66]      optimizer.step (sum) time: 0.94195556640625
## epoch[66] training(only) time: 13.565726280212402
# Switched to evaluate mode...
Test: [  0/100]	Time  0.174 ( 0.174)	Loss 1.1759e-01 (1.1759e-01)	Acc@1  98.00 ( 98.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.021 ( 0.035)	Loss 4.1465e-01 (3.1565e-01)	Acc@1  90.00 ( 91.91)	Acc@5 100.00 (100.00)
Test: [ 20/100]	Time  0.017 ( 0.028)	Loss 3.4065e-01 (3.6382e-01)	Acc@1  90.00 ( 91.19)	Acc@5 100.00 ( 99.76)
Test: [ 30/100]	Time  0.022 ( 0.026)	Loss 5.3662e-01 (3.9765e-01)	Acc@1  89.00 ( 90.87)	Acc@5  98.00 ( 99.65)
Test: [ 40/100]	Time  0.021 ( 0.024)	Loss 3.8562e-01 (4.0824e-01)	Acc@1  88.00 ( 90.83)	Acc@5 100.00 ( 99.61)
Test: [ 50/100]	Time  0.020 ( 0.024)	Loss 1.2911e-01 (3.9860e-01)	Acc@1  96.00 ( 91.06)	Acc@5 100.00 ( 99.65)
Test: [ 60/100]	Time  0.023 ( 0.023)	Loss 3.8842e-01 (3.8521e-01)	Acc@1  93.00 ( 91.10)	Acc@5 100.00 ( 99.69)
Test: [ 70/100]	Time  0.023 ( 0.023)	Loss 4.8200e-01 (3.7450e-01)	Acc@1  88.00 ( 91.20)	Acc@5 100.00 ( 99.69)
Test: [ 80/100]	Time  0.021 ( 0.023)	Loss 2.1386e-01 (3.6754e-01)	Acc@1  95.00 ( 91.33)	Acc@5 100.00 ( 99.70)
Test: [ 90/100]	Time  0.018 ( 0.022)	Loss 2.3969e-01 (3.7619e-01)	Acc@1  96.00 ( 91.24)	Acc@5 100.00 ( 99.70)
 * Acc@1 91.200 Acc@5 99.700
### epoch[66] execution time: 15.858286142349243
EPOCH 67
REMOVING: module.fire6.squeeze.0.weight
REMOVING: module.fire6.squeeze.0.bias
REMOVING: module.fire6.squeeze.1.weight
i:   0, name:    module.fire6.squeeze.1.bias  changing lr from: 0.001097710912901394   to: 0.001006300397652775
i:   1, name: module.fire6.expand_1x1.0.weight  changing lr from: 0.001169617316830456   to: 0.001032470385370559
i:   2, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.001260317230858542   to: 0.001078474111421939
i:   3, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.001369285037857564   to: 0.001143781733666065
i:   4, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.001496000947588138   to: 0.001227868349964883
i:   5, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.001639951288071267   to: 0.001330214347322949
i:   6, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.001800628770641443   to: 0.001450305722326721
i:   7, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.001977532730001601   to: 0.001587634374263829
i:   8, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.002170169340554178   to: 0.001741698372257676
i:   9, name:  module.fire7.squeeze.0.weight  changing lr from: 0.002378051810237041   to: 0.001912002197707645
i:  10, name:    module.fire7.squeeze.0.bias  changing lr from: 0.002600700553047746   to: 0.002098056963280664
i:  11, name:  module.fire7.squeeze.1.weight  changing lr from: 0.002837643341395767   to: 0.002299380609655914
i:  12, name:    module.fire7.squeeze.1.bias  changing lr from: 0.003088415439378416   to: 0.002515498081180883
i:  13, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.003352559718034181   to: 0.002745941481554459
i:  14, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.003629626753584846   to: 0.002990250210610356
i:  15, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.003919174909637739   to: 0.003247971083233430
i:  16, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.004220770404278883   to: 0.003518658431400523
i:  17, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.004533987362950075   to: 0.003801874190298492
i:  18, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.004858407857964086   to: 0.004097187969433141
i:  19, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.005193621935476489   to: 0.004404177109605488
i:  20, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.005539227630696308   to: 0.004722426726594813
i:  21, name:  module.fire8.squeeze.0.weight  changing lr from: 0.005894830972083497   to: 0.005051529742352678
i:  22, name:    module.fire8.squeeze.0.bias  changing lr from: 0.006260045975247352   to: 0.005391086904477016
i:  23, name:  module.fire8.squeeze.1.weight  changing lr from: 0.006634494627228127   to: 0.005740706794702343
i:  24, name:    module.fire8.squeeze.1.bias  changing lr from: 0.007017806861812103   to: 0.006100005827108983
i:  25, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.007409620526500132   to: 0.006468608236722655
i:  26, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.007809581341720872   to: 0.006846146059145857
i:  27, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.008217342852850799   to: 0.007232259101831650
i:  28, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.008632566375576477   to: 0.007626594907583211
i:  29, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.009054920935107763   to: 0.008028808710833640
i:  30, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.009484083199725882   to: 0.008438563387235004
i:  31, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.009919737409125207   to: 0.008855529397058887
i:  32, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.010361575297984593   to: 0.009279384722886714
i:  33, name:  module.fire9.squeeze.0.weight  changing lr from: 0.010809296015181769   to: 0.009709814802043925
i:  34, name:    module.fire9.squeeze.0.bias  changing lr from: 0.011262606039041889   to: 0.010146512454209142
i:  35, name:  module.fire9.squeeze.1.weight  changing lr from: 0.011721219088991496   to: 0.010589177804607431
i:  36, name:    module.fire9.squeeze.1.bias  changing lr from: 0.012184856033968544   to: 0.011037518203175788
i:  37, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.012653244797920311   to: 0.011491248140068366
i:  38, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.013126120262702705   to: 0.011950089157849286
i:  39, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.013603224168677003   to: 0.012413769760702915
i:  40, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.014084305013282943   to: 0.012882025320972205
i:  41, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.014569117947851672   to: 0.013354597983320071
i:  42, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.015057424672906106   to: 0.013831236566790944
i:  43, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.015548993332181738   to: 0.014311696465034395
i:  44, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.016043598405587507   to: 0.014795739544938225
i:  45, name:           module.conv10.weight  changing lr from: 0.016541020601311913   to: 0.015283134043902698
i:  46, name:             module.conv10.bias  changing lr from: 0.017041046747267870   to: 0.015773654465975163



# Switched to train mode...
Epoch: [67][  0/391]	Time  0.207 ( 0.207)	Data  0.171 ( 0.171)	Loss 6.1210e-02 (6.1210e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [67][ 10/391]	Time  0.032 ( 0.050)	Data  0.001 ( 0.016)	Loss 1.2638e-02 (3.1465e-02)	Acc@1  99.22 ( 99.15)	Acc@5 100.00 (100.00)
Epoch: [67][ 20/391]	Time  0.035 ( 0.043)	Data  0.001 ( 0.009)	Loss 6.2318e-02 (3.2473e-02)	Acc@1  96.88 ( 98.96)	Acc@5 100.00 (100.00)
Epoch: [67][ 30/391]	Time  0.036 ( 0.040)	Data  0.001 ( 0.006)	Loss 3.5729e-02 (3.2680e-02)	Acc@1  99.22 ( 98.89)	Acc@5 100.00 (100.00)
Epoch: [67][ 40/391]	Time  0.032 ( 0.039)	Data  0.001 ( 0.005)	Loss 3.6713e-02 (3.4423e-02)	Acc@1  98.44 ( 98.78)	Acc@5 100.00 (100.00)
Epoch: [67][ 50/391]	Time  0.034 ( 0.037)	Data  0.001 ( 0.004)	Loss 1.8725e-02 (3.4068e-02)	Acc@1  99.22 ( 98.77)	Acc@5 100.00 (100.00)
Epoch: [67][ 60/391]	Time  0.032 ( 0.037)	Data  0.001 ( 0.004)	Loss 1.8203e-02 (3.3635e-02)	Acc@1 100.00 ( 98.82)	Acc@5 100.00 (100.00)
Epoch: [67][ 70/391]	Time  0.034 ( 0.036)	Data  0.001 ( 0.003)	Loss 1.6711e-02 (3.5139e-02)	Acc@1 100.00 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [67][ 80/391]	Time  0.033 ( 0.036)	Data  0.001 ( 0.003)	Loss 4.4493e-02 (3.5100e-02)	Acc@1  97.66 ( 98.81)	Acc@5 100.00 (100.00)
Epoch: [67][ 90/391]	Time  0.035 ( 0.036)	Data  0.001 ( 0.003)	Loss 2.6580e-02 (3.4241e-02)	Acc@1  99.22 ( 98.82)	Acc@5 100.00 (100.00)
Epoch: [67][100/391]	Time  0.032 ( 0.036)	Data  0.001 ( 0.003)	Loss 4.9440e-03 (3.3969e-02)	Acc@1 100.00 ( 98.85)	Acc@5 100.00 (100.00)
Epoch: [67][110/391]	Time  0.035 ( 0.035)	Data  0.001 ( 0.003)	Loss 1.0944e-02 (3.3689e-02)	Acc@1 100.00 ( 98.87)	Acc@5 100.00 (100.00)
Epoch: [67][120/391]	Time  0.032 ( 0.035)	Data  0.001 ( 0.002)	Loss 2.1849e-02 (3.4163e-02)	Acc@1  99.22 ( 98.88)	Acc@5 100.00 (100.00)
Epoch: [67][130/391]	Time  0.032 ( 0.035)	Data  0.001 ( 0.002)	Loss 8.2559e-02 (3.4930e-02)	Acc@1  97.66 ( 98.84)	Acc@5 100.00 (100.00)
Epoch: [67][140/391]	Time  0.032 ( 0.035)	Data  0.001 ( 0.002)	Loss 1.6901e-02 (3.4380e-02)	Acc@1 100.00 ( 98.88)	Acc@5 100.00 (100.00)
Epoch: [67][150/391]	Time  0.035 ( 0.035)	Data  0.001 ( 0.002)	Loss 4.9906e-02 (3.4233e-02)	Acc@1  98.44 ( 98.91)	Acc@5 100.00 (100.00)
Epoch: [67][160/391]	Time  0.032 ( 0.035)	Data  0.001 ( 0.002)	Loss 2.2573e-02 (3.4253e-02)	Acc@1  99.22 ( 98.90)	Acc@5 100.00 (100.00)
Epoch: [67][170/391]	Time  0.033 ( 0.035)	Data  0.001 ( 0.002)	Loss 1.8902e-02 (3.4084e-02)	Acc@1  98.44 ( 98.89)	Acc@5 100.00 (100.00)
Epoch: [67][180/391]	Time  0.036 ( 0.035)	Data  0.001 ( 0.002)	Loss 1.8613e-02 (3.3538e-02)	Acc@1  99.22 ( 98.91)	Acc@5 100.00 (100.00)
Epoch: [67][190/391]	Time  0.035 ( 0.035)	Data  0.001 ( 0.002)	Loss 5.8297e-02 (3.3696e-02)	Acc@1  97.66 ( 98.90)	Acc@5 100.00 (100.00)
Epoch: [67][200/391]	Time  0.037 ( 0.035)	Data  0.001 ( 0.002)	Loss 8.9184e-02 (3.3944e-02)	Acc@1  96.88 ( 98.90)	Acc@5 100.00 (100.00)
Epoch: [67][210/391]	Time  0.033 ( 0.035)	Data  0.001 ( 0.002)	Loss 2.0304e-02 (3.4294e-02)	Acc@1 100.00 ( 98.87)	Acc@5 100.00 (100.00)
Epoch: [67][220/391]	Time  0.032 ( 0.035)	Data  0.001 ( 0.002)	Loss 2.0411e-02 (3.4317e-02)	Acc@1  99.22 ( 98.87)	Acc@5 100.00 (100.00)
Epoch: [67][230/391]	Time  0.032 ( 0.035)	Data  0.001 ( 0.002)	Loss 1.5737e-02 (3.4289e-02)	Acc@1  99.22 ( 98.87)	Acc@5 100.00 (100.00)
Epoch: [67][240/391]	Time  0.038 ( 0.035)	Data  0.001 ( 0.002)	Loss 4.5811e-02 (3.4265e-02)	Acc@1  98.44 ( 98.86)	Acc@5 100.00 (100.00)
Epoch: [67][250/391]	Time  0.034 ( 0.035)	Data  0.001 ( 0.002)	Loss 1.4466e-02 (3.4649e-02)	Acc@1 100.00 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [67][260/391]	Time  0.033 ( 0.035)	Data  0.001 ( 0.002)	Loss 4.8730e-02 (3.4355e-02)	Acc@1  99.22 ( 98.85)	Acc@5 100.00 (100.00)
Epoch: [67][270/391]	Time  0.033 ( 0.035)	Data  0.001 ( 0.002)	Loss 2.4404e-02 (3.4168e-02)	Acc@1  98.44 ( 98.84)	Acc@5 100.00 (100.00)
Epoch: [67][280/391]	Time  0.035 ( 0.034)	Data  0.001 ( 0.002)	Loss 1.3610e-02 (3.4005e-02)	Acc@1  99.22 ( 98.85)	Acc@5 100.00 (100.00)
Epoch: [67][290/391]	Time  0.032 ( 0.034)	Data  0.001 ( 0.002)	Loss 3.1650e-02 (3.4083e-02)	Acc@1  99.22 ( 98.85)	Acc@5 100.00 (100.00)
Epoch: [67][300/391]	Time  0.038 ( 0.034)	Data  0.001 ( 0.002)	Loss 2.6591e-02 (3.3682e-02)	Acc@1  99.22 ( 98.87)	Acc@5 100.00 (100.00)
Epoch: [67][310/391]	Time  0.034 ( 0.034)	Data  0.001 ( 0.002)	Loss 2.5018e-02 (3.3955e-02)	Acc@1 100.00 ( 98.85)	Acc@5 100.00 (100.00)
Epoch: [67][320/391]	Time  0.033 ( 0.034)	Data  0.001 ( 0.002)	Loss 1.3217e-02 (3.3867e-02)	Acc@1 100.00 ( 98.86)	Acc@5 100.00 (100.00)
Epoch: [67][330/391]	Time  0.034 ( 0.034)	Data  0.001 ( 0.002)	Loss 2.0633e-02 (3.3763e-02)	Acc@1 100.00 ( 98.86)	Acc@5 100.00 (100.00)
Epoch: [67][340/391]	Time  0.033 ( 0.034)	Data  0.001 ( 0.002)	Loss 4.2358e-02 (3.3879e-02)	Acc@1  98.44 ( 98.86)	Acc@5 100.00 (100.00)
Epoch: [67][350/391]	Time  0.030 ( 0.034)	Data  0.002 ( 0.002)	Loss 2.9556e-02 (3.3912e-02)	Acc@1  98.44 ( 98.86)	Acc@5 100.00 (100.00)
Epoch: [67][360/391]	Time  0.036 ( 0.034)	Data  0.001 ( 0.001)	Loss 1.4330e-02 (3.3974e-02)	Acc@1 100.00 ( 98.86)	Acc@5 100.00 (100.00)
Epoch: [67][370/391]	Time  0.035 ( 0.034)	Data  0.001 ( 0.001)	Loss 8.5133e-02 (3.4347e-02)	Acc@1  97.66 ( 98.85)	Acc@5 100.00 (100.00)
Epoch: [67][380/391]	Time  0.035 ( 0.034)	Data  0.001 ( 0.001)	Loss 2.4583e-02 (3.4219e-02)	Acc@1  99.22 ( 98.85)	Acc@5 100.00 (100.00)
Epoch: [67][390/391]	Time  0.023 ( 0.034)	Data  0.001 ( 0.001)	Loss 2.2448e-02 (3.4449e-02)	Acc@1 100.00 ( 98.84)	Acc@5 100.00 (100.00)
## e[67] optimizer.zero_grad (sum) time: 0.13031244277954102
## e[67]       loss.backward (sum) time: 2.930234909057617
## e[67]      optimizer.step (sum) time: 0.9095604419708252
## epoch[67] training(only) time: 13.51874828338623
# Switched to evaluate mode...
Test: [  0/100]	Time  0.172 ( 0.172)	Loss 1.5417e-01 (1.5417e-01)	Acc@1  97.00 ( 97.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.021 ( 0.034)	Loss 4.8559e-01 (3.3408e-01)	Acc@1  90.00 ( 92.09)	Acc@5 100.00 ( 99.91)
Test: [ 20/100]	Time  0.021 ( 0.028)	Loss 3.3588e-01 (3.7057e-01)	Acc@1  89.00 ( 91.57)	Acc@5 100.00 ( 99.62)
Test: [ 30/100]	Time  0.018 ( 0.025)	Loss 5.3331e-01 (4.0616e-01)	Acc@1  90.00 ( 91.29)	Acc@5  98.00 ( 99.58)
Test: [ 40/100]	Time  0.024 ( 0.024)	Loss 3.7476e-01 (4.1676e-01)	Acc@1  89.00 ( 90.93)	Acc@5 100.00 ( 99.61)
Test: [ 50/100]	Time  0.021 ( 0.024)	Loss 1.4794e-01 (4.1068e-01)	Acc@1  95.00 ( 91.14)	Acc@5 100.00 ( 99.65)
Test: [ 60/100]	Time  0.023 ( 0.023)	Loss 4.6069e-01 (4.0070e-01)	Acc@1  93.00 ( 91.11)	Acc@5  99.00 ( 99.67)
Test: [ 70/100]	Time  0.016 ( 0.023)	Loss 4.4825e-01 (3.8998e-01)	Acc@1  87.00 ( 91.23)	Acc@5 100.00 ( 99.68)
Test: [ 80/100]	Time  0.024 ( 0.022)	Loss 1.8233e-01 (3.8249e-01)	Acc@1  94.00 ( 91.33)	Acc@5 100.00 ( 99.70)
Test: [ 90/100]	Time  0.021 ( 0.022)	Loss 2.7462e-01 (3.8989e-01)	Acc@1  95.00 ( 91.29)	Acc@5 100.00 ( 99.74)
 * Acc@1 91.210 Acc@5 99.740
### epoch[67] execution time: 15.839776277542114
EPOCH 68
REMOVING: module.fire6.squeeze.1.bias
REMOVING: module.fire6.expand_1x1.0.weight
i:   0, name: module.fire6.expand_1x1.0.bias  changing lr from: 0.001078474111421939   to: 0.001002490326204652
i:   1, name: module.fire6.expand_1x1.1.weight  changing lr from: 0.001143781733666065   to: 0.001022645583294645
i:   2, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.001227868349964883   to: 0.001062595613413458
i:   3, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.001330214347322949   to: 0.001121816985860202
i:   4, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.001450305722326721   to: 0.001199791004779271
i:   5, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.001587634374263829   to: 0.001296004058538429
i:   6, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.001741698372257676   to: 0.001409947940826300
i:   7, name:  module.fire7.squeeze.0.weight  changing lr from: 0.001912002197707645   to: 0.001541120144816326
i:   8, name:    module.fire7.squeeze.0.bias  changing lr from: 0.002098056963280664   to: 0.001689024131700772
i:   9, name:  module.fire7.squeeze.1.weight  changing lr from: 0.002299380609655914   to: 0.001853169574854984
i:  10, name:    module.fire7.squeeze.1.bias  changing lr from: 0.002515498081180883   to: 0.002033072580849182
i:  11, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.002745941481554459   to: 0.002228255888482599
i:  12, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.002990250210610356   to: 0.002438249046972750
i:  13, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.003247971083233430   to: 0.002662588574391349
i:  14, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.003518658431400523   to: 0.002900818097397694
i:  15, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.003801874190298492   to: 0.003152488473280523
i:  16, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.004097187969433141   to: 0.003417157895280114
i:  17, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.004404177109605488   to: 0.003694391982124361
i:  18, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.004722426726594813   to: 0.003983763852674870
i:  19, name:  module.fire8.squeeze.0.weight  changing lr from: 0.005051529742352678   to: 0.004284854186542857
i:  20, name:    module.fire8.squeeze.0.bias  changing lr from: 0.005391086904477016   to: 0.004597251271499092
i:  21, name:  module.fire8.squeeze.1.weight  changing lr from: 0.005740706794702343   to: 0.004920551038467224
i:  22, name:    module.fire8.squeeze.1.bias  changing lr from: 0.006100005827108983   to: 0.005254357084856664
i:  23, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.006468608236722655   to: 0.005598280686957773
i:  24, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.006846146059145857   to: 0.005951940802091265
i:  25, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.007232259101831650   to: 0.006314964061172095
i:  26, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.007626594907583211   to: 0.006686984752319019
i:  27, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.008028808710833640   to: 0.007067644796111505
i:  28, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.008438563387235004   to: 0.007456593713068654
i:  29, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.008855529397058887   to: 0.007853488583896718
i:  30, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.009279384722886714   to: 0.008257994003027014
i:  31, name:  module.fire9.squeeze.0.weight  changing lr from: 0.009709814802043925   to: 0.008669782025939959
i:  32, name:    module.fire9.squeeze.0.bias  changing lr from: 0.010146512454209142   to: 0.009088532110747293
i:  33, name:  module.fire9.squeeze.1.weight  changing lr from: 0.010589177804607431   to: 0.009513931054481145
i:  34, name:    module.fire9.squeeze.1.bias  changing lr from: 0.011037518203175788   to: 0.009945672924516091
i:  35, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.011491248140068366   to: 0.010383458985528993
i:  36, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.011950089157849286   to: 0.010826997622380180
i:  37, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.012413769760702915   to: 0.011276004259280409
i:  38, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.012882025320972205   to: 0.011730201275587986
i:  39, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.013354597983320071   to: 0.012189317918562780
i:  40, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.013831236566790944   to: 0.012653090213386082
i:  41, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.014311696465034395   to: 0.013121260870737794
i:  42, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.014795739544938225   to: 0.013593579192207467
i:  43, name:           module.conv10.weight  changing lr from: 0.015283134043902698   to: 0.014069800973798841
i:  44, name:             module.conv10.bias  changing lr from: 0.015773654465975163   to: 0.014549688407773903



# Switched to train mode...
Epoch: [68][  0/391]	Time  0.203 ( 0.203)	Data  0.168 ( 0.168)	Loss 1.0224e-01 (1.0224e-01)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [68][ 10/391]	Time  0.035 ( 0.049)	Data  0.001 ( 0.016)	Loss 5.9794e-02 (3.7993e-02)	Acc@1  98.44 ( 98.79)	Acc@5 100.00 (100.00)
Epoch: [68][ 20/391]	Time  0.032 ( 0.041)	Data  0.001 ( 0.009)	Loss 2.8107e-02 (3.5714e-02)	Acc@1  99.22 ( 98.88)	Acc@5 100.00 (100.00)
Epoch: [68][ 30/391]	Time  0.032 ( 0.039)	Data  0.001 ( 0.006)	Loss 3.2091e-02 (3.5721e-02)	Acc@1  99.22 ( 98.82)	Acc@5 100.00 (100.00)
Epoch: [68][ 40/391]	Time  0.033 ( 0.037)	Data  0.001 ( 0.005)	Loss 1.4901e-02 (3.6203e-02)	Acc@1 100.00 ( 98.82)	Acc@5 100.00 (100.00)
Epoch: [68][ 50/391]	Time  0.032 ( 0.036)	Data  0.001 ( 0.004)	Loss 7.4156e-02 (3.6691e-02)	Acc@1  96.88 ( 98.76)	Acc@5 100.00 (100.00)
Epoch: [68][ 60/391]	Time  0.033 ( 0.036)	Data  0.001 ( 0.004)	Loss 2.4392e-02 (3.5035e-02)	Acc@1  99.22 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [68][ 70/391]	Time  0.033 ( 0.035)	Data  0.001 ( 0.003)	Loss 8.5010e-02 (3.5864e-02)	Acc@1  96.09 ( 98.76)	Acc@5 100.00 (100.00)
Epoch: [68][ 80/391]	Time  0.033 ( 0.035)	Data  0.001 ( 0.003)	Loss 1.3439e-02 (3.4981e-02)	Acc@1  99.22 ( 98.78)	Acc@5 100.00 (100.00)
Epoch: [68][ 90/391]	Time  0.032 ( 0.035)	Data  0.001 ( 0.003)	Loss 8.8805e-02 (3.5005e-02)	Acc@1  95.31 ( 98.75)	Acc@5 100.00 (100.00)
Epoch: [68][100/391]	Time  0.031 ( 0.035)	Data  0.001 ( 0.003)	Loss 4.2684e-02 (3.4733e-02)	Acc@1  99.22 ( 98.75)	Acc@5 100.00 (100.00)
Epoch: [68][110/391]	Time  0.033 ( 0.034)	Data  0.001 ( 0.002)	Loss 3.2119e-02 (3.4568e-02)	Acc@1  99.22 ( 98.78)	Acc@5 100.00 (100.00)
Epoch: [68][120/391]	Time  0.033 ( 0.034)	Data  0.001 ( 0.002)	Loss 2.4593e-02 (3.4515e-02)	Acc@1  98.44 ( 98.77)	Acc@5 100.00 (100.00)
Epoch: [68][130/391]	Time  0.032 ( 0.034)	Data  0.001 ( 0.002)	Loss 3.1852e-02 (3.3852e-02)	Acc@1  98.44 ( 98.82)	Acc@5 100.00 (100.00)
Epoch: [68][140/391]	Time  0.032 ( 0.034)	Data  0.001 ( 0.002)	Loss 7.8792e-03 (3.3153e-02)	Acc@1 100.00 ( 98.85)	Acc@5 100.00 (100.00)
Epoch: [68][150/391]	Time  0.035 ( 0.034)	Data  0.001 ( 0.002)	Loss 2.0827e-02 (3.2908e-02)	Acc@1  99.22 ( 98.85)	Acc@5 100.00 (100.00)
Epoch: [68][160/391]	Time  0.034 ( 0.034)	Data  0.001 ( 0.002)	Loss 5.0845e-02 (3.3500e-02)	Acc@1  99.22 ( 98.84)	Acc@5 100.00 (100.00)
Epoch: [68][170/391]	Time  0.032 ( 0.034)	Data  0.001 ( 0.002)	Loss 4.3101e-02 (3.3274e-02)	Acc@1  98.44 ( 98.84)	Acc@5 100.00 (100.00)
Epoch: [68][180/391]	Time  0.031 ( 0.034)	Data  0.001 ( 0.002)	Loss 3.0075e-02 (3.3162e-02)	Acc@1  98.44 ( 98.85)	Acc@5 100.00 (100.00)
Epoch: [68][190/391]	Time  0.035 ( 0.034)	Data  0.001 ( 0.002)	Loss 3.5659e-02 (3.3277e-02)	Acc@1  98.44 ( 98.85)	Acc@5 100.00 (100.00)
Epoch: [68][200/391]	Time  0.031 ( 0.034)	Data  0.001 ( 0.002)	Loss 1.7465e-02 (3.3067e-02)	Acc@1  99.22 ( 98.85)	Acc@5 100.00 (100.00)
Epoch: [68][210/391]	Time  0.032 ( 0.034)	Data  0.001 ( 0.002)	Loss 3.4210e-02 (3.2909e-02)	Acc@1  99.22 ( 98.86)	Acc@5 100.00 (100.00)
Epoch: [68][220/391]	Time  0.033 ( 0.034)	Data  0.001 ( 0.002)	Loss 3.4141e-02 (3.2992e-02)	Acc@1  98.44 ( 98.87)	Acc@5 100.00 (100.00)
Epoch: [68][230/391]	Time  0.033 ( 0.034)	Data  0.001 ( 0.002)	Loss 3.5847e-02 (3.2871e-02)	Acc@1  99.22 ( 98.89)	Acc@5 100.00 (100.00)
Epoch: [68][240/391]	Time  0.034 ( 0.034)	Data  0.001 ( 0.002)	Loss 5.6633e-02 (3.2728e-02)	Acc@1  97.66 ( 98.90)	Acc@5 100.00 (100.00)
Epoch: [68][250/391]	Time  0.032 ( 0.034)	Data  0.001 ( 0.002)	Loss 2.6184e-02 (3.2555e-02)	Acc@1  98.44 ( 98.89)	Acc@5 100.00 (100.00)
Epoch: [68][260/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.002)	Loss 6.0859e-02 (3.2495e-02)	Acc@1  97.66 ( 98.89)	Acc@5 100.00 (100.00)
Epoch: [68][270/391]	Time  0.033 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.4069e-02 (3.2409e-02)	Acc@1 100.00 ( 98.89)	Acc@5 100.00 (100.00)
Epoch: [68][280/391]	Time  0.034 ( 0.033)	Data  0.001 ( 0.002)	Loss 3.5503e-02 (3.2464e-02)	Acc@1  98.44 ( 98.90)	Acc@5 100.00 (100.00)
Epoch: [68][290/391]	Time  0.033 ( 0.033)	Data  0.001 ( 0.002)	Loss 7.2046e-02 (3.2470e-02)	Acc@1  98.44 ( 98.90)	Acc@5 100.00 (100.00)
Epoch: [68][300/391]	Time  0.039 ( 0.033)	Data  0.001 ( 0.002)	Loss 4.6550e-02 (3.2385e-02)	Acc@1  97.66 ( 98.90)	Acc@5 100.00 (100.00)
Epoch: [68][310/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.002)	Loss 7.4068e-02 (3.2713e-02)	Acc@1  96.88 ( 98.89)	Acc@5 100.00 (100.00)
Epoch: [68][320/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.4674e-02 (3.2471e-02)	Acc@1 100.00 ( 98.89)	Acc@5 100.00 (100.00)
Epoch: [68][330/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.4449e-02 (3.2467e-02)	Acc@1  99.22 ( 98.89)	Acc@5 100.00 (100.00)
Epoch: [68][340/391]	Time  0.037 ( 0.033)	Data  0.001 ( 0.002)	Loss 5.3209e-02 (3.2629e-02)	Acc@1  97.66 ( 98.89)	Acc@5 100.00 (100.00)
Epoch: [68][350/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.001)	Loss 2.1482e-02 (3.2613e-02)	Acc@1 100.00 ( 98.89)	Acc@5 100.00 (100.00)
Epoch: [68][360/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.001)	Loss 5.2227e-02 (3.2653e-02)	Acc@1  96.88 ( 98.89)	Acc@5 100.00 (100.00)
Epoch: [68][370/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.001)	Loss 2.9548e-02 (3.2748e-02)	Acc@1  98.44 ( 98.88)	Acc@5 100.00 (100.00)
Epoch: [68][380/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.001)	Loss 1.7089e-02 (3.2510e-02)	Acc@1  99.22 ( 98.89)	Acc@5 100.00 (100.00)
Epoch: [68][390/391]	Time  0.023 ( 0.033)	Data  0.001 ( 0.001)	Loss 7.6271e-02 (3.2592e-02)	Acc@1  97.50 ( 98.88)	Acc@5 100.00 (100.00)
## e[68] optimizer.zero_grad (sum) time: 0.125931978225708
## e[68]       loss.backward (sum) time: 2.9092469215393066
## e[68]      optimizer.step (sum) time: 0.9047975540161133
## epoch[68] training(only) time: 13.10090708732605
# Switched to evaluate mode...
Test: [  0/100]	Time  0.169 ( 0.169)	Loss 1.5696e-01 (1.5696e-01)	Acc@1  95.00 ( 95.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.017 ( 0.033)	Loss 5.0173e-01 (3.3158e-01)	Acc@1  91.00 ( 91.91)	Acc@5 100.00 (100.00)
Test: [ 20/100]	Time  0.024 ( 0.028)	Loss 3.4115e-01 (3.7199e-01)	Acc@1  91.00 ( 91.24)	Acc@5 100.00 ( 99.71)
Test: [ 30/100]	Time  0.023 ( 0.026)	Loss 5.0925e-01 (4.0484e-01)	Acc@1  89.00 ( 90.90)	Acc@5  98.00 ( 99.65)
Test: [ 40/100]	Time  0.019 ( 0.025)	Loss 3.8302e-01 (4.1894e-01)	Acc@1  90.00 ( 90.78)	Acc@5 100.00 ( 99.66)
Test: [ 50/100]	Time  0.021 ( 0.024)	Loss 1.4952e-01 (4.1088e-01)	Acc@1  94.00 ( 90.90)	Acc@5 100.00 ( 99.67)
Test: [ 60/100]	Time  0.021 ( 0.023)	Loss 4.6047e-01 (3.9689e-01)	Acc@1  93.00 ( 91.02)	Acc@5 100.00 ( 99.70)
Test: [ 70/100]	Time  0.023 ( 0.023)	Loss 4.6297e-01 (3.8513e-01)	Acc@1  88.00 ( 91.11)	Acc@5 100.00 ( 99.70)
Test: [ 80/100]	Time  0.020 ( 0.023)	Loss 2.0391e-01 (3.7854e-01)	Acc@1  95.00 ( 91.19)	Acc@5 100.00 ( 99.73)
Test: [ 90/100]	Time  0.023 ( 0.023)	Loss 2.8111e-01 (3.8634e-01)	Acc@1  94.00 ( 91.13)	Acc@5 100.00 ( 99.76)
 * Acc@1 91.060 Acc@5 99.760
### epoch[68] execution time: 15.463233470916748
EPOCH 69
REMOVING: module.fire6.expand_1x1.0.bias
REMOVING: module.fire6.expand_1x1.1.weight
i:   0, name: module.fire6.expand_1x1.1.bias  changing lr from: 0.001062595613413458   to: 0.001000524293140708
i:   1, name: module.fire6.expand_3x3.0.weight  changing lr from: 0.001121816985860202   to: 0.001015184389752537
i:   2, name: module.fire6.expand_3x3.0.bias  changing lr from: 0.001199791004779271   to: 0.001049589231723873
i:   3, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.001296004058538429   to: 0.001103221757881677
i:   4, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.001409947940826300   to: 0.001175569450770008
i:   5, name:  module.fire7.squeeze.0.weight  changing lr from: 0.001541120144816326   to: 0.001266124685572772
i:   6, name:    module.fire7.squeeze.0.bias  changing lr from: 0.001689024131700772   to: 0.001374385051193626
i:   7, name:  module.fire7.squeeze.1.weight  changing lr from: 0.001853169574854984   to: 0.001499853644807097
i:   8, name:    module.fire7.squeeze.1.bias  changing lr from: 0.002033072580849182   to: 0.001642039341152828
i:   9, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.002228255888482599   to: 0.001800457037803431
i:  10, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.002438249046972750   to: 0.001974627877594603
i:  11, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.002662588574391349   to: 0.002164079449365563
i:  12, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.002900818097397694   to: 0.002368345968116891
i:  13, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.003152488473280523   to: 0.002586968435653413
i:  14, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.003417157895280114   to: 0.002819494782739933
i:  15, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.003694391982124361   to: 0.003065479993759567
i:  16, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.003983763852674870   to: 0.003324486214825933
i:  17, name:  module.fire8.squeeze.0.weight  changing lr from: 0.004284854186542857   to: 0.003596082846264120
i:  18, name:    module.fire8.squeeze.0.bias  changing lr from: 0.004597251271499092   to: 0.003879846620338300
i:  19, name:  module.fire8.squeeze.1.weight  changing lr from: 0.004920551038467224   to: 0.004175361665069271
i:  20, name:    module.fire8.squeeze.1.bias  changing lr from: 0.005254357084856664   to: 0.004482219554950062
i:  21, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.005598280686957773   to: 0.004800019349334366
i:  22, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.005951940802091265   to: 0.005128367619240109
i:  23, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.006314964061172095   to: 0.005466878463278023
i:  24, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.006686984752319019   to: 0.005815173513385090
i:  25, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.007067644796111505   to: 0.006172881931011880
i:  26, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.007456593713068654   to: 0.006539640394384671
i:  27, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.007853488583896718   to: 0.006915093077434381
i:  28, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.008257994003027014   to: 0.007298891620957792
i:  29, name:  module.fire9.squeeze.0.weight  changing lr from: 0.008669782025939959   to: 0.007690695096549859
i:  30, name:    module.fire9.squeeze.0.bias  changing lr from: 0.009088532110747293   to: 0.008090169963820731
i:  31, name:  module.fire9.squeeze.1.weight  changing lr from: 0.009513931054481145   to: 0.008496990021386645
i:  32, name:    module.fire9.squeeze.1.bias  changing lr from: 0.009945672924516091   to: 0.008910836352100077
i:  33, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.010383458985528993   to: 0.009331397262961987
i:  34, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.010826997622380180   to: 0.009758368220137009
i:  35, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.011276004259280409   to: 0.010191451779471204
i:  36, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.011730201275587986   to: 0.010630357512891903
i:  37, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.012189317918562780   to: 0.011074801931049670
i:  38, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.012653090213386082   to: 0.011524508402543522
i:  39, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.013121260870737794   to: 0.011979207070052546
i:  40, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.013593579192207467   to: 0.012438634763680196
i:  41, name:           module.conv10.weight  changing lr from: 0.014069800973798841   to: 0.012902534911800372
i:  42, name:             module.conv10.bias  changing lr from: 0.014549688407773903   to: 0.013370657449679146



# Switched to train mode...
Epoch: [69][  0/391]	Time  0.211 ( 0.211)	Data  0.176 ( 0.176)	Loss 9.4217e-03 (9.4217e-03)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [69][ 10/391]	Time  0.034 ( 0.050)	Data  0.001 ( 0.017)	Loss 5.0362e-02 (3.7439e-02)	Acc@1  99.22 ( 98.58)	Acc@5 100.00 (100.00)
Epoch: [69][ 20/391]	Time  0.033 ( 0.041)	Data  0.001 ( 0.009)	Loss 7.3837e-02 (4.1605e-02)	Acc@1  98.44 ( 98.70)	Acc@5 100.00 (100.00)
Epoch: [69][ 30/391]	Time  0.032 ( 0.039)	Data  0.001 ( 0.007)	Loss 1.9422e-02 (3.9244e-02)	Acc@1  99.22 ( 98.71)	Acc@5 100.00 (100.00)
Epoch: [69][ 40/391]	Time  0.033 ( 0.037)	Data  0.001 ( 0.005)	Loss 1.8489e-02 (3.8056e-02)	Acc@1  98.44 ( 98.61)	Acc@5 100.00 (100.00)
Epoch: [69][ 50/391]	Time  0.033 ( 0.037)	Data  0.001 ( 0.004)	Loss 9.6034e-03 (3.6330e-02)	Acc@1 100.00 ( 98.74)	Acc@5 100.00 (100.00)
Epoch: [69][ 60/391]	Time  0.031 ( 0.036)	Data  0.001 ( 0.004)	Loss 5.1030e-02 (3.5052e-02)	Acc@1  98.44 ( 98.78)	Acc@5 100.00 (100.00)
Epoch: [69][ 70/391]	Time  0.034 ( 0.035)	Data  0.001 ( 0.003)	Loss 9.9435e-03 (3.4399e-02)	Acc@1 100.00 ( 98.78)	Acc@5 100.00 (100.00)
Epoch: [69][ 80/391]	Time  0.033 ( 0.035)	Data  0.001 ( 0.003)	Loss 5.1716e-02 (3.4222e-02)	Acc@1  98.44 ( 98.83)	Acc@5 100.00 (100.00)
Epoch: [69][ 90/391]	Time  0.032 ( 0.035)	Data  0.001 ( 0.003)	Loss 4.0227e-02 (3.4752e-02)	Acc@1  98.44 ( 98.82)	Acc@5 100.00 (100.00)
Epoch: [69][100/391]	Time  0.035 ( 0.035)	Data  0.001 ( 0.003)	Loss 1.6520e-02 (3.3992e-02)	Acc@1 100.00 ( 98.85)	Acc@5 100.00 (100.00)
Epoch: [69][110/391]	Time  0.033 ( 0.034)	Data  0.001 ( 0.003)	Loss 3.1600e-02 (3.4702e-02)	Acc@1  99.22 ( 98.84)	Acc@5 100.00 (100.00)
Epoch: [69][120/391]	Time  0.031 ( 0.034)	Data  0.001 ( 0.002)	Loss 3.5904e-02 (3.4728e-02)	Acc@1  96.88 ( 98.84)	Acc@5 100.00 (100.00)
Epoch: [69][130/391]	Time  0.032 ( 0.034)	Data  0.001 ( 0.002)	Loss 5.4648e-02 (3.4990e-02)	Acc@1  98.44 ( 98.84)	Acc@5 100.00 (100.00)
Epoch: [69][140/391]	Time  0.033 ( 0.034)	Data  0.001 ( 0.002)	Loss 4.3166e-02 (3.5101e-02)	Acc@1  98.44 ( 98.82)	Acc@5 100.00 (100.00)
Epoch: [69][150/391]	Time  0.033 ( 0.034)	Data  0.001 ( 0.002)	Loss 3.3784e-02 (3.5688e-02)	Acc@1  97.66 ( 98.79)	Acc@5 100.00 (100.00)
Epoch: [69][160/391]	Time  0.033 ( 0.034)	Data  0.001 ( 0.002)	Loss 7.9716e-03 (3.5223e-02)	Acc@1 100.00 ( 98.80)	Acc@5 100.00 (100.00)
Epoch: [69][170/391]	Time  0.032 ( 0.034)	Data  0.001 ( 0.002)	Loss 5.6782e-02 (3.4666e-02)	Acc@1  99.22 ( 98.84)	Acc@5 100.00 (100.00)
Epoch: [69][180/391]	Time  0.032 ( 0.034)	Data  0.001 ( 0.002)	Loss 4.6873e-02 (3.4238e-02)	Acc@1  97.66 ( 98.85)	Acc@5 100.00 (100.00)
Epoch: [69][190/391]	Time  0.038 ( 0.034)	Data  0.001 ( 0.002)	Loss 8.0809e-02 (3.3922e-02)	Acc@1  96.88 ( 98.86)	Acc@5 100.00 (100.00)
Epoch: [69][200/391]	Time  0.036 ( 0.034)	Data  0.001 ( 0.002)	Loss 1.7603e-02 (3.3849e-02)	Acc@1 100.00 ( 98.88)	Acc@5 100.00 (100.00)
Epoch: [69][210/391]	Time  0.034 ( 0.034)	Data  0.001 ( 0.002)	Loss 1.2484e-02 (3.4060e-02)	Acc@1 100.00 ( 98.87)	Acc@5 100.00 (100.00)
Epoch: [69][220/391]	Time  0.035 ( 0.034)	Data  0.001 ( 0.002)	Loss 6.5205e-02 (3.4098e-02)	Acc@1  97.66 ( 98.87)	Acc@5 100.00 (100.00)
Epoch: [69][230/391]	Time  0.033 ( 0.034)	Data  0.001 ( 0.002)	Loss 2.3524e-02 (3.4050e-02)	Acc@1  99.22 ( 98.87)	Acc@5 100.00 (100.00)
Epoch: [69][240/391]	Time  0.032 ( 0.034)	Data  0.001 ( 0.002)	Loss 3.3995e-02 (3.4086e-02)	Acc@1  98.44 ( 98.87)	Acc@5 100.00 (100.00)
Epoch: [69][250/391]	Time  0.033 ( 0.034)	Data  0.001 ( 0.002)	Loss 4.6423e-02 (3.3626e-02)	Acc@1  97.66 ( 98.89)	Acc@5 100.00 (100.00)
Epoch: [69][260/391]	Time  0.031 ( 0.034)	Data  0.001 ( 0.002)	Loss 1.8659e-02 (3.3422e-02)	Acc@1 100.00 ( 98.90)	Acc@5 100.00 (100.00)
Epoch: [69][270/391]	Time  0.032 ( 0.034)	Data  0.001 ( 0.002)	Loss 3.7889e-02 (3.3279e-02)	Acc@1  98.44 ( 98.92)	Acc@5 100.00 (100.00)
Epoch: [69][280/391]	Time  0.033 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.8181e-02 (3.2995e-02)	Acc@1  99.22 ( 98.92)	Acc@5 100.00 (100.00)
Epoch: [69][290/391]	Time  0.035 ( 0.033)	Data  0.001 ( 0.002)	Loss 5.0164e-02 (3.3092e-02)	Acc@1  97.66 ( 98.92)	Acc@5 100.00 (100.00)
Epoch: [69][300/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 6.6647e-02 (3.3387e-02)	Acc@1  99.22 ( 98.92)	Acc@5 100.00 (100.00)
Epoch: [69][310/391]	Time  0.034 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.4426e-02 (3.3418e-02)	Acc@1  99.22 ( 98.92)	Acc@5 100.00 (100.00)
Epoch: [69][320/391]	Time  0.036 ( 0.033)	Data  0.001 ( 0.002)	Loss 3.5205e-02 (3.3368e-02)	Acc@1  99.22 ( 98.91)	Acc@5 100.00 (100.00)
Epoch: [69][330/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.2821e-02 (3.3225e-02)	Acc@1 100.00 ( 98.92)	Acc@5 100.00 (100.00)
Epoch: [69][340/391]	Time  0.035 ( 0.033)	Data  0.001 ( 0.002)	Loss 4.3035e-02 (3.3117e-02)	Acc@1  97.66 ( 98.91)	Acc@5 100.00 (100.00)
Epoch: [69][350/391]	Time  0.035 ( 0.033)	Data  0.001 ( 0.002)	Loss 4.2325e-02 (3.3235e-02)	Acc@1  98.44 ( 98.90)	Acc@5 100.00 (100.00)
Epoch: [69][360/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.002)	Loss 4.4899e-02 (3.3204e-02)	Acc@1  96.88 ( 98.90)	Acc@5 100.00 (100.00)
Epoch: [69][370/391]	Time  0.034 ( 0.033)	Data  0.001 ( 0.001)	Loss 8.1353e-02 (3.3240e-02)	Acc@1  97.66 ( 98.89)	Acc@5 100.00 (100.00)
Epoch: [69][380/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.001)	Loss 1.8232e-02 (3.3143e-02)	Acc@1 100.00 ( 98.90)	Acc@5 100.00 (100.00)
Epoch: [69][390/391]	Time  0.021 ( 0.033)	Data  0.001 ( 0.001)	Loss 2.0474e-02 (3.2977e-02)	Acc@1 100.00 ( 98.90)	Acc@5 100.00 (100.00)
## e[69] optimizer.zero_grad (sum) time: 0.12082409858703613
## e[69]       loss.backward (sum) time: 2.9019570350646973
## e[69]      optimizer.step (sum) time: 0.8485558032989502
## epoch[69] training(only) time: 13.111677646636963
# Switched to evaluate mode...
Test: [  0/100]	Time  0.174 ( 0.174)	Loss 1.9043e-01 (1.9043e-01)	Acc@1  96.00 ( 96.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.022 ( 0.034)	Loss 5.2435e-01 (3.3632e-01)	Acc@1  89.00 ( 91.73)	Acc@5 100.00 ( 99.91)
Test: [ 20/100]	Time  0.023 ( 0.028)	Loss 3.3507e-01 (3.7416e-01)	Acc@1  90.00 ( 91.14)	Acc@5 100.00 ( 99.67)
Test: [ 30/100]	Time  0.018 ( 0.025)	Loss 4.9136e-01 (4.0695e-01)	Acc@1  89.00 ( 91.10)	Acc@5  98.00 ( 99.61)
Test: [ 40/100]	Time  0.018 ( 0.023)	Loss 3.3733e-01 (4.1578e-01)	Acc@1  90.00 ( 90.95)	Acc@5 100.00 ( 99.61)
Test: [ 50/100]	Time  0.021 ( 0.023)	Loss 1.3924e-01 (4.0727e-01)	Acc@1  95.00 ( 91.20)	Acc@5 100.00 ( 99.65)
Test: [ 60/100]	Time  0.023 ( 0.023)	Loss 4.7774e-01 (3.9326e-01)	Acc@1  93.00 ( 91.26)	Acc@5  99.00 ( 99.67)
Test: [ 70/100]	Time  0.021 ( 0.022)	Loss 4.4894e-01 (3.8167e-01)	Acc@1  88.00 ( 91.37)	Acc@5 100.00 ( 99.68)
Test: [ 80/100]	Time  0.018 ( 0.022)	Loss 2.4132e-01 (3.7718e-01)	Acc@1  95.00 ( 91.40)	Acc@5 100.00 ( 99.67)
Test: [ 90/100]	Time  0.021 ( 0.022)	Loss 2.9493e-01 (3.8458e-01)	Acc@1  94.00 ( 91.33)	Acc@5 100.00 ( 99.70)
 * Acc@1 91.300 Acc@5 99.710
### epoch[69] execution time: 15.410649299621582
EPOCH 70
REMOVING: module.fire6.expand_1x1.1.bias
REMOVING: module.fire6.expand_3x3.0.weight
REMOVING: module.fire6.expand_3x3.0.bias
i:   0, name: module.fire6.expand_3x3.1.weight  changing lr from: 0.001103221757881677   to: 0.001009670864964517
i:   1, name: module.fire6.expand_3x3.1.bias  changing lr from: 0.001175569450770008   to: 0.001039023113111897
i:   2, name:  module.fire7.squeeze.0.weight  changing lr from: 0.001266124685572772   to: 0.001087548957361666
i:   3, name:    module.fire7.squeeze.0.bias  changing lr from: 0.001374385051193626   to: 0.001154742020994247
i:   4, name:  module.fire7.squeeze.1.weight  changing lr from: 0.001499853644807097   to: 0.001240100641222196
i:   5, name:    module.fire7.squeeze.1.bias  changing lr from: 0.001642039341152828   to: 0.001343128189623249
i:   6, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.001800457037803431   to: 0.001463333366465174
i:   7, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.001974627877594603   to: 0.001600230470163127
i:   8, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.002164079449365563   to: 0.001753339643070189
i:   9, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.002368345968116891   to: 0.001922187094761551
i:  10, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.002586968435653413   to: 0.002106305303933475
i:  11, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.002819494782739933   to: 0.002305233199998751
i:  12, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.003065479993759567   to: 0.002518516325422137
i:  13, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.003324486214825933   to: 0.002745706979800721
i:  14, name:  module.fire8.squeeze.0.weight  changing lr from: 0.003596082846264120   to: 0.002986364346657399
i:  15, name:    module.fire8.squeeze.0.bias  changing lr from: 0.003879846620338300   to: 0.003240054603878377
i:  16, name:  module.fire8.squeeze.1.weight  changing lr from: 0.004175361665069271   to: 0.003506351018690340
i:  17, name:    module.fire8.squeeze.1.bias  changing lr from: 0.004482219554950062   to: 0.003784834028037264
i:  18, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.004800019349334366   to: 0.004075091305182654
i:  19, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.005128367619240109   to: 0.004376717813329905
i:  20, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.005466878463278023   to: 0.004689315847020197
i:  21, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.005815173513385090   to: 0.005012495062036043
i:  22, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.006172881931011880   to: 0.005345872494507608
i:  23, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.006539640394384671   to: 0.005689072569888814
i:  24, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.006915093077434381   to: 0.006041727102441241
i:  25, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.007298891620957792   to: 0.006403475285835530
i:  26, name:  module.fire9.squeeze.0.weight  changing lr from: 0.007690695096549859   to: 0.006773963675452826
i:  27, name:    module.fire9.squeeze.0.bias  changing lr from: 0.008090169963820731   to: 0.007152846162941911
i:  28, name:  module.fire9.squeeze.1.weight  changing lr from: 0.008496990021386645   to: 0.007539783943562744
i:  29, name:    module.fire9.squeeze.1.bias  changing lr from: 0.008910836352100077   to: 0.007934445476821751
i:  30, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.009331397262961987   to: 0.008336506440880707
i:  31, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.009758368220137009   to: 0.008745649681197931
i:  32, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.010191451779471204   to: 0.009161565153838373
i:  33, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.010630357512891903   to: 0.009583949863867430
i:  34, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.011074801931049670   to: 0.010012507799223296
i:  35, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.011524508402543522   to: 0.010446949860442489
i:  36, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.011979207070052546   to: 0.010886993786593736
i:  37, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.012438634763680196   to: 0.011332364077758138
i:  38, name:           module.conv10.weight  changing lr from: 0.012902534911800372   to: 0.011782791914374820
i:  39, name:             module.conv10.bias  changing lr from: 0.013370657449679146   to: 0.012238015073755000



# Switched to train mode...
Epoch: [70][  0/391]	Time  0.208 ( 0.208)	Data  0.174 ( 0.174)	Loss 3.9562e-02 (3.9562e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [70][ 10/391]	Time  0.033 ( 0.049)	Data  0.001 ( 0.017)	Loss 2.4573e-02 (3.0209e-02)	Acc@1  99.22 ( 99.29)	Acc@5 100.00 (100.00)
Epoch: [70][ 20/391]	Time  0.031 ( 0.041)	Data  0.001 ( 0.009)	Loss 4.1067e-02 (3.4837e-02)	Acc@1  98.44 ( 99.00)	Acc@5 100.00 (100.00)
Epoch: [70][ 30/391]	Time  0.031 ( 0.038)	Data  0.001 ( 0.007)	Loss 2.6147e-02 (3.3648e-02)	Acc@1  99.22 ( 98.97)	Acc@5 100.00 (100.00)
Epoch: [70][ 40/391]	Time  0.031 ( 0.036)	Data  0.001 ( 0.005)	Loss 1.1818e-02 (3.4093e-02)	Acc@1 100.00 ( 98.95)	Acc@5 100.00 (100.00)
Epoch: [70][ 50/391]	Time  0.034 ( 0.035)	Data  0.001 ( 0.004)	Loss 2.4776e-02 (3.2739e-02)	Acc@1  99.22 ( 98.99)	Acc@5 100.00 (100.00)
Epoch: [70][ 60/391]	Time  0.031 ( 0.035)	Data  0.001 ( 0.004)	Loss 2.0939e-02 (3.2131e-02)	Acc@1  99.22 ( 99.00)	Acc@5 100.00 (100.00)
Epoch: [70][ 70/391]	Time  0.031 ( 0.035)	Data  0.001 ( 0.003)	Loss 2.3244e-02 (3.2569e-02)	Acc@1 100.00 ( 98.98)	Acc@5 100.00 (100.00)
Epoch: [70][ 80/391]	Time  0.031 ( 0.034)	Data  0.001 ( 0.003)	Loss 1.6881e-02 (3.2388e-02)	Acc@1  99.22 ( 98.97)	Acc@5 100.00 (100.00)
Epoch: [70][ 90/391]	Time  0.031 ( 0.034)	Data  0.001 ( 0.003)	Loss 1.2980e-02 (3.1226e-02)	Acc@1 100.00 ( 99.00)	Acc@5 100.00 (100.00)
Epoch: [70][100/391]	Time  0.031 ( 0.034)	Data  0.001 ( 0.003)	Loss 3.2436e-02 (3.1391e-02)	Acc@1  98.44 ( 98.99)	Acc@5 100.00 (100.00)
Epoch: [70][110/391]	Time  0.031 ( 0.034)	Data  0.001 ( 0.003)	Loss 3.2733e-02 (3.1295e-02)	Acc@1  99.22 ( 98.99)	Acc@5 100.00 (100.00)
Epoch: [70][120/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.8980e-02 (3.1217e-02)	Acc@1  99.22 ( 98.98)	Acc@5 100.00 (100.00)
Epoch: [70][130/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 7.6039e-02 (3.1806e-02)	Acc@1  96.88 ( 98.93)	Acc@5 100.00 (100.00)
Epoch: [70][140/391]	Time  0.034 ( 0.033)	Data  0.001 ( 0.002)	Loss 4.2109e-02 (3.2076e-02)	Acc@1  98.44 ( 98.92)	Acc@5 100.00 (100.00)
Epoch: [70][150/391]	Time  0.033 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.6524e-02 (3.1789e-02)	Acc@1  99.22 ( 98.92)	Acc@5 100.00 (100.00)
Epoch: [70][160/391]	Time  0.042 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.3948e-02 (3.1629e-02)	Acc@1 100.00 ( 98.93)	Acc@5 100.00 (100.00)
Epoch: [70][170/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.1964e-02 (3.1286e-02)	Acc@1 100.00 ( 98.95)	Acc@5 100.00 (100.00)
Epoch: [70][180/391]	Time  0.033 ( 0.033)	Data  0.001 ( 0.002)	Loss 5.4446e-02 (3.1403e-02)	Acc@1  96.88 ( 98.93)	Acc@5 100.00 (100.00)
Epoch: [70][190/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.002)	Loss 9.1361e-03 (3.1535e-02)	Acc@1 100.00 ( 98.93)	Acc@5 100.00 (100.00)
Epoch: [70][200/391]	Time  0.034 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.5681e-02 (3.1786e-02)	Acc@1 100.00 ( 98.92)	Acc@5 100.00 (100.00)
Epoch: [70][210/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.5877e-02 (3.1472e-02)	Acc@1  99.22 ( 98.92)	Acc@5 100.00 (100.00)
Epoch: [70][220/391]	Time  0.029 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.8395e-02 (3.1829e-02)	Acc@1  99.22 ( 98.93)	Acc@5 100.00 (100.00)
Epoch: [70][230/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 4.1135e-02 (3.2038e-02)	Acc@1  97.66 ( 98.91)	Acc@5 100.00 (100.00)
Epoch: [70][240/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.002)	Loss 4.7324e-02 (3.1864e-02)	Acc@1  99.22 ( 98.93)	Acc@5 100.00 (100.00)
Epoch: [70][250/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.1209e-02 (3.1631e-02)	Acc@1 100.00 ( 98.94)	Acc@5 100.00 (100.00)
Epoch: [70][260/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 3.1951e-02 (3.1642e-02)	Acc@1  99.22 ( 98.94)	Acc@5 100.00 (100.00)
Epoch: [70][270/391]	Time  0.035 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.0535e-02 (3.1351e-02)	Acc@1 100.00 ( 98.95)	Acc@5 100.00 (100.00)
Epoch: [70][280/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.002)	Loss 7.4772e-02 (3.1481e-02)	Acc@1  99.22 ( 98.96)	Acc@5 100.00 (100.00)
Epoch: [70][290/391]	Time  0.033 ( 0.033)	Data  0.001 ( 0.002)	Loss 3.2809e-02 (3.1460e-02)	Acc@1  98.44 ( 98.96)	Acc@5 100.00 (100.00)
Epoch: [70][300/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.002)	Loss 7.2162e-02 (3.1284e-02)	Acc@1  96.09 ( 98.96)	Acc@5 100.00 (100.00)
Epoch: [70][310/391]	Time  0.035 ( 0.033)	Data  0.001 ( 0.002)	Loss 4.2565e-02 (3.1148e-02)	Acc@1  98.44 ( 98.96)	Acc@5 100.00 (100.00)
Epoch: [70][320/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.3138e-02 (3.1303e-02)	Acc@1  99.22 ( 98.95)	Acc@5 100.00 (100.00)
Epoch: [70][330/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 9.7431e-03 (3.1203e-02)	Acc@1  99.22 ( 98.95)	Acc@5 100.00 (100.00)
Epoch: [70][340/391]	Time  0.033 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.4814e-02 (3.0976e-02)	Acc@1  99.22 ( 98.96)	Acc@5 100.00 (100.00)
Epoch: [70][350/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.002)	Loss 8.3832e-03 (3.1213e-02)	Acc@1 100.00 ( 98.96)	Acc@5 100.00 (100.00)
Epoch: [70][360/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.001)	Loss 1.5548e-02 (3.1184e-02)	Acc@1  99.22 ( 98.95)	Acc@5 100.00 (100.00)
Epoch: [70][370/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.001)	Loss 2.9065e-02 (3.1026e-02)	Acc@1  99.22 ( 98.96)	Acc@5 100.00 (100.00)
Epoch: [70][380/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.001)	Loss 4.4382e-02 (3.0911e-02)	Acc@1  98.44 ( 98.96)	Acc@5 100.00 (100.00)
Epoch: [70][390/391]	Time  0.020 ( 0.033)	Data  0.001 ( 0.001)	Loss 4.2819e-03 (3.0869e-02)	Acc@1 100.00 ( 98.97)	Acc@5 100.00 (100.00)
## e[70] optimizer.zero_grad (sum) time: 0.11188745498657227
## e[70]       loss.backward (sum) time: 2.917830228805542
## e[70]      optimizer.step (sum) time: 0.7995607852935791
## epoch[70] training(only) time: 12.868181467056274
# Switched to evaluate mode...
Test: [  0/100]	Time  0.181 ( 0.181)	Loss 2.0469e-01 (2.0469e-01)	Acc@1  95.00 ( 95.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.018 ( 0.034)	Loss 5.0765e-01 (3.4739e-01)	Acc@1  90.00 ( 91.82)	Acc@5 100.00 (100.00)
Test: [ 20/100]	Time  0.021 ( 0.028)	Loss 3.2799e-01 (3.8000e-01)	Acc@1  88.00 ( 91.10)	Acc@5 100.00 ( 99.71)
Test: [ 30/100]	Time  0.017 ( 0.026)	Loss 5.0589e-01 (4.1235e-01)	Acc@1  90.00 ( 90.97)	Acc@5  98.00 ( 99.61)
Test: [ 40/100]	Time  0.022 ( 0.025)	Loss 3.9142e-01 (4.2321e-01)	Acc@1  91.00 ( 90.93)	Acc@5 100.00 ( 99.63)
Test: [ 50/100]	Time  0.024 ( 0.024)	Loss 1.5073e-01 (4.1373e-01)	Acc@1  95.00 ( 91.16)	Acc@5 100.00 ( 99.67)
Test: [ 60/100]	Time  0.023 ( 0.023)	Loss 4.7214e-01 (3.9870e-01)	Acc@1  92.00 ( 91.23)	Acc@5  99.00 ( 99.67)
Test: [ 70/100]	Time  0.021 ( 0.023)	Loss 4.7017e-01 (3.8725e-01)	Acc@1  88.00 ( 91.31)	Acc@5 100.00 ( 99.69)
Test: [ 80/100]	Time  0.022 ( 0.023)	Loss 2.3309e-01 (3.8005e-01)	Acc@1  94.00 ( 91.36)	Acc@5 100.00 ( 99.70)
Test: [ 90/100]	Time  0.022 ( 0.023)	Loss 2.9702e-01 (3.8579e-01)	Acc@1  94.00 ( 91.29)	Acc@5 100.00 ( 99.74)
 * Acc@1 91.240 Acc@5 99.750
### epoch[70] execution time: 15.22195315361023
EPOCH 71
REMOVING: module.fire6.expand_3x3.1.weight
REMOVING: module.fire6.expand_3x3.1.bias
i:   0, name:  module.fire7.squeeze.0.weight  changing lr from: 0.001087548957361666   to: 0.001005739167342089
i:   1, name:    module.fire7.squeeze.0.bias  changing lr from: 0.001154742020994247   to: 0.001030515493733146
i:   2, name:  module.fire7.squeeze.1.weight  changing lr from: 0.001240100641222196   to: 0.001074401537419799
i:   3, name:    module.fire7.squeeze.1.bias  changing lr from: 0.001343128189623249   to: 0.001136897016397869
i:   4, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.001463333366465174   to: 0.001217506196283401
i:   5, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.001600230470163127   to: 0.001315738209514527
i:   6, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.001753339643070189   to: 0.001431107348879439
i:   7, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.001922187094761551   to: 0.001563133336580263
i:   8, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.002106305303933475   to: 0.001711341570004048
i:   9, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.002305233199998751   to: 0.001875263345333310
i:  10, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.002518516325422137   to: 0.002054436060090497
i:  11, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.002745706979800721   to: 0.002248403395672892
i:  12, name:  module.fire8.squeeze.0.weight  changing lr from: 0.002986364346657399   to: 0.002456715480897148
i:  13, name:    module.fire8.squeeze.0.bias  changing lr from: 0.003240054603878377   to: 0.002678929037535787
i:  14, name:  module.fire8.squeeze.1.weight  changing lr from: 0.003506351018690340   to: 0.002914607508792116
i:  15, name:    module.fire8.squeeze.1.bias  changing lr from: 0.003784834028037264   to: 0.003163321171624266
i:  16, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.004075091305182654   to: 0.003424647233794231
i:  17, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.004376717813329905   to: 0.003698169916484167
i:  18, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.004689315847020197   to: 0.003983480523288279
i:  19, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.005012495062036043   to: 0.004280177496356812
i:  20, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.005345872494507608   to: 0.004587866460436351
i:  21, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.005689072569888814   to: 0.004906160255520474
i:  22, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.006041727102441241   to: 0.005234678958794042
i:  23, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.006403475285835530   to: 0.005573049896525994
i:  24, name:  module.fire9.squeeze.0.weight  changing lr from: 0.006773963675452826   to: 0.005920907646536588
i:  25, name:    module.fire9.squeeze.0.bias  changing lr from: 0.007152846162941911   to: 0.006277894031837993
i:  26, name:  module.fire9.squeeze.1.weight  changing lr from: 0.007539783943562744   to: 0.006643658106020350
i:  27, name:    module.fire9.squeeze.1.bias  changing lr from: 0.007934445476821751   to: 0.007017856130929578
i:  28, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.008336506440880707   to: 0.007400151547158551
i:  29, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.008745649681197931   to: 0.007790214937848899
i:  30, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.009161565153838373   to: 0.008187723986277429
i:  31, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.009583949863867430   to: 0.008592363427679044
i:  32, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.010012507799223296   to: 0.009003824995735831
i:  33, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.010446949860442489   to: 0.009421807364141683
i:  34, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.010886993786593736   to: 0.009846016083630994
i:  35, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.011332364077758138   to: 0.010276163514841414
i:  36, name:           module.conv10.weight  changing lr from: 0.011782791914374820   to: 0.010711968757361395
i:  37, name:             module.conv10.bias  changing lr from: 0.012238015073755000   to: 0.011153157575295593



# Switched to train mode...
Epoch: [71][  0/391]	Time  0.196 ( 0.196)	Data  0.159 ( 0.159)	Loss 1.6425e-02 (1.6425e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [71][ 10/391]	Time  0.031 ( 0.048)	Data  0.001 ( 0.015)	Loss 4.3100e-02 (2.2118e-02)	Acc@1  98.44 ( 99.36)	Acc@5 100.00 (100.00)
Epoch: [71][ 20/391]	Time  0.033 ( 0.040)	Data  0.001 ( 0.009)	Loss 1.7161e-02 (2.5001e-02)	Acc@1  99.22 ( 99.29)	Acc@5 100.00 (100.00)
Epoch: [71][ 30/391]	Time  0.031 ( 0.038)	Data  0.001 ( 0.006)	Loss 1.2965e-02 (2.8443e-02)	Acc@1 100.00 ( 99.24)	Acc@5 100.00 (100.00)
Epoch: [71][ 40/391]	Time  0.033 ( 0.036)	Data  0.001 ( 0.005)	Loss 2.5209e-02 (2.8041e-02)	Acc@1  99.22 ( 99.18)	Acc@5 100.00 (100.00)
Epoch: [71][ 50/391]	Time  0.036 ( 0.035)	Data  0.001 ( 0.004)	Loss 1.7778e-02 (2.8392e-02)	Acc@1 100.00 ( 99.19)	Acc@5 100.00 (100.00)
Epoch: [71][ 60/391]	Time  0.032 ( 0.035)	Data  0.001 ( 0.004)	Loss 1.5353e-02 (2.8316e-02)	Acc@1 100.00 ( 99.18)	Acc@5 100.00 (100.00)
Epoch: [71][ 70/391]	Time  0.032 ( 0.034)	Data  0.001 ( 0.003)	Loss 1.6788e-02 (2.8690e-02)	Acc@1  99.22 ( 99.17)	Acc@5 100.00 (100.00)
Epoch: [71][ 80/391]	Time  0.033 ( 0.034)	Data  0.001 ( 0.003)	Loss 1.2714e-02 (2.9811e-02)	Acc@1 100.00 ( 99.16)	Acc@5 100.00 (100.00)
Epoch: [71][ 90/391]	Time  0.031 ( 0.034)	Data  0.001 ( 0.003)	Loss 2.8986e-02 (3.0227e-02)	Acc@1  99.22 ( 99.14)	Acc@5 100.00 (100.00)
Epoch: [71][100/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.003)	Loss 2.8277e-02 (3.1138e-02)	Acc@1  97.66 ( 99.07)	Acc@5 100.00 (100.00)
Epoch: [71][110/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.0047e-02 (3.1400e-02)	Acc@1 100.00 ( 99.05)	Acc@5 100.00 (100.00)
Epoch: [71][120/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 3.0773e-02 (3.1623e-02)	Acc@1  98.44 ( 99.02)	Acc@5 100.00 (100.00)
Epoch: [71][130/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 8.4157e-03 (3.1610e-02)	Acc@1 100.00 ( 99.00)	Acc@5 100.00 (100.00)
Epoch: [71][140/391]	Time  0.035 ( 0.033)	Data  0.001 ( 0.002)	Loss 8.9739e-03 (3.1370e-02)	Acc@1 100.00 ( 99.00)	Acc@5 100.00 (100.00)
Epoch: [71][150/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.8616e-02 (3.1262e-02)	Acc@1 100.00 ( 98.99)	Acc@5 100.00 (100.00)
Epoch: [71][160/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.0172e-02 (3.1143e-02)	Acc@1  99.22 ( 98.99)	Acc@5 100.00 (100.00)
Epoch: [71][170/391]	Time  0.039 ( 0.033)	Data  0.002 ( 0.002)	Loss 8.0041e-03 (3.1012e-02)	Acc@1 100.00 ( 98.99)	Acc@5 100.00 (100.00)
Epoch: [71][180/391]	Time  0.041 ( 0.033)	Data  0.001 ( 0.002)	Loss 3.4944e-02 (3.1323e-02)	Acc@1  98.44 ( 98.97)	Acc@5 100.00 (100.00)
Epoch: [71][190/391]	Time  0.036 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.5421e-02 (3.1527e-02)	Acc@1 100.00 ( 98.95)	Acc@5 100.00 (100.00)
Epoch: [71][200/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.0275e-02 (3.1378e-02)	Acc@1 100.00 ( 98.99)	Acc@5 100.00 (100.00)
Epoch: [71][210/391]	Time  0.034 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.9419e-02 (3.1349e-02)	Acc@1  99.22 ( 98.99)	Acc@5 100.00 (100.00)
Epoch: [71][220/391]	Time  0.033 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.0887e-02 (3.1427e-02)	Acc@1  99.22 ( 98.99)	Acc@5 100.00 (100.00)
Epoch: [71][230/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 6.1489e-02 (3.1691e-02)	Acc@1  98.44 ( 99.00)	Acc@5 100.00 (100.00)
Epoch: [71][240/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 7.8131e-02 (3.1849e-02)	Acc@1  96.88 ( 98.99)	Acc@5 100.00 (100.00)
Epoch: [71][250/391]	Time  0.033 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.4635e-02 (3.1806e-02)	Acc@1 100.00 ( 98.99)	Acc@5 100.00 (100.00)
Epoch: [71][260/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 3.7268e-02 (3.1583e-02)	Acc@1  99.22 ( 99.01)	Acc@5 100.00 (100.00)
Epoch: [71][270/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 6.1550e-02 (3.1900e-02)	Acc@1  99.22 ( 99.01)	Acc@5 100.00 (100.00)
Epoch: [71][280/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.5506e-02 (3.1635e-02)	Acc@1 100.00 ( 99.03)	Acc@5 100.00 (100.00)
Epoch: [71][290/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.9602e-02 (3.1708e-02)	Acc@1  99.22 ( 99.02)	Acc@5 100.00 (100.00)
Epoch: [71][300/391]	Time  0.034 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.0265e-02 (3.1395e-02)	Acc@1 100.00 ( 99.02)	Acc@5 100.00 (100.00)
Epoch: [71][310/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.002)	Loss 9.3942e-03 (3.1650e-02)	Acc@1 100.00 ( 99.02)	Acc@5 100.00 (100.00)
Epoch: [71][320/391]	Time  0.031 ( 0.032)	Data  0.001 ( 0.002)	Loss 3.7341e-02 (3.1516e-02)	Acc@1  98.44 ( 99.02)	Acc@5 100.00 (100.00)
Epoch: [71][330/391]	Time  0.033 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.3058e-02 (3.1469e-02)	Acc@1 100.00 ( 99.03)	Acc@5 100.00 (100.00)
Epoch: [71][340/391]	Time  0.031 ( 0.032)	Data  0.001 ( 0.002)	Loss 9.3022e-03 (3.1431e-02)	Acc@1 100.00 ( 99.03)	Acc@5 100.00 (100.00)
Epoch: [71][350/391]	Time  0.032 ( 0.032)	Data  0.001 ( 0.001)	Loss 6.5092e-02 (3.1594e-02)	Acc@1  97.66 ( 99.02)	Acc@5 100.00 (100.00)
Epoch: [71][360/391]	Time  0.034 ( 0.032)	Data  0.001 ( 0.001)	Loss 2.0157e-02 (3.1519e-02)	Acc@1  99.22 ( 99.00)	Acc@5 100.00 (100.00)
Epoch: [71][370/391]	Time  0.032 ( 0.032)	Data  0.001 ( 0.001)	Loss 6.2613e-02 (3.1684e-02)	Acc@1  98.44 ( 98.99)	Acc@5 100.00 (100.00)
Epoch: [71][380/391]	Time  0.031 ( 0.032)	Data  0.001 ( 0.001)	Loss 4.5935e-02 (3.1603e-02)	Acc@1  97.66 ( 99.00)	Acc@5 100.00 (100.00)
Epoch: [71][390/391]	Time  0.022 ( 0.032)	Data  0.001 ( 0.001)	Loss 5.1865e-02 (3.1615e-02)	Acc@1  98.75 ( 99.00)	Acc@5 100.00 (100.00)
## e[71] optimizer.zero_grad (sum) time: 0.1069650650024414
## e[71]       loss.backward (sum) time: 2.8137853145599365
## e[71]      optimizer.step (sum) time: 0.7886579036712646
## epoch[71] training(only) time: 12.750468254089355
# Switched to evaluate mode...
Test: [  0/100]	Time  0.165 ( 0.165)	Loss 1.9187e-01 (1.9187e-01)	Acc@1  95.00 ( 95.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.018 ( 0.034)	Loss 5.3244e-01 (3.5340e-01)	Acc@1  89.00 ( 91.91)	Acc@5 100.00 ( 99.82)
Test: [ 20/100]	Time  0.025 ( 0.028)	Loss 3.4651e-01 (3.8642e-01)	Acc@1  89.00 ( 91.29)	Acc@5 100.00 ( 99.62)
Test: [ 30/100]	Time  0.024 ( 0.026)	Loss 4.8646e-01 (4.1181e-01)	Acc@1  88.00 ( 91.06)	Acc@5  98.00 ( 99.55)
Test: [ 40/100]	Time  0.018 ( 0.024)	Loss 3.9043e-01 (4.2139e-01)	Acc@1  88.00 ( 90.80)	Acc@5 100.00 ( 99.54)
Test: [ 50/100]	Time  0.021 ( 0.023)	Loss 1.4607e-01 (4.1427e-01)	Acc@1  96.00 ( 91.04)	Acc@5 100.00 ( 99.57)
Test: [ 60/100]	Time  0.024 ( 0.023)	Loss 5.0718e-01 (4.0040e-01)	Acc@1  92.00 ( 91.13)	Acc@5  99.00 ( 99.61)
Test: [ 70/100]	Time  0.023 ( 0.023)	Loss 4.4794e-01 (3.8913e-01)	Acc@1  90.00 ( 91.28)	Acc@5 100.00 ( 99.65)
Test: [ 80/100]	Time  0.017 ( 0.022)	Loss 1.8366e-01 (3.8097e-01)	Acc@1  95.00 ( 91.35)	Acc@5 100.00 ( 99.67)
Test: [ 90/100]	Time  0.019 ( 0.022)	Loss 2.6553e-01 (3.8563e-01)	Acc@1  95.00 ( 91.26)	Acc@5 100.00 ( 99.69)
 * Acc@1 91.220 Acc@5 99.690
### epoch[71] execution time: 15.083420276641846
EPOCH 72
REMOVING: module.fire7.squeeze.0.weight
REMOVING: module.fire7.squeeze.0.bias
i:   0, name:  module.fire7.squeeze.1.weight  changing lr from: 0.001074401537419799   to: 0.001003069530313571
i:   1, name:    module.fire7.squeeze.1.bias  changing lr from: 0.001136897016397869   to: 0.001023730732969574
i:   2, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.001217506196283401   to: 0.001063428588839609
i:   3, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.001315738209514527   to: 0.001121668857547208
i:   4, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.001431107348879439   to: 0.001197961691925286
i:   5, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.001563133336580263   to: 0.001291821955445720
i:   6, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.001711341570004048   to: 0.001402769514421103
i:   7, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.001875263345333310   to: 0.001530329506157884
i:   8, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.002054436060090497   to: 0.001674032584202994
i:   9, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.002248403395672892   to: 0.001833415141788557
i:  10, name:  module.fire8.squeeze.0.weight  changing lr from: 0.002456715480897148   to: 0.002008019514542663
i:  11, name:    module.fire8.squeeze.0.bias  changing lr from: 0.002678929037535787   to: 0.002197394163497334
i:  12, name:  module.fire8.squeeze.1.weight  changing lr from: 0.002914607508792116   to: 0.002401093839389167
i:  13, name:    module.fire8.squeeze.1.bias  changing lr from: 0.003163321171624266   to: 0.002618679729212130
i:  14, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.003424647233794231   to: 0.002849719585947285
i:  15, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.003698169916484167   to: 0.003093787842359857
i:  16, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.003983480523288279   to: 0.003350465709720218
i:  17, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.004280177496356812   to: 0.003619341262272474
i:  18, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.004587866460436351   to: 0.003900009508242085
i:  19, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.004906160255520474   to: 0.004192072448142386
i:  20, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.005234678958794042   to: 0.004495139121109131
i:  21, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.005573049896525994   to: 0.004808825639962443
i:  22, name:  module.fire9.squeeze.0.weight  changing lr from: 0.005920907646536588   to: 0.005132755215666017
i:  23, name:    module.fire9.squeeze.0.bias  changing lr from: 0.006277894031837993   to: 0.005466558171825502
i:  24, name:  module.fire9.squeeze.1.weight  changing lr from: 0.006643658106020350   to: 0.005809871949840211
i:  25, name:    module.fire9.squeeze.1.bias  changing lr from: 0.007017856130929578   to: 0.006162341105295754
i:  26, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.007400151547158551   to: 0.006523617296159189
i:  27, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.007790214937848899   to: 0.006893359263313258
i:  28, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.008187723986277429   to: 0.007271232803942090
i:  29, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.008592363427679044   to: 0.007656910738257094
i:  30, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.009003824995735831   to: 0.008050072870029379
i:  31, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.009421807364141683   to: 0.008450405941372785
i:  32, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.009846016083630994   to: 0.008857603582200752
i:  33, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.010276163514841414   to: 0.009271366254759737
i:  34, name:           module.conv10.weight  changing lr from: 0.010711968757361395   to: 0.009691401193622412
i:  35, name:             module.conv10.bias  changing lr from: 0.011153157575295593   to: 0.010117422341504662



# Switched to train mode...
Epoch: [72][  0/391]	Time  0.207 ( 0.207)	Data  0.170 ( 0.170)	Loss 5.2109e-02 (5.2109e-02)	Acc@1  97.66 ( 97.66)	Acc@5 100.00 (100.00)
Epoch: [72][ 10/391]	Time  0.031 ( 0.047)	Data  0.001 ( 0.016)	Loss 3.2571e-02 (2.5968e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [72][ 20/391]	Time  0.031 ( 0.040)	Data  0.001 ( 0.009)	Loss 5.2334e-02 (2.7678e-02)	Acc@1  98.44 ( 99.07)	Acc@5 100.00 (100.00)
Epoch: [72][ 30/391]	Time  0.043 ( 0.038)	Data  0.001 ( 0.006)	Loss 2.3959e-02 (2.9865e-02)	Acc@1  99.22 ( 98.97)	Acc@5 100.00 (100.00)
Epoch: [72][ 40/391]	Time  0.031 ( 0.036)	Data  0.001 ( 0.005)	Loss 4.8885e-02 (3.0306e-02)	Acc@1  98.44 ( 98.95)	Acc@5 100.00 (100.00)
Epoch: [72][ 50/391]	Time  0.032 ( 0.035)	Data  0.001 ( 0.004)	Loss 3.8140e-02 (2.9883e-02)	Acc@1  97.66 ( 98.94)	Acc@5 100.00 (100.00)
Epoch: [72][ 60/391]	Time  0.031 ( 0.035)	Data  0.001 ( 0.004)	Loss 2.3000e-02 (2.8712e-02)	Acc@1  99.22 ( 98.99)	Acc@5 100.00 (100.00)
Epoch: [72][ 70/391]	Time  0.031 ( 0.034)	Data  0.001 ( 0.003)	Loss 2.1849e-02 (2.9204e-02)	Acc@1 100.00 ( 99.02)	Acc@5 100.00 (100.00)
Epoch: [72][ 80/391]	Time  0.031 ( 0.034)	Data  0.001 ( 0.003)	Loss 1.0393e-02 (2.8304e-02)	Acc@1 100.00 ( 99.05)	Acc@5 100.00 (100.00)
Epoch: [72][ 90/391]	Time  0.031 ( 0.034)	Data  0.001 ( 0.003)	Loss 4.3847e-02 (2.9841e-02)	Acc@1  98.44 ( 98.99)	Acc@5 100.00 (100.00)
Epoch: [72][100/391]	Time  0.033 ( 0.033)	Data  0.001 ( 0.003)	Loss 7.2834e-02 (3.0755e-02)	Acc@1  97.66 ( 98.96)	Acc@5 100.00 (100.00)
Epoch: [72][110/391]	Time  0.036 ( 0.033)	Data  0.001 ( 0.003)	Loss 1.7963e-02 (3.0559e-02)	Acc@1 100.00 ( 98.97)	Acc@5 100.00 (100.00)
Epoch: [72][120/391]	Time  0.034 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.4438e-02 (3.0102e-02)	Acc@1  99.22 ( 99.01)	Acc@5 100.00 (100.00)
Epoch: [72][130/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.6284e-02 (3.0085e-02)	Acc@1  99.22 ( 99.02)	Acc@5 100.00 (100.00)
Epoch: [72][140/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.4826e-02 (2.9910e-02)	Acc@1 100.00 ( 99.05)	Acc@5 100.00 (100.00)
Epoch: [72][150/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 4.4342e-02 (2.9878e-02)	Acc@1  99.22 ( 99.06)	Acc@5 100.00 (100.00)
Epoch: [72][160/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.6223e-02 (3.0391e-02)	Acc@1  99.22 ( 99.04)	Acc@5 100.00 (100.00)
Epoch: [72][170/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.2694e-02 (2.9840e-02)	Acc@1  99.22 ( 99.07)	Acc@5 100.00 (100.00)
Epoch: [72][180/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 4.7194e-02 (3.0071e-02)	Acc@1  98.44 ( 99.07)	Acc@5 100.00 (100.00)
Epoch: [72][190/391]	Time  0.038 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.1239e-02 (2.9777e-02)	Acc@1 100.00 ( 99.08)	Acc@5 100.00 (100.00)
Epoch: [72][200/391]	Time  0.030 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.5107e-02 (2.9832e-02)	Acc@1  99.22 ( 99.08)	Acc@5 100.00 (100.00)
Epoch: [72][210/391]	Time  0.034 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.1943e-02 (3.0153e-02)	Acc@1 100.00 ( 99.07)	Acc@5 100.00 (100.00)
Epoch: [72][220/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 4.6031e-02 (3.0755e-02)	Acc@1  97.66 ( 99.05)	Acc@5 100.00 (100.00)
Epoch: [72][230/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.7801e-02 (3.0408e-02)	Acc@1  99.22 ( 99.07)	Acc@5 100.00 (100.00)
Epoch: [72][240/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.9820e-02 (3.0140e-02)	Acc@1  99.22 ( 99.08)	Acc@5 100.00 (100.00)
Epoch: [72][250/391]	Time  0.031 ( 0.032)	Data  0.001 ( 0.002)	Loss 4.3837e-02 (3.0480e-02)	Acc@1  99.22 ( 99.06)	Acc@5 100.00 (100.00)
Epoch: [72][260/391]	Time  0.035 ( 0.032)	Data  0.001 ( 0.002)	Loss 6.3734e-02 (3.0323e-02)	Acc@1  97.66 ( 99.07)	Acc@5 100.00 (100.00)
Epoch: [72][270/391]	Time  0.033 ( 0.032)	Data  0.001 ( 0.002)	Loss 7.7364e-03 (3.0244e-02)	Acc@1 100.00 ( 99.06)	Acc@5 100.00 (100.00)
Epoch: [72][280/391]	Time  0.031 ( 0.032)	Data  0.001 ( 0.002)	Loss 8.1017e-02 (3.0369e-02)	Acc@1  96.88 ( 99.06)	Acc@5 100.00 (100.00)
Epoch: [72][290/391]	Time  0.032 ( 0.032)	Data  0.001 ( 0.002)	Loss 3.8939e-02 (3.0276e-02)	Acc@1  98.44 ( 99.05)	Acc@5 100.00 (100.00)
Epoch: [72][300/391]	Time  0.031 ( 0.032)	Data  0.001 ( 0.002)	Loss 3.3111e-02 (3.0476e-02)	Acc@1  98.44 ( 99.04)	Acc@5 100.00 (100.00)
Epoch: [72][310/391]	Time  0.031 ( 0.032)	Data  0.001 ( 0.002)	Loss 8.5117e-03 (3.0415e-02)	Acc@1 100.00 ( 99.05)	Acc@5 100.00 (100.00)
Epoch: [72][320/391]	Time  0.033 ( 0.032)	Data  0.001 ( 0.002)	Loss 6.4651e-02 (3.0566e-02)	Acc@1  97.66 ( 99.04)	Acc@5 100.00 (100.00)
Epoch: [72][330/391]	Time  0.031 ( 0.032)	Data  0.001 ( 0.002)	Loss 3.2339e-02 (3.0595e-02)	Acc@1  99.22 ( 99.04)	Acc@5 100.00 (100.00)
Epoch: [72][340/391]	Time  0.040 ( 0.032)	Data  0.001 ( 0.002)	Loss 3.2832e-02 (3.0907e-02)	Acc@1  99.22 ( 99.04)	Acc@5 100.00 (100.00)
Epoch: [72][350/391]	Time  0.031 ( 0.032)	Data  0.001 ( 0.002)	Loss 3.1900e-02 (3.0912e-02)	Acc@1  99.22 ( 99.04)	Acc@5 100.00 (100.00)
Epoch: [72][360/391]	Time  0.032 ( 0.032)	Data  0.001 ( 0.002)	Loss 4.0253e-02 (3.1264e-02)	Acc@1  98.44 ( 99.02)	Acc@5 100.00 (100.00)
Epoch: [72][370/391]	Time  0.036 ( 0.032)	Data  0.001 ( 0.001)	Loss 1.1394e-02 (3.1215e-02)	Acc@1 100.00 ( 99.02)	Acc@5 100.00 (100.00)
Epoch: [72][380/391]	Time  0.031 ( 0.032)	Data  0.001 ( 0.001)	Loss 1.9634e-02 (3.1200e-02)	Acc@1 100.00 ( 99.02)	Acc@5 100.00 (100.00)
Epoch: [72][390/391]	Time  0.022 ( 0.032)	Data  0.001 ( 0.001)	Loss 8.9420e-02 (3.1361e-02)	Acc@1  98.75 ( 99.02)	Acc@5 100.00 (100.00)
## e[72] optimizer.zero_grad (sum) time: 0.10259580612182617
## e[72]       loss.backward (sum) time: 2.748504161834717
## e[72]      optimizer.step (sum) time: 0.7593133449554443
## epoch[72] training(only) time: 12.732909202575684
# Switched to evaluate mode...
Test: [  0/100]	Time  0.163 ( 0.163)	Loss 1.7548e-01 (1.7548e-01)	Acc@1  94.00 ( 94.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.021 ( 0.034)	Loss 4.9344e-01 (3.3394e-01)	Acc@1  88.00 ( 92.00)	Acc@5 100.00 ( 99.91)
Test: [ 20/100]	Time  0.018 ( 0.027)	Loss 3.4912e-01 (3.7212e-01)	Acc@1  88.00 ( 91.24)	Acc@5 100.00 ( 99.67)
Test: [ 30/100]	Time  0.024 ( 0.025)	Loss 4.8688e-01 (4.0299e-01)	Acc@1  90.00 ( 91.29)	Acc@5  98.00 ( 99.61)
Test: [ 40/100]	Time  0.022 ( 0.024)	Loss 3.9961e-01 (4.1614e-01)	Acc@1  89.00 ( 91.20)	Acc@5 100.00 ( 99.61)
Test: [ 50/100]	Time  0.022 ( 0.024)	Loss 1.3884e-01 (4.0767e-01)	Acc@1  94.00 ( 91.29)	Acc@5 100.00 ( 99.63)
Test: [ 60/100]	Time  0.019 ( 0.023)	Loss 5.1186e-01 (3.9539e-01)	Acc@1  93.00 ( 91.34)	Acc@5  99.00 ( 99.66)
Test: [ 70/100]	Time  0.017 ( 0.022)	Loss 4.4714e-01 (3.8512e-01)	Acc@1  89.00 ( 91.38)	Acc@5 100.00 ( 99.69)
Test: [ 80/100]	Time  0.019 ( 0.022)	Loss 2.0752e-01 (3.7741e-01)	Acc@1  95.00 ( 91.46)	Acc@5 100.00 ( 99.72)
Test: [ 90/100]	Time  0.024 ( 0.022)	Loss 2.6438e-01 (3.8428e-01)	Acc@1  95.00 ( 91.41)	Acc@5 100.00 ( 99.74)
 * Acc@1 91.350 Acc@5 99.750
### epoch[72] execution time: 15.027037143707275
EPOCH 73
REMOVING: module.fire7.squeeze.1.weight
REMOVING: module.fire7.squeeze.1.bias
i:   0, name: module.fire7.expand_1x1.0.weight  changing lr from: 0.001063428588839609   to: 0.001001384510484820
i:   1, name: module.fire7.expand_1x1.0.bias  changing lr from: 0.001121668857547208   to: 0.001018375610920601
i:   2, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.001197961691925286   to: 0.001054321688277159
i:   3, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.001291821955445720   to: 0.001108734484818834
i:   4, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.001402769514421103   to: 0.001181129993004647
i:   5, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.001530329506157884   to: 0.001271028770646153
i:   6, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.001674032584202994   to: 0.001377956231293325
i:   7, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.001833415141788557   to: 0.001501442910997702
i:   8, name:  module.fire8.squeeze.0.weight  changing lr from: 0.002008019514542663   to: 0.001641024712565863
i:   9, name:    module.fire8.squeeze.0.bias  changing lr from: 0.002197394163497334   to: 0.001796243128380636
i:  10, name:  module.fire8.squeeze.1.weight  changing lr from: 0.002401093839389167   to: 0.001966645442831493
i:  11, name:    module.fire8.squeeze.1.bias  changing lr from: 0.002618679729212130   to: 0.002151784915360637
i:  12, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.002849719585947285   to: 0.002351220945095966
i:  13, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.003093787842359857   to: 0.002564519218008326
i:  14, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.003350465709720218   to: 0.002791251837495888
i:  15, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.003619341262272474   to: 0.003030997439265958
i:  16, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.003900009508242085   to: 0.003283341291351177
i:  17, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.004192072448142386   to: 0.003547875380065917
i:  18, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.004495139121109131   to: 0.003824198482676394
i:  19, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.004808825639962443   to: 0.004111916227528572
i:  20, name:  module.fire9.squeeze.0.weight  changing lr from: 0.005132755215666017   to: 0.004410641142347165
i:  21, name:    module.fire9.squeeze.0.bias  changing lr from: 0.005466558171825502   to: 0.004719992691390578
i:  22, name:  module.fire9.squeeze.1.weight  changing lr from: 0.005809871949840211   to: 0.005039597302118093
i:  23, name:    module.fire9.squeeze.1.bias  changing lr from: 0.006162341105295754   to: 0.005369088381998127
i:  24, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.006523617296159189   to: 0.005708106326059647
i:  25, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.006893359263313258   to: 0.006056298515762914
i:  26, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.007271232803942090   to: 0.006413319309740478
i:  27, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.007656910738257094   to: 0.006778830026934989
i:  28, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.008050072870029379   to: 0.007152498922636868
i:  29, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.008450405941372785   to: 0.007534001157901876
i:  30, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.008857603582200752   to: 0.007923018762806478
i:  31, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.009271366254759737   to: 0.008319240593977918
i:  32, name:           module.conv10.weight  changing lr from: 0.009691401193622412   to: 0.008722362286814977
i:  33, name:             module.conv10.bias  changing lr from: 0.010117422341504662   to: 0.009132086202795479



# Switched to train mode...
Epoch: [73][  0/391]	Time  0.210 ( 0.210)	Data  0.175 ( 0.175)	Loss 1.9315e-02 (1.9315e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [73][ 10/391]	Time  0.033 ( 0.048)	Data  0.001 ( 0.017)	Loss 2.8902e-02 (2.5783e-02)	Acc@1  99.22 ( 99.08)	Acc@5 100.00 (100.00)
Epoch: [73][ 20/391]	Time  0.032 ( 0.040)	Data  0.001 ( 0.009)	Loss 1.9043e-02 (2.9814e-02)	Acc@1  99.22 ( 98.88)	Acc@5 100.00 (100.00)
Epoch: [73][ 30/391]	Time  0.033 ( 0.037)	Data  0.001 ( 0.007)	Loss 1.5542e-02 (2.9507e-02)	Acc@1 100.00 ( 98.97)	Acc@5 100.00 (100.00)
Epoch: [73][ 40/391]	Time  0.031 ( 0.036)	Data  0.001 ( 0.005)	Loss 1.7309e-02 (3.0700e-02)	Acc@1 100.00 ( 98.89)	Acc@5 100.00 (100.00)
Epoch: [73][ 50/391]	Time  0.033 ( 0.035)	Data  0.001 ( 0.004)	Loss 2.7481e-02 (3.1112e-02)	Acc@1  98.44 ( 98.91)	Acc@5 100.00 (100.00)
Epoch: [73][ 60/391]	Time  0.031 ( 0.035)	Data  0.001 ( 0.004)	Loss 3.5353e-02 (3.1167e-02)	Acc@1  98.44 ( 98.94)	Acc@5 100.00 (100.00)
Epoch: [73][ 70/391]	Time  0.034 ( 0.034)	Data  0.001 ( 0.004)	Loss 2.6180e-02 (3.0864e-02)	Acc@1  99.22 ( 98.94)	Acc@5 100.00 (100.00)
Epoch: [73][ 80/391]	Time  0.034 ( 0.034)	Data  0.001 ( 0.003)	Loss 4.0053e-02 (3.0187e-02)	Acc@1  97.66 ( 98.96)	Acc@5 100.00 (100.00)
Epoch: [73][ 90/391]	Time  0.035 ( 0.034)	Data  0.001 ( 0.003)	Loss 4.2174e-02 (2.9388e-02)	Acc@1  98.44 ( 98.98)	Acc@5 100.00 (100.00)
Epoch: [73][100/391]	Time  0.030 ( 0.034)	Data  0.001 ( 0.003)	Loss 3.0589e-02 (2.8619e-02)	Acc@1  98.44 ( 99.00)	Acc@5 100.00 (100.00)
Epoch: [73][110/391]	Time  0.030 ( 0.033)	Data  0.001 ( 0.003)	Loss 8.1410e-03 (2.9181e-02)	Acc@1 100.00 ( 98.99)	Acc@5 100.00 (100.00)
Epoch: [73][120/391]	Time  0.030 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.3751e-02 (2.9341e-02)	Acc@1  99.22 ( 98.97)	Acc@5 100.00 (100.00)
Epoch: [73][130/391]	Time  0.030 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.2262e-02 (2.9393e-02)	Acc@1  99.22 ( 98.97)	Acc@5 100.00 (100.00)
Epoch: [73][140/391]	Time  0.036 ( 0.033)	Data  0.001 ( 0.002)	Loss 7.8505e-03 (2.9017e-02)	Acc@1 100.00 ( 98.97)	Acc@5 100.00 (100.00)
Epoch: [73][150/391]	Time  0.035 ( 0.033)	Data  0.001 ( 0.002)	Loss 3.9825e-02 (2.9272e-02)	Acc@1  99.22 ( 98.98)	Acc@5 100.00 (100.00)
Epoch: [73][160/391]	Time  0.034 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.2898e-02 (2.9202e-02)	Acc@1  99.22 ( 98.99)	Acc@5 100.00 (100.00)
Epoch: [73][170/391]	Time  0.030 ( 0.033)	Data  0.001 ( 0.002)	Loss 4.8915e-02 (2.8942e-02)	Acc@1  97.66 ( 99.00)	Acc@5 100.00 (100.00)
Epoch: [73][180/391]	Time  0.030 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.4161e-02 (2.8442e-02)	Acc@1  99.22 ( 99.02)	Acc@5 100.00 (100.00)
Epoch: [73][190/391]	Time  0.030 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.9415e-02 (2.8379e-02)	Acc@1 100.00 ( 99.05)	Acc@5 100.00 (100.00)
Epoch: [73][200/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.8374e-02 (2.8525e-02)	Acc@1  99.22 ( 99.03)	Acc@5 100.00 (100.00)
Epoch: [73][210/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 3.3522e-02 (2.8582e-02)	Acc@1  99.22 ( 99.04)	Acc@5 100.00 (100.00)
Epoch: [73][220/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 4.3182e-02 (2.8517e-02)	Acc@1  97.66 ( 99.06)	Acc@5 100.00 (100.00)
Epoch: [73][230/391]	Time  0.030 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.1409e-02 (2.8223e-02)	Acc@1 100.00 ( 99.08)	Acc@5 100.00 (100.00)
Epoch: [73][240/391]	Time  0.036 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.0021e-02 (2.8227e-02)	Acc@1  98.44 ( 99.08)	Acc@5 100.00 (100.00)
Epoch: [73][250/391]	Time  0.035 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.4602e-02 (2.8313e-02)	Acc@1 100.00 ( 99.08)	Acc@5 100.00 (100.00)
Epoch: [73][260/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.7293e-02 (2.8283e-02)	Acc@1  99.22 ( 99.08)	Acc@5 100.00 (100.00)
Epoch: [73][270/391]	Time  0.030 ( 0.033)	Data  0.001 ( 0.002)	Loss 5.4489e-02 (2.8217e-02)	Acc@1  98.44 ( 99.08)	Acc@5 100.00 (100.00)
Epoch: [73][280/391]	Time  0.035 ( 0.033)	Data  0.001 ( 0.002)	Loss 3.5310e-02 (2.8016e-02)	Acc@1  97.66 ( 99.09)	Acc@5 100.00 (100.00)
Epoch: [73][290/391]	Time  0.030 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.4188e-02 (2.8074e-02)	Acc@1  99.22 ( 99.09)	Acc@5 100.00 (100.00)
Epoch: [73][300/391]	Time  0.035 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.7831e-02 (2.8248e-02)	Acc@1  99.22 ( 99.08)	Acc@5 100.00 (100.00)
Epoch: [73][310/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.002)	Loss 8.4655e-02 (2.8609e-02)	Acc@1  96.88 ( 99.08)	Acc@5 100.00 (100.00)
Epoch: [73][320/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 3.2076e-02 (2.8456e-02)	Acc@1  99.22 ( 99.08)	Acc@5 100.00 (100.00)
Epoch: [73][330/391]	Time  0.033 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.3460e-02 (2.8713e-02)	Acc@1 100.00 ( 99.08)	Acc@5 100.00 (100.00)
Epoch: [73][340/391]	Time  0.030 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.4024e-02 (2.8493e-02)	Acc@1  99.22 ( 99.09)	Acc@5 100.00 (100.00)
Epoch: [73][350/391]	Time  0.030 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.1926e-02 (2.8808e-02)	Acc@1  99.22 ( 99.07)	Acc@5 100.00 (100.00)
Epoch: [73][360/391]	Time  0.034 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.3120e-02 (2.9007e-02)	Acc@1 100.00 ( 99.07)	Acc@5 100.00 (100.00)
Epoch: [73][370/391]	Time  0.033 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.7426e-02 (2.9196e-02)	Acc@1 100.00 ( 99.06)	Acc@5 100.00 (100.00)
Epoch: [73][380/391]	Time  0.030 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.0544e-02 (2.9223e-02)	Acc@1  99.22 ( 99.05)	Acc@5 100.00 (100.00)
Epoch: [73][390/391]	Time  0.022 ( 0.032)	Data  0.001 ( 0.001)	Loss 1.2877e-02 (2.9437e-02)	Acc@1 100.00 ( 99.05)	Acc@5 100.00 (100.00)
## e[73] optimizer.zero_grad (sum) time: 0.09619593620300293
## e[73]       loss.backward (sum) time: 2.5519309043884277
## e[73]      optimizer.step (sum) time: 0.7059614658355713
## epoch[73] training(only) time: 12.84732723236084
# Switched to evaluate mode...
Test: [  0/100]	Time  0.161 ( 0.161)	Loss 1.8122e-01 (1.8122e-01)	Acc@1  96.00 ( 96.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.024 ( 0.035)	Loss 5.4194e-01 (3.4907e-01)	Acc@1  88.00 ( 91.55)	Acc@5 100.00 (100.00)
Test: [ 20/100]	Time  0.021 ( 0.028)	Loss 3.8461e-01 (3.8372e-01)	Acc@1  87.00 ( 90.81)	Acc@5 100.00 ( 99.71)
Test: [ 30/100]	Time  0.024 ( 0.026)	Loss 4.7798e-01 (4.1102e-01)	Acc@1  89.00 ( 90.77)	Acc@5  98.00 ( 99.65)
Test: [ 40/100]	Time  0.018 ( 0.025)	Loss 3.9208e-01 (4.2481e-01)	Acc@1  90.00 ( 90.63)	Acc@5 100.00 ( 99.61)
Test: [ 50/100]	Time  0.023 ( 0.024)	Loss 1.6957e-01 (4.1704e-01)	Acc@1  94.00 ( 90.82)	Acc@5 100.00 ( 99.63)
Test: [ 60/100]	Time  0.020 ( 0.024)	Loss 4.5641e-01 (4.0039e-01)	Acc@1  93.00 ( 90.98)	Acc@5  99.00 ( 99.66)
Test: [ 70/100]	Time  0.018 ( 0.023)	Loss 4.7976e-01 (3.9046e-01)	Acc@1  89.00 ( 91.13)	Acc@5 100.00 ( 99.69)
Test: [ 80/100]	Time  0.017 ( 0.023)	Loss 2.2667e-01 (3.8242e-01)	Acc@1  95.00 ( 91.22)	Acc@5 100.00 ( 99.72)
Test: [ 90/100]	Time  0.018 ( 0.022)	Loss 3.0637e-01 (3.8868e-01)	Acc@1  94.00 ( 91.15)	Acc@5 100.00 ( 99.75)
 * Acc@1 91.180 Acc@5 99.750
### epoch[73] execution time: 15.149653196334839
EPOCH 74
REMOVING: module.fire7.expand_1x1.0.weight
REMOVING: module.fire7.expand_1x1.0.bias
i:   0, name: module.fire7.expand_1x1.1.weight  changing lr from: 0.001054321688277159   to: 0.001000445491874213
i:   1, name: module.fire7.expand_1x1.1.bias  changing lr from: 0.001108734484818834   to: 0.001014195875105333
i:   2, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.001181129993004647   to: 0.001046811488842940
i:   3, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.001271028770646153   to: 0.001097809994158216
i:   4, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.001377956231293325   to: 0.001166713170187582
i:   5, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.001501442910997702   to: 0.001253047226559294
i:   6, name:  module.fire8.squeeze.0.weight  changing lr from: 0.001641024712565863   to: 0.001356343091512007
i:   7, name:    module.fire8.squeeze.0.bias  changing lr from: 0.001796243128380636   to: 0.001476136676824973
i:   8, name:  module.fire8.squeeze.1.weight  changing lr from: 0.001966645442831493   to: 0.001611969120644568
i:   9, name:    module.fire8.squeeze.1.bias  changing lr from: 0.002151784915360637   to: 0.001763387009257405
i:  10, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.002351220945095966   to: 0.001929942578825466
i:  11, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.002564519218008326   to: 0.002111193898065144
i:  12, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.002791251837495888   to: 0.002306705032817740
i:  13, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.003030997439265958   to: 0.002516046193426279
i:  14, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.003283341291351177   to: 0.002738793865800231
i:  15, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.003547875380065917   to: 0.002974530927018076
i:  16, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.003824198482676394   to: 0.003222846746285440
i:  17, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.004111916227528572   to: 0.003483337272036129
i:  18, name:  module.fire9.squeeze.0.weight  changing lr from: 0.004410641142347165   to: 0.003755605105932696
i:  19, name:    module.fire9.squeeze.0.bias  changing lr from: 0.004719992691390578   to: 0.004039259564493585
i:  20, name:  module.fire9.squeeze.1.weight  changing lr from: 0.005039597302118093   to: 0.004333916729045217
i:  21, name:    module.fire9.squeeze.1.bias  changing lr from: 0.005369088381998127   to: 0.004639199484668921
i:  22, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.005708106326059647   to: 0.004954737548785315
i:  23, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.006056298515762914   to: 0.005280167489991715
i:  24, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.006413319309740478   to: 0.005615132737742789
i:  25, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.006778830026934989   to: 0.005959283583438673
i:  26, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.007152498922636868   to: 0.006312277173460934
i:  27, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.007534001157901876   to: 0.006673777494672717
i:  28, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.007923018762806478   to: 0.007043455352876360
i:  29, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.008319240593977918   to: 0.007420988344699868
i:  30, name:           module.conv10.weight  changing lr from: 0.008722362286814977   to: 0.007806060823361893
i:  31, name:             module.conv10.bias  changing lr from: 0.009132086202795479   to: 0.008198363858743906



# Switched to train mode...
Epoch: [74][  0/391]	Time  0.201 ( 0.201)	Data  0.167 ( 0.167)	Loss 5.0594e-02 (5.0594e-02)	Acc@1  97.66 ( 97.66)	Acc@5 100.00 (100.00)
Epoch: [74][ 10/391]	Time  0.033 ( 0.047)	Data  0.001 ( 0.016)	Loss 1.1996e-02 (3.5979e-02)	Acc@1 100.00 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [74][ 20/391]	Time  0.031 ( 0.040)	Data  0.002 ( 0.009)	Loss 1.0314e-02 (3.4621e-02)	Acc@1 100.00 ( 98.70)	Acc@5 100.00 (100.00)
Epoch: [74][ 30/391]	Time  0.032 ( 0.037)	Data  0.001 ( 0.006)	Loss 1.2847e-02 (3.1037e-02)	Acc@1 100.00 ( 98.87)	Acc@5 100.00 (100.00)
Epoch: [74][ 40/391]	Time  0.031 ( 0.036)	Data  0.001 ( 0.005)	Loss 2.1743e-02 (2.9106e-02)	Acc@1  98.44 ( 98.91)	Acc@5 100.00 (100.00)
Epoch: [74][ 50/391]	Time  0.031 ( 0.035)	Data  0.001 ( 0.004)	Loss 1.0744e-02 (2.8406e-02)	Acc@1 100.00 ( 98.93)	Acc@5 100.00 (100.00)
Epoch: [74][ 60/391]	Time  0.036 ( 0.035)	Data  0.001 ( 0.004)	Loss 3.8866e-02 (2.9456e-02)	Acc@1  98.44 ( 98.91)	Acc@5 100.00 (100.00)
Epoch: [74][ 70/391]	Time  0.030 ( 0.034)	Data  0.001 ( 0.003)	Loss 1.9294e-02 (2.9233e-02)	Acc@1  99.22 ( 98.93)	Acc@5 100.00 (100.00)
Epoch: [74][ 80/391]	Time  0.032 ( 0.034)	Data  0.001 ( 0.003)	Loss 4.8788e-02 (2.9106e-02)	Acc@1  97.66 ( 98.96)	Acc@5 100.00 (100.00)
Epoch: [74][ 90/391]	Time  0.036 ( 0.034)	Data  0.001 ( 0.003)	Loss 4.8288e-02 (2.9784e-02)	Acc@1  97.66 ( 98.91)	Acc@5 100.00 (100.00)
Epoch: [74][100/391]	Time  0.030 ( 0.033)	Data  0.001 ( 0.003)	Loss 2.4121e-02 (2.9100e-02)	Acc@1  99.22 ( 98.96)	Acc@5 100.00 (100.00)
Epoch: [74][110/391]	Time  0.030 ( 0.033)	Data  0.001 ( 0.003)	Loss 5.7516e-02 (2.9441e-02)	Acc@1  98.44 ( 98.97)	Acc@5 100.00 (100.00)
Epoch: [74][120/391]	Time  0.030 ( 0.033)	Data  0.001 ( 0.002)	Loss 5.2974e-02 (2.9447e-02)	Acc@1  98.44 ( 98.95)	Acc@5 100.00 (100.00)
Epoch: [74][130/391]	Time  0.030 ( 0.033)	Data  0.001 ( 0.002)	Loss 3.7704e-02 (2.9775e-02)	Acc@1  98.44 ( 98.93)	Acc@5 100.00 (100.00)
Epoch: [74][140/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.6878e-02 (2.9788e-02)	Acc@1  99.22 ( 98.93)	Acc@5 100.00 (100.00)
Epoch: [74][150/391]	Time  0.030 ( 0.033)	Data  0.001 ( 0.002)	Loss 3.4604e-02 (2.9638e-02)	Acc@1  99.22 ( 98.95)	Acc@5 100.00 (100.00)
Epoch: [74][160/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.002)	Loss 3.6020e-02 (2.9342e-02)	Acc@1  98.44 ( 98.97)	Acc@5 100.00 (100.00)
Epoch: [74][170/391]	Time  0.030 ( 0.033)	Data  0.001 ( 0.002)	Loss 7.8875e-03 (2.9112e-02)	Acc@1 100.00 ( 98.97)	Acc@5 100.00 (100.00)
Epoch: [74][180/391]	Time  0.033 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.3256e-02 (2.8886e-02)	Acc@1 100.00 ( 98.99)	Acc@5 100.00 (100.00)
Epoch: [74][190/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 5.1594e-02 (2.8728e-02)	Acc@1  97.66 ( 98.98)	Acc@5 100.00 (100.00)
Epoch: [74][200/391]	Time  0.030 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.4702e-02 (2.8551e-02)	Acc@1 100.00 ( 98.99)	Acc@5 100.00 (100.00)
Epoch: [74][210/391]	Time  0.036 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.6934e-02 (2.8331e-02)	Acc@1  99.22 ( 99.01)	Acc@5 100.00 (100.00)
Epoch: [74][220/391]	Time  0.030 ( 0.032)	Data  0.001 ( 0.002)	Loss 6.3279e-02 (2.8681e-02)	Acc@1  98.44 ( 99.01)	Acc@5 100.00 (100.00)
Epoch: [74][230/391]	Time  0.030 ( 0.032)	Data  0.001 ( 0.002)	Loss 7.9611e-02 (2.9044e-02)	Acc@1  96.88 ( 98.99)	Acc@5 100.00 (100.00)
Epoch: [74][240/391]	Time  0.035 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.7736e-02 (2.8920e-02)	Acc@1  99.22 ( 99.00)	Acc@5 100.00 (100.00)
Epoch: [74][250/391]	Time  0.035 ( 0.032)	Data  0.001 ( 0.002)	Loss 4.1219e-02 (2.8713e-02)	Acc@1  98.44 ( 99.01)	Acc@5 100.00 (100.00)
Epoch: [74][260/391]	Time  0.030 ( 0.032)	Data  0.001 ( 0.002)	Loss 3.6081e-02 (2.8484e-02)	Acc@1  98.44 ( 99.02)	Acc@5 100.00 (100.00)
Epoch: [74][270/391]	Time  0.030 ( 0.032)	Data  0.001 ( 0.002)	Loss 4.4122e-02 (2.8506e-02)	Acc@1  98.44 ( 99.01)	Acc@5 100.00 (100.00)
Epoch: [74][280/391]	Time  0.032 ( 0.032)	Data  0.001 ( 0.002)	Loss 9.6226e-03 (2.8432e-02)	Acc@1 100.00 ( 99.02)	Acc@5 100.00 (100.00)
Epoch: [74][290/391]	Time  0.034 ( 0.032)	Data  0.001 ( 0.002)	Loss 5.0906e-02 (2.8493e-02)	Acc@1  99.22 ( 99.03)	Acc@5 100.00 (100.00)
Epoch: [74][300/391]	Time  0.033 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.4102e-02 (2.8375e-02)	Acc@1  99.22 ( 99.03)	Acc@5 100.00 (100.00)
Epoch: [74][310/391]	Time  0.030 ( 0.032)	Data  0.001 ( 0.002)	Loss 9.9748e-03 (2.8451e-02)	Acc@1 100.00 ( 99.03)	Acc@5 100.00 (100.00)
Epoch: [74][320/391]	Time  0.032 ( 0.032)	Data  0.001 ( 0.002)	Loss 6.5575e-03 (2.8271e-02)	Acc@1 100.00 ( 99.04)	Acc@5 100.00 (100.00)
Epoch: [74][330/391]	Time  0.032 ( 0.032)	Data  0.001 ( 0.002)	Loss 4.3713e-02 (2.8287e-02)	Acc@1  98.44 ( 99.04)	Acc@5 100.00 (100.00)
Epoch: [74][340/391]	Time  0.036 ( 0.032)	Data  0.001 ( 0.002)	Loss 3.8110e-02 (2.8195e-02)	Acc@1  97.66 ( 99.04)	Acc@5 100.00 (100.00)
Epoch: [74][350/391]	Time  0.031 ( 0.032)	Data  0.001 ( 0.001)	Loss 1.6449e-02 (2.8340e-02)	Acc@1 100.00 ( 99.04)	Acc@5 100.00 (100.00)
Epoch: [74][360/391]	Time  0.030 ( 0.032)	Data  0.001 ( 0.001)	Loss 1.2633e-02 (2.8246e-02)	Acc@1 100.00 ( 99.05)	Acc@5 100.00 (100.00)
Epoch: [74][370/391]	Time  0.030 ( 0.032)	Data  0.001 ( 0.001)	Loss 1.5596e-02 (2.8230e-02)	Acc@1  99.22 ( 99.05)	Acc@5 100.00 (100.00)
Epoch: [74][380/391]	Time  0.032 ( 0.032)	Data  0.001 ( 0.001)	Loss 1.9059e-02 (2.8049e-02)	Acc@1 100.00 ( 99.06)	Acc@5 100.00 (100.00)
Epoch: [74][390/391]	Time  0.021 ( 0.032)	Data  0.001 ( 0.001)	Loss 2.1691e-01 (2.8248e-02)	Acc@1  95.00 ( 99.06)	Acc@5 100.00 (100.00)
## e[74] optimizer.zero_grad (sum) time: 0.09064078330993652
## e[74]       loss.backward (sum) time: 2.5697591304779053
## e[74]      optimizer.step (sum) time: 0.6760835647583008
## epoch[74] training(only) time: 12.683701753616333
# Switched to evaluate mode...
Test: [  0/100]	Time  0.175 ( 0.175)	Loss 1.6365e-01 (1.6365e-01)	Acc@1  95.00 ( 95.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.021 ( 0.034)	Loss 4.7140e-01 (3.3878e-01)	Acc@1  90.00 ( 91.91)	Acc@5 100.00 (100.00)
Test: [ 20/100]	Time  0.024 ( 0.028)	Loss 3.5939e-01 (3.8283e-01)	Acc@1  88.00 ( 91.10)	Acc@5 100.00 ( 99.71)
Test: [ 30/100]	Time  0.020 ( 0.026)	Loss 5.1487e-01 (4.0957e-01)	Acc@1  90.00 ( 91.06)	Acc@5  98.00 ( 99.65)
Test: [ 40/100]	Time  0.018 ( 0.024)	Loss 4.1155e-01 (4.2409e-01)	Acc@1  89.00 ( 90.88)	Acc@5 100.00 ( 99.63)
Test: [ 50/100]	Time  0.022 ( 0.023)	Loss 1.5192e-01 (4.1684e-01)	Acc@1  94.00 ( 90.92)	Acc@5 100.00 ( 99.63)
Test: [ 60/100]	Time  0.021 ( 0.023)	Loss 4.9464e-01 (4.0372e-01)	Acc@1  92.00 ( 90.90)	Acc@5  99.00 ( 99.66)
Test: [ 70/100]	Time  0.029 ( 0.023)	Loss 4.6375e-01 (3.9353e-01)	Acc@1  89.00 ( 91.03)	Acc@5 100.00 ( 99.69)
Test: [ 80/100]	Time  0.021 ( 0.023)	Loss 1.9482e-01 (3.8547e-01)	Acc@1  94.00 ( 91.09)	Acc@5 100.00 ( 99.70)
Test: [ 90/100]	Time  0.020 ( 0.023)	Loss 2.5819e-01 (3.9230e-01)	Acc@1  96.00 ( 91.07)	Acc@5 100.00 ( 99.73)
 * Acc@1 91.030 Acc@5 99.740
### epoch[74] execution time: 15.035351276397705
EPOCH 75
REMOVING: module.fire7.expand_1x1.1.weight
REMOVING: module.fire7.expand_1x1.1.bias
i:   0, name: module.fire7.expand_3x3.0.weight  changing lr from: 0.001046811488842940   to: 0.001000049431371019
i:   1, name: module.fire7.expand_3x3.0.bias  changing lr from: 0.001097809994158216   to: 0.001010973022261990
i:   2, name: module.fire7.expand_3x3.1.weight  changing lr from: 0.001166713170187582   to: 0.001040664539663676
i:   3, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.001253047226559294   to: 0.001088647495717814
i:   4, name:  module.fire8.squeeze.0.weight  changing lr from: 0.001356343091512007   to: 0.001154449398874196
i:   5, name:    module.fire8.squeeze.0.bias  changing lr from: 0.001476136676824973   to: 0.001237602063164399
i:   6, name:  module.fire8.squeeze.1.weight  changing lr from: 0.001611969120644568   to: 0.001337641893638152
i:   7, name:    module.fire8.squeeze.1.bias  changing lr from: 0.001763387009257405   to: 0.001454110149052678
i:   8, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.001929942578825466   to: 0.001586553182871835
i:   9, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.002111193898065144   to: 0.001734522663598503
i:  10, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.002306705032817740   to: 0.001897575775430082
i:  11, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.002516046193426279   to: 0.002075275400194481
i:  12, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.002738793865800231   to: 0.002267190281490821
i:  13, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.002974530927018076   to: 0.002472895171927419
i:  14, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.003222846746285440   to: 0.002691970964317580
i:  15, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.003483337272036129   to: 0.002924004807662622
i:  16, name:  module.fire9.squeeze.0.weight  changing lr from: 0.003755605105932696   to: 0.003168590208721139
i:  17, name:    module.fire9.squeeze.0.bias  changing lr from: 0.004039259564493585   to: 0.003425327119933096
i:  18, name:  module.fire9.squeeze.1.weight  changing lr from: 0.004333916729045217   to: 0.003693822014438513
i:  19, name:    module.fire9.squeeze.1.bias  changing lr from: 0.004639199484668921   to: 0.003973687948901189
i:  20, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.004954737548785315   to: 0.004264544614820386
i:  21, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.005280167489991715   to: 0.004566018378985614
i:  22, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.005615132737742789   to: 0.004877742313703270
i:  23, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.005959283583438673   to: 0.005199356217397760
i:  24, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.006312277173460934   to: 0.005530506626164743
i:  25, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.006673777494672717   to: 0.005870846816829261
i:  26, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.007043455352876360   to: 0.006220036802037986
i:  27, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.007420988344699868   to: 0.006577743317891787
i:  28, name:           module.conv10.weight  changing lr from: 0.007806060823361893   to: 0.006943639804602369
i:  29, name:             module.conv10.bias  changing lr from: 0.008198363858743906   to: 0.007317406380634905



# Switched to train mode...
Epoch: [75][  0/391]	Time  0.211 ( 0.211)	Data  0.178 ( 0.178)	Loss 1.2318e-02 (1.2318e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [75][ 10/391]	Time  0.030 ( 0.047)	Data  0.001 ( 0.017)	Loss 2.4198e-02 (2.5645e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [75][ 20/391]	Time  0.030 ( 0.039)	Data  0.001 ( 0.009)	Loss 1.1625e-02 (2.4463e-02)	Acc@1 100.00 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [75][ 30/391]	Time  0.030 ( 0.037)	Data  0.001 ( 0.007)	Loss 3.3219e-02 (2.5731e-02)	Acc@1 100.00 ( 99.27)	Acc@5 100.00 (100.00)
Epoch: [75][ 40/391]	Time  0.030 ( 0.035)	Data  0.001 ( 0.005)	Loss 1.9037e-02 (2.5236e-02)	Acc@1  99.22 ( 99.29)	Acc@5 100.00 (100.00)
Epoch: [75][ 50/391]	Time  0.034 ( 0.035)	Data  0.001 ( 0.004)	Loss 1.5484e-02 (2.4887e-02)	Acc@1 100.00 ( 99.31)	Acc@5 100.00 (100.00)
Epoch: [75][ 60/391]	Time  0.035 ( 0.034)	Data  0.001 ( 0.004)	Loss 1.3444e-02 (2.5558e-02)	Acc@1 100.00 ( 99.28)	Acc@5 100.00 (100.00)
Epoch: [75][ 70/391]	Time  0.031 ( 0.034)	Data  0.001 ( 0.004)	Loss 3.4819e-02 (2.5981e-02)	Acc@1  98.44 ( 99.25)	Acc@5 100.00 (100.00)
Epoch: [75][ 80/391]	Time  0.033 ( 0.033)	Data  0.001 ( 0.003)	Loss 3.0759e-02 (2.7152e-02)	Acc@1  99.22 ( 99.20)	Acc@5 100.00 (100.00)
Epoch: [75][ 90/391]	Time  0.036 ( 0.033)	Data  0.001 ( 0.003)	Loss 8.6768e-03 (2.6794e-02)	Acc@1 100.00 ( 99.20)	Acc@5 100.00 (100.00)
Epoch: [75][100/391]	Time  0.030 ( 0.033)	Data  0.001 ( 0.003)	Loss 2.2646e-02 (2.7234e-02)	Acc@1  99.22 ( 99.17)	Acc@5 100.00 ( 99.99)
Epoch: [75][110/391]	Time  0.030 ( 0.033)	Data  0.001 ( 0.003)	Loss 5.1714e-02 (2.6687e-02)	Acc@1  98.44 ( 99.21)	Acc@5 100.00 ( 99.99)
Epoch: [75][120/391]	Time  0.030 ( 0.033)	Data  0.001 ( 0.002)	Loss 3.5854e-02 (2.6583e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 ( 99.99)
Epoch: [75][130/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.002)	Loss 2.1888e-02 (2.6944e-02)	Acc@1  98.44 ( 99.19)	Acc@5 100.00 ( 99.99)
Epoch: [75][140/391]	Time  0.033 ( 0.033)	Data  0.001 ( 0.002)	Loss 3.5636e-02 (2.7453e-02)	Acc@1  99.22 ( 99.18)	Acc@5 100.00 ( 99.99)
Epoch: [75][150/391]	Time  0.035 ( 0.033)	Data  0.001 ( 0.002)	Loss 4.2521e-02 (2.7713e-02)	Acc@1  98.44 ( 99.17)	Acc@5 100.00 ( 99.99)
Epoch: [75][160/391]	Time  0.031 ( 0.032)	Data  0.001 ( 0.002)	Loss 3.3060e-02 (2.7769e-02)	Acc@1  99.22 ( 99.17)	Acc@5 100.00 (100.00)
Epoch: [75][170/391]	Time  0.030 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.1945e-02 (2.7451e-02)	Acc@1 100.00 ( 99.18)	Acc@5 100.00 (100.00)
Epoch: [75][180/391]	Time  0.031 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.9153e-02 (2.7537e-02)	Acc@1  99.22 ( 99.19)	Acc@5 100.00 (100.00)
Epoch: [75][190/391]	Time  0.030 ( 0.032)	Data  0.001 ( 0.002)	Loss 3.7968e-02 (2.7368e-02)	Acc@1  97.66 ( 99.19)	Acc@5 100.00 (100.00)
Epoch: [75][200/391]	Time  0.031 ( 0.032)	Data  0.001 ( 0.002)	Loss 9.8072e-03 (2.7692e-02)	Acc@1 100.00 ( 99.18)	Acc@5 100.00 (100.00)
Epoch: [75][210/391]	Time  0.031 ( 0.032)	Data  0.001 ( 0.002)	Loss 5.9520e-02 (2.7517e-02)	Acc@1  99.22 ( 99.19)	Acc@5 100.00 (100.00)
Epoch: [75][220/391]	Time  0.032 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.3531e-02 (2.7303e-02)	Acc@1 100.00 ( 99.21)	Acc@5 100.00 (100.00)
Epoch: [75][230/391]	Time  0.030 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.3361e-02 (2.6973e-02)	Acc@1 100.00 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [75][240/391]	Time  0.033 ( 0.032)	Data  0.001 ( 0.002)	Loss 5.4810e-02 (2.6830e-02)	Acc@1  96.88 ( 99.23)	Acc@5 100.00 (100.00)
Epoch: [75][250/391]	Time  0.033 ( 0.032)	Data  0.001 ( 0.002)	Loss 4.2068e-02 (2.6823e-02)	Acc@1  98.44 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [75][260/391]	Time  0.030 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.0225e-02 (2.6851e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [75][270/391]	Time  0.032 ( 0.032)	Data  0.001 ( 0.002)	Loss 4.4147e-02 (2.6715e-02)	Acc@1  98.44 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [75][280/391]	Time  0.034 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.3711e-02 (2.6713e-02)	Acc@1 100.00 ( 99.23)	Acc@5 100.00 (100.00)
Epoch: [75][290/391]	Time  0.033 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.8278e-02 (2.6887e-02)	Acc@1 100.00 ( 99.23)	Acc@5 100.00 (100.00)
Epoch: [75][300/391]	Time  0.033 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.9335e-02 (2.6814e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [75][310/391]	Time  0.031 ( 0.032)	Data  0.001 ( 0.002)	Loss 5.0018e-02 (2.6902e-02)	Acc@1  98.44 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [75][320/391]	Time  0.032 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.0369e-02 (2.6943e-02)	Acc@1 100.00 ( 99.21)	Acc@5 100.00 (100.00)
Epoch: [75][330/391]	Time  0.032 ( 0.032)	Data  0.001 ( 0.002)	Loss 4.3780e-02 (2.7287e-02)	Acc@1  97.66 ( 99.20)	Acc@5 100.00 (100.00)
Epoch: [75][340/391]	Time  0.032 ( 0.032)	Data  0.002 ( 0.002)	Loss 2.6768e-02 (2.7188e-02)	Acc@1  99.22 ( 99.20)	Acc@5 100.00 (100.00)
Epoch: [75][350/391]	Time  0.029 ( 0.032)	Data  0.001 ( 0.002)	Loss 4.7000e-02 (2.7472e-02)	Acc@1  99.22 ( 99.18)	Acc@5 100.00 (100.00)
Epoch: [75][360/391]	Time  0.036 ( 0.032)	Data  0.001 ( 0.002)	Loss 3.4346e-02 (2.7482e-02)	Acc@1  99.22 ( 99.18)	Acc@5 100.00 (100.00)
Epoch: [75][370/391]	Time  0.039 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.6622e-02 (2.7508e-02)	Acc@1 100.00 ( 99.18)	Acc@5 100.00 (100.00)
Epoch: [75][380/391]	Time  0.031 ( 0.032)	Data  0.001 ( 0.002)	Loss 5.1744e-02 (2.7565e-02)	Acc@1  96.88 ( 99.17)	Acc@5 100.00 (100.00)
Epoch: [75][390/391]	Time  0.021 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.5919e-02 (2.7674e-02)	Acc@1  98.75 ( 99.17)	Acc@5 100.00 (100.00)
## e[75] optimizer.zero_grad (sum) time: 0.08689498901367188
## e[75]       loss.backward (sum) time: 2.5769712924957275
## e[75]      optimizer.step (sum) time: 0.6576700210571289
## epoch[75] training(only) time: 12.660298824310303
# Switched to evaluate mode...
Test: [  0/100]	Time  0.169 ( 0.169)	Loss 1.7623e-01 (1.7623e-01)	Acc@1  96.00 ( 96.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.022 ( 0.034)	Loss 4.9852e-01 (3.3681e-01)	Acc@1  90.00 ( 92.09)	Acc@5 100.00 (100.00)
Test: [ 20/100]	Time  0.021 ( 0.028)	Loss 3.6534e-01 (3.7269e-01)	Acc@1  88.00 ( 91.24)	Acc@5 100.00 ( 99.71)
Test: [ 30/100]	Time  0.017 ( 0.025)	Loss 4.6822e-01 (4.0415e-01)	Acc@1  91.00 ( 91.00)	Acc@5  98.00 ( 99.65)
Test: [ 40/100]	Time  0.018 ( 0.024)	Loss 3.6012e-01 (4.1905e-01)	Acc@1  89.00 ( 90.76)	Acc@5 100.00 ( 99.61)
Test: [ 50/100]	Time  0.018 ( 0.023)	Loss 1.6273e-01 (4.1321e-01)	Acc@1  95.00 ( 90.88)	Acc@5 100.00 ( 99.63)
Test: [ 60/100]	Time  0.018 ( 0.022)	Loss 4.8251e-01 (3.9985e-01)	Acc@1  93.00 ( 90.92)	Acc@5  99.00 ( 99.66)
Test: [ 70/100]	Time  0.023 ( 0.022)	Loss 4.6455e-01 (3.8976e-01)	Acc@1  90.00 ( 91.01)	Acc@5 100.00 ( 99.69)
Test: [ 80/100]	Time  0.017 ( 0.022)	Loss 2.0224e-01 (3.8225e-01)	Acc@1  95.00 ( 91.15)	Acc@5 100.00 ( 99.69)
Test: [ 90/100]	Time  0.021 ( 0.022)	Loss 2.8247e-01 (3.8881e-01)	Acc@1  94.00 ( 91.12)	Acc@5 100.00 ( 99.73)
 * Acc@1 91.100 Acc@5 99.730
### epoch[75] execution time: 14.920348882675171
EPOCH 76
REMOVING: module.fire7.expand_3x3.0.weight
REMOVING: module.fire7.expand_3x3.0.bias
REMOVING: module.fire7.expand_3x3.1.weight
i:   0, name: module.fire7.expand_3x3.1.bias  changing lr from: 0.001088647495717814   to: 0.001008521301549080
i:   1, name:  module.fire8.squeeze.0.weight  changing lr from: 0.001154449398874196   to: 0.001035680321383708
i:   2, name:    module.fire8.squeeze.0.bias  changing lr from: 0.001237602063164399   to: 0.001081032182975549
i:   3, name:  module.fire8.squeeze.1.weight  changing lr from: 0.001337641893638152   to: 0.001144110063154496
i:   4, name:    module.fire8.squeeze.1.bias  changing lr from: 0.001454110149052678   to: 0.001224451328897041
i:   5, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.001586553182871835   to: 0.001321597819700337
i:   6, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.001734522663598503   to: 0.001435096107656280
i:   7, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.001897575775430082   to: 0.001564497736254899
i:   8, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.002075275400194481   to: 0.001709359438914053
i:   9, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.002267190281490821   to: 0.001869243338200188
i:  10, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.002472895171927419   to: 0.002043717126673283
i:  11, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.002691970964317580   to: 0.002232354230257177
i:  12, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.002924004807662622   to: 0.002434733955005807
i:  13, name:  module.fire9.squeeze.0.weight  changing lr from: 0.003168590208721139   to: 0.002650441618104853
i:  14, name:    module.fire9.squeeze.0.bias  changing lr from: 0.003425327119933096   to: 0.002879068663918188
i:  15, name:  module.fire9.squeeze.1.weight  changing lr from: 0.003693822014438513   to: 0.003120212765859070
i:  16, name:    module.fire9.squeeze.1.bias  changing lr from: 0.003973687948901189   to: 0.003373477914836681
i:  17, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.004264544614820386   to: 0.003638474495000248
i:  18, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.004566018378985614   to: 0.003914819347475267
i:  19, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.004877742313703270   to: 0.004202135822758828
i:  20, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.005199356217397760   to: 0.004500053822414778
i:  21, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.005530506626164743   to: 0.004808209830683568
i:  22, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.005870846816829261   to: 0.005126246936596212
i:  23, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.006220036802037986   to: 0.005453814847157400
i:  24, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.006577743317891787   to: 0.005790569892139241
i:  25, name:           module.conv10.weight  changing lr from: 0.006943639804602369   to: 0.006136175021003542
i:  26, name:             module.conv10.bias  changing lr from: 0.007317406380634905   to: 0.006490299792448495



# Switched to train mode...
Epoch: [76][  0/391]	Time  0.197 ( 0.197)	Data  0.163 ( 0.163)	Loss 2.0338e-02 (2.0338e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [76][ 10/391]	Time  0.030 ( 0.048)	Data  0.001 ( 0.016)	Loss 3.8901e-02 (3.5126e-02)	Acc@1  98.44 ( 98.58)	Acc@5 100.00 (100.00)
Epoch: [76][ 20/391]	Time  0.030 ( 0.040)	Data  0.001 ( 0.009)	Loss 1.6528e-02 (3.2399e-02)	Acc@1  99.22 ( 98.77)	Acc@5 100.00 (100.00)
Epoch: [76][ 30/391]	Time  0.032 ( 0.037)	Data  0.001 ( 0.006)	Loss 9.2986e-03 (3.0754e-02)	Acc@1 100.00 ( 98.71)	Acc@5 100.00 (100.00)
Epoch: [76][ 40/391]	Time  0.030 ( 0.036)	Data  0.001 ( 0.005)	Loss 8.6359e-03 (3.1104e-02)	Acc@1 100.00 ( 98.76)	Acc@5 100.00 (100.00)
Epoch: [76][ 50/391]	Time  0.026 ( 0.035)	Data  0.001 ( 0.004)	Loss 8.0791e-03 (2.9306e-02)	Acc@1 100.00 ( 98.85)	Acc@5 100.00 (100.00)
Epoch: [76][ 60/391]	Time  0.030 ( 0.035)	Data  0.001 ( 0.004)	Loss 2.9676e-02 (2.8878e-02)	Acc@1  99.22 ( 98.89)	Acc@5 100.00 (100.00)
Epoch: [76][ 70/391]	Time  0.030 ( 0.034)	Data  0.001 ( 0.003)	Loss 6.1249e-02 (2.8980e-02)	Acc@1  97.66 ( 98.88)	Acc@5 100.00 (100.00)
Epoch: [76][ 80/391]	Time  0.035 ( 0.034)	Data  0.001 ( 0.003)	Loss 2.1227e-02 (2.9646e-02)	Acc@1  99.22 ( 98.89)	Acc@5 100.00 (100.00)
Epoch: [76][ 90/391]	Time  0.028 ( 0.033)	Data  0.001 ( 0.003)	Loss 1.2868e-02 (2.9634e-02)	Acc@1 100.00 ( 98.90)	Acc@5 100.00 (100.00)
Epoch: [76][100/391]	Time  0.029 ( 0.033)	Data  0.001 ( 0.003)	Loss 2.0559e-02 (2.9266e-02)	Acc@1  99.22 ( 98.92)	Acc@5 100.00 (100.00)
Epoch: [76][110/391]	Time  0.030 ( 0.033)	Data  0.001 ( 0.003)	Loss 5.2220e-02 (2.9015e-02)	Acc@1  98.44 ( 98.94)	Acc@5 100.00 (100.00)
Epoch: [76][120/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.002)	Loss 4.6509e-02 (2.9582e-02)	Acc@1  98.44 ( 98.95)	Acc@5 100.00 (100.00)
Epoch: [76][130/391]	Time  0.030 ( 0.033)	Data  0.001 ( 0.002)	Loss 4.4092e-02 (2.9127e-02)	Acc@1  98.44 ( 98.99)	Acc@5 100.00 (100.00)
Epoch: [76][140/391]	Time  0.035 ( 0.033)	Data  0.001 ( 0.002)	Loss 7.2517e-03 (2.8934e-02)	Acc@1 100.00 ( 99.00)	Acc@5 100.00 (100.00)
Epoch: [76][150/391]	Time  0.029 ( 0.033)	Data  0.001 ( 0.002)	Loss 1.4059e-02 (2.9073e-02)	Acc@1 100.00 ( 98.97)	Acc@5 100.00 (100.00)
Epoch: [76][160/391]	Time  0.031 ( 0.032)	Data  0.001 ( 0.002)	Loss 5.3614e-02 (2.9121e-02)	Acc@1  97.66 ( 98.97)	Acc@5 100.00 (100.00)
Epoch: [76][170/391]	Time  0.030 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.0947e-02 (2.8691e-02)	Acc@1 100.00 ( 98.99)	Acc@5 100.00 (100.00)
Epoch: [76][180/391]	Time  0.030 ( 0.032)	Data  0.001 ( 0.002)	Loss 8.9688e-03 (2.8523e-02)	Acc@1 100.00 ( 99.02)	Acc@5 100.00 (100.00)
Epoch: [76][190/391]	Time  0.030 ( 0.032)	Data  0.001 ( 0.002)	Loss 4.5619e-02 (2.9212e-02)	Acc@1  97.66 ( 99.00)	Acc@5 100.00 (100.00)
Epoch: [76][200/391]	Time  0.035 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.6258e-02 (2.9215e-02)	Acc@1  99.22 ( 99.00)	Acc@5 100.00 (100.00)
Epoch: [76][210/391]	Time  0.029 ( 0.032)	Data  0.001 ( 0.002)	Loss 3.8138e-02 (2.9132e-02)	Acc@1  99.22 ( 99.00)	Acc@5 100.00 (100.00)
Epoch: [76][220/391]	Time  0.030 ( 0.032)	Data  0.001 ( 0.002)	Loss 3.7996e-02 (2.8735e-02)	Acc@1  97.66 ( 99.02)	Acc@5 100.00 (100.00)
Epoch: [76][230/391]	Time  0.033 ( 0.032)	Data  0.001 ( 0.002)	Loss 3.2024e-02 (2.8909e-02)	Acc@1  98.44 ( 99.02)	Acc@5 100.00 (100.00)
Epoch: [76][240/391]	Time  0.029 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.6739e-02 (2.8888e-02)	Acc@1  99.22 ( 99.03)	Acc@5 100.00 (100.00)
Epoch: [76][250/391]	Time  0.030 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.6344e-02 (2.9046e-02)	Acc@1 100.00 ( 99.03)	Acc@5 100.00 (100.00)
Epoch: [76][260/391]	Time  0.032 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.1378e-02 (2.8726e-02)	Acc@1 100.00 ( 99.05)	Acc@5 100.00 (100.00)
Epoch: [76][270/391]	Time  0.031 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.6524e-02 (2.8912e-02)	Acc@1  99.22 ( 99.03)	Acc@5 100.00 (100.00)
Epoch: [76][280/391]	Time  0.035 ( 0.032)	Data  0.001 ( 0.002)	Loss 3.7326e-02 (2.9088e-02)	Acc@1  97.66 ( 99.02)	Acc@5 100.00 (100.00)
Epoch: [76][290/391]	Time  0.030 ( 0.032)	Data  0.001 ( 0.002)	Loss 4.6509e-02 (2.9081e-02)	Acc@1  98.44 ( 99.03)	Acc@5 100.00 (100.00)
Epoch: [76][300/391]	Time  0.034 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.4726e-02 (2.9015e-02)	Acc@1  99.22 ( 99.03)	Acc@5 100.00 (100.00)
Epoch: [76][310/391]	Time  0.030 ( 0.032)	Data  0.001 ( 0.002)	Loss 4.8216e-02 (2.8833e-02)	Acc@1  99.22 ( 99.05)	Acc@5 100.00 (100.00)
Epoch: [76][320/391]	Time  0.031 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.0000e-02 (2.8639e-02)	Acc@1  99.22 ( 99.06)	Acc@5 100.00 (100.00)
Epoch: [76][330/391]	Time  0.032 ( 0.032)	Data  0.001 ( 0.002)	Loss 4.2725e-02 (2.8468e-02)	Acc@1  98.44 ( 99.07)	Acc@5 100.00 (100.00)
Epoch: [76][340/391]	Time  0.032 ( 0.032)	Data  0.001 ( 0.002)	Loss 5.9331e-02 (2.8624e-02)	Acc@1  98.44 ( 99.07)	Acc@5 100.00 (100.00)
Epoch: [76][350/391]	Time  0.029 ( 0.032)	Data  0.001 ( 0.002)	Loss 8.2868e-03 (2.8670e-02)	Acc@1 100.00 ( 99.06)	Acc@5 100.00 (100.00)
Epoch: [76][360/391]	Time  0.041 ( 0.032)	Data  0.001 ( 0.002)	Loss 3.5686e-02 (2.8501e-02)	Acc@1  97.66 ( 99.07)	Acc@5 100.00 (100.00)
Epoch: [76][370/391]	Time  0.034 ( 0.032)	Data  0.001 ( 0.002)	Loss 5.8180e-02 (2.8394e-02)	Acc@1  98.44 ( 99.07)	Acc@5 100.00 (100.00)
Epoch: [76][380/391]	Time  0.035 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.3689e-02 (2.8227e-02)	Acc@1  99.22 ( 99.07)	Acc@5 100.00 (100.00)
Epoch: [76][390/391]	Time  0.021 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.0435e-02 (2.8342e-02)	Acc@1 100.00 ( 99.07)	Acc@5 100.00 (100.00)
## e[76] optimizer.zero_grad (sum) time: 0.08035039901733398
## e[76]       loss.backward (sum) time: 2.5300376415252686
## e[76]      optimizer.step (sum) time: 0.6139779090881348
## epoch[76] training(only) time: 12.606562614440918
# Switched to evaluate mode...
Test: [  0/100]	Time  0.180 ( 0.180)	Loss 1.7154e-01 (1.7154e-01)	Acc@1  96.00 ( 96.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.019 ( 0.034)	Loss 5.1239e-01 (3.4083e-01)	Acc@1  90.00 ( 91.55)	Acc@5 100.00 ( 99.91)
Test: [ 20/100]	Time  0.016 ( 0.027)	Loss 3.6561e-01 (3.8452e-01)	Acc@1  88.00 ( 90.95)	Acc@5 100.00 ( 99.67)
Test: [ 30/100]	Time  0.018 ( 0.024)	Loss 5.1739e-01 (4.1518e-01)	Acc@1  90.00 ( 90.94)	Acc@5  98.00 ( 99.58)
Test: [ 40/100]	Time  0.024 ( 0.023)	Loss 4.3007e-01 (4.3136e-01)	Acc@1  90.00 ( 90.78)	Acc@5 100.00 ( 99.59)
Test: [ 50/100]	Time  0.023 ( 0.023)	Loss 1.5428e-01 (4.2189e-01)	Acc@1  95.00 ( 90.88)	Acc@5 100.00 ( 99.61)
Test: [ 60/100]	Time  0.024 ( 0.023)	Loss 4.6725e-01 (4.0712e-01)	Acc@1  92.00 ( 90.92)	Acc@5  99.00 ( 99.64)
Test: [ 70/100]	Time  0.023 ( 0.023)	Loss 5.0393e-01 (3.9640e-01)	Acc@1  90.00 ( 91.06)	Acc@5 100.00 ( 99.68)
Test: [ 80/100]	Time  0.019 ( 0.022)	Loss 2.1760e-01 (3.8847e-01)	Acc@1  95.00 ( 91.16)	Acc@5 100.00 ( 99.70)
Test: [ 90/100]	Time  0.025 ( 0.022)	Loss 2.9076e-01 (3.9495e-01)	Acc@1  94.00 ( 91.05)	Acc@5 100.00 ( 99.73)
 * Acc@1 91.010 Acc@5 99.740
### epoch[76] execution time: 14.934156656265259
EPOCH 77
REMOVING: module.fire7.expand_3x3.1.bias
REMOVING: module.fire8.squeeze.0.weight
i:   0, name:    module.fire8.squeeze.0.bias  changing lr from: 0.001081032182975549   to: 0.001006684925930772
i:   1, name:  module.fire8.squeeze.1.weight  changing lr from: 0.001144110063154496   to: 0.001031688484983378
i:   2, name:    module.fire8.squeeze.1.bias  changing lr from: 0.001224451328897041   to: 0.001074779600293984
i:   3, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.001321597819700337   to: 0.001135497053327027
i:   4, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.001435096107656280   to: 0.001213383709259207
i:   5, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.001564497736254899   to: 0.001307986795944504
i:   6, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.001709359438914053   to: 0.001418858161030522
i:   7, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.001869243338200188   to: 0.001545554508228330
i:   8, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.002043717126673283   to: 0.001687637613706971
i:   9, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.002232354230257177   to: 0.001844674523552469
i:  10, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.002434733955005807   to: 0.002016237733200620
i:  11, name:  module.fire9.squeeze.0.weight  changing lr from: 0.002650441618104853   to: 0.002201905349722088
i:  12, name:    module.fire9.squeeze.0.bias  changing lr from: 0.002879068663918188   to: 0.002401261237808415
i:  13, name:  module.fire9.squeeze.1.weight  changing lr from: 0.003120212765859070   to: 0.002613895150277761
i:  14, name:    module.fire9.squeeze.1.bias  changing lr from: 0.003373477914836681   to: 0.002839402843889920
i:  15, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.003638474495000248   to: 0.003077386181231672
i:  16, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.003914819347475267   to: 0.003327453219404918
i:  17, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.004202135822758828   to: 0.003589218286223017
i:  18, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.004500053822414778   to: 0.003862302044593246
i:  19, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.004808209830683568   to: 0.004146331545737230
i:  20, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.005126246936596212   to: 0.004440940271875315
i:  21, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.005453814847157400   to: 0.004745768168975672
i:  22, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.005790569892139241   to: 0.005060461670144711
i:  23, name:           module.conv10.weight  changing lr from: 0.006136175021003542   to: 0.005384673710211318
i:  24, name:             module.conv10.bias  changing lr from: 0.006490299792448495   to: 0.005718063732034539



# Switched to train mode...
Epoch: [77][  0/391]	Time  0.202 ( 0.202)	Data  0.168 ( 0.168)	Loss 1.6280e-02 (1.6280e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [77][ 10/391]	Time  0.032 ( 0.048)	Data  0.001 ( 0.016)	Loss 1.8843e-02 (1.9294e-02)	Acc@1  99.22 ( 99.57)	Acc@5 100.00 (100.00)
Epoch: [77][ 20/391]	Time  0.031 ( 0.040)	Data  0.001 ( 0.009)	Loss 2.0454e-02 (2.3085e-02)	Acc@1  99.22 ( 99.40)	Acc@5 100.00 (100.00)
Epoch: [77][ 30/391]	Time  0.030 ( 0.037)	Data  0.001 ( 0.006)	Loss 1.7932e-02 (2.0839e-02)	Acc@1 100.00 ( 99.50)	Acc@5 100.00 (100.00)
Epoch: [77][ 40/391]	Time  0.029 ( 0.035)	Data  0.001 ( 0.005)	Loss 1.2921e-02 (2.3322e-02)	Acc@1  99.22 ( 99.33)	Acc@5 100.00 (100.00)
Epoch: [77][ 50/391]	Time  0.030 ( 0.035)	Data  0.001 ( 0.004)	Loss 8.0143e-03 (2.3772e-02)	Acc@1 100.00 ( 99.30)	Acc@5 100.00 (100.00)
Epoch: [77][ 60/391]	Time  0.029 ( 0.034)	Data  0.001 ( 0.004)	Loss 1.4546e-02 (2.4531e-02)	Acc@1 100.00 ( 99.24)	Acc@5 100.00 (100.00)
Epoch: [77][ 70/391]	Time  0.032 ( 0.034)	Data  0.001 ( 0.003)	Loss 3.2716e-02 (2.5116e-02)	Acc@1  99.22 ( 99.19)	Acc@5 100.00 (100.00)
Epoch: [77][ 80/391]	Time  0.033 ( 0.033)	Data  0.001 ( 0.003)	Loss 3.6285e-02 (2.5788e-02)	Acc@1  99.22 ( 99.15)	Acc@5 100.00 (100.00)
Epoch: [77][ 90/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.003)	Loss 5.8181e-02 (2.6152e-02)	Acc@1  98.44 ( 99.13)	Acc@5 100.00 (100.00)
Epoch: [77][100/391]	Time  0.029 ( 0.033)	Data  0.001 ( 0.003)	Loss 2.0322e-02 (2.5656e-02)	Acc@1 100.00 ( 99.16)	Acc@5 100.00 (100.00)
Epoch: [77][110/391]	Time  0.029 ( 0.033)	Data  0.001 ( 0.003)	Loss 2.7282e-02 (2.5917e-02)	Acc@1  99.22 ( 99.16)	Acc@5 100.00 (100.00)
Epoch: [77][120/391]	Time  0.029 ( 0.032)	Data  0.001 ( 0.002)	Loss 3.3591e-02 (2.6026e-02)	Acc@1  99.22 ( 99.17)	Acc@5 100.00 (100.00)
Epoch: [77][130/391]	Time  0.029 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.9194e-02 (2.5617e-02)	Acc@1  99.22 ( 99.18)	Acc@5 100.00 (100.00)
Epoch: [77][140/391]	Time  0.030 ( 0.032)	Data  0.001 ( 0.002)	Loss 4.9801e-02 (2.5393e-02)	Acc@1  97.66 ( 99.19)	Acc@5 100.00 (100.00)
Epoch: [77][150/391]	Time  0.033 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.7048e-02 (2.5451e-02)	Acc@1  99.22 ( 99.17)	Acc@5 100.00 (100.00)
Epoch: [77][160/391]	Time  0.030 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.4953e-02 (2.5362e-02)	Acc@1  99.22 ( 99.17)	Acc@5 100.00 (100.00)
Epoch: [77][170/391]	Time  0.029 ( 0.032)	Data  0.001 ( 0.002)	Loss 4.3866e-02 (2.5650e-02)	Acc@1  97.66 ( 99.14)	Acc@5 100.00 (100.00)
Epoch: [77][180/391]	Time  0.029 ( 0.032)	Data  0.001 ( 0.002)	Loss 5.1455e-02 (2.6030e-02)	Acc@1  98.44 ( 99.13)	Acc@5 100.00 (100.00)
Epoch: [77][190/391]	Time  0.029 ( 0.032)	Data  0.001 ( 0.002)	Loss 8.8251e-03 (2.6040e-02)	Acc@1 100.00 ( 99.13)	Acc@5 100.00 (100.00)
Epoch: [77][200/391]	Time  0.034 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.6472e-02 (2.5906e-02)	Acc@1  99.22 ( 99.13)	Acc@5 100.00 (100.00)
Epoch: [77][210/391]	Time  0.033 ( 0.032)	Data  0.001 ( 0.002)	Loss 6.3009e-03 (2.5728e-02)	Acc@1 100.00 ( 99.14)	Acc@5 100.00 (100.00)
Epoch: [77][220/391]	Time  0.033 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.9573e-02 (2.6268e-02)	Acc@1  99.22 ( 99.12)	Acc@5 100.00 (100.00)
Epoch: [77][230/391]	Time  0.030 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.1812e-02 (2.6143e-02)	Acc@1  99.22 ( 99.13)	Acc@5 100.00 (100.00)
Epoch: [77][240/391]	Time  0.027 ( 0.032)	Data  0.001 ( 0.002)	Loss 3.3121e-02 (2.6267e-02)	Acc@1  99.22 ( 99.13)	Acc@5 100.00 (100.00)
Epoch: [77][250/391]	Time  0.031 ( 0.032)	Data  0.001 ( 0.002)	Loss 4.4738e-02 (2.6614e-02)	Acc@1  99.22 ( 99.13)	Acc@5 100.00 (100.00)
Epoch: [77][260/391]	Time  0.040 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.7286e-02 (2.6279e-02)	Acc@1  99.22 ( 99.14)	Acc@5 100.00 (100.00)
Epoch: [77][270/391]	Time  0.034 ( 0.032)	Data  0.001 ( 0.002)	Loss 4.7476e-02 (2.6383e-02)	Acc@1  97.66 ( 99.14)	Acc@5 100.00 (100.00)
Epoch: [77][280/391]	Time  0.031 ( 0.032)	Data  0.001 ( 0.002)	Loss 3.3144e-02 (2.6236e-02)	Acc@1  99.22 ( 99.15)	Acc@5 100.00 (100.00)
Epoch: [77][290/391]	Time  0.032 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.0647e-02 (2.6224e-02)	Acc@1 100.00 ( 99.15)	Acc@5 100.00 (100.00)
Epoch: [77][300/391]	Time  0.030 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.9058e-02 (2.6409e-02)	Acc@1  99.22 ( 99.15)	Acc@5 100.00 (100.00)
Epoch: [77][310/391]	Time  0.032 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.5961e-02 (2.6470e-02)	Acc@1  99.22 ( 99.14)	Acc@5 100.00 (100.00)
Epoch: [77][320/391]	Time  0.029 ( 0.032)	Data  0.001 ( 0.002)	Loss 6.9650e-03 (2.6510e-02)	Acc@1 100.00 ( 99.14)	Acc@5 100.00 (100.00)
Epoch: [77][330/391]	Time  0.030 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.8847e-02 (2.6631e-02)	Acc@1 100.00 ( 99.14)	Acc@5 100.00 (100.00)
Epoch: [77][340/391]	Time  0.034 ( 0.032)	Data  0.001 ( 0.002)	Loss 9.1524e-03 (2.6375e-02)	Acc@1 100.00 ( 99.15)	Acc@5 100.00 (100.00)
Epoch: [77][350/391]	Time  0.031 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.7953e-02 (2.6450e-02)	Acc@1 100.00 ( 99.14)	Acc@5 100.00 (100.00)
Epoch: [77][360/391]	Time  0.040 ( 0.032)	Data  0.003 ( 0.002)	Loss 1.1382e-02 (2.6446e-02)	Acc@1 100.00 ( 99.14)	Acc@5 100.00 (100.00)
Epoch: [77][370/391]	Time  0.031 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.7059e-02 (2.6279e-02)	Acc@1  99.22 ( 99.15)	Acc@5 100.00 (100.00)
Epoch: [77][380/391]	Time  0.029 ( 0.032)	Data  0.001 ( 0.002)	Loss 4.2063e-02 (2.6224e-02)	Acc@1  99.22 ( 99.16)	Acc@5 100.00 (100.00)
Epoch: [77][390/391]	Time  0.018 ( 0.031)	Data  0.001 ( 0.002)	Loss 8.3772e-03 (2.6263e-02)	Acc@1 100.00 ( 99.15)	Acc@5 100.00 (100.00)
## e[77] optimizer.zero_grad (sum) time: 0.07248163223266602
## e[77]       loss.backward (sum) time: 2.488973617553711
## e[77]      optimizer.step (sum) time: 0.579207181930542
## epoch[77] training(only) time: 12.438547611236572
# Switched to evaluate mode...
Test: [  0/100]	Time  0.171 ( 0.171)	Loss 1.8053e-01 (1.8053e-01)	Acc@1  95.00 ( 95.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.023 ( 0.034)	Loss 5.2303e-01 (3.4214e-01)	Acc@1  89.00 ( 91.73)	Acc@5 100.00 (100.00)
Test: [ 20/100]	Time  0.020 ( 0.028)	Loss 3.4489e-01 (3.8285e-01)	Acc@1  88.00 ( 90.90)	Acc@5 100.00 ( 99.71)
Test: [ 30/100]	Time  0.017 ( 0.025)	Loss 4.8934e-01 (4.1227e-01)	Acc@1  90.00 ( 90.90)	Acc@5  98.00 ( 99.65)
Test: [ 40/100]	Time  0.021 ( 0.024)	Loss 4.0257e-01 (4.2455e-01)	Acc@1  89.00 ( 90.93)	Acc@5 100.00 ( 99.61)
Test: [ 50/100]	Time  0.022 ( 0.024)	Loss 1.4880e-01 (4.1620e-01)	Acc@1  95.00 ( 91.10)	Acc@5 100.00 ( 99.63)
Test: [ 60/100]	Time  0.020 ( 0.023)	Loss 4.6723e-01 (4.0192e-01)	Acc@1  93.00 ( 91.13)	Acc@5 100.00 ( 99.67)
Test: [ 70/100]	Time  0.022 ( 0.023)	Loss 5.1788e-01 (3.9283e-01)	Acc@1  89.00 ( 91.20)	Acc@5 100.00 ( 99.70)
Test: [ 80/100]	Time  0.021 ( 0.023)	Loss 2.1287e-01 (3.8527e-01)	Acc@1  95.00 ( 91.27)	Acc@5 100.00 ( 99.73)
Test: [ 90/100]	Time  0.016 ( 0.022)	Loss 2.9275e-01 (3.9234e-01)	Acc@1  95.00 ( 91.20)	Acc@5 100.00 ( 99.76)
 * Acc@1 91.170 Acc@5 99.760
### epoch[77] execution time: 14.755151271820068
EPOCH 78
REMOVING: module.fire8.squeeze.0.bias
REMOVING: module.fire8.squeeze.1.weight
i:   0, name:    module.fire8.squeeze.1.bias  changing lr from: 0.001074779600293984   to: 0.001005335479050528
i:   1, name: module.fire8.expand_1x1.0.weight  changing lr from: 0.001135497053327027   to: 0.001028546281756925
i:   2, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.001213383709259207   to: 0.001069733097291952
i:   3, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.001307986795944504   to: 0.001128440245871042
i:   4, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.001418858161030522   to: 0.001204216033518750
i:   5, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.001545554508228330   to: 0.001296613027309639
i:   6, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.001687637613706971   to: 0.001405188309214843
i:   7, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.001844674523552469   to: 0.001529503709529888
i:   8, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.002016237733200620   to: 0.001669126020829503
i:   9, name:  module.fire9.squeeze.0.weight  changing lr from: 0.002201905349722088   to: 0.001823627193364796
i:  10, name:    module.fire9.squeeze.0.bias  changing lr from: 0.002401261237808415   to: 0.001992584512788558
i:  11, name:  module.fire9.squeeze.1.weight  changing lr from: 0.002613895150277761   to: 0.002175580761064893
i:  12, name:    module.fire9.squeeze.1.bias  changing lr from: 0.002839402843889920   to: 0.002372204361390106
i:  13, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.003077386181231672   to: 0.002582049507923378
i:  14, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.003327453219404918   to: 0.002804716281096863
i:  15, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.003589218286223017   to: 0.003039810749247784
i:  16, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.003862302044593246   to: 0.003286945057287066
i:  17, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.004146331545737230   to: 0.003545737503092893
i:  18, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.004440940271875315   to: 0.003815812602291096
i:  19, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.004745768168975672   to: 0.004096801142058558
i:  20, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.005060461670144711   to: 0.004388340224561398
i:  21, name:           module.conv10.weight  changing lr from: 0.005384673710211318   to: 0.004690073300614627
i:  22, name:             module.conv10.bias  changing lr from: 0.005718063732034539   to: 0.005001650194126833



# Switched to train mode...
Epoch: [78][  0/391]	Time  0.202 ( 0.202)	Data  0.170 ( 0.170)	Loss 2.2829e-02 (2.2829e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [78][ 10/391]	Time  0.029 ( 0.047)	Data  0.001 ( 0.017)	Loss 1.6577e-02 (2.5114e-02)	Acc@1  99.22 ( 99.29)	Acc@5 100.00 (100.00)
Epoch: [78][ 20/391]	Time  0.031 ( 0.039)	Data  0.001 ( 0.009)	Loss 1.0938e-02 (2.7623e-02)	Acc@1 100.00 ( 99.11)	Acc@5 100.00 (100.00)
Epoch: [78][ 30/391]	Time  0.032 ( 0.037)	Data  0.001 ( 0.007)	Loss 5.2538e-02 (3.0085e-02)	Acc@1  98.44 ( 99.04)	Acc@5 100.00 (100.00)
Epoch: [78][ 40/391]	Time  0.035 ( 0.035)	Data  0.001 ( 0.005)	Loss 2.4526e-02 (2.8131e-02)	Acc@1  99.22 ( 99.12)	Acc@5 100.00 (100.00)
Epoch: [78][ 50/391]	Time  0.029 ( 0.035)	Data  0.001 ( 0.004)	Loss 4.6576e-02 (2.8079e-02)	Acc@1  97.66 ( 99.14)	Acc@5 100.00 (100.00)
Epoch: [78][ 60/391]	Time  0.039 ( 0.034)	Data  0.001 ( 0.004)	Loss 6.6922e-02 (2.7720e-02)	Acc@1  97.66 ( 99.14)	Acc@5 100.00 (100.00)
Epoch: [78][ 70/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.004)	Loss 1.3533e-02 (2.7902e-02)	Acc@1 100.00 ( 99.20)	Acc@5 100.00 (100.00)
Epoch: [78][ 80/391]	Time  0.029 ( 0.033)	Data  0.001 ( 0.003)	Loss 5.2922e-02 (2.7642e-02)	Acc@1  98.44 ( 99.20)	Acc@5 100.00 (100.00)
Epoch: [78][ 90/391]	Time  0.028 ( 0.033)	Data  0.001 ( 0.003)	Loss 1.4102e-02 (2.7160e-02)	Acc@1 100.00 ( 99.21)	Acc@5 100.00 (100.00)
Epoch: [78][100/391]	Time  0.034 ( 0.033)	Data  0.001 ( 0.003)	Loss 4.0031e-02 (2.8177e-02)	Acc@1  98.44 ( 99.16)	Acc@5 100.00 (100.00)
Epoch: [78][110/391]	Time  0.030 ( 0.033)	Data  0.001 ( 0.003)	Loss 1.0782e-02 (2.7685e-02)	Acc@1 100.00 ( 99.17)	Acc@5 100.00 (100.00)
Epoch: [78][120/391]	Time  0.030 ( 0.033)	Data  0.001 ( 0.003)	Loss 2.2665e-02 (2.7170e-02)	Acc@1  99.22 ( 99.17)	Acc@5 100.00 (100.00)
Epoch: [78][130/391]	Time  0.030 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.3548e-02 (2.7644e-02)	Acc@1 100.00 ( 99.14)	Acc@5 100.00 (100.00)
Epoch: [78][140/391]	Time  0.030 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.0795e-02 (2.7538e-02)	Acc@1 100.00 ( 99.14)	Acc@5 100.00 (100.00)
Epoch: [78][150/391]	Time  0.029 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.6574e-02 (2.7862e-02)	Acc@1  99.22 ( 99.12)	Acc@5 100.00 (100.00)
Epoch: [78][160/391]	Time  0.028 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.5332e-02 (2.7523e-02)	Acc@1 100.00 ( 99.14)	Acc@5 100.00 (100.00)
Epoch: [78][170/391]	Time  0.030 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.2909e-02 (2.7404e-02)	Acc@1  98.44 ( 99.14)	Acc@5 100.00 (100.00)
Epoch: [78][180/391]	Time  0.032 ( 0.032)	Data  0.001 ( 0.002)	Loss 5.0687e-02 (2.7252e-02)	Acc@1  97.66 ( 99.13)	Acc@5 100.00 (100.00)
Epoch: [78][190/391]	Time  0.029 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.7299e-02 (2.7324e-02)	Acc@1  99.22 ( 99.13)	Acc@5 100.00 (100.00)
Epoch: [78][200/391]	Time  0.030 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.1903e-02 (2.7377e-02)	Acc@1  99.22 ( 99.14)	Acc@5 100.00 (100.00)
Epoch: [78][210/391]	Time  0.029 ( 0.032)	Data  0.001 ( 0.002)	Loss 4.5685e-02 (2.7151e-02)	Acc@1  98.44 ( 99.14)	Acc@5 100.00 (100.00)
Epoch: [78][220/391]	Time  0.032 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.3002e-02 (2.7226e-02)	Acc@1  99.22 ( 99.14)	Acc@5 100.00 (100.00)
Epoch: [78][230/391]	Time  0.030 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.4196e-02 (2.7047e-02)	Acc@1  99.22 ( 99.14)	Acc@5 100.00 (100.00)
Epoch: [78][240/391]	Time  0.034 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.5345e-02 (2.7227e-02)	Acc@1  98.44 ( 99.13)	Acc@5 100.00 (100.00)
Epoch: [78][250/391]	Time  0.030 ( 0.032)	Data  0.001 ( 0.002)	Loss 4.3722e-02 (2.7218e-02)	Acc@1  96.88 ( 99.13)	Acc@5 100.00 (100.00)
Epoch: [78][260/391]	Time  0.029 ( 0.032)	Data  0.001 ( 0.002)	Loss 6.4132e-03 (2.7142e-02)	Acc@1 100.00 ( 99.13)	Acc@5 100.00 (100.00)
Epoch: [78][270/391]	Time  0.029 ( 0.032)	Data  0.001 ( 0.002)	Loss 3.2387e-02 (2.7188e-02)	Acc@1  99.22 ( 99.12)	Acc@5 100.00 (100.00)
Epoch: [78][280/391]	Time  0.030 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.6242e-02 (2.7839e-02)	Acc@1  99.22 ( 99.10)	Acc@5 100.00 (100.00)
Epoch: [78][290/391]	Time  0.033 ( 0.032)	Data  0.001 ( 0.002)	Loss 3.7791e-02 (2.7687e-02)	Acc@1  98.44 ( 99.10)	Acc@5 100.00 (100.00)
Epoch: [78][300/391]	Time  0.030 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.3410e-02 (2.7542e-02)	Acc@1  99.22 ( 99.10)	Acc@5 100.00 (100.00)
Epoch: [78][310/391]	Time  0.032 ( 0.032)	Data  0.001 ( 0.002)	Loss 3.1883e-02 (2.7472e-02)	Acc@1  99.22 ( 99.11)	Acc@5 100.00 (100.00)
Epoch: [78][320/391]	Time  0.033 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.0896e-02 (2.7335e-02)	Acc@1 100.00 ( 99.12)	Acc@5 100.00 (100.00)
Epoch: [78][330/391]	Time  0.030 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.3124e-02 (2.7014e-02)	Acc@1 100.00 ( 99.14)	Acc@5 100.00 (100.00)
Epoch: [78][340/391]	Time  0.027 ( 0.031)	Data  0.001 ( 0.002)	Loss 3.2958e-02 (2.7088e-02)	Acc@1  99.22 ( 99.14)	Acc@5 100.00 (100.00)
Epoch: [78][350/391]	Time  0.032 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.1957e-02 (2.7155e-02)	Acc@1 100.00 ( 99.14)	Acc@5 100.00 (100.00)
Epoch: [78][360/391]	Time  0.029 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.0593e-02 (2.7047e-02)	Acc@1 100.00 ( 99.15)	Acc@5 100.00 (100.00)
Epoch: [78][370/391]	Time  0.030 ( 0.031)	Data  0.001 ( 0.002)	Loss 3.7744e-02 (2.7072e-02)	Acc@1  98.44 ( 99.15)	Acc@5 100.00 (100.00)
Epoch: [78][380/391]	Time  0.034 ( 0.031)	Data  0.001 ( 0.002)	Loss 3.4655e-02 (2.7033e-02)	Acc@1  99.22 ( 99.16)	Acc@5 100.00 (100.00)
Epoch: [78][390/391]	Time  0.022 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.0579e-01 (2.7279e-02)	Acc@1  97.50 ( 99.15)	Acc@5 100.00 (100.00)
## e[78] optimizer.zero_grad (sum) time: 0.0677647590637207
## e[78]       loss.backward (sum) time: 2.474440097808838
## e[78]      optimizer.step (sum) time: 0.536475419998169
## epoch[78] training(only) time: 12.366029977798462
# Switched to evaluate mode...
Test: [  0/100]	Time  0.179 ( 0.179)	Loss 1.9095e-01 (1.9095e-01)	Acc@1  95.00 ( 95.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.023 ( 0.036)	Loss 5.2856e-01 (3.3587e-01)	Acc@1  90.00 ( 92.18)	Acc@5 100.00 (100.00)
Test: [ 20/100]	Time  0.024 ( 0.030)	Loss 3.6248e-01 (3.7985e-01)	Acc@1  88.00 ( 91.19)	Acc@5 100.00 ( 99.71)
Test: [ 30/100]	Time  0.020 ( 0.027)	Loss 4.9787e-01 (4.1107e-01)	Acc@1  89.00 ( 91.03)	Acc@5  97.00 ( 99.61)
Test: [ 40/100]	Time  0.018 ( 0.025)	Loss 3.8132e-01 (4.2475e-01)	Acc@1  89.00 ( 90.88)	Acc@5 100.00 ( 99.61)
Test: [ 50/100]	Time  0.019 ( 0.025)	Loss 1.2922e-01 (4.1679e-01)	Acc@1  95.00 ( 91.12)	Acc@5 100.00 ( 99.61)
Test: [ 60/100]	Time  0.022 ( 0.024)	Loss 4.5966e-01 (4.0296e-01)	Acc@1  93.00 ( 91.11)	Acc@5 100.00 ( 99.66)
Test: [ 70/100]	Time  0.017 ( 0.024)	Loss 4.8358e-01 (3.9259e-01)	Acc@1  89.00 ( 91.23)	Acc@5 100.00 ( 99.69)
Test: [ 80/100]	Time  0.022 ( 0.023)	Loss 2.2169e-01 (3.8509e-01)	Acc@1  95.00 ( 91.30)	Acc@5 100.00 ( 99.72)
Test: [ 90/100]	Time  0.017 ( 0.023)	Loss 2.7885e-01 (3.9109e-01)	Acc@1  95.00 ( 91.21)	Acc@5 100.00 ( 99.75)
 * Acc@1 91.180 Acc@5 99.750
### epoch[78] execution time: 14.747368335723877
EPOCH 79
REMOVING: module.fire8.squeeze.1.bias
REMOVING: module.fire8.expand_1x1.0.weight
i:   0, name: module.fire8.expand_1x1.0.bias  changing lr from: 0.001069733097291952   to: 0.001004369505446367
i:   1, name: module.fire8.expand_1x1.1.weight  changing lr from: 0.001128440245871042   to: 0.001026136172790403
i:   2, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.001204216033518750   to: 0.001065761458848346
i:   3, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.001296613027309639   to: 0.001122795155163180
i:   4, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.001405188309214843   to: 0.001196790949251835
i:   5, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.001529503709529888   to: 0.001287306695836942
i:   6, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.001669126020829503   to: 0.001393904667140432
i:   7, name:  module.fire9.squeeze.0.weight  changing lr from: 0.001823627193364796   to: 0.001516151783188795
i:   8, name:    module.fire9.squeeze.0.bias  changing lr from: 0.001992584512788558   to: 0.001653619823050389
i:   9, name:  module.fire9.squeeze.1.weight  changing lr from: 0.002175580761064893   to: 0.001805885617896413
i:  10, name:    module.fire9.squeeze.1.bias  changing lr from: 0.002372204361390106   to: 0.001972531226748080
i:  11, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.002582049507923378   to: 0.002153144095744069
i:  12, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.002804716281096863   to: 0.002347317201734177
i:  13, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.003039810749247784   to: 0.002554649180977081
i:  14, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.003286945057287066   to: 0.002774744443692950
i:  15, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.003545737503092893   to: 0.003007213275194497
i:  16, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.003815812602291096   to: 0.003251671924293802
i:  17, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.004096801142058558   to: 0.003507742679656028
i:  18, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.004388340224561398   to: 0.003775053934746230
i:  19, name:           module.conv10.weight  changing lr from: 0.004690073300614627   to: 0.004053240241990141
i:  20, name:             module.conv10.bias  changing lr from: 0.005001650194126833   to: 0.004341942356746003



# Switched to train mode...
Epoch: [79][  0/391]	Time  0.205 ( 0.205)	Data  0.173 ( 0.173)	Loss 2.6891e-02 (2.6891e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [79][ 10/391]	Time  0.029 ( 0.046)	Data  0.001 ( 0.017)	Loss 1.3925e-02 (2.4874e-02)	Acc@1 100.00 ( 99.36)	Acc@5 100.00 (100.00)
Epoch: [79][ 20/391]	Time  0.031 ( 0.039)	Data  0.001 ( 0.009)	Loss 4.7456e-03 (2.3800e-02)	Acc@1 100.00 ( 99.40)	Acc@5 100.00 (100.00)
Epoch: [79][ 30/391]	Time  0.033 ( 0.036)	Data  0.001 ( 0.007)	Loss 1.2859e-02 (2.6359e-02)	Acc@1 100.00 ( 99.27)	Acc@5 100.00 (100.00)
Epoch: [79][ 40/391]	Time  0.030 ( 0.035)	Data  0.001 ( 0.005)	Loss 1.1698e-02 (2.3223e-02)	Acc@1  99.22 ( 99.35)	Acc@5 100.00 (100.00)
Epoch: [79][ 50/391]	Time  0.026 ( 0.034)	Data  0.001 ( 0.005)	Loss 5.8076e-03 (2.3104e-02)	Acc@1 100.00 ( 99.33)	Acc@5 100.00 (100.00)
Epoch: [79][ 60/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.004)	Loss 1.5346e-02 (2.3547e-02)	Acc@1  99.22 ( 99.30)	Acc@5 100.00 (100.00)
Epoch: [79][ 70/391]	Time  0.028 ( 0.033)	Data  0.001 ( 0.004)	Loss 4.7490e-02 (2.5140e-02)	Acc@1  98.44 ( 99.26)	Acc@5 100.00 (100.00)
Epoch: [79][ 80/391]	Time  0.027 ( 0.033)	Data  0.001 ( 0.003)	Loss 7.9180e-02 (2.6886e-02)	Acc@1  96.88 ( 99.21)	Acc@5 100.00 (100.00)
Epoch: [79][ 90/391]	Time  0.034 ( 0.033)	Data  0.001 ( 0.003)	Loss 2.9247e-02 (2.6837e-02)	Acc@1  99.22 ( 99.21)	Acc@5 100.00 (100.00)
Epoch: [79][100/391]	Time  0.029 ( 0.032)	Data  0.001 ( 0.003)	Loss 7.1186e-02 (2.7063e-02)	Acc@1  97.66 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [79][110/391]	Time  0.029 ( 0.032)	Data  0.001 ( 0.003)	Loss 6.6911e-03 (2.6177e-02)	Acc@1 100.00 ( 99.26)	Acc@5 100.00 (100.00)
Epoch: [79][120/391]	Time  0.028 ( 0.032)	Data  0.001 ( 0.003)	Loss 4.0760e-02 (2.6351e-02)	Acc@1  99.22 ( 99.24)	Acc@5 100.00 (100.00)
Epoch: [79][130/391]	Time  0.028 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.8052e-02 (2.5935e-02)	Acc@1  99.22 ( 99.24)	Acc@5 100.00 (100.00)
Epoch: [79][140/391]	Time  0.035 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.2450e-02 (2.5709e-02)	Acc@1 100.00 ( 99.26)	Acc@5 100.00 (100.00)
Epoch: [79][150/391]	Time  0.032 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.8217e-02 (2.5623e-02)	Acc@1  98.44 ( 99.25)	Acc@5 100.00 (100.00)
Epoch: [79][160/391]	Time  0.029 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.8318e-02 (2.5518e-02)	Acc@1  98.44 ( 99.24)	Acc@5 100.00 (100.00)
Epoch: [79][170/391]	Time  0.029 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.3182e-02 (2.6470e-02)	Acc@1 100.00 ( 99.21)	Acc@5 100.00 (100.00)
Epoch: [79][180/391]	Time  0.034 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.4035e-02 (2.6269e-02)	Acc@1 100.00 ( 99.21)	Acc@5 100.00 (100.00)
Epoch: [79][190/391]	Time  0.028 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.9018e-02 (2.6488e-02)	Acc@1  99.22 ( 99.20)	Acc@5 100.00 (100.00)
Epoch: [79][200/391]	Time  0.034 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.2594e-02 (2.6719e-02)	Acc@1  99.22 ( 99.17)	Acc@5 100.00 (100.00)
Epoch: [79][210/391]	Time  0.029 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.2806e-02 (2.7065e-02)	Acc@1 100.00 ( 99.16)	Acc@5 100.00 (100.00)
Epoch: [79][220/391]	Time  0.029 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.6686e-02 (2.7126e-02)	Acc@1  99.22 ( 99.15)	Acc@5 100.00 (100.00)
Epoch: [79][230/391]	Time  0.031 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.1316e-02 (2.7154e-02)	Acc@1 100.00 ( 99.14)	Acc@5 100.00 (100.00)
Epoch: [79][240/391]	Time  0.032 ( 0.031)	Data  0.001 ( 0.002)	Loss 3.3496e-02 (2.7351e-02)	Acc@1  99.22 ( 99.14)	Acc@5 100.00 (100.00)
Epoch: [79][250/391]	Time  0.031 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.7352e-02 (2.7715e-02)	Acc@1  98.44 ( 99.12)	Acc@5 100.00 (100.00)
Epoch: [79][260/391]	Time  0.029 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.1411e-02 (2.7463e-02)	Acc@1  99.22 ( 99.13)	Acc@5 100.00 (100.00)
Epoch: [79][270/391]	Time  0.029 ( 0.031)	Data  0.001 ( 0.002)	Loss 4.8910e-03 (2.7467e-02)	Acc@1 100.00 ( 99.13)	Acc@5 100.00 (100.00)
Epoch: [79][280/391]	Time  0.033 ( 0.031)	Data  0.001 ( 0.002)	Loss 3.2178e-02 (2.7452e-02)	Acc@1  99.22 ( 99.12)	Acc@5 100.00 (100.00)
Epoch: [79][290/391]	Time  0.032 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.5296e-02 (2.7597e-02)	Acc@1 100.00 ( 99.12)	Acc@5 100.00 (100.00)
Epoch: [79][300/391]	Time  0.029 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.7320e-02 (2.7481e-02)	Acc@1  99.22 ( 99.12)	Acc@5 100.00 (100.00)
Epoch: [79][310/391]	Time  0.032 ( 0.031)	Data  0.001 ( 0.002)	Loss 3.2201e-02 (2.7129e-02)	Acc@1  98.44 ( 99.14)	Acc@5 100.00 (100.00)
Epoch: [79][320/391]	Time  0.041 ( 0.031)	Data  0.001 ( 0.002)	Loss 3.7338e-02 (2.7463e-02)	Acc@1  98.44 ( 99.13)	Acc@5 100.00 (100.00)
Epoch: [79][330/391]	Time  0.029 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.1084e-01 (2.7624e-02)	Acc@1  95.31 ( 99.12)	Acc@5 100.00 (100.00)
Epoch: [79][340/391]	Time  0.031 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.8647e-02 (2.7469e-02)	Acc@1  99.22 ( 99.12)	Acc@5 100.00 (100.00)
Epoch: [79][350/391]	Time  0.030 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.6816e-02 (2.7655e-02)	Acc@1  98.44 ( 99.11)	Acc@5 100.00 (100.00)
Epoch: [79][360/391]	Time  0.036 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.6447e-02 (2.7528e-02)	Acc@1 100.00 ( 99.11)	Acc@5 100.00 (100.00)
Epoch: [79][370/391]	Time  0.029 ( 0.031)	Data  0.001 ( 0.002)	Loss 3.9137e-02 (2.7615e-02)	Acc@1  99.22 ( 99.11)	Acc@5 100.00 (100.00)
Epoch: [79][380/391]	Time  0.030 ( 0.031)	Data  0.001 ( 0.002)	Loss 8.7285e-02 (2.7884e-02)	Acc@1  96.88 ( 99.10)	Acc@5 100.00 (100.00)
Epoch: [79][390/391]	Time  0.020 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.2448e-02 (2.7904e-02)	Acc@1 100.00 ( 99.10)	Acc@5 100.00 (100.00)
## e[79] optimizer.zero_grad (sum) time: 0.060896873474121094
## e[79]       loss.backward (sum) time: 2.3310868740081787
## e[79]      optimizer.step (sum) time: 0.48958587646484375
## epoch[79] training(only) time: 12.307258367538452
# Switched to evaluate mode...
Test: [  0/100]	Time  0.174 ( 0.174)	Loss 1.6720e-01 (1.6720e-01)	Acc@1  96.00 ( 96.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.023 ( 0.036)	Loss 4.9608e-01 (3.3038e-01)	Acc@1  90.00 ( 92.18)	Acc@5 100.00 ( 99.91)
Test: [ 20/100]	Time  0.023 ( 0.029)	Loss 3.8297e-01 (3.8047e-01)	Acc@1  87.00 ( 91.24)	Acc@5 100.00 ( 99.67)
Test: [ 30/100]	Time  0.021 ( 0.026)	Loss 5.1478e-01 (4.1186e-01)	Acc@1  88.00 ( 91.03)	Acc@5  98.00 ( 99.61)
Test: [ 40/100]	Time  0.023 ( 0.025)	Loss 3.9925e-01 (4.2506e-01)	Acc@1  90.00 ( 90.90)	Acc@5 100.00 ( 99.61)
Test: [ 50/100]	Time  0.024 ( 0.024)	Loss 1.1535e-01 (4.1867e-01)	Acc@1  95.00 ( 91.02)	Acc@5 100.00 ( 99.63)
Test: [ 60/100]	Time  0.019 ( 0.024)	Loss 4.7397e-01 (4.0433e-01)	Acc@1  93.00 ( 91.02)	Acc@5  99.00 ( 99.66)
Test: [ 70/100]	Time  0.024 ( 0.023)	Loss 5.1435e-01 (3.9498e-01)	Acc@1  89.00 ( 91.17)	Acc@5 100.00 ( 99.69)
Test: [ 80/100]	Time  0.019 ( 0.023)	Loss 2.2588e-01 (3.8806e-01)	Acc@1  94.00 ( 91.21)	Acc@5 100.00 ( 99.70)
Test: [ 90/100]	Time  0.020 ( 0.023)	Loss 2.7232e-01 (3.9596e-01)	Acc@1  95.00 ( 91.13)	Acc@5 100.00 ( 99.74)
 * Acc@1 91.060 Acc@5 99.730
### epoch[79] execution time: 14.64921259880066
EPOCH 80
REMOVING: module.fire8.expand_1x1.0.bias
REMOVING: module.fire8.expand_1x1.1.weight
i:   0, name: module.fire8.expand_1x1.1.bias  changing lr from: 0.001065761458848346   to: 0.001003706272527948
i:   1, name: module.fire8.expand_3x3.0.weight  changing lr from: 0.001122795155163180   to: 0.001024363606799349
i:   2, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.001196790949251835   to: 0.001062756700030997
i:   3, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.001287306695836942   to: 0.001118440746658211
i:   4, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.001393904667140432   to: 0.001190974754867984
i:   5, name:  module.fire9.squeeze.0.weight  changing lr from: 0.001516151783188795   to: 0.001279921813565021
i:   6, name:    module.fire9.squeeze.0.bias  changing lr from: 0.001653619823050389   to: 0.001384849338856824
i:   7, name:  module.fire9.squeeze.1.weight  changing lr from: 0.001805885617896413   to: 0.001505329300982121
i:   8, name:    module.fire9.squeeze.1.bias  changing lr from: 0.001972531226748080   to: 0.001640938432578486
i:   9, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.002153144095744069   to: 0.001791258419157192
i:  10, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.002347317201734177   to: 0.001955876072625034
i:  11, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.002554649180977081   to: 0.002134383488665630
i:  12, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.002774744443692950   to: 0.002326378188765048
i:  13, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.003007213275194497   to: 0.002531463247639936
i:  14, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.003251671924293802   to: 0.002749247406799559
i:  15, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.003507742679656028   to: 0.002979345174947167
i:  16, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.003775053934746230   to: 0.003221376915900558
i:  17, name:           module.conv10.weight  changing lr from: 0.004053240241990141   to: 0.003474968924686333
i:  18, name:             module.conv10.bias  changing lr from: 0.004341942356746003   to: 0.003739753492438124



# Switched to train mode...
Epoch: [80][  0/391]	Time  0.202 ( 0.202)	Data  0.170 ( 0.170)	Loss 7.6539e-03 (7.6539e-03)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [80][ 10/391]	Time  0.027 ( 0.047)	Data  0.001 ( 0.016)	Loss 2.0297e-02 (2.3780e-02)	Acc@1  99.22 ( 99.15)	Acc@5 100.00 (100.00)
Epoch: [80][ 20/391]	Time  0.029 ( 0.039)	Data  0.001 ( 0.009)	Loss 5.0739e-02 (2.7456e-02)	Acc@1  97.66 ( 99.03)	Acc@5 100.00 (100.00)
Epoch: [80][ 30/391]	Time  0.029 ( 0.036)	Data  0.001 ( 0.007)	Loss 8.5280e-03 (2.4221e-02)	Acc@1 100.00 ( 99.19)	Acc@5 100.00 (100.00)
Epoch: [80][ 40/391]	Time  0.032 ( 0.035)	Data  0.001 ( 0.005)	Loss 3.7548e-02 (2.4513e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [80][ 50/391]	Time  0.028 ( 0.034)	Data  0.001 ( 0.004)	Loss 7.1505e-03 (2.7564e-02)	Acc@1 100.00 ( 99.08)	Acc@5 100.00 (100.00)
Epoch: [80][ 60/391]	Time  0.029 ( 0.034)	Data  0.001 ( 0.004)	Loss 1.7113e-02 (2.7141e-02)	Acc@1  99.22 ( 99.10)	Acc@5 100.00 (100.00)
Epoch: [80][ 70/391]	Time  0.030 ( 0.033)	Data  0.001 ( 0.004)	Loss 3.8693e-02 (2.8265e-02)	Acc@1  99.22 ( 99.04)	Acc@5 100.00 (100.00)
Epoch: [80][ 80/391]	Time  0.029 ( 0.033)	Data  0.001 ( 0.003)	Loss 2.7804e-02 (2.7564e-02)	Acc@1  99.22 ( 99.07)	Acc@5 100.00 (100.00)
Epoch: [80][ 90/391]	Time  0.027 ( 0.033)	Data  0.001 ( 0.003)	Loss 1.9258e-02 (2.8397e-02)	Acc@1  99.22 ( 99.06)	Acc@5 100.00 (100.00)
Epoch: [80][100/391]	Time  0.028 ( 0.033)	Data  0.001 ( 0.003)	Loss 3.4155e-02 (2.8588e-02)	Acc@1  99.22 ( 99.04)	Acc@5 100.00 (100.00)
Epoch: [80][110/391]	Time  0.031 ( 0.032)	Data  0.001 ( 0.003)	Loss 1.0601e-02 (2.7871e-02)	Acc@1 100.00 ( 99.09)	Acc@5 100.00 (100.00)
Epoch: [80][120/391]	Time  0.027 ( 0.032)	Data  0.001 ( 0.003)	Loss 5.0577e-02 (2.8162e-02)	Acc@1  98.44 ( 99.09)	Acc@5 100.00 (100.00)
Epoch: [80][130/391]	Time  0.029 ( 0.032)	Data  0.001 ( 0.002)	Loss 5.4018e-03 (2.7476e-02)	Acc@1 100.00 ( 99.12)	Acc@5 100.00 (100.00)
Epoch: [80][140/391]	Time  0.029 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.4237e-02 (2.7548e-02)	Acc@1  99.22 ( 99.11)	Acc@5 100.00 (100.00)
Epoch: [80][150/391]	Time  0.028 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.0023e-02 (2.7131e-02)	Acc@1 100.00 ( 99.13)	Acc@5 100.00 (100.00)
Epoch: [80][160/391]	Time  0.028 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.7658e-02 (2.6902e-02)	Acc@1  99.22 ( 99.12)	Acc@5 100.00 (100.00)
Epoch: [80][170/391]	Time  0.029 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.3235e-02 (2.6712e-02)	Acc@1 100.00 ( 99.12)	Acc@5 100.00 (100.00)
Epoch: [80][180/391]	Time  0.033 ( 0.032)	Data  0.001 ( 0.002)	Loss 6.5954e-03 (2.6289e-02)	Acc@1 100.00 ( 99.15)	Acc@5 100.00 (100.00)
Epoch: [80][190/391]	Time  0.029 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.2766e-02 (2.6571e-02)	Acc@1  99.22 ( 99.15)	Acc@5 100.00 (100.00)
Epoch: [80][200/391]	Time  0.029 ( 0.032)	Data  0.001 ( 0.002)	Loss 3.2925e-02 (2.6695e-02)	Acc@1  99.22 ( 99.14)	Acc@5 100.00 (100.00)
Epoch: [80][210/391]	Time  0.031 ( 0.032)	Data  0.001 ( 0.002)	Loss 5.8245e-02 (2.7779e-02)	Acc@1  98.44 ( 99.10)	Acc@5 100.00 (100.00)
Epoch: [80][220/391]	Time  0.035 ( 0.032)	Data  0.001 ( 0.002)	Loss 5.0219e-02 (2.7957e-02)	Acc@1  99.22 ( 99.10)	Acc@5 100.00 (100.00)
Epoch: [80][230/391]	Time  0.034 ( 0.032)	Data  0.001 ( 0.002)	Loss 1.0769e-02 (2.7864e-02)	Acc@1 100.00 ( 99.10)	Acc@5 100.00 (100.00)
Epoch: [80][240/391]	Time  0.034 ( 0.032)	Data  0.001 ( 0.002)	Loss 4.2451e-02 (2.7744e-02)	Acc@1  98.44 ( 99.10)	Acc@5 100.00 (100.00)
Epoch: [80][250/391]	Time  0.035 ( 0.032)	Data  0.001 ( 0.002)	Loss 8.4339e-03 (2.7618e-02)	Acc@1 100.00 ( 99.12)	Acc@5 100.00 (100.00)
Epoch: [80][260/391]	Time  0.029 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.0944e-02 (2.7630e-02)	Acc@1  99.22 ( 99.12)	Acc@5 100.00 (100.00)
Epoch: [80][270/391]	Time  0.033 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.9865e-02 (2.7531e-02)	Acc@1 100.00 ( 99.11)	Acc@5 100.00 (100.00)
Epoch: [80][280/391]	Time  0.031 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.0735e-02 (2.7432e-02)	Acc@1  99.22 ( 99.11)	Acc@5 100.00 (100.00)
Epoch: [80][290/391]	Time  0.027 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.5457e-02 (2.7103e-02)	Acc@1 100.00 ( 99.12)	Acc@5 100.00 (100.00)
Epoch: [80][300/391]	Time  0.031 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.4776e-02 (2.7016e-02)	Acc@1  99.22 ( 99.13)	Acc@5 100.00 (100.00)
Epoch: [80][310/391]	Time  0.029 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.9800e-02 (2.6623e-02)	Acc@1  99.22 ( 99.14)	Acc@5 100.00 (100.00)
Epoch: [80][320/391]	Time  0.031 ( 0.031)	Data  0.001 ( 0.002)	Loss 5.5459e-02 (2.6724e-02)	Acc@1  98.44 ( 99.15)	Acc@5 100.00 (100.00)
Epoch: [80][330/391]	Time  0.029 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.3234e-02 (2.6829e-02)	Acc@1 100.00 ( 99.15)	Acc@5 100.00 (100.00)
Epoch: [80][340/391]	Time  0.029 ( 0.031)	Data  0.001 ( 0.002)	Loss 4.0531e-02 (2.6878e-02)	Acc@1  98.44 ( 99.14)	Acc@5 100.00 (100.00)
Epoch: [80][350/391]	Time  0.031 ( 0.031)	Data  0.001 ( 0.002)	Loss 3.7915e-02 (2.7055e-02)	Acc@1  99.22 ( 99.14)	Acc@5 100.00 (100.00)
Epoch: [80][360/391]	Time  0.029 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.3547e-02 (2.7130e-02)	Acc@1 100.00 ( 99.13)	Acc@5 100.00 (100.00)
Epoch: [80][370/391]	Time  0.032 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.1223e-02 (2.7111e-02)	Acc@1 100.00 ( 99.14)	Acc@5 100.00 (100.00)
Epoch: [80][380/391]	Time  0.028 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.9234e-02 (2.7151e-02)	Acc@1  99.22 ( 99.14)	Acc@5 100.00 (100.00)
Epoch: [80][390/391]	Time  0.022 ( 0.031)	Data  0.001 ( 0.002)	Loss 3.9624e-03 (2.6924e-02)	Acc@1 100.00 ( 99.15)	Acc@5 100.00 (100.00)
## e[80] optimizer.zero_grad (sum) time: 0.05720114707946777
## e[80]       loss.backward (sum) time: 2.3117926120758057
## e[80]      optimizer.step (sum) time: 0.44920873641967773
## epoch[80] training(only) time: 12.283408164978027
# Switched to evaluate mode...
Test: [  0/100]	Time  0.178 ( 0.178)	Loss 1.6703e-01 (1.6703e-01)	Acc@1  96.00 ( 96.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.024 ( 0.035)	Loss 5.3704e-01 (3.3182e-01)	Acc@1  89.00 ( 92.00)	Acc@5 100.00 (100.00)
Test: [ 20/100]	Time  0.022 ( 0.029)	Loss 3.8174e-01 (3.8027e-01)	Acc@1  89.00 ( 91.38)	Acc@5 100.00 ( 99.71)
Test: [ 30/100]	Time  0.020 ( 0.027)	Loss 5.1058e-01 (4.1104e-01)	Acc@1  90.00 ( 91.26)	Acc@5  98.00 ( 99.65)
Test: [ 40/100]	Time  0.024 ( 0.026)	Loss 4.0969e-01 (4.2453e-01)	Acc@1  90.00 ( 91.07)	Acc@5 100.00 ( 99.61)
Test: [ 50/100]	Time  0.021 ( 0.025)	Loss 1.2560e-01 (4.1732e-01)	Acc@1  95.00 ( 91.14)	Acc@5 100.00 ( 99.61)
Test: [ 60/100]	Time  0.018 ( 0.024)	Loss 4.6473e-01 (4.0288e-01)	Acc@1  92.00 ( 91.10)	Acc@5  99.00 ( 99.64)
Test: [ 70/100]	Time  0.021 ( 0.024)	Loss 5.0347e-01 (3.9340e-01)	Acc@1  88.00 ( 91.20)	Acc@5 100.00 ( 99.68)
Test: [ 80/100]	Time  0.022 ( 0.023)	Loss 2.1122e-01 (3.8654e-01)	Acc@1  96.00 ( 91.26)	Acc@5 100.00 ( 99.70)
Test: [ 90/100]	Time  0.022 ( 0.023)	Loss 2.7533e-01 (3.9375e-01)	Acc@1  94.00 ( 91.18)	Acc@5 100.00 ( 99.74)
 * Acc@1 91.140 Acc@5 99.740
### epoch[80] execution time: 14.618328094482422
EPOCH 81
REMOVING: module.fire8.expand_1x1.1.bias
REMOVING: module.fire8.expand_3x3.0.weight
i:   0, name: module.fire8.expand_3x3.0.bias  changing lr from: 0.001062756700030997   to: 0.001003285693309052
i:   1, name: module.fire8.expand_3x3.1.weight  changing lr from: 0.001118440746658211   to: 0.001023154955715848
i:   2, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.001190974754867984   to: 0.001060632015731526
i:   3, name:  module.fire9.squeeze.0.weight  changing lr from: 0.001279921813565021   to: 0.001115277401700664
i:   4, name:    module.fire9.squeeze.0.bias  changing lr from: 0.001384849338856824   to: 0.001186655380664685
i:   5, name:  module.fire9.squeeze.1.weight  changing lr from: 0.001505329300982121   to: 0.001274334220832600
i:   6, name:    module.fire9.squeeze.1.bias  changing lr from: 0.001640938432578486   to: 0.001377886434028008
i:   7, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.001791258419157192   to: 0.001496888999011630
i:   8, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.001955876072625034   to: 0.001630923566551200
i:   9, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.002134383488665630   to: 0.001779576647083491
i:  10, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.002326378188765048   to: 0.001942439781786120
i:  11, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.002531463247639936   to: 0.002119109697850068
i:  12, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.002749247406799559   to: 0.002309188448717436
i:  13, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.002979345174947167   to: 0.002512283540022647
i:  14, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.003221376915900558   to: 0.002728008041950036
i:  15, name:           module.conv10.weight  changing lr from: 0.003474968924686333   to: 0.002955980688694964
i:  16, name:             module.conv10.bias  changing lr from: 0.003739753492438124   to: 0.003195825965691140



# Switched to train mode...
Epoch: [81][  0/391]	Time  0.198 ( 0.198)	Data  0.166 ( 0.166)	Loss 2.4425e-02 (2.4425e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [81][ 10/391]	Time  0.031 ( 0.046)	Data  0.001 ( 0.016)	Loss 3.9058e-02 (2.9151e-02)	Acc@1  98.44 ( 99.01)	Acc@5 100.00 (100.00)
Epoch: [81][ 20/391]	Time  0.029 ( 0.039)	Data  0.001 ( 0.009)	Loss 2.7802e-02 (2.7619e-02)	Acc@1  98.44 ( 99.03)	Acc@5 100.00 (100.00)
Epoch: [81][ 30/391]	Time  0.028 ( 0.036)	Data  0.001 ( 0.006)	Loss 2.0637e-02 (2.4745e-02)	Acc@1  99.22 ( 99.19)	Acc@5 100.00 (100.00)
Epoch: [81][ 40/391]	Time  0.031 ( 0.034)	Data  0.001 ( 0.005)	Loss 6.3642e-03 (2.5343e-02)	Acc@1 100.00 ( 99.18)	Acc@5 100.00 (100.00)
Epoch: [81][ 50/391]	Time  0.033 ( 0.034)	Data  0.001 ( 0.004)	Loss 1.0455e-02 (2.5666e-02)	Acc@1 100.00 ( 99.13)	Acc@5 100.00 (100.00)
Epoch: [81][ 60/391]	Time  0.031 ( 0.033)	Data  0.001 ( 0.004)	Loss 2.7522e-02 (2.6813e-02)	Acc@1  99.22 ( 99.07)	Acc@5 100.00 (100.00)
Epoch: [81][ 70/391]	Time  0.028 ( 0.033)	Data  0.001 ( 0.003)	Loss 1.3449e-01 (2.7864e-02)	Acc@1  95.31 ( 99.05)	Acc@5 100.00 (100.00)
Epoch: [81][ 80/391]	Time  0.031 ( 0.032)	Data  0.001 ( 0.003)	Loss 2.3319e-02 (2.7369e-02)	Acc@1  99.22 ( 99.05)	Acc@5 100.00 (100.00)
Epoch: [81][ 90/391]	Time  0.033 ( 0.032)	Data  0.001 ( 0.003)	Loss 2.6291e-02 (2.7507e-02)	Acc@1  99.22 ( 99.03)	Acc@5 100.00 (100.00)
Epoch: [81][100/391]	Time  0.033 ( 0.032)	Data  0.001 ( 0.003)	Loss 2.1385e-02 (2.7513e-02)	Acc@1  99.22 ( 99.03)	Acc@5 100.00 (100.00)
Epoch: [81][110/391]	Time  0.028 ( 0.032)	Data  0.001 ( 0.003)	Loss 4.2308e-02 (2.7270e-02)	Acc@1  98.44 ( 99.04)	Acc@5 100.00 (100.00)
Epoch: [81][120/391]	Time  0.031 ( 0.032)	Data  0.001 ( 0.003)	Loss 1.1098e-02 (2.6518e-02)	Acc@1 100.00 ( 99.09)	Acc@5 100.00 (100.00)
Epoch: [81][130/391]	Time  0.028 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.6791e-02 (2.6240e-02)	Acc@1  99.22 ( 99.11)	Acc@5 100.00 (100.00)
Epoch: [81][140/391]	Time  0.033 ( 0.031)	Data  0.001 ( 0.002)	Loss 5.8367e-02 (2.5883e-02)	Acc@1  98.44 ( 99.14)	Acc@5 100.00 (100.00)
Epoch: [81][150/391]	Time  0.030 ( 0.031)	Data  0.001 ( 0.002)	Loss 4.4365e-02 (2.6111e-02)	Acc@1  98.44 ( 99.13)	Acc@5 100.00 (100.00)
Epoch: [81][160/391]	Time  0.036 ( 0.031)	Data  0.002 ( 0.002)	Loss 4.5771e-02 (2.6953e-02)	Acc@1  96.88 ( 99.11)	Acc@5 100.00 (100.00)
Epoch: [81][170/391]	Time  0.025 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.7204e-02 (2.6595e-02)	Acc@1  99.22 ( 99.13)	Acc@5 100.00 (100.00)
Epoch: [81][180/391]	Time  0.031 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.3657e-02 (2.6539e-02)	Acc@1  98.44 ( 99.11)	Acc@5 100.00 (100.00)
Epoch: [81][190/391]	Time  0.028 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.7372e-02 (2.6791e-02)	Acc@1 100.00 ( 99.10)	Acc@5 100.00 (100.00)
Epoch: [81][200/391]	Time  0.033 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.2944e-02 (2.6589e-02)	Acc@1  99.22 ( 99.10)	Acc@5 100.00 (100.00)
Epoch: [81][210/391]	Time  0.032 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.3479e-02 (2.6173e-02)	Acc@1 100.00 ( 99.12)	Acc@5 100.00 (100.00)
Epoch: [81][220/391]	Time  0.028 ( 0.031)	Data  0.001 ( 0.002)	Loss 4.7185e-02 (2.6068e-02)	Acc@1  98.44 ( 99.13)	Acc@5 100.00 (100.00)
Epoch: [81][230/391]	Time  0.033 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.4324e-02 (2.5851e-02)	Acc@1 100.00 ( 99.14)	Acc@5 100.00 (100.00)
Epoch: [81][240/391]	Time  0.029 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.4714e-02 (2.5664e-02)	Acc@1 100.00 ( 99.15)	Acc@5 100.00 (100.00)
Epoch: [81][250/391]	Time  0.029 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.4433e-02 (2.5440e-02)	Acc@1 100.00 ( 99.16)	Acc@5 100.00 (100.00)
Epoch: [81][260/391]	Time  0.031 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.2995e-02 (2.6010e-02)	Acc@1 100.00 ( 99.14)	Acc@5 100.00 (100.00)
Epoch: [81][270/391]	Time  0.032 ( 0.031)	Data  0.001 ( 0.002)	Loss 3.8189e-02 (2.5966e-02)	Acc@1  98.44 ( 99.14)	Acc@5 100.00 (100.00)
Epoch: [81][280/391]	Time  0.028 ( 0.031)	Data  0.001 ( 0.002)	Loss 7.3770e-03 (2.6353e-02)	Acc@1 100.00 ( 99.13)	Acc@5 100.00 (100.00)
Epoch: [81][290/391]	Time  0.029 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.2571e-02 (2.6650e-02)	Acc@1  99.22 ( 99.12)	Acc@5 100.00 (100.00)
Epoch: [81][300/391]	Time  0.034 ( 0.031)	Data  0.001 ( 0.002)	Loss 4.0615e-02 (2.6642e-02)	Acc@1  98.44 ( 99.12)	Acc@5 100.00 (100.00)
Epoch: [81][310/391]	Time  0.032 ( 0.031)	Data  0.003 ( 0.002)	Loss 1.4494e-02 (2.6512e-02)	Acc@1  99.22 ( 99.14)	Acc@5 100.00 (100.00)
Epoch: [81][320/391]	Time  0.031 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.9680e-02 (2.6505e-02)	Acc@1  99.22 ( 99.13)	Acc@5 100.00 (100.00)
Epoch: [81][330/391]	Time  0.031 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.0370e-02 (2.6694e-02)	Acc@1 100.00 ( 99.12)	Acc@5 100.00 (100.00)
Epoch: [81][340/391]	Time  0.028 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.2636e-02 (2.6658e-02)	Acc@1 100.00 ( 99.12)	Acc@5 100.00 (100.00)
Epoch: [81][350/391]	Time  0.027 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.8438e-02 (2.6540e-02)	Acc@1 100.00 ( 99.13)	Acc@5 100.00 (100.00)
Epoch: [81][360/391]	Time  0.033 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.3212e-02 (2.6474e-02)	Acc@1 100.00 ( 99.13)	Acc@5 100.00 (100.00)
Epoch: [81][370/391]	Time  0.032 ( 0.031)	Data  0.001 ( 0.002)	Loss 9.0420e-03 (2.6378e-02)	Acc@1 100.00 ( 99.13)	Acc@5 100.00 (100.00)
Epoch: [81][380/391]	Time  0.030 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.0517e-02 (2.6342e-02)	Acc@1  99.22 ( 99.14)	Acc@5 100.00 (100.00)
Epoch: [81][390/391]	Time  0.022 ( 0.031)	Data  0.001 ( 0.002)	Loss 5.6058e-02 (2.6403e-02)	Acc@1  97.50 ( 99.13)	Acc@5 100.00 (100.00)
## e[81] optimizer.zero_grad (sum) time: 0.05147957801818848
## e[81]       loss.backward (sum) time: 2.3193554878234863
## e[81]      optimizer.step (sum) time: 0.4059007167816162
## epoch[81] training(only) time: 12.13123083114624
# Switched to evaluate mode...
Test: [  0/100]	Time  0.178 ( 0.178)	Loss 1.5385e-01 (1.5385e-01)	Acc@1  96.00 ( 96.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.020 ( 0.035)	Loss 4.7642e-01 (3.3145e-01)	Acc@1  90.00 ( 92.27)	Acc@5 100.00 (100.00)
Test: [ 20/100]	Time  0.023 ( 0.029)	Loss 3.7703e-01 (3.8125e-01)	Acc@1  86.00 ( 91.29)	Acc@5 100.00 ( 99.71)
Test: [ 30/100]	Time  0.022 ( 0.027)	Loss 5.3244e-01 (4.1275e-01)	Acc@1  88.00 ( 91.10)	Acc@5  98.00 ( 99.58)
Test: [ 40/100]	Time  0.019 ( 0.026)	Loss 3.9472e-01 (4.2866e-01)	Acc@1  90.00 ( 90.90)	Acc@5 100.00 ( 99.59)
Test: [ 50/100]	Time  0.021 ( 0.025)	Loss 1.3074e-01 (4.2205e-01)	Acc@1  94.00 ( 90.96)	Acc@5 100.00 ( 99.59)
Test: [ 60/100]	Time  0.022 ( 0.024)	Loss 5.0024e-01 (4.0784e-01)	Acc@1  92.00 ( 91.00)	Acc@5  99.00 ( 99.62)
Test: [ 70/100]	Time  0.019 ( 0.023)	Loss 4.6572e-01 (3.9720e-01)	Acc@1  89.00 ( 91.11)	Acc@5 100.00 ( 99.66)
Test: [ 80/100]	Time  0.022 ( 0.023)	Loss 1.9884e-01 (3.8905e-01)	Acc@1  95.00 ( 91.21)	Acc@5 100.00 ( 99.69)
Test: [ 90/100]	Time  0.017 ( 0.023)	Loss 2.7087e-01 (3.9628e-01)	Acc@1  94.00 ( 91.15)	Acc@5 100.00 ( 99.71)
 * Acc@1 91.110 Acc@5 99.730
### epoch[81] execution time: 14.464643716812134
EPOCH 82
REMOVING: module.fire8.expand_3x3.0.bias
REMOVING: module.fire8.expand_3x3.1.weight
i:   0, name: module.fire8.expand_3x3.1.bias  changing lr from: 0.001060632015731526   to: 0.001003066399462587
i:   1, name:  module.fire9.squeeze.0.weight  changing lr from: 0.001115277401700664   to: 0.001022455597948134
i:   2, name:    module.fire9.squeeze.0.bias  changing lr from: 0.001186655380664685   to: 0.001059319875281760
i:   3, name:  module.fire9.squeeze.1.weight  changing lr from: 0.001274334220832600   to: 0.001113225024591373
i:   4, name:    module.fire9.squeeze.1.bias  changing lr from: 0.001377886434028008   to: 0.001183740509379848
i:   5, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.001496888999011630   to: 0.001270439721296356
i:   6, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.001630923566551200   to: 0.001372900218340305
i:   7, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.001779576647083491   to: 0.001490703944372700
i:   8, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.001942439781786120   to: 0.001623437430783142
i:   9, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.002119109697850068   to: 0.001770691981134602
i:  10, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.002309188448717436   to: 0.001932063839581693
i:  11, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.002512283540022647   to: 0.002107154343832318
i:  12, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.002728008041950036   to: 0.002295570063397211
i:  13, name:           module.conv10.weight  changing lr from: 0.002955980688694964   to: 0.002496922923846145
i:  14, name:             module.conv10.bias  changing lr from: 0.003195825965691140   to: 0.002710830317765122



# Switched to train mode...
Epoch: [82][  0/391]	Time  0.206 ( 0.206)	Data  0.174 ( 0.174)	Loss 1.0239e-02 (1.0239e-02)	Acc@1 100.00 (100.00)	Acc@5 100.00 (100.00)
Epoch: [82][ 10/391]	Time  0.028 ( 0.046)	Data  0.001 ( 0.017)	Loss 5.0532e-02 (3.0273e-02)	Acc@1  97.66 ( 98.86)	Acc@5 100.00 (100.00)
Epoch: [82][ 20/391]	Time  0.027 ( 0.038)	Data  0.001 ( 0.009)	Loss 1.3993e-02 (2.8246e-02)	Acc@1 100.00 ( 99.03)	Acc@5 100.00 (100.00)
Epoch: [82][ 30/391]	Time  0.030 ( 0.036)	Data  0.001 ( 0.007)	Loss 2.2289e-02 (3.0198e-02)	Acc@1  99.22 ( 98.92)	Acc@5 100.00 (100.00)
Epoch: [82][ 40/391]	Time  0.034 ( 0.034)	Data  0.001 ( 0.005)	Loss 6.5370e-02 (3.0299e-02)	Acc@1  96.88 ( 98.93)	Acc@5 100.00 (100.00)
Epoch: [82][ 50/391]	Time  0.027 ( 0.034)	Data  0.001 ( 0.005)	Loss 1.2812e-02 (2.8649e-02)	Acc@1 100.00 ( 99.00)	Acc@5 100.00 (100.00)
Epoch: [82][ 60/391]	Time  0.033 ( 0.033)	Data  0.001 ( 0.004)	Loss 6.1895e-02 (2.7176e-02)	Acc@1  97.66 ( 99.09)	Acc@5 100.00 (100.00)
Epoch: [82][ 70/391]	Time  0.033 ( 0.032)	Data  0.001 ( 0.004)	Loss 2.9328e-02 (2.6992e-02)	Acc@1  99.22 ( 99.12)	Acc@5 100.00 (100.00)
Epoch: [82][ 80/391]	Time  0.038 ( 0.032)	Data  0.001 ( 0.003)	Loss 3.0869e-02 (2.7799e-02)	Acc@1  98.44 ( 99.09)	Acc@5 100.00 (100.00)
Epoch: [82][ 90/391]	Time  0.032 ( 0.032)	Data  0.001 ( 0.003)	Loss 2.0602e-02 (2.7768e-02)	Acc@1  99.22 ( 99.08)	Acc@5 100.00 (100.00)
Epoch: [82][100/391]	Time  0.044 ( 0.032)	Data  0.001 ( 0.003)	Loss 3.4248e-02 (2.7549e-02)	Acc@1  99.22 ( 99.07)	Acc@5 100.00 (100.00)
Epoch: [82][110/391]	Time  0.028 ( 0.032)	Data  0.001 ( 0.003)	Loss 1.5298e-02 (2.7743e-02)	Acc@1 100.00 ( 99.06)	Acc@5 100.00 (100.00)
Epoch: [82][120/391]	Time  0.028 ( 0.032)	Data  0.001 ( 0.003)	Loss 2.6277e-02 (2.7282e-02)	Acc@1  99.22 ( 99.08)	Acc@5 100.00 (100.00)
Epoch: [82][130/391]	Time  0.030 ( 0.032)	Data  0.001 ( 0.003)	Loss 4.0176e-02 (2.7382e-02)	Acc@1  98.44 ( 99.10)	Acc@5 100.00 (100.00)
Epoch: [82][140/391]	Time  0.031 ( 0.032)	Data  0.001 ( 0.002)	Loss 2.5078e-02 (2.7538e-02)	Acc@1  98.44 ( 99.10)	Acc@5 100.00 (100.00)
Epoch: [82][150/391]	Time  0.029 ( 0.032)	Data  0.001 ( 0.002)	Loss 7.1999e-02 (2.7619e-02)	Acc@1  98.44 ( 99.10)	Acc@5 100.00 (100.00)
Epoch: [82][160/391]	Time  0.029 ( 0.031)	Data  0.001 ( 0.002)	Loss 5.6495e-02 (2.7421e-02)	Acc@1  99.22 ( 99.12)	Acc@5 100.00 (100.00)
Epoch: [82][170/391]	Time  0.028 ( 0.031)	Data  0.001 ( 0.002)	Loss 3.6484e-02 (2.7137e-02)	Acc@1  97.66 ( 99.12)	Acc@5 100.00 (100.00)
Epoch: [82][180/391]	Time  0.028 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.3487e-02 (2.6878e-02)	Acc@1 100.00 ( 99.14)	Acc@5 100.00 (100.00)
Epoch: [82][190/391]	Time  0.028 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.1680e-02 (2.6960e-02)	Acc@1  99.22 ( 99.13)	Acc@5 100.00 (100.00)
Epoch: [82][200/391]	Time  0.028 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.2690e-02 (2.7017e-02)	Acc@1  99.22 ( 99.13)	Acc@5 100.00 (100.00)
Epoch: [82][210/391]	Time  0.031 ( 0.031)	Data  0.001 ( 0.002)	Loss 3.8975e-02 (2.7071e-02)	Acc@1  99.22 ( 99.12)	Acc@5 100.00 (100.00)
Epoch: [82][220/391]	Time  0.030 ( 0.031)	Data  0.002 ( 0.002)	Loss 2.5579e-02 (2.6590e-02)	Acc@1  98.44 ( 99.14)	Acc@5 100.00 (100.00)
Epoch: [82][230/391]	Time  0.027 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.6875e-02 (2.6633e-02)	Acc@1  99.22 ( 99.15)	Acc@5 100.00 (100.00)
Epoch: [82][240/391]	Time  0.037 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.0527e-02 (2.6491e-02)	Acc@1 100.00 ( 99.16)	Acc@5 100.00 (100.00)
Epoch: [82][250/391]	Time  0.028 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.8766e-02 (2.6364e-02)	Acc@1  98.44 ( 99.16)	Acc@5 100.00 (100.00)
Epoch: [82][260/391]	Time  0.028 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.5453e-02 (2.6086e-02)	Acc@1 100.00 ( 99.17)	Acc@5 100.00 (100.00)
Epoch: [82][270/391]	Time  0.034 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.0250e-02 (2.5797e-02)	Acc@1 100.00 ( 99.19)	Acc@5 100.00 (100.00)
Epoch: [82][280/391]	Time  0.042 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.9542e-02 (2.5861e-02)	Acc@1  99.22 ( 99.19)	Acc@5 100.00 (100.00)
Epoch: [82][290/391]	Time  0.030 ( 0.031)	Data  0.001 ( 0.002)	Loss 5.1117e-02 (2.6038e-02)	Acc@1  98.44 ( 99.19)	Acc@5 100.00 (100.00)
Epoch: [82][300/391]	Time  0.027 ( 0.031)	Data  0.001 ( 0.002)	Loss 5.5569e-03 (2.5858e-02)	Acc@1 100.00 ( 99.20)	Acc@5 100.00 (100.00)
Epoch: [82][310/391]	Time  0.028 ( 0.031)	Data  0.001 ( 0.002)	Loss 4.4068e-02 (2.5799e-02)	Acc@1  97.66 ( 99.20)	Acc@5 100.00 (100.00)
Epoch: [82][320/391]	Time  0.028 ( 0.031)	Data  0.001 ( 0.002)	Loss 5.3334e-02 (2.6025e-02)	Acc@1  97.66 ( 99.18)	Acc@5 100.00 (100.00)
Epoch: [82][330/391]	Time  0.030 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.6786e-02 (2.5969e-02)	Acc@1 100.00 ( 99.18)	Acc@5 100.00 (100.00)
Epoch: [82][340/391]	Time  0.028 ( 0.031)	Data  0.001 ( 0.002)	Loss 4.0741e-02 (2.6061e-02)	Acc@1  97.66 ( 99.17)	Acc@5 100.00 (100.00)
Epoch: [82][350/391]	Time  0.035 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.3224e-01 (2.6463e-02)	Acc@1  96.09 ( 99.15)	Acc@5 100.00 (100.00)
Epoch: [82][360/391]	Time  0.029 ( 0.031)	Data  0.001 ( 0.002)	Loss 3.6427e-02 (2.6460e-02)	Acc@1  98.44 ( 99.15)	Acc@5 100.00 (100.00)
Epoch: [82][370/391]	Time  0.036 ( 0.031)	Data  0.001 ( 0.002)	Loss 8.8611e-03 (2.6189e-02)	Acc@1 100.00 ( 99.16)	Acc@5 100.00 (100.00)
Epoch: [82][380/391]	Time  0.033 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.8969e-02 (2.6099e-02)	Acc@1  99.22 ( 99.16)	Acc@5 100.00 (100.00)
Epoch: [82][390/391]	Time  0.020 ( 0.031)	Data  0.001 ( 0.002)	Loss 5.4404e-02 (2.6115e-02)	Acc@1  96.25 ( 99.16)	Acc@5 100.00 (100.00)
## e[82] optimizer.zero_grad (sum) time: 0.046820878982543945
## e[82]       loss.backward (sum) time: 2.2771174907684326
## e[82]      optimizer.step (sum) time: 0.3628993034362793
## epoch[82] training(only) time: 12.152040481567383
# Switched to evaluate mode...
Test: [  0/100]	Time  0.174 ( 0.174)	Loss 1.8846e-01 (1.8846e-01)	Acc@1  95.00 ( 95.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.024 ( 0.037)	Loss 5.2368e-01 (3.3442e-01)	Acc@1  90.00 ( 92.27)	Acc@5 100.00 (100.00)
Test: [ 20/100]	Time  0.026 ( 0.029)	Loss 3.7067e-01 (3.8146e-01)	Acc@1  88.00 ( 91.48)	Acc@5 100.00 ( 99.71)
Test: [ 30/100]	Time  0.023 ( 0.026)	Loss 5.0371e-01 (4.1231e-01)	Acc@1  88.00 ( 91.23)	Acc@5  97.00 ( 99.61)
Test: [ 40/100]	Time  0.018 ( 0.024)	Loss 4.1108e-01 (4.2811e-01)	Acc@1  90.00 ( 90.98)	Acc@5 100.00 ( 99.61)
Test: [ 50/100]	Time  0.022 ( 0.023)	Loss 1.3498e-01 (4.1912e-01)	Acc@1  95.00 ( 91.12)	Acc@5 100.00 ( 99.63)
Test: [ 60/100]	Time  0.020 ( 0.023)	Loss 4.6940e-01 (4.0387e-01)	Acc@1  92.00 ( 91.13)	Acc@5 100.00 ( 99.67)
Test: [ 70/100]	Time  0.023 ( 0.023)	Loss 4.9684e-01 (3.9354e-01)	Acc@1  89.00 ( 91.20)	Acc@5 100.00 ( 99.70)
Test: [ 80/100]	Time  0.021 ( 0.023)	Loss 2.2044e-01 (3.8617e-01)	Acc@1  95.00 ( 91.30)	Acc@5 100.00 ( 99.73)
Test: [ 90/100]	Time  0.018 ( 0.022)	Loss 2.9413e-01 (3.9312e-01)	Acc@1  94.00 ( 91.23)	Acc@5 100.00 ( 99.76)
 * Acc@1 91.210 Acc@5 99.760
### epoch[82] execution time: 14.508457660675049
EPOCH 83
REMOVING: module.fire8.expand_3x3.1.bias
REMOVING: module.fire9.squeeze.0.weight
i:   0, name:    module.fire9.squeeze.0.bias  changing lr from: 0.001059319875281760   to: 0.001003023954831738
i:   1, name:  module.fire9.squeeze.1.weight  changing lr from: 0.001113225024591373   to: 0.001022228139766423
i:   2, name:    module.fire9.squeeze.1.bias  changing lr from: 0.001183740509379848   to: 0.001058770252822366
i:   3, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.001270439721296356   to: 0.001112221282993524
i:   4, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.001372900218340305   to: 0.001182155827637237
i:   5, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.001490703944372700   to: 0.001268152345366118
i:   6, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.001623437430783142   to: 0.001369793389827222
i:   7, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.001770691981134602   to: 0.001486665825219396
i:   8, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.001932063839581693   to: 0.001618361024374059
i:   9, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.002107154343832318   to: 0.001764475050199076
i:  10, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.002295570063397211   to: 0.001924608821260220
i:  11, name:           module.conv10.weight  changing lr from: 0.002496922923846145   to: 0.002098368262249433
i:  12, name:             module.conv10.bias  changing lr from: 0.002710830317765122   to: 0.002285364440064529



# Switched to train mode...
Epoch: [83][  0/391]	Time  0.208 ( 0.208)	Data  0.175 ( 0.175)	Loss 2.5193e-02 (2.5193e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [83][ 10/391]	Time  0.031 ( 0.046)	Data  0.001 ( 0.017)	Loss 3.0228e-02 (2.2064e-02)	Acc@1  99.22 ( 99.50)	Acc@5 100.00 (100.00)
Epoch: [83][ 20/391]	Time  0.028 ( 0.038)	Data  0.001 ( 0.009)	Loss 2.1218e-02 (2.5221e-02)	Acc@1  99.22 ( 99.37)	Acc@5 100.00 (100.00)
Epoch: [83][ 30/391]	Time  0.027 ( 0.035)	Data  0.003 ( 0.007)	Loss 2.3813e-02 (2.5134e-02)	Acc@1  99.22 ( 99.32)	Acc@5 100.00 (100.00)
Epoch: [83][ 40/391]	Time  0.027 ( 0.034)	Data  0.001 ( 0.005)	Loss 2.5488e-02 (2.6341e-02)	Acc@1  99.22 ( 99.28)	Acc@5 100.00 (100.00)
Epoch: [83][ 50/391]	Time  0.030 ( 0.033)	Data  0.001 ( 0.005)	Loss 3.4229e-02 (2.7396e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [83][ 60/391]	Time  0.034 ( 0.032)	Data  0.001 ( 0.004)	Loss 2.9932e-02 (2.6166e-02)	Acc@1  99.22 ( 99.27)	Acc@5 100.00 (100.00)
Epoch: [83][ 70/391]	Time  0.037 ( 0.032)	Data  0.001 ( 0.004)	Loss 4.3359e-02 (2.8951e-02)	Acc@1  98.44 ( 99.17)	Acc@5 100.00 (100.00)
Epoch: [83][ 80/391]	Time  0.027 ( 0.032)	Data  0.001 ( 0.003)	Loss 3.0338e-02 (2.8298e-02)	Acc@1  99.22 ( 99.17)	Acc@5 100.00 (100.00)
Epoch: [83][ 90/391]	Time  0.032 ( 0.032)	Data  0.001 ( 0.003)	Loss 1.5342e-02 (2.8363e-02)	Acc@1 100.00 ( 99.12)	Acc@5 100.00 (100.00)
Epoch: [83][100/391]	Time  0.030 ( 0.031)	Data  0.001 ( 0.003)	Loss 1.2537e-02 (2.8514e-02)	Acc@1 100.00 ( 99.11)	Acc@5 100.00 (100.00)
Epoch: [83][110/391]	Time  0.027 ( 0.031)	Data  0.001 ( 0.003)	Loss 7.7322e-03 (2.7926e-02)	Acc@1 100.00 ( 99.13)	Acc@5 100.00 (100.00)
Epoch: [83][120/391]	Time  0.032 ( 0.031)	Data  0.001 ( 0.003)	Loss 1.1835e-02 (2.7647e-02)	Acc@1 100.00 ( 99.14)	Acc@5 100.00 (100.00)
Epoch: [83][130/391]	Time  0.033 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.3577e-02 (2.7738e-02)	Acc@1  99.22 ( 99.14)	Acc@5 100.00 (100.00)
Epoch: [83][140/391]	Time  0.027 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.1616e-02 (2.7989e-02)	Acc@1  99.22 ( 99.11)	Acc@5 100.00 (100.00)
Epoch: [83][150/391]	Time  0.027 ( 0.031)	Data  0.001 ( 0.002)	Loss 9.7392e-03 (2.7718e-02)	Acc@1 100.00 ( 99.12)	Acc@5 100.00 (100.00)
Epoch: [83][160/391]	Time  0.028 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.3737e-02 (2.7214e-02)	Acc@1  99.22 ( 99.14)	Acc@5 100.00 (100.00)
Epoch: [83][170/391]	Time  0.028 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.1156e-02 (2.6989e-02)	Acc@1  99.22 ( 99.14)	Acc@5 100.00 (100.00)
Epoch: [83][180/391]	Time  0.028 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.5385e-02 (2.6671e-02)	Acc@1  99.22 ( 99.14)	Acc@5 100.00 (100.00)
Epoch: [83][190/391]	Time  0.031 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.3198e-02 (2.6497e-02)	Acc@1 100.00 ( 99.15)	Acc@5 100.00 (100.00)
Epoch: [83][200/391]	Time  0.032 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.8801e-02 (2.6238e-02)	Acc@1 100.00 ( 99.16)	Acc@5 100.00 (100.00)
Epoch: [83][210/391]	Time  0.030 ( 0.031)	Data  0.001 ( 0.002)	Loss 5.4106e-02 (2.6289e-02)	Acc@1  98.44 ( 99.17)	Acc@5 100.00 (100.00)
Epoch: [83][220/391]	Time  0.028 ( 0.031)	Data  0.001 ( 0.002)	Loss 3.7139e-02 (2.6308e-02)	Acc@1  98.44 ( 99.17)	Acc@5 100.00 (100.00)
Epoch: [83][230/391]	Time  0.031 ( 0.031)	Data  0.005 ( 0.002)	Loss 2.4399e-02 (2.6561e-02)	Acc@1  99.22 ( 99.16)	Acc@5 100.00 (100.00)
Epoch: [83][240/391]	Time  0.028 ( 0.030)	Data  0.001 ( 0.002)	Loss 3.2127e-02 (2.6918e-02)	Acc@1  98.44 ( 99.16)	Acc@5 100.00 (100.00)
Epoch: [83][250/391]	Time  0.029 ( 0.030)	Data  0.001 ( 0.002)	Loss 1.3451e-02 (2.6792e-02)	Acc@1  99.22 ( 99.17)	Acc@5 100.00 (100.00)
Epoch: [83][260/391]	Time  0.035 ( 0.030)	Data  0.001 ( 0.002)	Loss 3.2582e-02 (2.7062e-02)	Acc@1  97.66 ( 99.15)	Acc@5 100.00 (100.00)
Epoch: [83][270/391]	Time  0.027 ( 0.030)	Data  0.001 ( 0.002)	Loss 7.0089e-03 (2.7014e-02)	Acc@1 100.00 ( 99.16)	Acc@5 100.00 (100.00)
Epoch: [83][280/391]	Time  0.032 ( 0.030)	Data  0.001 ( 0.002)	Loss 2.5745e-02 (2.6959e-02)	Acc@1  97.66 ( 99.15)	Acc@5 100.00 (100.00)
Epoch: [83][290/391]	Time  0.028 ( 0.030)	Data  0.001 ( 0.002)	Loss 2.5449e-02 (2.6946e-02)	Acc@1  98.44 ( 99.14)	Acc@5 100.00 (100.00)
Epoch: [83][300/391]	Time  0.031 ( 0.030)	Data  0.001 ( 0.002)	Loss 9.3933e-03 (2.6829e-02)	Acc@1 100.00 ( 99.15)	Acc@5 100.00 (100.00)
Epoch: [83][310/391]	Time  0.028 ( 0.030)	Data  0.001 ( 0.002)	Loss 2.5282e-02 (2.6946e-02)	Acc@1  99.22 ( 99.13)	Acc@5 100.00 (100.00)
Epoch: [83][320/391]	Time  0.027 ( 0.030)	Data  0.001 ( 0.002)	Loss 3.6143e-02 (2.6569e-02)	Acc@1  98.44 ( 99.15)	Acc@5 100.00 (100.00)
Epoch: [83][330/391]	Time  0.028 ( 0.030)	Data  0.001 ( 0.002)	Loss 1.3255e-02 (2.6246e-02)	Acc@1  99.22 ( 99.17)	Acc@5 100.00 (100.00)
Epoch: [83][340/391]	Time  0.028 ( 0.030)	Data  0.001 ( 0.002)	Loss 3.6831e-02 (2.6332e-02)	Acc@1  99.22 ( 99.16)	Acc@5 100.00 (100.00)
Epoch: [83][350/391]	Time  0.027 ( 0.030)	Data  0.001 ( 0.002)	Loss 1.4714e-02 (2.6368e-02)	Acc@1 100.00 ( 99.16)	Acc@5 100.00 (100.00)
Epoch: [83][360/391]	Time  0.032 ( 0.030)	Data  0.001 ( 0.002)	Loss 2.2676e-02 (2.6523e-02)	Acc@1 100.00 ( 99.16)	Acc@5 100.00 (100.00)
Epoch: [83][370/391]	Time  0.029 ( 0.030)	Data  0.001 ( 0.002)	Loss 1.4098e-02 (2.6494e-02)	Acc@1  99.22 ( 99.16)	Acc@5 100.00 (100.00)
Epoch: [83][380/391]	Time  0.030 ( 0.030)	Data  0.004 ( 0.002)	Loss 5.4369e-02 (2.6587e-02)	Acc@1  99.22 ( 99.15)	Acc@5  99.22 (100.00)
Epoch: [83][390/391]	Time  0.019 ( 0.030)	Data  0.001 ( 0.002)	Loss 7.5427e-02 (2.6548e-02)	Acc@1  98.75 ( 99.16)	Acc@5 100.00 (100.00)
## e[83] optimizer.zero_grad (sum) time: 0.04179716110229492
## e[83]       loss.backward (sum) time: 2.163825035095215
## e[83]      optimizer.step (sum) time: 0.3101227283477783
## epoch[83] training(only) time: 11.898330926895142
# Switched to evaluate mode...
Test: [  0/100]	Time  0.172 ( 0.172)	Loss 1.9018e-01 (1.9018e-01)	Acc@1  95.00 ( 95.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.024 ( 0.036)	Loss 5.2270e-01 (3.3659e-01)	Acc@1  90.00 ( 91.91)	Acc@5 100.00 (100.00)
Test: [ 20/100]	Time  0.021 ( 0.029)	Loss 3.5423e-01 (3.8080e-01)	Acc@1  88.00 ( 91.24)	Acc@5 100.00 ( 99.71)
Test: [ 30/100]	Time  0.022 ( 0.026)	Loss 4.9137e-01 (4.1263e-01)	Acc@1  90.00 ( 91.06)	Acc@5  98.00 ( 99.65)
Test: [ 40/100]	Time  0.023 ( 0.025)	Loss 4.2135e-01 (4.2740e-01)	Acc@1  89.00 ( 90.90)	Acc@5 100.00 ( 99.63)
Test: [ 50/100]	Time  0.023 ( 0.024)	Loss 1.4645e-01 (4.1803e-01)	Acc@1  95.00 ( 91.08)	Acc@5 100.00 ( 99.65)
Test: [ 60/100]	Time  0.022 ( 0.024)	Loss 4.5548e-01 (4.0344e-01)	Acc@1  92.00 ( 91.07)	Acc@5 100.00 ( 99.69)
Test: [ 70/100]	Time  0.020 ( 0.023)	Loss 4.9540e-01 (3.9337e-01)	Acc@1  89.00 ( 91.14)	Acc@5 100.00 ( 99.72)
Test: [ 80/100]	Time  0.018 ( 0.023)	Loss 2.1566e-01 (3.8539e-01)	Acc@1  95.00 ( 91.23)	Acc@5 100.00 ( 99.74)
Test: [ 90/100]	Time  0.022 ( 0.023)	Loss 2.8210e-01 (3.9222e-01)	Acc@1  94.00 ( 91.14)	Acc@5 100.00 ( 99.77)
 * Acc@1 91.130 Acc@5 99.770
### epoch[83] execution time: 14.242483377456665
EPOCH 84
REMOVING: module.fire9.squeeze.0.bias
REMOVING: module.fire9.squeeze.1.weight
i:   0, name:    module.fire9.squeeze.1.bias  changing lr from: 0.001058770252822366   to: 0.001003149200086217
i:   1, name: module.fire9.expand_1x1.0.weight  changing lr from: 0.001112221282993524   to: 0.001022450765790477
i:   2, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.001182155827637237   to: 0.001058948984684287
i:   3, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.001268152345366118   to: 0.001112219973221495
i:   4, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.001369793389827222   to: 0.001181843400108284
i:   5, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.001486665825219396   to: 0.001267402734158117
i:   6, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.001618361024374059   to: 0.001368485473486380
i:   7, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.001764475050199076   to: 0.001484683356872134
i:   8, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.001924608821260220   to: 0.001615592558089739
i:   9, name:           module.conv10.weight  changing lr from: 0.002098368262249433   to: 0.001760813863988175
i:  10, name:             module.conv10.bias  changing lr from: 0.002285364440064529   to: 0.001919952837071525



# Switched to train mode...
Epoch: [84][  0/391]	Time  0.204 ( 0.204)	Data  0.172 ( 0.172)	Loss 2.9131e-02 (2.9131e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [84][ 10/391]	Time  0.031 ( 0.047)	Data  0.001 ( 0.017)	Loss 5.6915e-02 (3.5357e-02)	Acc@1  98.44 ( 98.72)	Acc@5 100.00 (100.00)
Epoch: [84][ 20/391]	Time  0.034 ( 0.039)	Data  0.001 ( 0.009)	Loss 2.7883e-02 (3.2909e-02)	Acc@1  98.44 ( 98.77)	Acc@5 100.00 (100.00)
Epoch: [84][ 30/391]	Time  0.027 ( 0.036)	Data  0.001 ( 0.007)	Loss 1.2814e-02 (3.1364e-02)	Acc@1 100.00 ( 98.89)	Acc@5 100.00 (100.00)
Epoch: [84][ 40/391]	Time  0.026 ( 0.034)	Data  0.001 ( 0.005)	Loss 2.5633e-02 (3.1719e-02)	Acc@1  99.22 ( 98.88)	Acc@5 100.00 (100.00)
Epoch: [84][ 50/391]	Time  0.032 ( 0.033)	Data  0.001 ( 0.005)	Loss 2.5004e-02 (3.2181e-02)	Acc@1  98.44 ( 98.88)	Acc@5 100.00 (100.00)
Epoch: [84][ 60/391]	Time  0.027 ( 0.033)	Data  0.001 ( 0.004)	Loss 1.9201e-02 (3.2156e-02)	Acc@1 100.00 ( 98.91)	Acc@5 100.00 (100.00)
Epoch: [84][ 70/391]	Time  0.027 ( 0.032)	Data  0.001 ( 0.004)	Loss 5.6097e-02 (3.1238e-02)	Acc@1  97.66 ( 98.92)	Acc@5 100.00 (100.00)
Epoch: [84][ 80/391]	Time  0.027 ( 0.032)	Data  0.001 ( 0.003)	Loss 2.5794e-02 (3.0388e-02)	Acc@1  99.22 ( 98.93)	Acc@5 100.00 (100.00)
Epoch: [84][ 90/391]	Time  0.032 ( 0.032)	Data  0.001 ( 0.003)	Loss 1.4290e-02 (3.0172e-02)	Acc@1  99.22 ( 98.96)	Acc@5 100.00 (100.00)
Epoch: [84][100/391]	Time  0.028 ( 0.031)	Data  0.001 ( 0.003)	Loss 1.5530e-02 (2.9158e-02)	Acc@1 100.00 ( 99.01)	Acc@5 100.00 (100.00)
Epoch: [84][110/391]	Time  0.031 ( 0.031)	Data  0.001 ( 0.003)	Loss 1.5041e-02 (2.8383e-02)	Acc@1 100.00 ( 99.06)	Acc@5 100.00 (100.00)
Epoch: [84][120/391]	Time  0.032 ( 0.031)	Data  0.001 ( 0.003)	Loss 6.3026e-02 (2.8221e-02)	Acc@1  98.44 ( 99.06)	Acc@5 100.00 (100.00)
Epoch: [84][130/391]	Time  0.030 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.5037e-02 (2.7870e-02)	Acc@1  99.22 ( 99.06)	Acc@5 100.00 (100.00)
Epoch: [84][140/391]	Time  0.028 ( 0.031)	Data  0.001 ( 0.002)	Loss 3.8725e-02 (2.7926e-02)	Acc@1  98.44 ( 99.06)	Acc@5 100.00 (100.00)
Epoch: [84][150/391]	Time  0.030 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.5491e-02 (2.8423e-02)	Acc@1  99.22 ( 99.04)	Acc@5 100.00 (100.00)
Epoch: [84][160/391]	Time  0.031 ( 0.031)	Data  0.001 ( 0.002)	Loss 3.0274e-02 (2.8090e-02)	Acc@1  99.22 ( 99.07)	Acc@5 100.00 (100.00)
Epoch: [84][170/391]	Time  0.025 ( 0.031)	Data  0.001 ( 0.002)	Loss 7.3652e-02 (2.8417e-02)	Acc@1  97.66 ( 99.05)	Acc@5 100.00 (100.00)
Epoch: [84][180/391]	Time  0.027 ( 0.031)	Data  0.001 ( 0.002)	Loss 5.3079e-02 (2.9016e-02)	Acc@1  98.44 ( 99.03)	Acc@5 100.00 (100.00)
Epoch: [84][190/391]	Time  0.029 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.1382e-02 (2.8980e-02)	Acc@1  99.22 ( 99.04)	Acc@5 100.00 (100.00)
Epoch: [84][200/391]	Time  0.028 ( 0.031)	Data  0.001 ( 0.002)	Loss 3.6291e-02 (2.9450e-02)	Acc@1  99.22 ( 99.02)	Acc@5 100.00 (100.00)
Epoch: [84][210/391]	Time  0.027 ( 0.031)	Data  0.001 ( 0.002)	Loss 9.6332e-03 (2.9340e-02)	Acc@1 100.00 ( 99.02)	Acc@5 100.00 (100.00)
Epoch: [84][220/391]	Time  0.030 ( 0.031)	Data  0.001 ( 0.002)	Loss 2.9145e-02 (2.9697e-02)	Acc@1  99.22 ( 99.00)	Acc@5 100.00 (100.00)
Epoch: [84][230/391]	Time  0.031 ( 0.031)	Data  0.001 ( 0.002)	Loss 1.4348e-02 (2.9827e-02)	Acc@1 100.00 ( 98.99)	Acc@5 100.00 (100.00)
Epoch: [84][240/391]	Time  0.029 ( 0.030)	Data  0.001 ( 0.002)	Loss 8.7537e-02 (2.9603e-02)	Acc@1  98.44 ( 99.01)	Acc@5  99.22 (100.00)
Epoch: [84][250/391]	Time  0.027 ( 0.030)	Data  0.001 ( 0.002)	Loss 3.3475e-02 (2.9349e-02)	Acc@1  99.22 ( 99.02)	Acc@5 100.00 (100.00)
Epoch: [84][260/391]	Time  0.038 ( 0.030)	Data  0.001 ( 0.002)	Loss 2.4556e-02 (2.9414e-02)	Acc@1  99.22 ( 99.00)	Acc@5 100.00 (100.00)
Epoch: [84][270/391]	Time  0.028 ( 0.030)	Data  0.001 ( 0.002)	Loss 3.6215e-02 (2.9321e-02)	Acc@1  99.22 ( 99.01)	Acc@5 100.00 (100.00)
Epoch: [84][280/391]	Time  0.028 ( 0.030)	Data  0.001 ( 0.002)	Loss 9.5156e-03 (2.9327e-02)	Acc@1 100.00 ( 99.00)	Acc@5 100.00 (100.00)
Epoch: [84][290/391]	Time  0.030 ( 0.030)	Data  0.001 ( 0.002)	Loss 3.0250e-02 (2.9066e-02)	Acc@1  99.22 ( 99.01)	Acc@5 100.00 (100.00)
Epoch: [84][300/391]	Time  0.036 ( 0.030)	Data  0.000 ( 0.002)	Loss 2.8777e-02 (2.8983e-02)	Acc@1  98.44 ( 99.02)	Acc@5 100.00 (100.00)
Epoch: [84][310/391]	Time  0.031 ( 0.030)	Data  0.001 ( 0.002)	Loss 1.1658e-02 (2.9110e-02)	Acc@1 100.00 ( 99.02)	Acc@5 100.00 (100.00)
Epoch: [84][320/391]	Time  0.028 ( 0.030)	Data  0.001 ( 0.002)	Loss 7.8307e-03 (2.9017e-02)	Acc@1 100.00 ( 99.01)	Acc@5 100.00 (100.00)
Epoch: [84][330/391]	Time  0.027 ( 0.030)	Data  0.001 ( 0.002)	Loss 2.0474e-02 (2.8815e-02)	Acc@1 100.00 ( 99.03)	Acc@5 100.00 (100.00)
Epoch: [84][340/391]	Time  0.027 ( 0.030)	Data  0.001 ( 0.002)	Loss 1.7171e-02 (2.8764e-02)	Acc@1  99.22 ( 99.04)	Acc@5 100.00 (100.00)
Epoch: [84][350/391]	Time  0.030 ( 0.030)	Data  0.001 ( 0.002)	Loss 2.3145e-02 (2.8597e-02)	Acc@1  99.22 ( 99.05)	Acc@5 100.00 (100.00)
Epoch: [84][360/391]	Time  0.031 ( 0.030)	Data  0.001 ( 0.002)	Loss 2.9167e-02 (2.8643e-02)	Acc@1  99.22 ( 99.05)	Acc@5 100.00 (100.00)
Epoch: [84][370/391]	Time  0.033 ( 0.030)	Data  0.001 ( 0.002)	Loss 1.8928e-02 (2.8790e-02)	Acc@1  99.22 ( 99.04)	Acc@5 100.00 (100.00)
Epoch: [84][380/391]	Time  0.027 ( 0.030)	Data  0.001 ( 0.002)	Loss 2.5672e-02 (2.8823e-02)	Acc@1  98.44 ( 99.04)	Acc@5 100.00 (100.00)
Epoch: [84][390/391]	Time  0.019 ( 0.030)	Data  0.001 ( 0.002)	Loss 2.4029e-02 (2.8646e-02)	Acc@1 100.00 ( 99.05)	Acc@5 100.00 (100.00)
## e[84] optimizer.zero_grad (sum) time: 0.03653883934020996
## e[84]       loss.backward (sum) time: 2.128206253051758
## e[84]      optimizer.step (sum) time: 0.2675294876098633
## epoch[84] training(only) time: 11.878400325775146
# Switched to evaluate mode...
Test: [  0/100]	Time  0.171 ( 0.171)	Loss 1.6251e-01 (1.6251e-01)	Acc@1  94.00 ( 94.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.020 ( 0.034)	Loss 5.2265e-01 (3.3291e-01)	Acc@1  90.00 ( 92.09)	Acc@5 100.00 (100.00)
Test: [ 20/100]	Time  0.018 ( 0.027)	Loss 3.5980e-01 (3.8192e-01)	Acc@1  89.00 ( 91.43)	Acc@5 100.00 ( 99.71)
Test: [ 30/100]	Time  0.025 ( 0.025)	Loss 5.2066e-01 (4.1381e-01)	Acc@1  86.00 ( 91.19)	Acc@5  97.00 ( 99.61)
Test: [ 40/100]	Time  0.021 ( 0.024)	Loss 4.0011e-01 (4.2670e-01)	Acc@1  90.00 ( 90.95)	Acc@5 100.00 ( 99.61)
Test: [ 50/100]	Time  0.016 ( 0.023)	Loss 1.2981e-01 (4.1846e-01)	Acc@1  95.00 ( 91.10)	Acc@5 100.00 ( 99.63)
Test: [ 60/100]	Time  0.018 ( 0.023)	Loss 4.8688e-01 (4.0325e-01)	Acc@1  92.00 ( 91.10)	Acc@5  99.00 ( 99.66)
Test: [ 70/100]	Time  0.024 ( 0.023)	Loss 4.6350e-01 (3.9279e-01)	Acc@1  89.00 ( 91.21)	Acc@5 100.00 ( 99.69)
Test: [ 80/100]	Time  0.023 ( 0.022)	Loss 2.1011e-01 (3.8616e-01)	Acc@1  95.00 ( 91.28)	Acc@5 100.00 ( 99.70)
Test: [ 90/100]	Time  0.021 ( 0.022)	Loss 2.8405e-01 (3.9252e-01)	Acc@1  94.00 ( 91.18)	Acc@5 100.00 ( 99.74)
 * Acc@1 91.120 Acc@5 99.750
### epoch[84] execution time: 14.189830541610718
EPOCH 85
REMOVING: module.fire9.squeeze.1.bias
REMOVING: module.fire9.expand_1x1.0.weight
i:   0, name: module.fire9.expand_1x1.0.bias  changing lr from: 0.001058948984684287   to: 0.001003446719752992
i:   1, name: module.fire9.expand_1x1.1.weight  changing lr from: 0.001112219973221495   to: 0.001023115710064964
i:   2, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.001181843400108284   to: 0.001059836245524220
i:   3, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.001267402734158117   to: 0.001113189502407707
i:   4, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.001368485473486380   to: 0.001182760158637774
i:   5, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.001484683356872134   to: 0.001268136636463984
i:   6, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.001615592558089739   to: 0.001368911326934018
i:   7, name:           module.conv10.weight  changing lr from: 0.001760813863988175   to: 0.001484680796958326
i:   8, name:             module.conv10.bias  changing lr from: 0.001919952837071525   to: 0.001615045979749002



# Switched to train mode...
Epoch: [85][  0/391]	Time  0.201 ( 0.201)	Data  0.169 ( 0.169)	Loss 6.1241e-02 (6.1241e-02)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
Epoch: [85][ 10/391]	Time  0.028 ( 0.044)	Data  0.001 ( 0.016)	Loss 3.0756e-02 (2.3691e-02)	Acc@1  98.44 ( 99.15)	Acc@5 100.00 (100.00)
Epoch: [85][ 20/391]	Time  0.029 ( 0.037)	Data  0.001 ( 0.009)	Loss 5.8831e-02 (2.5604e-02)	Acc@1  97.66 ( 99.14)	Acc@5 100.00 (100.00)
Epoch: [85][ 30/391]	Time  0.027 ( 0.034)	Data  0.001 ( 0.007)	Loss 5.3987e-02 (2.5945e-02)	Acc@1  97.66 ( 99.09)	Acc@5 100.00 (100.00)
Epoch: [85][ 40/391]	Time  0.027 ( 0.033)	Data  0.002 ( 0.005)	Loss 1.1558e-02 (2.4894e-02)	Acc@1 100.00 ( 99.14)	Acc@5 100.00 (100.00)
Epoch: [85][ 50/391]	Time  0.029 ( 0.032)	Data  0.001 ( 0.005)	Loss 2.4316e-02 (2.5951e-02)	Acc@1  99.22 ( 99.11)	Acc@5 100.00 (100.00)
Epoch: [85][ 60/391]	Time  0.029 ( 0.032)	Data  0.001 ( 0.004)	Loss 3.0338e-02 (2.6919e-02)	Acc@1  98.44 ( 99.08)	Acc@5 100.00 (100.00)
Epoch: [85][ 70/391]	Time  0.035 ( 0.031)	Data  0.001 ( 0.004)	Loss 2.9043e-02 (2.7279e-02)	Acc@1  99.22 ( 99.04)	Acc@5 100.00 (100.00)
Epoch: [85][ 80/391]	Time  0.027 ( 0.031)	Data  0.001 ( 0.003)	Loss 1.0360e-02 (2.7411e-02)	Acc@1 100.00 ( 99.04)	Acc@5 100.00 (100.00)
Epoch: [85][ 90/391]	Time  0.030 ( 0.031)	Data  0.001 ( 0.003)	Loss 2.8271e-02 (2.7888e-02)	Acc@1  99.22 ( 99.00)	Acc@5 100.00 (100.00)
Epoch: [85][100/391]	Time  0.033 ( 0.031)	Data  0.001 ( 0.003)	Loss 3.7048e-02 (2.7910e-02)	Acc@1  99.22 ( 99.03)	Acc@5 100.00 (100.00)
Epoch: [85][110/391]	Time  0.026 ( 0.030)	Data  0.001 ( 0.003)	Loss 2.3325e-02 (2.7739e-02)	Acc@1  98.44 ( 99.02)	Acc@5 100.00 (100.00)
Epoch: [85][120/391]	Time  0.028 ( 0.030)	Data  0.001 ( 0.003)	Loss 3.4095e-02 (2.7441e-02)	Acc@1  98.44 ( 99.04)	Acc@5 100.00 (100.00)
Epoch: [85][130/391]	Time  0.027 ( 0.030)	Data  0.001 ( 0.002)	Loss 2.1504e-02 (2.7460e-02)	Acc@1  99.22 ( 99.02)	Acc@5 100.00 (100.00)
Epoch: [85][140/391]	Time  0.027 ( 0.030)	Data  0.001 ( 0.002)	Loss 4.9214e-02 (2.7843e-02)	Acc@1  98.44 ( 99.03)	Acc@5 100.00 (100.00)
Epoch: [85][150/391]	Time  0.027 ( 0.030)	Data  0.001 ( 0.002)	Loss 3.5372e-02 (2.7489e-02)	Acc@1  99.22 ( 99.05)	Acc@5 100.00 (100.00)
Epoch: [85][160/391]	Time  0.027 ( 0.030)	Data  0.001 ( 0.002)	Loss 2.8352e-02 (2.7209e-02)	Acc@1  99.22 ( 99.06)	Acc@5 100.00 (100.00)
Epoch: [85][170/391]	Time  0.026 ( 0.030)	Data  0.001 ( 0.002)	Loss 3.4795e-02 (2.6968e-02)	Acc@1  98.44 ( 99.08)	Acc@5 100.00 (100.00)
Epoch: [85][180/391]	Time  0.026 ( 0.030)	Data  0.001 ( 0.002)	Loss 5.9152e-02 (2.7039e-02)	Acc@1  97.66 ( 99.08)	Acc@5 100.00 (100.00)
Epoch: [85][190/391]	Time  0.032 ( 0.030)	Data  0.004 ( 0.002)	Loss 6.5853e-02 (2.7412e-02)	Acc@1  97.66 ( 99.07)	Acc@5 100.00 (100.00)
Epoch: [85][200/391]	Time  0.030 ( 0.030)	Data  0.001 ( 0.002)	Loss 2.8602e-02 (2.7634e-02)	Acc@1  99.22 ( 99.07)	Acc@5 100.00 (100.00)
Epoch: [85][210/391]	Time  0.026 ( 0.030)	Data  0.001 ( 0.002)	Loss 4.7458e-02 (2.7812e-02)	Acc@1  98.44 ( 99.05)	Acc@5 100.00 (100.00)
Epoch: [85][220/391]	Time  0.031 ( 0.030)	Data  0.001 ( 0.002)	Loss 1.1387e-02 (2.7708e-02)	Acc@1 100.00 ( 99.06)	Acc@5 100.00 (100.00)
Epoch: [85][230/391]	Time  0.029 ( 0.030)	Data  0.001 ( 0.002)	Loss 3.6694e-02 (2.7795e-02)	Acc@1  99.22 ( 99.05)	Acc@5 100.00 (100.00)
Epoch: [85][240/391]	Time  0.027 ( 0.030)	Data  0.001 ( 0.002)	Loss 1.9583e-02 (2.7898e-02)	Acc@1 100.00 ( 99.05)	Acc@5 100.00 (100.00)
Epoch: [85][250/391]	Time  0.036 ( 0.030)	Data  0.001 ( 0.002)	Loss 2.3616e-02 (2.7755e-02)	Acc@1  99.22 ( 99.06)	Acc@5 100.00 (100.00)
Epoch: [85][260/391]	Time  0.031 ( 0.030)	Data  0.001 ( 0.002)	Loss 2.5570e-02 (2.7816e-02)	Acc@1  99.22 ( 99.06)	Acc@5 100.00 (100.00)
Epoch: [85][270/391]	Time  0.027 ( 0.030)	Data  0.001 ( 0.002)	Loss 8.2941e-03 (2.7353e-02)	Acc@1 100.00 ( 99.09)	Acc@5 100.00 (100.00)
Epoch: [85][280/391]	Time  0.030 ( 0.030)	Data  0.001 ( 0.002)	Loss 3.9322e-03 (2.7293e-02)	Acc@1 100.00 ( 99.09)	Acc@5 100.00 (100.00)
Epoch: [85][290/391]	Time  0.030 ( 0.030)	Data  0.001 ( 0.002)	Loss 1.3981e-02 (2.7106e-02)	Acc@1  99.22 ( 99.10)	Acc@5 100.00 (100.00)
Epoch: [85][300/391]	Time  0.031 ( 0.030)	Data  0.001 ( 0.002)	Loss 2.2796e-02 (2.6761e-02)	Acc@1  99.22 ( 99.11)	Acc@5 100.00 (100.00)
Epoch: [85][310/391]	Time  0.026 ( 0.030)	Data  0.001 ( 0.002)	Loss 1.7386e-02 (2.6606e-02)	Acc@1 100.00 ( 99.12)	Acc@5 100.00 (100.00)
Epoch: [85][320/391]	Time  0.027 ( 0.030)	Data  0.001 ( 0.002)	Loss 6.1986e-03 (2.6679e-02)	Acc@1 100.00 ( 99.13)	Acc@5 100.00 (100.00)
Epoch: [85][330/391]	Time  0.038 ( 0.030)	Data  0.001 ( 0.002)	Loss 1.9891e-02 (2.6481e-02)	Acc@1  99.22 ( 99.13)	Acc@5 100.00 (100.00)
Epoch: [85][340/391]	Time  0.026 ( 0.030)	Data  0.001 ( 0.002)	Loss 3.0453e-02 (2.6279e-02)	Acc@1  98.44 ( 99.13)	Acc@5 100.00 (100.00)
Epoch: [85][350/391]	Time  0.028 ( 0.030)	Data  0.001 ( 0.002)	Loss 1.9877e-02 (2.6220e-02)	Acc@1  99.22 ( 99.13)	Acc@5 100.00 (100.00)
Epoch: [85][360/391]	Time  0.027 ( 0.030)	Data  0.001 ( 0.002)	Loss 2.9234e-02 (2.6357e-02)	Acc@1  99.22 ( 99.13)	Acc@5 100.00 (100.00)
Epoch: [85][370/391]	Time  0.027 ( 0.030)	Data  0.001 ( 0.002)	Loss 1.0598e-02 (2.6243e-02)	Acc@1 100.00 ( 99.14)	Acc@5 100.00 (100.00)
Epoch: [85][380/391]	Time  0.026 ( 0.030)	Data  0.000 ( 0.002)	Loss 1.9072e-02 (2.6127e-02)	Acc@1  99.22 ( 99.14)	Acc@5 100.00 (100.00)
Epoch: [85][390/391]	Time  0.018 ( 0.029)	Data  0.000 ( 0.002)	Loss 2.2650e-02 (2.6168e-02)	Acc@1 100.00 ( 99.14)	Acc@5 100.00 (100.00)
## e[85] optimizer.zero_grad (sum) time: 0.030495166778564453
## e[85]       loss.backward (sum) time: 1.9930827617645264
## e[85]      optimizer.step (sum) time: 0.22119688987731934
## epoch[85] training(only) time: 11.632118701934814
# Switched to evaluate mode...
Test: [  0/100]	Time  0.171 ( 0.171)	Loss 1.9129e-01 (1.9129e-01)	Acc@1  95.00 ( 95.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.024 ( 0.035)	Loss 5.2630e-01 (3.4279e-01)	Acc@1  90.00 ( 91.73)	Acc@5 100.00 (100.00)
Test: [ 20/100]	Time  0.022 ( 0.029)	Loss 3.5900e-01 (3.8564e-01)	Acc@1  88.00 ( 91.10)	Acc@5 100.00 ( 99.71)
Test: [ 30/100]	Time  0.020 ( 0.027)	Loss 5.0241e-01 (4.1580e-01)	Acc@1  90.00 ( 91.00)	Acc@5  97.00 ( 99.61)
Test: [ 40/100]	Time  0.023 ( 0.026)	Loss 4.1116e-01 (4.3033e-01)	Acc@1  89.00 ( 90.83)	Acc@5 100.00 ( 99.63)
Test: [ 50/100]	Time  0.022 ( 0.025)	Loss 1.3415e-01 (4.2157e-01)	Acc@1  95.00 ( 90.98)	Acc@5 100.00 ( 99.63)
Test: [ 60/100]	Time  0.021 ( 0.024)	Loss 4.6525e-01 (4.0637e-01)	Acc@1  92.00 ( 90.97)	Acc@5 100.00 ( 99.67)
Test: [ 70/100]	Time  0.019 ( 0.024)	Loss 4.9344e-01 (3.9573e-01)	Acc@1  89.00 ( 91.06)	Acc@5 100.00 ( 99.70)
Test: [ 80/100]	Time  0.022 ( 0.023)	Loss 2.2289e-01 (3.8792e-01)	Acc@1  94.00 ( 91.19)	Acc@5 100.00 ( 99.73)
Test: [ 90/100]	Time  0.019 ( 0.023)	Loss 2.8840e-01 (3.9472e-01)	Acc@1  94.00 ( 91.11)	Acc@5 100.00 ( 99.76)
 * Acc@1 91.080 Acc@5 99.760
### epoch[85] execution time: 14.029391527175903
EPOCH 86
REMOVING: module.fire9.expand_1x1.0.bias
REMOVING: module.fire9.expand_1x1.1.weight
i:   0, name: module.fire9.expand_1x1.1.bias  changing lr from: 0.001059836245524220   to: 0.001003933423372998
i:   1, name: module.fire9.expand_3x3.0.weight  changing lr from: 0.001113189502407707   to: 0.001024227839703445
i:   2, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.001182760158637774   to: 0.001061425135423954
i:   3, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.001268136636463984   to: 0.001115111479985164
i:   4, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.001368911326934018   to: 0.001184876498997799
i:   5, name:           module.conv10.weight  changing lr from: 0.001484680796958326   to: 0.001270313511625136
i:   6, name:             module.conv10.bias  changing lr from: 0.001615045979749002   to: 0.001371019750210400



# Switched to train mode...
Epoch: [86][  0/391]	Time  0.195 ( 0.195)	Data  0.165 ( 0.165)	Loss 2.2064e-02 (2.2064e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [86][ 10/391]	Time  0.034 ( 0.045)	Data  0.002 ( 0.016)	Loss 2.7649e-02 (2.4170e-02)	Acc@1  99.22 ( 99.08)	Acc@5 100.00 (100.00)
Epoch: [86][ 20/391]	Time  0.032 ( 0.037)	Data  0.001 ( 0.009)	Loss 3.2632e-02 (2.3724e-02)	Acc@1  98.44 ( 99.14)	Acc@5 100.00 (100.00)
Epoch: [86][ 30/391]	Time  0.029 ( 0.034)	Data  0.001 ( 0.007)	Loss 3.8089e-02 (2.5775e-02)	Acc@1  98.44 ( 99.17)	Acc@5 100.00 (100.00)
Epoch: [86][ 40/391]	Time  0.027 ( 0.033)	Data  0.001 ( 0.005)	Loss 1.1038e-02 (2.5569e-02)	Acc@1 100.00 ( 99.20)	Acc@5 100.00 (100.00)
Epoch: [86][ 50/391]	Time  0.032 ( 0.032)	Data  0.001 ( 0.004)	Loss 3.2843e-02 (2.6478e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [86][ 60/391]	Time  0.033 ( 0.032)	Data  0.001 ( 0.004)	Loss 3.8311e-02 (2.6736e-02)	Acc@1  98.44 ( 99.21)	Acc@5 100.00 (100.00)
Epoch: [86][ 70/391]	Time  0.030 ( 0.031)	Data  0.001 ( 0.004)	Loss 3.2078e-02 (2.5473e-02)	Acc@1  99.22 ( 99.27)	Acc@5 100.00 (100.00)
Epoch: [86][ 80/391]	Time  0.030 ( 0.031)	Data  0.001 ( 0.003)	Loss 2.2932e-02 (2.5961e-02)	Acc@1 100.00 ( 99.26)	Acc@5 100.00 (100.00)
Epoch: [86][ 90/391]	Time  0.027 ( 0.031)	Data  0.001 ( 0.003)	Loss 1.0788e-02 (2.5543e-02)	Acc@1 100.00 ( 99.28)	Acc@5 100.00 (100.00)
Epoch: [86][100/391]	Time  0.032 ( 0.031)	Data  0.001 ( 0.003)	Loss 1.4246e-02 (2.5852e-02)	Acc@1 100.00 ( 99.25)	Acc@5 100.00 (100.00)
Epoch: [86][110/391]	Time  0.026 ( 0.030)	Data  0.001 ( 0.003)	Loss 2.3198e-02 (2.5191e-02)	Acc@1  99.22 ( 99.29)	Acc@5 100.00 (100.00)
Epoch: [86][120/391]	Time  0.026 ( 0.030)	Data  0.001 ( 0.003)	Loss 4.0580e-02 (2.5351e-02)	Acc@1  99.22 ( 99.28)	Acc@5 100.00 (100.00)
Epoch: [86][130/391]	Time  0.030 ( 0.030)	Data  0.001 ( 0.002)	Loss 2.0168e-02 (2.5689e-02)	Acc@1  99.22 ( 99.23)	Acc@5 100.00 (100.00)
Epoch: [86][140/391]	Time  0.027 ( 0.030)	Data  0.001 ( 0.002)	Loss 3.2812e-02 (2.5619e-02)	Acc@1  98.44 ( 99.21)	Acc@5 100.00 (100.00)
Epoch: [86][150/391]	Time  0.026 ( 0.030)	Data  0.001 ( 0.002)	Loss 2.3728e-02 (2.5447e-02)	Acc@1  99.22 ( 99.21)	Acc@5 100.00 (100.00)
Epoch: [86][160/391]	Time  0.034 ( 0.030)	Data  0.001 ( 0.002)	Loss 2.5390e-02 (2.5255e-02)	Acc@1  98.44 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [86][170/391]	Time  0.037 ( 0.030)	Data  0.001 ( 0.002)	Loss 3.9348e-02 (2.5422e-02)	Acc@1  99.22 ( 99.23)	Acc@5 100.00 (100.00)
Epoch: [86][180/391]	Time  0.027 ( 0.030)	Data  0.001 ( 0.002)	Loss 2.5263e-02 (2.6173e-02)	Acc@1  99.22 ( 99.21)	Acc@5 100.00 (100.00)
Epoch: [86][190/391]	Time  0.027 ( 0.030)	Data  0.001 ( 0.002)	Loss 6.0422e-02 (2.6771e-02)	Acc@1  98.44 ( 99.19)	Acc@5 100.00 (100.00)
Epoch: [86][200/391]	Time  0.029 ( 0.030)	Data  0.001 ( 0.002)	Loss 8.0465e-03 (2.6815e-02)	Acc@1 100.00 ( 99.19)	Acc@5 100.00 (100.00)
Epoch: [86][210/391]	Time  0.029 ( 0.030)	Data  0.004 ( 0.002)	Loss 1.9010e-02 (2.7370e-02)	Acc@1 100.00 ( 99.16)	Acc@5 100.00 (100.00)
Epoch: [86][220/391]	Time  0.035 ( 0.030)	Data  0.001 ( 0.002)	Loss 3.1674e-02 (2.7751e-02)	Acc@1  99.22 ( 99.14)	Acc@5 100.00 (100.00)
Epoch: [86][230/391]	Time  0.027 ( 0.030)	Data  0.001 ( 0.002)	Loss 3.5484e-02 (2.7633e-02)	Acc@1  99.22 ( 99.14)	Acc@5 100.00 (100.00)
Epoch: [86][240/391]	Time  0.035 ( 0.030)	Data  0.001 ( 0.002)	Loss 2.4070e-02 (2.7629e-02)	Acc@1  99.22 ( 99.14)	Acc@5 100.00 (100.00)
Epoch: [86][250/391]	Time  0.027 ( 0.030)	Data  0.002 ( 0.002)	Loss 2.1781e-02 (2.7300e-02)	Acc@1  99.22 ( 99.15)	Acc@5 100.00 (100.00)
Epoch: [86][260/391]	Time  0.027 ( 0.030)	Data  0.001 ( 0.002)	Loss 7.6605e-03 (2.7243e-02)	Acc@1 100.00 ( 99.15)	Acc@5 100.00 (100.00)
Epoch: [86][270/391]	Time  0.027 ( 0.030)	Data  0.001 ( 0.002)	Loss 6.1080e-02 (2.7362e-02)	Acc@1  98.44 ( 99.15)	Acc@5 100.00 (100.00)
Epoch: [86][280/391]	Time  0.027 ( 0.030)	Data  0.001 ( 0.002)	Loss 1.7857e-02 (2.7260e-02)	Acc@1 100.00 ( 99.15)	Acc@5 100.00 (100.00)
Epoch: [86][290/391]	Time  0.027 ( 0.030)	Data  0.001 ( 0.002)	Loss 3.5573e-02 (2.7140e-02)	Acc@1  98.44 ( 99.15)	Acc@5 100.00 (100.00)
Epoch: [86][300/391]	Time  0.032 ( 0.030)	Data  0.001 ( 0.002)	Loss 1.8790e-02 (2.6877e-02)	Acc@1  99.22 ( 99.17)	Acc@5 100.00 (100.00)
Epoch: [86][310/391]	Time  0.029 ( 0.030)	Data  0.001 ( 0.002)	Loss 2.7053e-02 (2.6718e-02)	Acc@1  99.22 ( 99.17)	Acc@5 100.00 (100.00)
Epoch: [86][320/391]	Time  0.039 ( 0.030)	Data  0.001 ( 0.002)	Loss 1.7219e-02 (2.6765e-02)	Acc@1  99.22 ( 99.17)	Acc@5 100.00 (100.00)
Epoch: [86][330/391]	Time  0.027 ( 0.029)	Data  0.002 ( 0.002)	Loss 7.8407e-02 (2.6772e-02)	Acc@1  97.66 ( 99.18)	Acc@5 100.00 (100.00)
Epoch: [86][340/391]	Time  0.030 ( 0.029)	Data  0.001 ( 0.002)	Loss 4.4287e-02 (2.6780e-02)	Acc@1  97.66 ( 99.17)	Acc@5 100.00 (100.00)
Epoch: [86][350/391]	Time  0.026 ( 0.029)	Data  0.001 ( 0.002)	Loss 2.7855e-02 (2.7027e-02)	Acc@1  98.44 ( 99.16)	Acc@5 100.00 (100.00)
Epoch: [86][360/391]	Time  0.031 ( 0.029)	Data  0.004 ( 0.002)	Loss 8.9047e-03 (2.6891e-02)	Acc@1 100.00 ( 99.17)	Acc@5 100.00 (100.00)
Epoch: [86][370/391]	Time  0.028 ( 0.029)	Data  0.001 ( 0.002)	Loss 1.9561e-02 (2.6826e-02)	Acc@1 100.00 ( 99.17)	Acc@5 100.00 (100.00)
Epoch: [86][380/391]	Time  0.037 ( 0.029)	Data  0.001 ( 0.002)	Loss 5.8358e-03 (2.6608e-02)	Acc@1 100.00 ( 99.18)	Acc@5 100.00 (100.00)
Epoch: [86][390/391]	Time  0.019 ( 0.029)	Data  0.001 ( 0.002)	Loss 7.6280e-03 (2.6661e-02)	Acc@1 100.00 ( 99.17)	Acc@5 100.00 (100.00)
## e[86] optimizer.zero_grad (sum) time: 0.025554895401000977
## e[86]       loss.backward (sum) time: 1.99147629737854
## e[86]      optimizer.step (sum) time: 0.17634916305541992
## epoch[86] training(only) time: 11.583029747009277
# Switched to evaluate mode...
Test: [  0/100]	Time  0.173 ( 0.173)	Loss 1.7465e-01 (1.7465e-01)	Acc@1  96.00 ( 96.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.018 ( 0.035)	Loss 5.1427e-01 (3.3339e-01)	Acc@1  89.00 ( 92.00)	Acc@5 100.00 (100.00)
Test: [ 20/100]	Time  0.021 ( 0.029)	Loss 3.6627e-01 (3.7739e-01)	Acc@1  89.00 ( 91.38)	Acc@5 100.00 ( 99.71)
Test: [ 30/100]	Time  0.017 ( 0.026)	Loss 4.8154e-01 (4.0640e-01)	Acc@1  91.00 ( 91.26)	Acc@5  98.00 ( 99.65)
Test: [ 40/100]	Time  0.023 ( 0.024)	Loss 4.0476e-01 (4.1988e-01)	Acc@1  90.00 ( 91.10)	Acc@5 100.00 ( 99.61)
Test: [ 50/100]	Time  0.018 ( 0.023)	Loss 1.3979e-01 (4.1215e-01)	Acc@1  95.00 ( 91.22)	Acc@5 100.00 ( 99.63)
Test: [ 60/100]	Time  0.023 ( 0.023)	Loss 4.5456e-01 (3.9719e-01)	Acc@1  93.00 ( 91.23)	Acc@5  99.00 ( 99.66)
Test: [ 70/100]	Time  0.024 ( 0.023)	Loss 5.1286e-01 (3.8812e-01)	Acc@1  88.00 ( 91.25)	Acc@5 100.00 ( 99.69)
Test: [ 80/100]	Time  0.026 ( 0.022)	Loss 2.1256e-01 (3.8137e-01)	Acc@1  94.00 ( 91.30)	Acc@5 100.00 ( 99.72)
Test: [ 90/100]	Time  0.016 ( 0.022)	Loss 2.8812e-01 (3.8896e-01)	Acc@1  94.00 ( 91.18)	Acc@5 100.00 ( 99.75)
 * Acc@1 91.140 Acc@5 99.750
### epoch[86] execution time: 13.85263466835022
EPOCH 87
REMOVING: module.fire9.expand_1x1.1.bias
REMOVING: module.fire9.expand_3x3.0.weight
i:   0, name: module.fire9.expand_3x3.0.bias  changing lr from: 0.001061425135423954   to: 0.001004637233038102
i:   1, name: module.fire9.expand_3x3.1.weight  changing lr from: 0.001115111479985164   to: 0.001025803343559833
i:   2, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.001184876498997799   to: 0.001063720370616826
i:   3, name:           module.conv10.weight  changing lr from: 0.001270313511625136   to: 0.001117979411353114
i:   4, name:             module.conv10.bias  changing lr from: 0.001371019750210400   to: 0.001188174978340949



# Switched to train mode...
Epoch: [87][  0/391]	Time  0.198 ( 0.198)	Data  0.166 ( 0.166)	Loss 4.5748e-02 (4.5748e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [87][ 10/391]	Time  0.027 ( 0.043)	Data  0.001 ( 0.016)	Loss 5.9857e-03 (2.3619e-02)	Acc@1 100.00 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [87][ 20/391]	Time  0.026 ( 0.037)	Data  0.001 ( 0.009)	Loss 3.3754e-02 (2.1356e-02)	Acc@1  98.44 ( 99.37)	Acc@5 100.00 (100.00)
Epoch: [87][ 30/391]	Time  0.026 ( 0.034)	Data  0.001 ( 0.006)	Loss 1.0106e-02 (2.4658e-02)	Acc@1 100.00 ( 99.29)	Acc@5 100.00 (100.00)
Epoch: [87][ 40/391]	Time  0.030 ( 0.033)	Data  0.001 ( 0.005)	Loss 2.3010e-02 (2.5090e-02)	Acc@1 100.00 ( 99.26)	Acc@5 100.00 (100.00)
Epoch: [87][ 50/391]	Time  0.035 ( 0.032)	Data  0.001 ( 0.005)	Loss 1.2824e-02 (2.5631e-02)	Acc@1 100.00 ( 99.31)	Acc@5 100.00 (100.00)
Epoch: [87][ 60/391]	Time  0.026 ( 0.031)	Data  0.001 ( 0.004)	Loss 1.1599e-02 (2.5372e-02)	Acc@1  99.22 ( 99.30)	Acc@5 100.00 (100.00)
Epoch: [87][ 70/391]	Time  0.026 ( 0.031)	Data  0.001 ( 0.004)	Loss 5.9789e-02 (2.5354e-02)	Acc@1  98.44 ( 99.32)	Acc@5 100.00 (100.00)
Epoch: [87][ 80/391]	Time  0.030 ( 0.030)	Data  0.001 ( 0.003)	Loss 3.5067e-02 (2.6214e-02)	Acc@1  99.22 ( 99.30)	Acc@5 100.00 (100.00)
Epoch: [87][ 90/391]	Time  0.030 ( 0.030)	Data  0.001 ( 0.003)	Loss 2.7755e-02 (2.6653e-02)	Acc@1  98.44 ( 99.26)	Acc@5 100.00 (100.00)
Epoch: [87][100/391]	Time  0.035 ( 0.030)	Data  0.001 ( 0.003)	Loss 3.4243e-02 (2.6227e-02)	Acc@1  98.44 ( 99.27)	Acc@5 100.00 (100.00)
Epoch: [87][110/391]	Time  0.026 ( 0.030)	Data  0.001 ( 0.003)	Loss 1.6443e-02 (2.6415e-02)	Acc@1 100.00 ( 99.26)	Acc@5 100.00 (100.00)
Epoch: [87][120/391]	Time  0.027 ( 0.030)	Data  0.001 ( 0.003)	Loss 3.6985e-02 (2.6815e-02)	Acc@1  97.66 ( 99.24)	Acc@5 100.00 (100.00)
Epoch: [87][130/391]	Time  0.026 ( 0.030)	Data  0.001 ( 0.003)	Loss 1.6263e-02 (2.6637e-02)	Acc@1 100.00 ( 99.27)	Acc@5 100.00 ( 99.99)
Epoch: [87][140/391]	Time  0.033 ( 0.030)	Data  0.000 ( 0.002)	Loss 1.5355e-02 (2.6155e-02)	Acc@1  99.22 ( 99.27)	Acc@5 100.00 ( 99.99)
Epoch: [87][150/391]	Time  0.026 ( 0.030)	Data  0.001 ( 0.002)	Loss 2.7389e-02 (2.6447e-02)	Acc@1  99.22 ( 99.25)	Acc@5 100.00 ( 99.99)
Epoch: [87][160/391]	Time  0.030 ( 0.030)	Data  0.001 ( 0.002)	Loss 5.9333e-03 (2.6342e-02)	Acc@1 100.00 ( 99.28)	Acc@5 100.00 ( 99.99)
Epoch: [87][170/391]	Time  0.026 ( 0.030)	Data  0.002 ( 0.002)	Loss 1.4525e-02 (2.6195e-02)	Acc@1 100.00 ( 99.27)	Acc@5 100.00 ( 99.99)
Epoch: [87][180/391]	Time  0.032 ( 0.030)	Data  0.001 ( 0.002)	Loss 2.9477e-02 (2.6447e-02)	Acc@1  99.22 ( 99.24)	Acc@5 100.00 ( 99.99)
Epoch: [87][190/391]	Time  0.033 ( 0.030)	Data  0.001 ( 0.002)	Loss 4.1367e-02 (2.6876e-02)	Acc@1  99.22 ( 99.23)	Acc@5 100.00 ( 99.99)
Epoch: [87][200/391]	Time  0.027 ( 0.029)	Data  0.001 ( 0.002)	Loss 1.3850e-02 (2.6847e-02)	Acc@1 100.00 ( 99.22)	Acc@5 100.00 ( 99.99)
Epoch: [87][210/391]	Time  0.028 ( 0.029)	Data  0.001 ( 0.002)	Loss 4.3040e-02 (2.7115e-02)	Acc@1  98.44 ( 99.22)	Acc@5 100.00 ( 99.99)
Epoch: [87][220/391]	Time  0.024 ( 0.029)	Data  0.001 ( 0.002)	Loss 1.5106e-02 (2.6787e-02)	Acc@1 100.00 ( 99.22)	Acc@5 100.00 ( 99.99)
Epoch: [87][230/391]	Time  0.028 ( 0.029)	Data  0.002 ( 0.002)	Loss 2.5982e-02 (2.6630e-02)	Acc@1  99.22 ( 99.23)	Acc@5 100.00 ( 99.99)
Epoch: [87][240/391]	Time  0.028 ( 0.029)	Data  0.001 ( 0.002)	Loss 4.7286e-02 (2.6502e-02)	Acc@1  98.44 ( 99.23)	Acc@5 100.00 ( 99.99)
Epoch: [87][250/391]	Time  0.036 ( 0.029)	Data  0.001 ( 0.002)	Loss 8.0524e-03 (2.6423e-02)	Acc@1 100.00 ( 99.23)	Acc@5 100.00 ( 99.99)
Epoch: [87][260/391]	Time  0.027 ( 0.029)	Data  0.002 ( 0.002)	Loss 2.0051e-02 (2.6321e-02)	Acc@1  99.22 ( 99.23)	Acc@5 100.00 ( 99.99)
Epoch: [87][270/391]	Time  0.035 ( 0.029)	Data  0.003 ( 0.002)	Loss 7.3646e-03 (2.6613e-02)	Acc@1 100.00 ( 99.21)	Acc@5 100.00 ( 99.99)
Epoch: [87][280/391]	Time  0.032 ( 0.029)	Data  0.001 ( 0.002)	Loss 2.1626e-02 (2.6639e-02)	Acc@1  99.22 ( 99.20)	Acc@5 100.00 ( 99.99)
Epoch: [87][290/391]	Time  0.026 ( 0.029)	Data  0.001 ( 0.002)	Loss 1.1423e-02 (2.6448e-02)	Acc@1 100.00 ( 99.20)	Acc@5 100.00 ( 99.99)
Epoch: [87][300/391]	Time  0.027 ( 0.029)	Data  0.001 ( 0.002)	Loss 2.3757e-02 (2.6291e-02)	Acc@1  99.22 ( 99.20)	Acc@5 100.00 ( 99.99)
Epoch: [87][310/391]	Time  0.032 ( 0.029)	Data  0.004 ( 0.002)	Loss 1.6857e-02 (2.6277e-02)	Acc@1 100.00 ( 99.21)	Acc@5 100.00 ( 99.99)
Epoch: [87][320/391]	Time  0.035 ( 0.029)	Data  0.001 ( 0.002)	Loss 1.5448e-02 (2.6276e-02)	Acc@1 100.00 ( 99.21)	Acc@5 100.00 (100.00)
Epoch: [87][330/391]	Time  0.032 ( 0.029)	Data  0.001 ( 0.002)	Loss 1.2146e-02 (2.6216e-02)	Acc@1 100.00 ( 99.21)	Acc@5 100.00 (100.00)
Epoch: [87][340/391]	Time  0.027 ( 0.029)	Data  0.001 ( 0.002)	Loss 5.6841e-02 (2.6149e-02)	Acc@1  98.44 ( 99.23)	Acc@5 100.00 (100.00)
Epoch: [87][350/391]	Time  0.026 ( 0.029)	Data  0.001 ( 0.002)	Loss 2.0731e-02 (2.6158e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [87][360/391]	Time  0.027 ( 0.029)	Data  0.001 ( 0.002)	Loss 7.4719e-03 (2.5966e-02)	Acc@1 100.00 ( 99.23)	Acc@5 100.00 (100.00)
Epoch: [87][370/391]	Time  0.028 ( 0.029)	Data  0.001 ( 0.002)	Loss 4.1848e-02 (2.6082e-02)	Acc@1  97.66 ( 99.21)	Acc@5 100.00 (100.00)
Epoch: [87][380/391]	Time  0.041 ( 0.029)	Data  0.001 ( 0.002)	Loss 1.8685e-02 (2.6110e-02)	Acc@1  99.22 ( 99.21)	Acc@5 100.00 (100.00)
Epoch: [87][390/391]	Time  0.022 ( 0.029)	Data  0.001 ( 0.002)	Loss 2.9298e-02 (2.6319e-02)	Acc@1  97.50 ( 99.20)	Acc@5 100.00 (100.00)
## e[87] optimizer.zero_grad (sum) time: 0.01965045928955078
## e[87]       loss.backward (sum) time: 1.9202170372009277
## e[87]      optimizer.step (sum) time: 0.13010191917419434
## epoch[87] training(only) time: 11.477661848068237
# Switched to evaluate mode...
Test: [  0/100]	Time  0.165 ( 0.165)	Loss 1.5178e-01 (1.5178e-01)	Acc@1  96.00 ( 96.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.024 ( 0.035)	Loss 5.1589e-01 (3.3885e-01)	Acc@1  89.00 ( 92.36)	Acc@5 100.00 (100.00)
Test: [ 20/100]	Time  0.024 ( 0.029)	Loss 3.9393e-01 (3.8659e-01)	Acc@1  88.00 ( 91.48)	Acc@5 100.00 ( 99.71)
Test: [ 30/100]	Time  0.021 ( 0.027)	Loss 5.2386e-01 (4.1609e-01)	Acc@1  90.00 ( 91.13)	Acc@5  98.00 ( 99.58)
Test: [ 40/100]	Time  0.017 ( 0.025)	Loss 4.1009e-01 (4.2972e-01)	Acc@1  90.00 ( 90.93)	Acc@5 100.00 ( 99.56)
Test: [ 50/100]	Time  0.018 ( 0.024)	Loss 1.4092e-01 (4.2263e-01)	Acc@1  94.00 ( 91.02)	Acc@5 100.00 ( 99.59)
Test: [ 60/100]	Time  0.017 ( 0.023)	Loss 4.7616e-01 (4.0875e-01)	Acc@1  92.00 ( 91.00)	Acc@5  99.00 ( 99.62)
Test: [ 70/100]	Time  0.018 ( 0.023)	Loss 4.6923e-01 (3.9921e-01)	Acc@1  89.00 ( 91.13)	Acc@5 100.00 ( 99.65)
Test: [ 80/100]	Time  0.021 ( 0.023)	Loss 1.9344e-01 (3.9096e-01)	Acc@1  95.00 ( 91.22)	Acc@5 100.00 ( 99.68)
Test: [ 90/100]	Time  0.020 ( 0.022)	Loss 2.7497e-01 (3.9805e-01)	Acc@1  94.00 ( 91.14)	Acc@5 100.00 ( 99.71)
 * Acc@1 91.060 Acc@5 99.730
### epoch[87] execution time: 13.801208019256592
EPOCH 88
REMOVING: module.fire9.expand_3x3.0.bias
REMOVING: module.fire9.expand_3x3.1.weight
i:   0, name: module.fire9.expand_3x3.1.bias  changing lr from: 0.001063720370616826   to: 0.001005595870043812
i:   1, name:           module.conv10.weight  changing lr from: 0.001117979411353114   to: 0.001027868518844992
i:   2, name:             module.conv10.bias  changing lr from: 0.001188174978340949   to: 0.001066737070941547



# Switched to train mode...
Epoch: [88][  0/391]	Time  0.201 ( 0.201)	Data  0.171 ( 0.171)	Loss 2.3598e-02 (2.3598e-02)	Acc@1  99.22 ( 99.22)	Acc@5 100.00 (100.00)
Epoch: [88][ 10/391]	Time  0.038 ( 0.045)	Data  0.001 ( 0.017)	Loss 2.3323e-02 (2.7724e-02)	Acc@1  98.44 ( 98.93)	Acc@5 100.00 (100.00)
Epoch: [88][ 20/391]	Time  0.032 ( 0.037)	Data  0.001 ( 0.009)	Loss 3.5978e-02 (2.7967e-02)	Acc@1  98.44 ( 98.88)	Acc@5 100.00 (100.00)
Epoch: [88][ 30/391]	Time  0.031 ( 0.034)	Data  0.001 ( 0.007)	Loss 1.7968e-02 (2.7298e-02)	Acc@1 100.00 ( 98.94)	Acc@5 100.00 (100.00)
Epoch: [88][ 40/391]	Time  0.027 ( 0.033)	Data  0.001 ( 0.005)	Loss 1.5219e-02 (2.5832e-02)	Acc@1  99.22 ( 99.03)	Acc@5 100.00 (100.00)
Epoch: [88][ 50/391]	Time  0.026 ( 0.032)	Data  0.001 ( 0.005)	Loss 3.2738e-02 (2.7305e-02)	Acc@1  99.22 ( 98.97)	Acc@5 100.00 (100.00)
Epoch: [88][ 60/391]	Time  0.029 ( 0.031)	Data  0.001 ( 0.004)	Loss 2.0809e-02 (2.7586e-02)	Acc@1  99.22 ( 99.01)	Acc@5 100.00 (100.00)
Epoch: [88][ 70/391]	Time  0.025 ( 0.031)	Data  0.001 ( 0.004)	Loss 4.4375e-02 (2.6937e-02)	Acc@1  98.44 ( 99.05)	Acc@5 100.00 (100.00)
Epoch: [88][ 80/391]	Time  0.024 ( 0.030)	Data  0.001 ( 0.003)	Loss 2.7276e-02 (2.7537e-02)	Acc@1  99.22 ( 99.04)	Acc@5 100.00 (100.00)
Epoch: [88][ 90/391]	Time  0.029 ( 0.030)	Data  0.002 ( 0.003)	Loss 1.4945e-02 (2.6825e-02)	Acc@1  99.22 ( 99.07)	Acc@5 100.00 (100.00)
Epoch: [88][100/391]	Time  0.025 ( 0.030)	Data  0.001 ( 0.003)	Loss 1.3391e-02 (2.6891e-02)	Acc@1 100.00 ( 99.07)	Acc@5 100.00 (100.00)
Epoch: [88][110/391]	Time  0.026 ( 0.030)	Data  0.001 ( 0.003)	Loss 1.1544e-02 (2.6816e-02)	Acc@1 100.00 ( 99.08)	Acc@5 100.00 (100.00)
Epoch: [88][120/391]	Time  0.030 ( 0.030)	Data  0.004 ( 0.003)	Loss 4.8572e-02 (2.7629e-02)	Acc@1  98.44 ( 99.04)	Acc@5 100.00 (100.00)
Epoch: [88][130/391]	Time  0.030 ( 0.030)	Data  0.001 ( 0.003)	Loss 8.7599e-03 (2.7009e-02)	Acc@1 100.00 ( 99.08)	Acc@5 100.00 (100.00)
Epoch: [88][140/391]	Time  0.027 ( 0.030)	Data  0.003 ( 0.002)	Loss 7.3000e-03 (2.6918e-02)	Acc@1 100.00 ( 99.09)	Acc@5 100.00 (100.00)
Epoch: [88][150/391]	Time  0.025 ( 0.030)	Data  0.001 ( 0.002)	Loss 2.9749e-02 (2.7041e-02)	Acc@1  99.22 ( 99.09)	Acc@5 100.00 (100.00)
Epoch: [88][160/391]	Time  0.036 ( 0.030)	Data  0.001 ( 0.002)	Loss 2.2997e-02 (2.7508e-02)	Acc@1 100.00 ( 99.07)	Acc@5 100.00 (100.00)
Epoch: [88][170/391]	Time  0.025 ( 0.029)	Data  0.001 ( 0.002)	Loss 1.2065e-02 (2.7502e-02)	Acc@1 100.00 ( 99.06)	Acc@5 100.00 (100.00)
Epoch: [88][180/391]	Time  0.026 ( 0.029)	Data  0.001 ( 0.002)	Loss 1.4652e-02 (2.7040e-02)	Acc@1 100.00 ( 99.09)	Acc@5 100.00 (100.00)
Epoch: [88][190/391]	Time  0.038 ( 0.029)	Data  0.001 ( 0.002)	Loss 5.3667e-02 (2.7400e-02)	Acc@1  99.22 ( 99.08)	Acc@5 100.00 (100.00)
Epoch: [88][200/391]	Time  0.034 ( 0.029)	Data  0.001 ( 0.002)	Loss 4.1044e-02 (2.7501e-02)	Acc@1  99.22 ( 99.08)	Acc@5 100.00 (100.00)
Epoch: [88][210/391]	Time  0.025 ( 0.029)	Data  0.001 ( 0.002)	Loss 7.2756e-03 (2.7353e-02)	Acc@1 100.00 ( 99.09)	Acc@5 100.00 (100.00)
Epoch: [88][220/391]	Time  0.033 ( 0.029)	Data  0.001 ( 0.002)	Loss 1.6212e-02 (2.7083e-02)	Acc@1  99.22 ( 99.10)	Acc@5 100.00 (100.00)
Epoch: [88][230/391]	Time  0.026 ( 0.029)	Data  0.001 ( 0.002)	Loss 5.4096e-02 (2.6970e-02)	Acc@1  96.09 ( 99.09)	Acc@5 100.00 (100.00)
Epoch: [88][240/391]	Time  0.026 ( 0.029)	Data  0.002 ( 0.002)	Loss 1.2726e-02 (2.6854e-02)	Acc@1 100.00 ( 99.10)	Acc@5 100.00 (100.00)
Epoch: [88][250/391]	Time  0.026 ( 0.029)	Data  0.001 ( 0.002)	Loss 2.3667e-02 (2.6766e-02)	Acc@1  99.22 ( 99.10)	Acc@5 100.00 (100.00)
Epoch: [88][260/391]	Time  0.025 ( 0.029)	Data  0.001 ( 0.002)	Loss 3.6734e-02 (2.6632e-02)	Acc@1  98.44 ( 99.11)	Acc@5 100.00 (100.00)
Epoch: [88][270/391]	Time  0.026 ( 0.029)	Data  0.001 ( 0.002)	Loss 1.7296e-02 (2.6799e-02)	Acc@1  99.22 ( 99.10)	Acc@5 100.00 (100.00)
Epoch: [88][280/391]	Time  0.026 ( 0.029)	Data  0.001 ( 0.002)	Loss 1.0028e-02 (2.6460e-02)	Acc@1 100.00 ( 99.12)	Acc@5 100.00 (100.00)
Epoch: [88][290/391]	Time  0.034 ( 0.029)	Data  0.001 ( 0.002)	Loss 3.6339e-02 (2.6650e-02)	Acc@1  97.66 ( 99.11)	Acc@5 100.00 (100.00)
Epoch: [88][300/391]	Time  0.029 ( 0.029)	Data  0.001 ( 0.002)	Loss 7.2450e-02 (2.6795e-02)	Acc@1  97.66 ( 99.11)	Acc@5 100.00 (100.00)
Epoch: [88][310/391]	Time  0.028 ( 0.029)	Data  0.001 ( 0.002)	Loss 2.0452e-02 (2.6966e-02)	Acc@1 100.00 ( 99.11)	Acc@5 100.00 (100.00)
Epoch: [88][320/391]	Time  0.027 ( 0.029)	Data  0.001 ( 0.002)	Loss 2.3548e-02 (2.6868e-02)	Acc@1  99.22 ( 99.12)	Acc@5 100.00 (100.00)
Epoch: [88][330/391]	Time  0.044 ( 0.029)	Data  0.002 ( 0.002)	Loss 3.9475e-03 (2.6798e-02)	Acc@1 100.00 ( 99.12)	Acc@5 100.00 (100.00)
Epoch: [88][340/391]	Time  0.026 ( 0.029)	Data  0.001 ( 0.002)	Loss 2.5612e-02 (2.7181e-02)	Acc@1  99.22 ( 99.11)	Acc@5 100.00 (100.00)
Epoch: [88][350/391]	Time  0.034 ( 0.029)	Data  0.001 ( 0.002)	Loss 5.1509e-02 (2.7128e-02)	Acc@1  98.44 ( 99.11)	Acc@5 100.00 (100.00)
Epoch: [88][360/391]	Time  0.026 ( 0.029)	Data  0.001 ( 0.002)	Loss 2.3277e-02 (2.7073e-02)	Acc@1 100.00 ( 99.12)	Acc@5 100.00 (100.00)
Epoch: [88][370/391]	Time  0.037 ( 0.029)	Data  0.001 ( 0.002)	Loss 1.6785e-02 (2.6787e-02)	Acc@1 100.00 ( 99.14)	Acc@5 100.00 (100.00)
Epoch: [88][380/391]	Time  0.026 ( 0.029)	Data  0.001 ( 0.002)	Loss 3.3659e-02 (2.6736e-02)	Acc@1  99.22 ( 99.14)	Acc@5 100.00 (100.00)
Epoch: [88][390/391]	Time  0.018 ( 0.029)	Data  0.001 ( 0.002)	Loss 6.5483e-03 (2.6722e-02)	Acc@1 100.00 ( 99.14)	Acc@5 100.00 (100.00)
## e[88] optimizer.zero_grad (sum) time: 0.014864206314086914
## e[88]       loss.backward (sum) time: 1.9226672649383545
## e[88]      optimizer.step (sum) time: 0.08398938179016113
## epoch[88] training(only) time: 11.3836088180542
# Switched to evaluate mode...
Test: [  0/100]	Time  0.173 ( 0.173)	Loss 1.8677e-01 (1.8677e-01)	Acc@1  95.00 ( 95.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.022 ( 0.033)	Loss 5.4971e-01 (3.4184e-01)	Acc@1  90.00 ( 92.00)	Acc@5 100.00 (100.00)
Test: [ 20/100]	Time  0.022 ( 0.027)	Loss 3.7424e-01 (3.8709e-01)	Acc@1  88.00 ( 91.29)	Acc@5 100.00 ( 99.71)
Test: [ 30/100]	Time  0.023 ( 0.025)	Loss 4.8351e-01 (4.1436e-01)	Acc@1  91.00 ( 91.29)	Acc@5  97.00 ( 99.61)
Test: [ 40/100]	Time  0.021 ( 0.024)	Loss 4.0820e-01 (4.2788e-01)	Acc@1  89.00 ( 91.02)	Acc@5 100.00 ( 99.63)
Test: [ 50/100]	Time  0.024 ( 0.024)	Loss 1.3777e-01 (4.1832e-01)	Acc@1  95.00 ( 91.22)	Acc@5 100.00 ( 99.63)
Test: [ 60/100]	Time  0.017 ( 0.023)	Loss 4.6239e-01 (4.0355e-01)	Acc@1  92.00 ( 91.18)	Acc@5  99.00 ( 99.66)
Test: [ 70/100]	Time  0.017 ( 0.023)	Loss 4.8003e-01 (3.9352e-01)	Acc@1  89.00 ( 91.23)	Acc@5 100.00 ( 99.69)
Test: [ 80/100]	Time  0.022 ( 0.022)	Loss 2.1535e-01 (3.8565e-01)	Acc@1  94.00 ( 91.30)	Acc@5 100.00 ( 99.72)
Test: [ 90/100]	Time  0.020 ( 0.022)	Loss 2.7587e-01 (3.9196e-01)	Acc@1  94.00 ( 91.22)	Acc@5 100.00 ( 99.75)
 * Acc@1 91.210 Acc@5 99.750
### epoch[88] execution time: 13.681472778320312
EPOCH 89
REMOVING: module.fire9.expand_3x3.1.bias
REMOVING: module.conv10.weight
i:   0, name:             module.conv10.bias  changing lr from: 0.001066737070941547   to: 0.001006855733852490



# Switched to train mode...
Epoch: [89][  0/391]	Time  0.199 ( 0.199)	Data  0.170 ( 0.170)	Loss 3.6148e-02 (3.6148e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
Epoch: [89][ 10/391]	Time  0.026 ( 0.043)	Data  0.001 ( 0.017)	Loss 2.2241e-02 (2.9539e-02)	Acc@1  99.22 ( 98.93)	Acc@5 100.00 (100.00)
Epoch: [89][ 20/391]	Time  0.025 ( 0.035)	Data  0.001 ( 0.009)	Loss 1.3169e-02 (3.0326e-02)	Acc@1  99.22 ( 98.88)	Acc@5 100.00 (100.00)
Epoch: [89][ 30/391]	Time  0.024 ( 0.033)	Data  0.001 ( 0.007)	Loss 1.6548e-02 (3.0034e-02)	Acc@1  99.22 ( 98.92)	Acc@5 100.00 (100.00)
Epoch: [89][ 40/391]	Time  0.025 ( 0.032)	Data  0.001 ( 0.005)	Loss 1.9368e-02 (2.8396e-02)	Acc@1  99.22 ( 99.05)	Acc@5 100.00 (100.00)
Epoch: [89][ 50/391]	Time  0.031 ( 0.031)	Data  0.001 ( 0.005)	Loss 8.9415e-02 (2.9776e-02)	Acc@1  96.88 ( 98.99)	Acc@5 100.00 (100.00)
Epoch: [89][ 60/391]	Time  0.025 ( 0.031)	Data  0.001 ( 0.004)	Loss 3.0298e-02 (2.8985e-02)	Acc@1  98.44 ( 99.00)	Acc@5 100.00 (100.00)
Epoch: [89][ 70/391]	Time  0.031 ( 0.030)	Data  0.004 ( 0.004)	Loss 1.9820e-02 (2.8225e-02)	Acc@1 100.00 ( 99.09)	Acc@5 100.00 (100.00)
Epoch: [89][ 80/391]	Time  0.025 ( 0.030)	Data  0.001 ( 0.003)	Loss 2.2928e-02 (2.7713e-02)	Acc@1  99.22 ( 99.10)	Acc@5 100.00 (100.00)
Epoch: [89][ 90/391]	Time  0.035 ( 0.030)	Data  0.001 ( 0.003)	Loss 2.0219e-02 (2.7735e-02)	Acc@1  99.22 ( 99.13)	Acc@5 100.00 (100.00)
Epoch: [89][100/391]	Time  0.028 ( 0.030)	Data  0.001 ( 0.003)	Loss 2.8343e-02 (2.8488e-02)	Acc@1  99.22 ( 99.13)	Acc@5 100.00 (100.00)
Epoch: [89][110/391]	Time  0.029 ( 0.029)	Data  0.002 ( 0.003)	Loss 2.6858e-02 (2.7726e-02)	Acc@1  98.44 ( 99.15)	Acc@5 100.00 (100.00)
Epoch: [89][120/391]	Time  0.026 ( 0.029)	Data  0.001 ( 0.003)	Loss 1.1632e-02 (2.6927e-02)	Acc@1  99.22 ( 99.18)	Acc@5 100.00 (100.00)
Epoch: [89][130/391]	Time  0.028 ( 0.029)	Data  0.005 ( 0.003)	Loss 3.3929e-02 (2.6787e-02)	Acc@1  98.44 ( 99.17)	Acc@5 100.00 (100.00)
Epoch: [89][140/391]	Time  0.035 ( 0.029)	Data  0.006 ( 0.003)	Loss 7.5988e-02 (2.7035e-02)	Acc@1  96.88 ( 99.13)	Acc@5 100.00 (100.00)
Epoch: [89][150/391]	Time  0.028 ( 0.029)	Data  0.001 ( 0.002)	Loss 3.6411e-02 (2.6733e-02)	Acc@1  98.44 ( 99.15)	Acc@5 100.00 (100.00)
Epoch: [89][160/391]	Time  0.025 ( 0.029)	Data  0.001 ( 0.002)	Loss 1.7982e-02 (2.6619e-02)	Acc@1 100.00 ( 99.15)	Acc@5 100.00 (100.00)
Epoch: [89][170/391]	Time  0.027 ( 0.029)	Data  0.001 ( 0.002)	Loss 1.2937e-02 (2.6693e-02)	Acc@1 100.00 ( 99.16)	Acc@5 100.00 (100.00)
Epoch: [89][180/391]	Time  0.025 ( 0.029)	Data  0.001 ( 0.002)	Loss 2.1723e-02 (2.6642e-02)	Acc@1  99.22 ( 99.16)	Acc@5 100.00 (100.00)
Epoch: [89][190/391]	Time  0.025 ( 0.029)	Data  0.001 ( 0.002)	Loss 2.5899e-02 (2.6480e-02)	Acc@1  99.22 ( 99.17)	Acc@5 100.00 (100.00)
Epoch: [89][200/391]	Time  0.028 ( 0.029)	Data  0.002 ( 0.002)	Loss 3.4262e-02 (2.6695e-02)	Acc@1  99.22 ( 99.15)	Acc@5 100.00 (100.00)
Epoch: [89][210/391]	Time  0.025 ( 0.029)	Data  0.001 ( 0.002)	Loss 1.3545e-02 (2.6899e-02)	Acc@1  99.22 ( 99.13)	Acc@5 100.00 (100.00)
Epoch: [89][220/391]	Time  0.024 ( 0.029)	Data  0.000 ( 0.002)	Loss 3.2162e-02 (2.6979e-02)	Acc@1  99.22 ( 99.11)	Acc@5 100.00 (100.00)
Epoch: [89][230/391]	Time  0.025 ( 0.029)	Data  0.001 ( 0.002)	Loss 2.8280e-02 (2.7283e-02)	Acc@1  99.22 ( 99.10)	Acc@5 100.00 (100.00)
Epoch: [89][240/391]	Time  0.033 ( 0.029)	Data  0.001 ( 0.002)	Loss 8.5215e-02 (2.7310e-02)	Acc@1  96.09 ( 99.10)	Acc@5 100.00 (100.00)
Epoch: [89][250/391]	Time  0.033 ( 0.029)	Data  0.001 ( 0.002)	Loss 1.0712e-02 (2.6891e-02)	Acc@1 100.00 ( 99.12)	Acc@5 100.00 (100.00)
Epoch: [89][260/391]	Time  0.031 ( 0.029)	Data  0.001 ( 0.002)	Loss 1.0170e-02 (2.6770e-02)	Acc@1 100.00 ( 99.13)	Acc@5 100.00 (100.00)
Epoch: [89][270/391]	Time  0.025 ( 0.029)	Data  0.001 ( 0.002)	Loss 5.1992e-02 (2.7099e-02)	Acc@1  98.44 ( 99.12)	Acc@5 100.00 (100.00)
Epoch: [89][280/391]	Time  0.033 ( 0.029)	Data  0.001 ( 0.002)	Loss 1.1060e-02 (2.6946e-02)	Acc@1 100.00 ( 99.13)	Acc@5 100.00 (100.00)
Epoch: [89][290/391]	Time  0.032 ( 0.029)	Data  0.001 ( 0.002)	Loss 2.6120e-02 (2.6802e-02)	Acc@1  99.22 ( 99.13)	Acc@5 100.00 (100.00)
Epoch: [89][300/391]	Time  0.038 ( 0.029)	Data  0.001 ( 0.002)	Loss 2.5678e-02 (2.6959e-02)	Acc@1  99.22 ( 99.11)	Acc@5 100.00 (100.00)
Epoch: [89][310/391]	Time  0.028 ( 0.029)	Data  0.001 ( 0.002)	Loss 1.2649e-02 (2.6940e-02)	Acc@1 100.00 ( 99.12)	Acc@5 100.00 (100.00)
Epoch: [89][320/391]	Time  0.029 ( 0.029)	Data  0.001 ( 0.002)	Loss 6.1492e-02 (2.7261e-02)	Acc@1  97.66 ( 99.10)	Acc@5 100.00 (100.00)
Epoch: [89][330/391]	Time  0.034 ( 0.029)	Data  0.003 ( 0.002)	Loss 2.8386e-02 (2.7018e-02)	Acc@1  99.22 ( 99.11)	Acc@5 100.00 (100.00)
Epoch: [89][340/391]	Time  0.023 ( 0.029)	Data  0.001 ( 0.002)	Loss 9.2309e-03 (2.7128e-02)	Acc@1 100.00 ( 99.11)	Acc@5 100.00 (100.00)
Epoch: [89][350/391]	Time  0.025 ( 0.029)	Data  0.001 ( 0.002)	Loss 3.7072e-02 (2.7118e-02)	Acc@1  99.22 ( 99.11)	Acc@5 100.00 (100.00)
Epoch: [89][360/391]	Time  0.025 ( 0.029)	Data  0.001 ( 0.002)	Loss 8.2534e-03 (2.7081e-02)	Acc@1 100.00 ( 99.11)	Acc@5 100.00 (100.00)
Epoch: [89][370/391]	Time  0.036 ( 0.029)	Data  0.001 ( 0.002)	Loss 3.0535e-02 (2.7053e-02)	Acc@1  99.22 ( 99.11)	Acc@5 100.00 (100.00)
Epoch: [89][380/391]	Time  0.028 ( 0.029)	Data  0.001 ( 0.002)	Loss 6.3428e-03 (2.7092e-02)	Acc@1 100.00 ( 99.11)	Acc@5 100.00 (100.00)
Epoch: [89][390/391]	Time  0.018 ( 0.028)	Data  0.001 ( 0.002)	Loss 1.7432e-02 (2.7114e-02)	Acc@1 100.00 ( 99.11)	Acc@5 100.00 (100.00)
## e[89] optimizer.zero_grad (sum) time: 0.0075016021728515625
## e[89]       loss.backward (sum) time: 1.7607853412628174
## e[89]      optimizer.step (sum) time: 0.03360605239868164
## epoch[89] training(only) time: 11.26969599723816
# Switched to evaluate mode...
Test: [  0/100]	Time  0.169 ( 0.169)	Loss 1.9770e-01 (1.9770e-01)	Acc@1  95.00 ( 95.00)	Acc@5 100.00 (100.00)
Test: [ 10/100]	Time  0.023 ( 0.035)	Loss 5.5100e-01 (3.4096e-01)	Acc@1  89.00 ( 91.64)	Acc@5 100.00 (100.00)
Test: [ 20/100]	Time  0.022 ( 0.029)	Loss 3.6039e-01 (3.8065e-01)	Acc@1  88.00 ( 91.19)	Acc@5 100.00 ( 99.71)
Test: [ 30/100]	Time  0.023 ( 0.027)	Loss 4.8100e-01 (4.1041e-01)	Acc@1  91.00 ( 91.10)	Acc@5  97.00 ( 99.61)
Test: [ 40/100]	Time  0.020 ( 0.025)	Loss 4.0022e-01 (4.2415e-01)	Acc@1  89.00 ( 90.85)	Acc@5  99.00 ( 99.59)
Test: [ 50/100]	Time  0.018 ( 0.024)	Loss 1.4424e-01 (4.1515e-01)	Acc@1  95.00 ( 91.06)	Acc@5 100.00 ( 99.61)
Test: [ 60/100]	Time  0.021 ( 0.024)	Loss 4.4550e-01 (3.9973e-01)	Acc@1  93.00 ( 91.08)	Acc@5 100.00 ( 99.66)
Test: [ 70/100]	Time  0.022 ( 0.023)	Loss 5.0370e-01 (3.9000e-01)	Acc@1  89.00 ( 91.15)	Acc@5 100.00 ( 99.69)
Test: [ 80/100]	Time  0.018 ( 0.023)	Loss 2.2218e-01 (3.8290e-01)	Acc@1  93.00 ( 91.25)	Acc@5 100.00 ( 99.72)
Test: [ 90/100]	Time  0.022 ( 0.023)	Loss 2.9766e-01 (3.8962e-01)	Acc@1  95.00 ( 91.21)	Acc@5 100.00 ( 99.75)
 * Acc@1 91.180 Acc@5 99.740
### epoch[89] execution time: 13.597528457641602
### Training complete:
*** Model named parameters and requires_grad:
name:           module.stem.0.weight  req_grad: False 
name:             module.stem.0.bias  req_grad: False 
name:           module.stem.1.weight  req_grad: False 
name:             module.stem.1.bias  req_grad: False 
name:  module.fire2.squeeze.0.weight  req_grad: False 
name:    module.fire2.squeeze.0.bias  req_grad: False 
name:  module.fire2.squeeze.1.weight  req_grad: False 
name:    module.fire2.squeeze.1.bias  req_grad: False 
name: module.fire2.expand_1x1.0.weight  req_grad: False 
name: module.fire2.expand_1x1.0.bias  req_grad: False 
name: module.fire2.expand_1x1.1.weight  req_grad: False 
name: module.fire2.expand_1x1.1.bias  req_grad: False 
name: module.fire2.expand_3x3.0.weight  req_grad: False 
name: module.fire2.expand_3x3.0.bias  req_grad: False 
name: module.fire2.expand_3x3.1.weight  req_grad: False 
name: module.fire2.expand_3x3.1.bias  req_grad: False 
name:  module.fire3.squeeze.0.weight  req_grad: False 
name:    module.fire3.squeeze.0.bias  req_grad: False 
name:  module.fire3.squeeze.1.weight  req_grad: False 
name:    module.fire3.squeeze.1.bias  req_grad: False 
name: module.fire3.expand_1x1.0.weight  req_grad: False 
name: module.fire3.expand_1x1.0.bias  req_grad: False 
name: module.fire3.expand_1x1.1.weight  req_grad: False 
name: module.fire3.expand_1x1.1.bias  req_grad: False 
name: module.fire3.expand_3x3.0.weight  req_grad: False 
name: module.fire3.expand_3x3.0.bias  req_grad: False 
name: module.fire3.expand_3x3.1.weight  req_grad: False 
name: module.fire3.expand_3x3.1.bias  req_grad: False 
name:  module.fire4.squeeze.0.weight  req_grad: False 
name:    module.fire4.squeeze.0.bias  req_grad: False 
name:  module.fire4.squeeze.1.weight  req_grad: False 
name:    module.fire4.squeeze.1.bias  req_grad: False 
name: module.fire4.expand_1x1.0.weight  req_grad: False 
name: module.fire4.expand_1x1.0.bias  req_grad: False 
name: module.fire4.expand_1x1.1.weight  req_grad: False 
name: module.fire4.expand_1x1.1.bias  req_grad: False 
name: module.fire4.expand_3x3.0.weight  req_grad: False 
name: module.fire4.expand_3x3.0.bias  req_grad: False 
name: module.fire4.expand_3x3.1.weight  req_grad: False 
name: module.fire4.expand_3x3.1.bias  req_grad: False 
name:  module.fire5.squeeze.0.weight  req_grad: False 
name:    module.fire5.squeeze.0.bias  req_grad: False 
name:  module.fire5.squeeze.1.weight  req_grad: False 
name:    module.fire5.squeeze.1.bias  req_grad: False 
name: module.fire5.expand_1x1.0.weight  req_grad: False 
name: module.fire5.expand_1x1.0.bias  req_grad: False 
name: module.fire5.expand_1x1.1.weight  req_grad: False 
name: module.fire5.expand_1x1.1.bias  req_grad: False 
name: module.fire5.expand_3x3.0.weight  req_grad: False 
name: module.fire5.expand_3x3.0.bias  req_grad: False 
name: module.fire5.expand_3x3.1.weight  req_grad: False 
name: module.fire5.expand_3x3.1.bias  req_grad: False 
name:  module.fire6.squeeze.0.weight  req_grad: False 
name:    module.fire6.squeeze.0.bias  req_grad: False 
name:  module.fire6.squeeze.1.weight  req_grad: False 
name:    module.fire6.squeeze.1.bias  req_grad: False 
name: module.fire6.expand_1x1.0.weight  req_grad: False 
name: module.fire6.expand_1x1.0.bias  req_grad: False 
name: module.fire6.expand_1x1.1.weight  req_grad: False 
name: module.fire6.expand_1x1.1.bias  req_grad: False 
name: module.fire6.expand_3x3.0.weight  req_grad: False 
name: module.fire6.expand_3x3.0.bias  req_grad: False 
name: module.fire6.expand_3x3.1.weight  req_grad: False 
name: module.fire6.expand_3x3.1.bias  req_grad: False 
name:  module.fire7.squeeze.0.weight  req_grad: False 
name:    module.fire7.squeeze.0.bias  req_grad: False 
name:  module.fire7.squeeze.1.weight  req_grad: False 
name:    module.fire7.squeeze.1.bias  req_grad: False 
name: module.fire7.expand_1x1.0.weight  req_grad: False 
name: module.fire7.expand_1x1.0.bias  req_grad: False 
name: module.fire7.expand_1x1.1.weight  req_grad: False 
name: module.fire7.expand_1x1.1.bias  req_grad: False 
name: module.fire7.expand_3x3.0.weight  req_grad: False 
name: module.fire7.expand_3x3.0.bias  req_grad: False 
name: module.fire7.expand_3x3.1.weight  req_grad: False 
name: module.fire7.expand_3x3.1.bias  req_grad: False 
name:  module.fire8.squeeze.0.weight  req_grad: False 
name:    module.fire8.squeeze.0.bias  req_grad: False 
name:  module.fire8.squeeze.1.weight  req_grad: False 
name:    module.fire8.squeeze.1.bias  req_grad: False 
name: module.fire8.expand_1x1.0.weight  req_grad: False 
name: module.fire8.expand_1x1.0.bias  req_grad: False 
name: module.fire8.expand_1x1.1.weight  req_grad: False 
name: module.fire8.expand_1x1.1.bias  req_grad: False 
name: module.fire8.expand_3x3.0.weight  req_grad: False 
name: module.fire8.expand_3x3.0.bias  req_grad: False 
name: module.fire8.expand_3x3.1.weight  req_grad: False 
name: module.fire8.expand_3x3.1.bias  req_grad: False 
name:  module.fire9.squeeze.0.weight  req_grad: False 
name:    module.fire9.squeeze.0.bias  req_grad: False 
name:  module.fire9.squeeze.1.weight  req_grad: False 
name:    module.fire9.squeeze.1.bias  req_grad: False 
name: module.fire9.expand_1x1.0.weight  req_grad: False 
name: module.fire9.expand_1x1.0.bias  req_grad: False 
name: module.fire9.expand_1x1.1.weight  req_grad: False 
name: module.fire9.expand_1x1.1.bias  req_grad: False 
name: module.fire9.expand_3x3.0.weight  req_grad: False 
name: module.fire9.expand_3x3.0.bias  req_grad: False 
name: module.fire9.expand_3x3.1.weight  req_grad: False 
name: module.fire9.expand_3x3.1.bias  req_grad: False 
name:           module.conv10.weight  req_grad: False 
name:             module.conv10.bias  req_grad:  True 


*** Optimizer groups, parameters and req_grads
#        requires_grad:                            True
#           param_name:              module.conv10.bias
#                   lr:             0.00100685573385249
#             momentum:                             0.9
#         weight_decay:                          0.0001
#            dampening:                               0
#             nesterov:                           False



*** Optimizer group lrs
# group:  0,   name:             module.conv10.bias,   req_grad:   True   lr: 0.001006855733852490,   mmm: 0.90000,   weight_decay:    0.0,   damp:    0.0,   nesterov:  False
---------------
#### total training(only) time: 1336.36199426651
##### Total run time: 1548.866502046585
